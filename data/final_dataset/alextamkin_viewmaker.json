{"home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.simclr.SimCLRObjective.__init__": [[11, 17], ["super().__init__", "src.utils.utils.l2_normalize", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["    ", "def", "__init__", "(", "self", ",", "outputs1", ",", "outputs2", ",", "t", ",", "push_only", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "outputs1", "=", "l2_normalize", "(", "outputs1", ",", "dim", "=", "1", ")", "\n", "self", ".", "outputs2", "=", "l2_normalize", "(", "outputs2", ",", "dim", "=", "1", ")", "\n", "self", ".", "t", "=", "t", "\n", "self", ".", "push_only", "=", "push_only", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.simclr.SimCLRObjective.get_loss": [[18, 29], ["simclr.SimCLRObjective.outputs1.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ")", ":", "\n", "        ", "batch_size", "=", "self", ".", "outputs1", ".", "size", "(", "0", ")", "# batch_size x out_dim", "\n", "witness_score", "=", "torch", ".", "sum", "(", "self", ".", "outputs1", "*", "self", ".", "outputs2", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "push_only", ":", "\n", "# Don't pull views together.", "\n", "            ", "witness_score", "=", "0", "\n", "", "outputs12", "=", "torch", ".", "cat", "(", "[", "self", ".", "outputs1", ",", "self", ".", "outputs2", "]", ",", "dim", "=", "0", ")", "\n", "witness_norm", "=", "self", ".", "outputs1", "@", "outputs12", ".", "T", "\n", "witness_norm", "=", "torch", ".", "logsumexp", "(", "witness_norm", "/", "self", ".", "t", ",", "dim", "=", "1", ")", "-", "math", ".", "log", "(", "2", "*", "batch_size", ")", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "witness_score", "/", "self", ".", "t", "-", "witness_norm", ")", "\n", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.__init__": [[10, 17], ["super().__init__", "memory_bank.MemoryBank.register_buffer", "memory_bank.MemoryBank._create", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank._create"], ["def", "__init__", "(", "self", ",", "size", ",", "dim", ",", "dtype", "=", "float", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "register_buffer", "(", "'_bank'", ",", "self", ".", "_create", "(", ")", ")", "\n", "if", "dtype", "==", "int", ":", "\n", "            ", "self", ".", "_bank", "=", "torch", ".", "zeros_like", "(", "self", ".", "_bank", ",", "dtype", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank._create": [[18, 26], ["torch.rand", "src.utils.utils.l2_normalize", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "", "def", "_create", "(", "self", ")", ":", "\n", "# initialize random weights", "\n", "        ", "mb_init", "=", "torch", ".", "rand", "(", "self", ".", "size", ",", "self", ".", "dim", ",", "requires_grad", "=", "False", ")", "\n", "std_dev", "=", "1.", "/", "np", ".", "sqrt", "(", "self", ".", "dim", "/", "3", ")", "\n", "mb_init", "=", "mb_init", "*", "(", "2", "*", "std_dev", ")", "-", "std_dev", "\n", "# L2 normalise so that the norm is 1", "\n", "mb_init", "=", "l2_normalize", "(", "mb_init", ",", "dim", "=", "1", ")", "\n", "return", "mb_init", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.as_tensor": [[27, 29], ["None"], "methods", ["None"], ["", "def", "as_tensor", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_bank", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.at_idxs": [[30, 32], ["torch.index_select"], "methods", ["None"], ["", "def", "at_idxs", "(", "self", ",", "idxs", ")", ":", "\n", "        ", "return", "torch", ".", "index_select", "(", "self", ".", "_bank", ",", "0", ",", "idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.get_all_distances": [[33, 48], ["torch.sqrt", "len", "memory_bank.MemoryBank._bank.unsqueeze", "emb_batch.unsqueeze", "torch.einsum"], "methods", ["None"], ["", "def", "get_all_distances", "(", "self", ",", "emb_batch", ")", ":", "\n", "        ", "'''Returns a tensor of L2-distances between each given embedding and all the embeddings in the bank\n        \n        Args:\n            emb_batch: [batch_size, emb_dim] Tensor of embeddings\n        \n        Returns:\n            [batch_size, memory_bank_size] Tensor of L2-norm distances\n        '''", "\n", "assert", "len", "(", "emb_batch", ".", "shape", ")", "==", "2", "\n", "\n", "differences", "=", "self", ".", "_bank", ".", "unsqueeze", "(", "0", ")", "-", "emb_batch", ".", "unsqueeze", "(", "1", ")", "\n", "# Broadcasted elementwise dot product.", "\n", "distances", "=", "torch", ".", "sqrt", "(", "torch", ".", "einsum", "(", "'abc,abc->ab'", ",", "differences", ",", "differences", ")", ")", "\n", "return", "distances", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.get_all_dot_products": [[49, 53], ["torch.matmul", "len", "torch.transpose", "vec.size"], "methods", ["None"], ["", "def", "get_all_dot_products", "(", "self", ",", "vec", ")", ":", "\n", "# [bs, dim]", "\n", "        ", "assert", "len", "(", "vec", ".", "size", "(", ")", ")", "==", "2", "\n", "return", "torch", ".", "matmul", "(", "vec", ",", "torch", ".", "transpose", "(", "self", ".", "_bank", ",", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.get_dot_products": [[54, 82], ["list", "list", "torch.sum", "vec.view.view.size", "idxs.size", "len", "len", "len", "vec.view.view.view", "list", "torch.no_grad", "torch.index_select", "list", "torch.no_grad", "idxs.view", "torch.index_select", "memory_vecs.view.view.view", "list", "prods.size", "memory_vecs.view.view.size", "idxs.size", "idxs.size", "memory_bank.MemoryBank._bank.size", "memory_vecs.view.view.size", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "get_dot_products", "(", "self", ",", "vec", ",", "idxs", ")", ":", "\n", "        ", "vec_shape", "=", "list", "(", "vec", ".", "size", "(", ")", ")", "# [bs, dim]", "\n", "idxs_shape", "=", "list", "(", "idxs", ".", "size", "(", ")", ")", "# [bs, ...]", "\n", "\n", "assert", "len", "(", "idxs_shape", ")", "in", "[", "1", ",", "2", "]", "\n", "assert", "len", "(", "vec_shape", ")", "==", "2", "\n", "assert", "vec_shape", "[", "0", "]", "==", "idxs_shape", "[", "0", "]", "\n", "\n", "if", "len", "(", "idxs_shape", ")", "==", "1", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "memory_vecs", "=", "torch", ".", "index_select", "(", "self", ".", "_bank", ",", "0", ",", "idxs", ")", "\n", "memory_vecs_shape", "=", "list", "(", "memory_vecs", ".", "size", "(", ")", ")", "\n", "assert", "memory_vecs_shape", "[", "0", "]", "==", "idxs_shape", "[", "0", "]", "\n", "", "", "else", ":", "# len(idxs_shape) == 2", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "batch_size", ",", "k_dim", "=", "idxs", ".", "size", "(", "0", ")", ",", "idxs", ".", "size", "(", "1", ")", "\n", "flat_idxs", "=", "idxs", ".", "view", "(", "-", "1", ")", "\n", "memory_vecs", "=", "torch", ".", "index_select", "(", "self", ".", "_bank", ",", "0", ",", "flat_idxs", ")", "\n", "memory_vecs", "=", "memory_vecs", ".", "view", "(", "batch_size", ",", "k_dim", ",", "self", ".", "_bank", ".", "size", "(", "1", ")", ")", "\n", "memory_vecs_shape", "=", "list", "(", "memory_vecs", ".", "size", "(", ")", ")", "\n", "\n", "", "vec_shape", "[", "1", ":", "1", "]", "=", "[", "1", "]", "*", "(", "len", "(", "idxs_shape", ")", "-", "1", ")", "\n", "vec", "=", "vec", ".", "view", "(", "vec_shape", ")", "# [bs, 1, dim]", "\n", "\n", "", "prods", "=", "memory_vecs", "*", "vec", "\n", "assert", "list", "(", "prods", ".", "size", "(", ")", ")", "==", "memory_vecs_shape", "\n", "\n", "return", "torch", ".", "sum", "(", "prods", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.update": [[83, 88], ["data_memory.size", "memory_bank.MemoryBank._bank.scatter", "indices.unsqueeze().repeat", "data_memory.detach", "indices.unsqueeze"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "indices", ",", "data_memory", ")", ":", "\n", "# in lieu of scatter-update operation", "\n", "        ", "data_dim", "=", "data_memory", ".", "size", "(", "1", ")", "\n", "self", ".", "_bank", "=", "self", ".", "_bank", ".", "scatter", "(", "0", ",", "indices", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "data_dim", ")", ",", "\n", "data_memory", ".", "detach", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.infonce.NoiseConstrastiveEstimation.__init__": [[10, 19], ["indices.detach", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["    ", "def", "__init__", "(", "self", ",", "indices", ",", "outputs", ",", "memory_bank", ",", "k", "=", "4096", ",", "t", "=", "0.07", ",", "m", "=", "0.5", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "k", ",", "self", ".", "t", ",", "self", ".", "m", "=", "k", ",", "t", ",", "m", "\n", "\n", "self", ".", "indices", "=", "indices", ".", "detach", "(", ")", "\n", "self", ".", "outputs", "=", "l2_normalize", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "\n", "self", ".", "memory_bank", "=", "memory_bank", "\n", "self", ".", "device", "=", "outputs", ".", "device", "\n", "self", ".", "data_len", "=", "memory_bank", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.infonce.NoiseConstrastiveEstimation.updated_new_data_memory": [[20, 24], ["infonce.NoiseConstrastiveEstimation.memory_bank.at_idxs", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.at_idxs", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "def", "updated_new_data_memory", "(", "self", ")", ":", "\n", "        ", "data_memory", "=", "self", ".", "memory_bank", ".", "at_idxs", "(", "self", ".", "indices", ")", "\n", "new_data_memory", "=", "data_memory", "*", "self", ".", "m", "+", "(", "1", "-", "self", ".", "m", ")", "*", "self", ".", "outputs", "\n", "return", "l2_normalize", "(", "new_data_memory", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.infonce.NoiseConstrastiveEstimation.get_loss": [[25, 38], ["infonce.NoiseConstrastiveEstimation.indices.size", "infonce.NoiseConstrastiveEstimation.memory_bank.get_dot_products", "torch.randint", "noise_indx.long.long.long", "infonce.NoiseConstrastiveEstimation.memory_bank.get_dot_products", "torch.logsumexp", "math.log", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.get_dot_products", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.get_dot_products"], ["", "def", "get_loss", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "batch_size", "=", "self", ".", "indices", ".", "size", "(", "0", ")", "\n", "\n", "witness_score", "=", "self", ".", "memory_bank", ".", "get_dot_products", "(", "self", ".", "outputs", ",", "self", ".", "indices", ")", "\n", "\n", "noise_indx", "=", "torch", ".", "randint", "(", "0", ",", "self", ".", "data_len", ",", "(", "batch_size", ",", "self", ".", "k", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "# U(0, data_len)", "\n", "noise_indx", "=", "noise_indx", ".", "long", "(", ")", "\n", "witness_norm", "=", "self", ".", "memory_bank", ".", "get_dot_products", "(", "self", ".", "outputs", ",", "noise_indx", ")", "\n", "witness_norm", "=", "torch", ".", "logsumexp", "(", "witness_norm", "/", "self", ".", "t", ",", "dim", "=", "1", ")", "-", "math", ".", "log", "(", "self", ".", "k", ")", "\n", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "witness_score", "/", "self", ".", "t", "-", "witness_norm", ")", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialSimCLRLoss.__init__": [[12, 34], ["adversarial.AdversarialSimCLRLoss.normalize_embeddings"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialSimCLRLoss.normalize_embeddings"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "embs1", ",", "\n", "embs2", ",", "\n", "t", "=", "0.07", ",", "\n", "view_maker_loss_weight", "=", "1.0", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "'''Adversarial version of SimCLR loss.\n        \n        Args:\n            embs1: embeddings of the first views of the inputs\n            embs1: embeddings of the second views of the inputs\n            t: temperature\n            view_maker_loss_weight: how much to weight the view_maker loss vs the encoder loss\n        '''", "\n", "self", ".", "embs1", "=", "embs1", "\n", "self", ".", "embs2", "=", "embs2", "\n", "self", ".", "t", "=", "t", "\n", "self", ".", "view_maker_loss_weight", "=", "view_maker_loss_weight", "\n", "\n", "self", ".", "normalize_embeddings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialSimCLRLoss.normalize_embeddings": [[35, 38], ["src.utils.utils.l2_normalize", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "def", "normalize_embeddings", "(", "self", ")", ":", "\n", "        ", "self", ".", "embs1", "=", "l2_normalize", "(", "self", ".", "embs1", ")", "\n", "self", ".", "embs2", "=", "l2_normalize", "(", "self", ".", "embs2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialSimCLRLoss.get_loss": [[39, 45], ["src.objectives.simclr.SimCLRObjective", "src.objectives.simclr.SimCLRObjective.get_loss"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss"], ["", "def", "get_loss", "(", "self", ")", ":", "\n", "        ", "'''Return scalar encoder and view-maker losses for the batch'''", "\n", "simclr_loss", "=", "SimCLRObjective", "(", "self", ".", "embs1", ",", "self", ".", "embs2", ",", "self", ".", "t", ")", "\n", "encoder_loss", "=", "simclr_loss", ".", "get_loss", "(", ")", "\n", "view_maker_loss", "=", "-", "encoder_loss", "*", "self", ".", "view_maker_loss_weight", "\n", "return", "encoder_loss", ",", "view_maker_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.__init__": [[49, 68], ["indices.detach", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "indices", ",", "\n", "outputs", ",", "\n", "memory_bank", ",", "\n", "k", "=", "4096", ",", "\n", "t", "=", "0.07", ",", "\n", "m", "=", "0.5", ",", "\n", "view_maker_loss_weight", "=", "1.0", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "self", ".", "k", ",", "self", ".", "t", ",", "self", ".", "m", "=", "k", ",", "t", ",", "m", "\n", "self", ".", "indices", "=", "indices", ".", "detach", "(", ")", "\n", "self", ".", "outputs", "=", "l2_normalize", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "\n", "self", ".", "view_maker_loss_weight", "=", "view_maker_loss_weight", "\n", "self", ".", "memory_bank", "=", "memory_bank", "\n", "self", ".", "device", "=", "outputs", ".", "device", "\n", "self", ".", "data_len", "=", "memory_bank", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.updated_new_data_memory": [[69, 73], ["adversarial.AdversarialNCELoss.memory_bank.at_idxs", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.at_idxs", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "def", "updated_new_data_memory", "(", "self", ")", ":", "\n", "        ", "data_memory", "=", "self", ".", "memory_bank", ".", "at_idxs", "(", "self", ".", "indices", ")", "\n", "new_data_memory", "=", "data_memory", "*", "self", ".", "m", "+", "(", "1", "-", "self", ".", "m", ")", "*", "self", ".", "outputs", "\n", "return", "l2_normalize", "(", "new_data_memory", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss": [[74, 82], ["src.objectives.infonce.NoiseConstrastiveEstimation", "src.objectives.infonce.NoiseConstrastiveEstimation.get_loss"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss"], ["", "def", "get_loss", "(", "self", ")", ":", "\n", "        ", "nce_loss", "=", "NoiseConstrastiveEstimation", "(", "\n", "self", ".", "indices", ",", "self", ".", "outputs", ",", "self", ".", "memory_bank", ",", "\n", "k", "=", "self", ".", "k", ",", "t", "=", "self", ".", "t", ",", "m", "=", "self", ".", "m", ",", "\n", ")", "\n", "encoder_loss", "=", "nce_loss", ".", "get_loss", "(", ")", "\n", "view_maker_loss", "=", "-", "encoder_loss", "*", "self", ".", "view_maker_loss_weight", "\n", "return", "encoder_loss", ",", "view_maker_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.makedirs": [[18, 22], ["os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.makedirs"], ["def", "makedirs", "(", "dir_list", ")", ":", "\n", "    ", "for", "dir", "in", "dir_list", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.process_config": [[24, 28], ["src.utils.utils.load_json", "setup._process_config"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup._process_config"], ["", "", "", "def", "process_config", "(", "config_path", ",", "override_dotmap", "=", "None", ",", "exp_name_suffix", "=", "None", ")", ":", "\n", "    ", "config_json", "=", "load_json", "(", "config_path", ")", "\n", "return", "_process_config", "(", "config_json", ",", "override_dotmap", "=", "override_dotmap", ",", "\n", "exp_name_suffix", "=", "exp_name_suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup._process_config": [[30, 79], ["dotmap.DotMap", "print", "pprint.pprint", "print", "print", "print", "print", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "setup.makedirs", "os.path.join", "src.utils.utils.save_json", "setup.setup_logging", "logging.getLogger().info", "dotmap.DotMap.update", "dotmap.DotMap.toDict", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.makedirs", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.save_json", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.setup_logging", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update"], ["", "def", "_process_config", "(", "config_json", ",", "override_dotmap", "=", "None", ",", "exp_name_suffix", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Processes config file:\n        1) Converts it to a DotMap\n        2) Creates experiments path and required subdirs\n        3) Set up logging\n    \"\"\"", "\n", "config", "=", "DotMap", "(", "config_json", ")", "\n", "if", "override_dotmap", "is", "not", "None", ":", "\n", "        ", "config", ".", "update", "(", "override_dotmap", ")", "\n", "\n", "", "if", "exp_name_suffix", "is", "not", "None", ":", "\n", "        ", "config", ".", "exp_name", "=", "f'{config.exp_name}_{exp_name_suffix}'", "\n", "\n", "", "print", "(", "\"Loaded configuration: \"", ")", "\n", "pprint", "(", "config", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\" *************************************** \"", ")", "\n", "print", "(", "\"      Running experiment {}\"", ".", "format", "(", "config", ".", "exp_name", ")", ")", "\n", "print", "(", "\" *************************************** \"", ")", "\n", "print", "(", ")", "\n", "\n", "exp_base", "=", "config", ".", "exp_base", "or", "DEFAULT_EXP_BASE", "\n", "\n", "# Uncomment me if you wish to not overwrite", "\n", "# timestamp = strftime('%Y-%m-%d--%H_%M_%S', localtime())", "\n", "exp_dir", "=", "os", ".", "path", ".", "join", "(", "exp_base", ",", "\"experiments\"", ",", "config", ".", "exp_name", ")", "\n", "config", ".", "exp_dir", "=", "exp_dir", "\n", "\n", "# create some important directories to be used for the experiment.", "\n", "config", ".", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "config", ".", "out_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"out/\"", ")", "\n", "config", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"logs/\"", ")", "\n", "\n", "# will not create if already existing", "\n", "makedirs", "(", "[", "config", ".", "checkpoint_dir", ",", "config", ".", "out_dir", ",", "config", ".", "log_dir", "]", ")", "\n", "\n", "# save config to experiment dir", "\n", "config_out", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "'config.json'", ")", "\n", "save_json", "(", "config", ".", "toDict", "(", ")", ",", "config_out", ")", "\n", "\n", "# setup logging in the project", "\n", "setup_logging", "(", "config", ".", "log_dir", ")", "\n", "\n", "logging", ".", "getLogger", "(", ")", ".", "info", "(", "\n", "\"Configurations and directories successfully set up.\"", ")", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.setup_logging": [[81, 106], ["logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.handlers.RotatingFileHandler", "logging.handlers.RotatingFileHandler.setLevel", "logging.handlers.RotatingFileHandler.setFormatter", "logging.handlers.RotatingFileHandler", "logging.handlers.RotatingFileHandler.setLevel", "logging.handlers.RotatingFileHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.addHandler", "logging.getLogger.addHandler", "logging.Formatter", "logging.Formatter", "logging.Formatter"], "function", ["None"], ["", "def", "setup_logging", "(", "log_dir", ")", ":", "\n", "    ", "log_file_format", "=", "\"[%(levelname)s] - %(asctime)s - %(name)s - : %(message)s in %(pathname)s:%(lineno)d\"", "\n", "log_console_format", "=", "\"[%(levelname)s]: %(message)s\"", "\n", "\n", "# Main logger", "\n", "main_logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "main_logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "console_handler", ".", "setFormatter", "(", "Formatter", "(", "log_console_format", ")", ")", "\n", "\n", "exp_file_handler", "=", "RotatingFileHandler", "(", "\n", "'{}exp_debug.log'", ".", "format", "(", "log_dir", ")", ",", "maxBytes", "=", "10", "**", "6", ",", "backupCount", "=", "5", ")", "\n", "exp_file_handler", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "exp_file_handler", ".", "setFormatter", "(", "Formatter", "(", "log_file_format", ")", ")", "\n", "\n", "exp_errors_file_handler", "=", "RotatingFileHandler", "(", "\n", "'{}exp_error.log'", ".", "format", "(", "log_dir", ")", ",", "maxBytes", "=", "10", "**", "6", ",", "backupCount", "=", "5", ")", "\n", "exp_errors_file_handler", ".", "setLevel", "(", "logging", ".", "WARNING", ")", "\n", "exp_errors_file_handler", ".", "setFormatter", "(", "Formatter", "(", "log_file_format", ")", ")", "\n", "\n", "main_logger", ".", "addHandler", "(", "console_handler", ")", "\n", "main_logger", ".", "addHandler", "(", "exp_file_handler", ")", "\n", "main_logger", ".", "addHandler", "(", "exp_errors_file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.print_cuda_statistics": [[108, 128], ["logging.getLogger", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "call", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "call", "torch.backends.cudnn.version", "torch.cuda.device_count", "torch.cuda.current_device", "torch.cuda.device_count", "torch.cuda.current_device"], "function", ["None"], ["", "def", "print_cuda_statistics", "(", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "\"CUDA Statistics\"", ")", "\n", "import", "sys", "\n", "from", "subprocess", "import", "call", "\n", "import", "torch", "\n", "logger", ".", "info", "(", "'__Python VERSION:  {}'", ".", "format", "(", "sys", ".", "version", ")", ")", "\n", "logger", ".", "info", "(", "'__pyTorch VERSION:  {}'", ".", "format", "(", "torch", ".", "__version__", ")", ")", "\n", "logger", ".", "info", "(", "'__CUDA VERSION'", ")", "\n", "try", ":", "\n", "        ", "call", "(", "[", "\"nvcc\"", ",", "\"--version\"", "]", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "", "logger", ".", "info", "(", "'__CUDNN VERSION:  {}'", ".", "format", "(", "torch", ".", "backends", ".", "cudnn", ".", "version", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "'__Number CUDA Devices:  {}'", ".", "format", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "'__Devices'", ")", "\n", "call", "(", "[", "\"nvidia-smi\"", ",", "\"--format=csv\"", ",", "\n", "\"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"", "]", ")", "\n", "logger", ".", "info", "(", "'Active CUDA Device: GPU {}'", ".", "format", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Available devices  {}'", ".", "format", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Current cuda device  {}'", ".", "format", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.callbacks.MoCoLRScheduler.__init__": [[7, 17], ["pytorch_lightning.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "initial_lr", "=", "0.03", ",", "\n", "use_cosine_scheduler", "=", "False", ",", "\n", "schedule", "=", "(", "120", ",", "160", ")", ",", "\n", "max_epochs", "=", "200", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lr", "=", "initial_lr", "\n", "self", ".", "use_cosine_scheduler", "=", "use_cosine_scheduler", "\n", "self", ".", "schedule", "=", "schedule", "\n", "self", ".", "max_epochs", "=", "max_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.callbacks.MoCoLRScheduler.on_epoch_start": [[18, 31], ["math.cos"], "methods", ["None"], ["", "def", "on_epoch_start", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "epoch", "=", "trainer", ".", "current_epoch", "\n", "lr", "=", "self", ".", "lr", "\n", "\n", "if", "self", ".", "use_cosine_scheduler", ":", "# cosine lr schedule", "\n", "            ", "lr", "*=", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "epoch", "/", "self", ".", "max_epochs", ")", ")", "\n", "", "else", ":", "# stepwise lr schedule", "\n", "            ", "for", "milestone", "in", "self", ".", "schedule", ":", "\n", "                ", "lr", "*=", "0.1", "if", "epoch", ">=", "milestone", "else", "1.", "\n", "\n", "", "", "optimizer", "=", "trainer", ".", "optimizers", "[", "0", "]", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.__init__": [[13, 15], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.reset": [[16, 21], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update": [[22, 27], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.OrderedCounter.__repr__": [[57, 59], ["collections.OrderedDict"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'%s(%r)'", "%", "(", "self", ".", "__class__", ".", "__name__", ",", "OrderedDict", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.OrderedCounter.__reduce__": [[60, 62], ["collections.OrderedDict"], "methods", ["None"], ["", "def", "__reduce__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ",", "(", "OrderedDict", "(", "self", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.copy_checkpoint": [[29, 33], ["shutil.copyfile", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "def", "copy_checkpoint", "(", "folder", "=", "'./'", ",", "filename", "=", "'checkpoint.pth.tar'", ",", "\n", "copyname", "=", "'copy.pth.tar'", ")", ":", "\n", "    ", "shutil", ".", "copyfile", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "filename", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "folder", ",", "copyname", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.save_checkpoint": [[35, 42], ["torch.save", "os.path.isdir", "os.mkdir", "os.path.join", "shutil.copyfile", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "folder", "=", "'./'", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "isdir", "(", "folder", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "folder", ")", "\n", "", "torch", ".", "save", "(", "state", ",", "os", ".", "path", ".", "join", "(", "folder", ",", "filename", ")", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "filename", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "folder", ",", "'model_best.pth.tar'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json": [[44, 47], ["open", "json.load"], "function", ["None"], ["", "", "def", "load_json", "(", "f_path", ")", ":", "\n", "    ", "with", "open", "(", "f_path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.save_json": [[49, 52], ["open", "json.dump"], "function", ["None"], ["", "", "def", "save_json", "(", "obj", ",", "f_path", ")", ":", "\n", "    ", "with", "open", "(", "f_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "obj", ",", "f", ",", "ensure_ascii", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params": [[64, 67], ["module.parameters"], "function", ["None"], ["", "", "def", "frozen_params", "(", "module", ")", ":", "\n", "    ", "for", "p", "in", "module", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.free_params": [[69, 72], ["module.parameters"], "function", ["None"], ["", "", "def", "free_params", "(", "module", ")", ":", "\n", "    ", "for", "p", "in", "module", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize": [[74, 76], ["torch.sqrt", "torch.sum().unsqueeze", "torch.sum"], "function", ["None"], ["", "", "def", "l2_normalize", "(", "x", ",", "dim", "=", "1", ")", ":", "\n", "    ", "return", "x", "/", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "x", "**", "2", ",", "dim", "=", "dim", ")", ".", "unsqueeze", "(", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.compute_accuracy": [[78, 92], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].reshape().float().sum", "res.append", "correct[].reshape().float().sum.item", "target.view", "correct[].reshape().float", "correct[].reshape"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "compute_accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "item", "(", ")", ")", "\n", "", "return", "res", "\n", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.google_speech.GoogleSpeechCommands.__init__": [[27, 61], ["torch.utils.data.Dataset.__init__", "len", "open().readlines", "open().readlines", "open().readlines", "path.strip", "open", "open", "open", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'google_speech'", "]", ",", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "max_length", "=", "150526", ",", "\n", "input_size", "=", "224", ",", "\n", "normalize_mean", "=", "GOOGLESPEECH_MEAN", ",", "\n", "normalize_stdev", "=", "GOOGLESPEECH_STDEV", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "not", "(", "spectral_transforms", "and", "wavform_transforms", ")", "\n", "if", "train", ":", "\n", "            ", "train_paths", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'training_list.txt'", ")", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "val_paths", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'validation_list.txt'", ")", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "wav_paths", "=", "train_paths", "+", "val_paths", "\n", "", "else", ":", "\n", "            ", "test_paths", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'testing_list.txt'", ")", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "wav_paths", "=", "test_paths", "\n", "\n", "", "wav_paths", "=", "[", "path", ".", "strip", "(", ")", "for", "path", "in", "wav_paths", "]", "\n", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "num_labels", "=", "len", "(", "GOOGLESPEECH_LABELS", ")", "\n", "self", ".", "wav_paths", "=", "wav_paths", "\n", "self", ".", "spectral_transforms", "=", "spectral_transforms", "\n", "self", ".", "wavform_transforms", "=", "wavform_transforms", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "FILTER_SIZE", "=", "input_size", "\n", "self", ".", "normalize_mean", "=", "normalize_mean", "\n", "self", ".", "normalize_stdev", "=", "normalize_stdev", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.google_speech.GoogleSpeechCommands.__getitem__": [[62, 111], ["[].lower", "GOOGLESPEECH_LABELS.index", "os.path.join", "torchaudio.load", "wavform[].numpy", "librosa.feature.melspectrogram", "librosa.power_to_db", "torch.from_numpy().float", "src.datasets.librispeech.SpectrumAugmentation.unsqueeze", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize.", "src.datasets.librispeech.WavformAugmentation", "src.datasets.librispeech.SpectrumAugmentation.", "len", "numpy.zeros", "src.datasets.librispeech.SpectrumAugmentation", "src.datasets.librispeech.SpectrumAugmentation.", "int", "bool", "torch.from_numpy", "torch.randn_like", "wav_name.split", "random.getrandbits", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "wav_name", "=", "self", ".", "wav_paths", "[", "index", "]", "\n", "label_name", "=", "wav_name", ".", "split", "(", "'/'", ")", "[", "0", "]", ".", "lower", "(", ")", "\n", "label", "=", "GOOGLESPEECH_LABELS", ".", "index", "(", "label_name", ")", "\n", "wav_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "wav_name", ")", "\n", "\n", "wavform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "wav_path", ")", "\n", "wavform", "=", "wavform", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "wavform_transforms", ":", "\n", "            ", "transforms", "=", "WavformAugmentation", "(", "sample_rate", ")", "\n", "wavform", "=", "transforms", "(", "wavform", ")", "\n", "\n", "# pad to 150k frames", "\n", "", "if", "len", "(", "wavform", ")", ">", "self", ".", "max_length", ":", "\n", "# randomly pick which side to chop off (fix if validation)", "\n", "            ", "flip", "=", "(", "bool", "(", "random", ".", "getrandbits", "(", "1", ")", ")", "if", "self", ".", "train", "else", "True", ")", "\n", "padded", "=", "(", "wavform", "[", ":", "self", ".", "max_length", "]", "if", "flip", "else", "\n", "wavform", "[", "-", "self", ".", "max_length", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "padded", "=", "np", ".", "zeros", "(", "self", ".", "max_length", ")", "\n", "padded", "[", ":", "len", "(", "wavform", ")", "]", "=", "wavform", "# pad w/ silence", "\n", "\n", "", "hop_length_dict", "=", "{", "224", ":", "672", ",", "112", ":", "1344", ",", "64", ":", "2360", ",", "32", ":", "4800", "}", "\n", "spectrum", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "padded", ",", "\n", "sample_rate", ",", "\n", "hop_length", "=", "hop_length_dict", "[", "self", ".", "input_size", "]", ",", "\n", "n_mels", "=", "self", ".", "input_size", ",", "\n", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply time and frequency masks", "\n", "            ", "transforms", "=", "SpectrumAugmentation", "(", ")", "\n", "spectrum", "=", "transforms", "(", "spectrum", ")", "\n", "\n", "# log mel-spectrogram", "\n", "", "spectrum", "=", "librosa", ".", "power_to_db", "(", "spectrum", "**", "2", ")", "\n", "spectrum", "=", "torch", ".", "from_numpy", "(", "spectrum", ")", ".", "float", "(", ")", "\n", "spectrum", "=", "spectrum", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply noise on spectral", "\n", "            ", "noise_stdev", "=", "0.25", "*", "self", ".", "normalize_stdev", "[", "0", "]", "\n", "noise", "=", "torch", ".", "randn_like", "(", "spectrum", ")", "*", "noise_stdev", "\n", "spectrum", "=", "spectrum", "+", "noise", "\n", "\n", "", "normalize", "=", "Normalize", "(", "self", ".", "normalize_mean", ",", "self", ".", "normalize_stdev", ")", "\n", "spectrum", "=", "normalize", "(", "spectrum", ")", "\n", "\n", "return", "index", ",", "spectrum", ",", "int", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.google_speech.GoogleSpeechCommands.__len__": [[112, 114], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "wav_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech.__init__": [[22, 69], ["torch.utils.data.Dataset.__init__", "librispeech.LibriSpeech.get_speaker_ids", "sorted", "len", "dict", "numpy.array", "torchaudio.datasets.LIBRISPEECH", "list", "zip", "torchaudio.datasets.LIBRISPEECH", "torchaudio.datasets.LIBRISPEECH", "torchaudio.datasets.LIBRISPEECH", "torchaudio.datasets.LIBRISPEECH", "set", "range"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.get_speaker_ids"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'librispeech'", "]", ",", "\n", "train", "=", "True", ",", "\n", "small", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "True", ",", "\n", "test_url", "=", "'dev-clean'", ",", "\n", "max_length", "=", "150526", ",", "\n", "input_size", "=", "224", ",", "\n", "normalize_mean", "=", "LIBRISPEECH_MEAN", ",", "\n", "normalize_stdev", "=", "LIBRISPEECH_STDEV", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# choose to either apply augmentation at wavform or at augmentation level", "\n", "assert", "not", "(", "spectral_transforms", "and", "wavform_transforms", ")", "\n", "if", "train", ":", "\n", "            ", "if", "small", ":", "\n", "                ", "self", ".", "dataset", "=", "LIBRISPEECH", "(", "root", ",", "url", "=", "'train-clean-100'", ",", "download", "=", "True", ",", "\n", "folder_in_archive", "=", "'LibriSpeech'", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "dataset1", "=", "LIBRISPEECH", "(", "root", ",", "url", "=", "'train-clean-100'", ",", "download", "=", "True", ",", "\n", "folder_in_archive", "=", "'LibriSpeech'", ")", "\n", "self", ".", "dataset2", "=", "LIBRISPEECH", "(", "root", ",", "url", "=", "'train-clean-360'", ",", "download", "=", "True", ",", "\n", "folder_in_archive", "=", "'LibriSpeech'", ")", "\n", "self", ".", "dataset3", "=", "LIBRISPEECH", "(", "root", ",", "url", "=", "'train-other-500'", ",", "download", "=", "True", ",", "\n", "folder_in_archive", "=", "'LibriSpeech'", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "dataset", "=", "LIBRISPEECH", "(", "root", ",", "url", "=", "test_url", ",", "download", "=", "True", ",", "\n", "folder_in_archive", "=", "'LibriSpeech'", ")", "\n", "\n", "", "self", ".", "spectral_transforms", "=", "spectral_transforms", "\n", "self", ".", "wavform_transforms", "=", "wavform_transforms", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "small", "=", "small", "\n", "all_speaker_ids", "=", "self", ".", "get_speaker_ids", "(", ")", "\n", "unique_speaker_ids", "=", "sorted", "(", "list", "(", "set", "(", "all_speaker_ids", ")", ")", ")", "\n", "num_unique_speakers", "=", "len", "(", "unique_speaker_ids", ")", "\n", "self", ".", "speaker_id_map", "=", "dict", "(", "zip", "(", "unique_speaker_ids", ",", "range", "(", "num_unique_speakers", ")", ")", ")", "\n", "self", ".", "all_speaker_ids", "=", "np", ".", "array", "(", "[", "self", ".", "speaker_id_map", "[", "sid", "]", "for", "sid", "in", "all_speaker_ids", "]", ")", "\n", "self", ".", "num_unique_speakers", "=", "num_unique_speakers", "\n", "self", ".", "num_labels", "=", "num_unique_speakers", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "FILTER_SIZE", "=", "input_size", "\n", "self", ".", "normalize_mean", "=", "normalize_mean", "\n", "self", ".", "normalize_stdev", "=", "normalize_stdev", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech.get_speaker_ids": [[70, 78], ["librispeech.LibriSpeech._get_speaker_ids", "librispeech.LibriSpeech._get_speaker_ids", "librispeech.LibriSpeech._get_speaker_ids", "numpy.concatenate", "librispeech.LibriSpeech._get_speaker_ids"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech._get_speaker_ids", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech._get_speaker_ids", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech._get_speaker_ids", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech._get_speaker_ids"], ["", "def", "get_speaker_ids", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", "and", "not", "self", ".", "small", ":", "\n", "            ", "speaker_ids_1", "=", "self", ".", "_get_speaker_ids", "(", "self", ".", "dataset1", ")", "\n", "speaker_ids_2", "=", "self", ".", "_get_speaker_ids", "(", "self", ".", "dataset2", ")", "\n", "speaker_ids_3", "=", "self", ".", "_get_speaker_ids", "(", "self", ".", "dataset3", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "speaker_ids_1", ",", "speaker_ids_2", ",", "speaker_ids_3", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_get_speaker_ids", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech._get_speaker_ids": [[79, 91], ["range", "numpy.array", "len", "librispeech.LibriSpeech.load_librispeech_speaker_id", "speaker_ids.append"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.load_librispeech_speaker_id"], ["", "", "def", "_get_speaker_ids", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "speaker_ids", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "            ", "fileid", "=", "dataset", ".", "_walker", "[", "i", "]", "\n", "speaker_id", "=", "self", ".", "load_librispeech_speaker_id", "(", "\n", "fileid", ",", "\n", "dataset", ".", "_path", ",", "\n", "dataset", ".", "_ext_audio", ",", "\n", "dataset", ".", "_ext_txt", ",", "\n", ")", "\n", "speaker_ids", ".", "append", "(", "speaker_id", ")", "\n", "", "return", "np", ".", "array", "(", "speaker_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech.load_librispeech_speaker_id": [[92, 95], ["fileid.split", "int"], "methods", ["None"], ["", "def", "load_librispeech_speaker_id", "(", "self", ",", "fileid", ",", "path", ",", "ext_audio", ",", "ext_txt", ")", ":", "\n", "        ", "speaker_id", ",", "_", ",", "_", "=", "fileid", ".", "split", "(", "\"-\"", ")", "\n", "return", "int", "(", "speaker_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech.__getitem__": [[96, 169], ["numpy.asarray", "librosa.feature.melspectrogram", "librosa.power_to_db", "torch.from_numpy().float", "SpectrumAugmentation.unsqueeze", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize.", "librispeech.WavformAugmentation", "SpectrumAugmentation.", "len", "numpy.zeros", "librispeech.SpectrumAugmentation", "SpectrumAugmentation.", "librispeech.LibriSpeech.dataset.__getitem__", "bool", "torch.from_numpy", "torch.randn_like", "len", "len", "librispeech.LibriSpeech.dataset3.__getitem__", "len", "librispeech.LibriSpeech.dataset.__getitem__", "random.getrandbits", "len", "librispeech.LibriSpeech.dataset3", "librispeech.LibriSpeech.dataset2.__getitem__", "librispeech.LibriSpeech.dataset1.__getitem__", "len", "len", "len", "librispeech.LibriSpeech.dataset2.__getitem__", "librispeech.LibriSpeech.dataset1.__getitem__", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "if", "self", ".", "train", "and", "not", "self", ".", "small", ":", "\n", "            ", "if", "index", ">=", "(", "len", "(", "self", ".", "dataset1", ")", "+", "len", "(", "self", ".", "dataset2", ")", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset3", ".", "__getitem__", "(", "index", "-", "len", "(", "self", ".", "dataset1", ")", "-", "len", "(", "self", ".", "dataset2", ")", ")", "\n", "", "except", ":", "\n", "                    ", "index2", "=", "(", "index", "-", "len", "(", "self", ".", "dataset1", ")", "-", "len", "(", "self", ".", "dataset2", ")", "+", "1", ")", "%", "len", "(", "self", ".", "dataset3", ")", "\n", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset3", "(", "index2", ")", "\n", "", "", "elif", "index", ">=", "len", "(", "self", ".", "dataset1", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset2", ".", "__getitem__", "(", "index", "-", "len", "(", "self", ".", "dataset1", ")", ")", "\n", "", "except", ":", "\n", "                    ", "index2", "=", "(", "index", "-", "len", "(", "self", ".", "dataset1", ")", "+", "1", ")", "%", "len", "(", "self", ".", "dataset2", ")", "\n", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset2", ".", "__getitem__", "(", "index2", ")", "\n", "", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset1", ".", "__getitem__", "(", "index", ")", "\n", "", "except", ":", "\n", "                    ", "index2", "=", "(", "index", "+", "1", ")", "%", "len", "(", "self", ".", "dataset", ")", "\n", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset1", ".", "__getitem__", "(", "index2", ")", "\n", "", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "", "except", ":", "\n", "                ", "index2", "=", "(", "index", "+", "1", ")", "%", "len", "(", "self", ".", "dataset", ")", "\n", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index2", ")", "\n", "\n", "\n", "", "", "speaker_id", "=", "self", ".", "speaker_id_map", "[", "speaker_id", "]", "\n", "wavform", "=", "np", ".", "asarray", "(", "wavform", "[", "0", "]", ")", "\n", "\n", "if", "self", ".", "wavform_transforms", ":", "\n", "            ", "transforms", "=", "WavformAugmentation", "(", "sample_rate", ")", "\n", "wavform", "=", "transforms", "(", "wavform", ")", "\n", "\n", "# pad to 150k frames", "\n", "", "if", "len", "(", "wavform", ")", ">", "self", ".", "max_length", ":", "\n", "# randomly pick which side to chop off (fix if validation)", "\n", "            ", "flip", "=", "(", "bool", "(", "random", ".", "getrandbits", "(", "1", ")", ")", "if", "self", ".", "train", "else", "True", ")", "\n", "padded", "=", "(", "wavform", "[", ":", "self", ".", "max_length", "]", "if", "flip", "else", "\n", "wavform", "[", "-", "self", ".", "max_length", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "padded", "=", "np", ".", "zeros", "(", "self", ".", "max_length", ")", "\n", "padded", "[", ":", "len", "(", "wavform", ")", "]", "=", "wavform", "# pad w/ silence", "\n", "\n", "", "hop_length_dict", "=", "{", "224", ":", "672", ",", "112", ":", "1344", ",", "64", ":", "2360", ",", "32", ":", "4800", "}", "\n", "spectrum", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "padded", ",", "\n", "sample_rate", ",", "\n", "hop_length", "=", "hop_length_dict", "[", "self", ".", "input_size", "]", ",", "\n", "n_mels", "=", "self", ".", "input_size", ",", "\n", ")", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply time and frequency masks", "\n", "            ", "transforms", "=", "SpectrumAugmentation", "(", ")", "\n", "spectrum", "=", "transforms", "(", "spectrum", ")", "\n", "\n", "# log mel-spectrogram", "\n", "", "spectrum", "=", "librosa", ".", "power_to_db", "(", "spectrum", "**", "2", ")", "\n", "spectrum", "=", "torch", ".", "from_numpy", "(", "spectrum", ")", ".", "float", "(", ")", "\n", "spectrum", "=", "spectrum", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply noise on spectral", "\n", "            ", "noise_stdev", "=", "0.25", "*", "self", ".", "normalize_stdev", "[", "0", "]", "\n", "noise", "=", "torch", ".", "randn_like", "(", "spectrum", ")", "*", "noise_stdev", "\n", "spectrum", "=", "spectrum", "+", "noise", "\n", "\n", "", "normalize", "=", "Normalize", "(", "self", ".", "normalize_mean", ",", "self", ".", "normalize_stdev", ")", "\n", "spectrum", "=", "normalize", "(", "spectrum", ")", "\n", "\n", "return", "index", ",", "spectrum", ",", "speaker_id", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeech.__len__": [[170, 175], ["len", "len", "len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", "and", "not", "self", ".", "small", ":", "\n", "            ", "return", "len", "(", "self", ".", "dataset1", ")", "+", "len", "(", "self", ".", "dataset2", ")", "+", "len", "(", "self", ".", "dataset3", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTwoViews.__getitem__": [[179, 184], ["librispeech.LibriSpeech.__getitem__", "librispeech.LibriSpeech.__getitem__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "index", ",", "spectrum1", ",", "speaker_id", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "spectrum2", ",", "_", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "\n", "return", "index", ",", "spectrum1", ",", "spectrum2", ",", "speaker_id", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.__init__": [[191, 223], ["torch.utils.data.Dataset.__init__", "torchaudio.datasets.LIBRISPEECH", "librispeech.LibriSpeechTransfer.get_speaker_ids", "sorted", "len", "dict", "numpy.array", "librispeech.LibriSpeechTransfer.train_test_split", "list", "zip", "set", "range"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.get_speaker_ids", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.train_test_split"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'librispeech'", "]", ",", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "max_length", "=", "150526", ",", "\n", "input_size", "=", "224", ",", "\n", "normalize_mean", "=", "LIBRISPEECH_MEAN", ",", "\n", "normalize_stdev", "=", "LIBRISPEECH_STDEV", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "not", "(", "spectral_transforms", "and", "wavform_transforms", ")", "\n", "self", ".", "dataset", "=", "LIBRISPEECH", "(", "root", ",", "url", "=", "'dev-clean'", ",", "download", "=", "True", ",", "\n", "folder_in_archive", "=", "'LibriSpeech'", ")", "\n", "\n", "all_speaker_ids", "=", "self", ".", "get_speaker_ids", "(", "self", ".", "dataset", ")", "\n", "unique_speaker_ids", "=", "sorted", "(", "list", "(", "set", "(", "all_speaker_ids", ")", ")", ")", "\n", "num_unique_speakers", "=", "len", "(", "unique_speaker_ids", ")", "\n", "self", ".", "speaker_id_map", "=", "dict", "(", "zip", "(", "unique_speaker_ids", ",", "range", "(", "num_unique_speakers", ")", ")", ")", "\n", "self", ".", "all_speaker_ids", "=", "np", ".", "array", "(", "[", "self", ".", "speaker_id_map", "[", "sid", "]", "for", "sid", "in", "all_speaker_ids", "]", ")", "\n", "self", ".", "num_unique_speakers", "=", "num_unique_speakers", "\n", "self", ".", "num_labels", "=", "num_unique_speakers", "\n", "\n", "self", ".", "indices", "=", "self", ".", "train_test_split", "(", "self", ".", "dataset", ",", "all_speaker_ids", ",", "train", "=", "train", ")", "\n", "self", ".", "spectral_transforms", "=", "spectral_transforms", "\n", "self", ".", "wavform_transforms", "=", "wavform_transforms", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "normalize_mean", "=", "normalize_mean", "\n", "self", ".", "normalize_stdev", "=", "normalize_stdev", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.get_speaker_ids": [[224, 236], ["range", "numpy.array", "len", "librispeech.LibriSpeechTransfer.load_librispeech_speaker_id", "speaker_ids.append"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.load_librispeech_speaker_id"], ["", "def", "get_speaker_ids", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "speaker_ids", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "            ", "fileid", "=", "dataset", ".", "_walker", "[", "i", "]", "\n", "speaker_id", "=", "self", ".", "load_librispeech_speaker_id", "(", "\n", "fileid", ",", "\n", "dataset", ".", "_path", ",", "\n", "dataset", ".", "_ext_audio", ",", "\n", "dataset", ".", "_ext_txt", ",", "\n", ")", "\n", "speaker_ids", ".", "append", "(", "speaker_id", ")", "\n", "", "return", "np", ".", "array", "(", "speaker_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.train_test_split": [[237, 254], ["numpy.random.RandomState", "sorted", "numpy.array", "set", "len", "numpy.random.RandomState.shuffle", "int", "train_indices.extend", "test_indices.extend", "numpy.where", "speaker_indices[].tolist", "speaker_indices[].tolist"], "methods", ["None"], ["", "def", "train_test_split", "(", "self", ",", "dataset", ",", "speaker_ids", ",", "train", "=", "True", ")", ":", "\n", "        ", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "# fix seed so reproducible splitting", "\n", "\n", "unique_speaker_ids", "=", "sorted", "(", "set", "(", "speaker_ids", ")", ")", "\n", "unique_speaker_ids", "=", "np", ".", "array", "(", "unique_speaker_ids", ")", "\n", "\n", "# train test split to ensure the 80/20 splits", "\n", "train_indices", ",", "test_indices", "=", "[", "]", ",", "[", "]", "\n", "for", "speaker_id", "in", "unique_speaker_ids", ":", "\n", "            ", "speaker_indices", "=", "np", ".", "where", "(", "speaker_ids", "==", "speaker_id", ")", "[", "0", "]", "\n", "size", "=", "len", "(", "speaker_indices", ")", "\n", "rs", ".", "shuffle", "(", "speaker_indices", ")", "\n", "train_size", "=", "int", "(", "0.8", "*", "size", ")", "\n", "train_indices", ".", "extend", "(", "speaker_indices", "[", ":", "train_size", "]", ".", "tolist", "(", ")", ")", "\n", "test_indices", ".", "extend", "(", "speaker_indices", "[", "train_size", ":", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "", "return", "train_indices", "if", "train", "else", "test_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.load_librispeech_speaker_id": [[255, 258], ["fileid.split", "int"], "methods", ["None"], ["", "def", "load_librispeech_speaker_id", "(", "self", ",", "fileid", ",", "path", ",", "ext_audio", ",", "ext_txt", ")", ":", "\n", "        ", "speaker_id", ",", "_", ",", "_", "=", "fileid", ".", "split", "(", "\"-\"", ")", "\n", "return", "int", "(", "speaker_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.__getitem__": [[259, 313], ["numpy.asarray", "librosa.feature.melspectrogram", "librosa.power_to_db", "torch.from_numpy().float", "SpectrumAugmentation.unsqueeze", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize.", "librispeech.LibriSpeechTransfer.dataset.__getitem__", "librispeech.WavformAugmentation", "SpectrumAugmentation.", "len", "numpy.zeros", "librispeech.SpectrumAugmentation", "SpectrumAugmentation.", "librispeech.LibriSpeechTransfer.dataset.__getitem__", "bool", "torch.from_numpy", "torch.randn_like", "len", "random.getrandbits", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# NOTE: overwrite index with our custom indices mapping exapmles", "\n", "#       to the training and test splits", "\n", "        ", "index", "=", "self", ".", "indices", "[", "index", "]", "\n", "\n", "try", ":", "\n", "            ", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "", "except", ":", "\n", "            ", "index2", "=", "(", "index", "+", "1", ")", "%", "len", "(", "self", ".", "dataset", ")", "\n", "wavform", ",", "sample_rate", ",", "_", ",", "speaker_id", ",", "_", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index2", ")", "\n", "\n", "", "speaker_id", "=", "self", ".", "speaker_id_map", "[", "speaker_id", "]", "\n", "wavform", "=", "np", ".", "asarray", "(", "wavform", "[", "0", "]", ")", "\n", "\n", "if", "self", ".", "wavform_transforms", ":", "\n", "            ", "transforms", "=", "WavformAugmentation", "(", "sample_rate", ")", "\n", "wavform", "=", "transforms", "(", "wavform", ")", "\n", "\n", "# pad to 150k frames", "\n", "", "if", "len", "(", "wavform", ")", ">", "self", ".", "max_length", ":", "\n", "# randomly pick which side to chop off (fix if validation)", "\n", "            ", "flip", "=", "(", "bool", "(", "random", ".", "getrandbits", "(", "1", ")", ")", "if", "self", ".", "train", "else", "True", ")", "\n", "padded", "=", "(", "wavform", "[", ":", "self", ".", "max_length", "]", "if", "flip", "else", "\n", "wavform", "[", "-", "self", ".", "max_length", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "padded", "=", "np", ".", "zeros", "(", "self", ".", "max_length", ")", "\n", "padded", "[", ":", "len", "(", "wavform", ")", "]", "=", "wavform", "# pad w/ silence", "\n", "\n", "", "hop_length_dict", "=", "{", "224", ":", "672", ",", "112", ":", "1344", ",", "64", ":", "2360", ",", "32", ":", "4800", "}", "\n", "spectrum", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "padded", ",", "\n", "sample_rate", ",", "\n", "hop_length", "=", "hop_length_dict", "[", "self", ".", "input_size", "]", ",", "\n", "n_mels", "=", "self", ".", "input_size", ",", "\n", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply time and frequency masks", "\n", "            ", "transforms", "=", "SpectrumAugmentation", "(", ")", "\n", "spectrum", "=", "transforms", "(", "spectrum", ")", "\n", "\n", "# log mel-spectrogram", "\n", "", "spectrum", "=", "librosa", ".", "power_to_db", "(", "spectrum", "**", "2", ")", "\n", "spectrum", "=", "torch", ".", "from_numpy", "(", "spectrum", ")", ".", "float", "(", ")", "\n", "spectrum", "=", "spectrum", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply noise on spectral", "\n", "            ", "noise_stdev", "=", "0.25", "*", "self", ".", "normalize_stdev", "[", "0", "]", "\n", "noise", "=", "torch", ".", "randn_like", "(", "spectrum", ")", "*", "noise_stdev", "\n", "spectrum", "=", "spectrum", "+", "noise", "\n", "\n", "", "normalize", "=", "Normalize", "(", "self", ".", "normalize_mean", ",", "self", ".", "normalize_stdev", ")", "\n", "spectrum", "=", "normalize", "(", "spectrum", ")", "\n", "\n", "return", "index", ",", "spectrum", ",", "speaker_id", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.LibriSpeechTransfer.__len__": [[314, 316], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.SpectrumAugmentation.get_random_freq_mask": [[320, 322], ["nlpaug.FrequencyMaskingAug", "nlpaug.FrequencyMaskingAug", "nlpaug.FrequencyMaskingAug"], "methods", ["None"], ["    ", "def", "get_random_freq_mask", "(", "self", ")", ":", "\n", "        ", "return", "nas", ".", "FrequencyMaskingAug", "(", "mask_factor", "=", "40", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.SpectrumAugmentation.get_random_time_mask": [[323, 325], ["nlpaug.TimeMaskingAug", "nlpaug.TimeMaskingAug", "nlpaug.TimeMaskingAug"], "methods", ["None"], ["", "def", "get_random_time_mask", "(", "self", ")", ":", "\n", "        ", "return", "nas", ".", "TimeMaskingAug", "(", "mask_factor", "=", "40", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.SpectrumAugmentation.__call__": [[326, 330], ["nlpaug.Sequential", "nlpaug.Sequential", "nlpaug.Sequential", "nlpaug.Sequential.augment", "librispeech.SpectrumAugmentation.get_random_freq_mask", "librispeech.SpectrumAugmentation.get_random_time_mask"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioNoiseAug.augment", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.SpectrumAugmentation.get_random_freq_mask", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.SpectrumAugmentation.get_random_time_mask"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "transforms", "=", "naf", ".", "Sequential", "(", "[", "self", ".", "get_random_freq_mask", "(", ")", ",", "\n", "self", ".", "get_random_time_mask", "(", ")", "]", ")", "\n", "return", "transforms", ".", "augment", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.__init__": [[334, 338], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "sample_rate", "=", "None", ",", "crop_and_noise_only", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "crop_and_noise_only", "=", "crop_and_noise_only", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_loudness": [[339, 341], ["nlpaug.LoudnessAug", "nlpaug.LoudnessAug", "nlpaug.LoudnessAug"], "methods", ["None"], ["", "def", "get_random_loudness", "(", "self", ")", ":", "\n", "        ", "return", "naa", ".", "LoudnessAug", "(", "crop", "=", "(", "0", ",", "1", ")", ",", "coverage", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_crop": [[342, 344], ["librispeech.AudioCropAug"], "methods", ["None"], ["", "def", "get_random_crop", "(", "self", ")", ":", "\n", "        ", "return", "AudioCropAug", "(", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_noise": [[345, 347], ["librispeech.AudioNoiseAug"], "methods", ["None"], ["", "def", "get_random_noise", "(", "self", ")", ":", "\n", "        ", "return", "AudioNoiseAug", "(", "scale", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_pitch": [[348, 350], ["nlpaug.PitchAug", "nlpaug.PitchAug", "nlpaug.PitchAug"], "methods", ["None"], ["", "def", "get_random_pitch", "(", "self", ")", ":", "\n", "        ", "return", "naa", ".", "PitchAug", "(", "self", ".", "sample_rate", ",", "crop", "=", "(", "0", ",", "1", ")", ",", "coverage", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.__call__": [[351, 361], ["random.shuffle", "transform.augment", "librispeech.WavformAugmentation.get_random_crop", "librispeech.WavformAugmentation.get_random_noise", "librispeech.WavformAugmentation.get_random_crop", "librispeech.WavformAugmentation.get_random_loudness", "librispeech.WavformAugmentation.get_random_noise", "librispeech.WavformAugmentation.get_random_pitch"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioNoiseAug.augment", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_crop", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_noise", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_crop", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_loudness", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_noise", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.WavformAugmentation.get_random_pitch"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "crop_and_noise_only", ":", "\n", "            ", "transforms", "=", "[", "self", ".", "get_random_crop", "(", ")", ",", "self", ".", "get_random_noise", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "transforms", "=", "[", "self", ".", "get_random_crop", "(", ")", ",", "self", ".", "get_random_loudness", "(", ")", ",", "\n", "self", ".", "get_random_noise", "(", ")", ",", "self", ".", "get_random_pitch", "(", ")", "]", "\n", "", "random", ".", "shuffle", "(", "transforms", ")", "\n", "for", "transform", "in", "transforms", ":", "\n", "            ", "data", "=", "transform", ".", "augment", "(", "data", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioCropAug.__init__": [[365, 369], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ",", "rescale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "rescale", "=", "rescale", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioCropAug.augment": [[370, 387], ["numpy.random.uniform", "len", "int", "int", "numpy.random.choice", "librosa.effects.time_stretch", "numpy.zeros", "numpy.arange"], "methods", ["None"], ["", "def", "augment", "(", "self", ",", "data", ")", ":", "\n", "        ", "scale", "=", "np", ".", "random", ".", "uniform", "(", "\n", "low", "=", "self", ".", "scale", "[", "0", "]", ",", "\n", "high", "=", "self", ".", "scale", "[", "1", "]", ",", "\n", ")", "\n", "data_size", "=", "len", "(", "data", ")", "\n", "crop_size", "=", "int", "(", "scale", "*", "data_size", ")", "\n", "start_ix", "=", "int", "(", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "data_size", "-", "crop_size", ")", ")", ")", "\n", "crop", "=", "data", "[", "start_ix", ":", "start_ix", "+", "crop_size", "]", "\n", "\n", "if", "self", ".", "rescale", ":", "\n", "            ", "result", "=", "librosa", ".", "effects", ".", "time_stretch", "(", "crop", ",", "crop_size", "/", "data_size", ")", "\n", "", "else", ":", "\n", "            ", "result", "=", "np", ".", "zeros", "(", "data_size", ")", "\n", "result", "[", "start_ix", ":", "start_ix", "+", "crop_size", "]", "=", "crop", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioNoiseAug.__init__": [[391, 394], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioNoiseAug.get_noise": [[395, 405], ["numpy.random.randn", "numpy.fft.irfft"], "methods", ["None"], ["", "def", "get_noise", "(", "self", ",", "segment_size", ",", "scale", ")", ":", "\n", "# https://en.wikipedia.org/wiki/Colors_of_noise", "\n", "        ", "uneven", "=", "segment_size", "%", "2", "\n", "fft_size", "=", "segment_size", "//", "2", "+", "1", "+", "uneven", "\n", "noise_fft", "=", "np", ".", "random", ".", "randn", "(", "fft_size", ")", "\n", "noise_fft", "=", "noise_fft", "*", "scale", "# magnify?", "\n", "noise", "=", "np", ".", "fft", ".", "irfft", "(", "noise_fft", ")", "\n", "if", "uneven", ":", "\n", "            ", "noise", "=", "noise", "[", ":", "-", "1", "]", "\n", "", "return", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioNoiseAug.augment": [[406, 409], ["librispeech.AudioNoiseAug.get_noise", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioNoiseAug.get_noise"], ["", "def", "augment", "(", "self", ",", "data", ")", ":", "\n", "        ", "noise", "=", "self", ".", "get_noise", "(", "len", "(", "data", ")", ",", "self", ".", "scale", ")", "\n", "return", "data", "+", "noise", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.PAMAP2.__init__": [[70, 84], ["torch.Dataset.__init__", "pamap2.BasePAMAP2"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "mode", "=", "'train'", ",", "\n", "sensor_transforms", "=", "None", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'pamap2'", "]", ",", "\n", "examples_per_epoch", "=", "10000", "# Examples are generated stochastically.", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "examples_per_epoch", "=", "examples_per_epoch", "\n", "self", ".", "sensor_transforms", "=", "sensor_transforms", "\n", "self", ".", "dataset", "=", "BasePAMAP2", "(", "\n", "mode", "=", "mode", ",", "\n", "root", "=", "root", ",", "\n", "examples_per_epoch", "=", "examples_per_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.PAMAP2.transform": [[85, 101], ["torch.tensor.numpy().transpose", "torch.tensor.numpy().transpose", "SpectrumAugmentation.", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pamap2.SpectrumAugmentation", "torch.tensor.transpose", "torch.tensor.transpose", "ValueError", "pamap2.SpectrumAugmentation", "ValueError", "torch.tensor.numpy", "torch.tensor.numpy"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "spectrogram", ")", ":", "\n", "        ", "if", "self", ".", "sensor_transforms", ":", "\n", "            ", "if", "self", ".", "sensor_transforms", "==", "'spectral'", ":", "\n", "                ", "spectral_transforms", "=", "SpectrumAugmentation", "(", ")", "\n", "", "elif", "self", ".", "sensor_transforms", "==", "'spectral_noise'", ":", "\n", "                ", "spectral_transforms", "=", "SpectrumAugmentation", "(", "noise", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'Transforms {self.sensor_transforms} not implemented.'", ")", "\n", "\n", "", "spectrogram", "=", "spectrogram", ".", "numpy", "(", ")", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "spectrogram", "=", "spectral_transforms", "(", "spectrogram", ")", "\n", "spectrogram", "=", "torch", ".", "tensor", "(", "spectrogram", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "", "elif", "self", ".", "sensor_transforms", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'Transforms \"{self.sensor_transforms}\" not implemented.'", ")", "\n", "", "return", "spectrogram", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.PAMAP2.__getitem__": [[102, 112], ["pamap2.PAMAP2.dataset.__getitem__", "tuple", "pamap2.PAMAP2.transform().float", "pamap2.PAMAP2.transform().float", "pamap2.PAMAP2.transform", "pamap2.PAMAP2.transform"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.PAMAP2.transform", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.PAMAP2.transform"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "subject_data", "=", "[", "\n", "index", ",", "\n", "self", ".", "transform", "(", "img_data", ")", ".", "float", "(", ")", ",", "\n", "self", ".", "transform", "(", "img_data", ")", ".", "float", "(", ")", ",", "\n", "label", "]", "\n", "\n", "return", "tuple", "(", "subject_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.PAMAP2.__len__": [[113, 115], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "examples_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.__init__": [[120, 134], ["torch.Dataset.__init__", "pamap2.BasePAMAP2.load_data"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.load_data"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "mode", "=", "'train'", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'pamap2'", "]", ",", "\n", "measurements_per_example", "=", "1000", ",", "\n", "examples_per_epoch", "=", "10000", ",", "\n", "normalize", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "examples_per_epoch", "=", "examples_per_epoch", "\n", "self", ".", "measurements_per_example", "=", "measurements_per_example", "# Measurements used to make spectrogram", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "subject_data", "=", "self", ".", "load_data", "(", "root", ")", "\n", "self", ".", "normalize", "=", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.get_subject_ids": [[135, 147], ["ValueError"], "methods", ["None"], ["", "def", "get_subject_ids", "(", "self", ",", "mode", ")", ":", "\n", "        ", "if", "mode", "==", "'train'", ":", "\n", "            ", "nums", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "7", ",", "8", ",", "9", "]", "\n", "", "elif", "mode", "==", "'train_small'", ":", "\n", "            ", "nums", "=", "[", "1", "]", "\n", "", "elif", "mode", "==", "'val'", ":", "\n", "            ", "nums", "=", "[", "5", "]", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "nums", "=", "[", "6", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'mode must be one of [train, train_small, val, test]. got {mode}.'", ")", "\n", "", "return", "nums", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.get_subject_filenames": [[148, 151], ["pamap2.BasePAMAP2.get_subject_ids"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.get_subject_ids"], ["", "def", "get_subject_filenames", "(", "self", ",", "mode", ")", ":", "\n", "        ", "nums", "=", "self", ".", "get_subject_ids", "(", "mode", ")", "\n", "return", "[", "f'subject10{num}.dat'", "for", "num", "in", "nums", "]", "# like 'subject101.dat'", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.load_data": [[152, 172], ["pamap2.BasePAMAP2.get_subject_filenames", "os.path.join", "os.path.isfile", "subject_data.append", "range", "print", "pandas.read_pickle", "pandas.read_csv", "df.interpolate.interpolate.interpolate", "print", "df.interpolate.interpolate.to_pickle", "columns.append", "str"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.get_subject_filenames"], ["", "def", "load_data", "(", "self", ",", "root_path", ")", ":", "\n", "        ", "subject_data", "=", "[", "]", "# list of data frames, one for subject", "\n", "for", "subject_filename", "in", "self", ".", "get_subject_filenames", "(", "self", ".", "mode", ")", ":", "\n", "            ", "columns", "=", "[", "'timestamp'", ",", "'activity_id'", ",", "'heart_rate'", "]", "\n", "for", "part", "in", "[", "'hand'", ",", "'chest'", ",", "'ankle'", "]", ":", "\n", "                ", "for", "i", "in", "range", "(", "17", ")", ":", "\n", "                    ", "columns", ".", "append", "(", "part", "+", "str", "(", "i", ")", ")", "\n", "", "", "subj_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "subject_filename", ")", "\n", "subj_path_cache", "=", "subj_path", "+", "'.p'", "\n", "if", "os", ".", "path", ".", "isfile", "(", "subj_path_cache", ")", ":", "\n", "                ", "print", "(", "f'Loading {subj_path_cache}'", ")", "\n", "df", "=", "pd", ".", "read_pickle", "(", "subj_path_cache", ")", "\n", "\n", "", "else", ":", "\n", "                ", "df", "=", "pd", ".", "read_csv", "(", "subj_path", ",", "names", "=", "columns", ",", "sep", "=", "' '", ")", "\n", "df", "=", "df", ".", "interpolate", "(", ")", "# Interpolate out NaNs.", "\n", "print", "(", "f'Saving {subj_path_cache}'", ")", "\n", "df", ".", "to_pickle", "(", "subj_path_cache", ")", "\n", "", "subject_data", ".", "append", "(", "df", ")", "\n", "", "return", "subject_data", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.__getitem__": [[173, 194], ["numpy.random.randint", "torchaudio.transforms.Spectrogram", "torchaudio.transforms.Spectrogram.", "numpy.random.randint", "numpy.random.randint", "df[].to_numpy", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "len", "len", "FEATURE_STDS.reshape", "FEATURE_MEANS.reshape"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "subject_id", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "self", ".", "subject_data", ")", ")", "\n", "activity_id", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "ACTIVITY_LABELS", ")", ")", "\n", "df", "=", "self", ".", "subject_data", "[", "subject_id", "]", "\n", "activity_data", "=", "df", "[", "df", "[", "'activity_id'", "]", "==", "ACTIVITY_LABELS", "[", "activity_id", "]", "]", ".", "to_numpy", "(", ")", "\n", "if", "len", "(", "activity_data", ")", ">", "self", ".", "measurements_per_example", ":", "break", "\n", "", "start_idx", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "activity_data", ")", "-", "self", ".", "measurements_per_example", ")", "\n", "\n", "# Get frame and also truncate off label and timestamp.", "\n", "# [self.measurements_per_example, 52]", "\n", "measurements", "=", "activity_data", "[", "start_idx", ":", "start_idx", "+", "self", ".", "measurements_per_example", ",", "2", ":", "]", "\n", "\n", "# Yields spectrograms of shape [52, 32, 32]", "\n", "spectrogram_transform", "=", "Spectrogram", "(", "n_fft", "=", "64", "-", "1", ",", "hop_length", "=", "32", ",", "power", "=", "2", ")", "\n", "spectrogram", "=", "spectrogram_transform", "(", "torch", ".", "tensor", "(", "measurements", ".", "T", ")", ")", "\n", "spectrogram", "=", "(", "spectrogram", "+", "1e-6", ")", ".", "log", "(", ")", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "spectrogram", "=", "(", "spectrogram", "-", "FEATURE_MEANS", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", ")", "/", "FEATURE_STDS", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "return", "spectrogram", ",", "activity_id", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.BasePAMAP2.__len__": [[196, 198], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "examples_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.SpectrumAugmentation.__init__": [[202, 205], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "noise", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "noise", "=", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.SpectrumAugmentation.get_random_freq_mask": [[206, 208], ["nlpaug.FrequencyMaskingAug", "nlpaug.FrequencyMaskingAug"], "methods", ["None"], ["", "def", "get_random_freq_mask", "(", "self", ")", ":", "\n", "        ", "return", "nas", ".", "FrequencyMaskingAug", "(", "mask_factor", "=", "20", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.SpectrumAugmentation.get_random_time_mask": [[209, 211], ["nlpaug.TimeMaskingAug", "nlpaug.TimeMaskingAug"], "methods", ["None"], ["", "def", "get_random_time_mask", "(", "self", ")", ":", "\n", "        ", "return", "nas", ".", "TimeMaskingAug", "(", "mask_factor", "=", "20", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.SpectrumAugmentation.__call__": [[212, 221], ["nlpaug.Sequential", "nlpaug.Sequential", "nlpaug.Sequential.augment", "pamap2.SpectrumAugmentation.get_random_freq_mask", "pamap2.SpectrumAugmentation.get_random_time_mask", "numpy.array().reshape", "numpy.random.normal", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.librispeech.AudioNoiseAug.augment", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.SpectrumAugmentation.get_random_freq_mask", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.pamap2.SpectrumAugmentation.get_random_time_mask"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "transforms", "=", "naf", ".", "Sequential", "(", "[", "self", ".", "get_random_freq_mask", "(", ")", ",", "\n", "self", ".", "get_random_time_mask", "(", ")", "]", ")", "\n", "data", "=", "transforms", ".", "augment", "(", "data", ")", "\n", "if", "self", ".", "noise", ":", "\n", "            ", "noise_stdev", "=", "0.25", "*", "np", ".", "array", "(", "FEATURE_STDS", ")", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "noise", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "data", ".", "shape", ")", "*", "noise_stdev", "\n", "data", "=", "data", "+", "noise", "\n", "", "return", "data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.mscoco.MSCOCO.__init__": [[25, 36], ["torch.Dataset.__init__", "mscoco.BaseMSCOCO"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'meta_mscoco'", "]", ",", "\n", "train", "=", "True", ",", "\n", "image_transforms", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseMSCOCO", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.mscoco.MSCOCO.__getitem__": [[38, 45], ["numpy.random.choice", "mscoco.MSCOCO.dataset.__getitem__", "mscoco.MSCOCO.dataset.__getitem__", "mscoco.MSCOCO.dataset.__getitem__", "numpy.arange", "mscoco.MSCOCO.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "return", "index", ",", "img_data", ",", "img2_data", ",", "neg_data", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.mscoco.MSCOCO.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.mscoco.BaseMSCOCO.__init__": [[53, 64], ["torch.Dataset.__init__", "mscoco.BaseMSCOCO.load_coco", "mscoco.BaseMSCOCO.load_images"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.BaseMSCOCO.load_coco", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_mscoco'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "image_transforms", "=", "image_transforms", "\n", "annotations", ",", "coco_cat_id_to_label", "=", "self", ".", "load_coco", "(", ")", "\n", "paths", ",", "bboxes", ",", "labels", "=", "self", ".", "load_images", "(", "annotations", ",", "coco_cat_id_to_label", ")", "\n", "self", ".", "paths", "=", "paths", "\n", "self", ".", "bboxes", "=", "bboxes", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "targets", "=", "labels", "# we sometimes query this by targets", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.mscoco.BaseMSCOCO.load_coco": [[65, 82], ["os.path.join", "os.path.join", "dict", "open", "json.load", "zip", "len", "ValueError", "range", "len"], "methods", ["None"], ["", "def", "load_coco", "(", "self", ")", ":", "\n", "        ", "image_dir_name", "=", "(", "'train2017'", "if", "self", ".", "train", "else", "'val2017'", ")", "\n", "image_dir", "=", "join", "(", "self", ".", "root", ",", "image_dir_name", ")", "\n", "annotation_name", "=", "(", "'instances_train2017.json'", "if", "self", ".", "train", "else", "'instances_val2017.json'", ")", "\n", "annotation_path", "=", "join", "(", "self", ".", "root", ",", "'annotations'", ",", "annotation_name", ")", "\n", "\n", "with", "open", "(", "annotation_path", ",", "'r'", ")", "as", "json_file", ":", "\n", "            ", "annotations", "=", "json", ".", "load", "(", "json_file", ")", "\n", "instance_annotations", "=", "annotations", "[", "'annotations'", "]", "\n", "categories", "=", "annotations", "[", "'categories'", "]", "\n", "if", "len", "(", "categories", ")", "!=", "self", ".", "NUM_CLASSES", ":", "\n", "                ", "raise", "ValueError", "(", "'Total number of MSCOCO classes %d should be 80'", ")", "\n", "\n", "", "", "category_ids", "=", "[", "cat", "[", "'id'", "]", "for", "cat", "in", "categories", "]", "\n", "coco_cat_id_to_label", "=", "dict", "(", "zip", "(", "category_ids", ",", "range", "(", "len", "(", "categories", ")", ")", ")", ")", "\n", "\n", "return", "instance_annotations", ",", "coco_cat_id_to_label", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.mscoco.BaseMSCOCO.load_images": [[83, 98], ["os.path.join", "os.path.join", "all_filepaths.append", "all_bboxes.append", "all_labels.append"], "methods", ["None"], ["", "def", "load_images", "(", "self", ",", "annotations", ",", "coco_cat_id_to_label", ")", ":", "\n", "        ", "image_dir_name", "=", "(", "'train2017'", "if", "self", ".", "train", "else", "'val2017'", ")", "\n", "image_dir", "=", "join", "(", "self", ".", "root", ",", "image_dir_name", ")", "\n", "all_filepaths", ",", "all_bboxes", ",", "all_labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "anno", "in", "annotations", ":", "\n", "            ", "image_id", "=", "anno", "[", "'image_id'", "]", "\n", "image_path", "=", "join", "(", "image_dir", ",", "'%012d.jpg'", "%", "image_id", ")", "\n", "bbox", "=", "anno", "[", "'bbox'", "]", "\n", "coco_class_id", "=", "anno", "[", "'category_id'", "]", "\n", "label", "=", "coco_cat_id_to_label", "[", "coco_class_id", "]", "\n", "all_filepaths", ".", "append", "(", "image_path", ")", "\n", "all_bboxes", ".", "append", "(", "bbox", ")", "\n", "all_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "return", "all_filepaths", ",", "all_bboxes", ",", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.mscoco.BaseMSCOCO.__len__": [[99, 101], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.mscoco.BaseMSCOCO.__getitem__": [[102, 109], ["PIL.Image.open().convert", "mscoco.BaseMSCOCO.image_transforms", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "label", "=", "self", ".", "labels", "[", "index", "]", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "mode", "=", "'RGB'", ")", "\n", "if", "self", ".", "image_transforms", ":", "\n", "            ", "image", "=", "self", ".", "image_transforms", "(", "image", ")", "\n", "", "return", "image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.voxceleb1.VoxCeleb1.__init__": [[22, 54], ["torch.utils.data.Dataset.__init__", "voxceleb1.VoxCeleb1.get_split", "sorted", "dict", "len", "len", "set", "zip", "range", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.voxceleb1.VoxCeleb1.get_split"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'voxceleb1'", "]", ",", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "max_length", "=", "150526", ",", "\n", "input_size", "=", "224", ",", "\n", "normalize_mean", "=", "VOX_CELEB_MEAN", ",", "\n", "normalize_stdev", "=", "VOX_CELEB_STDEV", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "not", "(", "spectral_transforms", "and", "wavform_transforms", ")", "\n", "self", ".", "root", "=", "root", "\n", "wav_paths", ",", "speaker_strs", "=", "self", ".", "get_split", "(", "train", ")", "\n", "# change speaker_strs to integers ", "\n", "unique_speakers", "=", "sorted", "(", "set", "(", "speaker_strs", ")", ")", "\n", "speaker_id_map", "=", "dict", "(", "zip", "(", "unique_speakers", ",", "range", "(", "len", "(", "unique_speakers", ")", ")", ")", ")", "\n", "speaker_ids", "=", "[", "speaker_id_map", "[", "sp", "]", "for", "sp", "in", "speaker_strs", "]", "\n", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "spectral_transforms", "=", "spectral_transforms", "\n", "self", ".", "wavform_transforms", "=", "wavform_transforms", "\n", "self", ".", "wav_paths", "=", "wav_paths", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "speaker_ids", "=", "speaker_ids", "\n", "self", ".", "num_unique_speakers", "=", "len", "(", "unique_speakers", ")", "\n", "self", ".", "num_labels", "=", "len", "(", "unique_speakers", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "FILTER_SIZE", "=", "input_size", "\n", "self", ".", "normalize_mean", "=", "normalize_mean", "\n", "self", ".", "normalize_stdev", "=", "normalize_stdev", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.voxceleb1.VoxCeleb1.get_split": [[55, 75], ["os.path.join", "collections.defaultdict", "open", "fp.readlines", "split.strip().split", "paths[].append", "p.split", "p.split", "split.strip"], "methods", ["None"], ["", "def", "get_split", "(", "self", ",", "train", "=", "True", ")", ":", "\n", "        ", "split_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'iden_split.txt'", ")", "\n", "with", "open", "(", "split_file", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "splits", "=", "fp", ".", "readlines", "(", ")", "\n", "\n", "", "paths", "=", "defaultdict", "(", "lambda", ":", "[", "]", ")", "\n", "for", "split", "in", "splits", ":", "\n", "            ", "spl", ",", "path", "=", "split", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "paths", "[", "spl", "]", ".", "append", "(", "path", ")", "\n", "\n", "", "train_paths", "=", "paths", "[", "'1'", "]", "+", "paths", "[", "'2'", "]", "\n", "test_paths", "=", "paths", "[", "'3'", "]", "\n", "\n", "train_speaker_ids", "=", "[", "p", ".", "split", "(", "'/'", ")", "[", "0", "]", "for", "p", "in", "train_paths", "]", "\n", "test_speaker_ids", "=", "[", "p", ".", "split", "(", "'/'", ")", "[", "0", "]", "for", "p", "in", "test_paths", "]", "\n", "\n", "if", "train", ":", "\n", "            ", "return", "train_paths", ",", "train_speaker_ids", "\n", "", "else", ":", "\n", "            ", "return", "test_paths", ",", "test_speaker_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.voxceleb1.VoxCeleb1.__getitem__": [[76, 122], ["os.path.join", "torchaudio.load", "wavform[].numpy", "librosa.feature.melspectrogram", "librosa.power_to_db", "torch.from_numpy().float", "src.datasets.librispeech.SpectrumAugmentation.unsqueeze", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize.", "src.datasets.librispeech.WavformAugmentation", "src.datasets.librispeech.SpectrumAugmentation.", "len", "numpy.zeros", "src.datasets.librispeech.SpectrumAugmentation", "src.datasets.librispeech.SpectrumAugmentation.", "bool", "torch.from_numpy", "torch.randn_like", "random.getrandbits", "len"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "wav_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'wav'", ",", "self", ".", "wav_paths", "[", "index", "]", ")", "\n", "speaker_id", "=", "self", ".", "speaker_ids", "[", "index", "]", "\n", "wavform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "wav_path", ")", "\n", "wavform", "=", "wavform", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "wavform_transforms", ":", "\n", "            ", "transforms", "=", "WavformAugmentation", "(", "sample_rate", ")", "\n", "wavform", "=", "transforms", "(", "wavform", ")", "\n", "\n", "# pad to 150k frames", "\n", "", "if", "len", "(", "wavform", ")", ">", "self", ".", "max_length", ":", "\n", "# randomly pick which side to chop off (fix if validation)", "\n", "            ", "flip", "=", "(", "bool", "(", "random", ".", "getrandbits", "(", "1", ")", ")", "if", "self", ".", "train", "else", "True", ")", "\n", "padded", "=", "(", "wavform", "[", ":", "self", ".", "max_length", "]", "if", "flip", "else", "\n", "wavform", "[", "-", "self", ".", "max_length", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "padded", "=", "np", ".", "zeros", "(", "self", ".", "max_length", ")", "\n", "padded", "[", ":", "len", "(", "wavform", ")", "]", "=", "wavform", "# pad w/ silence", "\n", "\n", "", "hop_length_dict", "=", "{", "224", ":", "672", ",", "112", ":", "1344", ",", "64", ":", "2360", ",", "32", ":", "4800", "}", "\n", "spectrum", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "padded", ",", "\n", "sample_rate", ",", "\n", "hop_length", "=", "hop_length_dict", "[", "self", ".", "input_size", "]", ",", "\n", "n_mels", "=", "self", ".", "input_size", ",", "\n", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply time and frequency masks", "\n", "            ", "transforms", "=", "SpectrumAugmentation", "(", ")", "\n", "spectrum", "=", "transforms", "(", "spectrum", ")", "\n", "\n", "# log mel-spectrogram", "\n", "", "spectrum", "=", "librosa", ".", "power_to_db", "(", "spectrum", "**", "2", ")", "\n", "spectrum", "=", "torch", ".", "from_numpy", "(", "spectrum", ")", ".", "float", "(", ")", "\n", "spectrum", "=", "spectrum", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply noise on spectral", "\n", "            ", "noise_stdev", "=", "0.25", "*", "self", ".", "normalize_stdev", "[", "0", "]", "\n", "noise", "=", "torch", ".", "randn_like", "(", "spectrum", ")", "*", "noise_stdev", "\n", "spectrum", "=", "spectrum", "+", "noise", "\n", "\n", "", "normalize", "=", "Normalize", "(", "self", ".", "normalize_mean", ",", "self", ".", "normalize_stdev", ")", "\n", "spectrum", "=", "normalize", "(", "spectrum", ")", "\n", "\n", "return", "index", ",", "spectrum", ",", "speaker_id", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.voxceleb1.VoxCeleb1.__len__": [[123, 125], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "wav_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.data_statistics.get_data_mean_and_stdev": [[1, 57], ["Exception"], "function", ["None"], ["def", "get_data_mean_and_stdev", "(", "dataset", ")", ":", "\n", "    ", "if", "dataset", "==", "'meta_aircraft'", ":", "\n", "        ", "mean", "=", "[", "0.486", ",", "0.507", ",", "0.525", "]", "\n", "std", "=", "[", "0.266", ",", "0.260", ",", "0.276", "]", "\n", "", "elif", "dataset", "==", "'meta_cu_birds'", ":", "\n", "        ", "mean", "=", "[", "0.483", ",", "0.491", ",", "0.424", "]", "\n", "std", "=", "[", "0.228", ",", "0.224", ",", "0.259", "]", "\n", "", "elif", "dataset", "==", "'meta_dtd'", ":", "\n", "        ", "mean", "=", "[", "0.533", ",", "0.474", ",", "0.426", "]", "\n", "std", "=", "[", "0.261", ",", "0.250", ",", "0.259", "]", "\n", "", "elif", "dataset", "==", "'meta_fashionmnist'", ":", "\n", "        ", "mean", "=", "[", "0.348", ",", "0.348", ",", "0.348", "]", "\n", "std", "=", "[", "0.347", ",", "0.347", ",", "0.347", "]", "\n", "", "elif", "dataset", "==", "'meta_fungi'", ":", "\n", "        ", "mean", "=", "[", "0.452", ",", "0.421", ",", "0.344", "]", "\n", "std", "=", "[", "0.249", ",", "0.237", ",", "0.242", "]", "\n", "", "elif", "dataset", "==", "'meta_mnist'", ":", "\n", "        ", "mean", "=", "[", "0.170", ",", "0.170", ",", "0.170", "]", "\n", "std", "=", "[", "0.320", ",", "0.320", ",", "0.320", "]", "\n", "", "elif", "dataset", "==", "'meta_mscoco'", ":", "\n", "        ", "mean", "=", "[", "0.408", ",", "0.377", ",", "0.352", "]", "\n", "std", "=", "[", "0.269", ",", "0.260", ",", "0.261", "]", "\n", "", "elif", "dataset", "==", "'meta_traffic_sign'", ":", "\n", "        ", "mean", "=", "[", "0.335", ",", "0.291", ",", "0.295", "]", "\n", "std", "=", "[", "0.267", ",", "0.249", ",", "0.251", "]", "\n", "", "elif", "dataset", "==", "'meta_vgg_flower'", ":", "\n", "        ", "mean", "=", "[", "0.518", ",", "0.410", ",", "0.329", "]", "\n", "std", "=", "[", "0.296", ",", "0.249", ",", "0.285", "]", "\n", "", "elif", "dataset", "==", "'mscoco'", ":", "\n", "        ", "mean", "=", "[", "0.408", ",", "0.377", ",", "0.352", "]", "\n", "std", "=", "[", "0.269", ",", "0.260", ",", "0.261", "]", "\n", "", "elif", "dataset", "==", "'celeba'", ":", "\n", "        ", "mean", "=", "[", "0.515", ",", "0.417", ",", "0.366", "]", "\n", "std", "=", "[", "0.301", ",", "0.272", ",", "0.268", "]", "\n", "", "elif", "dataset", "==", "'lsun'", ":", "\n", "        ", "mean", "=", "[", "0.588", ",", "0.523", ",", "0.468", "]", "\n", "std", "=", "[", "0.249", ",", "0.260", ",", "0.273", "]", "\n", "", "elif", "dataset", "==", "'retinopathy'", ":", "\n", "        ", "mean", "=", "[", "0.444", ",", "0.307", ",", "0.219", "]", "\n", "std", "=", "[", "0.275", ",", "0.202", ",", "0.169", "]", "\n", "", "elif", "dataset", "==", "'chexpert'", ":", "\n", "        ", "mean", "=", "[", "128.", "/", "256.", "]", "\n", "std", "=", "[", "64.", "/", "256.", "]", "\n", "", "elif", "dataset", "==", "'chexpert_customaug'", ":", "\n", "        ", "mean", "=", "[", "128.", "/", "256.", "]", "\n", "std", "=", "[", "64.", "/", "256.", "]", "\n", "", "elif", "dataset", "==", "'satellite'", ":", "\n", "        ", "mean", "=", "[", "0.377", ",", "0.391", ",", "0.363", "]", "\n", "std", "=", "[", "0.203", ",", "0.189", ",", "0.186", "]", "\n", "", "elif", "dataset", "==", "'ham10k'", ":", "\n", "        ", "mean", "=", "[", "0.764", ",", "0.537", ",", "0.561", "]", "\n", "std", "=", "[", "0.137", ",", "0.158", ",", "0.176", "]", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f'Dataset {dataset} not supported.'", ")", "\n", "\n", "", "return", "mean", ",", "std", "\n", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.fluent_speech.FluentSpeechCommands.__init__": [[35, 87], ["torch.utils.data.Dataset.__init__", "os.path.join", "os.path.join", "pandas.read_csv", "list", "list", "pandas.read_csv", "list", "list", "os.path.join", "pandas.read_csv", "list", "list", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "label_type", "=", "'action'", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'fluent_speech'", "]", ",", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "max_length", "=", "150526", ",", "\n", "input_size", "=", "224", ",", "\n", "normalize_mean", "=", "FLUENTSPEECH_MEAN", ",", "\n", "normalize_stdev", "=", "FLUENTSPEECH_STDEV", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "not", "(", "spectral_transforms", "and", "wavform_transforms", ")", "\n", "assert", "label_type", "in", "[", "'action'", ",", "'object'", ",", "'location'", "]", "\n", "\n", "if", "train", ":", "\n", "            ", "train_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'data'", ",", "'train_data.csv'", ")", "\n", "val_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'data'", ",", "'valid_data.csv'", ")", "\n", "train_data", "=", "pd", ".", "read_csv", "(", "train_path", ")", "\n", "train_paths", "=", "list", "(", "train_data", "[", "'path'", "]", ")", "\n", "train_labels", "=", "list", "(", "train_data", "[", "label_type", "]", ")", "\n", "val_data", "=", "pd", ".", "read_csv", "(", "val_path", ")", "\n", "val_paths", "=", "list", "(", "val_data", "[", "'path'", "]", ")", "\n", "val_labels", "=", "list", "(", "val_data", "[", "label_type", "]", ")", "\n", "wav_paths", "=", "train_paths", "+", "val_paths", "\n", "labels", "=", "train_labels", "+", "val_labels", "\n", "", "else", ":", "\n", "            ", "test_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'data'", ",", "'test_data.csv'", ")", "\n", "test_data", "=", "pd", ".", "read_csv", "(", "test_path", ")", "\n", "wav_paths", "=", "list", "(", "test_data", "[", "'path'", "]", ")", "\n", "labels", "=", "list", "(", "test_data", "[", "label_type", "]", ")", "\n", "\n", "", "if", "label_type", "==", "'action'", ":", "\n", "            ", "self", ".", "num_labels", "=", "len", "(", "FLUENTSPEECH_ACTIONS", ")", "\n", "", "elif", "label_type", "==", "'object'", ":", "\n", "            ", "self", ".", "num_labels", "=", "len", "(", "FLUENTSPEECH_OBJECTS", ")", "\n", "", "elif", "label_type", "==", "'location'", ":", "\n", "            ", "self", ".", "num_labels", "=", "len", "(", "FLUENTSPEECH_LOCATIONS", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "label_type", "=", "label_type", "\n", "self", ".", "wav_paths", "=", "wav_paths", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "spectral_transforms", "=", "spectral_transforms", "\n", "self", ".", "wavform_transforms", "=", "wavform_transforms", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "FILTER_SIZE", "=", "input_size", "\n", "self", ".", "normalize_mean", "=", "normalize_mean", "\n", "self", ".", "normalize_stdev", "=", "normalize_stdev", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.fluent_speech.FluentSpeechCommands.__getitem__": [[88, 144], ["os.path.join", "torchaudio.load", "wavform[].numpy", "librosa.feature.melspectrogram", "librosa.power_to_db", "torch.from_numpy().float", "src.datasets.librispeech.SpectrumAugmentation.unsqueeze", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize.", "FLUENTSPEECH_ACTIONS.index", "src.datasets.librispeech.WavformAugmentation", "src.datasets.librispeech.SpectrumAugmentation.", "len", "numpy.zeros", "src.datasets.librispeech.SpectrumAugmentation", "src.datasets.librispeech.SpectrumAugmentation.", "int", "FLUENTSPEECH_OBJECTS.index", "bool", "torch.from_numpy", "torch.randn_like", "FLUENTSPEECH_LOCATIONS.index", "random.getrandbits", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "wav_name", "=", "self", ".", "wav_paths", "[", "index", "]", "\n", "wav_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "wav_name", ")", "\n", "\n", "label", "=", "self", ".", "labels", "[", "index", "]", "\n", "\n", "if", "self", ".", "label_type", "==", "'action'", ":", "\n", "            ", "label", "=", "FLUENTSPEECH_ACTIONS", ".", "index", "(", "label", ")", "\n", "", "elif", "self", ".", "label_type", "==", "'object'", ":", "\n", "            ", "label", "=", "FLUENTSPEECH_OBJECTS", ".", "index", "(", "label", ")", "\n", "", "elif", "self", ".", "label_type", "==", "'location'", ":", "\n", "            ", "label", "=", "FLUENTSPEECH_LOCATIONS", ".", "index", "(", "label", ")", "\n", "\n", "", "wavform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "wav_path", ")", "\n", "wavform", "=", "wavform", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "wavform_transforms", ":", "\n", "            ", "transforms", "=", "WavformAugmentation", "(", "sample_rate", ")", "\n", "wavform", "=", "transforms", "(", "wavform", ")", "\n", "\n", "# pad to 150k frames", "\n", "", "if", "len", "(", "wavform", ")", ">", "self", ".", "max_length", ":", "\n", "# randomly pick which side to chop off (fix if validation)", "\n", "            ", "flip", "=", "(", "bool", "(", "random", ".", "getrandbits", "(", "1", ")", ")", "if", "self", ".", "train", "else", "True", ")", "\n", "padded", "=", "(", "wavform", "[", ":", "self", ".", "max_length", "]", "if", "flip", "else", "\n", "wavform", "[", "-", "self", ".", "max_length", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "padded", "=", "np", ".", "zeros", "(", "self", ".", "max_length", ")", "\n", "padded", "[", ":", "len", "(", "wavform", ")", "]", "=", "wavform", "# pad w/ silence", "\n", "\n", "", "hop_length_dict", "=", "{", "224", ":", "672", ",", "112", ":", "1344", ",", "64", ":", "2360", ",", "32", ":", "4800", "}", "\n", "spectrum", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "padded", ",", "\n", "sample_rate", ",", "\n", "hop_length", "=", "hop_length_dict", "[", "self", ".", "input_size", "]", ",", "\n", "n_mels", "=", "self", ".", "input_size", ",", "\n", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply time and frequency masks", "\n", "            ", "transforms", "=", "SpectrumAugmentation", "(", ")", "\n", "spectrum", "=", "transforms", "(", "spectrum", ")", "\n", "\n", "# log mel-spectrogram", "\n", "", "spectrum", "=", "librosa", ".", "power_to_db", "(", "spectrum", "**", "2", ")", "\n", "spectrum", "=", "torch", ".", "from_numpy", "(", "spectrum", ")", ".", "float", "(", ")", "\n", "spectrum", "=", "spectrum", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply noise on spectral", "\n", "            ", "noise_stdev", "=", "0.25", "*", "self", ".", "normalize_stdev", "[", "0", "]", "\n", "noise", "=", "torch", ".", "randn_like", "(", "spectrum", ")", "*", "noise_stdev", "\n", "spectrum", "=", "spectrum", "+", "noise", "\n", "\n", "", "normalize", "=", "Normalize", "(", "self", ".", "normalize_mean", ",", "self", ".", "normalize_stdev", ")", "\n", "spectrum", "=", "normalize", "(", "spectrum", ")", "\n", "\n", "return", "index", ",", "spectrum", ",", "int", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.fluent_speech.FluentSpeechCommands.__len__": [[145, 147], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "wav_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10.__init__": [[20, 34], ["torch.Dataset.__init__", "torchvision.datasets.cifar.CIFAR10", "os.path.isdir", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.makedirs"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'cifar10'", "]", ",", "\n", "train", "=", "True", ",", "\n", "image_transforms", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "root", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "root", ")", "\n", "", "self", ".", "dataset", "=", "datasets", ".", "cifar", ".", "CIFAR10", "(", "\n", "root", ",", "\n", "train", "=", "train", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10.__getitem__": [[36, 46], ["numpy.random.choice", "cifar10.CIFAR10.dataset.__getitem__", "cifar10.CIFAR10.dataset.__getitem__", "cifar10.CIFAR10.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "cifar10.CIFAR10.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10.__len__": [[47, 49], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.__init__": [[59, 75], ["torch.Dataset.__init__", "torchvision.datasets.cifar.CIFAR10", "os.path.isdir", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.makedirs"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'cifar10'", "]", ",", "\n", "train", "=", "True", ",", "\n", "image_transforms", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "root", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "root", ")", "\n", "", "self", ".", "dataset", "=", "datasets", ".", "cifar", ".", "CIFAR10", "(", "\n", "root", ",", "\n", "train", "=", "train", ",", "\n", "download", "=", "True", "# Don't apply transformations yet", "\n", ")", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "transforms", "=", "image_transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.get_random_cifar": [[76, 79], ["random.randint", "len"], "methods", ["None"], ["", "def", "get_random_cifar", "(", "self", ")", ":", "\n", "        ", "idx", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "dataset", ")", "-", "1", ")", "\n", "return", "self", ".", "dataset", "[", "idx", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.paste_random_cifar_square": [[81, 86], ["cifar10.CIFAR10Corners.get_random_cifar", "cifar10.CIFAR10Corners.crop", "base_img.paste"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.get_random_cifar"], ["", "def", "paste_random_cifar_square", "(", "self", ",", "base_img", ",", "x", ",", "y", ")", ":", "\n", "        ", "img", "=", "self", ".", "get_random_cifar", "(", ")", "\n", "img_crop", "=", "img", ".", "crop", "(", "(", "x", ",", "y", ",", "x", "+", "16", ",", "y", "+", "16", ")", ")", "\n", "base_img", ".", "paste", "(", "img_crop", ",", "(", "x", ",", "y", ")", ")", "\n", "return", "base_img", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.get_cifar_corners": [[88, 94], ["cifar10.CIFAR10Corners.get_random_cifar", "cifar10.CIFAR10Corners.paste_random_cifar_square", "cifar10.CIFAR10Corners.paste_random_cifar_square", "cifar10.CIFAR10Corners.paste_random_cifar_square"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.get_random_cifar", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.paste_random_cifar_square", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.paste_random_cifar_square", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.paste_random_cifar_square"], ["", "def", "get_cifar_corners", "(", "self", ")", ":", "\n", "        ", "base_img", "=", "self", ".", "get_random_cifar", "(", ")", "\n", "base_img", "=", "self", ".", "paste_random_cifar_square", "(", "base_img", ",", "16", ",", "0", ")", "\n", "base_img", "=", "self", ".", "paste_random_cifar_square", "(", "base_img", ",", "16", ",", "16", ")", "\n", "base_img", "=", "self", ".", "paste_random_cifar_square", "(", "base_img", ",", "0", ",", "16", ")", "\n", "return", "base_img", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.__getitem__": [[96, 108], ["tuple", "cifar10.CIFAR10Corners.dataset.__getitem__", "cifar10.CIFAR10Corners.dataset.__getitem__", "cifar10.CIFAR10Corners.get_cifar_corners", "cifar10.CIFAR10Corners.transforms().float", "cifar10.CIFAR10Corners.transforms().float", "cifar10.CIFAR10Corners.transforms().float", "cifar10.CIFAR10Corners.transforms().float", "cifar10.CIFAR10Corners.transforms", "cifar10.CIFAR10Corners.transforms", "cifar10.CIFAR10Corners.transforms", "cifar10.CIFAR10Corners.transforms"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.get_cifar_corners"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "not", "self", ".", "train", ":", "\n", "            ", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "self", ".", "transforms", "(", "img_data", ")", ".", "float", "(", ")", ",", "self", ".", "transforms", "(", "img2_data", ")", ".", "float", "(", ")", ",", "label", ",", "label", "]", "\n", "", "else", ":", "\n", "            ", "img_data", "=", "self", ".", "get_cifar_corners", "(", ")", "\n", "img2_data", "=", "img_data", "\n", "# No labels for pano.", "\n", "data", "=", "[", "index", ",", "self", ".", "transforms", "(", "img_data", ")", ".", "float", "(", ")", ",", "self", ".", "transforms", "(", "img2_data", ")", ".", "float", "(", ")", ",", "0", ",", "0", "]", "\n", "", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.cifar10.CIFAR10Corners.__len__": [[109, 111], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.audio_mnist.AudioMNIST.__init__": [[29, 60], ["torch.utils.data.Dataset.__init__", "glob.glob.glob", "wav_paths.extend", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'audio_mnist'", "]", ",", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "True", ",", "\n", "max_length", "=", "150526", ",", "\n", "input_size", "=", "224", ",", "\n", "normalize_mean", "=", "AUDIOMNIST_MEAN", ",", "\n", "normalize_stdev", "=", "AUDIOMNIST_STDEV", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "not", "(", "spectral_transforms", "and", "wavform_transforms", ")", "\n", "if", "train", ":", "\n", "            ", "speakers", "=", "AUDIOMNIST_TRAIN_SPK", "+", "AUDIOMNIST_VAL_SPK", "\n", "", "else", ":", "\n", "            ", "speakers", "=", "AUDIOMNIST_TEST_SPK", "\n", "", "wav_paths", "=", "[", "]", "\n", "for", "spk", "in", "speakers", ":", "\n", "            ", "spk_paths", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"{:02d}\"", ".", "format", "(", "spk", ")", ",", "'*.wav'", ")", ")", "\n", "wav_paths", ".", "extend", "(", "spk_paths", ")", "\n", "", "self", ".", "wav_paths", "=", "wav_paths", "\n", "self", ".", "num_labels", "=", "10", "\n", "self", ".", "spectral_transforms", "=", "spectral_transforms", "\n", "self", ".", "wavform_transforms", "=", "wavform_transforms", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "FILTER_SIZE", "=", "input_size", "\n", "self", ".", "normalize_mean", "=", "normalize_mean", "\n", "self", ".", "normalize_stdev", "=", "normalize_stdev", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.audio_mnist.AudioMNIST.__getitem__": [[61, 108], ["[].split", "torchaudio.load", "wavform[].numpy", "librosa.feature.melspectrogram", "librosa.power_to_db", "torch.from_numpy().float", "src.datasets.librispeech.SpectrumAugmentation.unsqueeze", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize.", "src.datasets.librispeech.WavformAugmentation", "src.datasets.librispeech.SpectrumAugmentation.", "len", "numpy.zeros", "src.datasets.librispeech.SpectrumAugmentation", "src.datasets.librispeech.SpectrumAugmentation.", "int", "bool", "torch.from_numpy", "torch.randn_like", "wav_path.rstrip().split", "random.getrandbits", "len", "wav_path.rstrip"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "wav_path", "=", "self", ".", "wav_paths", "[", "index", "]", "\n", "label", ",", "_", ",", "_", "=", "wav_path", ".", "rstrip", "(", "\".wav\"", ")", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "\n", "\n", "wavform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "wav_path", ")", "\n", "wavform", "=", "wavform", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "wavform_transforms", ":", "\n", "            ", "transforms", "=", "WavformAugmentation", "(", "sample_rate", ")", "\n", "wavform", "=", "transforms", "(", "wavform", ")", "\n", "\n", "# pad to 150k frames", "\n", "", "if", "len", "(", "wavform", ")", ">", "self", ".", "max_length", ":", "\n", "# randomly pick which side to chop off (fix if validation)", "\n", "            ", "flip", "=", "(", "bool", "(", "random", ".", "getrandbits", "(", "1", ")", ")", "if", "self", ".", "train", "else", "True", ")", "\n", "padded", "=", "(", "wavform", "[", ":", "self", ".", "max_length", "]", "if", "flip", "else", "\n", "wavform", "[", "-", "self", ".", "max_length", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "padded", "=", "np", ".", "zeros", "(", "self", ".", "max_length", ")", "\n", "padded", "[", ":", "len", "(", "wavform", ")", "]", "=", "wavform", "# pad w/ silence", "\n", "\n", "", "hop_length_dict", "=", "{", "224", ":", "672", ",", "112", ":", "1344", ",", "64", ":", "2360", ",", "32", ":", "4800", "}", "\n", "spectrum", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "padded", ",", "\n", "sample_rate", ",", "\n", "hop_length", "=", "hop_length_dict", "[", "self", ".", "input_size", "]", ",", "\n", "n_mels", "=", "self", ".", "input_size", ",", "\n", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply time and frequency masks", "\n", "            ", "transforms", "=", "SpectrumAugmentation", "(", ")", "\n", "spectrum", "=", "transforms", "(", "spectrum", ")", "\n", "\n", "# log mel-spectrogram", "\n", "", "spectrum", "=", "librosa", ".", "power_to_db", "(", "spectrum", "**", "2", ")", "\n", "spectrum", "=", "torch", ".", "from_numpy", "(", "spectrum", ")", ".", "float", "(", ")", "\n", "spectrum", "=", "spectrum", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "self", ".", "spectral_transforms", ":", "# apply noise on spectral", "\n", "            ", "noise_stdev", "=", "0.25", "*", "self", ".", "normalize_stdev", "[", "0", "]", "\n", "noise", "=", "torch", ".", "randn_like", "(", "spectrum", ")", "*", "noise_stdev", "\n", "spectrum", "=", "spectrum", "+", "noise", "\n", "\n", "", "normalize", "=", "Normalize", "(", "self", ".", "normalize_mean", ",", "self", ".", "normalize_stdev", ")", "\n", "spectrum", "=", "normalize", "(", "spectrum", ")", "\n", "\n", "return", "index", ",", "spectrum", ",", "int", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.audio_mnist.AudioMNIST.__len__": [[109, 111], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "wav_paths", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.GaussianBlur.__init__": [[161, 163], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sigma", "=", "(", "0.1", ",", "2.0", ")", ")", ":", "\n", "        ", "self", ".", "sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.GaussianBlur.__call__": [[164, 168], ["random.uniform", "x.filter.filter.filter", "PIL.ImageFilter.GaussianBlur"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "sigma", "=", "random", ".", "uniform", "(", "self", ".", "sigma", "[", "0", "]", ",", "self", ".", "sigma", "[", "1", "]", ")", "\n", "x", "=", "x", ".", "filter", "(", "ImageFilter", ".", "GaussianBlur", "(", "radius", "=", "sigma", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.zscore_image": [[34, 38], ["img_tensor.mean", "img_tensor.std"], "function", ["None"], ["def", "zscore_image", "(", "img_tensor", ")", ":", "\n", "    ", "img_tensor", "-=", "img_tensor", ".", "mean", "(", "[", "-", "1", ",", "-", "2", "]", ",", "keepdim", "=", "True", ")", "\n", "img_tensor", "/=", "img_tensor", ".", "std", "(", "[", "-", "1", ",", "-", "2", "]", ",", "keepdim", "=", "True", ")", "\n", "return", "img_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.get_image_datasets": [[39, 56], ["load_transforms"], "function", ["None"], ["", "def", "get_image_datasets", "(", "\n", "dataset_name", ",", "\n", "default_augmentations", "=", "'none'", ",", "\n", ")", ":", "\n", "    ", "load_transforms", "=", "TRANSFORMS", "[", "default_augmentations", "]", "\n", "train_transforms", ",", "test_transforms", "=", "load_transforms", "(", "\n", "dataset", "=", "dataset_name", ",", "\n", ")", "\n", "train_dataset", "=", "DATASET", "[", "dataset_name", "]", "(", "\n", "train", "=", "True", ",", "\n", "image_transforms", "=", "train_transforms", "\n", ")", "\n", "val_dataset", "=", "DATASET", "[", "dataset_name", "]", "(", "\n", "train", "=", "False", ",", "\n", "image_transforms", "=", "test_transforms", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.load_image_transforms": [[58, 77], ["torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "load_image_transforms", "(", "dataset", ")", ":", "\n", "    ", "if", "'cifar'", "in", "dataset", ":", "\n", "        ", "train_transforms", "=", "transforms", ".", "ToTensor", "(", ")", "\n", "test_transforms", "=", "transforms", ".", "ToTensor", "(", ")", "\n", "", "elif", "dataset", "in", "[", "'mscoco'", "]", "or", "'meta_'", "in", "dataset", ":", "\n", "        ", "train_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "32", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "32", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "test_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "32", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "32", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", ",", "None", "\n", "\n", "", "return", "train_transforms", ",", "test_transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.load_default_transforms": [[79, 121], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "src.datasets.data_statistics.get_data_mean_and_stdev", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "datasets.GaussianBlur", "torchvision.transforms.ColorJitter", "datasets.GaussianBlur"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.data_statistics.get_data_mean_and_stdev"], ["", "def", "load_default_transforms", "(", "dataset", ")", ":", "\n", "    ", "if", "'cifar'", "in", "dataset", ":", "\n", "        ", "train_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "32", ",", "scale", "=", "(", "0.2", ",", "1.", ")", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "\n", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "# not strengthened", "\n", "]", ",", "p", "=", "0.8", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", "[", ".1", ",", "2.", "]", ")", "]", ",", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.491", ",", "0.482", ",", "0.446", "]", ",", "\n", "std", "=", "[", "0.247", ",", "0.243", ",", "0.261", "]", ")", ",", "\n", "]", ")", "\n", "test_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.491", ",", "0.482", ",", "0.446", "]", ",", "\n", "std", "=", "[", "0.247", ",", "0.243", ",", "0.261", "]", ")", ",", "\n", "]", ")", "\n", "", "elif", "dataset", "in", "[", "'mscoco'", "]", "or", "'meta_'", "in", "dataset", ":", "\n", "        ", "mean", ",", "std", "=", "get_data_mean_and_stdev", "(", "dataset", ")", "\n", "train_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "32", ",", "scale", "=", "(", "0.2", ",", "1.", ")", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "\n", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "# not strengthened", "\n", "]", ",", "p", "=", "0.8", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", "[", ".1", ",", "2.", "]", ")", "]", ",", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", ",", "\n", "]", ")", "\n", "test_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "32", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "32", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", ",", "None", "\n", "\n", "", "return", "train_transforms", ",", "test_transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.load_default_unnorm_transforms": [[123, 156], ["torchvision.transforms.Compose", "torchvision.transforms.ToTensor", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.ColorJitter", "datasets.GaussianBlur", "torchvision.transforms.ColorJitter", "datasets.GaussianBlur"], "function", ["None"], ["", "def", "load_default_unnorm_transforms", "(", "dataset", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "'cifar'", "in", "dataset", ":", "\n", "        ", "train_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "32", ",", "scale", "=", "(", "0.2", ",", "1.", ")", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "\n", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "# not strengthened", "\n", "]", ",", "p", "=", "0.8", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", "[", ".1", ",", "2.", "]", ")", "]", ",", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "test_transforms", "=", "transforms", ".", "ToTensor", "(", ")", "\n", "", "elif", "dataset", "in", "[", "'mscoco'", "]", "or", "'meta_'", "in", "dataset", ":", "\n", "        ", "train_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "32", ",", "scale", "=", "(", "0.2", ",", "1.", ")", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "\n", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "# not strengthened", "\n", "]", ",", "p", "=", "0.8", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", "[", ".1", ",", "2.", "]", ")", "]", ",", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "test_transforms", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "32", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "32", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", ",", "None", "\n", "\n", "", "return", "train_transforms", ",", "test_transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fashionmnist.FashionMNIST.__init__": [[19, 25], ["torch.Dataset.__init__", "fashionmnist.BaseFashionMNIST"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_fashionmnist'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseFashionMNIST", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fashionmnist.FashionMNIST.__getitem__": [[27, 37], ["numpy.random.choice", "fashionmnist.FashionMNIST.dataset.__getitem__", "fashionmnist.FashionMNIST.dataset.__getitem__", "fashionmnist.FashionMNIST.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "fashionmnist.FashionMNIST.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "_", ",", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fashionmnist.FashionMNIST.__len__": [[38, 40], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fashionmnist.BaseFashionMNIST.__init__": [[44, 53], ["torch.Dataset.__init__", "torchvision.datasets.mnist.FashionMNIST", "os.path.isdir", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.makedirs"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_fashionmnist'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "root", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "root", ")", "\n", "", "self", ".", "image_transforms", "=", "image_transforms", "\n", "self", ".", "dataset", "=", "datasets", ".", "mnist", ".", "FashionMNIST", "(", "\n", "root", ",", "\n", "train", "=", "train", ",", "\n", "download", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fashionmnist.BaseFashionMNIST.__getitem__": [[55, 62], ["PIL.Image.fromarray().convert", "int", "fashionmnist.BaseFashionMNIST.image_transforms", "PIL.Image.fromarray", "fashionmnist.BaseFashionMNIST.numpy"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "self", ".", "dataset", ".", "data", "[", "index", "]", ",", "int", "(", "self", ".", "dataset", ".", "targets", "[", "index", "]", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ".", "numpy", "(", ")", ",", "mode", "=", "'L'", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "image_transforms", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "image_transforms", "(", "img", ")", "\n", "\n", "", "return", "index", ",", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fashionmnist.BaseFashionMNIST.__len__": [[63, 65], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.traffic_sign.TrafficSign.__init__": [[26, 32], ["torch.Dataset.__init__", "traffic_sign.BaseTrafficSign"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_traffic_sign'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseTrafficSign", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.traffic_sign.TrafficSign.__getitem__": [[34, 44], ["numpy.random.choice", "traffic_sign.TrafficSign.dataset.__getitem__", "traffic_sign.TrafficSign.dataset.__getitem__", "traffic_sign.TrafficSign.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "traffic_sign.TrafficSign.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "_", ",", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.traffic_sign.TrafficSign.__len__": [[45, 47], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.traffic_sign.BaseTrafficSign.__init__": [[52, 59], ["torch.Dataset.__init__", "traffic_sign.BaseTrafficSign.load_images"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_traffic_sign'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "image_transforms", "=", "image_transforms", "\n", "paths", ",", "labels", "=", "self", ".", "load_images", "(", ")", "\n", "self", ".", "paths", ",", "self", ".", "labels", "=", "paths", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.traffic_sign.BaseTrafficSign.load_images": [[60, 82], ["numpy.random.RandomState", "range", "os.path.join", "glob.glob.glob", "numpy.array", "len", "numpy.arange", "numpy.random.RandomState.shuffle", "image_paths[].tolist", "all_filepaths.extend", "all_labels.extend", "os.path.join", "len", "int", "int"], "methods", ["None"], ["", "def", "load_images", "(", "self", ")", ":", "\n", "        ", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "\n", "all_filepaths", ",", "all_labels", "=", "[", "]", ",", "[", "]", "\n", "for", "class_i", "in", "range", "(", "self", ".", "NUM_CLASSES", ")", ":", "\n", "            ", "class_dir_i", "=", "join", "(", "self", ".", "root", ",", "'Final_Training'", ",", "'Images'", ",", "\n", "'{:05d}'", ".", "format", "(", "class_i", ")", ")", "\n", "image_paths", "=", "glob", "(", "join", "(", "class_dir_i", ",", "\"*.ppm\"", ")", ")", "\n", "# train test splitting", "\n", "image_paths", "=", "np", ".", "array", "(", "image_paths", ")", "\n", "num", "=", "len", "(", "image_paths", ")", "\n", "indexer", "=", "np", ".", "arange", "(", "num", ")", "\n", "rs", ".", "shuffle", "(", "indexer", ")", "\n", "image_paths", "=", "image_paths", "[", "indexer", "]", ".", "tolist", "(", ")", "\n", "if", "self", ".", "train", ":", "\n", "                ", "image_paths", "=", "image_paths", "[", ":", "int", "(", "0.8", "*", "num", ")", "]", "\n", "", "else", ":", "\n", "                ", "image_paths", "=", "image_paths", "[", "int", "(", "0.8", "*", "num", ")", ":", "]", "\n", "", "labels", "=", "[", "class_i", "]", "*", "len", "(", "image_paths", ")", "\n", "all_filepaths", ".", "extend", "(", "image_paths", ")", "\n", "all_labels", ".", "extend", "(", "labels", ")", "\n", "\n", "", "return", "all_filepaths", ",", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.traffic_sign.BaseTrafficSign.__len__": [[83, 85], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.traffic_sign.BaseTrafficSign.__getitem__": [[86, 95], ["PIL.Image.open().convert", "traffic_sign.BaseTrafficSign.image_transforms", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "label", "=", "self", ".", "labels", "[", "index", "]", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "mode", "=", "'RGB'", ")", "\n", "\n", "if", "self", ".", "image_transforms", ":", "\n", "            ", "image", "=", "self", ".", "image_transforms", "(", "image", ")", "\n", "\n", "", "return", "index", ",", "image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mnist.MNIST.__init__": [[19, 25], ["torch.Dataset.__init__", "mnist.BaseMNIST"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_mnist'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseMNIST", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mnist.MNIST.__getitem__": [[27, 37], ["numpy.random.choice", "mnist.MNIST.dataset.__getitem__", "mnist.MNIST.dataset.__getitem__", "mnist.MNIST.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "mnist.MNIST.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "_", ",", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mnist.MNIST.__len__": [[38, 40], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mnist.BaseMNIST.__init__": [[44, 53], ["torch.Dataset.__init__", "torchvision.datasets.mnist.MNIST", "os.path.isdir", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.makedirs"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_mnist'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "root", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "root", ")", "\n", "", "self", ".", "image_transforms", "=", "image_transforms", "\n", "self", ".", "dataset", "=", "datasets", ".", "mnist", ".", "MNIST", "(", "\n", "root", ",", "\n", "train", "=", "train", ",", "\n", "download", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mnist.BaseMNIST.__getitem__": [[55, 62], ["PIL.Image.fromarray().convert", "int", "mnist.BaseMNIST.image_transforms", "PIL.Image.fromarray", "mnist.BaseMNIST.numpy"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "self", ".", "dataset", ".", "data", "[", "index", "]", ",", "int", "(", "self", ".", "dataset", ".", "targets", "[", "index", "]", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ".", "numpy", "(", ")", ",", "mode", "=", "'L'", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "image_transforms", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "image_transforms", "(", "img", ")", "\n", "\n", "", "return", "index", ",", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mnist.BaseMNIST.__len__": [[63, 65], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.MSCOCO.__init__": [[26, 32], ["torch.Dataset.__init__", "mscoco.BaseMSCOCO"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["self", ",", "\n", "root", "=", "DATA_ROOTS", "[", "'meta_mscoco'", "]", ",", "\n", "train", "=", "True", ",", "\n", "image_transforms", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseMSCOCO", "(", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.MSCOCO.__getitem__": [[34, 44], ["numpy.random.choice", "mscoco.MSCOCO.dataset.__getitem__", "mscoco.MSCOCO.dataset.__getitem__", "mscoco.MSCOCO.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "mscoco.MSCOCO.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "return", "index", ",", "img_data", ",", "img2_data", ",", "neg_data", ",", "label", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.MSCOCO.__len__": [[45, 47], ["len"], "methods", ["None"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.BaseMSCOCO.__init__": [[53, 63], ["torch.Dataset.__init__", "mscoco.BaseMSCOCO.load_coco", "mscoco.BaseMSCOCO.load_images"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.BaseMSCOCO.load_coco", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_mscoco'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "image_transforms", "=", "image_transforms", "\n", "annotations", ",", "coco_cat_id_to_label", "=", "self", ".", "load_coco", "(", ")", "\n", "paths", ",", "bboxes", ",", "labels", "=", "self", ".", "load_images", "(", "annotations", ",", "coco_cat_id_to_label", ")", "\n", "self", ".", "paths", "=", "paths", "\n", "self", ".", "bboxes", "=", "bboxes", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "targets", "=", "labels", "# we sometimes query this by targets", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.BaseMSCOCO.load_coco": [[64, 81], ["os.path.join", "os.path.join", "dict", "open", "json.load", "zip", "len", "ValueError", "range", "len"], "methods", ["None"], ["\n", "", "def", "load_coco", "(", "self", ")", ":", "\n", "        ", "image_dir_name", "=", "(", "'train2017'", "if", "self", ".", "train", "else", "'val2017'", ")", "\n", "image_dir", "=", "join", "(", "self", ".", "root", ",", "image_dir_name", ")", "\n", "annotation_name", "=", "(", "'instances_train2017.json'", "if", "self", ".", "train", "else", "'instances_val2017.json'", ")", "\n", "annotation_path", "=", "join", "(", "self", ".", "root", ",", "'annotations'", ",", "annotation_name", ")", "\n", "\n", "with", "open", "(", "annotation_path", ",", "'r'", ")", "as", "json_file", ":", "\n", "            ", "annotations", "=", "json", ".", "load", "(", "json_file", ")", "\n", "instance_annotations", "=", "annotations", "[", "'annotations'", "]", "\n", "categories", "=", "annotations", "[", "'categories'", "]", "\n", "if", "len", "(", "categories", ")", "!=", "self", ".", "NUM_CLASSES", ":", "\n", "                ", "raise", "ValueError", "(", "'Total number of MSCOCO classes %d should be 80'", ")", "\n", "\n", "", "", "category_ids", "=", "[", "cat", "[", "'id'", "]", "for", "cat", "in", "categories", "]", "\n", "coco_cat_id_to_label", "=", "dict", "(", "zip", "(", "category_ids", ",", "range", "(", "len", "(", "categories", ")", ")", ")", ")", "\n", "\n", "return", "instance_annotations", ",", "coco_cat_id_to_label", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.BaseMSCOCO.load_images": [[82, 97], ["os.path.join", "os.path.join", "all_filepaths.append", "all_bboxes.append", "all_labels.append"], "methods", ["None"], ["\n", "", "def", "load_images", "(", "self", ",", "annotations", ",", "coco_cat_id_to_label", ")", ":", "\n", "        ", "image_dir_name", "=", "(", "'train2017'", "if", "self", ".", "train", "else", "'val2017'", ")", "\n", "image_dir", "=", "join", "(", "self", ".", "root", ",", "image_dir_name", ")", "\n", "all_filepaths", ",", "all_bboxes", ",", "all_labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "anno", "in", "annotations", ":", "\n", "            ", "image_id", "=", "anno", "[", "'image_id'", "]", "\n", "image_path", "=", "join", "(", "image_dir", ",", "'%012d.jpg'", "%", "image_id", ")", "\n", "bbox", "=", "anno", "[", "'bbox'", "]", "\n", "coco_class_id", "=", "anno", "[", "'category_id'", "]", "\n", "label", "=", "coco_cat_id_to_label", "[", "coco_class_id", "]", "\n", "all_filepaths", ".", "append", "(", "image_path", ")", "\n", "all_bboxes", ".", "append", "(", "bbox", ")", "\n", "all_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "return", "all_filepaths", ",", "all_bboxes", ",", "all_labels", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.BaseMSCOCO.__len__": [[98, 100], ["len"], "methods", ["None"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.mscoco.BaseMSCOCO.__getitem__": [[101, 139], ["PIL.Image.open().convert", "mscoco.BaseMSCOCO.__getitem__.scale_box"], "methods", ["None"], ["\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "label", "=", "self", ".", "labels", "[", "index", "]", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "mode", "=", "'RGB'", ")", "\n", "if", "self", ".", "image_transforms", ":", "\n", "            ", "image", "=", "self", ".", "image_transforms", "(", "image", ")", "\n", "", "return", "image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.dtd.DTD.__init__": [[22, 28], ["torch.Dataset.__init__", "dtd.BaseDTD"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_dtd'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseDTD", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.dtd.DTD.__getitem__": [[30, 40], ["numpy.random.choice", "dtd.DTD.dataset.__getitem__", "dtd.DTD.dataset.__getitem__", "dtd.DTD.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "dtd.DTD.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "_", ",", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.dtd.DTD.__len__": [[41, 43], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.dtd.BaseDTD.__init__": [[47, 54], ["torch.Dataset.__init__", "dtd.BaseDTD.load_images"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_dtd'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "image_transforms", "=", "image_transforms", "\n", "paths", ",", "labels", "=", "self", ".", "load_images", "(", ")", "\n", "self", ".", "paths", ",", "self", ".", "labels", "=", "paths", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.dtd.BaseDTD.load_images": [[55, 88], ["sorted", "os.path.join", "os.path.join", "os.path.join", "sorted.append", "list", "sorted.index", "all_paths.append", "all_labels.append", "open", "open", "open", "image_path.split", "set", "image_path.split", "os.path.join", "line.split", "f.readlines", "line.split", "f.readlines", "line.split", "f.readlines"], "methods", ["None"], ["", "def", "load_images", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "train_info_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'labels'", ",", "'train1.txt'", ")", "\n", "with", "open", "(", "train_info_path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "train_info", "=", "[", "line", ".", "split", "(", "'\\n'", ")", "[", "0", "]", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "val_info_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'labels'", ",", "'val1.txt'", ")", "\n", "with", "open", "(", "val_info_path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "val_info", "=", "[", "line", ".", "split", "(", "'\\n'", ")", "[", "0", "]", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "split_info", "=", "train_info", "+", "val_info", "\n", "", "else", ":", "\n", "            ", "test_info_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'labels'", ",", "'test1.txt'", ")", "\n", "with", "open", "(", "test_info_path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "split_info", "=", "[", "line", ".", "split", "(", "'\\n'", ")", "[", "0", "]", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "# pull out categoires from paths", "\n", "", "", "categories", "=", "[", "]", "\n", "for", "row", "in", "split_info", ":", "\n", "            ", "image_path", "=", "row", "\n", "category", "=", "image_path", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "categories", ".", "append", "(", "category", ")", "\n", "", "categories", "=", "sorted", "(", "list", "(", "set", "(", "categories", ")", ")", ")", "\n", "\n", "all_paths", ",", "all_labels", "=", "[", "]", ",", "[", "]", "\n", "for", "row", "in", "split_info", ":", "\n", "            ", "image_path", "=", "row", "\n", "category", "=", "image_path", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "label", "=", "categories", ".", "index", "(", "category", ")", "\n", "all_paths", ".", "append", "(", "join", "(", "self", ".", "root", ",", "'images'", ",", "image_path", ")", ")", "\n", "all_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "return", "all_paths", ",", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.dtd.BaseDTD.__len__": [[89, 91], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.dtd.BaseDTD.__getitem__": [[92, 102], ["PIL.Image.open().convert", "dtd.BaseDTD.image_transforms", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "label", "=", "self", ".", "labels", "[", "index", "]", "\n", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "mode", "=", "'RGB'", ")", "\n", "\n", "if", "self", ".", "image_transforms", ":", "\n", "            ", "image", "=", "self", ".", "image_transforms", "(", "image", ")", "\n", "\n", "", "return", "index", ",", "image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.vgg_flower.VGGFlower.__init__": [[25, 31], ["torch.Dataset.__init__", "vgg_flower.BaseVGGFlower"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_vgg_flower'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseVGGFlower", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.vgg_flower.VGGFlower.__getitem__": [[33, 43], ["numpy.random.choice", "vgg_flower.VGGFlower.dataset.__getitem__", "vgg_flower.VGGFlower.dataset.__getitem__", "vgg_flower.VGGFlower.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "vgg_flower.VGGFlower.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "_", ",", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.vgg_flower.VGGFlower.__len__": [[44, 46], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.vgg_flower.BaseVGGFlower.__init__": [[50, 57], ["torch.Dataset.__init__", "vgg_flower.BaseVGGFlower.load_images"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_vgg_flower'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "image_transforms", "=", "image_transforms", "\n", "paths", ",", "labels", "=", "self", ".", "load_images", "(", ")", "\n", "self", ".", "paths", ",", "self", ".", "labels", "=", "paths", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.vgg_flower.BaseVGGFlower.load_images": [[58, 87], ["numpy.random.RandomState", "os.path.join", "collections.defaultdict", "enumerate", "collections.defaultdict.items", "open", "all_filepaths[].append", "len", "numpy.array", "numpy.arange", "numpy.random.RandomState.shuffle", "paths[].tolist", "split_filepaths.extend", "split_labels.extend", "os.path.join", "len", "scipy.io.loadmat", "int", "int"], "methods", ["None"], ["", "def", "load_images", "(", "self", ")", ":", "\n", "        ", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "\n", "imagelabels_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'imagelabels.mat'", ")", "\n", "with", "open", "(", "imagelabels_path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "labels", "=", "loadmat", "(", "f", ")", "[", "'labels'", "]", "[", "0", "]", "\n", "\n", "", "all_filepaths", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "all_filepaths", "[", "label", "]", ".", "append", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'jpg'", ",", "'image_{:05d}.jpg'", ".", "format", "(", "i", "+", "1", ")", ")", ")", "\n", "# train test split", "\n", "", "split_filepaths", ",", "split_labels", "=", "[", "]", ",", "[", "]", "\n", "for", "label", ",", "paths", "in", "all_filepaths", ".", "items", "(", ")", ":", "\n", "            ", "num", "=", "len", "(", "paths", ")", "\n", "paths", "=", "np", ".", "array", "(", "paths", ")", "\n", "indexer", "=", "np", ".", "arange", "(", "num", ")", "\n", "rs", ".", "shuffle", "(", "indexer", ")", "\n", "paths", "=", "paths", "[", "indexer", "]", ".", "tolist", "(", ")", "\n", "\n", "if", "self", ".", "train", ":", "\n", "                ", "paths", "=", "paths", "[", ":", "int", "(", "0.8", "*", "num", ")", "]", "\n", "", "else", ":", "\n", "                ", "paths", "=", "paths", "[", "int", "(", "0.8", "*", "num", ")", ":", "]", "\n", "\n", "", "labels", "=", "[", "label", "]", "*", "len", "(", "paths", ")", "\n", "split_filepaths", ".", "extend", "(", "paths", ")", "\n", "split_labels", ".", "extend", "(", "labels", ")", "\n", "\n", "", "return", "split_filepaths", ",", "split_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.vgg_flower.BaseVGGFlower.__len__": [[88, 90], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.vgg_flower.BaseVGGFlower.__getitem__": [[91, 100], ["PIL.Image.open().convert", "int", "vgg_flower.BaseVGGFlower.image_transforms", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "label", "=", "int", "(", "self", ".", "labels", "[", "index", "]", ")", "-", "1", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "mode", "=", "'RGB'", ")", "\n", "\n", "if", "self", ".", "image_transforms", ":", "\n", "            ", "image", "=", "self", ".", "image_transforms", "(", "image", ")", "\n", "\n", "", "return", "index", ",", "image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fungi.Fungi.__init__": [[24, 30], ["torch.Dataset.__init__", "fungi.BaseFungi"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_fungi'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseFungi", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fungi.Fungi.__getitem__": [[32, 42], ["numpy.random.choice", "fungi.Fungi.dataset.__getitem__", "fungi.Fungi.dataset.__getitem__", "fungi.Fungi.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "fungi.Fungi.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "_", ",", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fungi.Fungi.__len__": [[43, 45], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fungi.BaseFungi.__init__": [[49, 55], ["torch.Dataset.__init__", "fungi.BaseFungi.load_images"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_fungi'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "image_transforms", "=", "image_transforms", "\n", "self", ".", "data", "=", "self", ".", "load_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fungi.BaseFungi.load_images": [[56, 75], ["list", "open", "json.load", "image_id_dict.values", "os.path.join"], "methods", ["None"], ["", "def", "load_images", "(", "self", ")", ":", "\n", "        ", "split", "=", "'train'", "if", "self", ".", "train", "else", "'val'", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "f'{split}.json'", ")", ")", "as", "f", ":", "\n", "            ", "data_info", "=", "json", ".", "load", "(", "f", ")", "\n", "", "image_list", "=", "data_info", "[", "'images'", "]", "\n", "image_id_dict", "=", "{", "}", "\n", "for", "image", "in", "image_list", ":", "\n", "# assert this image_id was not previously added", "\n", "            ", "assert", "image", "[", "'id'", "]", "not", "in", "image_id_dict", "\n", "image_id_dict", "[", "image", "[", "'id'", "]", "]", "=", "image", "\n", "\n", "# Add a class annotation to every image in image_id_dict.", "\n", "", "annotations", "=", "data_info", "[", "'annotations'", "]", "\n", "for", "annotation", "in", "annotations", ":", "\n", "# assert this images_id was not previously annotated", "\n", "            ", "assert", "'class'", "not", "in", "image_id_dict", "[", "annotation", "[", "'image_id'", "]", "]", "\n", "image_id_dict", "[", "annotation", "[", "'image_id'", "]", "]", "[", "'class'", "]", "=", "annotation", "[", "'category_id'", "]", "\n", "\n", "", "return", "list", "(", "image_id_dict", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fungi.BaseFungi.__len__": [[76, 78], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.fungi.BaseFungi.__getitem__": [[79, 88], ["os.path.join", "PIL.Image.open().convert", "fungi.BaseFungi.image_transforms", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "data", "[", "index", "]", "[", "'file_name'", "]", ")", "\n", "label", "=", "self", ".", "data", "[", "index", "]", "[", "'class'", "]", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "mode", "=", "'RGB'", ")", "\n", "\n", "if", "self", ".", "image_transforms", ":", "\n", "            ", "image", "=", "self", ".", "image_transforms", "(", "image", ")", "\n", "\n", "", "return", "index", ",", "image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.Aircraft.__init__": [[22, 29], ["torch.Dataset.__init__", "aircraft.BaseAircraft"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_aircraft'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ",", "seed", "=", "42", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseAircraft", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.Aircraft.__getitem__": [[31, 41], ["numpy.random.choice", "aircraft.Aircraft.dataset.__getitem__", "aircraft.Aircraft.dataset.__getitem__", "aircraft.Aircraft.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "aircraft.Aircraft.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "_", ",", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.Aircraft.__len__": [[42, 44], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.BaseAircraft.__init__": [[48, 57], ["torch.Dataset.__init__", "aircraft.BaseAircraft.load_images"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_aircraft'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ",", "seed", "=", "42", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "image_transforms", "=", "image_transforms", "\n", "paths", ",", "bboxes", ",", "labels", "=", "self", ".", "load_images", "(", ")", "\n", "self", ".", "paths", "=", "paths", "\n", "self", ".", "bboxes", "=", "bboxes", "\n", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.BaseAircraft.load_images": [[58, 92], ["os.path.join", "dict", "collections.defaultdict", "dict.items", "aircraft.BaseAircraft.get_bounding_boxes", "sorted", "enumerate", "open", "variants_to_names[].append", "list", "list", "[].split", "set", "os.path.join", "f.readlines", "collections.defaultdict.keys", "sorted", "sorted", "len", "line.split"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.BaseAircraft.get_bounding_boxes"], ["", "def", "load_images", "(", "self", ")", ":", "\n", "        ", "split", "=", "'trainval'", "if", "self", ".", "train", "else", "'test'", "\n", "variant_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'data'", ",", "f'images_variant_{split}.txt'", ")", "\n", "with", "open", "(", "variant_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "names_to_variants", "=", "[", "\n", "line", ".", "split", "(", "'\\n'", ")", "[", "0", "]", ".", "split", "(", "' '", ",", "1", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "\n", "]", "\n", "", "names_to_variants", "=", "dict", "(", "names_to_variants", ")", "\n", "\n", "# Build mapping from variant to filenames. \"Variant\" refers to the aircraft", "\n", "# model variant (e.g., A330-200) and is used as the class name in the", "\n", "# dataset. The position of the class name in the concatenated list of", "\n", "# training, validation, and test class name constitutes its class ID.", "\n", "variants_to_names", "=", "defaultdict", "(", "list", ")", "\n", "for", "name", ",", "variant", "in", "names_to_variants", ".", "items", "(", ")", ":", "\n", "            ", "variants_to_names", "[", "variant", "]", ".", "append", "(", "name", ")", "\n", "\n", "", "names_to_bboxes", "=", "self", ".", "get_bounding_boxes", "(", ")", "\n", "\n", "variants", "=", "sorted", "(", "list", "(", "set", "(", "variants_to_names", ".", "keys", "(", ")", ")", ")", ")", "\n", "split_files", ",", "split_labels", ",", "split_bboxes", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "variant_id", ",", "variant", "in", "enumerate", "(", "variants", ")", ":", "\n", "            ", "class_files", "=", "[", "join", "(", "self", ".", "root", ",", "'data'", ",", "'images'", ",", "f'{filename}.jpg'", ")", "\n", "for", "filename", "in", "sorted", "(", "variants_to_names", "[", "variant", "]", ")", "]", "\n", "bboxes", "=", "[", "names_to_bboxes", "[", "name", "]", "\n", "for", "name", "in", "sorted", "(", "variants_to_names", "[", "variant", "]", ")", "]", "\n", "labels", "=", "list", "(", "[", "variant_id", "]", "*", "len", "(", "class_files", ")", ")", "\n", "\n", "split_files", "+=", "class_files", "\n", "split_labels", "+=", "labels", "\n", "split_bboxes", "+=", "bboxes", "\n", "\n", "", "return", "split_files", ",", "split_bboxes", ",", "split_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.BaseAircraft.get_bounding_boxes": [[93, 104], ["os.path.join", "open", "dict", "[].split", "f.readlines", "list", "line.split", "map"], "methods", ["None"], ["", "def", "get_bounding_boxes", "(", "self", ")", ":", "\n", "        ", "bboxes_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'data'", ",", "'images_box.txt'", ")", "\n", "with", "open", "(", "bboxes_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "names_to_bboxes", "=", "[", "\n", "line", ".", "split", "(", "'\\n'", ")", "[", "0", "]", ".", "split", "(", "' '", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "\n", "]", "\n", "names_to_bboxes", "=", "dict", "(", "\n", "(", "name", ",", "list", "(", "map", "(", "int", ",", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", ")", ")", ")", "\n", "for", "name", ",", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "in", "names_to_bboxes", ")", "\n", "\n", "", "return", "names_to_bboxes", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.BaseAircraft.__len__": [[105, 107], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.aircraft.BaseAircraft.__getitem__": [[108, 120], ["tuple", "PIL.Image.open().convert", "aircraft.BaseAircraft.crop", "aircraft.BaseAircraft.image_transforms", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "bbox", "=", "tuple", "(", "self", ".", "bboxes", "[", "index", "]", ")", "\n", "label", "=", "self", ".", "labels", "[", "index", "]", "\n", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "mode", "=", "'RGB'", ")", "\n", "image", "=", "image", ".", "crop", "(", "bbox", ")", "\n", "\n", "if", "self", ".", "image_transforms", ":", "\n", "            ", "image", "=", "self", ".", "image_transforms", "(", "image", ")", "\n", "\n", "", "return", "index", ",", "image", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.CUBirds.__init__": [[22, 28], ["torch.Dataset.__init__", "cu_birds.BaseCUBirds"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_cu_birds'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "BaseCUBirds", "(", "\n", "root", "=", "root", ",", "\n", "train", "=", "train", ",", "\n", "image_transforms", "=", "image_transforms", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.CUBirds.__getitem__": [[30, 40], ["numpy.random.choice", "cu_birds.CUBirds.dataset.__getitem__", "cu_birds.CUBirds.dataset.__getitem__", "cu_birds.CUBirds.dataset.__getitem__", "tuple", "numpy.arange", "img_data.float", "img2_data.float", "neg_data.float", "cu_birds.CUBirds.__len__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# pick random number", "\n", "        ", "neg_index", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "__len__", "(", ")", ")", ")", "\n", "_", ",", "img_data", ",", "label", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "img2_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "_", ",", "neg_data", ",", "_", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neg_index", ")", "\n", "# build this wrapper such that we can return index", "\n", "data", "=", "[", "index", ",", "img_data", ".", "float", "(", ")", ",", "img2_data", ".", "float", "(", ")", ",", "\n", "neg_data", ".", "float", "(", ")", ",", "label", "]", "\n", "return", "tuple", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.CUBirds.__len__": [[41, 43], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__init__": [[47, 54], ["torch.Dataset.__init__", "cu_birds.BaseCUBirds.load_images"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "DATA_ROOTS", "[", "'meta_cu_birds'", "]", ",", "train", "=", "True", ",", "image_transforms", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "image_transforms", "=", "image_transforms", "\n", "paths", ",", "labels", "=", "self", ".", "load_images", "(", ")", "\n", "self", ".", "paths", ",", "self", ".", "labels", "=", "paths", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.load_images": [[55, 95], ["os.path.join", "dict", "os.path.join", "dict", "os.path.join", "dict", "dict.items", "open", "open", "open", "int", "[].split", "[].split", "[].split", "f.readlines", "f.readlines", "f.readlines", "all_paths.append", "all_labels.append", "all_paths.append", "all_labels.append", "line.split", "line.split", "line.split"], "methods", ["None"], ["", "def", "load_images", "(", "self", ")", ":", "\n", "# load id to image path information", "\n", "        ", "image_info_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'images.txt'", ")", "\n", "with", "open", "(", "image_info_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "image_info", "=", "[", "\n", "line", ".", "split", "(", "'\\n'", ")", "[", "0", "]", ".", "split", "(", "' '", ",", "1", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "\n", "]", "\n", "", "image_info", "=", "dict", "(", "image_info", ")", "\n", "\n", "# load image to label information", "\n", "label_info_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'image_class_labels.txt'", ")", "\n", "with", "open", "(", "label_info_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "label_info", "=", "[", "\n", "line", ".", "split", "(", "'\\n'", ")", "[", "0", "]", ".", "split", "(", "' '", ",", "1", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "\n", "]", "\n", "", "label_info", "=", "dict", "(", "label_info", ")", "\n", "\n", "# load train test split", "\n", "train_test_info_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'train_test_split.txt'", ")", "\n", "with", "open", "(", "train_test_info_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "train_test_info", "=", "[", "\n", "line", ".", "split", "(", "'\\n'", ")", "[", "0", "]", ".", "split", "(", "' '", ",", "1", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "\n", "]", "\n", "", "train_test_info", "=", "dict", "(", "train_test_info", ")", "\n", "\n", "all_paths", ",", "all_labels", "=", "[", "]", ",", "[", "]", "\n", "for", "index", ",", "image_path", "in", "image_info", ".", "items", "(", ")", ":", "\n", "            ", "label", "=", "label_info", "[", "index", "]", "\n", "split", "=", "int", "(", "train_test_info", "[", "index", "]", ")", "\n", "\n", "if", "self", ".", "train", ":", "\n", "                ", "if", "split", "==", "1", ":", "\n", "                    ", "all_paths", ".", "append", "(", "image_path", ")", "\n", "all_labels", ".", "append", "(", "label", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "split", "==", "0", ":", "\n", "                    ", "all_paths", ".", "append", "(", "image_path", ")", "\n", "all_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "", "", "return", "all_paths", ",", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__len__": [[96, 98], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.meta_datasets.cu_birds.BaseCUBirds.__getitem__": [[99, 109], ["os.path.join", "PIL.Image.open().convert", "int", "cu_birds.BaseCUBirds.image_transforms", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'images'", ",", "self", ".", "paths", "[", "index", "]", ")", "\n", "label", "=", "int", "(", "self", ".", "labels", "[", "index", "]", ")", "-", "1", "\n", "\n", "image", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "mode", "=", "'RGB'", ")", "\n", "\n", "if", "self", ".", "image_transforms", ":", "\n", "            ", "image", "=", "self", ".", "image_transforms", "(", "image", ")", "\n", "\n", "", "return", "index", ",", "image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.__init__": [[48, 70], ["pytorch_lightning.LightningModule.__init__", "src.datasets.datasets.get_image_datasets", "numpy.array", "image_systems.PretrainViewMakerSystem.create_encoder", "image_systems.PretrainViewMakerSystem.create_viewmaker", "src.objectives.memory_bank.MemoryBank", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.get_image_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.create_encoder", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.create_viewmaker"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "self", ".", "loss_name", "=", "self", ".", "config", ".", "loss_params", ".", "objective", "\n", "self", ".", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", "\n", "\n", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "datasets", ".", "get_image_datasets", "(", "\n", "config", ".", "data_params", ".", "dataset", ",", "\n", "config", ".", "data_params", ".", "default_augmentations", "or", "'none'", ",", "\n", ")", "\n", "# Used for computing knn validation accuracy", "\n", "train_labels", "=", "self", ".", "train_dataset", ".", "dataset", ".", "targets", "\n", "self", ".", "train_ordered_labels", "=", "np", ".", "array", "(", "train_labels", ")", "\n", "\n", "self", ".", "model", "=", "self", ".", "create_encoder", "(", ")", "\n", "self", ".", "viewmaker", "=", "self", ".", "create_viewmaker", "(", ")", "\n", "\n", "# Used for computing knn validation accuracy.", "\n", "self", ".", "memory_bank", "=", "MemoryBank", "(", "\n", "len", "(", "self", ".", "train_dataset", ")", ",", "\n", "self", ".", "config", ".", "model_params", ".", "out_dim", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view": [[72, 78], ["image_systems.PretrainViewMakerSystem.viewmaker", "image_systems.PretrainViewMakerSystem.normalize", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.normalize"], ["", "def", "view", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "if", "'Expert'", "in", "self", ".", "config", ".", "system", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Cannot call self.view() with Expert system'", ")", "\n", "", "views", "=", "self", ".", "viewmaker", "(", "imgs", ")", "\n", "views", "=", "self", ".", "normalize", "(", "views", ")", "\n", "return", "views", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.create_encoder": [[79, 101], ["src.models.resnet_small.ResNet18", "getattr", "getattr.", "getattr.fc.weight.size", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet18"], ["", "def", "create_encoder", "(", "self", ")", ":", "\n", "        ", "'''Create the encoder model.'''", "\n", "if", "self", ".", "config", ".", "model_params", ".", "resnet_small", ":", "\n", "# ResNet variant for smaller inputs (e.g. CIFAR-10).", "\n", "            ", "encoder_model", "=", "resnet_small", ".", "ResNet18", "(", "self", ".", "config", ".", "model_params", ".", "out_dim", ")", "\n", "", "else", ":", "\n", "            ", "resnet_class", "=", "getattr", "(", "\n", "torchvision", ".", "models", ",", "\n", "self", ".", "config", ".", "model_params", ".", "resnet_version", ",", "\n", ")", "\n", "encoder_model", "=", "resnet_class", "(", "\n", "pretrained", "=", "False", ",", "\n", "num_classes", "=", "self", ".", "config", ".", "model_params", ".", "out_dim", ",", "\n", ")", "\n", "", "if", "self", ".", "config", ".", "model_params", ".", "projection_head", ":", "\n", "            ", "mlp_dim", "=", "encoder_model", ".", "fc", ".", "weight", ".", "size", "(", "1", ")", "\n", "encoder_model", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "mlp_dim", ",", "mlp_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "encoder_model", ".", "fc", ",", "\n", ")", "\n", "", "return", "encoder_model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.create_viewmaker": [[102, 113], ["src.models.viewmaker.Viewmaker"], "methods", ["None"], ["", "def", "create_viewmaker", "(", "self", ")", ":", "\n", "        ", "view_model", "=", "viewmaker", ".", "Viewmaker", "(", "\n", "num_channels", "=", "self", ".", "train_dataset", ".", "NUM_CHANNELS", ",", "\n", "distortion_budget", "=", "self", ".", "config", ".", "model_params", ".", "view_bound_magnitude", ",", "\n", "activation", "=", "self", ".", "config", ".", "model_params", ".", "generator_activation", "or", "'relu'", ",", "\n", "clamp", "=", "self", ".", "config", ".", "model_params", ".", "clamp_views", ",", "\n", "frequency_domain", "=", "self", ".", "config", ".", "model_params", ".", "spectral", "or", "False", ",", "\n", "downsample_to", "=", "self", ".", "config", ".", "model_params", ".", "viewmaker_downsample", "or", "False", ",", "\n", "num_res_blocks", "=", "self", ".", "config", ".", "model_params", ".", "num_res_blocks", "or", "5", ",", "\n", ")", "\n", "return", "view_model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.noise": [[114, 119], ["src.utils.utils.l2_normalize", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "def", "noise", "(", "self", ",", "batch_size", ",", "device", ")", ":", "\n", "        ", "shape", "=", "(", "batch_size", ",", "self", ".", "config", ".", "model_params", ".", "noise_dim", ")", "\n", "# Center noise at 0 then project to unit sphere.", "\n", "noise", "=", "utils", ".", "l2_normalize", "(", "torch", ".", "rand", "(", "shape", ",", "device", "=", "device", ")", "-", "0.5", ")", "\n", "return", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.get_repr": [[120, 126], ["image_systems.PretrainViewMakerSystem.model", "image_systems.PretrainViewMakerSystem.normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.normalize"], ["", "def", "get_repr", "(", "self", ",", "img", ")", ":", "\n", "        ", "'''Get the representation for a given image.'''", "\n", "if", "'Expert'", "not", "in", "self", ".", "config", ".", "system", ":", "\n", "# The Expert system datasets are normalized already.", "\n", "            ", "img", "=", "self", ".", "normalize", "(", "img", ")", "\n", "", "return", "self", ".", "model", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.normalize": [[127, 136], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "ValueError"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "imgs", ")", ":", "\n", "# These numbers were computed using compute_image_dset_stats.py", "\n", "        ", "if", "'cifar'", "in", "self", ".", "config", ".", "data_params", ".", "dataset", ":", "\n", "            ", "mean", "=", "torch", ".", "tensor", "(", "[", "0.491", ",", "0.482", ",", "0.446", "]", ",", "device", "=", "imgs", ".", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "0.247", ",", "0.243", ",", "0.261", "]", ",", "device", "=", "imgs", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Dataset normalizer for {self.config.data_params.dataset} not implemented'", ")", "\n", "", "imgs", "=", "(", "imgs", "-", "mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "/", "std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.forward": [[137, 166], ["image_systems.PretrainViewMakerSystem.view", "image_systems.PretrainViewMakerSystem.model", "wandb.log", "ValueError", "image_systems.PretrainViewMakerSystem.permute().detach().cpu().numpy", "image_systems.PretrainViewMakerSystem.view", "image_systems.PretrainViewMakerSystem.view", "image_systems.PretrainViewMakerSystem.view", "image_systems.PretrainViewMakerSystem.model", "image_systems.PretrainViewMakerSystem.model", "image_systems.PretrainViewMakerSystem.permute().detach().cpu", "wandb.Image", "image_systems.PretrainViewMakerSystem.permute().detach", "image_systems.PretrainViewMakerSystem.permute"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "batch", ",", "train", "=", "True", ")", ":", "\n", "        ", "indices", ",", "img", ",", "img2", ",", "neg_img", ",", "_", ",", "=", "batch", "\n", "if", "self", ".", "loss_name", "==", "'AdversarialNCELoss'", ":", "\n", "            ", "view1", "=", "self", ".", "view", "(", "img", ")", "\n", "view1_embs", "=", "self", ".", "model", "(", "view1", ")", "\n", "emb_dict", "=", "{", "\n", "'indices'", ":", "indices", ",", "\n", "'view1_embs'", ":", "view1_embs", ",", "\n", "}", "\n", "", "elif", "self", ".", "loss_name", "==", "'AdversarialSimCLRLoss'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "double_viewmaker", ":", "\n", "                ", "view1", ",", "view2", "=", "self", ".", "view", "(", "img", ")", "\n", "", "else", ":", "\n", "                ", "view1", "=", "self", ".", "view", "(", "img", ")", "\n", "view2", "=", "self", ".", "view", "(", "img2", ")", "\n", "", "emb_dict", "=", "{", "\n", "'indices'", ":", "indices", ",", "\n", "'view1_embs'", ":", "self", ".", "model", "(", "view1", ")", ",", "\n", "'view2_embs'", ":", "self", ".", "model", "(", "view2", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unimplemented loss_name {self.loss_name}.'", ")", "\n", "\n", "", "if", "self", ".", "global_step", "%", "200", "==", "0", ":", "\n", "# Log some example views. ", "\n", "            ", "views_to_log", "=", "view1", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "10", "]", "\n", "wandb", ".", "log", "(", "{", "\"examples\"", ":", "[", "wandb", ".", "Image", "(", "view", ",", "caption", "=", "f\"Epoch: {self.current_epoch}, Step {self.global_step}, Train {train}\"", ")", "for", "view", "in", "views_to_log", "]", "}", ")", "\n", "\n", "", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.get_losses_for_batch": [[167, 205], ["src.objectives.adversarial.AdversarialSimCLRLoss", "src.objectives.adversarial.AdversarialNCELoss.get_loss", "src.objectives.adversarial.AdversarialNCELoss", "src.objectives.adversarial.AdversarialNCELoss.get_loss", "Exception", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "src.objectives.adversarial.AdversarialNCELoss.updated_new_data_memory", "image_systems.PretrainViewMakerSystem.memory_bank.update", "src.utils.utils.l2_normalize", "image_systems.PretrainViewMakerSystem.memory_bank.update"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.updated_new_data_memory", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update"], ["", "def", "get_losses_for_batch", "(", "self", ",", "emb_dict", ",", "train", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "loss_name", "==", "'AdversarialSimCLRLoss'", ":", "\n", "            ", "view_maker_loss_weight", "=", "self", ".", "config", ".", "loss_params", ".", "view_maker_loss_weight", "\n", "loss_function", "=", "AdversarialSimCLRLoss", "(", "\n", "embs1", "=", "emb_dict", "[", "'view1_embs'", "]", ",", "\n", "embs2", "=", "emb_dict", "[", "'view2_embs'", "]", ",", "\n", "t", "=", "self", ".", "t", ",", "\n", "view_maker_loss_weight", "=", "view_maker_loss_weight", "\n", ")", "\n", "encoder_loss", ",", "view_maker_loss", "=", "loss_function", ".", "get_loss", "(", ")", "\n", "img_embs", "=", "emb_dict", "[", "'view1_embs'", "]", "\n", "", "elif", "self", ".", "loss_name", "==", "'AdversarialNCELoss'", ":", "\n", "            ", "view_maker_loss_weight", "=", "self", ".", "config", ".", "loss_params", ".", "view_maker_loss_weight", "\n", "loss_function", "=", "AdversarialNCELoss", "(", "\n", "emb_dict", "[", "'indices'", "]", ",", "\n", "emb_dict", "[", "'view1_embs'", "]", ",", "\n", "self", ".", "memory_bank", ",", "\n", "k", "=", "self", ".", "config", ".", "loss_params", ".", "k", ",", "\n", "t", "=", "self", ".", "t", ",", "\n", "m", "=", "self", ".", "config", ".", "loss_params", ".", "m", ",", "\n", "view_maker_loss_weight", "=", "view_maker_loss_weight", "\n", ")", "\n", "encoder_loss", ",", "view_maker_loss", "=", "loss_function", ".", "get_loss", "(", ")", "\n", "img_embs", "=", "emb_dict", "[", "'view1_embs'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'Objective {self.loss_name} is not supported.'", ")", "\n", "\n", "# Update memory bank.", "\n", "", "if", "train", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "self", ".", "loss_name", "==", "'AdversarialNCELoss'", ":", "\n", "                    ", "new_data_memory", "=", "loss_function", ".", "updated_new_data_memory", "(", ")", "\n", "self", ".", "memory_bank", ".", "update", "(", "emb_dict", "[", "'indices'", "]", ",", "new_data_memory", ")", "\n", "", "else", ":", "\n", "                    ", "new_data_memory", "=", "utils", ".", "l2_normalize", "(", "img_embs", ",", "dim", "=", "1", ")", "\n", "self", ".", "memory_bank", ".", "update", "(", "emb_dict", "[", "'indices'", "]", ",", "new_data_memory", ")", "\n", "\n", "", "", "", "return", "encoder_loss", ",", "view_maker_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.get_nearest_neighbor_label": [[206, 224], ["img_embs.size", "image_systems.PretrainViewMakerSystem.memory_bank.get_all_dot_products", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "neighbor_idxs.cpu().numpy.cpu().numpy.squeeze", "neighbor_idxs.cpu().numpy.cpu().numpy.cpu().numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "neighbor_idxs.cpu().numpy.cpu().numpy.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.from_numpy().long.cpu", "torch.from_numpy().long.cpu", "torch.from_numpy().long.cpu", "labels.cpu"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.get_all_dot_products"], ["", "def", "get_nearest_neighbor_label", "(", "self", ",", "img_embs", ",", "labels", ")", ":", "\n", "        ", "'''\n        Used for online kNN classifier.\n        For each image in validation, find the nearest image in the \n        training dataset using the memory bank. Assume its label as\n        the predicted label.\n        '''", "\n", "batch_size", "=", "img_embs", ".", "size", "(", "0", ")", "\n", "all_dps", "=", "self", ".", "memory_bank", ".", "get_all_dot_products", "(", "img_embs", ")", "\n", "_", ",", "neighbor_idxs", "=", "torch", ".", "topk", "(", "all_dps", ",", "k", "=", "1", ",", "sorted", "=", "False", ",", "dim", "=", "1", ")", "\n", "neighbor_idxs", "=", "neighbor_idxs", ".", "squeeze", "(", "1", ")", "\n", "neighbor_idxs", "=", "neighbor_idxs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "neighbor_labels", "=", "self", ".", "train_ordered_labels", "[", "neighbor_idxs", "]", "\n", "neighbor_labels", "=", "torch", ".", "from_numpy", "(", "neighbor_labels", ")", ".", "long", "(", ")", "\n", "\n", "num_correct", "=", "torch", ".", "sum", "(", "neighbor_labels", ".", "cpu", "(", ")", "==", "labels", ".", "cpu", "(", ")", ")", ".", "item", "(", ")", "\n", "return", "num_correct", ",", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.training_step": [[225, 229], ["image_systems.PretrainViewMakerSystem.forward", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ",", "optimizer_idx", ")", ":", "\n", "        ", "emb_dict", "=", "self", ".", "forward", "(", "batch", ")", "\n", "emb_dict", "[", "'optimizer_idx'", "]", "=", "torch", ".", "tensor", "(", "optimizer_idx", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.training_step_end": [[230, 248], ["image_systems.PretrainViewMakerSystem.get_losses_for_batch", "emb_dict[].dim"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch"], ["", "def", "training_step_end", "(", "self", ",", "emb_dict", ")", ":", "\n", "        ", "encoder_loss", ",", "view_maker_loss", "=", "self", ".", "get_losses_for_batch", "(", "emb_dict", ",", "train", "=", "True", ")", "\n", "\n", "# Handle Tensor (dp) and int (ddp) cases", "\n", "if", "emb_dict", "[", "'optimizer_idx'", "]", ".", "__class__", "==", "int", "or", "emb_dict", "[", "'optimizer_idx'", "]", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "optimizer_idx", "=", "emb_dict", "[", "'optimizer_idx'", "]", "\n", "", "else", ":", "\n", "            ", "optimizer_idx", "=", "emb_dict", "[", "'optimizer_idx'", "]", "[", "0", "]", "\n", "", "if", "optimizer_idx", "==", "0", ":", "\n", "            ", "metrics", "=", "{", "\n", "'encoder_loss'", ":", "encoder_loss", ",", "'temperature'", ":", "self", ".", "t", "\n", "}", "\n", "return", "{", "'loss'", ":", "encoder_loss", ",", "'log'", ":", "metrics", "}", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "\n", "'view_maker_loss'", ":", "view_maker_loss", ",", "\n", "}", "\n", "return", "{", "'loss'", ":", "view_maker_loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.validation_step": [[249, 269], ["image_systems.PretrainViewMakerSystem.forward", "image_systems.PretrainViewMakerSystem.get_losses_for_batch", "image_systems.PretrainViewMakerSystem.get_nearest_neighbor_label", "collections.OrderedDict", "image_systems.PretrainViewMakerSystem.get_repr", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.get_repr"], ["", "", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "emb_dict", "=", "self", ".", "forward", "(", "batch", ",", "train", "=", "False", ")", "\n", "if", "'img_embs'", "in", "emb_dict", ":", "\n", "            ", "img_embs", "=", "emb_dict", "[", "'img_embs'", "]", "\n", "", "else", ":", "\n", "            ", "_", ",", "img", ",", "_", ",", "_", ",", "_", "=", "batch", "\n", "img_embs", "=", "self", ".", "get_repr", "(", "img", ")", "# Need encoding of image without augmentations (only normalization).", "\n", "", "labels", "=", "batch", "[", "-", "1", "]", "\n", "encoder_loss", ",", "view_maker_loss", "=", "self", ".", "get_losses_for_batch", "(", "emb_dict", ",", "train", "=", "False", ")", "\n", "\n", "num_correct", ",", "batch_size", "=", "self", ".", "get_nearest_neighbor_label", "(", "img_embs", ",", "labels", ")", "\n", "output", "=", "OrderedDict", "(", "{", "\n", "'val_loss'", ":", "encoder_loss", "+", "view_maker_loss", ",", "\n", "'val_encoder_loss'", ":", "encoder_loss", ",", "\n", "'val_view_maker_loss'", ":", "view_maker_loss", ",", "\n", "'val_num_correct'", ":", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_num_total'", ":", "torch", ".", "tensor", "(", "batch_size", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "}", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.validation_epoch_end": [[270, 287], ["outputs[].keys", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "float", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "metrics", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n", "", "", "num_correct", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "num_total", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", "}", "\n", "return", "{", "'val_loss'", ":", "metrics", "[", "'val_loss'", "]", ",", "\n", "'log'", ":", "metrics", ",", "\n", "'val_acc'", ":", "val_acc", ",", "\n", "'progress_bar'", ":", "progress_bar", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.optimizer_step": [[288, 301], ["super().optimizer_step", "optimizer.step", "optimizer.zero_grad", "optimizer.step", "optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.optimizer_step"], ["", "def", "optimizer_step", "(", "self", ",", "current_epoch", ",", "batch_nb", ",", "optimizer", ",", "optimizer_idx", ",", "\n", "second_order_closure", "=", "None", ",", "on_tpu", "=", "False", ",", "using_native_amp", "=", "False", ",", "using_lbfgs", "=", "False", ")", ":", "\n", "        ", "if", "not", "self", ".", "config", ".", "optim_params", ".", "viewmaker_freeze_epoch", ":", "\n", "            ", "super", "(", ")", ".", "optimizer_step", "(", "current_epoch", ",", "batch_nb", ",", "optimizer", ",", "optimizer_idx", ")", "\n", "return", "\n", "\n", "", "if", "optimizer_idx", "==", "0", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "elif", "current_epoch", "<", "self", ".", "config", ".", "optim_params", ".", "viewmaker_freeze_epoch", ":", "\n", "# Optionally freeze the viewmaker at a certain pretraining epoch.", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.configure_optimizers": [[302, 331], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "image_systems.PretrainViewMakerSystem.viewmaker.parameters", "image_systems.PretrainViewMakerSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "type", "type", "list", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "ValueError", "image_systems.PretrainViewMakerSystem.model.parameters"], "methods", ["None"], ["", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "# Optimize temperature with encoder.", "\n", "        ", "if", "type", "(", "self", ".", "t", ")", "==", "float", "or", "type", "(", "self", ".", "t", ")", "==", "int", ":", "\n", "            ", "encoder_params", "=", "self", ".", "model", ".", "parameters", "(", ")", "\n", "", "else", ":", "\n", "            ", "encoder_params", "=", "list", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", "+", "[", "self", ".", "t", "]", "\n", "\n", "", "encoder_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "encoder_params", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "view_optim_name", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_optim", "\n", "view_parameters", "=", "self", ".", "viewmaker", ".", "parameters", "(", ")", "\n", "if", "view_optim_name", "==", "'adam'", ":", "\n", "            ", "view_optim", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "view_parameters", ",", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_learning_rate", "or", "0.001", ")", "\n", "", "elif", "not", "view_optim_name", "or", "view_optim_name", "==", "'sgd'", ":", "\n", "            ", "view_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "view_parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_learning_rate", "or", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Optimizer {view_optim_name} not implemented'", ")", "\n", "\n", "", "return", "[", "encoder_optim", ",", "view_optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.train_dataloader": [[332, 334], ["image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "train_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.val_dataloader": [[335, 338], ["image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "val_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "drop_last", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainExpertSystem.__init__": [[346, 367], ["image_systems.PretrainViewMakerSystem.__init__", "src.datasets.datasets.get_image_datasets", "numpy.array", "image_systems.PretrainExpertSystem.create_encoder", "src.objectives.memory_bank.MemoryBank", "dotmap.DotMap", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.get_image_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.create_encoder"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PretrainViewMakerSystem", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "self", ".", "loss_name", "=", "self", ".", "config", ".", "loss_params", ".", "name", "\n", "self", ".", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", "\n", "\n", "default_augmentations", "=", "self", ".", "config", ".", "data_params", ".", "default_augmentations", "\n", "# DotMap is the default argument when a config argument is missing", "\n", "if", "default_augmentations", "==", "DotMap", "(", ")", ":", "\n", "           ", "default_augmentations", "=", "'all'", "\n", "", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "datasets", ".", "get_image_datasets", "(", "\n", "config", ".", "data_params", ".", "dataset", ",", "\n", "default_augmentations", "=", "default_augmentations", ",", "\n", ")", "\n", "train_labels", "=", "self", ".", "train_dataset", ".", "dataset", ".", "targets", "\n", "self", ".", "train_ordered_labels", "=", "np", ".", "array", "(", "train_labels", ")", "\n", "self", ".", "model", "=", "self", ".", "create_encoder", "(", ")", "\n", "self", ".", "memory_bank", "=", "MemoryBank", "(", "\n", "len", "(", "self", ".", "train_dataset", ")", ",", "\n", "self", ".", "config", ".", "model_params", ".", "out_dim", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainExpertSystem.forward": [[369, 371], ["image_systems.PretrainExpertSystem.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainExpertSystem.get_losses_for_batch": [[372, 401], ["src.objectives.infonce.NoiseConstrastiveEstimation", "src.objectives.simclr.SimCLRObjective.get_loss", "src.objectives.simclr.SimCLRObjective", "src.objectives.simclr.SimCLRObjective.get_loss", "Exception", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "ValueError", "src.objectives.simclr.SimCLRObjective.updated_new_data_memory", "image_systems.PretrainExpertSystem.memory_bank.update", "image_systems.PretrainExpertSystem.memory_bank.update", "Exception", "src.utils.utils.l2_normalize", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.updated_new_data_memory", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "def", "get_losses_for_batch", "(", "self", ",", "emb_dict", ",", "train", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "loss_name", "==", "'nce'", ":", "\n", "            ", "loss_fn", "=", "NoiseConstrastiveEstimation", "(", "emb_dict", "[", "'indices'", "]", ",", "emb_dict", "[", "'img_embs_1'", "]", ",", "self", ".", "memory_bank", ",", "\n", "k", "=", "self", ".", "config", ".", "loss_params", ".", "k", ",", "\n", "t", "=", "self", ".", "t", ",", "\n", "m", "=", "self", ".", "config", ".", "loss_params", ".", "m", ")", "\n", "loss", "=", "loss_fn", ".", "get_loss", "(", ")", "\n", "", "elif", "self", ".", "loss_name", "==", "'simclr'", ":", "\n", "            ", "if", "'img_embs_2'", "not", "in", "emb_dict", ":", "\n", "                ", "raise", "ValueError", "(", "f'img_embs_2 is required for SimCLR loss'", ")", "\n", "", "loss_fn", "=", "SimCLRObjective", "(", "emb_dict", "[", "'img_embs_1'", "]", ",", "emb_dict", "[", "'img_embs_2'", "]", ",", "t", "=", "self", ".", "t", ")", "\n", "loss", "=", "loss_fn", ".", "get_loss", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'Objective {self.loss_name} is not supported.'", ")", "\n", "\n", "", "if", "train", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "self", ".", "loss_name", "==", "'nce'", ":", "\n", "                    ", "new_data_memory", "=", "loss_fn", ".", "updated_new_data_memory", "(", ")", "\n", "self", ".", "memory_bank", ".", "update", "(", "emb_dict", "[", "'indices'", "]", ",", "new_data_memory", ")", "\n", "", "elif", "'simclr'", "in", "self", ".", "loss_name", ":", "\n", "                    ", "outputs_avg", "=", "(", "utils", ".", "l2_normalize", "(", "emb_dict", "[", "'img_embs_1'", "]", ",", "dim", "=", "1", ")", "+", "\n", "utils", ".", "l2_normalize", "(", "emb_dict", "[", "'img_embs_2'", "]", ",", "dim", "=", "1", ")", ")", "/", "2.", "\n", "indices", "=", "emb_dict", "[", "'indices'", "]", "\n", "self", ".", "memory_bank", ".", "update", "(", "indices", ",", "outputs_avg", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "f'Objective {self.loss_name} is not supported.'", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainExpertSystem.configure_optimizers": [[402, 415], ["image_systems.PretrainExpertSystem.model.parameters", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "encoder_params", "=", "self", ".", "model", ".", "parameters", "(", ")", "\n", "\n", "if", "self", ".", "config", ".", "optim_params", ".", "adam", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "AdamW", "(", "encoder_params", ")", "\n", "", "else", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "encoder_params", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "return", "[", "optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainExpertSystem.training_step": [[416, 428], ["image_systems.PretrainExpertSystem.forward", "image_systems.PretrainExpertSystem.forward", "image_systems.PretrainExpertSystem.forward"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "emb_dict", "=", "{", "}", "\n", "indices", ",", "img", ",", "img2", ",", "neg_img", ",", "labels", ",", "=", "batch", "\n", "if", "self", ".", "loss_name", "==", "'nce'", ":", "\n", "            ", "emb_dict", "[", "'img_embs_1'", "]", "=", "self", ".", "forward", "(", "img", ")", "\n", "", "elif", "'simclr'", "in", "self", ".", "loss_name", ":", "\n", "            ", "emb_dict", "[", "'img_embs_1'", "]", "=", "self", ".", "forward", "(", "img", ")", "\n", "emb_dict", "[", "'img_embs_2'", "]", "=", "self", ".", "forward", "(", "img2", ")", "\n", "\n", "", "emb_dict", "[", "'indices'", "]", "=", "indices", "\n", "emb_dict", "[", "'labels'", "]", "=", "labels", "\n", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainExpertSystem.training_step_end": [[429, 433], ["image_systems.PretrainExpertSystem.get_losses_for_batch"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch"], ["", "def", "training_step_end", "(", "self", ",", "emb_dict", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "emb_dict", ",", "train", "=", "True", ")", "\n", "metrics", "=", "{", "'loss'", ":", "loss", ",", "'temperature'", ":", "self", ".", "t", "}", "\n", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainExpertSystem.validation_step": [[434, 456], ["image_systems.PretrainExpertSystem.get_losses_for_batch", "image_systems.PretrainExpertSystem.get_nearest_neighbor_label", "collections.OrderedDict", "image_systems.PretrainExpertSystem.forward", "image_systems.PretrainExpertSystem.forward", "image_systems.PretrainExpertSystem.forward", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "emb_dict", "=", "{", "}", "\n", "indices", ",", "img", ",", "img2", ",", "neg_img", ",", "labels", ",", "=", "batch", "\n", "if", "self", ".", "loss_name", "==", "'nce'", ":", "\n", "            ", "emb_dict", "[", "'img_embs_1'", "]", "=", "self", ".", "forward", "(", "img", ")", "\n", "", "elif", "'simclr'", "in", "self", ".", "loss_name", ":", "\n", "            ", "emb_dict", "[", "'img_embs_1'", "]", "=", "self", ".", "forward", "(", "img", ")", "\n", "emb_dict", "[", "'img_embs_2'", "]", "=", "self", ".", "forward", "(", "img2", ")", "\n", "\n", "", "emb_dict", "[", "'indices'", "]", "=", "indices", "\n", "emb_dict", "[", "'labels'", "]", "=", "labels", "\n", "img_embs", "=", "emb_dict", "[", "'img_embs_1'", "]", "\n", "\n", "loss", "=", "self", ".", "get_losses_for_batch", "(", "emb_dict", ",", "train", "=", "False", ")", "\n", "\n", "num_correct", ",", "batch_size", "=", "self", ".", "get_nearest_neighbor_label", "(", "img_embs", ",", "labels", ")", "\n", "output", "=", "OrderedDict", "(", "{", "\n", "'val_loss'", ":", "loss", ",", "\n", "'val_num_correct'", ":", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_num_total'", ":", "torch", ".", "tensor", "(", "batch_size", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "}", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.__init__": [[463, 495], ["pytorch_lightning.LightningModule.__init__", "image_systems.TransferViewMakerSystem.load_pretrained_model", "src.datasets.datasets.get_image_datasets", "image_systems.TransferViewMakerSystem.encoder.eval", "image_systems.TransferViewMakerSystem.viewmaker.eval", "src.utils.utils.frozen_params", "src.utils.utils.frozen_params", "image_systems.TransferViewMakerSystem.create_model", "Exception", "torch.Sequential", "torch.Sequential", "torch.Sequential", "list", "image_systems.TransferViewMakerSystem.encoder.children"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.load_pretrained_model", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.get_image_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_model"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "self", ".", "encoder", ",", "self", ".", "viewmaker", ",", "self", ".", "system", ",", "self", ".", "pretrain_config", "=", "self", ".", "load_pretrained_model", "(", ")", "\n", "resnet", "=", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_version", "\n", "\n", "if", "resnet", "==", "'resnet18'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "                    ", "num_features", "=", "512", "*", "4", "*", "4", "\n", "", "else", ":", "\n", "                    ", "num_features", "=", "512", "*", "7", "*", "7", "\n", "", "", "else", ":", "\n", "                ", "num_features", "=", "512", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'resnet {resnet} not supported.'", ")", "\n", "", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "datasets", ".", "get_image_datasets", "(", "\n", "config", ".", "data_params", ".", "dataset", ",", "\n", "default_augmentations", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "default_augmentations", "or", "False", ",", "\n", ")", "\n", "if", "not", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "encoder", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", "# keep pooling layer", "\n", "\n", "", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "self", ".", "viewmaker", "=", "self", ".", "viewmaker", ".", "eval", "(", ")", "\n", "# linear evaluation freezes pretrained weights", "\n", "utils", ".", "frozen_params", "(", "self", ".", "encoder", ")", "\n", "utils", ".", "frozen_params", "(", "self", ".", "viewmaker", ")", "\n", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.load_pretrained_model": [[496, 517], ["os.path.join", "src.utils.utils.load_json", "dotmap.DotMap", "SystemClass", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "SystemClass.load_state_dict", "SystemClass.model.eval", "SystemClass.viewmaker.eval", "globals"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json"], ["", "def", "load_pretrained_model", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "self", ".", "config", ".", "pretrain_model", ".", "exp_dir", "\n", "checkpoint_name", "=", "self", ".", "config", ".", "pretrain_model", ".", "checkpoint_name", "\n", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'config.json'", ")", "\n", "config_json", "=", "utils", ".", "load_json", "(", "config_path", ")", "\n", "config", "=", "DotMap", "(", "config_json", ")", "\n", "\n", "if", "self", ".", "config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "config", ".", "model_params", ".", "resnet_small", "=", "self", ".", "config", ".", "model_params", ".", "resnet_small", "\n", "\n", "", "SystemClass", "=", "globals", "(", ")", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'checkpoints'", ",", "checkpoint_name", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ",", "map_location", "=", "self", ".", "device", ")", "\n", "system", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "False", ")", "\n", "\n", "encoder", "=", "system", ".", "model", ".", "eval", "(", ")", "\n", "viewmaker", "=", "system", ".", "viewmaker", ".", "eval", "(", ")", "\n", "\n", "return", "encoder", ",", "viewmaker", ",", "system", ",", "system", ".", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.create_model": [[518, 522], ["src.models.transfer.LogisticRegression"], "methods", ["None"], ["", "def", "create_model", "(", "self", ")", ":", "\n", "        ", "num_class", "=", "self", ".", "train_dataset", ".", "NUM_CLASSES", "\n", "model", "=", "LogisticRegression", "(", "self", ".", "num_features", ",", "num_class", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.noise": [[523, 528], ["src.utils.utils.l2_normalize", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "def", "noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "shape", "=", "(", "batch_size", ",", "self", ".", "pretrain_config", ".", "model_params", ".", "noise_dim", ")", "\n", "# Center noise at 0 then project to unit sphere.", "\n", "noise", "=", "utils", ".", "l2_normalize", "(", "torch", ".", "rand", "(", "shape", ")", "-", "0.5", ")", "\n", "return", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.forward": [[529, 550], ["image_systems.TransferViewMakerSystem.size", "image_systems.TransferViewMakerSystem.model", "image_systems.TransferViewMakerSystem.system.normalize", "torch_dct.dct_2d", "image_systems.TransferViewMakerSystem.viewmaker", "image_systems.TransferViewMakerSystem.system.normalize", "image_systems.TransferViewMakerSystem.encoder", "image_systems.TransferViewMakerSystem.view", "image_systems.TransferViewMakerSystem.std", "type", "random.randint", "image_systems.TransferViewMakerSystem.encoder", "image_systems.TransferViewMakerSystem.encoder", "image_systems.TransferViewMakerSystem.mean"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "img", ",", "valid", "=", "False", ")", ":", "\n", "        ", "batch_size", "=", "img", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "pretrain_config", ".", "data_params", ".", "spectral_domain", ":", "\n", "            ", "img", "=", "self", ".", "system", ".", "normalize", "(", "img", ")", "\n", "img", "=", "dct", ".", "dct_2d", "(", "img", ")", "\n", "img", "=", "(", "img", "-", "img", ".", "mean", "(", ")", ")", "/", "img", ".", "std", "(", ")", "\n", "", "if", "not", "valid", "and", "not", "self", ".", "config", ".", "optim_params", ".", "no_views", ":", "\n", "            ", "img", "=", "self", ".", "viewmaker", "(", "img", ")", "\n", "if", "type", "(", "img", ")", "==", "tuple", ":", "\n", "                ", "idx", "=", "random", ".", "randint", "(", "0", ",", "1", ")", "\n", "img", "=", "img", "[", "idx", "]", "\n", "", "", "if", "'Expert'", "not", "in", "self", ".", "pretrain_config", ".", "system", "and", "not", "self", ".", "pretrain_config", ".", "data_params", ".", "spectral_domain", ":", "\n", "            ", "img", "=", "self", ".", "system", ".", "normalize", "(", "img", ")", "\n", "", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "embs", "=", "self", ".", "encoder", "(", "img", ",", "layer", "=", "5", ")", "\n", "", "else", ":", "\n", "                ", "embs", "=", "self", ".", "encoder", "(", "img", ",", "layer", "=", "6", ")", "\n", "", "", "else", ":", "\n", "            ", "embs", "=", "self", ".", "encoder", "(", "img", ")", "\n", "", "return", "self", ".", "model", "(", "embs", ".", "view", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.get_losses_for_batch": [[551, 559], ["image_systems.TransferViewMakerSystem.forward", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view", "label.view().float", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "label.view"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ",", "valid", "=", "False", ")", ":", "\n", "        ", "_", ",", "img", ",", "_", ",", "_", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "img", ",", "valid", ")", "\n", "if", "self", ".", "train_dataset", ".", "MULTI_LABEL", ":", "\n", "            ", "return", "F", ".", "binary_cross_entropy", "(", "torch", ".", "sigmoid", "(", "logits", ")", ".", "view", "(", "-", "1", ")", ",", "\n", "label", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.get_accuracies_for_batch": [[560, 577], ["img.size", "image_systems.TransferViewMakerSystem.forward", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "preds.long().cpu.long().cpu.long().cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum().item.detach().cpu().numpy", "torch.sum().item.detach().cpu().numpy", "torch.sum().item.detach().cpu().numpy", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "preds.long().cpu.long().cpu.long().cpu", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "label.cpu", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "preds.long().cpu.long().cpu.long", "preds.long().cpu.long().cpu.cpu", "label.cpu", "torch.sum().item.detach().cpu", "torch.sum().item.detach().cpu", "torch.sum().item.detach().cpu", "preds.long().cpu.long().cpu.long", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum().item.detach", "torch.sum().item.detach", "torch.sum().item.detach", "label.long().cpu", "label.long"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "", "def", "get_accuracies_for_batch", "(", "self", ",", "batch", ",", "valid", "=", "False", ")", ":", "\n", "        ", "_", ",", "img", ",", "_", ",", "_", ",", "label", "=", "batch", "\n", "batch_size", "=", "img", ".", "size", "(", "0", ")", "\n", "logits", "=", "self", ".", "forward", "(", "img", ",", "valid", ")", "\n", "if", "self", ".", "train_dataset", ".", "MULTI_LABEL", ":", "\n", "            ", "preds", "=", "torch", ".", "round", "(", "torch", ".", "sigmoid", "(", "logits", ")", ")", "\n", "preds", "=", "preds", ".", "long", "(", ")", ".", "cpu", "(", ")", "\n", "num_correct", "=", "torch", ".", "sum", "(", "preds", ".", "cpu", "(", ")", "==", "label", ".", "cpu", "(", ")", ",", "dim", "=", "0", ")", "\n", "num_correct", "=", "num_correct", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "num_total", "=", "batch_size", "\n", "return", "num_correct", ",", "num_total", ",", "preds", ",", "label", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "torch", ".", "argmax", "(", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", "\n", "preds", "=", "preds", ".", "long", "(", ")", ".", "cpu", "(", ")", "\n", "num_correct", "=", "torch", ".", "sum", "(", "preds", "==", "label", ".", "long", "(", ")", ".", "cpu", "(", ")", ")", ".", "item", "(", ")", "\n", "num_total", "=", "batch_size", "\n", "return", "num_correct", ",", "num_total", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.training_step": [[578, 593], ["image_systems.TransferViewMakerSystem.get_losses_for_batch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "image_systems.TransferViewMakerSystem.get_accuracies_for_batch", "num_correct.mean.mean.mean", "image_systems.TransferViewMakerSystem.get_accuracies_for_batch", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "train_dataset", ".", "MULTI_LABEL", ":", "\n", "                ", "num_correct", ",", "num_total", ",", "_", ",", "_", "=", "self", ".", "get_accuracies_for_batch", "(", "batch", ")", "\n", "num_correct", "=", "num_correct", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "num_correct", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "batch", ")", "\n", "", "metrics", "=", "{", "\n", "'train_loss'", ":", "loss", ",", "\n", "'train_num_correct'", ":", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'train_num_total'", ":", "torch", ".", "tensor", "(", "num_total", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'train_acc'", ":", "torch", ".", "tensor", "(", "num_correct", "/", "float", "(", "num_total", ")", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "}", "\n", "", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.validation_step": [[594, 614], ["image_systems.TransferViewMakerSystem.get_losses_for_batch", "image_systems.TransferViewMakerSystem.get_accuracies_for_batch", "collections.OrderedDict", "image_systems.TransferViewMakerSystem.get_accuracies_for_batch", "collections.OrderedDict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "val_preds.float", "val_labels.float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "float", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ",", "valid", "=", "True", ")", "\n", "if", "self", ".", "train_dataset", ".", "MULTI_LABEL", ":", "# regardless if binary or not", "\n", "            ", "num_correct", ",", "num_total", ",", "val_preds", ",", "val_labels", "=", "self", ".", "get_accuracies_for_batch", "(", "batch", ",", "valid", "=", "True", ")", "\n", "return", "OrderedDict", "(", "{", "\n", "'val_loss'", ":", "loss", ",", "\n", "'val_num_correct'", ":", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_num_total'", ":", "torch", ".", "tensor", "(", "num_total", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_acc'", ":", "torch", ".", "tensor", "(", "num_correct", "/", "float", "(", "num_total", ")", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_pred_labels'", ":", "val_preds", ".", "float", "(", ")", ",", "\n", "'val_true_labels'", ":", "val_labels", ".", "float", "(", ")", ",", "\n", "}", ")", "\n", "", "else", ":", "\n", "            ", "num_correct", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "batch", ",", "valid", "=", "True", ")", "\n", "return", "OrderedDict", "(", "{", "\n", "'val_loss'", ":", "loss", ",", "\n", "'val_num_correct'", ":", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_num_total'", ":", "torch", ".", "tensor", "(", "num_total", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_acc'", ":", "torch", ".", "tensor", "(", "num_correct", "/", "float", "(", "num_total", ")", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.validation_epoch_end": [[616, 660], ["outputs[].keys", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "val_acc.mean", "range", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "range", "sum", "sum", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "float", "val_acc.mean", "sklearn.metrics.f1_score", "float", "float", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "float", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "metrics", "[", "key", "]", "=", "torch", ".", "tensor", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n", "", "", "if", "self", ".", "train_dataset", ".", "MULTI_LABEL", ":", "\n", "            ", "num_correct", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ",", "dim", "=", "1", ")", ".", "sum", "(", "1", ")", "\n", "num_total", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", ".", "mean", "(", ")", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", ".", "mean", "(", ")", "}", "\n", "num_class", "=", "self", ".", "train_dataset", ".", "NUM_CLASSES", "\n", "for", "c", "in", "range", "(", "num_class", ")", ":", "\n", "                ", "val_acc_c", "=", "num_correct", "[", "c", "]", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "f'val_acc_feat{c}'", "]", "=", "val_acc_c", "\n", "", "val_pred_labels", "=", "torch", ".", "cat", "(", "[", "out", "[", "'val_pred_labels'", "]", "for", "out", "in", "outputs", "]", ",", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "val_true_labels", "=", "torch", ".", "cat", "(", "[", "out", "[", "'val_true_labels'", "]", "for", "out", "in", "outputs", "]", ",", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "\n", "val_f1", "=", "0", "\n", "for", "c", "in", "range", "(", "num_class", ")", ":", "\n", "                ", "val_f1_c", "=", "f1_score", "(", "val_true_labels", "[", ":", ",", "c", "]", ",", "val_pred_labels", "[", ":", ",", "c", "]", ")", "\n", "metrics", "[", "f'val_f1_feat{c}'", "]", "=", "val_f1_c", "\n", "val_f1", "=", "val_f1", "+", "val_f1_c", "\n", "", "val_f1", "=", "val_f1", "/", "float", "(", "num_class", ")", "\n", "metrics", "[", "'val_f1'", "]", "=", "val_f1", "\n", "progress_bar", "[", "'f1'", "]", "=", "val_f1", "\n", "return", "{", "'val_loss'", ":", "metrics", "[", "'val_loss'", "]", ",", "\n", "'log'", ":", "metrics", ",", "\n", "'val_acc'", ":", "val_acc", ",", "\n", "'val_f1'", ":", "val_f1", ",", "\n", "'progress_bar'", ":", "progress_bar", "}", "\n", "", "else", ":", "\n", "            ", "num_correct", "=", "sum", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "num_total", "=", "sum", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", "}", "\n", "return", "{", "'val_loss'", ":", "metrics", "[", "'val_loss'", "]", ",", "\n", "'log'", ":", "metrics", ",", "\n", "'val_acc'", ":", "val_acc", ",", "\n", "'progress_bar'", ":", "progress_bar", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.configure_optimizers": [[661, 673], ["image_systems.TransferViewMakerSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD"], "methods", ["None"], ["", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "params_iterator", "=", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "self", ".", "config", ".", "optim_params", "==", "'adam'", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "Adam", "(", "params_iterator", ")", "\n", "", "else", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "params_iterator", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "return", "[", "optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.train_dataloader": [[674, 676], ["image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "train_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferViewMakerSystem.val_dataloader": [[677, 680], ["image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "val_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "drop_last", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferExpertSystem.__init__": [[684, 718], ["image_systems.TransferViewMakerSystem.__init__", "image_systems.TransferExpertSystem.load_pretrained_model", "image_systems.TransferExpertSystem.encoder.eval", "src.utils.utils.frozen_params", "src.datasets.datasets.get_image_datasets", "image_systems.TransferExpertSystem.create_model", "Exception", "torch.Sequential", "torch.Sequential", "torch.Sequential", "dotmap.DotMap", "list", "image_systems.TransferExpertSystem.encoder.children"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.load_pretrained_model", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params", "home.repos.pwc.inspect_result.alextamkin_viewmaker.datasets.datasets.get_image_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_model"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransferViewMakerSystem", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "\n", "self", ".", "encoder", ",", "self", ".", "pretrain_config", "=", "self", ".", "load_pretrained_model", "(", ")", "\n", "resnet", "=", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_version", "\n", "if", "resnet", "==", "'resnet18'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "                    ", "num_features", "=", "512", "*", "4", "*", "4", "\n", "", "else", ":", "\n", "                    ", "num_features", "=", "512", "*", "7", "*", "7", "\n", "", "", "else", ":", "\n", "                ", "num_features", "=", "512", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'resnet {resnet} not supported.'", ")", "\n", "\n", "", "if", "not", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "encoder", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", "# keep pooling layer", "\n", "\n", "# Freeze encoder for linear evaluation.", "\n", "", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "utils", ".", "frozen_params", "(", "self", ".", "encoder", ")", "\n", "\n", "default_augmentations", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "default_augmentations", "\n", "if", "self", ".", "config", ".", "data_params", ".", "force_default_views", "or", "default_augmentations", "==", "DotMap", "(", ")", ":", "\n", "           ", "default_augmentations", "=", "'all'", "\n", "", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "datasets", ".", "get_image_datasets", "(", "\n", "config", ".", "data_params", ".", "dataset", ",", "\n", "default_augmentations", "=", "default_augmentations", ",", "\n", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferExpertSystem.load_pretrained_model": [[719, 738], ["os.path.join", "src.utils.utils.load_json", "dotmap.DotMap", "SystemClass", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "SystemClass.load_state_dict", "SystemClass.model.eval", "globals"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json"], ["", "def", "load_pretrained_model", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "self", ".", "config", ".", "pretrain_model", ".", "exp_dir", "\n", "checkpoint_name", "=", "self", ".", "config", ".", "pretrain_model", ".", "checkpoint_name", "\n", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'config.json'", ")", "\n", "config_json", "=", "utils", ".", "load_json", "(", "config_path", ")", "\n", "config", "=", "DotMap", "(", "config_json", ")", "\n", "\n", "if", "self", ".", "config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "config", ".", "model_params", ".", "resnet_small", "=", "self", ".", "config", ".", "model_params", ".", "resnet_small", "\n", "\n", "", "SystemClass", "=", "globals", "(", ")", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'checkpoints'", ",", "checkpoint_name", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ",", "map_location", "=", "self", ".", "device", ")", "\n", "system", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "False", ")", "\n", "\n", "encoder", "=", "system", ".", "model", ".", "eval", "(", ")", "\n", "return", "encoder", ",", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.TransferExpertSystem.forward": [[739, 750], ["img.size", "image_systems.TransferExpertSystem.model", "image_systems.TransferExpertSystem.encoder", "image_systems.TransferExpertSystem.view", "image_systems.TransferExpertSystem.encoder", "image_systems.TransferExpertSystem.encoder"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "img", ",", "unused_valid", "=", "None", ")", ":", "\n", "        ", "del", "unused_valid", "\n", "batch_size", "=", "img", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "embs", "=", "self", ".", "encoder", "(", "img", ",", "layer", "=", "5", ")", "\n", "", "else", ":", "\n", "                ", "embs", "=", "self", ".", "encoder", "(", "img", ",", "layer", "=", "6", ")", "\n", "", "", "else", ":", "\n", "            ", "embs", "=", "self", ".", "encoder", "(", "img", ")", "\n", "", "return", "self", ".", "model", "(", "embs", ".", "view", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader": [[31, 41], ["torch.utils.data.DataLoader"], "function", ["None"], ["def", "create_dataloader", "(", "dataset", ",", "config", ",", "batch_size", ",", "shuffle", "=", "True", ",", "drop_last", "=", "True", ")", ":", "\n", "    ", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", "num_workers", "=", "config", ".", "data_loader_workers", ",", "\n", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.__init__": [[43, 53], ["pytorch_lightning.LightningModule.__init__", "audio_systems.PretrainExpertInstDiscSystem.create_datasets", "audio_systems.PretrainExpertInstDiscSystem.create_encoder", "src.objectives.memory_bank.MemoryBank", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.create_encoder"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "# self.device = f'cuda:{config.gpu_device}' if config.cuda else 'cpu'", "\n", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "self", ".", "create_datasets", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "create_encoder", "(", ")", "\n", "self", ".", "memory_bank", "=", "MemoryBank", "(", "len", "(", "self", ".", "train_dataset", ")", ",", "\n", "self", ".", "config", ".", "model_params", ".", "out_dim", ")", "\n", "self", ".", "train_ordered_labels", "=", "self", ".", "train_dataset", ".", "all_speaker_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.create_datasets": [[54, 73], ["print", "src.datasets.librispeech.LibriSpeech", "print", "src.datasets.librispeech.LibriSpeech"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Initializing train dataset.'", ")", "\n", "train_dataset", "=", "LibriSpeech", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "wavform_transforms", "=", "not", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "small", "=", "self", ".", "config", ".", "data_params", ".", "small", ",", "\n", "input_size", "=", "self", ".", "config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "print", "(", "'Initializing validation dataset.'", ")", "\n", "val_dataset", "=", "LibriSpeech", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "small", "=", "self", ".", "config", ".", "data_params", ".", "small", ",", "\n", "test_url", "=", "self", ".", "config", ".", "data_params", ".", "test_url", ",", "\n", "input_size", "=", "self", ".", "config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.create_encoder": [[74, 101], ["src.models.resnet_small.ResNet18", "getattr", "getattr.", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "getattr.fc.weight.size", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet18"], ["", "def", "create_encoder", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "encoder_model", "=", "resnet_small", ".", "ResNet18", "(", "\n", "self", ".", "config", ".", "model_params", ".", "out_dim", ",", "\n", "num_channels", "=", "1", ",", "\n", "input_size", "=", "64", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "resnet_class", "=", "getattr", "(", "\n", "torchvision", ".", "models", ",", "\n", "self", ".", "config", ".", "model_params", ".", "resnet_version", ",", "\n", ")", "\n", "encoder_model", "=", "resnet_class", "(", "\n", "pretrained", "=", "False", ",", "\n", "num_classes", "=", "self", ".", "config", ".", "model_params", ".", "out_dim", ",", "\n", ")", "\n", "encoder_model", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "\n", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "model_params", ".", "projection_head", ":", "\n", "            ", "mlp_dim", "=", "encoder_model", ".", "fc", ".", "weight", ".", "size", "(", "1", ")", "\n", "encoder_model", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "mlp_dim", ",", "mlp_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "encoder_model", ".", "fc", ",", "\n", ")", "\n", "", "return", "encoder_model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.configure_optimizers": [[102, 108], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "audio_systems.PretrainExpertInstDiscSystem.model.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "optim", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ")", "\n", "return", "[", "optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.forward": [[109, 111], ["audio_systems.PretrainExpertInstDiscSystem.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.get_losses_for_batch": [[112, 126], ["audio_systems.PretrainExpertInstDiscSystem.forward", "src.objectives.infonce.NoiseConstrastiveEstimation", "src.objectives.infonce.NoiseConstrastiveEstimation.get_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "src.objectives.infonce.NoiseConstrastiveEstimation.updated_new_data_memory", "audio_systems.PretrainExpertInstDiscSystem.memory_bank.update"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.updated_new_data_memory", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "indices", ",", "inputs", ",", "_", "=", "batch", "\n", "outputs", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "loss_fn", "=", "NoiseConstrastiveEstimation", "(", "indices", ",", "outputs", ",", "self", ".", "memory_bank", ",", "\n", "k", "=", "self", ".", "config", ".", "loss_params", ".", "k", ",", "\n", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", ",", "\n", "m", "=", "self", ".", "config", ".", "loss_params", ".", "m", ")", "\n", "loss", "=", "loss_fn", ".", "get_loss", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_data_memory", "=", "loss_fn", ".", "updated_new_data_memory", "(", ")", "\n", "self", ".", "memory_bank", ".", "update", "(", "indices", ",", "new_data_memory", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.training_step": [[127, 131], ["audio_systems.PretrainExpertInstDiscSystem.get_losses_for_batch"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ")", "\n", "metrics", "=", "{", "'loss'", ":", "loss", "}", "\n", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label": [[132, 151], ["audio_systems.PretrainExpertInstDiscSystem.memory_bank.get_all_dot_products", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "neighbor_idxs.cpu().numpy.cpu().numpy.squeeze", "neighbor_idxs.cpu().numpy.cpu().numpy.cpu().numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "embs.size", "neighbor_idxs.cpu().numpy.cpu().numpy.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.from_numpy().long.cpu", "torch.from_numpy().long.cpu", "torch.from_numpy().long.cpu", "labels.cpu"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.get_all_dot_products"], ["", "def", "get_nearest_neighbor_label", "(", "self", ",", "embs", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: ONLY TO BE USED FOR VALIDATION.\n        \n        For each example in validation, find the nearest example in the \n        training dataset using the memory bank. Assume its label as\n        the predicted label.\n        \"\"\"", "\n", "all_dps", "=", "self", ".", "memory_bank", ".", "get_all_dot_products", "(", "embs", ")", "\n", "_", ",", "neighbor_idxs", "=", "torch", ".", "topk", "(", "all_dps", ",", "k", "=", "1", ",", "sorted", "=", "False", ",", "dim", "=", "1", ")", "\n", "neighbor_idxs", "=", "neighbor_idxs", ".", "squeeze", "(", "1", ")", "\n", "neighbor_idxs", "=", "neighbor_idxs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "neighbor_labels", "=", "self", ".", "train_ordered_labels", "[", "neighbor_idxs", "]", "\n", "neighbor_labels", "=", "torch", ".", "from_numpy", "(", "neighbor_labels", ")", ".", "long", "(", ")", "\n", "\n", "num_correct", "=", "torch", ".", "sum", "(", "neighbor_labels", ".", "cpu", "(", ")", "==", "labels", ".", "cpu", "(", ")", ")", ".", "item", "(", ")", "\n", "\n", "return", "num_correct", ",", "embs", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.validation_step": [[152, 160], ["audio_systems.PretrainExpertInstDiscSystem.model", "audio_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "collections.OrderedDict"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "speaker_ids", "=", "batch", "\n", "outputs", "=", "self", ".", "model", "(", "inputs", ")", "\n", "num_correct", ",", "batch_size", "=", "self", ".", "get_nearest_neighbor_label", "(", "outputs", ",", "speaker_ids", ")", "\n", "num_correct", "=", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "batch_size", "=", "torch", ".", "tensor", "(", "batch_size", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "OrderedDict", "(", "{", "'val_num_correct'", ":", "num_correct", ",", "\n", "'val_num_total'", ":", "batch_size", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.validation_epoch_end": [[161, 170], ["outputs[].keys", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "float", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "", "num_correct", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "num_total", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "return", "{", "'log'", ":", "metrics", ",", "'val_acc'", ":", "val_acc", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.train_dataloader": [[171, 173], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "train_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertInstDiscSystem.val_dataloader": [[174, 176], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "val_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertSimCLRSystem.create_datasets": [[180, 197], ["src.datasets.librispeech.LibriSpeechTwoViews", "src.datasets.librispeech.LibriSpeech"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "LibriSpeechTwoViews", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "wavform_transforms", "=", "not", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "small", "=", "self", ".", "config", ".", "data_params", ".", "small", ",", "\n", "input_size", "=", "self", ".", "config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "LibriSpeech", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "small", "=", "self", ".", "config", ".", "data_params", ".", "small", ",", "\n", "test_url", "=", "self", ".", "config", ".", "data_params", ".", "test_url", ",", "\n", "input_size", "=", "self", ".", "config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainExpertSimCLRSystem.get_losses_for_batch": [[198, 212], ["audio_systems.PretrainExpertSimCLRSystem.forward", "audio_systems.PretrainExpertSimCLRSystem.forward", "src.objectives.simclr.SimCLRObjective", "src.objectives.simclr.SimCLRObjective.get_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "audio_systems.PretrainExpertSimCLRSystem.memory_bank.update", "src.utils.utils.l2_normalize", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "indices", ",", "inputs1", ",", "inputs2", ",", "_", "=", "batch", "\n", "outputs1", "=", "self", ".", "forward", "(", "inputs1", ")", "\n", "outputs2", "=", "self", ".", "forward", "(", "inputs2", ")", "\n", "loss_fn", "=", "SimCLRObjective", "(", "outputs1", ",", "outputs2", ",", "\n", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", ")", "\n", "loss", "=", "loss_fn", ".", "get_loss", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "# for nearest neighbor", "\n", "            ", "new_data_memory", "=", "(", "l2_normalize", "(", "outputs1", ",", "dim", "=", "1", ")", "+", "\n", "l2_normalize", "(", "outputs2", ",", "dim", "=", "1", ")", ")", "/", "2.", "\n", "self", ".", "memory_bank", ".", "update", "(", "indices", ",", "new_data_memory", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.__init__": [[219, 222], ["audio_systems.PretrainExpertInstDiscSystem.__init__", "audio_systems.PretrainViewMakerInstDiscSystem.create_viewmaker"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.create_viewmaker"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "view", "=", "self", ".", "create_viewmaker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.create_datasets": [[223, 240], ["src.datasets.librispeech.LibriSpeech", "src.datasets.librispeech.LibriSpeech"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "LibriSpeech", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "small", "=", "self", ".", "config", ".", "data_params", ".", "small", ",", "\n", "input_size", "=", "self", ".", "config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "LibriSpeech", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "small", "=", "self", ".", "config", ".", "data_params", ".", "small", ",", "\n", "test_url", "=", "self", ".", "config", ".", "data_params", ".", "test_url", ",", "\n", "input_size", "=", "self", ".", "config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.create_viewmaker": [[241, 250], ["src.models.viewmaker.Viewmaker"], "methods", ["None"], ["", "def", "create_viewmaker", "(", "self", ")", ":", "\n", "        ", "view_model", "=", "Viewmaker", "(", "\n", "num_channels", "=", "1", ",", "\n", "distortion_budget", "=", "self", ".", "config", ".", "model_params", ".", "view_bound_magnitude", ",", "\n", "activation", "=", "self", ".", "config", ".", "model_params", ".", "generator_activation", "or", "'relu'", ",", "\n", "num_res_blocks", "=", "self", ".", "config", ".", "model_params", ".", "num_res_blocks", ",", "\n", "clamp", "=", "False", ",", "\n", ")", "\n", "return", "view_model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.configure_optimizers": [[251, 273], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "audio_systems.PretrainViewMakerInstDiscSystem.view.parameters", "audio_systems.PretrainViewMakerInstDiscSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "ValueError"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "encoder_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "view_optim_name", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_optim", "\n", "view_parameters", "=", "self", ".", "view", ".", "parameters", "(", ")", "\n", "if", "view_optim_name", "==", "'adam'", ":", "\n", "            ", "view_optim", "=", "torch", ".", "optim", ".", "Adam", "(", "view_parameters", ")", "\n", "", "elif", "not", "view_optim_name", "or", "view_optim_name", "==", "'sgd'", ":", "\n", "            ", "view_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "view_parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_learning_rate", "or", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Optimizer {view_optim_name} not implemented'", ")", "\n", "\n", "", "return", "[", "encoder_optim", ",", "view_optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.forward": [[274, 290], ["audio_systems.PretrainViewMakerInstDiscSystem.view", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "audio_systems.PretrainViewMakerInstDiscSystem.model"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "indices", ",", "inputs", ",", "_", "=", "batch", "\n", "view", "=", "self", ".", "view", "(", "inputs", ")", "\n", "\n", "if", "self", ".", "config", ".", "model_params", ".", "view_clip", ":", "\n", "            ", "num_std", "=", "self", ".", "config", ".", "model_params", ".", "view_clip_num_std", "\n", "tot_std", "=", "num_std", "*", "self", ".", "train_dataset", ".", "normalize_stdev", "\n", "view_min", "=", "self", ".", "train_dataset", ".", "normalize_mean", "-", "tot_std", "\n", "view_max", "=", "self", ".", "train_dataset", ".", "normalize_mean", "+", "tot_std", "\n", "view", "=", "torch", ".", "clamp", "(", "view", ",", "view_min", ",", "view_max", ")", "\n", "\n", "", "emb_dict", "=", "{", "\n", "'indices'", ":", "indices", ",", "\n", "'view_embs'", ":", "self", ".", "model", "(", "view", ")", ",", "\n", "}", "\n", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.get_losses_for_batch": [[291, 308], ["src.objectives.adversarial.AdversarialNCELoss", "src.objectives.adversarial.AdversarialNCELoss.get_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "src.objectives.adversarial.AdversarialNCELoss.updated_new_data_memory", "audio_systems.PretrainViewMakerInstDiscSystem.memory_bank.update"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.updated_new_data_memory", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update"], ["", "def", "get_losses_for_batch", "(", "self", ",", "emb_dict", ")", ":", "\n", "        ", "indices", "=", "emb_dict", "[", "'indices'", "]", "\n", "outputs", "=", "emb_dict", "[", "'view_embs'", "]", "\n", "loss_fn", "=", "AdversarialNCELoss", "(", "\n", "indices", ",", "outputs", ",", "self", ".", "memory_bank", ",", "\n", "k", "=", "self", ".", "config", ".", "loss_params", ".", "k", ",", "\n", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", ",", "\n", "m", "=", "self", ".", "config", ".", "loss_params", ".", "m", ",", "\n", "view_maker_loss_weight", "=", "self", ".", "config", ".", "loss_params", ".", "view_maker_loss_weight", ",", "\n", ")", "\n", "encoder_loss", ",", "view_maker_loss", "=", "loss_fn", ".", "get_loss", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_data_memory", "=", "loss_fn", ".", "updated_new_data_memory", "(", ")", "\n", "self", ".", "memory_bank", ".", "update", "(", "indices", ",", "new_data_memory", ")", "\n", "\n", "", "return", "encoder_loss", ",", "view_maker_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.get_view_bound_magnitude": [[309, 311], ["None"], "methods", ["None"], ["", "def", "get_view_bound_magnitude", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "config", ".", "model_params", ".", "view_bound_magnitude", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.training_step": [[312, 316], ["audio_systems.PretrainViewMakerInstDiscSystem.forward", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ",", "optimizer_idx", ")", ":", "\n", "        ", "emb_dict", "=", "self", ".", "forward", "(", "batch", ")", "\n", "emb_dict", "[", "'optimizer_idx'", "]", "=", "torch", ".", "tensor", "(", "optimizer_idx", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.training_step_end": [[317, 340], ["audio_systems.PretrainViewMakerInstDiscSystem.get_losses_for_batch", "audio_systems.PretrainViewMakerInstDiscSystem.get_view_bound_magnitude", "emb_dict[].dim"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.get_view_bound_magnitude"], ["", "def", "training_step_end", "(", "self", ",", "emb_dict", ")", ":", "\n", "        ", "encoder_loss", ",", "view_maker_loss", "=", "self", ".", "get_losses_for_batch", "(", "emb_dict", ")", "\n", "\n", "# Handle Tensor (dp) and int (ddp) cases", "\n", "if", "emb_dict", "[", "'optimizer_idx'", "]", ".", "__class__", "==", "int", "or", "emb_dict", "[", "'optimizer_idx'", "]", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "optimizer_idx", "=", "emb_dict", "[", "'optimizer_idx'", "]", "\n", "", "else", ":", "\n", "            ", "optimizer_idx", "=", "emb_dict", "[", "'optimizer_idx'", "]", "[", "0", "]", "\n", "\n", "", "if", "optimizer_idx", "==", "0", ":", "\n", "            ", "metrics", "=", "{", "\n", "'encoder_loss'", ":", "encoder_loss", ",", "\n", "}", "\n", "return", "{", "'loss'", ":", "encoder_loss", ",", "'log'", ":", "metrics", "}", "\n", "", "else", ":", "\n", "# update the bound allowed for view", "\n", "            ", "self", ".", "view", ".", "bound_magnitude", "=", "self", ".", "get_view_bound_magnitude", "(", ")", "\n", "\n", "metrics", "=", "{", "\n", "'view_maker_loss'", ":", "view_maker_loss", ",", "\n", "# 'view_bound_magnitude': self.view.bound_magnitude,", "\n", "}", "\n", "return", "{", "'loss'", ":", "view_maker_loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.validation_step": [[341, 350], ["audio_systems.PretrainViewMakerInstDiscSystem.model", "audio_systems.PretrainViewMakerInstDiscSystem.get_nearest_neighbor_label", "collections.OrderedDict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label"], ["", "", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "labels", "=", "batch", "\n", "outputs", "=", "self", ".", "model", "(", "inputs", ")", "\n", "num_correct", ",", "batch_size", "=", "self", ".", "get_nearest_neighbor_label", "(", "outputs", ",", "labels", ")", "\n", "output", "=", "OrderedDict", "(", "{", "\n", "'val_num_correct'", ":", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_num_total'", ":", "torch", ".", "tensor", "(", "batch_size", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "}", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerInstDiscSystem.validation_epoch_end": [[351, 361], ["outputs[].keys", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "float", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "", "num_correct", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "num_total", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", "}", "\n", "return", "{", "'log'", ":", "metrics", ",", "'val_acc'", ":", "val_acc", ",", "'progress_bar'", ":", "progress_bar", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.__init__": [[368, 371], ["audio_systems.PretrainExpertInstDiscSystem.__init__", "audio_systems.PretrainViewMakerSimCLRSystem.create_viewmaker"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.create_viewmaker"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "view", "=", "self", ".", "create_viewmaker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.create_datasets": [[372, 389], ["src.datasets.librispeech.LibriSpeechTwoViews", "src.datasets.librispeech.LibriSpeech"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "LibriSpeechTwoViews", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "small", "=", "self", ".", "config", ".", "data_params", ".", "small", ",", "\n", "input_size", "=", "self", ".", "config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "LibriSpeech", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "small", "=", "self", ".", "config", ".", "data_params", ".", "small", ",", "\n", "test_url", "=", "self", ".", "config", ".", "data_params", ".", "test_url", ",", "\n", "input_size", "=", "self", ".", "config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.create_viewmaker": [[390, 400], ["src.models.viewmaker.Viewmaker"], "methods", ["None"], ["", "def", "create_viewmaker", "(", "self", ")", ":", "\n", "        ", "filter_size", "=", "self", ".", "train_dataset", ".", "FILTER_SIZE", "\n", "view_model", "=", "Viewmaker", "(", "\n", "num_channels", "=", "1", ",", "\n", "distortion_budget", "=", "self", ".", "config", ".", "model_params", ".", "view_bound_magnitude", ",", "\n", "activation", "=", "self", ".", "config", ".", "model_params", ".", "generator_activation", "or", "'relu'", ",", "\n", "num_res_blocks", "=", "self", ".", "config", ".", "model_params", ".", "num_res_blocks", ",", "\n", "clamp", "=", "False", ",", "\n", ")", "\n", "return", "view_model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.configure_optimizers": [[401, 423], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "audio_systems.PretrainViewMakerSimCLRSystem.view.parameters", "audio_systems.PretrainViewMakerSimCLRSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "ValueError"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "encoder_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "view_optim_name", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_optim", "\n", "view_parameters", "=", "self", ".", "view", ".", "parameters", "(", ")", "\n", "if", "view_optim_name", "==", "'adam'", ":", "\n", "            ", "view_optim", "=", "torch", ".", "optim", ".", "Adam", "(", "view_parameters", ")", "\n", "", "elif", "not", "view_optim_name", "or", "view_optim_name", "==", "'sgd'", ":", "\n", "            ", "view_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "view_parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_learning_rate", "or", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Optimizer {view_optim_name} not implemented'", ")", "\n", "\n", "", "return", "[", "encoder_optim", ",", "view_optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.forward": [[424, 443], ["audio_systems.PretrainViewMakerSimCLRSystem.view", "audio_systems.PretrainViewMakerSimCLRSystem.view", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "audio_systems.PretrainViewMakerSimCLRSystem.model", "audio_systems.PretrainViewMakerSimCLRSystem.model"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "indices", ",", "inputs", ",", "inputs2", ",", "_", "=", "batch", "\n", "view1", "=", "self", ".", "view", "(", "inputs", ")", "\n", "view2", "=", "self", ".", "view", "(", "inputs2", ")", "\n", "\n", "if", "self", ".", "config", ".", "model_params", ".", "view_clip", ":", "\n", "            ", "num_std", "=", "self", ".", "config", ".", "model_params", ".", "view_clip_num_std", "\n", "tot_std", "=", "num_std", "*", "self", ".", "train_dataset", ".", "normalize_stdev", "\n", "view_min", "=", "self", ".", "train_dataset", ".", "normalize_mean", "-", "tot_std", "\n", "view_max", "=", "self", ".", "train_dataset", ".", "normalize_mean", "+", "tot_std", "\n", "view1", "=", "torch", ".", "clamp", "(", "view1", ",", "view_min", ",", "view_max", ")", "\n", "view2", "=", "torch", ".", "clamp", "(", "view2", ",", "view_min", ",", "view_max", ")", "\n", "\n", "", "emb_dict", "=", "{", "\n", "'indices'", ":", "indices", ",", "\n", "'view1_embs'", ":", "self", ".", "model", "(", "view1", ")", ",", "\n", "'view2_embs'", ":", "self", ".", "model", "(", "view2", ")", ",", "\n", "}", "\n", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.get_losses_for_batch": [[444, 458], ["src.objectives.adversarial.AdversarialSimCLRLoss", "src.objectives.adversarial.AdversarialSimCLRLoss.get_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "src.utils.utils.l2_normalize", "audio_systems.PretrainViewMakerSimCLRSystem.memory_bank.update", "emb_dict[].detach"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update"], ["", "def", "get_losses_for_batch", "(", "self", ",", "emb_dict", ")", ":", "\n", "        ", "loss_function", "=", "AdversarialSimCLRLoss", "(", "\n", "embs1", "=", "emb_dict", "[", "'view1_embs'", "]", ",", "\n", "embs2", "=", "emb_dict", "[", "'view2_embs'", "]", ",", "\n", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", ",", "\n", "view_maker_loss_weight", "=", "self", ".", "config", ".", "loss_params", ".", "view_maker_loss_weight", "\n", ")", "\n", "encoder_loss", ",", "view_maker_loss", "=", "loss_function", ".", "get_loss", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_data_memory", "=", "l2_normalize", "(", "emb_dict", "[", "'view1_embs'", "]", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "self", ".", "memory_bank", ".", "update", "(", "emb_dict", "[", "'indices'", "]", ",", "new_data_memory", ")", "\n", "\n", "", "return", "encoder_loss", ",", "view_maker_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.get_view_bound_magnitude": [[459, 470], ["int", "math.ceil", "len"], "methods", ["None"], ["", "def", "get_view_bound_magnitude", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "model_params", ".", "view_bound_linear_scale", ":", "\n", "            ", "batch_size", "=", "self", ".", "config", ".", "optim_params", ".", "batch_size", "\n", "num_epochs", "=", "self", ".", "config", ".", "num_epochs", "\n", "num_steps", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "self", ".", "train_dataset", ")", "/", "batch_size", ")", ")", "*", "num_epochs", "\n", "view_bound_max", "=", "self", ".", "config", ".", "model_params", ".", "view_bound_max", "\n", "view_bound_min", "=", "self", ".", "config", ".", "model_params", ".", "view_bound_min", "\n", "iter_incr", "=", "(", "view_bound_max", "-", "view_bound_min", ")", "/", "num_steps", "\n", "return", "view_bound_min", "+", "self", ".", "global_step", "*", "iter_incr", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "config", ".", "model_params", ".", "view_bound_magnitude", "# constant", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.training_step": [[471, 475], ["audio_systems.PretrainViewMakerSimCLRSystem.forward", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ",", "optimizer_idx", ")", ":", "\n", "        ", "emb_dict", "=", "self", ".", "forward", "(", "batch", ")", "\n", "emb_dict", "[", "'optimizer_idx'", "]", "=", "torch", ".", "tensor", "(", "optimizer_idx", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.training_step_end": [[476, 499], ["audio_systems.PretrainViewMakerSimCLRSystem.get_losses_for_batch", "audio_systems.PretrainViewMakerSimCLRSystem.get_view_bound_magnitude", "emb_dict[].dim"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.get_view_bound_magnitude"], ["", "def", "training_step_end", "(", "self", ",", "emb_dict", ")", ":", "\n", "        ", "encoder_loss", ",", "view_maker_loss", "=", "self", ".", "get_losses_for_batch", "(", "emb_dict", ")", "\n", "\n", "# Handle Tensor (dp) and int (ddp) cases", "\n", "if", "emb_dict", "[", "'optimizer_idx'", "]", ".", "__class__", "==", "int", "or", "emb_dict", "[", "'optimizer_idx'", "]", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "optimizer_idx", "=", "emb_dict", "[", "'optimizer_idx'", "]", "\n", "", "else", ":", "\n", "            ", "optimizer_idx", "=", "emb_dict", "[", "'optimizer_idx'", "]", "[", "0", "]", "\n", "\n", "", "if", "optimizer_idx", "==", "0", ":", "\n", "            ", "metrics", "=", "{", "\n", "'encoder_loss'", ":", "encoder_loss", ",", "\n", "}", "\n", "return", "{", "'loss'", ":", "encoder_loss", ",", "'log'", ":", "metrics", "}", "\n", "", "else", ":", "\n", "# update the bound allowed for view", "\n", "            ", "self", ".", "view", ".", "bound_magnitude", "=", "self", ".", "get_view_bound_magnitude", "(", ")", "\n", "\n", "metrics", "=", "{", "\n", "'view_maker_loss'", ":", "view_maker_loss", ",", "\n", "# 'view_bound_magnitude': self.view.bound_magnitude,", "\n", "}", "\n", "return", "{", "'loss'", ":", "view_maker_loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.validation_step": [[500, 509], ["audio_systems.PretrainViewMakerSimCLRSystem.model", "audio_systems.PretrainViewMakerSimCLRSystem.get_nearest_neighbor_label", "collections.OrderedDict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label"], ["", "", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "labels", "=", "batch", "\n", "outputs", "=", "self", ".", "model", "(", "inputs", ")", "\n", "num_correct", ",", "batch_size", "=", "self", ".", "get_nearest_neighbor_label", "(", "outputs", ",", "labels", ")", "\n", "output", "=", "OrderedDict", "(", "{", "\n", "'val_num_correct'", ":", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_num_total'", ":", "torch", ".", "tensor", "(", "batch_size", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "}", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.PretrainViewMakerSimCLRSystem.validation_epoch_end": [[510, 520], ["outputs[].keys", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "float", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "", "num_correct", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "num_total", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", "}", "\n", "return", "{", "'log'", ":", "metrics", ",", "'val_acc'", ":", "val_acc", ",", "'progress_bar'", ":", "progress_bar", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.BaseTransferExpertSystem.__init__": [[524, 561], ["pytorch_lightning.LightningModule.__init__", "audio_systems.BaseTransferExpertSystem.load_pretrained_model", "audio_systems.BaseTransferExpertSystem.encoder.eval", "src.utils.utils.frozen_params", "audio_systems.BaseTransferExpertSystem.create_datasets", "audio_systems.BaseTransferExpertSystem.create_model", "torch.Sequential", "torch.Sequential", "torch.Sequential", "Exception", "list", "audio_systems.BaseTransferExpertSystem.encoder.children"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.load_pretrained_model", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_model"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "\n", "self", ".", "encoder", ",", "self", ".", "pretrain_config", "=", "self", ".", "load_pretrained_model", "(", ")", "\n", "resnet", "=", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_version", "\n", "if", "resnet", "==", "'resnet18'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "                    ", "num_features", "=", "512", "*", "4", "*", "4", "\n", "", "else", ":", "\n", "                    ", "num_features", "=", "512", "*", "2", "*", "2", "\n", "", "", "else", ":", "\n", "                ", "num_features", "=", "512", "\n", "", "", "elif", "resnet", "==", "'resnet50'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "num_features", "=", "2048", "*", "4", "*", "4", "\n", "", "else", ":", "\n", "                ", "num_features", "=", "2048", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'resnet {resnet} not supported.'", ")", "\n", "\n", "", "if", "not", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "cut_ix", "=", "-", "2", "\n", "", "else", ":", "\n", "                ", "cut_ix", "=", "-", "1", "\n", "# keep pooling layer", "\n", "", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "encoder", ".", "children", "(", ")", ")", "[", ":", "cut_ix", "]", ")", "\n", "\n", "", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "frozen_params", "(", "self", ".", "encoder", ")", "\n", "\n", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "self", ".", "create_datasets", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.BaseTransferExpertSystem.load_pretrained_model": [[562, 581], ["os.path.join", "src.utils.utils.load_json", "dotmap.DotMap", "SystemClass", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "SystemClass.load_state_dict", "SystemClass.model.eval", "SystemClass.model.eval.parameters", "globals"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json"], ["", "def", "load_pretrained_model", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "self", ".", "config", ".", "pretrain_model", ".", "exp_dir", "\n", "checkpoint_name", "=", "self", ".", "config", ".", "pretrain_model", ".", "checkpoint_name", "\n", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'config.json'", ")", "\n", "config_json", "=", "load_json", "(", "config_path", ")", "\n", "config", "=", "DotMap", "(", "config_json", ")", "\n", "\n", "SystemClass", "=", "globals", "(", ")", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'checkpoints'", ",", "checkpoint_name", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ",", "map_location", "=", "self", ".", "device", ")", "\n", "system", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "\n", "encoder", "=", "system", ".", "model", ".", "eval", "(", ")", "\n", "for", "param", "in", "encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "return", "encoder", ",", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.BaseTransferExpertSystem.train_dataloader": [[582, 584], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "train_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.BaseTransferExpertSystem.val_dataloader": [[585, 587], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "val_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.create_datasets": [[591, 605], ["src.datasets.librispeech.LibriSpeechTransfer", "src.datasets.librispeech.LibriSpeechTransfer"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "LibriSpeechTransfer", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "wavform_transforms", "=", "not", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "LibriSpeechTransfer", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.create_model": [[606, 609], ["src.models.transfer.LogisticRegression", "src.models.transfer.LogisticRegression.to"], "methods", ["None"], ["", "def", "create_model", "(", "self", ")", ":", "\n", "        ", "model", "=", "LogisticRegression", "(", "self", ".", "num_features", ",", "self", ".", "train_dataset", ".", "num_labels", ")", "\n", "return", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.configure_optimizers": [[610, 622], ["audio_systems.TransferExpertLibriSpeechSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "parameters", "=", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "self", ".", "config", ".", "optim_params", "==", "'adam'", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ")", "\n", "", "else", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "return", "[", "optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.forward": [[623, 633], ["inputs.size", "audio_systems.TransferExpertLibriSpeechSystem.view", "audio_systems.TransferExpertLibriSpeechSystem.model", "audio_systems.TransferExpertLibriSpeechSystem.encoder", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "audio_systems.TransferExpertLibriSpeechSystem.encoder"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "layer", "=", "5", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", "else", "6", "\n", "embs", "=", "self", ".", "encoder", "(", "inputs", ",", "layer", "=", "layer", ")", "\n", "embs", "=", "F", ".", "avg_pool2d", "(", "embs", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "embs", "=", "self", ".", "encoder", "(", "inputs", ")", "\n", "", "embs", "=", "embs", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "return", "self", ".", "model", "(", "embs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.get_losses_for_batch": [[634, 638], ["audio_systems.TransferExpertLibriSpeechSystem.forward", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.get_accuracies_for_batch": [[639, 646], ["audio_systems.TransferExpertLibriSpeechSystem.forward", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "src.utils.utils.compute_accuracy", "inputs.size"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.compute_accuracy"], ["", "def", "get_accuracies_for_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "outputs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "num_correct_top1", ",", "num_correct_top5", "=", "compute_accuracy", "(", "outputs", ",", "label", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "num_total", "=", "inputs", ".", "size", "(", "0", ")", "\n", "return", "num_correct_top1", ",", "num_correct_top5", ",", "num_total", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.training_step": [[647, 660], ["audio_systems.TransferExpertLibriSpeechSystem.get_losses_for_batch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "audio_systems.TransferExpertLibriSpeechSystem.get_accuracies_for_batch", "float", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "num_correct_top1", ",", "num_correct_top5", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "batch", ")", "\n", "metrics", "=", "{", "\n", "'train_loss'", ":", "loss", ",", "\n", "'train_num_correct_top1'", ":", "num_correct_top1", ",", "\n", "'train_num_correct_top5'", ":", "num_correct_top5", ",", "\n", "'train_num_total'", ":", "num_total", ",", "\n", "'train_top1'", ":", "num_correct_top1", "/", "float", "(", "num_total", ")", ",", "\n", "'train_top5'", ":", "num_correct_top5", "/", "float", "(", "num_total", ")", ",", "\n", "}", "\n", "", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.validation_step": [[661, 671], ["audio_systems.TransferExpertLibriSpeechSystem.get_losses_for_batch", "audio_systems.TransferExpertLibriSpeechSystem.get_accuracies_for_batch", "collections.OrderedDict", "float", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ")", "\n", "num_correct_top1", ",", "num_correct_top5", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "batch", ")", "\n", "return", "OrderedDict", "(", "{", "\n", "'val_loss'", ":", "loss", ",", "\n", "'val_num_correct_top1'", ":", "num_correct_top1", ",", "\n", "'val_num_correct_top5'", ":", "num_correct_top5", ",", "\n", "'val_num_total'", ":", "num_total", ",", "\n", "'val_top1'", ":", "num_correct_top1", "/", "float", "(", "num_total", ")", ",", "\n", "'val_top5'", ":", "num_correct_top5", "/", "float", "(", "num_total", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertLibriSpeechSystem.validation_epoch_end": [[673, 686], ["outputs[].keys", "sum", "sum", "sum", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "float", "float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "tensor", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "", "num_correct_top1", "=", "sum", "(", "[", "out", "[", "'val_num_correct_top1'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "num_correct_top5", "=", "sum", "(", "[", "out", "[", "'val_num_correct_top5'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "num_total", "=", "sum", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "val_top1", "=", "num_correct_top1", "/", "float", "(", "num_total", ")", "\n", "val_top5", "=", "num_correct_top5", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_top1'", "]", "=", "val_top1", "\n", "metrics", "[", "'val_top5'", "]", "=", "val_top5", "\n", "return", "{", "'val_loss'", ":", "metrics", "[", "'val_loss'", "]", ",", "'log'", ":", "metrics", ",", "\n", "'val_top1'", ":", "val_top1", ",", "'val_top5'", ":", "val_top5", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertVoxCeleb1System.create_datasets": [[690, 704], ["src.datasets.voxceleb1.VoxCeleb1", "src.datasets.voxceleb1.VoxCeleb1"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "VoxCeleb1", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "wavform_transforms", "=", "not", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "VoxCeleb1", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertAudioMNISTSystem.create_datasets": [[708, 722], ["src.datasets.audio_mnist.AudioMNIST", "src.datasets.audio_mnist.AudioMNIST"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "AudioMNIST", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "wavform_transforms", "=", "not", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "AudioMNIST", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertGoogleSpeechCommandsSystem.create_datasets": [[726, 740], ["src.datasets.google_speech.GoogleSpeechCommands", "src.datasets.google_speech.GoogleSpeechCommands"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "GoogleSpeechCommands", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "wavform_transforms", "=", "not", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "GoogleSpeechCommands", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferExpertFluentSpeechCommandsSystem.create_datasets": [[744, 760], ["src.datasets.fluent_speech.FluentSpeechCommands", "src.datasets.fluent_speech.FluentSpeechCommands"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "FluentSpeechCommands", "(", "\n", "self", ".", "config", ".", "data_params", ".", "caller_intent", ",", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "wavform_transforms", "=", "not", "self", ".", "config", ".", "data_params", ".", "spectral_transforms", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "FluentSpeechCommands", "(", "\n", "self", ".", "config", ".", "data_params", ".", "caller_intent", ",", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.BaseTransferViewMakerSystem.__init__": [[764, 801], ["pytorch_lightning.LightningModule.__init__", "audio_systems.BaseTransferViewMakerSystem.load_pretrained_model", "audio_systems.BaseTransferViewMakerSystem.encoder.eval", "src.utils.utils.frozen_params", "src.utils.utils.frozen_params", "audio_systems.BaseTransferViewMakerSystem.create_datasets", "audio_systems.BaseTransferViewMakerSystem.create_model", "torch.Sequential", "torch.Sequential", "torch.Sequential", "Exception", "list", "audio_systems.BaseTransferViewMakerSystem.encoder.children"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.load_pretrained_model", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_model"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "\n", "self", ".", "encoder", ",", "self", ".", "viewmaker", ",", "self", ".", "system", ",", "self", ".", "pretrain_config", "=", "self", ".", "load_pretrained_model", "(", ")", "\n", "resnet", "=", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_version", "\n", "if", "resnet", "==", "'resnet18'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "                    ", "num_features", "=", "512", "*", "4", "*", "4", "\n", "", "else", ":", "\n", "                    ", "num_features", "=", "512", "*", "2", "*", "2", "\n", "", "", "else", ":", "\n", "                ", "num_features", "=", "512", "\n", "", "", "elif", "resnet", "==", "'resnet50'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "num_features", "=", "2048", "*", "4", "*", "4", "\n", "", "else", ":", "\n", "                ", "num_features", "=", "2048", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'resnet {resnet} not supported.'", ")", "\n", "\n", "", "if", "not", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "cut_ix", "=", "-", "2", "\n", "", "else", ":", "\n", "                ", "cut_ix", "=", "-", "1", "\n", "", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "encoder", ".", "children", "(", ")", ")", "[", ":", "cut_ix", "]", ")", "\n", "\n", "", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "frozen_params", "(", "self", ".", "encoder", ")", "\n", "frozen_params", "(", "self", ".", "viewmaker", ")", "\n", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "self", ".", "create_datasets", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.BaseTransferViewMakerSystem.load_pretrained_model": [[802, 826], ["os.path.join", "src.utils.utils.load_json", "dotmap.DotMap", "SystemClass", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "SystemClass.load_state_dict", "SystemClass.model.eval", "SystemClass.view.eval", "SystemClass.model.eval.parameters", "SystemClass.view.eval.parameters", "globals"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json"], ["", "def", "load_pretrained_model", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "self", ".", "config", ".", "pretrain_model", ".", "exp_dir", "\n", "checkpoint_name", "=", "self", ".", "config", ".", "pretrain_model", ".", "checkpoint_name", "\n", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'config.json'", ")", "\n", "config_json", "=", "load_json", "(", "config_path", ")", "\n", "config", "=", "DotMap", "(", "config_json", ")", "\n", "\n", "SystemClass", "=", "globals", "(", ")", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'checkpoints'", ",", "checkpoint_name", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ",", "map_location", "=", "self", ".", "device", ")", "\n", "system", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "\n", "encoder", "=", "system", ".", "model", ".", "eval", "(", ")", "\n", "viewmaker", "=", "system", ".", "view", ".", "eval", "(", ")", "\n", "\n", "for", "param", "in", "encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "for", "param", "in", "viewmaker", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "return", "encoder", ",", "viewmaker", ",", "system", ",", "system", ".", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.BaseTransferViewMakerSystem.train_dataloader": [[827, 829], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "train_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.BaseTransferViewMakerSystem.val_dataloader": [[830, 832], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "val_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.create_datasets": [[836, 850], ["src.datasets.librispeech.LibriSpeechTransfer", "src.datasets.librispeech.LibriSpeechTransfer"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "LibriSpeechTransfer", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "LibriSpeechTransfer", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.create_model": [[851, 854], ["src.models.transfer.LogisticRegression", "src.models.transfer.LogisticRegression.to"], "methods", ["None"], ["", "def", "create_model", "(", "self", ")", ":", "\n", "        ", "model", "=", "LogisticRegression", "(", "self", ".", "num_features", ",", "self", ".", "train_dataset", ".", "num_labels", ")", "\n", "return", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.configure_optimizers": [[855, 868], ["audio_systems.TransferViewMakerLibriSpeechSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "parameters", "=", "self", ".", "model", ".", "parameters", "(", ")", "\n", "\n", "if", "self", ".", "config", ".", "optim_params", "==", "'adam'", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ")", "\n", "", "else", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "return", "[", "optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.forward": [[869, 887], ["torch.clamp.size", "torch.clamp.size", "torch.clamp.size", "audio_systems.TransferViewMakerLibriSpeechSystem.view", "audio_systems.TransferViewMakerLibriSpeechSystem.model", "audio_systems.TransferViewMakerLibriSpeechSystem.viewmaker", "audio_systems.TransferViewMakerLibriSpeechSystem.encoder", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "audio_systems.TransferViewMakerLibriSpeechSystem.encoder", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "train", "=", "True", ")", ":", "\n", "        ", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "if", "train", ":", "\n", "            ", "inputs", "=", "self", ".", "viewmaker", "(", "inputs", ")", "\n", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "view_clip", ":", "\n", "                ", "num_std", "=", "self", ".", "pretrain_config", ".", "model_params", ".", "view_clip_num_std", "\n", "tot_std", "=", "num_std", "*", "self", ".", "train_dataset", ".", "normalize_stdev", "\n", "view_min", "=", "self", ".", "train_dataset", ".", "normalize_mean", "-", "tot_std", "\n", "view_max", "=", "self", ".", "train_dataset", ".", "normalize_mean", "+", "tot_std", "\n", "inputs", "=", "torch", ".", "clamp", "(", "inputs", ",", "view_min", ",", "view_max", ")", "\n", "", "", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "layer", "=", "5", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", "else", "6", "\n", "embs", "=", "self", ".", "encoder", "(", "inputs", ",", "layer", "=", "layer", ")", "\n", "embs", "=", "F", ".", "avg_pool2d", "(", "embs", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "embs", "=", "self", ".", "encoder", "(", "inputs", ")", "\n", "", "embs", "=", "embs", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "return", "self", ".", "model", "(", "embs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.get_losses_for_batch": [[888, 892], ["audio_systems.TransferViewMakerLibriSpeechSystem.forward", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ",", "train", "=", "True", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "inputs", ",", "train", "=", "train", ")", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.get_accuracies_for_batch": [[893, 900], ["audio_systems.TransferViewMakerLibriSpeechSystem.forward", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "src.utils.utils.compute_accuracy", "inputs.size"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.compute_accuracy"], ["", "def", "get_accuracies_for_batch", "(", "self", ",", "batch", ",", "train", "=", "True", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "inputs", ",", "train", "=", "train", ")", "\n", "outputs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "num_correct_top1", ",", "num_correct_top5", "=", "compute_accuracy", "(", "outputs", ",", "label", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "num_total", "=", "inputs", ".", "size", "(", "0", ")", "\n", "return", "num_correct_top1", ",", "num_correct_top5", ",", "num_total", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.training_step": [[901, 914], ["audio_systems.TransferViewMakerLibriSpeechSystem.get_losses_for_batch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "audio_systems.TransferViewMakerLibriSpeechSystem.get_accuracies_for_batch", "float", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ",", "train", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "num_correct_top1", ",", "num_correct_top5", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "batch", ",", "train", "=", "True", ")", "\n", "metrics", "=", "{", "\n", "'train_loss'", ":", "loss", ",", "\n", "'train_num_correct_top1'", ":", "num_correct_top1", ",", "\n", "'train_num_correct_top5'", ":", "num_correct_top5", ",", "\n", "'train_num_total'", ":", "num_total", ",", "\n", "'train_top1'", ":", "num_correct_top1", "/", "float", "(", "num_total", ")", ",", "\n", "'train_top5'", ":", "num_correct_top5", "/", "float", "(", "num_total", ")", ",", "\n", "}", "\n", "", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.validation_step": [[915, 925], ["audio_systems.TransferViewMakerLibriSpeechSystem.get_losses_for_batch", "audio_systems.TransferViewMakerLibriSpeechSystem.get_accuracies_for_batch", "collections.OrderedDict", "float", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ",", "train", "=", "False", ")", "\n", "num_correct_top1", ",", "num_correct_top5", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "batch", ",", "train", "=", "False", ")", "\n", "return", "OrderedDict", "(", "{", "\n", "'val_loss'", ":", "loss", ",", "\n", "'val_num_correct_top1'", ":", "num_correct_top1", ",", "\n", "'val_num_correct_top5'", ":", "num_correct_top5", ",", "\n", "'val_num_total'", ":", "num_total", ",", "\n", "'val_top1'", ":", "num_correct_top1", "/", "float", "(", "num_total", ")", ",", "\n", "'val_top5'", ":", "num_correct_top5", "/", "float", "(", "num_total", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerLibriSpeechSystem.validation_epoch_end": [[927, 940], ["outputs[].keys", "sum", "sum", "sum", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "float", "float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "tensor", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "", "num_correct_top1", "=", "sum", "(", "[", "out", "[", "'val_num_correct_top1'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "num_correct_top5", "=", "sum", "(", "[", "out", "[", "'val_num_correct_top5'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "num_total", "=", "sum", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "val_top1", "=", "num_correct_top1", "/", "float", "(", "num_total", ")", "\n", "val_top5", "=", "num_correct_top5", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_top1'", "]", "=", "val_top1", "\n", "metrics", "[", "'val_top5'", "]", "=", "val_top5", "\n", "return", "{", "'val_loss'", ":", "metrics", "[", "'val_loss'", "]", ",", "'log'", ":", "metrics", ",", "\n", "'val_top1'", ":", "val_top1", ",", "'val_top5'", ":", "val_top5", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerVoxCeleb1System.create_datasets": [[944, 958], ["src.datasets.voxceleb1.VoxCeleb1", "src.datasets.voxceleb1.VoxCeleb1"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "VoxCeleb1", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "VoxCeleb1", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerAudioMNISTSystem.create_datasets": [[962, 976], ["src.datasets.audio_mnist.AudioMNIST", "src.datasets.audio_mnist.AudioMNIST"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "AudioMNIST", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "AudioMNIST", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerGoogleSpeechCommandsSystem.create_datasets": [[980, 994], ["src.datasets.google_speech.GoogleSpeechCommands", "src.datasets.google_speech.GoogleSpeechCommands"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "GoogleSpeechCommands", "(", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "GoogleSpeechCommands", "(", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.audio_systems.TransferViewMakerFluentSpeechCommandsSystem.create_datasets": [[998, 1014], ["src.datasets.fluent_speech.FluentSpeechCommands", "src.datasets.fluent_speech.FluentSpeechCommands"], "methods", ["None"], ["    ", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "FluentSpeechCommands", "(", "\n", "self", ".", "config", ".", "data_params", ".", "caller_intent", ",", "\n", "train", "=", "True", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "val_dataset", "=", "FluentSpeechCommands", "(", "\n", "self", ".", "config", ".", "data_params", ".", "caller_intent", ",", "\n", "train", "=", "False", ",", "\n", "spectral_transforms", "=", "False", ",", "\n", "wavform_transforms", "=", "False", ",", "\n", "input_size", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "input_size", ",", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.__init__": [[40, 49], ["pytorch_lightning.LightningModule.__init__", "sensor_systems.PretrainExpertInstDiscSystem.create_datasets", "sensor_systems.PretrainExpertInstDiscSystem.create_encoder", "src.objectives.memory_bank.MemoryBank", "src.objectives.memory_bank.MemoryBank", "len", "len"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.create_encoder"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "self", ".", "create_datasets", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "create_encoder", "(", ")", "\n", "self", ".", "memory_bank", "=", "MemoryBank", "(", "len", "(", "self", ".", "train_dataset", ")", ",", "\n", "self", ".", "config", ".", "model_params", ".", "out_dim", ")", "\n", "self", ".", "memory_bank_labels", "=", "MemoryBank", "(", "len", "(", "self", ".", "train_dataset", ")", ",", "1", ",", "dtype", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.create_datasets": [[50, 69], ["print", "src.datasets.pamap2.PAMAP2", "print", "src.datasets.pamap2.PAMAP2", "print"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Initializing validation dataset.'", ")", "\n", "# We use a larger default value of 50k examples for validation to reduce variance.", "\n", "val_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "'val'", ",", "\n", "examples_per_epoch", "=", "self", ".", "config", ".", "data_params", ".", "val_examples_per_epoch", "or", "50000", "\n", ")", "\n", "\n", "if", "not", "self", ".", "config", ".", "quick", ":", "\n", "            ", "print", "(", "'Initializing train dataset.'", ")", "\n", "train_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "'train'", ",", "\n", "examples_per_epoch", "=", "self", ".", "config", ".", "data_params", ".", "train_examples_per_epoch", "or", "10000", "\n", ")", "\n", "if", "not", "self", ".", "config", ".", "data_params", ".", "train_examples_per_epoch", ":", "\n", "                ", "print", "(", "'WARNING: self.config.data_params.train_examples_per_epoch not specified. Using default value of 10k'", ")", "\n", "", "", "else", ":", "\n", "            ", "train_dataset", "=", "val_dataset", "\n", "", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.create_encoder": [[70, 97], ["src.models.resnet_small.ResNet18", "getattr", "getattr.", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "getattr.linear.weight.size", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet18"], ["", "def", "create_encoder", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "encoder_model", "=", "resnet_small", ".", "ResNet18", "(", "\n", "self", ".", "config", ".", "model_params", ".", "out_dim", ",", "\n", "num_channels", "=", "52", ",", "# 52 feature spectrograms", "\n", "input_size", "=", "32", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "resnet_class", "=", "getattr", "(", "\n", "torchvision", ".", "models", ",", "\n", "self", ".", "config", ".", "model_params", ".", "resnet_version", ",", "\n", ")", "\n", "encoder_model", "=", "resnet_class", "(", "\n", "pretrained", "=", "False", ",", "\n", "num_classes", "=", "self", ".", "config", ".", "model_params", ".", "out_dim", ",", "\n", ")", "\n", "encoder_model", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "\n", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "model_params", ".", "projection_head", ":", "\n", "            ", "mlp_dim", "=", "encoder_model", ".", "linear", ".", "weight", ".", "size", "(", "1", ")", "\n", "encoder_model", ".", "linear", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "mlp_dim", ",", "mlp_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "encoder_model", ".", "linear", ",", "\n", ")", "\n", "", "return", "encoder_model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.configure_optimizers": [[98, 104], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "sensor_systems.PretrainExpertInstDiscSystem.model.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "optim", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ")", "\n", "return", "[", "optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.forward": [[105, 107], ["sensor_systems.PretrainExpertInstDiscSystem.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_losses_for_batch": [[108, 122], ["sensor_systems.PretrainExpertInstDiscSystem.forward", "src.objectives.infonce.NoiseConstrastiveEstimation", "src.objectives.infonce.NoiseConstrastiveEstimation.get_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "src.objectives.infonce.NoiseConstrastiveEstimation.updated_new_data_memory", "sensor_systems.PretrainExpertInstDiscSystem.memory_bank.update"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.updated_new_data_memory", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "indices", ",", "inputs1", ",", "inputs2", ",", "_", "=", "batch", "\n", "outputs", "=", "self", ".", "forward", "(", "inputs1", ")", "\n", "loss_fn", "=", "NoiseConstrastiveEstimation", "(", "indices", ",", "outputs", ",", "self", ".", "memory_bank", ",", "\n", "k", "=", "self", ".", "config", ".", "loss_params", ".", "k", ",", "\n", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", ",", "\n", "m", "=", "self", ".", "config", ".", "loss_params", ".", "m", ")", "\n", "loss", "=", "loss_fn", ".", "get_loss", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_data_memory", "=", "loss_fn", ".", "updated_new_data_memory", "(", ")", "\n", "self", ".", "memory_bank", ".", "update", "(", "indices", ",", "new_data_memory", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.training_step": [[123, 127], ["sensor_systems.PretrainExpertInstDiscSystem.get_losses_for_batch"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ")", "\n", "metrics", "=", "{", "'loss'", ":", "loss", "}", "\n", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label": [[128, 144], ["sensor_systems.PretrainExpertInstDiscSystem.memory_bank.get_all_dot_products", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "neighbor_idxs.squeeze.squeeze.squeeze", "sensor_systems.PretrainExpertInstDiscSystem.memory_bank_labels.at_idxs().squeeze", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "embs.size", "sensor_systems.PretrainExpertInstDiscSystem.memory_bank_labels.at_idxs", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "sensor_systems.PretrainExpertInstDiscSystem.cpu", "labels.cpu"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.get_all_dot_products", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.memory_bank.MemoryBank.at_idxs"], ["", "def", "get_nearest_neighbor_label", "(", "self", ",", "embs", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: ONLY TO BE USED FOR VALIDATION.\n        \n        For each example in validation, find the nearest example in the \n        training dataset using the memory bank. Assume its label as\n        the predicted label.\n        \"\"\"", "\n", "all_dps", "=", "self", ".", "memory_bank", ".", "get_all_dot_products", "(", "embs", ")", "\n", "_", ",", "neighbor_idxs", "=", "torch", ".", "topk", "(", "all_dps", ",", "k", "=", "1", ",", "sorted", "=", "False", ",", "dim", "=", "1", ")", "\n", "neighbor_idxs", "=", "neighbor_idxs", ".", "squeeze", "(", "1", ")", "\n", "\n", "neighbor_labels", "=", "self", ".", "memory_bank_labels", ".", "at_idxs", "(", "neighbor_idxs", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "num_correct", "=", "torch", ".", "sum", "(", "neighbor_labels", ".", "cpu", "(", ")", "==", "labels", ".", "cpu", "(", ")", ")", ".", "item", "(", ")", "\n", "\n", "return", "num_correct", ",", "embs", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.validation_step": [[145, 153], ["sensor_systems.PretrainExpertInstDiscSystem.model", "sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "collections.OrderedDict"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "_", ",", "inputs1", ",", "inputs2", ",", "labels", "=", "batch", "\n", "outputs", "=", "self", ".", "model", "(", "inputs1", ")", "\n", "num_correct", ",", "batch_size", "=", "self", ".", "get_nearest_neighbor_label", "(", "outputs", ",", "labels", ")", "\n", "num_correct", "=", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "batch_size", "=", "torch", ".", "tensor", "(", "batch_size", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "OrderedDict", "(", "{", "'val_num_correct'", ":", "num_correct", ",", "\n", "'val_num_total'", ":", "batch_size", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.validation_epoch_end": [[154, 164], ["outputs[].keys", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "float", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "", "num_correct", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "num_total", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", "}", "\n", "return", "{", "'log'", ":", "metrics", ",", "'val_acc'", ":", "val_acc", ",", "'progress_bar'", ":", "progress_bar", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.train_dataloader": [[165, 167], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "train_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.val_dataloader": [[168, 170], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "val_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertSimCLRSystem.create_datasets": [[175, 195], ["print", "src.datasets.pamap2.PAMAP2", "print", "src.datasets.pamap2.PAMAP2", "print"], "methods", ["None"], ["def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Initializing validation dataset.'", ")", "\n", "val_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "'val'", ",", "\n", "examples_per_epoch", "=", "self", ".", "config", ".", "data_params", ".", "val_examples_per_epoch", "or", "50000", ",", "\n", "sensor_transforms", "=", "None", ",", "\n", ")", "\n", "\n", "if", "not", "self", ".", "config", ".", "quick", ":", "\n", "            ", "print", "(", "'Initializing train dataset.'", ")", "\n", "train_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "'train'", ",", "\n", "examples_per_epoch", "=", "self", ".", "config", ".", "data_params", ".", "train_examples_per_epoch", "or", "10000", ",", "\n", "sensor_transforms", "=", "self", ".", "config", ".", "data_params", ".", "sensor_transforms", "\n", ")", "\n", "if", "not", "self", ".", "config", ".", "data_params", ".", "train_examples_per_epoch", ":", "\n", "                ", "print", "(", "'WARNING: self.config.data_params.train_examples_per_epoch not specified. Using default value of 10k'", ")", "\n", "", "", "else", ":", "\n", "            ", "train_dataset", "=", "val_dataset", "\n", "", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertSimCLRSystem.get_losses_for_batch": [[196, 211], ["sensor_systems.PretrainExpertSimCLRSystem.forward", "sensor_systems.PretrainExpertSimCLRSystem.forward", "src.objectives.simclr.SimCLRObjective", "src.objectives.simclr.SimCLRObjective.get_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sensor_systems.PretrainExpertSimCLRSystem.memory_bank.update", "sensor_systems.PretrainExpertSimCLRSystem.memory_bank_labels.update", "labels.unsqueeze", "src.utils.utils.l2_normalize", "src.utils.utils.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward", "home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "indices", ",", "inputs1", ",", "inputs2", ",", "labels", "=", "batch", "\n", "outputs1", "=", "self", ".", "forward", "(", "inputs1", ")", "\n", "outputs2", "=", "self", ".", "forward", "(", "inputs2", ")", "\n", "loss_fn", "=", "SimCLRObjective", "(", "outputs1", ",", "outputs2", ",", "\n", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", ")", "\n", "loss", "=", "loss_fn", ".", "get_loss", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "# for nearest neighbor", "\n", "            ", "new_data_memory", "=", "(", "l2_normalize", "(", "outputs1", ",", "dim", "=", "1", ")", "+", "\n", "l2_normalize", "(", "outputs2", ",", "dim", "=", "1", ")", ")", "/", "2.", "\n", "self", ".", "memory_bank", ".", "update", "(", "indices", ",", "new_data_memory", ")", "\n", "self", ".", "memory_bank_labels", ".", "update", "(", "indices", ",", "labels", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.__init__": [[218, 221], ["sensor_systems.PretrainExpertInstDiscSystem.__init__", "sensor_systems.PretrainViewMakerSystem.create_viewmaker"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.create_viewmaker"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "view", "=", "self", ".", "create_viewmaker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.create_datasets": [[222, 241], ["print", "src.datasets.pamap2.PAMAP2", "print", "src.datasets.pamap2.PAMAP2", "print"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Initializing validation dataset.'", ")", "\n", "val_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "'val'", ",", "\n", "examples_per_epoch", "=", "self", ".", "config", ".", "data_params", ".", "val_examples_per_epoch", "or", "50000", "\n", ")", "\n", "\n", "if", "self", ".", "config", ".", "quick", ":", "\n", "            ", "train_dataset", "=", "val_dataset", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Initializing train dataset.'", ")", "\n", "train_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "'train'", ",", "\n", "examples_per_epoch", "=", "self", ".", "config", ".", "data_params", ".", "train_examples_per_epoch", "or", "10000", "\n", ")", "\n", "if", "not", "self", ".", "config", ".", "data_params", ".", "train_examples_per_epoch", ":", "\n", "                ", "print", "(", "\n", "'WARNING: self.config.data_params.train_examples_per_epoch not specified. Using default value of 10k'", ")", "\n", "", "", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.create_viewmaker": [[242, 249], ["src.models.viewmaker.Viewmaker"], "methods", ["None"], ["", "def", "create_viewmaker", "(", "self", ")", ":", "\n", "        ", "view_model", "=", "viewmaker", ".", "Viewmaker", "(", "\n", "num_channels", "=", "52", ",", "\n", "distortion_budget", "=", "self", ".", "config", ".", "model_params", ".", "view_bound_magnitude", ",", "\n", "clamp", "=", "False", ",", "\n", ")", "\n", "return", "view_model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.configure_optimizers": [[250, 272], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "sensor_systems.PretrainViewMakerSystem.view.parameters", "sensor_systems.PretrainViewMakerSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "ValueError"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "encoder_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "view_optim_name", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_optim", "\n", "view_parameters", "=", "self", ".", "view", ".", "parameters", "(", ")", "\n", "if", "view_optim_name", "==", "'adam'", ":", "\n", "            ", "view_optim", "=", "torch", ".", "optim", ".", "Adam", "(", "view_parameters", ")", "\n", "", "elif", "not", "view_optim_name", "or", "view_optim_name", "==", "'sgd'", ":", "\n", "            ", "view_optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "view_parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "viewmaker_learning_rate", "or", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Optimizer {view_optim_name} not implemented'", ")", "\n", "\n", "", "return", "[", "encoder_optim", ",", "view_optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.forward": [[273, 298], ["sensor_systems.PretrainViewMakerSystem.view", "sensor_systems.PretrainViewMakerSystem.view", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "sensor_systems.PretrainViewMakerSystem.model", "sensor_systems.PretrainViewMakerSystem.model", "[].view().cpu().numpy", "wandb.log", "len", "[].view().cpu", "wandb.Image", "[].view", "torch.clamp.detach", "torch.clamp.detach", "torch.clamp.detach"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "indices", ",", "inputs", ",", "inputs2", ",", "labels", "=", "batch", "\n", "view1", "=", "self", ".", "view", "(", "inputs", ")", "\n", "view2", "=", "self", ".", "view", "(", "inputs2", ")", "\n", "\n", "if", "self", ".", "config", ".", "model_params", ".", "view_clip", ":", "\n", "            ", "num_std", "=", "self", ".", "config", ".", "model_params", ".", "view_clip_num_std", "\n", "tot_std", "=", "num_std", "*", "self", ".", "train_dataset", ".", "normalize_stdev", "\n", "view_min", "=", "self", ".", "train_dataset", ".", "normalize_mean", "-", "tot_std", "\n", "view_max", "=", "self", ".", "train_dataset", ".", "normalize_mean", "+", "tot_std", "\n", "view1", "=", "torch", ".", "clamp", "(", "view1", ",", "view_min", ",", "view_max", ")", "\n", "view2", "=", "torch", ".", "clamp", "(", "view2", ",", "view_min", ",", "view_max", ")", "\n", "\n", "", "emb_dict", "=", "{", "\n", "'indices'", ":", "indices", ",", "\n", "'view1_embs'", ":", "self", ".", "model", "(", "view1", ")", ",", "\n", "'view2_embs'", ":", "self", ".", "model", "(", "view2", ")", ",", "\n", "'labels'", ":", "labels", ",", "\n", "}", "\n", "\n", "if", "self", ".", "global_step", "%", "(", "len", "(", "self", ".", "train_dataset", ")", "//", "self", ".", "batch_size", ")", "==", "0", ":", "\n", "            ", "views_to_log", "=", "view1", ".", "detach", "(", ")", "[", "0", "]", ".", "view", "(", "-", "1", ",", "32", ",", "32", ",", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "wandb", ".", "log", "(", "{", "\"examples\"", ":", "[", "wandb", ".", "Image", "(", "view", ",", "caption", "=", "f\"Epoch: {self.current_epoch}, Step {self.global_step}\"", ")", "for", "view", "in", "views_to_log", "]", "}", ")", "\n", "\n", "", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.get_losses_for_batch": [[299, 314], ["src.objectives.adversarial.AdversarialSimCLRLoss", "src.objectives.adversarial.AdversarialSimCLRLoss.get_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "src.utils.utils.l2_normalize", "sensor_systems.PretrainViewMakerSystem.memory_bank.update", "sensor_systems.PretrainViewMakerSystem.memory_bank_labels.update", "emb_dict[].detach", "emb_dict[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.objectives.adversarial.AdversarialNCELoss.get_loss", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.l2_normalize", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.AverageMeter.update"], ["", "def", "get_losses_for_batch", "(", "self", ",", "emb_dict", ")", ":", "\n", "        ", "loss_function", "=", "AdversarialSimCLRLoss", "(", "\n", "embs1", "=", "emb_dict", "[", "'view1_embs'", "]", ",", "\n", "embs2", "=", "emb_dict", "[", "'view2_embs'", "]", ",", "\n", "t", "=", "self", ".", "config", ".", "loss_params", ".", "t", ",", "\n", "view_maker_loss_weight", "=", "self", ".", "config", ".", "loss_params", ".", "view_maker_loss_weight", "\n", ")", "\n", "encoder_loss", ",", "view_maker_loss", "=", "loss_function", ".", "get_loss", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_data_memory", "=", "l2_normalize", "(", "emb_dict", "[", "'view1_embs'", "]", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "self", ".", "memory_bank", ".", "update", "(", "emb_dict", "[", "'indices'", "]", ",", "new_data_memory", ")", "\n", "self", ".", "memory_bank_labels", ".", "update", "(", "emb_dict", "[", "'indices'", "]", ",", "emb_dict", "[", "'labels'", "]", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "", "return", "encoder_loss", ",", "view_maker_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.get_view_bound_magnitude": [[315, 317], ["None"], "methods", ["None"], ["", "def", "get_view_bound_magnitude", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "config", ".", "model_params", ".", "view_bound_magnitude", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.training_step": [[318, 322], ["sensor_systems.PretrainViewMakerSystem.forward", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ",", "optimizer_idx", ")", ":", "\n", "        ", "emb_dict", "=", "self", ".", "forward", "(", "batch", ")", "\n", "emb_dict", "[", "'optimizer_idx'", "]", "=", "torch", ".", "tensor", "(", "optimizer_idx", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "emb_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.training_step_end": [[323, 343], ["sensor_systems.PretrainViewMakerSystem.get_losses_for_batch", "sensor_systems.PretrainViewMakerSystem.get_view_bound_magnitude", "emb_dict[].dim"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.get_view_bound_magnitude"], ["", "def", "training_step_end", "(", "self", ",", "emb_dict", ")", ":", "\n", "        ", "encoder_loss", ",", "view_maker_loss", "=", "self", ".", "get_losses_for_batch", "(", "emb_dict", ")", "\n", "\n", "# Handle Tensor (dp) and int (ddp) cases", "\n", "if", "emb_dict", "[", "'optimizer_idx'", "]", ".", "__class__", "==", "int", "or", "emb_dict", "[", "'optimizer_idx'", "]", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "optimizer_idx", "=", "emb_dict", "[", "'optimizer_idx'", "]", "\n", "", "else", ":", "\n", "            ", "optimizer_idx", "=", "emb_dict", "[", "'optimizer_idx'", "]", "[", "0", "]", "\n", "\n", "", "if", "optimizer_idx", "==", "0", ":", "\n", "            ", "metrics", "=", "{", "\n", "'encoder_loss'", ":", "encoder_loss", ",", "\n", "}", "\n", "return", "{", "'loss'", ":", "encoder_loss", ",", "'log'", ":", "metrics", "}", "\n", "", "else", ":", "\n", "# update the bound allowed for view", "\n", "            ", "self", ".", "view", ".", "bound_magnitude", "=", "self", ".", "get_view_bound_magnitude", "(", ")", "\n", "\n", "metrics", "=", "{", "'view_maker_loss'", ":", "view_maker_loss", "}", "\n", "return", "{", "'loss'", ":", "view_maker_loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.validation_step": [[344, 353], ["sensor_systems.PretrainViewMakerSystem.model", "sensor_systems.PretrainViewMakerSystem.get_nearest_neighbor_label", "collections.OrderedDict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainExpertInstDiscSystem.get_nearest_neighbor_label"], ["", "", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "_", ",", "inputs1", ",", "inputs2", ",", "labels", "=", "batch", "\n", "outputs", "=", "self", ".", "model", "(", "inputs1", ")", "\n", "num_correct", ",", "batch_size", "=", "self", ".", "get_nearest_neighbor_label", "(", "outputs", ",", "labels", ")", "\n", "output", "=", "OrderedDict", "(", "{", "\n", "'val_num_correct'", ":", "torch", ".", "tensor", "(", "num_correct", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "'val_num_total'", ":", "torch", ".", "tensor", "(", "batch_size", ",", "dtype", "=", "float", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "}", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.PretrainViewMakerSystem.validation_epoch_end": [[354, 364], ["outputs[].keys", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "float", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "elem", "[", "key", "]", "for", "elem", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "", "num_correct", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "num_total", "=", "torch", ".", "stack", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", "}", "\n", "return", "{", "'log'", ":", "metrics", ",", "'val_acc'", ":", "val_acc", ",", "'progress_bar'", ":", "progress_bar", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.__init__": [[369, 405], ["pytorch_lightning.LightningModule.__init__", "sensor_systems.TransferViewMakerSystem.load_pretrained_model", "src.utils.utils.frozen_params", "sensor_systems.TransferViewMakerSystem.create_datasets", "sensor_systems.TransferViewMakerSystem.create_model", "torch.Sequential", "torch.Sequential", "torch.Sequential", "sensor_systems.TransferViewMakerSystem.encoder.eval", "src.utils.utils.frozen_params", "Exception", "list", "sensor_systems.TransferViewMakerSystem.encoder.children"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.load_pretrained_model", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_model", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "\n", "self", ".", "encoder", ",", "self", ".", "viewmaker", ",", "self", ".", "system", ",", "self", ".", "pretrain_config", "=", "self", ".", "load_pretrained_model", "(", ")", "\n", "resnet", "=", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_version", "\n", "if", "resnet", "==", "'resnet18'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "                    ", "num_features", "=", "512", "*", "4", "*", "4", "\n", "", "else", ":", "\n", "                    ", "num_features", "=", "512", "*", "2", "*", "2", "\n", "", "", "else", ":", "\n", "                ", "num_features", "=", "512", "\n", "", "", "elif", "resnet", "==", "'resnet50'", ":", "\n", "            ", "num_features", "=", "2048", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'resnet {resnet} not supported.'", ")", "\n", "\n", "", "if", "not", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "cut_ix", "=", "-", "2", "\n", "", "else", ":", "\n", "                ", "cut_ix", "=", "-", "1", "\n", "", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "encoder", ".", "children", "(", ")", ")", "[", ":", "cut_ix", "]", ")", "\n", "\n", "", "if", "not", "self", ".", "config", ".", "optim_params", ".", "supervised", ":", "\n", "            ", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "frozen_params", "(", "self", ".", "encoder", ")", "\n", "\n", "", "frozen_params", "(", "self", ".", "viewmaker", ")", "\n", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "self", ".", "create_datasets", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.load_pretrained_model": [[406, 435], ["os.path.join", "src.utils.utils.load_json", "dotmap.DotMap", "SystemClass", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "SystemClass.view.eval", "SystemClass.view.eval.parameters", "globals", "SystemClass.load_state_dict", "SystemClass.model.eval", "SystemClass.model.eval.parameters"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json"], ["", "def", "load_pretrained_model", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "self", ".", "config", ".", "pretrain_model", ".", "exp_dir", "\n", "checkpoint_name", "=", "self", ".", "config", ".", "pretrain_model", ".", "checkpoint_name", "\n", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'config.json'", ")", "\n", "config_json", "=", "load_json", "(", "config_path", ")", "\n", "config", "=", "DotMap", "(", "config_json", ")", "\n", "\n", "SystemClass", "=", "globals", "(", ")", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'checkpoints'", ",", "checkpoint_name", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ",", "map_location", "=", "self", ".", "device", ")", "\n", "\n", "# If supervised, train from scratch. ", "\n", "if", "not", "self", ".", "config", ".", "optim_params", ".", "supervised", ":", "\n", "            ", "system", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "\n", "", "viewmaker", "=", "system", ".", "view", ".", "eval", "(", ")", "\n", "encoder", "=", "system", ".", "model", "\n", "\n", "if", "not", "self", ".", "config", ".", "optim_params", ".", "supervised", ":", "\n", "            ", "encoder", "=", "system", ".", "model", ".", "eval", "(", ")", "\n", "for", "param", "in", "encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "for", "param", "in", "viewmaker", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "return", "encoder", ",", "viewmaker", ",", "system", ",", "system", ".", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.create_datasets": [[436, 452], ["print", "src.datasets.pamap2.PAMAP2", "print", "src.datasets.pamap2.PAMAP2"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Initializing train dataset.'", ")", "\n", "if", "self", ".", "config", ".", "data_params", ".", "train_small", ":", "\n", "            ", "train_mode", "=", "'train_small'", "\n", "", "else", ":", "\n", "            ", "train_mode", "=", "'train'", "\n", "", "train_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "train_mode", ",", "\n", "examples_per_epoch", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "train_examples_per_epoch", "or", "10000", "\n", ")", "\n", "print", "(", "'Initializing validation dataset.'", ")", "\n", "val_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "'val'", ",", "\n", "examples_per_epoch", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "val_examples_per_epoch", "or", "50000", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.create_model": [[453, 457], ["src.models.transfer.LogisticRegression", "src.models.transfer.LogisticRegression.to"], "methods", ["None"], ["", "def", "create_model", "(", "self", ")", ":", "\n", "        ", "model", "=", "LogisticRegression", "(", "\n", "self", ".", "num_features", ",", "self", ".", "train_dataset", ".", "NUM_CLASSES", ")", "\n", "return", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.configure_optimizers": [[458, 473], ["sensor_systems.TransferViewMakerSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "list", "list", "sensor_systems.TransferViewMakerSystem.model.parameters", "sensor_systems.TransferViewMakerSystem.encoder.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "optim_params", ".", "supervised", ":", "\n", "            ", "parameters", "=", "list", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "encoder", ".", "parameters", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "parameters", "=", "self", ".", "model", ".", "parameters", "(", ")", "\n", "", "if", "self", ".", "config", ".", "optim_params", "==", "'adam'", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ")", "\n", "", "else", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "return", "[", "optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.forward": [[474, 484], ["sensor_systems.TransferViewMakerSystem.size", "sensor_systems.TransferViewMakerSystem.view", "sensor_systems.TransferViewMakerSystem.model", "sensor_systems.TransferViewMakerSystem.viewmaker", "sensor_systems.TransferViewMakerSystem.encoder", "sensor_systems.TransferViewMakerSystem.encoder"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "train", "=", "True", ")", ":", "\n", "        ", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "if", "train", ":", "\n", "            ", "inputs", "=", "self", ".", "viewmaker", "(", "inputs", ")", "\n", "", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "embs", "=", "self", ".", "encoder", "(", "inputs", ",", "layer", "=", "6", ")", "\n", "", "else", ":", "\n", "            ", "embs", "=", "self", ".", "encoder", "(", "inputs", ")", "\n", "", "embs", "=", "embs", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "return", "self", ".", "model", "(", "embs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.get_losses_for_batch": [[485, 489], ["sensor_systems.TransferViewMakerSystem.forward", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ",", "train", "=", "True", ")", ":", "\n", "        ", "_", ",", "inputs1", ",", "inputs2", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "inputs1", ",", "train", "=", "train", ")", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.get_accuracies_for_batch": [[490, 498], ["sensor_systems.TransferViewMakerSystem.forward", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "preds.long().cpu.long().cpu.long().cpu", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "inputs.size", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "preds.long().cpu.long().cpu.long", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "label.long().cpu", "label.long"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "get_accuracies_for_batch", "(", "self", ",", "batch", ",", "train", "=", "True", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "inputs2", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "inputs", ",", "train", "=", "train", ")", "\n", "preds", "=", "torch", ".", "argmax", "(", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", "\n", "preds", "=", "preds", ".", "long", "(", ")", ".", "cpu", "(", ")", "\n", "num_correct", "=", "torch", ".", "sum", "(", "preds", "==", "label", ".", "long", "(", ")", ".", "cpu", "(", ")", ")", ".", "item", "(", ")", "\n", "num_total", "=", "inputs", ".", "size", "(", "0", ")", "\n", "return", "num_correct", ",", "num_total", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.training_step": [[499, 511], ["sensor_systems.TransferViewMakerSystem.get_losses_for_batch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sensor_systems.TransferViewMakerSystem.get_accuracies_for_batch", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ",", "train", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "num_correct", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "\n", "batch", ",", "train", "=", "True", ")", "\n", "metrics", "=", "{", "\n", "'train_loss'", ":", "loss", ",", "\n", "'train_num_correct'", ":", "num_correct", ",", "\n", "'train_num_total'", ":", "num_total", ",", "\n", "'train_acc'", ":", "num_correct", "/", "float", "(", "num_total", ")", ",", "\n", "}", "\n", "", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.validation_step": [[512, 521], ["sensor_systems.TransferViewMakerSystem.get_losses_for_batch", "sensor_systems.TransferViewMakerSystem.get_accuracies_for_batch", "collections.OrderedDict", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ",", "train", "=", "False", ")", "\n", "num_correct", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "\n", "batch", ",", "train", "=", "False", ")", "\n", "return", "OrderedDict", "(", "{", "\n", "'val_loss'", ":", "loss", ",", "\n", "'val_num_correct'", ":", "num_correct", ",", "\n", "'val_num_total'", ":", "num_total", ",", "\n", "'val_acc'", ":", "num_correct", "/", "float", "(", "num_total", ")", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.validation_epoch_end": [[523, 534], ["outputs[].keys", "sum", "sum", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "tensor", "(", "[", "elem", "[", "key", "]", "\n", "for", "elem", "in", "outputs", "]", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "", "num_correct", "=", "sum", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "num_total", "=", "sum", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", "}", "\n", "return", "{", "'val_loss'", ":", "metrics", "[", "'val_loss'", "]", ",", "'log'", ":", "metrics", ",", "'val_acc'", ":", "val_acc", ",", "'progress_bar'", ":", "progress_bar", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.train_dataloader": [[535, 537], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "train_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferViewMakerSystem.val_dataloader": [[538, 540], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "val_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.__init__": [[545, 575], ["pytorch_lightning.LightningModule.__init__", "sensor_systems.TransferExpertSystem.load_pretrained_model", "sensor_systems.TransferExpertSystem.create_datasets", "sensor_systems.TransferExpertSystem.create_model", "NotImplementedError", "sensor_systems.TransferExpertSystem.encoder.eval", "src.utils.utils.frozen_params", "Exception"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.load_pretrained_model", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_datasets", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_model", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.frozen_params"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "batch_size", "=", "config", ".", "optim_params", ".", "batch_size", "\n", "\n", "self", ".", "encoder", ",", "self", ".", "system", ",", "self", ".", "pretrain_config", "=", "self", ".", "load_pretrained_model", "(", ")", "\n", "resnet", "=", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_version", "\n", "if", "resnet", "==", "'resnet18'", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_params", ".", "use_prepool", ":", "\n", "                ", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "                    ", "num_features", "=", "512", "*", "4", "*", "4", "\n", "", "else", ":", "\n", "                    ", "num_features", "=", "512", "*", "2", "*", "2", "\n", "", "", "else", ":", "\n", "                ", "num_features", "=", "512", "\n", "", "", "elif", "resnet", "==", "'resnet50'", ":", "\n", "            ", "num_features", "=", "2048", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f'resnet {resnet} not supported.'", ")", "\n", "\n", "", "if", "not", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "config", ".", "optim_params", ".", "supervised", ":", "\n", "            ", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "frozen_params", "(", "self", ".", "encoder", ")", "\n", "\n", "", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "train_dataset", ",", "self", ".", "val_dataset", "=", "self", ".", "create_datasets", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "create_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_model": [[576, 580], ["src.models.transfer.LogisticRegression", "src.models.transfer.LogisticRegression.to"], "methods", ["None"], ["", "def", "create_model", "(", "self", ")", ":", "\n", "        ", "model", "=", "LogisticRegression", "(", "\n", "self", ".", "num_features", ",", "self", ".", "train_dataset", ".", "NUM_CLASSES", ")", "\n", "return", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.configure_optimizers": [[581, 596], ["sensor_systems.TransferExpertSystem.model.parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "list", "list", "sensor_systems.TransferExpertSystem.model.parameters", "sensor_systems.TransferExpertSystem.encoder.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "optim_params", ".", "supervised", ":", "\n", "            ", "parameters", "=", "list", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "encoder", ".", "parameters", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "parameters", "=", "self", ".", "model", ".", "parameters", "(", ")", "\n", "", "if", "self", ".", "config", ".", "optim_params", "==", "'adam'", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ")", "\n", "", "else", ":", "\n", "            ", "optim", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "momentum", "=", "self", ".", "config", ".", "optim_params", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "config", ".", "optim_params", ".", "weight_decay", ",", "\n", ")", "\n", "", "return", "[", "optim", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch": [[597, 601], ["sensor_systems.TransferExpertSystem.forward", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "get_losses_for_batch", "(", "self", ",", "batch", ",", "train", "=", "True", ")", ":", "\n", "        ", "_", ",", "inputs1", ",", "inputs2", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "inputs1", ",", "train", "=", "train", ")", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch": [[602, 610], ["sensor_systems.TransferExpertSystem.forward", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "preds.long().cpu.long().cpu.long().cpu", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "inputs.size", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "preds.long().cpu.long().cpu.long", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "label.long().cpu", "label.long"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward"], ["", "def", "get_accuracies_for_batch", "(", "self", ",", "batch", ",", "train", "=", "True", ")", ":", "\n", "        ", "_", ",", "inputs", ",", "inputs2", ",", "label", "=", "batch", "\n", "logits", "=", "self", ".", "forward", "(", "inputs", ",", "train", "=", "train", ")", "\n", "preds", "=", "torch", ".", "argmax", "(", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", "\n", "preds", "=", "preds", ".", "long", "(", ")", ".", "cpu", "(", ")", "\n", "num_correct", "=", "torch", ".", "sum", "(", "preds", "==", "label", ".", "long", "(", ")", ".", "cpu", "(", ")", ")", ".", "item", "(", ")", "\n", "num_total", "=", "inputs", ".", "size", "(", "0", ")", "\n", "return", "num_correct", ",", "num_total", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.training_step": [[611, 623], ["sensor_systems.TransferExpertSystem.get_losses_for_batch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sensor_systems.TransferExpertSystem.get_accuracies_for_batch", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ",", "train", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "num_correct", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "\n", "batch", ",", "train", "=", "True", ")", "\n", "metrics", "=", "{", "\n", "'train_loss'", ":", "loss", ",", "\n", "'train_num_correct'", ":", "num_correct", ",", "\n", "'train_num_total'", ":", "num_total", ",", "\n", "'train_acc'", ":", "num_correct", "/", "float", "(", "num_total", ")", ",", "\n", "}", "\n", "", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.validation_step": [[624, 633], ["sensor_systems.TransferExpertSystem.get_losses_for_batch", "sensor_systems.TransferExpertSystem.get_accuracies_for_batch", "collections.OrderedDict", "float"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_losses_for_batch", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.get_accuracies_for_batch"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_losses_for_batch", "(", "batch", ",", "train", "=", "False", ")", "\n", "num_correct", ",", "num_total", "=", "self", ".", "get_accuracies_for_batch", "(", "\n", "batch", ",", "train", "=", "False", ")", "\n", "return", "OrderedDict", "(", "{", "\n", "'val_loss'", ":", "loss", ",", "\n", "'val_num_correct'", ":", "num_correct", ",", "\n", "'val_num_total'", ":", "num_total", ",", "\n", "'val_acc'", ":", "num_correct", "/", "float", "(", "num_total", ")", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.validation_epoch_end": [[635, 646], ["outputs[].keys", "sum", "sum", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "torch.tensor().float().mean", "float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "for", "key", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "torch", ".", "tensor", "(", "[", "elem", "[", "key", "]", "\n", "for", "elem", "in", "outputs", "]", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "", "num_correct", "=", "sum", "(", "[", "out", "[", "'val_num_correct'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "num_total", "=", "sum", "(", "[", "out", "[", "'val_num_total'", "]", "for", "out", "in", "outputs", "]", ")", "\n", "val_acc", "=", "num_correct", "/", "float", "(", "num_total", ")", "\n", "metrics", "[", "'val_acc'", "]", "=", "val_acc", "\n", "progress_bar", "=", "{", "'acc'", ":", "val_acc", "}", "\n", "return", "{", "'val_loss'", ":", "metrics", "[", "'val_loss'", "]", ",", "'log'", ":", "metrics", ",", "'val_acc'", ":", "val_acc", ",", "'progress_bar'", ":", "progress_bar", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.create_datasets": [[647, 664], ["print", "src.datasets.pamap2.PAMAP2", "print", "src.datasets.pamap2.PAMAP2"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Initializing train dataset.'", ")", "\n", "if", "self", ".", "config", ".", "data_params", ".", "train_small", ":", "\n", "            ", "train_mode", "=", "'train_small'", "\n", "", "else", ":", "\n", "            ", "train_mode", "=", "'train'", "\n", "", "train_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "train_mode", ",", "\n", "examples_per_epoch", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "train_examples_per_epoch", "or", "10000", ",", "\n", "sensor_transforms", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "sensor_transforms", "\n", ")", "\n", "print", "(", "'Initializing validation dataset.'", ")", "\n", "val_dataset", "=", "PAMAP2", "(", "\n", "mode", "=", "'val'", ",", "\n", "examples_per_epoch", "=", "self", ".", "pretrain_config", ".", "data_params", ".", "val_examples_per_epoch", "or", "50000", "\n", ")", "\n", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.forward": [[665, 673], ["inputs.size", "sensor_systems.TransferExpertSystem.view", "sensor_systems.TransferExpertSystem.model", "sensor_systems.TransferExpertSystem.encoder", "sensor_systems.TransferExpertSystem.encoder"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "train", "=", "True", ")", ":", "\n", "        ", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "pretrain_config", ".", "model_params", ".", "resnet_small", ":", "\n", "            ", "embs", "=", "self", ".", "encoder", "(", "inputs", ",", "layer", "=", "6", ")", "\n", "", "else", ":", "\n", "            ", "embs", "=", "self", ".", "encoder", "(", "inputs", ")", "\n", "", "embs", "=", "embs", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "return", "self", ".", "model", "(", "embs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.load_pretrained_model": [[674, 697], ["os.path.join", "src.utils.utils.load_json", "dotmap.DotMap", "SystemClass", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "globals", "SystemClass.load_state_dict", "SystemClass.model.eval", "SystemClass.model.eval.parameters"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json"], ["", "def", "load_pretrained_model", "(", "self", ")", ":", "\n", "        ", "base_dir", "=", "self", ".", "config", ".", "pretrain_model", ".", "exp_dir", "\n", "checkpoint_name", "=", "self", ".", "config", ".", "pretrain_model", ".", "checkpoint_name", "\n", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'config.json'", ")", "\n", "config_json", "=", "load_json", "(", "config_path", ")", "\n", "config", "=", "DotMap", "(", "config_json", ")", "\n", "\n", "SystemClass", "=", "globals", "(", ")", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "\n", "base_dir", ",", "'checkpoints'", ",", "checkpoint_name", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ",", "map_location", "=", "self", ".", "device", ")", "\n", "if", "not", "self", ".", "config", ".", "optim_params", ".", "supervised", ":", "\n", "            ", "system", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "\n", "", "encoder", "=", "system", ".", "model", "\n", "if", "not", "self", ".", "config", ".", "optim_params", ".", "supervised", ":", "\n", "            ", "encoder", "=", "system", ".", "model", ".", "eval", "(", ")", "\n", "for", "param", "in", "encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "return", "encoder", ",", "system", ",", "system", ".", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.train_dataloader": [[698, 700], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "train_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.sensor_systems.TransferExpertSystem.val_dataloader": [[701, 703], ["src.systems.image_systems.create_dataloader"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.create_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "create_dataloader", "(", "self", ".", "val_dataset", ",", "self", ".", "config", ",", "self", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.transfer.LogisticRegression.__init__": [[7, 12], ["torch.Module.__init__", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_outputs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_inputs", "=", "num_inputs", "\n", "self", ".", "num_outputs", "=", "num_outputs", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "num_inputs", ",", "num_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.transfer.LogisticRegression.forward": [[13, 15], ["transfer.LogisticRegression.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "linear", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.Normalize.__init__": [[29, 32], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "power", "=", "2", ")", ":", "\n", "        ", "super", "(", "Normalize", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "power", "=", "power", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.Normalize.forward": [[33, 37], ["x.pow().sum().pow", "x.div", "x.pow().sum", "x.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "norm", "=", "x", ".", "pow", "(", "self", ".", "power", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "pow", "(", "1.", "/", "self", ".", "power", ")", "\n", "out", "=", "x", ".", "div", "(", "norm", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.BasicBlock.__init__": [[42, 51], ["torch.Module.__init__", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.conv3x3", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.BasicBlock.forward": [[52, 69], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.Bottleneck.__init__": [[74, 86], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.Bottleneck.forward": [[87, 108], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.ResNet.__init__": [[112, 137], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "low_dim", "=", "128", ",", "in_channel", "=", "3", ",", "width", "=", "1", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channel", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "base", "=", "int", "(", "64", "*", "width", ")", "\n", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "self", ".", "base", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "self", ".", "base", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "self", ".", "base", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "self", ".", "base", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "base", "*", "8", "*", "block", ".", "expansion", ",", "low_dim", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.ResNet._make_layer": [[138, 154], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.ResNet.forward": [[155, 182], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.size"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer", "=", "7", ")", ":", "\n", "        ", "if", "layer", "<=", "0", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "if", "layer", "==", "1", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "if", "layer", "==", "2", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "if", "layer", "==", "3", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "if", "layer", "==", "4", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "if", "layer", "==", "5", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "if", "layer", "==", "6", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.conv3x3": [[21, 25], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.resnet18": [[184, 193], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.resnet34": [[195, 204], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.resnet50": [[206, 215], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.resnet101": [[217, 226], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet.resnet152": [[228, 237], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.mlp.MLP.__init__": [[6, 15], ["torch.Module.__init__", "torch.Sequential", "torch.Linear", "torch.BatchNorm1d", "torch.ReLU", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", "=", "2048", ",", "hidden_size", "=", "4096", ",", "output_dim", "=", "256", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "output_dim", ",", "bias", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.mlp.MLP.forward": [[16, 19], ["mlp.MLP.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.__init__": [[20, 69], ["super().__init__", "viewmaker.ConvLayer", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "viewmaker.ConvLayer", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "viewmaker.ConvLayer", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "viewmaker.ResidualBlock", "viewmaker.ResidualBlock", "viewmaker.ResidualBlock", "viewmaker.ResidualBlock", "viewmaker.ResidualBlock", "viewmaker.UpsampleConvLayer", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "viewmaker.UpsampleConvLayer", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "viewmaker.ConvLayer"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "num_channels", "=", "3", ",", "distortion_budget", "=", "0.05", ",", "activation", "=", "'relu'", ",", "\n", "clamp", "=", "True", ",", "frequency_domain", "=", "False", ",", "downsample_to", "=", "False", ",", "num_res_blocks", "=", "3", ")", ":", "\n", "        ", "'''Initialize the Viewmaker network.\n\n        Args:\n            num_channels: Number of channels in the input (e.g. 1 for speech, 3 for images)\n                Input will have shape [batch_size, num_channels, height, width]\n            distortion_budget: Distortion budget of the viewmaker (epsilon, in the paper).\n                Controls how strong the perturbations can be.\n            activation: The activation function used in the network ('relu' and 'leaky_relu' currently supported)\n            clamp: Whether to clamp the outputs to [0, 1] (useful to ensure output is, e.g., a valid image)\n            frequency_domain: Whether to apply perturbation (and distortion budget) in the frequency domain.\n                This is useful for shifting the inductive bias of the viewmaker towards more global / textural views.\n            downsample_to: Downsamples the image, applies viewmaker, then upsamples. Possibly useful for \n                higher-resolution inputs, but not evaluaed in the paper.\n            num_res_blocks: Number of residual blocks to use in the network.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_channels", "=", "num_channels", "\n", "self", ".", "num_res_blocks", "=", "num_res_blocks", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "clamp", "=", "clamp", "\n", "self", ".", "frequency_domain", "=", "frequency_domain", "\n", "self", ".", "downsample_to", "=", "downsample_to", "\n", "self", ".", "distortion_budget", "=", "distortion_budget", "\n", "self", ".", "act", "=", "ACTIVATIONS", "[", "activation", "]", "(", ")", "\n", "\n", "# Initial convolution layers (+ 1 for noise filter)", "\n", "self", ".", "conv1", "=", "ConvLayer", "(", "self", ".", "num_channels", "+", "1", ",", "32", ",", "kernel_size", "=", "9", ",", "stride", "=", "1", ")", "\n", "self", ".", "in1", "=", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "32", ",", "affine", "=", "True", ")", "\n", "self", ".", "conv2", "=", "ConvLayer", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "in2", "=", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "64", ",", "affine", "=", "True", ")", "\n", "self", ".", "conv3", "=", "ConvLayer", "(", "64", ",", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "in3", "=", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "128", ",", "affine", "=", "True", ")", "\n", "\n", "# Residual layers have +N for added random channels", "\n", "self", ".", "res1", "=", "ResidualBlock", "(", "128", "+", "1", ")", "\n", "self", ".", "res2", "=", "ResidualBlock", "(", "128", "+", "2", ")", "\n", "self", ".", "res3", "=", "ResidualBlock", "(", "128", "+", "3", ")", "\n", "self", ".", "res4", "=", "ResidualBlock", "(", "128", "+", "4", ")", "\n", "self", ".", "res5", "=", "ResidualBlock", "(", "128", "+", "5", ")", "\n", "\n", "# Upsampling Layers", "\n", "self", ".", "deconv1", "=", "UpsampleConvLayer", "(", "128", "+", "self", ".", "num_res_blocks", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "upsample", "=", "2", ")", "\n", "self", ".", "in4", "=", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "64", ",", "affine", "=", "True", ")", "\n", "self", ".", "deconv2", "=", "UpsampleConvLayer", "(", "64", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "upsample", "=", "2", ")", "\n", "self", ".", "in5", "=", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "32", ",", "affine", "=", "True", ")", "\n", "self", ".", "deconv3", "=", "ConvLayer", "(", "32", ",", "self", ".", "num_channels", ",", "kernel_size", "=", "9", ",", "stride", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.zero_init": [[70, 79], ["isinstance", "torch.nn.functional.normal_", "torch.nn.functional.normal_", "torch.nn.functional.constant_", "torch.nn.functional.constant_", "isinstance"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "zero_init", "(", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Conv2d", ")", ")", ":", "\n", "# actual 0 has symmetry problems", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "mean", "=", "0", ",", "std", "=", "1e-4", ")", "\n", "# init.constant_(m.weight.data, 0)", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm1d", ")", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.add_noise_channel": [[80, 88], ["x.size", "x.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.tensor.view", "torch.tensor.view"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view", "home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "", "def", "add_noise_channel", "(", "self", ",", "x", ",", "num", "=", "1", ",", "bound_multiplier", "=", "1", ")", ":", "\n", "# bound_multiplier is a scalar or a 1D tensor of length batch_size", "\n", "        ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "filter_size", "=", "x", ".", "size", "(", "-", "1", ")", "\n", "shp", "=", "(", "batch_size", ",", "num", ",", "filter_size", ",", "filter_size", ")", "\n", "bound_multiplier", "=", "torch", ".", "tensor", "(", "bound_multiplier", ",", "device", "=", "x", ".", "device", ")", "\n", "noise", "=", "torch", ".", "rand", "(", "shp", ",", "device", "=", "x", ".", "device", ")", "*", "bound_multiplier", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "x", ",", "noise", ")", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.basic_net": [[89, 111], ["viewmaker.Viewmaker.add_noise_channel", "viewmaker.Viewmaker.act", "viewmaker.Viewmaker.act", "viewmaker.Viewmaker.act", "res.clone().mean", "enumerate", "viewmaker.Viewmaker.act", "viewmaker.Viewmaker.act", "viewmaker.Viewmaker.deconv3", "list", "ValueError", "viewmaker.Viewmaker.in1", "viewmaker.Viewmaker.in2", "viewmaker.Viewmaker.in3", "viewmaker.Viewmaker.in4", "viewmaker.Viewmaker.in5", "range", "viewmaker.Viewmaker.conv1", "viewmaker.Viewmaker.conv2", "viewmaker.Viewmaker.conv3", "res.clone", "res", "viewmaker.Viewmaker.deconv1", "viewmaker.Viewmaker.deconv2", "viewmaker.Viewmaker.add_noise_channel", "list", "range"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.add_noise_channel", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.add_noise_channel"], ["", "def", "basic_net", "(", "self", ",", "y", ",", "num_res_blocks", "=", "5", ",", "bound_multiplier", "=", "1", ")", ":", "\n", "        ", "if", "num_res_blocks", "not", "in", "list", "(", "range", "(", "6", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'num_res_blocks must be in {list(range(6))}, got {num_res_blocks}.'", ")", "\n", "\n", "", "y", "=", "self", ".", "add_noise_channel", "(", "y", ",", "bound_multiplier", "=", "bound_multiplier", ")", "\n", "y", "=", "self", ".", "act", "(", "self", ".", "in1", "(", "self", ".", "conv1", "(", "y", ")", ")", ")", "\n", "y", "=", "self", ".", "act", "(", "self", ".", "in2", "(", "self", ".", "conv2", "(", "y", ")", ")", ")", "\n", "y", "=", "self", ".", "act", "(", "self", ".", "in3", "(", "self", ".", "conv3", "(", "y", ")", ")", ")", "\n", "\n", "# Features that could be useful for other auxilary layers / losses.", "\n", "# [batch_size, 128]", "\n", "features", "=", "y", ".", "clone", "(", ")", ".", "mean", "(", "[", "-", "1", ",", "-", "2", "]", ")", "\n", "\n", "for", "i", ",", "res", "in", "enumerate", "(", "[", "self", ".", "res1", ",", "self", ".", "res2", ",", "self", ".", "res3", ",", "self", ".", "res4", ",", "self", ".", "res5", "]", ")", ":", "\n", "            ", "if", "i", "<", "num_res_blocks", ":", "\n", "                ", "y", "=", "res", "(", "self", ".", "add_noise_channel", "(", "y", ",", "bound_multiplier", "=", "bound_multiplier", ")", ")", "\n", "\n", "", "", "y", "=", "self", ".", "act", "(", "self", ".", "in4", "(", "self", ".", "deconv1", "(", "y", ")", ")", ")", "\n", "y", "=", "self", ".", "act", "(", "self", ".", "in5", "(", "self", ".", "deconv2", "(", "y", ")", ")", ")", "\n", "y", "=", "self", ".", "deconv3", "(", "y", ")", "\n", "\n", "return", "y", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.get_delta": [[112, 120], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh.abs().mean", "torch.tanh.abs().mean", "torch.tanh.abs", "torch.tanh.abs"], "methods", ["None"], ["", "def", "get_delta", "(", "self", ",", "y_pixels", ",", "eps", "=", "1e-4", ")", ":", "\n", "        ", "'''Constrains the input perturbation by projecting it onto an L1 sphere'''", "\n", "distortion_budget", "=", "self", ".", "distortion_budget", "\n", "delta", "=", "torch", ".", "tanh", "(", "y_pixels", ")", "# Project to [-1, 1]", "\n", "avg_magnitude", "=", "delta", ".", "abs", "(", ")", ".", "mean", "(", "[", "1", ",", "2", ",", "3", "]", ",", "keepdim", "=", "True", ")", "\n", "max_magnitude", "=", "distortion_budget", "\n", "delta", "=", "delta", "*", "max_magnitude", "/", "(", "avg_magnitude", "+", "eps", ")", "\n", "return", "delta", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.forward": [[121, 151], ["viewmaker.Viewmaker.basic_net", "viewmaker.Viewmaker.get_delta", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch_dct.dct_2d", "torch_dct.idct_2d", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.basic_net", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.Viewmaker.get_delta"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "downsample_to", ":", "\n", "# Downsample.", "\n", "            ", "x_orig", "=", "x", "\n", "x", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "x", ",", "size", "=", "(", "self", ".", "downsample_to", ",", "self", ".", "downsample_to", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "", "y", "=", "x", "\n", "\n", "if", "self", ".", "frequency_domain", ":", "\n", "# Input to viewmaker is in frequency domain, outputs frequency domain perturbation.", "\n", "# Uses the Discrete Cosine Transform.", "\n", "# shape still [batch_size, C, W, H]", "\n", "            ", "y", "=", "dct", ".", "dct_2d", "(", "y", ")", "\n", "\n", "", "y_pixels", ",", "features", "=", "self", ".", "basic_net", "(", "y", ",", "self", ".", "num_res_blocks", ",", "bound_multiplier", "=", "1", ")", "\n", "delta", "=", "self", ".", "get_delta", "(", "y_pixels", ")", "\n", "if", "self", ".", "frequency_domain", ":", "\n", "# Compute inverse DCT from frequency domain to time domain.", "\n", "            ", "delta", "=", "dct", ".", "idct_2d", "(", "delta", ")", "\n", "", "if", "self", ".", "downsample_to", ":", "\n", "# Upsample.", "\n", "            ", "x", "=", "x_orig", "\n", "delta", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "delta", ",", "size", "=", "x_orig", ".", "shape", "[", "-", "2", ":", "]", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "# Additive perturbation", "\n", "", "result", "=", "x", "+", "delta", "\n", "if", "self", ".", "clamp", ":", "\n", "            ", "result", "=", "torch", ".", "clamp", "(", "result", ",", "0", ",", "1.0", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.ConvLayer.__init__": [[156, 162], ["super().__init__", "torch.nn.ReflectionPad2d", "torch.nn.ReflectionPad2d", "torch.nn.ReflectionPad2d", "torch.nn.ReflectionPad2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ")", ":", "\n", "        ", "super", "(", "ConvLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "reflection_padding", "=", "kernel_size", "//", "2", "\n", "self", ".", "reflection_pad", "=", "torch", ".", "nn", ".", "ReflectionPad2d", "(", "reflection_padding", ")", "\n", "self", ".", "conv2d", "=", "torch", ".", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.ConvLayer.forward": [[163, 167], ["viewmaker.ConvLayer.reflection_pad", "viewmaker.ConvLayer.conv2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "reflection_pad", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2d", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.ResidualBlock.__init__": [[175, 182], ["super().__init__", "viewmaker.ConvLayer", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "viewmaker.ConvLayer", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "channels", ",", "activation", "=", "'relu'", ")", ":", "\n", "        ", "super", "(", "ResidualBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "ConvLayer", "(", "channels", ",", "channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "self", ".", "in1", "=", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "channels", ",", "affine", "=", "True", ")", "\n", "self", ".", "conv2", "=", "ConvLayer", "(", "channels", ",", "channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "self", ".", "in2", "=", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "channels", ",", "affine", "=", "True", ")", "\n", "self", ".", "act", "=", "ACTIVATIONS", "[", "activation", "]", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.ResidualBlock.forward": [[183, 189], ["viewmaker.ResidualBlock.act", "viewmaker.ResidualBlock.in2", "viewmaker.ResidualBlock.in1", "viewmaker.ResidualBlock.conv2", "viewmaker.ResidualBlock.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "out", "=", "self", ".", "act", "(", "self", ".", "in1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "in2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "=", "out", "+", "residual", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.UpsampleConvLayer.__init__": [[198, 205], ["super().__init__", "torch.nn.ReflectionPad2d", "torch.nn.ReflectionPad2d", "torch.nn.ReflectionPad2d", "torch.nn.ReflectionPad2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "upsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "UpsampleConvLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "upsample", "=", "upsample", "\n", "reflection_padding", "=", "kernel_size", "//", "2", "\n", "self", ".", "reflection_pad", "=", "torch", ".", "nn", ".", "ReflectionPad2d", "(", "reflection_padding", ")", "\n", "self", ".", "conv2d", "=", "torch", ".", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.viewmaker.UpsampleConvLayer.forward": [[206, 214], ["viewmaker.UpsampleConvLayer.reflection_pad", "viewmaker.UpsampleConvLayer.conv2d", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_in", "=", "x", "\n", "if", "self", ".", "upsample", ":", "\n", "            ", "x_in", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "x_in", ",", "mode", "=", "'nearest'", ",", "scale_factor", "=", "self", ".", "upsample", ")", "\n", "", "out", "=", "self", ".", "reflection_pad", "(", "x_in", ")", "\n", "out", "=", "self", ".", "conv2d", "(", "out", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.BasicBlock.__init__": [[11, 23], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.BasicBlock.forward": [[25, 31], ["torch.relu", "torch.relu", "torch.relu", "resnet_small.BasicBlock.bn2", "resnet_small.BasicBlock.shortcut", "torch.relu", "torch.relu", "torch.relu", "resnet_small.BasicBlock.bn1", "resnet_small.BasicBlock.conv2", "resnet_small.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.Bottleneck.__init__": [[36, 50], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.Bottleneck.forward": [[52, 59], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "resnet_small.Bottleneck.bn3", "resnet_small.Bottleneck.shortcut", "torch.relu", "torch.relu", "torch.relu", "resnet_small.Bottleneck.bn1", "resnet_small.Bottleneck.bn2", "resnet_small.Bottleneck.conv3", "resnet_small.Bottleneck.conv1", "resnet_small.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__": [[63, 77], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "resnet_small.ResNet._make_layer", "resnet_small.ResNet._make_layer", "resnet_small.ResNet._make_layer", "resnet_small.ResNet._make_layer", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.__init__", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer", "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "num_classes", "=", "10", ",", "num_channels", "=", "3", ",", "input_size", "=", "32", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "input_size", "in", "[", "32", ",", "64", "]", "\n", "self", ".", "in_planes", "=", "64", "\n", "self", ".", "num_channels", "=", "num_channels", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "num_channels", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "num_blocks", "[", "0", "]", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "num_blocks", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "num_blocks", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "num_blocks", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "fc_input_size", "=", "512", "*", "block", ".", "expansion", "*", "(", "4", "if", "input_size", "==", "64", "else", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "fc_input_size", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet._make_layer": [[78, 85], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "stride", "in", "strides", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "*", "block", ".", "expansion", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet.forward": [[86, 110], ["torch.relu", "torch.relu", "torch.relu", "resnet_small.ResNet.layer1", "resnet_small.ResNet.layer2", "resnet_small.ResNet.layer3", "resnet_small.ResNet.layer4", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "resnet_small.ResNet.view", "resnet_small.ResNet.fc", "resnet_small.ResNet.bn1", "resnet_small.ResNet.size", "resnet_small.ResNet.conv1"], "methods", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer", "=", "7", ")", ":", "\n", "        ", "if", "layer", "<=", "0", ":", "\n", "            ", "return", "x", "\n", "", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "if", "layer", "==", "1", ":", "\n", "            ", "return", "out", "\n", "", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "if", "layer", "==", "2", ":", "\n", "            ", "return", "out", "\n", "", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "if", "layer", "==", "3", ":", "\n", "            ", "return", "out", "\n", "", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "if", "layer", "==", "4", ":", "\n", "            ", "return", "out", "\n", "", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "if", "layer", "==", "5", ":", "\n", "            ", "return", "out", "\n", "", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "4", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "if", "layer", "==", "6", ":", "\n", "            ", "return", "out", "\n", "", "out", "=", "self", ".", "fc", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet18": [[112, 115], ["resnet_small.ResNet"], "function", ["None"], ["", "", "def", "ResNet18", "(", "num_classes", ",", "num_channels", "=", "3", ",", "input_size", "=", "32", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "num_classes", ",", "num_channels", "=", "num_channels", ",", "\n", "input_size", "=", "input_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet34": [[117, 119], ["resnet_small.ResNet"], "function", ["None"], ["", "def", "ResNet34", "(", "num_classes", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet50": [[121, 123], ["resnet_small.ResNet"], "function", ["None"], ["", "def", "ResNet50", "(", "num_classes", ")", ":", "\n", "    ", "return", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet101": [[125, 127], ["resnet_small.ResNet"], "function", ["None"], ["", "def", "ResNet101", "(", "num_classes", ")", ":", "\n", "    ", "return", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.models.resnet_small.ResNet152": [[129, 131], ["resnet_small.ResNet"], "function", ["None"], ["", "def", "ResNet152", "(", "num_classes", ")", ":", "\n", "    ", "return", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "num_classes", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.get_loader": [[37, 63], ["numpy.load", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "transforms_li.append", "torchvision.transforms.Compose", "torchvision.datasets.cifar.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "numpy.load", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["def", "get_loader", "(", "corruption", ",", "clean", ")", ":", "\n", "    ", "data", "=", "np", ".", "load", "(", "CIFAR_C_DIR", "+", "corruption", "+", "'.npy'", ")", "\n", "labels", "=", "torch", ".", "LongTensor", "(", "np", ".", "load", "(", "CIFAR_C_DIR", "+", "'labels.npy'", ")", ")", "\n", "transforms_li", "=", "[", "transforms", ".", "ToTensor", "(", ")", "]", "\n", "transforms_li", ".", "append", "(", "transforms", ".", "Normalize", "(", "[", "0.491", ",", "0.482", ",", "0.446", "]", ",", "[", "0.247", ",", "0.243", ",", "0.261", "]", ")", ")", "\n", "image_transforms", "=", "transforms", ".", "Compose", "(", "transforms_li", ")", "\n", "\n", "dataset", "=", "datasets", ".", "cifar", ".", "CIFAR10", "(", "\n", "CIFAR_DIR", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "image_transforms", ",", "\n", ")", "\n", "\n", "if", "not", "clean", ":", "\n", "# Overwrite with corruption", "\n", "        ", "dataset", ".", "data", "=", "data", "\n", "dataset", ".", "targets", "=", "labels", "\n", "\n", "", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "True", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.get_system": [[64, 72], ["src.utils.utils.load_json", "dotmap.DotMap", "src.systems.image_systems.TransferExpertSystem", "torch.load", "torch.load", "torch.load", "src.systems.image_systems.TransferExpertSystem.load_state_dict", "model_path.split"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.utils.load_json"], ["", "def", "get_system", "(", "model_path", ",", "device", ")", ":", "\n", "    ", "config_dir", "=", "'/'", ".", "join", "(", "model_path", ".", "split", "(", "'/'", ")", "[", ":", "-", "2", "]", ")", "# Remove \"checkpoints/epoch=X.ckpt\"", "\n", "config_json", "=", "load_json", "(", "config_dir", "+", "'/config.json'", ")", "\n", "config", "=", "DotMap", "(", "config_json", ")", "\n", "system", "=", "TransferExpertSystem", "(", "config", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "device", ")", "\n", "system", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "False", ")", "\n", "return", "system", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.predict": [[73, 77], ["images.size", "encoder().view", "model", "encoder"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.systems.image_systems.PretrainViewMakerSystem.view"], ["", "def", "predict", "(", "encoder", ",", "model", ",", "images", ")", ":", "\n", "    ", "batch_size", "=", "images", ".", "size", "(", "0", ")", "\n", "embs", "=", "encoder", "(", "images", ",", "layer", "=", "5", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "return", "model", "(", "embs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.test": [[78, 94], ["system.encoder.eval().to", "system.model.eval().to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "system.encoder.eval", "system.model.eval", "eval_cifar10_c.predict", "torch.cross_entropy", "float", "pred.eq().sum().item", "len", "len", "images.to", "targets.to", "predict.data.max", "pred.eq().sum", "pred.eq"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.predict"], ["", "def", "test", "(", "system", ",", "test_loader", ",", "device", ")", ":", "\n", "    ", "encoder", "=", "system", ".", "encoder", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "model", "=", "system", ".", "model", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "total_loss", "=", "0.", "\n", "total_correct", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "images", ",", "targets", "in", "test_loader", ":", "\n", "            ", "images", ",", "targets", "=", "images", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "logits", "=", "predict", "(", "encoder", ",", "model", ",", "images", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "targets", ")", "\n", "pred", "=", "logits", ".", "data", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "total_loss", "+=", "float", "(", "loss", ".", "data", ")", "\n", "total_correct", "+=", "pred", ".", "eq", "(", "targets", ".", "data", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "return", "total_loss", "/", "len", "(", "test_loader", ".", "dataset", ")", ",", "total_correct", "/", "len", "(", "\n", "test_loader", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.main": [[95, 110], ["print", "print", "eval_cifar10_c.get_loader", "torch.device", "torch.device", "torch.device", "eval_cifar10_c.get_system", "eval_cifar10_c.test", "corruption_accs.append", "print", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.get_loader", "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.get_system", "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.eval_cifar10_c.test"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "corruption_accs", "=", "[", "]", "\n", "for", "corruption", "in", "CORRUPTIONS", ":", "\n", "        ", "loader", "=", "get_loader", "(", "corruption", ",", "args", ".", "clean", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ",", "args", ".", "gpu", ")", "\n", "system", "=", "get_system", "(", "args", ".", "model_path", ",", "device", ")", "\n", "test_loss", ",", "test_acc", "=", "test", "(", "system", ",", "loader", ",", "device", ")", "\n", "corruption_accs", ".", "append", "(", "test_acc", ")", "\n", "print", "(", "'{}\\n\\tTest Loss {:.3f} | Test Error {:.3f}'", ".", "format", "(", "\n", "corruption", ",", "test_loss", ",", "100", "-", "100.", "*", "test_acc", ")", ")", "\n", "if", "args", ".", "clean", ":", "\n", "            ", "break", "\n", "\n", "", "", "print", "(", "'Mean Corruption Accuracy:'", ",", "np", ".", "mean", "(", "corruption_accs", ")", ")", "\n", "print", "(", "'Accuracies:'", ",", "corruption_accs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_meta_transfer.run": [[18, 85], ["src.utils.setup.process_config", "run_meta_transfer.seed_everything", "SystemClass", "pytorch_lightning.callbacks.ModelCheckpoint", "wandb.init", "pytorch_lightning.Trainer", "pl.Trainer.fit", "os.path.join", "globals", "int", "int"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.process_config", "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_sensor.seed_everything"], ["def", "run", "(", "args", ",", "gpu_device", "=", "None", ")", ":", "\n", "    ", "'''Run the Lightning system. \n\n    Args:\n        args\n            args.config_path: str, filepath to the config file\n        gpu_device: str or None, specifies GPU device as follows:\n            None: CPU (specified as null in config)\n            'cpu': CPU\n            '-1': All available GPUs\n            '0': GPU 0\n            '4': GPU 4\n            '0,3' GPUs 1 and 3\n            See: https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html\n    '''", "\n", "if", "gpu_device", "==", "'cpu'", "or", "not", "gpu_device", ":", "\n", "        ", "gpu_device", "=", "None", "\n", "# --- custom", "\n", "", "config", "=", "process_config", "(", "args", ".", "config", ",", "exp_name_suffix", "=", "args", ".", "dataset", ")", "\n", "config", ".", "data_params", ".", "dataset", "=", "args", ".", "dataset", "\n", "if", "args", ".", "test", ":", "# as a test just run for 1 epoch", "\n", "        ", "config", ".", "num_epochs", "=", "1", "\n", "# ---", "\n", "# Only override if specified.", "\n", "", "if", "gpu_device", ":", "config", ".", "gpu_device", "=", "gpu_device", "\n", "if", "args", ".", "num_workers", ":", "config", ".", "data_loader_workers", "=", "args", ".", "num_workers", "\n", "seed_everything", "(", "config", ".", "seed", ")", "\n", "SystemClass", "=", "SYSTEM", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "\n", "if", "config", ".", "optim_params", ".", "scheduler", ":", "\n", "        ", "lr_callback", "=", "globals", "(", ")", "[", "config", ".", "optim_params", ".", "scheduler", "]", "(", "\n", "initial_lr", "=", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "max_epochs", "=", "config", ".", "num_epochs", ",", "\n", "schedule", "=", "(", "\n", "int", "(", "0.6", "*", "config", ".", "num_epochs", ")", ",", "\n", "int", "(", "0.8", "*", "config", ".", "num_epochs", ")", ",", "\n", ")", ",", "\n", ")", "\n", "callbacks", "=", "[", "lr_callback", "]", "\n", "", "else", ":", "\n", "        ", "callbacks", "=", "[", "]", "\n", "\n", "# TODO: adjust period for saving checkpoints.", "\n", "", "ckpt_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "config", ".", "exp_dir", ",", "'checkpoints'", ")", ",", "\n", "save_top_k", "=", "-", "1", ",", "\n", "period", "=", "1", ",", "\n", ")", "\n", "wandb", ".", "init", "(", "project", "=", "'image'", ",", "entity", "=", "'viewmaker'", ",", "name", "=", "config", ".", "exp_name", ",", "config", "=", "config", ",", "sync_tensorboard", "=", "True", ")", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "default_root_dir", "=", "config", ".", "exp_dir", ",", "\n", "gpus", "=", "gpu_device", ",", "\n", "# 'ddp' is usually faster, but we use 'dp' so the negative samples ", "\n", "# for the whole batch are used for the SimCLR loss", "\n", "distributed_backend", "=", "config", ".", "distributed_backend", "or", "'dp'", ",", "\n", "max_epochs", "=", "config", ".", "num_epochs", ",", "\n", "min_epochs", "=", "config", ".", "num_epochs", ",", "\n", "checkpoint_callback", "=", "ckpt_callback", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "ckpt", "or", "config", ".", "continue_from_checkpoint", ",", "\n", "profiler", "=", "args", ".", "profiler", ",", "\n", "precision", "=", "config", ".", "optim_params", ".", "precision", "or", "32", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "val_check_interval", "=", "config", ".", "val_check_interval", "or", "1.0", ",", "\n", "limit_val_batches", "=", "config", ".", "limit_val_batches", "or", "1.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_meta_transfer.seed_everything": [[87, 93], ["random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "str"], "function", ["None"], ["", "def", "seed_everything", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "numpy", ".", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_audio.run": [[30, 99], ["run_audio.seed_everything", "SystemClass", "pytorch_lightning.callbacks.ModelCheckpoint", "wandb.init", "pytorch_lightning.Trainer", "pl.Trainer.fit", "src.utils.setup.process_config", "src.utils.setup.process_config", "os.path.join", "globals", "int", "int"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_sensor.seed_everything", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.process_config", "home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.process_config"], ["def", "run", "(", "args", ",", "gpu_device", "=", "None", ")", ":", "\n", "    ", "'''Run the Lightning system. \n\n    Args:\n        args\n            args.config_path: str, filepath to the config file\n        gpu_device: str or None, specifies GPU device as follows:\n            None: CPU (specified as null in config)\n            'cpu': CPU\n            '-1': All available GPUs\n            '0': GPU 0\n            '4': GPU 4\n            '0,3' GPUs 1 and 3\n            See: https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html\n    '''", "\n", "if", "gpu_device", "==", "'cpu'", "or", "not", "gpu_device", ":", "\n", "        ", "gpu_device", "=", "None", "\n", "\n", "", "if", "args", ".", "caller_intent", "is", "not", "None", ":", "\n", "# for harpervalley, we need to choose between different transfer tasks", "\n", "        ", "config", "=", "process_config", "(", "args", ".", "config", ",", "exp_name_suffix", "=", "args", ".", "caller_intent", ")", "\n", "config", ".", "data_params", ".", "caller_intent", "=", "args", ".", "caller_intent", "\n", "", "else", ":", "\n", "        ", "config", "=", "process_config", "(", "args", ".", "config", ")", "\n", "\n", "# Only override if specified.", "\n", "", "if", "gpu_device", ":", "config", ".", "gpu_device", "=", "gpu_device", "\n", "seed_everything", "(", "config", ".", "seed", ")", "\n", "SystemClass", "=", "SYSTEM", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "\n", "if", "config", ".", "optim_params", ".", "scheduler", ":", "\n", "        ", "lr_callback", "=", "globals", "(", ")", "[", "config", ".", "optim_params", ".", "scheduler", "]", "(", "\n", "initial_lr", "=", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "max_epochs", "=", "config", ".", "num_epochs", ",", "\n", "schedule", "=", "(", "\n", "int", "(", "0.6", "*", "config", ".", "num_epochs", ")", ",", "\n", "int", "(", "0.8", "*", "config", ".", "num_epochs", ")", ",", "\n", ")", ",", "\n", ")", "\n", "callbacks", "=", "[", "lr_callback", "]", "\n", "", "else", ":", "\n", "        ", "callbacks", "=", "None", "\n", "\n", "# TODO: adjust period for saving checkpoints.", "\n", "", "ckpt_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "config", ".", "exp_dir", ",", "'checkpoints'", ")", ",", "\n", "save_top_k", "=", "-", "1", ",", "\n", "period", "=", "1", ",", "\n", ")", "\n", "wandb", ".", "init", "(", "project", "=", "'audio'", ",", "entity", "=", "'viewmaker'", ",", "name", "=", "config", ".", "exp_name", ",", "config", "=", "config", ",", "sync_tensorboard", "=", "True", ")", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "default_root_dir", "=", "config", ".", "exp_dir", ",", "\n", "gpus", "=", "gpu_device", ",", "\n", "# 'ddp' is usually faster, but we use 'dp' so the negative samples ", "\n", "# for the whole batch are used for the SimCLR loss", "\n", "distributed_backend", "=", "config", ".", "distributed_backend", "or", "'dp'", ",", "\n", "max_epochs", "=", "config", ".", "num_epochs", ",", "\n", "min_epochs", "=", "config", ".", "num_epochs", ",", "\n", "checkpoint_callback", "=", "ckpt_callback", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "ckpt", "or", "config", ".", "continue_from_checkpoint", ",", "\n", "profiler", "=", "args", ".", "profiler", ",", "\n", "precision", "=", "config", ".", "optim_params", ".", "precision", "or", "32", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "val_check_interval", "=", "config", ".", "val_check_interval", "or", "1.0", ",", "\n", "limit_val_batches", "=", "config", ".", "limit_val_batches", "or", "1.0", ",", "\n", "num_sanity_val_steps", "=", "-", "1", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_audio.seed_everything": [[101, 107], ["random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "str"], "function", ["None"], ["", "def", "seed_everything", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "numpy", ".", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_image.run": [[22, 85], ["src.utils.setup.process_config", "run_image.seed_everything", "SystemClass", "pytorch_lightning.callbacks.ModelCheckpoint", "wandb.init", "pytorch_lightning.Trainer", "pl.Trainer.fit", "os.path.join", "globals", "int", "int"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.process_config", "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_sensor.seed_everything"], ["def", "run", "(", "args", ",", "gpu_device", "=", "None", ")", ":", "\n", "    ", "'''Run the Lightning system. \n\n    Args:\n        args\n            args.config_path: str, filepath to the config file\n        gpu_device: str or None, specifies GPU device as follows:\n            None: CPU (specified as null in config)\n            'cpu': CPU\n            '-1': All available GPUs\n            '0': GPU 0\n            '4': GPU 4\n            '0,3' GPUs 1 and 3\n            See the following for more options: \n            https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html\n    '''", "\n", "if", "gpu_device", "==", "'cpu'", "or", "not", "gpu_device", ":", "\n", "        ", "gpu_device", "=", "None", "\n", "", "config", "=", "process_config", "(", "args", ".", "config", ")", "\n", "# Only override if specified.", "\n", "if", "gpu_device", ":", "config", ".", "gpu_device", "=", "gpu_device", "\n", "if", "args", ".", "num_workers", ":", "config", ".", "data_loader_workers", "=", "args", ".", "num_workers", "\n", "seed_everything", "(", "config", ".", "seed", ")", "\n", "SystemClass", "=", "SYSTEM", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "\n", "if", "config", ".", "optim_params", ".", "scheduler", ":", "\n", "        ", "lr_callback", "=", "globals", "(", ")", "[", "config", ".", "optim_params", ".", "scheduler", "]", "(", "\n", "initial_lr", "=", "config", ".", "optim_params", ".", "learning_rate", ",", "\n", "max_epochs", "=", "config", ".", "num_epochs", ",", "\n", "schedule", "=", "(", "\n", "int", "(", "0.6", "*", "config", ".", "num_epochs", ")", ",", "\n", "int", "(", "0.8", "*", "config", ".", "num_epochs", ")", ",", "\n", ")", ",", "\n", ")", "\n", "callbacks", "=", "[", "lr_callback", "]", "\n", "", "else", ":", "\n", "        ", "callbacks", "=", "[", "]", "\n", "\n", "# TODO: adjust period for saving checkpoints.", "\n", "", "ckpt_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "config", ".", "exp_dir", ",", "'checkpoints'", ")", ",", "\n", "save_top_k", "=", "-", "1", ",", "\n", "period", "=", "1", ",", "\n", ")", "\n", "wandb", ".", "init", "(", "project", "=", "'image'", ",", "entity", "=", "'viewmaker'", ",", "name", "=", "config", ".", "exp_name", ",", "config", "=", "config", ",", "sync_tensorboard", "=", "True", ")", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "default_root_dir", "=", "config", ".", "exp_dir", ",", "\n", "gpus", "=", "gpu_device", ",", "\n", "# 'ddp' is usually faster, but we use 'dp' so the negative samples ", "\n", "# for the whole batch are used for the SimCLR loss", "\n", "# distributed_backend=config.distributed_backend or 'dp',", "\n", "max_epochs", "=", "config", ".", "num_epochs", ",", "\n", "min_epochs", "=", "config", ".", "num_epochs", ",", "\n", "checkpoint_callback", "=", "ckpt_callback", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "ckpt", "or", "config", ".", "continue_from_checkpoint", ",", "\n", "profiler", "=", "args", ".", "profiler", ",", "\n", "precision", "=", "config", ".", "optim_params", ".", "precision", "or", "32", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "val_check_interval", "=", "config", ".", "val_check_interval", "or", "1.0", ",", "\n", "limit_val_batches", "=", "config", ".", "limit_val_batches", "or", "1.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_image.seed_everything": [[87, 93], ["random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "str"], "function", ["None"], ["", "def", "seed_everything", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "numpy", ".", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_sensor.run": [[21, 76], ["src.utils.setup.process_config", "run_sensor.seed_everything", "SystemClass", "pytorch_lightning.callbacks.ModelCheckpoint", "wandb.init", "pytorch_lightning.Trainer", "pl.Trainer.fit", "os.path.join"], "function", ["home.repos.pwc.inspect_result.alextamkin_viewmaker.utils.setup.process_config", "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_sensor.seed_everything"], ["def", "run", "(", "args", ",", "gpu_device", "=", "None", ")", ":", "\n", "    ", "'''Run the Lightning system. \n\n    Args:\n        args\n            args.config_path: str, filepath to the config file\n        gpu_device: str or None, specifies GPU device as follows:\n            None: CPU (specified as null in config)\n            'cpu': CPU\n            '-1': All available GPUs\n            '0': GPU 0\n            '4': GPU 4\n            '0,3' GPUs 1 and 3\n            See: https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html\n    '''", "\n", "if", "gpu_device", "==", "'cpu'", "or", "not", "gpu_device", ":", "\n", "        ", "gpu_device", "=", "None", "\n", "\n", "", "config", "=", "process_config", "(", "args", ".", "config", ")", "\n", "\n", "# Only override if specified.", "\n", "if", "gpu_device", ":", "\n", "        ", "config", ".", "gpu_device", "=", "gpu_device", "\n", "", "if", "args", ".", "quick", ":", "\n", "        ", "config", ".", "quick", "=", "args", ".", "quick", "\n", "", "if", "args", ".", "num_workers", "is", "not", "None", ":", "\n", "        ", "config", ".", "data_loader_workers", "=", "args", ".", "num_workers", "\n", "\n", "", "seed_everything", "(", "config", ".", "seed", ")", "\n", "SystemClass", "=", "SYSTEM", "[", "config", ".", "system", "]", "\n", "system", "=", "SystemClass", "(", "config", ")", "\n", "\n", "ckpt_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "config", ".", "exp_dir", ",", "'checkpoints'", ")", ",", "\n", "save_top_k", "=", "-", "1", ",", "\n", "period", "=", "1", ",", "\n", ")", "\n", "wandb", ".", "init", "(", "project", "=", "'sensor'", ",", "entity", "=", "'viewmaker'", ",", "\n", "name", "=", "config", ".", "exp_name", ",", "config", "=", "config", ",", "sync_tensorboard", "=", "True", ")", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "default_root_dir", "=", "config", ".", "exp_dir", ",", "\n", "gpus", "=", "gpu_device", ",", "\n", "distributed_backend", "=", "config", ".", "distributed_backend", "or", "'dp'", ",", "\n", "max_epochs", "=", "config", ".", "num_epochs", ",", "\n", "min_epochs", "=", "config", ".", "num_epochs", ",", "\n", "checkpoint_callback", "=", "ckpt_callback", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "ckpt", "or", "config", ".", "continue_from_checkpoint", ",", "\n", "profiler", "=", "args", ".", "profiler", ",", "\n", "precision", "=", "config", ".", "optim_params", ".", "precision", "or", "32", ",", "\n", "callbacks", "=", "None", ",", "\n", "val_check_interval", "=", "config", ".", "val_check_interval", "or", "1.0", ",", "\n", "limit_val_batches", "=", "config", ".", "limit_val_batches", "or", "1.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alextamkin_viewmaker.scripts.run_sensor.seed_everything": [[78, 84], ["random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "str"], "function", ["None"], ["", "def", "seed_everything", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "numpy", ".", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "\n"]]}