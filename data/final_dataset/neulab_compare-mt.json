{"home.repos.pwc.inspect_result.neulab_compare-mt.None.setup.test_suite": [[5, 10], ["unittest.TestLoader", "unittest.TestLoader.discover"], "function", ["None"], ["def", "test_suite", "(", ")", ":", "\n", "  ", "test_loader", "=", "unittest", ".", "TestLoader", "(", ")", "\n", "test_suite", "=", "test_loader", ".", "discover", "(", "\"compare_mt/tests\"", ",", "pattern", "=", "\"test_*.py\"", ")", "\n", "\n", "return", "test_suite", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_ll_main.print_word_likelihood_report": [[10, 52], ["compare_mt.bucketers.create_word_bucketer_from_profile", "print", "enumerate", "type", "compare_mt.corpus_utils.load_tokens", "print", "print", "print", "bucketers.create_word_bucketer_from_profile.calc_bucketed_likelihoods", "bucketers.create_word_bucketer_from_profile.name", "compare_mt.formatting.fmt"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.create_word_bucketer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_bucketed_likelihoods", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["def", "print_word_likelihood_report", "(", "ref", ",", "lls", ",", "bucket_type", "=", "'freq'", ",", "bucket_cutoffs", "=", "None", ",", "\n", "freq_count_file", "=", "None", ",", "freq_corpus_file", "=", "None", ",", "\n", "label_corpus", "=", "None", ",", "label_set", "=", "None", ",", "\n", "case_insensitive", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  Print a report comparing the word log likelihood.\n\n  Args:\n  ref: the ref of words over which the likelihoods are computed\n  lls: likelihoods corresponding to each word in ref from the systems\n  bucket_type: A string specifying the way to bucket words together to calculate average likelihood\n  bucket_cutoffs: The boundaries between buckets, specified as a colon-separated string.\n  freq_corpus_file: When using \"freq\" as a bucketer, which corpus to use to calculate frequency.\n  freq_count_file: An alternative to freq_corpus that uses a count file in \"word\\tfreq\" format.\n  label_corpus: When using \"label\" as bucket type, the corpus containing the labels\n                corresponding to each word in the corpus\n  label_set: the permissible set of labels when using \"label\" as a bucket type\n  case_insensitive: A boolean specifying whether to turn on the case insensitive option\n  \"\"\"", "\n", "case_insensitive", "=", "True", "if", "case_insensitive", "==", "'True'", "else", "False", "\n", "\n", "bucketer", "=", "bucketers", ".", "create_word_bucketer_from_profile", "(", "bucket_type", "=", "bucket_type", ",", "\n", "bucket_cutoffs", "=", "bucket_cutoffs", ",", "\n", "freq_count_file", "=", "freq_count_file", ",", "\n", "freq_corpus_file", "=", "freq_corpus_file", ",", "\n", "label_set", "=", "label_set", ",", "\n", "case_insensitive", "=", "case_insensitive", ")", "\n", "\n", "if", "type", "(", "label_corpus", ")", "==", "str", ":", "\n", "    ", "label_corpus", "=", "corpus_utils", ".", "load_tokens", "(", "label_corpus", ")", "\n", "\n", "", "if", "label_corpus", "is", "not", "None", ":", "\n", "    ", "ref", "=", "label_corpus", "\n", "\n", "", "lls_out", "=", "[", "[", "l", "for", "l", "in", "bucketer", ".", "calc_bucketed_likelihoods", "(", "ref", ",", "ll", ")", "]", "for", "ll", "in", "lls", "]", "\n", "\n", "print", "(", "f'--- average word log likelihood by {bucketer.name()} bucket'", ")", "\n", "for", "i", ",", "bucket_str", "in", "enumerate", "(", "bucketer", ".", "bucket_strs", ")", ":", "\n", "    ", "print", "(", "bucket_str", "+", "\"\\t\"", ",", "end", "=", "''", ")", "\n", "for", "ll_out", "in", "lls_out", ":", "\n", "      ", "print", "(", "f\"{formatting.fmt(ll_out[i])}\\t\"", ",", "end", "=", "\"\"", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_ll_main.main": [[53, 87], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "compare_mt.formatting.fmt.set_decimals", "compare_mt.corpus_utils.load_tokens", "compare_mt.corpus_utils.load_nums", "compare_mt.print_utils.print_header", "compare_mt.arg_utils.parse_profile", "compare_ll_main.print_word_likelihood_report", "print"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.formatting.Formatter.set_decimals", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_nums", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print_header", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_ll_main.print_word_likelihood_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Program to compare MT results'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--ref-file'", ",", "type", "=", "str", ",", "dest", "=", "'ref_file'", ",", "\n", "help", "=", "'A path to a reference file over which the likelihoods are being computed/compared'", ")", "\n", "parser", ".", "add_argument", "(", "'--ll-files'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "dest", "=", "'ll_files'", ",", "\n", "help", "=", "'A path to file containing log likelihoods for ref-file generated by systems'", ")", "\n", "parser", ".", "add_argument", "(", "'--compare-word-likelihoods'", ",", "type", "=", "str", ",", "dest", "=", "'compare_word_likelihoods'", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "[", "'bucket_type=freq'", "]", ",", "\n", "help", "=", "\"\"\"\n                    Compare word log likelihoods by buckets. Can specify arguments in 'arg1=val1,arg2=val2,...' format.\n                    See documentation for 'print_word_likelihood_report' to see which arguments are available.\n                    \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--decimals'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "\"Number of decimals to print for floating point numbers\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Set formatting", "\n", "\n", "# Set formatting", "\n", "formatting", ".", "fmt", ".", "set_decimals", "(", "args", ".", "decimals", ")", "\n", "\n", "ref", "=", "corpus_utils", ".", "load_tokens", "(", "args", ".", "ref_file", ")", "\n", "lls", "=", "[", "corpus_utils", ".", "load_nums", "(", "x", ")", "for", "x", "in", "args", ".", "ll_files", "]", "\n", "\n", "# Word likelihood analysis", "\n", "if", "args", ".", "compare_word_likelihoods", ":", "\n", "    ", "print_utils", ".", "print_header", "(", "'Word Likelihood Analysis'", ")", "\n", "for", "profile", "in", "args", ".", "compare_word_likelihoods", ":", "\n", "      ", "kargs", "=", "arg_utils", ".", "parse_profile", "(", "profile", ")", "\n", "print_word_likelihood_report", "(", "ref", ",", "lls", ",", "**", "kargs", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.formatting.Formatter.__init__": [[12, 14], ["formatting.Formatter.set_decimals"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.formatting.Formatter.set_decimals"], ["def", "__init__", "(", "self", ",", "decimals", "=", "4", ")", ":", "\n", "        ", "self", ".", "set_decimals", "(", "decimals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.formatting.Formatter.set_decimals": [[15, 17], ["None"], "methods", ["None"], ["", "def", "set_decimals", "(", "self", ",", "decimals", ")", ":", "\n", "        ", "self", ".", "decimals", "=", "decimals", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.formatting.Formatter.escape_latex": [[18, 24], ["formatting.Formatter.latex_substitutions.items", "pat.sub"], "methods", ["None"], ["", "def", "escape_latex", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Adds escape sequences wherever needed to make the output\n        LateX compatible\"\"\"", "\n", "for", "pat", ",", "replace_with", "in", "self", ".", "latex_substitutions", ".", "items", "(", ")", ":", "\n", "            ", "x", "=", "pat", ".", "sub", "(", "replace_with", ",", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.formatting.Formatter.__call__": [[25, 35], ["isinstance", "isinstance", "formatting.Formatter.escape_latex", "isinstance", "str"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.formatting.Formatter.escape_latex"], ["", "def", "__call__", "(", "self", ",", "x", ",", "latex", "=", "True", ")", ":", "\n", "        ", "\"\"\"Convert object to string with controlled decimals\"\"\"", "\n", "if", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "            ", "return", "self", ".", "escape_latex", "(", "x", ")", "if", "latex", "else", "x", "\n", "", "elif", "isinstance", "(", "x", ",", "int", ")", ":", "\n", "            ", "return", "f\"{x:d}\"", "\n", "", "elif", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "return", "f\"{x:.{self.decimals}f}\"", "\n", "", "else", ":", "\n", "            ", "str", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.sent_ngrams_list": [[4, 20], ["range", "tuple", "word_ngram.append", "len"], "function", ["None"], ["def", "sent_ngrams_list", "(", "words", ",", "n", ")", ":", "\n", "  ", "\"\"\"\n  Create a list with all the n-grams in a sentence\n\n  Arguments:\n    words: A list of strings representing a sentence\n    n: The ngram length to consider\n\n  Returns:\n    A list of n-grams in the sentence\n  \"\"\"", "\n", "word_ngram", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "n", "+", "1", ")", ":", "\n", "    ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "word_ngram", ".", "append", "(", "ngram", ")", "\n", "", "return", "word_ngram", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.iterate_sent_ngrams": [[21, 42], ["range", "ValueError", "range", "len", "len", "tuple", "len", "tuple", "len", "len"], "function", ["None"], ["", "def", "iterate_sent_ngrams", "(", "words", ",", "labels", "=", "None", ",", "min_length", "=", "1", ",", "max_length", "=", "4", ")", ":", "\n", "  ", "\"\"\"\n  Create a list with all the n-grams in a sentence\n\n  Arguments:\n    words: A list of strings representing a sentence\n    labels: A list of labels on each word in the sentence, optional (will use `words` if not specified)\n    min_length: The minimum ngram length to consider\n    max_length: The maximum ngram length to consider\n\n  Returns:\n    An iterator over n-grams in the sentence with both words and labels\n  \"\"\"", "\n", "if", "labels", "is", "not", "None", "and", "len", "(", "labels", ")", "!=", "len", "(", "words", ")", ":", "\n", "    ", "raise", "ValueError", "(", "f'length of labels and sentence must be the same but got'", "\n", "f' {len(words)} != {len(labels)} at\\n{words}\\n{labels}'", ")", "\n", "", "for", "n", "in", "range", "(", "min_length", "-", "1", ",", "max_length", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "n", ")", ":", "\n", "      ", "word_ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "n", "+", "1", "]", ")", "\n", "label_ngram", "=", "tuple", "(", "labels", "[", "i", ":", "i", "+", "n", "+", "1", "]", ")", "if", "(", "labels", "is", "not", "None", ")", "else", "word_ngram", "\n", "yield", "word_ngram", ",", "label_ngram", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.compare_ngrams": [[43, 88], ["itertools.zip_longest", "ValueError", "collections.defaultdict", "list", "collections.defaultdict", "ngram_utils.iterate_sent_ngrams", "reversed", "range", "ngram_utils.iterate_sent_ngrams"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.iterate_sent_ngrams", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.iterate_sent_ngrams"], ["", "", "", "def", "compare_ngrams", "(", "ref", ",", "out", ",", "ref_labels", "=", "None", ",", "out_labels", "=", "None", ",", "min_length", "=", "1", ",", "max_length", "=", "4", ")", ":", "\n", "  ", "\"\"\"\n  Compare n-grams appearing in the reference sentences and output\n\n  Args:\n    ref: A list of reference sentences\n    out: A list of output sentences\n    ref_labels: Alternative labels for reference words (e.g. POS tags) to use when aggregating counts\n    out_labels: Alternative labels for output words (e.g. POS tags) to use when aggregating counts\n    min_length: The minimum length of n-grams to consider\n    max_length: The maximum length of n-grams to consider\n\n  Returns:\n    A tuple of dictionaries including\n      total: the total number of n-grams in the output\n      match: the total number of matched n-grams appearing in both output and reference\n      over: the total number of over-generated n-grams appearing in output but not reference\n      under: the total number of under-generated n-grams appearing in output but not reference\n  \"\"\"", "\n", "if", "(", "ref_labels", "is", "None", ")", "!=", "(", "out_labels", "is", "None", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'ref_labels or out_labels must both be either None or not None'", ")", "\n", "", "total", ",", "match", ",", "over", ",", "under", "=", "[", "defaultdict", "(", "lambda", ":", "0", ")", "for", "_", "in", "range", "(", "4", ")", "]", "\n", "if", "ref_labels", "is", "None", ":", "ref_labels", "=", "[", "]", "\n", "if", "out_labels", "is", "None", ":", "out_labels", "=", "[", "]", "\n", "for", "ref_sent", ",", "out_sent", ",", "ref_lab", ",", "out_lab", "in", "itertools", ".", "zip_longest", "(", "ref", ",", "out", ",", "ref_labels", ",", "out_labels", ")", ":", "\n", "# Find the number of reference n-grams (on a word level)", "\n", "    ", "ref_ngrams", "=", "list", "(", "iterate_sent_ngrams", "(", "ref_sent", ",", "labels", "=", "ref_lab", ",", "min_length", "=", "min_length", ",", "max_length", "=", "max_length", ")", ")", "\n", "ref_word_counts", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "for", "ref_w", ",", "ref_l", "in", "ref_ngrams", ":", "\n", "      ", "ref_word_counts", "[", "ref_w", "]", "+=", "1", "\n", "# Step through the output ngrams and find matched and overproduced ones", "\n", "", "for", "out_w", ",", "out_l", "in", "iterate_sent_ngrams", "(", "out_sent", ",", "labels", "=", "out_lab", ",", "min_length", "=", "min_length", ",", "max_length", "=", "max_length", ")", ":", "\n", "      ", "total", "[", "out_l", "]", "+=", "1", "\n", "if", "ref_word_counts", "[", "out_w", "]", ">", "0", ":", "\n", "        ", "match", "[", "out_l", "]", "+=", "1", "\n", "ref_word_counts", "[", "out_w", "]", "-=", "1", "\n", "", "else", ":", "\n", "        ", "over", "[", "out_l", "]", "+=", "1", "\n", "# Remaining ones are underproduced", "\n", "# (do reverse order just to make ordering consistent for over and under, shouldn't matter much)", "\n", "", "", "for", "ref_w", ",", "ref_l", "in", "reversed", "(", "ref_ngrams", ")", ":", "\n", "      ", "if", "ref_word_counts", "[", "ref_w", "]", ">", "0", ":", "\n", "        ", "under", "[", "ref_l", "]", "+=", "1", "\n", "ref_word_counts", "[", "ref_w", "]", "-=", "1", "\n", "", "", "", "return", "total", ",", "match", ",", "over", ",", "under", "\n", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.sign_utils.eval_with_paired_bootstrap": [[16, 87], ["len", "list", "int", "range", "range", "range", "numpy.random.choice", "range", "len", "sys_scores[].sort", "sys_stats.append", "scorer.cache_stats", "zip", "zip", "enumerate", "len", "sys_scores[].append", "numpy.mean", "numpy.median", "float", "scorer.score_cached_corpus", "scorer.score_corpus", "int", "int"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["def", "eval_with_paired_bootstrap", "(", "ref", ",", "outs", ",", "src", ",", "\n", "scorer", ",", "\n", "compare_directions", "=", "[", "(", "0", ",", "1", ")", "]", ",", "\n", "num_samples", "=", "1000", ",", "sample_ratio", "=", "0.5", ",", "\n", "cache_stats", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Evaluate with paired boostrap.\n  This compares several systems, performing a signifiance tests with\n  paired bootstrap resampling to compare the accuracy of the specified systems.\n\n  Args:\n    ref: The correct labels\n    outs: The output of systems\n    src: The source corpus\n    scorer: The scorer\n    compare_directions: A string specifying which two systems to compare\n    num_samples: The number of bootstrap samples to take\n    sample_ratio: The ratio of samples to take every time\n    cache_stats: The precomputed statistics\n\n  Returns:\n    A tuple containing the win ratios, statistics for systems\n  \"\"\"", "\n", "sys_scores", "=", "[", "[", "]", "for", "_", "in", "outs", "]", "\n", "wins", "=", "[", "[", "0", ",", "0", ",", "0", "]", "for", "_", "in", "compare_directions", "]", "if", "compare_directions", "is", "not", "None", "else", "None", "\n", "n", "=", "len", "(", "ref", ")", "\n", "ids", "=", "list", "(", "range", "(", "n", ")", ")", "\n", "\n", "if", "cache_stats", "is", "None", ":", "\n", "    ", "cache_stats", "=", "[", "scorer", ".", "cache_stats", "(", "ref", ",", "out", ",", "src", "=", "src", ")", "for", "out", "in", "outs", "]", "\n", "", "sample_size", "=", "int", "(", "n", "*", "sample_ratio", ")", "\n", "for", "_", "in", "range", "(", "num_samples", ")", ":", "\n", "# Subsample the gold and system outputs (with replacement)", "\n", "    ", "reduced_ids", "=", "np", ".", "random", ".", "choice", "(", "ids", ",", "size", "=", "sample_size", ",", "replace", "=", "True", ")", "\n", "# Calculate accuracy on the reduced sample and save stats", "\n", "if", "cache_stats", "[", "0", "]", ":", "\n", "      ", "sys_score", ",", "_", "=", "zip", "(", "*", "[", "scorer", ".", "score_cached_corpus", "(", "reduced_ids", ",", "cache_stat", ")", "for", "cache_stat", "in", "cache_stats", "]", ")", "\n", "", "else", ":", "\n", "      ", "reduced_ref", "=", "[", "ref", "[", "i", "]", "for", "i", "in", "reduced_ids", "]", "\n", "reduced_outs", "=", "[", "[", "out", "[", "i", "]", "for", "i", "in", "reduced_ids", "]", "for", "out", "in", "outs", "]", "\n", "reduced_src", "=", "[", "src", "[", "i", "]", "for", "i", "in", "reduced_ids", "]", "\n", "sys_score", ",", "_", "=", "zip", "(", "*", "[", "scorer", ".", "score_corpus", "(", "reduced_ref", ",", "reduced_out", ",", "reduced_src", ")", "for", "reduced_out", "in", "reduced_outs", "]", ")", "\n", "\n", "", "if", "wins", "is", "not", "None", ":", "\n", "      ", "for", "i", ",", "compare_direction", "in", "enumerate", "(", "compare_directions", ")", ":", "\n", "        ", "left", ",", "right", "=", "compare_direction", "\n", "if", "sys_score", "[", "left", "]", ">", "sys_score", "[", "right", "]", ":", "\n", "          ", "wins", "[", "i", "]", "[", "0", "]", "+=", "1", "\n", "", "if", "sys_score", "[", "left", "]", "<", "sys_score", "[", "right", "]", ":", "\n", "          ", "wins", "[", "i", "]", "[", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "          ", "wins", "[", "i", "]", "[", "2", "]", "+=", "1", "\n", "\n", "", "", "", "for", "i", "in", "range", "(", "len", "(", "outs", ")", ")", ":", "\n", "      ", "sys_scores", "[", "i", "]", ".", "append", "(", "sys_score", "[", "i", "]", ")", "\n", "\n", "# Print win stats", "\n", "", "", "wins", "=", "[", "[", "x", "/", "float", "(", "num_samples", ")", "for", "x", "in", "win", "]", "for", "win", "in", "wins", "]", "if", "wins", "is", "not", "None", "else", "None", "\n", "\n", "# Print system stats", "\n", "sys_stats", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "outs", ")", ")", ":", "\n", "    ", "sys_scores", "[", "i", "]", ".", "sort", "(", ")", "\n", "sys_stats", ".", "append", "(", "{", "\n", "'mean'", ":", "np", ".", "mean", "(", "sys_scores", "[", "i", "]", ")", ",", "\n", "'median'", ":", "np", ".", "median", "(", "sys_scores", "[", "i", "]", ")", ",", "\n", "'lower_bound'", ":", "sys_scores", "[", "i", "]", "[", "int", "(", "num_samples", "*", "0.025", ")", "]", ",", "\n", "'upper_bound'", ":", "sys_scores", "[", "i", "]", "[", "int", "(", "num_samples", "*", "0.975", ")", "]", "\n", "}", ")", "\n", "\n", "", "return", "wins", ",", "sys_stats", "\n", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.iterate_tokens": [[1, 5], ["open", "line.strip().split", "line.strip"], "function", ["None"], ["def", "iterate_tokens", "(", "filename", ")", ":", "\n", "  ", "with", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "for", "line", "in", "f", ":", "\n", "      ", "yield", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens": [[6, 8], ["list", "corpus_utils.iterate_tokens"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.iterate_tokens"], ["", "", "", "def", "load_tokens", "(", "filename", ")", ":", "\n", "  ", "return", "list", "(", "iterate_tokens", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.iterate_nums": [[9, 13], ["open", "float", "line.strip().split", "line.strip"], "function", ["None"], ["", "def", "iterate_nums", "(", "filename", ")", ":", "\n", "  ", "with", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "for", "line", "in", "f", ":", "\n", "      ", "yield", "[", "float", "(", "i", ")", "for", "i", "in", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_nums": [[14, 16], ["list", "corpus_utils.iterate_nums"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.iterate_nums"], ["", "", "", "def", "load_nums", "(", "filename", ")", ":", "\n", "  ", "return", "list", "(", "iterate_nums", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.iterate_alignments": [[17, 24], ["open", "ValueError", "int", "int", "x.split", "line.strip().split", "line.strip"], "function", ["None"], ["", "def", "iterate_alignments", "(", "filename", ")", ":", "\n", "  ", "with", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "for", "line", "in", "f", ":", "\n", "      ", "try", ":", "\n", "        ", "yield", "[", "(", "int", "(", "src", ")", ",", "int", "(", "trg", ")", ")", "for", "(", "src", ",", "trg", ")", "in", "[", "x", ".", "split", "(", "'-'", ")", "for", "x", "in", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "]", "]", "\n", "", "except", ":", "\n", "        ", "raise", "ValueError", "(", "f'Poorly formed alignment line in {filename}:\\n{line}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_alignments": [[25, 27], ["list", "corpus_utils.iterate_alignments"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.iterate_alignments"], ["", "", "", "", "def", "load_alignments", "(", "filename", ")", ":", "\n", "  ", "return", "list", "(", "iterate_alignments", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower": [[28, 30], ["inp.lower", "type", "corpus_utils.lower"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "lower", "(", "inp", ")", ":", "\n", "  ", "return", "inp", ".", "lower", "(", ")", "if", "type", "(", "inp", ")", "==", "str", "else", "[", "lower", "(", "x", ")", "for", "x", "in", "inp", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.list2str": [[31, 36], ["enumerate", "str", "str"], "function", ["None"], ["", "def", "list2str", "(", "l", ")", ":", "\n", "  ", "string", "=", "''", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "l", ")", ":", "\n", "    ", "string", "=", "string", "+", "' '", "+", "str", "(", "s", ")", "if", "i", "!=", "0", "else", "string", "+", "str", "(", "s", ")", "\n", "", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.write_tokens": [[37, 44], ["open", "enumerate", "corpus_utils.list2str", "f.write"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.list2str"], ["", "def", "write_tokens", "(", "filename", ",", "ls", ")", ":", "\n", "  ", "with", "open", "(", "filename", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "for", "i", ",", "l", "in", "enumerate", "(", "ls", ")", ":", "\n", "      ", "string", "=", "list2str", "(", "l", ")", "\n", "string", "=", "'\\n'", "+", "string", "if", "i", "!=", "0", "else", "string", "\n", "f", ".", "write", "(", "string", ")", "\n", "", "", "return", "string", "\n", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.print_utils.print_header": [[1, 3], ["print"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["def", "print_header", "(", "header", ")", ":", "\n", "  ", "print", "(", "f'********************** {header} ************************'", ")", "", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.align_utils._count_ngram": [[4, 13], ["dict", "range", "enumerate", "collections.defaultdict", "range", "min", "[].append"], "function", ["None"], ["def", "_count_ngram", "(", "sent", ",", "order", ")", ":", "\n", "  ", "gram_pos", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "order", ")", ":", "\n", "    ", "gram_pos", "[", "i", "+", "1", "]", "=", "defaultdict", "(", "lambda", ":", "[", "]", ")", "\n", "", "for", "i", ",", "word", "in", "enumerate", "(", "sent", ")", ":", "\n", "    ", "for", "j", "in", "range", "(", "min", "(", "i", "+", "1", ",", "order", ")", ")", ":", "\n", "      ", "gram_pos", "[", "j", "+", "1", "]", "[", "word", "]", ".", "append", "(", "i", "-", "j", ")", "\n", "word", "=", "sent", "[", "i", "-", "j", "-", "1", "]", "+", "' '", "+", "word", "\n", "", "", "return", "gram_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.align_utils.ngram_context_align": [[14, 65], ["align_utils._count_ngram", "align_utils._count_ngram", "enumerate", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "len", "len", "len", "len", "worder.append", "range", "len", "len", "len", "worder.append", "len", "len", "worder.append"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.align_utils._count_ngram", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.align_utils._count_ngram", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "ngram_context_align", "(", "ref", ",", "out", ",", "order", "=", "-", "1", ",", "case_insensitive", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  Calculate the word alignment between a reference sentence and an output sentence. \n  Proposed in the following paper:\n\n  Automatic Evaluation of Translation Quality for Distant Language Pairs\n  Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito Sudoh, Hajime Tsukada\n  http://www.anthology.aclweb.org/D/D10/D10-1092.pdf \n\n  Args:\n    ref: A reference sentence\n    out: An output sentence\n    order: The highest order of grams we want to consider (-1=inf)\n    case_insensitive: A boolean specifying whether to turn on the case insensitive option\n\n  Returns:\n    The word alignment, represented as a list of integers. \n  \"\"\"", "\n", "\n", "if", "case_insensitive", ":", "\n", "    ", "ref", "=", "corpus_utils", ".", "lower", "(", "ref", ")", "\n", "out", "=", "corpus_utils", ".", "lower", "(", "out", ")", "\n", "\n", "", "order", "=", "len", "(", "ref", ")", "if", "order", "==", "-", "1", "else", "order", "\n", "\n", "ref_gram_pos", "=", "_count_ngram", "(", "ref", ",", "order", ")", "\n", "out_gram_pos", "=", "_count_ngram", "(", "out", ",", "order", ")", "\n", "\n", "worder", "=", "[", "]", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "out", ")", ":", "\n", "    ", "if", "len", "(", "ref_gram_pos", "[", "1", "]", "[", "word", "]", ")", "==", "0", ":", "\n", "      ", "continue", "\n", "", "if", "len", "(", "ref_gram_pos", "[", "1", "]", "[", "word", "]", ")", "==", "len", "(", "out_gram_pos", "[", "1", "]", "[", "word", "]", ")", "==", "1", ":", "\n", "      ", "worder", ".", "append", "(", "ref_gram_pos", "[", "1", "]", "[", "word", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "      ", "word_forward", "=", "word", "\n", "word_backward", "=", "word", "\n", "for", "j", "in", "range", "(", "1", ",", "order", ")", ":", "\n", "        ", "if", "i", "-", "j", ">=", "0", ":", "\n", "          ", "word_backward", "=", "out", "[", "i", "-", "j", "]", "+", "' '", "+", "word_backward", "\n", "if", "len", "(", "ref_gram_pos", "[", "j", "+", "1", "]", "[", "word_backward", "]", ")", "==", "len", "(", "out_gram_pos", "[", "j", "+", "1", "]", "[", "word_backward", "]", ")", "==", "1", ":", "\n", "            ", "worder", ".", "append", "(", "ref_gram_pos", "[", "j", "+", "1", "]", "[", "word_backward", "]", "[", "0", "]", "+", "j", ")", "\n", "break", "\n", "\n", "", "", "if", "i", "+", "j", "<", "len", "(", "out", ")", ":", "\n", "          ", "word_forward", "=", "word_forward", "+", "' '", "+", "out", "[", "i", "+", "j", "]", "\n", "if", "len", "(", "ref_gram_pos", "[", "j", "+", "1", "]", "[", "word_forward", "]", ")", "==", "len", "(", "out_gram_pos", "[", "j", "+", "1", "]", "[", "word_forward", "]", ")", "==", "1", ":", "\n", "            ", "worder", ".", "append", "(", "ref_gram_pos", "[", "j", "+", "1", "]", "[", "word_forward", "]", "[", "0", "]", ")", "\n", "break", "\n", "\n", "", "", "", "", "", "return", "worder", "\n", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_profile": [[1, 14], ["profile.split", "kv.split", "ValueError"], "function", ["None"], ["def", "parse_profile", "(", "profile", ")", ":", "\n", "  ", "kargs", "=", "{", "}", "\n", "try", ":", "\n", "    ", "for", "kv", "in", "profile", ".", "split", "(", "','", ")", ":", "\n", "      ", "k", ",", "v", "=", "kv", ".", "split", "(", "'='", ")", "\n", "kargs", "[", "k", "]", "=", "v", "\n", "", "", "except", "ValueError", ":", "\n", "# more informative error message", "\n", "    ", "raise", "ValueError", "(", "\n", "f\"Failed to parse profile: {profile}. The expected format is:\"", "\n", "\" \\\"key1=value1,key2=value2,[...]\\\"\"", "\n", ")", "\n", "", "return", "kargs", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_compare_directions": [[15, 29], ["compare_directions.split", "direc.split", "direcs.append", "ValueError", "int", "int"], "function", ["None"], ["", "def", "parse_compare_directions", "(", "compare_directions", ")", ":", "\n", "  ", "direcs", "=", "[", "]", "\n", "try", ":", "\n", "    ", "for", "direc", "in", "compare_directions", ".", "split", "(", "';'", ")", ":", "\n", "      ", "left", ",", "right", "=", "direc", ".", "split", "(", "'-'", ")", "\n", "left", ",", "right", "=", "int", "(", "left", ")", ",", "int", "(", "right", ")", "\n", "direcs", ".", "append", "(", "(", "left", ",", "right", ")", ")", "\n", "", "", "except", "ValueError", ":", "\n", "# more informative error message", "\n", "    ", "raise", "ValueError", "(", "\n", "f\"Failed to parse directions: {compare_directions}.\"", "\n", "\" The expected format is: \\\"left1-right1;left2-right2;[...]\\\"\"", "\n", ")", "\n", "", "return", "direcs", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_files": [[30, 35], ["filenames.split", "files.append"], "function", ["None"], ["", "def", "parse_files", "(", "filenames", ")", ":", "\n", "  ", "files", "=", "[", "]", "\n", "for", "f", "in", "filenames", ".", "split", "(", "';'", ")", ":", "\n", "    ", "files", ".", "append", "(", "f", ")", "\n", "", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_intfloat": [[36, 41], ["int", "float"], "function", ["None"], ["", "def", "parse_intfloat", "(", "s", ")", ":", "\n", "  ", "try", ":", "\n", "    ", "return", "int", "(", "s", ")", "\n", "", "except", "ValueError", ":", "\n", "    ", "return", "float", "(", "s", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.stat_utils.extract_salient_features": [[2, 19], ["set", "set", "dict1.keys", "dict2.keys"], "function", ["None"], ["def", "extract_salient_features", "(", "dict1", ",", "dict2", ",", "alpha", "=", "1.0", ")", ":", "\n", "  ", "\"\"\"\n  Score salient features given to dictionaries.\n\n  Args:\n    dict1: First set of feature coutns\n    dict2: Second set of feature counts\n    alpha: The amount of smoothing (default 1 to Laplace smoothed probabilities)\n\n  Returns:\n    Laplace smoothed differences between features\n  \"\"\"", "\n", "all_keys", "=", "set", "(", "dict1", ".", "keys", "(", ")", ")", "|", "set", "(", "dict2", ".", "keys", "(", ")", ")", "\n", "scores", "=", "{", "}", "\n", "for", "k", "in", "all_keys", ":", "\n", "    ", "scores", "[", "k", "]", "=", "(", "dict1", "[", "k", "]", "+", "alpha", ")", "/", "(", "dict1", "[", "k", "]", "+", "dict2", "[", "k", "]", "+", "2", "*", "alpha", ")", "\n", "", "return", "scores", "", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print": [[132, 134], ["NotImplementedError"], "methods", ["None"], ["  ", "def", "print", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "'print must be implemented in subclasses of Report'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.plot": [[135, 137], ["NotImplementedError"], "methods", ["None"], ["", "def", "plot", "(", "self", ",", "output_directory", ",", "output_fig_file", ",", "output_fig_type", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "'plot must be implemented in subclasses of Report'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print_header": [[138, 140], ["reporters.Report.print"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "def", "print_header", "(", "self", ",", "header", ")", ":", "\n", "    ", "print", "(", "f'********************** {header} ************************'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print_tabbed_table": [[141, 145], ["reporters.Report.print"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "def", "print_tabbed_table", "(", "self", ",", "tab", ")", ":", "\n", "    ", "for", "x", "in", "tab", ":", "\n", "      ", "print", "(", "'\\t'", ".", "join", "(", "[", "fmt", "(", "y", ",", "latex", "=", "False", ")", "if", "y", "else", "''", "for", "y", "in", "x", "]", ")", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.generate_report": [[146, 148], ["reporters.Report.print"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "def", "generate_report", "(", "self", ",", "output_fig_file", "=", "None", ",", "output_fig_format", "=", "None", ",", "output_directory", "=", "None", ")", ":", "\n", "    ", "self", ".", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.__init__": [[150, 161], ["scorer.name", "compare_mt.formatting.fmt", "zip", "reporters.next_fig_id", "scorer.idstr", "compare_mt.formatting.fmt"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.next_fig_id", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.idstr"], ["  ", "def", "__init__", "(", "self", ",", "scorer", ",", "scores", ",", "strs", ",", "\n", "wins", "=", "None", ",", "sys_stats", "=", "None", ",", "prob_thresh", "=", "0.05", ",", "\n", "title", "=", "None", ")", ":", "\n", "    ", "self", ".", "scorer", "=", "scorer", "\n", "self", ".", "scores", "=", "scores", "\n", "self", ".", "strs", "=", "[", "f'{fmt(x)} ({y})'", "if", "y", "else", "fmt", "(", "x", ")", "for", "(", "x", ",", "y", ")", "in", "zip", "(", "scores", ",", "strs", ")", "]", "\n", "self", ".", "wins", "=", "wins", "\n", "self", ".", "sys_stats", "=", "sys_stats", "\n", "self", ".", "output_fig_file", "=", "f'{next_fig_id()}-score-{scorer.idstr()}'", "\n", "self", ".", "prob_thresh", "=", "prob_thresh", "\n", "self", ".", "title", "=", "scorer", ".", "name", "(", ")", "if", "not", "title", "else", "title", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.winstr_pval": [[162, 171], ["None"], "methods", ["None"], ["", "def", "winstr_pval", "(", "self", ",", "my_wins", ")", ":", "\n", "    ", "if", "1", "-", "my_wins", "[", "0", "]", "<", "self", ".", "prob_thresh", ":", "\n", "      ", "winstr", "=", "'s1>s2'", "\n", "", "elif", "1", "-", "my_wins", "[", "1", "]", "<", "self", ".", "prob_thresh", ":", "\n", "      ", "winstr", "=", "'s2>s1'", "\n", "", "else", ":", "\n", "      ", "winstr", "=", "'-'", "\n", "", "pval", "=", "1", "-", "(", "my_wins", "[", "0", "]", "if", "my_wins", "[", "0", "]", ">", "my_wins", "[", "1", "]", "else", "my_wins", "[", "1", "]", ")", "\n", "return", "winstr", ",", "pval", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.scores_to_tables": [[172, 200], ["len", "len", "reporters.ScoreReport.winstr_pval", "range", "wptable.append", "reporters.ScoreReport.winstr_pval", "reporters.ScoreReport.scorer.name", "len", "reporters.ScoreReport.scorer.name", "compare_mt.formatting.fmt", "range", "reporters.ScoreReport.scorer.name", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt", "reporters.ScoreReport.scorer.name", "len", "len", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.winstr_pval", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.winstr_pval", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["", "def", "scores_to_tables", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "wins", "is", "None", ":", "\n", "# Single table with just scores", "\n", "      ", "return", "[", "[", "\"\"", "]", "+", "sys_names", ",", "[", "self", ".", "scorer", ".", "name", "(", ")", "]", "+", "self", ".", "strs", "]", ",", "None", "\n", "", "elif", "len", "(", "self", ".", "scores", ")", "==", "1", ":", "\n", "# Single table with scores for one system", "\n", "      ", "return", "[", "\n", "[", "\"\"", "]", "+", "sys_names", ",", "\n", "[", "self", ".", "scorer", ".", "name", "(", ")", "]", "+", "self", ".", "strs", ",", "\n", "[", "\"\"", "]", "+", "[", "f'[{fmt(x[\"lower_bound\"])},{fmt(x[\"upper_bound\"])}]'", "for", "x", "in", "self", ".", "sys_stats", "]", "\n", "]", ",", "None", "\n", "", "elif", "len", "(", "self", ".", "scores", ")", "==", "2", ":", "\n", "# Single table with scores and wins for two systems", "\n", "      ", "winstr", ",", "pval", "=", "self", ".", "winstr_pval", "(", "self", ".", "wins", "[", "0", "]", "[", "1", "]", ")", "\n", "return", "[", "\n", "[", "\"\"", "]", "+", "sys_names", "+", "[", "\"Win?\"", "]", ",", "\n", "[", "self", ".", "scorer", ".", "name", "(", ")", "]", "+", "self", ".", "strs", "+", "[", "winstr", "]", ",", "\n", "[", "\"\"", "]", "+", "[", "f'[{fmt(x[\"lower_bound\"])},{fmt(x[\"upper_bound\"])}]'", "for", "x", "in", "self", ".", "sys_stats", "]", "+", "[", "f'p={fmt(pval)}'", "]", "\n", "]", ",", "None", "\n", "", "else", ":", "\n", "# Table with scores, and separate one with wins for multiple systems", "\n", "      ", "wptable", "=", "[", "[", "'v s1 / s2 ->'", "]", "+", "[", "sys_names", "[", "i", "]", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "scores", ")", ")", "]", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "self", ".", "scores", ")", "-", "1", ")", ":", "\n", "        ", "wptable", ".", "append", "(", "[", "sys_names", "[", "i", "]", "]", "+", "[", "\"\"", "]", "*", "(", "len", "(", "self", ".", "scores", ")", "-", "1", ")", ")", "\n", "", "for", "(", "left", ",", "right", ")", ",", "my_wins", "in", "self", ".", "wins", ":", "\n", "        ", "winstr", ",", "pval", "=", "self", ".", "winstr_pval", "(", "my_wins", ")", "\n", "wptable", "[", "left", "+", "1", "]", "[", "right", "]", "=", "f'{winstr} (p={fmt(pval)})'", "\n", "", "return", "[", "[", "\"\"", "]", "+", "sys_names", ",", "[", "self", ".", "scorer", ".", "name", "(", ")", "]", "+", "self", ".", "strs", "]", ",", "wptable", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.print": [[201, 208], ["reporters.ScoreReport.scores_to_tables", "reporters.ScoreReport.print_header", "reporters.ScoreReport.print"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.scores_to_tables", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print_header", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "", "def", "print", "(", "self", ")", ":", "\n", "    ", "aggregate_table", ",", "win_table", "=", "self", ".", "scores_to_tables", "(", ")", "\n", "self", ".", "print_header", "(", "'Aggregate Scores'", ")", "\n", "print", "(", "f'{self.title}:'", ")", "\n", "self", ".", "print_tabbed_table", "(", "aggregate_table", ")", "\n", "if", "win_table", ":", "\n", "      ", "self", ".", "print_tabbed_table", "(", "win_table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.plot": [[209, 222], ["reporters.make_bar_chart", "numpy.array", "reporters.ScoreReport.scorer.name", "zip"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.make_bar_chart", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["", "", "def", "plot", "(", "self", ",", "output_directory", ",", "output_fig_file", ",", "output_fig_format", "=", "'pdf'", ")", ":", "\n", "    ", "sys", "=", "[", "[", "score", "]", "for", "score", "in", "self", ".", "scores", "]", "\n", "if", "self", ".", "wins", ":", "\n", "      ", "sys_errs", "=", "[", "np", ".", "array", "(", "[", "[", "score", "-", "stat", "[", "'lower_bound'", "]", "]", ",", "[", "stat", "[", "'upper_bound'", "]", "-", "score", "]", "]", ")", "for", "(", "score", ",", "stat", ")", "in", "zip", "(", "self", ".", "scores", ",", "self", ".", "sys_stats", ")", "]", "\n", "", "else", ":", "\n", "      ", "sys_errs", "=", "None", "\n", "", "xticklabels", "=", "None", "\n", "\n", "make_bar_chart", "(", "sys", ",", "\n", "output_directory", ",", "output_fig_file", ",", "\n", "output_fig_format", "=", "output_fig_format", ",", "\n", "errs", "=", "sys_errs", ",", "ylabel", "=", "self", ".", "scorer", ".", "name", "(", ")", ",", "\n", "xticklabels", "=", "xticklabels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.html_content": [[223, 232], ["reporters.ScoreReport.scores_to_tables", "reporters.html_table", "reporters.html_img_reference", "reporters.html_table", "reporters.ScoreReport.plot", "reporters.ScoreReport.scorer.name"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.ScoreReport.scores_to_tables", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_img_reference", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.plot", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["", "def", "html_content", "(", "self", ",", "output_directory", ")", ":", "\n", "    ", "aggregate_table", ",", "win_table", "=", "self", ".", "scores_to_tables", "(", ")", "\n", "html", "=", "html_table", "(", "aggregate_table", ",", "title", "=", "self", ".", "title", ")", "\n", "if", "win_table", ":", "\n", "      ", "html", "+=", "html_table", "(", "win_table", ",", "title", "=", "f'{self.scorer.name()} Wins'", ")", "\n", "", "for", "ext", "in", "(", "'png'", ",", "'pdf'", ")", ":", "\n", "      ", "self", ".", "plot", "(", "output_directory", ",", "self", ".", "output_fig_file", ",", "ext", ")", "\n", "", "html", "+=", "html_img_reference", "(", "self", ".", "output_fig_file", ",", "'Score Comparison'", ")", "\n", "return", "html", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.__init__": [[234, 261], ["reporters.next_fig_id", "bucketer.name", "bucketer.name"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.next_fig_id", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["  ", "def", "__init__", "(", "self", ",", "bucketer", ",", "statistics", ",", "\n", "acc_type", ",", "header", ",", "\n", "examples", "=", "None", ",", "\n", "bucket_cnts", "=", "None", ",", "\n", "bucket_intervals", "=", "None", ",", "\n", "src_sents", "=", "None", ",", "\n", "ref_sents", "=", "None", ",", "ref_labels", "=", "None", ",", "\n", "out_sents", "=", "None", ",", "out_labels", "=", "None", ",", "\n", "src_labels", "=", "None", ",", "ref_aligns", "=", "None", ",", "\n", "title", "=", "None", ")", ":", "\n", "    ", "self", ".", "bucketer", "=", "bucketer", "\n", "self", ".", "statistics", "=", "[", "[", "s", "for", "s", "in", "stat", "]", "for", "stat", "in", "statistics", "]", "\n", "self", ".", "examples", "=", "examples", "\n", "self", ".", "bucket_cnts", "=", "bucket_cnts", "\n", "self", ".", "bucket_intervals", "=", "bucket_intervals", "\n", "self", ".", "src_sents", "=", "src_sents", "\n", "self", ".", "ref_sents", "=", "ref_sents", "\n", "self", ".", "ref_labels", "=", "ref_labels", "\n", "self", ".", "out_sents", "=", "out_sents", "\n", "self", ".", "out_labels", "=", "out_labels", "\n", "self", ".", "src_labels", "=", "src_labels", "\n", "self", ".", "ref_aligns", "=", "ref_aligns", "\n", "self", ".", "acc_type", "=", "acc_type", "\n", "self", ".", "header", "=", "header", "\n", "self", ".", "acc_type_map", "=", "{", "'prec'", ":", "3", ",", "'rec'", ":", "4", ",", "'fmeas'", ":", "5", "}", "\n", "self", ".", "output_fig_file", "=", "f'{next_fig_id()}-wordacc-{bucketer.name()}'", "\n", "self", ".", "title", "=", "title", "if", "title", "else", "f'word {acc_type} by {bucketer.name()} bucket'", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.print": [[262, 291], ["reporters.WordReport.print_header", "acc_type.split", "reporters.WordReport.print"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print_header", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "def", "print", "(", "self", ")", ":", "\n", "    ", "acc_type_map", "=", "self", ".", "acc_type_map", "\n", "bucketer", ",", "statistics", ",", "acc_type", ",", "header", "=", "self", ".", "bucketer", ",", "self", ".", "statistics", ",", "self", ".", "acc_type", ",", "self", ".", "header", "\n", "self", ".", "print_header", "(", "header", ")", "\n", "acc_types", "=", "acc_type", ".", "split", "(", "'+'", ")", "\n", "for", "at", "in", "acc_types", ":", "\n", "      ", "if", "at", "not", "in", "acc_type_map", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unknown accuracy type {at}'", ")", "\n", "", "aid", "=", "acc_type_map", "[", "at", "]", "\n", "print", "(", "f'--- {self.title}'", ")", "\n", "# first line", "\n", "print", "(", "f'{bucketer.name()}'", ",", "end", "=", "''", ")", "\n", "if", "self", ".", "bucket_cnts", "is", "not", "None", ":", "\n", "        ", "print", "(", "f'\\t# words'", ",", "end", "=", "''", ")", "\n", "", "for", "sn", "in", "sys_names", ":", "\n", "        ", "print", "(", "f'\\t{sn}'", ",", "end", "=", "''", ")", "\n", "", "print", "(", ")", "\n", "# stats", "\n", "for", "i", ",", "bucket_str", "in", "enumerate", "(", "bucketer", ".", "bucket_strs", ")", ":", "\n", "        ", "print", "(", "f'{bucket_str}'", ",", "end", "=", "''", ")", "\n", "if", "self", ".", "bucket_cnts", "is", "not", "None", ":", "\n", "          ", "print", "(", "f'\\t{self.bucket_cnts[i]}'", ",", "end", "=", "''", ")", "\n", "", "for", "j", ",", "match", "in", "enumerate", "(", "statistics", ")", ":", "\n", "          ", "print", "(", "f'\\t{fmt(match[i][aid])}'", ",", "end", "=", "''", ")", "\n", "if", "self", ".", "bucket_intervals", "is", "not", "None", ":", "\n", "            ", "low", ",", "up", "=", "self", ".", "bucket_intervals", "[", "j", "]", "[", "i", "]", "[", "aid", "]", "\n", "print", "(", "f' [{fmt(low)}, {fmt(up)}]'", ",", "end", "=", "''", ")", "\n", "", "", "print", "(", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.plot": [[292, 319], ["reporters.WordReport.acc_type.split", "reporters.make_bar_chart", "ValueError", "enumerate", "enumerate", "errs.append", "reporters.WordReport.bucketer.name", "lows.append", "ups.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.make_bar_chart", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["", "", "def", "plot", "(", "self", ",", "output_directory", ",", "output_fig_file", ",", "output_fig_format", "=", "'pdf'", ")", ":", "\n", "    ", "acc_types", "=", "self", ".", "acc_type", ".", "split", "(", "'+'", ")", "\n", "for", "at", "in", "acc_types", ":", "\n", "      ", "if", "at", "not", "in", "self", ".", "acc_type_map", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unknown accuracy type {at}'", ")", "\n", "", "aid", "=", "self", ".", "acc_type_map", "[", "at", "]", "\n", "sys", "=", "[", "[", "m", "[", "aid", "]", "for", "m", "in", "match", "]", "for", "match", "in", "self", ".", "statistics", "]", "\n", "xticklabels", "=", "[", "s", "for", "s", "in", "self", ".", "bucketer", ".", "bucket_strs", "]", "\n", "\n", "if", "self", ".", "bucket_intervals", ":", "\n", "        ", "errs", "=", "[", "]", "\n", "for", "i", ",", "match", "in", "enumerate", "(", "sys", ")", ":", "\n", "          ", "lows", ",", "ups", "=", "[", "]", ",", "[", "]", "\n", "for", "j", ",", "score", "in", "enumerate", "(", "match", ")", ":", "\n", "            ", "low", ",", "up", "=", "self", ".", "bucket_intervals", "[", "i", "]", "[", "j", "]", "[", "aid", "]", "\n", "lows", ".", "append", "(", "score", "-", "low", ")", "\n", "ups", ".", "append", "(", "up", "-", "score", ")", "\n", "", "errs", ".", "append", "(", "np", ".", "array", "(", "[", "lows", ",", "ups", "]", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "errs", "=", "None", "\n", "\n", "", "make_bar_chart", "(", "sys", ",", "\n", "output_directory", ",", "output_fig_file", ",", "\n", "output_fig_format", "=", "output_fig_format", ",", "\n", "errs", "=", "errs", ",", "\n", "xlabel", "=", "self", ".", "bucketer", ".", "name", "(", ")", ",", "ylabel", "=", "at", ",", "\n", "xticklabels", "=", "xticklabels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.highlight_words": [[320, 324], ["zip"], "methods", ["None"], ["", "", "def", "highlight_words", "(", "self", ",", "sent", ",", "hls", "=", "None", ")", ":", "\n", "    ", "if", "not", "hls", ":", "\n", "      ", "return", "' '", ".", "join", "(", "sent", ")", "\n", "", "return", "' '", ".", "join", "(", "[", "f'<em>{w}</em>'", "if", "hl", "else", "w", "for", "(", "w", ",", "hl", ")", "in", "zip", "(", "sent", ",", "hls", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.write_examples": [[325, 371], ["enumerate", "reporters.tag_str", "open", "example_stream.write", "reporters.tag_str", "reporters.styled_html_message", "len", "table.append", "itertools.zip_longest", "reporters.html_table", "reporters.WordReport.bucketer._calc_src_buckets_and_matches", "table.append", "reporters.WordReport.bucketer._calc_trg_buckets_and_matches", "table.append", "reporters.WordReport.highlight_words", "reporters.WordReport.highlight_words", "zip", "zip", "reporters.WordReport.highlight_words", "zip"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.styled_html_message", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_src_buckets_and_matches", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_trg_buckets_and_matches", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.highlight_words", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.highlight_words", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.highlight_words"], ["", "def", "write_examples", "(", "self", ",", "title", ",", "output_directory", ")", ":", "\n", "# Create separate examples HTML file", "\n", "    ", "html", "=", "''", "\n", "for", "bi", ",", "bucket_examples", "in", "enumerate", "(", "self", ".", "examples", ")", ":", "\n", "      ", "html", "+=", "f'<a name=\"bucket{bi}\"/>'", "\n", "html", "+=", "tag_str", "(", "'h3'", ",", "f'Examples for Bucket {self.bucketer.bucket_strs[bi]}'", ")", "\n", "for", "tag", ",", "examp_ids", "in", "bucket_examples", ":", "\n", "#  Skip ones with no examples", "\n", "        ", "if", "len", "(", "examp_ids", ")", "==", "0", ":", "\n", "          ", "continue", "\n", "", "html", "+=", "tag_str", "(", "'h4'", ",", "tag", ")", "\n", "for", "eid", "in", "examp_ids", ":", "\n", "          ", "table", "=", "[", "[", "''", ",", "'Output'", "]", "]", "\n", "# Find buckets for the examples if it's on the source side (will have alignments in this case)", "\n", "if", "self", ".", "ref_aligns", ":", "\n", "            ", "_", ",", "_", ",", "_", ",", "src_buckets", ",", "ref_aligns", ",", "ref_matches", "=", "self", ".", "bucketer", ".", "_calc_src_buckets_and_matches", "(", "self", ".", "src_sents", "[", "eid", "]", ",", "\n", "self", ".", "src_labels", "[", "eid", "]", "if", "self", ".", "src_labels", "else", "None", ",", "\n", "self", ".", "ref_sents", "[", "eid", "]", ",", "\n", "self", ".", "ref_aligns", "[", "eid", "]", ",", "\n", "[", "x", "[", "eid", "]", "for", "x", "in", "self", ".", "out_sents", "]", ")", "\n", "src_hls", "=", "[", "x", "==", "bi", "for", "x", "in", "src_buckets", "]", "\n", "table", ".", "append", "(", "[", "'Src'", ",", "self", ".", "highlight_words", "(", "self", ".", "src_sents", "[", "eid", "]", ",", "src_hls", ")", "]", ")", "\n", "ref_hls", "=", "[", "False", "for", "_", "in", "self", ".", "ref_sents", "[", "eid", "]", "]", "\n", "out_hls", "=", "[", "[", "False", "for", "_", "in", "x", "[", "eid", "]", "]", "for", "x", "in", "self", ".", "out_sents", "]", "\n", "for", "sid", ",", "tid", "in", "self", ".", "ref_aligns", "[", "eid", "]", ":", "\n", "              ", "if", "src_hls", "[", "sid", "]", ":", "\n", "                ", "ref_hls", "[", "tid", "]", "=", "True", "\n", "for", "rm", ",", "ohls", "in", "zip", "(", "ref_matches", ",", "out_hls", ")", ":", "\n", "                  ", "if", "rm", "[", "tid", "]", ">=", "0", ":", "\n", "                    ", "ohls", "[", "rm", "[", "tid", "]", "]", "=", "True", "\n", "# Find buckets for the examples if it's on the target side", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "_", ",", "_", ",", "_", ",", "ref_buckets", ",", "out_buckets", ",", "out_matches", "=", "self", ".", "bucketer", ".", "_calc_trg_buckets_and_matches", "(", "self", ".", "ref_sents", "[", "eid", "]", ",", "\n", "self", ".", "ref_labels", "[", "eid", "]", "if", "self", ".", "ref_labels", "else", "None", ",", "\n", "[", "x", "[", "eid", "]", "for", "x", "in", "self", ".", "out_sents", "]", ",", "\n", "[", "x", "[", "eid", "]", "for", "x", "in", "self", ".", "out_labels", "]", "if", "self", ".", "out_labels", "else", "None", ")", "\n", "ref_hls", "=", "[", "x", "==", "bi", "for", "x", "in", "ref_buckets", "]", "\n", "out_hls", "=", "[", "[", "(", "b", "==", "bi", "and", "m", ">=", "0", ")", "for", "(", "b", ",", "m", ")", "in", "zip", "(", "ob", ",", "om", ")", "]", "for", "(", "ob", ",", "om", ")", "in", "zip", "(", "out_buckets", ",", "out_matches", ")", "]", "\n", "", "table", ".", "append", "(", "[", "'Ref'", ",", "self", ".", "highlight_words", "(", "self", ".", "ref_sents", "[", "eid", "]", ",", "ref_hls", ")", "]", ")", "\n", "for", "sn", ",", "oss", ",", "ohl", "in", "itertools", ".", "zip_longest", "(", "sys_names", ",", "self", ".", "out_sents", ",", "out_hls", ")", ":", "\n", "            ", "table", ".", "append", "(", "[", "sn", ",", "self", ".", "highlight_words", "(", "oss", "[", "eid", "]", ",", "ohl", ")", "]", ")", "\n", "", "html", "+=", "html_table", "(", "table", ",", "None", ")", "\n", "", "", "", "with", "open", "(", "f'{output_directory}/{self.output_fig_file}.html'", ",", "'w'", ")", "as", "example_stream", ":", "\n", "      ", "example_stream", ".", "write", "(", "styled_html_message", "(", "title", ",", "html", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.html_content": [[372, 413], ["acc_type.split", "reporters.WordReport.write_examples", "enumerate", "reporters.html_table", "reporters.html_img_reference", "ValueError", "bucketer.name", "line.append", "table[].append", "enumerate", "reporters.WordReport.plot", "bucketer.name", "line.append", "line.append", "line.append", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.WordReport.write_examples", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_img_reference", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.plot", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["", "", "def", "html_content", "(", "self", ",", "output_directory", ")", ":", "\n", "    ", "acc_type_map", "=", "self", ".", "acc_type_map", "\n", "bucketer", ",", "matches", ",", "acc_type", ",", "header", "=", "self", ".", "bucketer", ",", "self", ".", "statistics", ",", "self", ".", "acc_type", ",", "self", ".", "header", "\n", "acc_types", "=", "acc_type", ".", "split", "(", "'+'", ")", "\n", "\n", "title", "=", "f'Word {acc_type} by {bucketer.name()} bucket'", "if", "not", "self", ".", "title", "else", "self", ".", "title", "\n", "\n", "if", "self", ".", "examples", ":", "\n", "      ", "self", ".", "write_examples", "(", "title", ",", "output_directory", ")", "\n", "\n", "# Create main HTML content", "\n", "", "html", "=", "''", "\n", "for", "at", "in", "acc_types", ":", "\n", "      ", "if", "at", "not", "in", "acc_type_map", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unknown accuracy type {at}'", ")", "\n", "", "aid", "=", "acc_type_map", "[", "at", "]", "\n", "line", "=", "[", "bucketer", ".", "name", "(", ")", "]", "\n", "if", "self", ".", "bucket_cnts", "is", "not", "None", ":", "\n", "        ", "line", ".", "append", "(", "'# words'", ")", "\n", "", "line", "+=", "sys_names", "\n", "table", "=", "[", "line", "]", "\n", "if", "self", ".", "examples", ":", "\n", "        ", "table", "[", "0", "]", ".", "append", "(", "'Examples'", ")", "\n", "", "for", "i", ",", "bs", "in", "enumerate", "(", "bucketer", ".", "bucket_strs", ")", ":", "\n", "        ", "line", "=", "[", "bs", "]", "\n", "if", "self", ".", "bucket_cnts", "is", "not", "None", ":", "\n", "          ", "line", ".", "append", "(", "f'{self.bucket_cnts[i]}'", ")", "\n", "", "for", "j", ",", "match", "in", "enumerate", "(", "matches", ")", ":", "\n", "          ", "line", ".", "append", "(", "f'{fmt(match[i][aid])}'", ")", "\n", "if", "self", ".", "bucket_intervals", "is", "not", "None", ":", "\n", "            ", "low", ",", "up", "=", "self", ".", "bucket_intervals", "[", "j", "]", "[", "i", "]", "[", "aid", "]", "\n", "line", "[", "-", "1", "]", "+=", "f'<font size=2> [{fmt(low)}, {fmt(up)}]</font>'", "\n", "", "", "if", "self", ".", "examples", ":", "\n", "          ", "line", ".", "append", "(", "f'<a href=\"{self.output_fig_file}.html#bucket{i}\">Examples</a>'", ")", "\n", "", "table", "+=", "[", "line", "]", "\n", "", "html", "+=", "html_table", "(", "table", ",", "title", ",", "latex_ignore_cols", "=", "{", "3", "}", ")", "\n", "img_name", "=", "f'{self.output_fig_file}-{at}'", "\n", "for", "ext", "in", "(", "'png'", ",", "'pdf'", ")", ":", "\n", "        ", "self", ".", "plot", "(", "output_directory", ",", "img_name", ",", "ext", ")", "\n", "", "html", "+=", "html_img_reference", "(", "img_name", ",", "self", ".", "header", ")", "\n", "", "return", "html", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.NgramReport.__init__": [[415, 427], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "scorelist", ",", "report_length", ",", "min_ngram_length", ",", "max_ngram_length", ",", "\n", "matches", ",", "compare_type", ",", "alpha", ",", "compare_directions", "=", "[", "(", "0", ",", "1", ")", "]", ",", "label_files", "=", "None", ",", "title", "=", "None", ")", ":", "\n", "    ", "self", ".", "scorelist", "=", "scorelist", "\n", "self", ".", "report_length", "=", "report_length", "\n", "self", ".", "min_ngram_length", "=", "min_ngram_length", "\n", "self", ".", "max_ngram_length", "=", "max_ngram_length", "\n", "self", ".", "matches", "=", "matches", "\n", "self", ".", "compare_type", "=", "compare_type", "\n", "self", ".", "label_files", "=", "label_files", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "compare_directions", "=", "compare_directions", "\n", "self", ".", "title", "=", "title", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.NgramReport.print": [[428, 449], ["reporters.NgramReport.print_header", "enumerate", "reporters.NgramReport.print"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print_header", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "def", "print", "(", "self", ")", ":", "\n", "    ", "report_length", "=", "self", ".", "report_length", "\n", "self", ".", "print_header", "(", "'N-gram Difference Analysis'", ")", "\n", "if", "self", ".", "title", ":", "\n", "      ", "print", "(", "f'--- {self.title}'", ")", "\n", "", "else", ":", "\n", "      ", "print", "(", "f'--- min_ngram_length={self.min_ngram_length}, max_ngram_length={self.max_ngram_length}'", ")", "\n", "print", "(", "f'    report_length={report_length}, alpha={self.alpha}, compare_type={self.compare_type}'", ")", "\n", "\n", "", "if", "self", ".", "label_files", "is", "not", "None", ":", "\n", "      ", "print", "(", "self", ".", "label_files", ")", "\n", "\n", "", "for", "i", ",", "(", "left", ",", "right", ")", "in", "enumerate", "(", "self", ".", "compare_directions", ")", ":", "\n", "      ", "print", "(", "f'--- {report_length} n-grams where {sys_names[left]}>{sys_names[right]} in {self.compare_type}'", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "scorelist", "[", "i", "]", "[", ":", "report_length", "]", ":", "\n", "        ", "print", "(", "f\"{' '.join(k)}\\t{fmt(v)} (sys{left+1}={self.matches[left][k]}, sys{right+1}={self.matches[right][k]})\"", ")", "\n", "", "print", "(", ")", "\n", "print", "(", "f'--- {report_length} n-grams where {sys_names[right]}>{sys_names[left]} in {self.compare_type}'", ")", "\n", "for", "k", ",", "v", "in", "reversed", "(", "self", ".", "scorelist", "[", "i", "]", "[", "-", "report_length", ":", "]", ")", ":", "\n", "        ", "print", "(", "f\"{' '.join(k)}\\t{fmt(v)} (sys{left+1}={self.matches[left][k]}, sys{right+1}={self.matches[right][k]})\"", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.NgramReport.plot": [[450, 452], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "plot", "(", "self", ",", "output_directory", ",", "output_fig_file", ",", "output_fig_format", "=", "'pdf'", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "'Plotting is not implemented for n-gram reports'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.NgramReport.html_content": [[453, 474], ["enumerate", "reporters.tag_str", "reporters.tag_str", "reporters.tag_str", "table.extend", "reporters.html_table", "table.extend", "reporters.html_table", "reporters.tag_str", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt", "reversed"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str"], ["", "def", "html_content", "(", "self", ",", "output_directory", "=", "None", ")", ":", "\n", "    ", "report_length", "=", "self", ".", "report_length", "\n", "if", "self", ".", "title", ":", "\n", "      ", "html", "=", "tag_str", "(", "'p'", ",", "self", ".", "title", ")", "\n", "", "else", ":", "\n", "      ", "html", "=", "tag_str", "(", "'p'", ",", "f'min_ngram_length={self.min_ngram_length}, max_ngram_length={self.max_ngram_length}'", ")", "\n", "html", "+=", "tag_str", "(", "'p'", ",", "f'report_length={report_length}, alpha={self.alpha}, compare_type={self.compare_type}'", ")", "\n", "if", "self", ".", "label_files", "is", "not", "None", ":", "\n", "        ", "html", "+=", "tag_str", "(", "'p'", ",", "self", ".", "label_files", ")", "\n", "\n", "", "", "for", "i", ",", "(", "left", ",", "right", ")", "in", "enumerate", "(", "self", ".", "compare_directions", ")", ":", "\n", "      ", "title", "=", "f'{report_length} n-grams where {sys_names[left]}>{sys_names[right]} in {self.compare_type}'", "\n", "table", "=", "[", "[", "'n-gram'", ",", "self", ".", "compare_type", ",", "f'{sys_names[left]}'", ",", "f'{sys_names[right]}'", "]", "]", "\n", "table", ".", "extend", "(", "[", "[", "' '", ".", "join", "(", "k", ")", ",", "fmt", "(", "v", ")", ",", "self", ".", "matches", "[", "left", "]", "[", "k", "]", ",", "self", ".", "matches", "[", "right", "]", "[", "k", "]", "]", "for", "k", ",", "v", "in", "self", ".", "scorelist", "[", "i", "]", "[", ":", "report_length", "]", "]", ")", "\n", "html", "+=", "html_table", "(", "table", ",", "title", ")", "\n", "\n", "title", "=", "f'{report_length} n-grams where {sys_names[right]}>{sys_names[left]} in {self.compare_type}'", "\n", "table", "=", "[", "[", "'n-gram'", ",", "self", ".", "compare_type", ",", "f'{sys_names[left]}'", ",", "f'{sys_names[right]}'", "]", "]", "\n", "table", ".", "extend", "(", "[", "[", "' '", ".", "join", "(", "k", ")", ",", "fmt", "(", "v", ")", ",", "self", ".", "matches", "[", "left", "]", "[", "k", "]", ",", "self", ".", "matches", "[", "right", "]", "[", "k", "]", "]", "for", "k", ",", "v", "in", "reversed", "(", "self", ".", "scorelist", "[", "i", "]", "[", "-", "report_length", ":", "]", ")", "]", ")", "\n", "html", "+=", "html_table", "(", "table", ",", "title", ")", "\n", "", "return", "html", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceReport.__init__": [[477, 493], ["scorer.name", "scorer.idstr", "reporters.next_fig_id", "bucketer.idstr", "bucketer.name", "scorer.name", "bucketer.name"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.idstr", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.next_fig_id", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.idstr", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["  ", "def", "__init__", "(", "self", ",", "bucketer", "=", "None", ",", "sys_stats", "=", "None", ",", "statistic_type", "=", "None", ",", "scorer", "=", "None", ",", "bucket_cnts", "=", "None", ",", "bucket_intervals", "=", "None", ",", "title", "=", "None", ")", ":", "\n", "    ", "self", ".", "bucketer", "=", "bucketer", "\n", "self", ".", "sys_stats", "=", "[", "[", "s", "for", "s", "in", "stat", "]", "for", "stat", "in", "sys_stats", "]", "\n", "self", ".", "statistic_type", "=", "statistic_type", "\n", "self", ".", "scorer", "=", "scorer", "\n", "self", ".", "bucket_cnts", "=", "bucket_cnts", "\n", "self", ".", "bucket_intervals", "=", "bucket_intervals", "\n", "self", ".", "yname", "=", "scorer", ".", "name", "(", ")", "if", "statistic_type", "==", "'score'", "else", "statistic_type", "\n", "self", ".", "yidstr", "=", "scorer", ".", "idstr", "(", ")", "if", "statistic_type", "==", "'score'", "else", "statistic_type", "\n", "self", ".", "output_fig_file", "=", "f'{next_fig_id()}-sent-{bucketer.idstr()}-{self.yidstr}'", "\n", "if", "title", ":", "\n", "      ", "self", ".", "title", "=", "title", "\n", "", "elif", "scorer", ":", "\n", "      ", "self", ".", "title", "=", "f'bucket type: {bucketer.name()}, statistic type: {scorer.name()}'", "\n", "", "else", ":", "\n", "      ", "self", ".", "title", "=", "f'bucket type: {bucketer.name()}, statistic type: {statistic_type}'", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceReport.print": [[494, 516], ["reporters.SentenceReport.print_header", "reporters.SentenceReport.print"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print_header", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "", "def", "print", "(", "self", ")", ":", "\n", "    ", "self", ".", "print_header", "(", "'Sentence Bucket Analysis'", ")", "\n", "print", "(", "f'--- {self.title}'", ")", "\n", "# first line", "\n", "print", "(", "f'{self.bucketer.idstr()}'", ",", "end", "=", "''", ")", "\n", "if", "self", ".", "bucket_cnts", "is", "not", "None", ":", "\n", "      ", "print", "(", "f'\\t# sents'", ",", "end", "=", "''", ")", "\n", "", "for", "sn", "in", "sys_names", ":", "\n", "      ", "print", "(", "f'\\t{sn}'", ",", "end", "=", "''", ")", "\n", "", "print", "(", ")", "\n", "for", "i", ",", "bs", "in", "enumerate", "(", "self", ".", "bucketer", ".", "bucket_strs", ")", ":", "\n", "      ", "print", "(", "f'{bs}'", ",", "end", "=", "''", ")", "\n", "if", "self", ".", "bucket_cnts", "is", "not", "None", ":", "\n", "        ", "print", "(", "f'\\t{self.bucket_cnts[i]}'", ",", "end", "=", "''", ")", "\n", "", "for", "j", ",", "stat", "in", "enumerate", "(", "self", ".", "sys_stats", ")", ":", "\n", "        ", "print", "(", "f'\\t{fmt(stat[i])}'", ",", "end", "=", "''", ")", "\n", "if", "self", ".", "bucket_intervals", "is", "not", "None", ":", "\n", "          ", "interval", "=", "self", ".", "bucket_intervals", "[", "j", "]", "[", "i", "]", "\n", "low", ",", "up", "=", "interval", "[", "'lower_bound'", "]", ",", "interval", "[", "'upper_bound'", "]", "\n", "print", "(", "f' [{fmt(low)}, {fmt(up)}]'", ",", "end", "=", "''", ")", "\n", "", "", "print", "(", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceReport.plot": [[517, 540], ["reporters.make_bar_chart", "enumerate", "enumerate", "errs.append", "reporters.SentenceReport.bucketer.name", "lows.append", "ups.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.make_bar_chart", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["", "def", "plot", "(", "self", ",", "output_directory", "=", "'outputs'", ",", "output_fig_file", "=", "'word-acc'", ",", "output_fig_format", "=", "'pdf'", ")", ":", "\n", "    ", "sys", "=", "self", ".", "sys_stats", "\n", "xticklabels", "=", "[", "s", "for", "s", "in", "self", ".", "bucketer", ".", "bucket_strs", "]", "\n", "\n", "if", "self", ".", "bucket_intervals", ":", "\n", "      ", "errs", "=", "[", "]", "\n", "for", "i", ",", "stat", "in", "enumerate", "(", "sys", ")", ":", "\n", "        ", "lows", ",", "ups", "=", "[", "]", ",", "[", "]", "\n", "for", "j", ",", "score", "in", "enumerate", "(", "stat", ")", ":", "\n", "          ", "interval", "=", "self", ".", "bucket_intervals", "[", "i", "]", "[", "j", "]", "\n", "low", ",", "up", "=", "interval", "[", "'lower_bound'", "]", ",", "interval", "[", "'upper_bound'", "]", "\n", "lows", ".", "append", "(", "score", "-", "low", ")", "\n", "ups", ".", "append", "(", "up", "-", "score", ")", "\n", "", "errs", ".", "append", "(", "np", ".", "array", "(", "[", "lows", ",", "ups", "]", ")", ")", "\n", "", "", "else", ":", "\n", "      ", "errs", "=", "None", "\n", "\n", "", "make_bar_chart", "(", "sys", ",", "\n", "output_directory", ",", "output_fig_file", ",", "\n", "output_fig_format", "=", "output_fig_format", ",", "\n", "errs", "=", "errs", ",", "\n", "xlabel", "=", "self", ".", "bucketer", ".", "name", "(", ")", ",", "ylabel", "=", "self", ".", "yname", ",", "\n", "xticklabels", "=", "xticklabels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceReport.html_content": [[541, 563], ["enumerate", "reporters.html_table", "reporters.html_img_reference", "reporters.SentenceReport.bucketer.idstr", "line.append", "enumerate", "table.extend", "reporters.SentenceReport.plot", "line.append", "line.append", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_img_reference", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.idstr", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.plot"], ["", "def", "html_content", "(", "self", ",", "output_directory", "=", "None", ")", ":", "\n", "    ", "line", "=", "[", "self", ".", "bucketer", ".", "idstr", "(", ")", "]", "\n", "if", "self", ".", "bucket_cnts", "is", "not", "None", ":", "\n", "      ", "line", ".", "append", "(", "'# sents'", ")", "\n", "", "line", "+=", "sys_names", "\n", "table", "=", "[", "line", "]", "\n", "for", "i", ",", "bs", "in", "enumerate", "(", "self", ".", "bucketer", ".", "bucket_strs", ")", ":", "\n", "      ", "line", "=", "[", "bs", "]", "\n", "if", "self", ".", "bucket_cnts", "is", "not", "None", ":", "\n", "        ", "line", ".", "append", "(", "f'\\t{self.bucket_cnts[i]}'", ")", "\n", "", "for", "j", ",", "stat", "in", "enumerate", "(", "self", ".", "sys_stats", ")", ":", "\n", "        ", "line", ".", "append", "(", "fmt", "(", "stat", "[", "i", "]", ")", ")", "\n", "if", "self", ".", "bucket_intervals", "is", "not", "None", ":", "\n", "          ", "interval", "=", "self", ".", "bucket_intervals", "[", "j", "]", "[", "i", "]", "\n", "low", ",", "up", "=", "interval", "[", "'lower_bound'", "]", ",", "interval", "[", "'upper_bound'", "]", "\n", "line", "[", "-", "1", "]", "+=", "f'<font size=2> [{fmt(low)}, {fmt(up)}]</font>'", "\n", "", "", "table", ".", "extend", "(", "[", "line", "]", ")", "\n", "", "html", "=", "html_table", "(", "table", ",", "self", ".", "title", ")", "\n", "for", "ext", "in", "(", "'png'", ",", "'pdf'", ")", ":", "\n", "      ", "self", ".", "plot", "(", "output_directory", ",", "self", ".", "output_fig_file", ",", "ext", ")", "\n", "", "html", "+=", "html_img_reference", "(", "self", ".", "output_fig_file", ",", "'Sentence Bucket Analysis'", ")", "\n", "return", "html", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.__init__": [[566, 575], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "report_length", "=", "None", ",", "scorediff_lists", "=", "None", ",", "scorer", "=", "None", ",", "ref", "=", "None", ",", "outs", "=", "None", ",", "src", "=", "None", ",", "compare_directions", "=", "[", "(", "0", ",", "1", ")", "]", ",", "title", "=", "None", ")", ":", "\n", "    ", "self", ".", "report_length", "=", "report_length", "\n", "self", ".", "scorediff_lists", "=", "scorediff_lists", "\n", "self", ".", "scorer", "=", "scorer", "\n", "self", ".", "ref", "=", "ref", "\n", "self", ".", "outs", "=", "outs", "\n", "self", ".", "src", "=", "src", "\n", "self", ".", "compare_directions", "=", "compare_directions", "\n", "self", ".", "title", "=", "title", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print": [[576, 600], ["reporters.SentenceExampleReport.print_header", "enumerate", "reporters.SentenceExampleReport.print"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.print_header", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print"], ["", "def", "print", "(", "self", ")", ":", "\n", "    ", "self", ".", "print_header", "(", "'Sentence Examples Analysis'", ")", "\n", "report_length", "=", "self", ".", "report_length", "\n", "for", "cnt", ",", "(", "left", ",", "right", ")", "in", "enumerate", "(", "self", ".", "compare_directions", ")", ":", "\n", "      ", "ref", ",", "out1", ",", "out2", "=", "self", ".", "ref", ",", "self", ".", "outs", "[", "left", "]", ",", "self", ".", "outs", "[", "right", "]", "\n", "sleft", ",", "sright", "=", "sys_names", "[", "left", "]", ",", "sys_names", "[", "right", "]", "\n", "print", "(", "f'--- {report_length} sentences where {sleft}>{sright} at {self.scorer.name()}'", ")", "\n", "for", "bdiff", ",", "s1", ",", "s2", ",", "str1", ",", "str2", ",", "i", "in", "self", ".", "scorediff_lists", "[", "cnt", "]", "[", ":", "report_length", "]", ":", "\n", "        ", "print", "(", "f\"{sleft}-{sright}={fmt(-bdiff)}, {sleft}={fmt(s1)}, {sright}={fmt(s2)}\"", ")", "\n", "if", "self", ".", "src", "and", "self", ".", "src", "[", "i", "]", ":", "\n", "          ", "print", "(", "f\"Src:  {' '.join(self.src[i])}\"", ")", "\n", "", "print", "(", "\n", "f\"Ref:  {' '.join(ref[i])}\\n\"", "\n", "f\"{sleft}: {' '.join(out1[i])}\\n\"", "\n", "f\"{sright}: {' '.join(out2[i])}\\n\"", "\n", ")", "\n", "\n", "", "print", "(", "f'--- {report_length} sentences where {sright}>{sleft} at {self.scorer.name()}'", ")", "\n", "for", "bdiff", ",", "s1", ",", "s2", ",", "str1", ",", "str2", ",", "i", "in", "self", ".", "scorediff_lists", "[", "cnt", "]", "[", "-", "report_length", ":", "]", ":", "\n", "        ", "print", "(", "f\"{sleft}-{sright}={fmt(-bdiff)}, {sleft}={fmt(s1)}, {sright}={fmt(s2)}\"", ")", "\n", "if", "self", ".", "src", "and", "self", ".", "src", "[", "i", "]", ":", "\n", "          ", "print", "(", "f\"Src:  {' '.join(self.src[i])}\"", ")", "\n", "", "print", "(", "\n", "f\"Ref:  {' '.join(ref[i])}\\n\"", "\n", "f\"{sleft}: {' '.join(out1[i])}\\n\"", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.plot": [[604, 606], ["None"], "methods", ["None"], ["", "", "", "def", "plot", "(", "self", ",", "output_directory", ",", "output_fig_file", ",", "output_fig_format", "=", "'pdf'", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.html_content": [[607, 639], ["enumerate", "reporters.tag_str", "reporters.tag_str", "reporters.html_table", "reporters.html_table", "table.append", "table.append", "reporters.SentenceExampleReport.scorer.name", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt", "reporters.SentenceExampleReport.scorer.name", "compare_mt.formatting.fmt", "compare_mt.formatting.fmt", "reporters.SentenceExampleReport.scorer.idstr", "reporters.SentenceExampleReport.scorer.idstr"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.idstr", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.idstr"], ["", "def", "html_content", "(", "self", ",", "output_directory", "=", "None", ")", ":", "\n", "    ", "report_length", "=", "self", ".", "report_length", "\n", "for", "cnt", ",", "(", "left", ",", "right", ")", "in", "enumerate", "(", "self", ".", "compare_directions", ")", ":", "\n", "      ", "sleft", ",", "sright", "=", "sys_names", "[", "left", "]", ",", "sys_names", "[", "right", "]", "\n", "ref", ",", "out1", ",", "out2", "=", "self", ".", "ref", ",", "self", ".", "outs", "[", "left", "]", ",", "self", ".", "outs", "[", "right", "]", "\n", "html", "=", "tag_str", "(", "'h4'", ",", "f'{report_length} sentences where {sleft}>{sright} at {self.scorer.name()}'", ")", "\n", "for", "bdiff", ",", "s1", ",", "s2", ",", "str1", ",", "str2", ",", "i", "in", "self", ".", "scorediff_lists", "[", "cnt", "]", "[", ":", "report_length", "]", ":", "\n", "        ", "table", "=", "[", "[", "''", ",", "'Output'", ",", "f'{self.scorer.idstr()}'", "]", "]", "\n", "if", "self", ".", "src", "and", "self", ".", "src", "[", "i", "]", ":", "\n", "          ", "table", ".", "append", "(", "[", "'Src'", ",", "' '", ".", "join", "(", "self", ".", "src", "[", "i", "]", ")", ",", "''", "]", ")", "\n", "", "table", "+=", "[", "\n", "[", "'Ref'", ",", "' '", ".", "join", "(", "ref", "[", "i", "]", ")", ",", "''", "]", ",", "\n", "[", "f'{sleft}'", ",", "' '", ".", "join", "(", "out1", "[", "i", "]", ")", ",", "fmt", "(", "s1", ")", "]", ",", "\n", "[", "f'{sright}'", ",", "' '", ".", "join", "(", "out2", "[", "i", "]", ")", ",", "fmt", "(", "s2", ")", "]", "\n", "]", "\n", "\n", "html", "+=", "html_table", "(", "table", ",", "None", ")", "\n", "\n", "", "html", "+=", "tag_str", "(", "'h4'", ",", "f'{report_length} sentences where {sright}>{sleft} at {self.scorer.name()}'", ")", "\n", "for", "bdiff", ",", "s1", ",", "s2", ",", "str1", ",", "str2", ",", "i", "in", "self", ".", "scorediff_lists", "[", "cnt", "]", "[", "-", "report_length", ":", "]", ":", "\n", "        ", "table", "=", "[", "[", "''", ",", "'Output'", ",", "f'{self.scorer.idstr()}'", "]", "]", "\n", "if", "self", ".", "src", "and", "self", ".", "src", "[", "i", "]", ":", "\n", "          ", "table", ".", "append", "(", "[", "'Src'", ",", "' '", ".", "join", "(", "self", ".", "src", "[", "i", "]", ")", ",", "''", "]", ")", "\n", "", "table", "+=", "[", "\n", "[", "'Ref'", ",", "' '", ".", "join", "(", "ref", "[", "i", "]", ")", ",", "''", "]", ",", "\n", "[", "f'{sleft}'", ",", "' '", ".", "join", "(", "out1", "[", "i", "]", ")", ",", "fmt", "(", "s1", ")", "]", ",", "\n", "[", "f'{sright}'", ",", "' '", ".", "join", "(", "out2", "[", "i", "]", ")", ",", "fmt", "(", "s2", ")", "]", "\n", "]", "\n", "\n", "html", "+=", "html_table", "(", "table", ",", "None", ")", "\n", "\n", "", "", "return", "html", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.next_fig_id": [[74, 78], ["None"], "function", ["None"], ["def", "next_fig_id", "(", ")", ":", "\n", "  ", "global", "fig_counter", "\n", "fig_counter", "+=", "1", "\n", "return", "f'{fig_counter:03d}'", "\n", "", "def", "next_tab_id", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.next_tab_id": [[78, 82], ["None"], "function", ["None"], ["", "def", "next_tab_id", "(", ")", ":", "\n", "  ", "global", "tab_counter", "\n", "tab_counter", "+=", "1", "\n", "return", "f'{tab_counter:03d}'", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.make_bar_chart": [[83, 114], ["matplotlib.pyplot.subplots", "numpy.arange", "enumerate", "ax.legend", "ax.autoscale_view", "os.path.join", "matplotlib.pyplot.savefig", "len", "len", "bars.append", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.set_xticks", "ax.set_xticklabels", "matplotlib.pyplot.xticks", "ax.xaxis.set_visible", "os.path.exists", "os.makedirs", "ax.bar"], "function", ["None"], ["", "def", "make_bar_chart", "(", "datas", ",", "\n", "output_directory", ",", "output_fig_file", ",", "output_fig_format", "=", "'png'", ",", "\n", "errs", "=", "None", ",", "title", "=", "None", ",", "xlabel", "=", "None", ",", "xticklabels", "=", "None", ",", "ylabel", "=", "None", ")", ":", "\n", "  ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "fig_size", ")", "\n", "ind", "=", "np", ".", "arange", "(", "len", "(", "datas", "[", "0", "]", ")", ")", "\n", "width", "=", "0.7", "/", "len", "(", "datas", ")", "\n", "bars", "=", "[", "]", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "datas", ")", ":", "\n", "    ", "err", "=", "errs", "[", "i", "]", "if", "errs", "!=", "None", "else", "None", "\n", "bars", ".", "append", "(", "ax", ".", "bar", "(", "ind", "+", "i", "*", "width", ",", "data", ",", "width", ",", "bottom", "=", "0", ",", "yerr", "=", "err", ")", ")", "\n", "# Set axis/title labels", "\n", "", "if", "title", "is", "not", "None", ":", "\n", "    ", "ax", ".", "set_title", "(", "title", ")", "\n", "", "if", "xlabel", "is", "not", "None", ":", "\n", "    ", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "", "if", "ylabel", "is", "not", "None", ":", "\n", "    ", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "", "if", "xticklabels", "is", "not", "None", ":", "\n", "    ", "ax", ".", "set_xticks", "(", "ind", "+", "width", "/", "2", ")", "\n", "ax", ".", "set_xticklabels", "(", "xticklabels", ")", "\n", "plt", ".", "xticks", "(", "rotation", "=", "70", ")", "\n", "", "else", ":", "\n", "    ", "ax", ".", "xaxis", ".", "set_visible", "(", "False", ")", "\n", "\n", "", "ax", ".", "legend", "(", "bars", ",", "sys_names", ")", "\n", "ax", ".", "autoscale_view", "(", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_directory", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_directory", ")", "\n", "", "out_file", "=", "os", ".", "path", ".", "join", "(", "output_directory", ",", "f'{output_fig_file}.{output_fig_format}'", ")", "\n", "plt", ".", "savefig", "(", "out_file", ",", "format", "=", "output_fig_format", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_img_reference": [[115, 126], ["None"], "function", ["None"], ["", "def", "html_img_reference", "(", "fig_file", ",", "title", ")", ":", "\n", "  ", "latex_code_pieces", "=", "[", "r\"\\begin{figure}[h]\"", ",", "\n", "r\"  \\centering\"", ",", "\n", "r\"  \\includegraphics{\"", "+", "fig_file", "+", "\".pdf}\"", ",", "\n", "r\"  \\caption{\"", "+", "title", "+", "\"}\"", ",", "\n", "r\"  \\label{fig:\"", "+", "fig_file", "+", "\"}\"", ",", "\n", "r\"\\end{figure}\"", "]", "\n", "latex_code", "=", "\"\\n\"", ".", "join", "(", "latex_code_pieces", ")", "\n", "return", "(", "f'<img src=\"{fig_file}.png\" alt=\"{title}\"> <br/>'", "+", "\n", "f'<button onclick=\"showhide(\\'{fig_file}_latex\\')\">Show/Hide LaTeX</button> <br/>'", "+", "\n", "f'<pre id=\"{fig_file}_latex\" style=\"display:none\">{latex_code}</pre>'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str": [[641, 643], ["None"], "function", ["None"], ["", "", "def", "tag_str", "(", "tag", ",", "str", ",", "new_line", "=", "''", ")", ":", "\n", "  ", "return", "f'<{tag}>{new_line} {str} {new_line}</{tag}>'", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.html_table": [[644, 667], ["enumerate", "reporters.next_tab_id", "enumerate", "reporters.tag_str", "reporters.tag_str", "len", "reporters.tag_str", "enumerate", "compare_mt.formatting.fmt", "enumerate"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.next_tab_id", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.tag_str"], ["", "def", "html_table", "(", "table", ",", "title", "=", "None", ",", "bold_rows", "=", "1", ",", "bold_cols", "=", "1", ",", "latex_ignore_cols", "=", "{", "}", ")", ":", "\n", "  ", "html", "=", "'<table border=\"1\">\\n'", "\n", "if", "title", "is", "not", "None", ":", "\n", "    ", "html", "+=", "tag_str", "(", "'caption'", ",", "title", ")", "\n", "", "for", "i", ",", "row", "in", "enumerate", "(", "table", ")", ":", "\n", "    ", "tag_type", "=", "'th'", "if", "(", "i", "<", "bold_rows", ")", "else", "'td'", "\n", "table_row", "=", "'\\n  '", ".", "join", "(", "tag_str", "(", "'th'", "if", "j", "<", "bold_cols", "else", "tag_type", ",", "rdata", ")", "for", "(", "j", ",", "rdata", ")", "in", "enumerate", "(", "row", ")", ")", "\n", "html", "+=", "tag_str", "(", "'tr'", ",", "table_row", ")", "\n", "", "html", "+=", "'\\n</table>\\n <br/>'", "\n", "\n", "tab_id", "=", "next_tab_id", "(", ")", "\n", "latex_code", "=", "\"\\\\begin{table}[t]\\n  \\\\centering\\n\"", "\n", "cs", "=", "[", "'c'", "]", "*", "len", "(", "table", "[", "0", "]", ")", "\n", "if", "bold_cols", "!=", "0", ":", "\n", "    ", "cs", "[", "bold_cols", "-", "1", "]", "=", "'c||'", "\n", "", "latex_code", "+=", "\"  \\\\begin{tabular}{\"", "+", "''", ".", "join", "(", "cs", ")", "+", "\"}\\n\"", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "table", ")", ":", "\n", "    ", "latex_code", "+=", "' & '", ".", "join", "(", "[", "fmt", "(", "x", ")", "for", "c_i", ",", "x", "in", "enumerate", "(", "row", ")", "if", "c_i", "not", "in", "latex_ignore_cols", "]", ")", "+", "(", "' \\\\\\\\\\n'", "if", "i", "!=", "bold_rows", "-", "1", "else", "' \\\\\\\\ \\\\hline \\\\hline\\n'", ")", "\n", "", "latex_code", "+=", "\"  \\\\end{tabular}\\n  \\\\caption{Caption}\\n  \\\\label{tab:table\"", "+", "tab_id", "+", "\"}\\n\\\\end{table}\"", "\n", "\n", "html", "+=", "(", "f'<button onclick=\"showhide(\\'{tab_id}_latex\\')\">Show/Hide LaTeX</button> <br/>'", "+", "\n", "f'<pre id=\"{tab_id}_latex\" style=\"display:none\">{latex_code}</pre>'", ")", "\n", "return", "html", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.styled_html_message": [[668, 673], ["content.encode().decode.encode().decode", "content.encode().decode.encode"], "function", ["None"], ["", "def", "styled_html_message", "(", "report_title", ",", "content", ")", ":", "\n", "  ", "content", "=", "content", ".", "encode", "(", "\"ascii\"", ",", "\"xmlcharrefreplace\"", ")", ".", "decode", "(", ")", "\n", "return", "(", "f'<html>\\n<head>\\n<link rel=\"stylesheet\" href=\"compare_mt.css\">\\n</head>\\n'", "+", "\n", "f'<script>\\n{javascript_style}\\n</script>\\n'", "+", "\n", "f'<body>\\n<h1>{report_title}</h1>\\n {content} \\n</body>\\n</html>'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.generate_html_report": [[674, 690], ["os.path.join", "os.path.join", "content.append", "os.path.exists", "os.makedirs", "open", "f.write", "open", "f.write", "content.append", "reporters.styled_html_message", "r.html_content"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.styled_html_message", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.html_content"], ["", "def", "generate_html_report", "(", "reports", ",", "output_directory", ",", "report_title", ")", ":", "\n", "  ", "content", "=", "[", "]", "\n", "for", "name", ",", "rep", "in", "reports", ":", "\n", "    ", "content", ".", "append", "(", "f'<h2>{name}</h2>'", ")", "\n", "for", "r", "in", "rep", ":", "\n", "      ", "content", ".", "append", "(", "r", ".", "html_content", "(", "output_directory", ")", ")", "\n", "", "", "content", "=", "\"\\n\"", ".", "join", "(", "content", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_directory", ")", "\n", "", "html_file", "=", "os", ".", "path", ".", "join", "(", "output_directory", ",", "'index.html'", ")", "\n", "with", "open", "(", "html_file", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "styled_html_message", "(", "report_title", ",", "content", ")", ")", "\n", "", "css_file", "=", "os", ".", "path", ".", "join", "(", "output_directory", ",", "'compare_mt.css'", ")", "\n", "with", "open", "(", "css_file", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "css_style", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.launch_http_server": [[691, 703], ["pathlib.Path().is_dir", "logging.info", "logging.info", "functools.partial", "http.server.HTTPServer", "socket.gethostname", "http.server.HTTPServer.serve_forever", "pathlib.Path"], "function", ["None"], ["", "", "def", "launch_http_server", "(", "output_directory", ":", "str", ",", "bind_address", ":", "str", "=", "'0.0.0.0'", ",", "bind_port", ":", "int", "=", "8000", ")", ":", "\n", "  ", "assert", "Path", "(", "output_directory", ")", ".", "is_dir", "(", ")", "\n", "hostname", "=", "bind_address", "if", "bind_address", "!=", "'0.0.0.0'", "else", "socket", ".", "gethostname", "(", ")", "\n", "log", ".", "info", "(", "f'Directory = {output_directory}'", ")", "\n", "log", ".", "info", "(", "f'Launching a web server:: http://{hostname}:{bind_port}/'", ")", "\n", "Handler", "=", "partial", "(", "SimpleHTTPRequestHandler", ",", "directory", "=", "output_directory", ")", "\n", "server", "=", "HTTPServer", "(", "server_address", "=", "(", "bind_address", ",", "bind_port", ")", ",", "\n", "RequestHandlerClass", "=", "Handler", ")", "\n", "try", ":", "\n", "    ", "server", ".", "serve_forever", "(", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "    ", "pass", "# all good! Exiting without printing stacktrace", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.Scorer.scale": [[23, 26], ["None"], "methods", ["None"], ["  ", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.Scorer.score_corpus": [[27, 29], ["None"], "methods", ["None"], ["", "def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.Scorer.score_sentence": [[30, 32], ["None"], "methods", ["None"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.Scorer.cache_stats": [[33, 35], ["None"], "methods", ["None"], ["", "def", "cache_stats", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.Scorer.name": [[36, 41], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    A name that can have spaces that describes the scorer.\n    \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.Scorer.idstr": [[42, 47], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    An ID string that contains no spaces but identifies the scorer.\n    \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SentenceFactoredScorer.score_corpus": [[49, 68], ["zip", "len", "scorers.SentenceFactoredScorer.score_sentence", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["  ", "def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using the average of the score\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source corpus. Might be ignored or required \n        depending on the metric\n    Returns:\n      A tuple containing a single value for the average score, and None\n    \"\"\"", "\n", "if", "len", "(", "ref", ")", "==", "0", ":", "\n", "      ", "return", "0.0", ",", "None", "\n", "", "score_sum", "=", "0", "\n", "src", "=", "[", "None", "for", "_", "in", "ref", "]", "if", "src", "is", "None", "else", "src", "\n", "for", "r", ",", "o", ",", "s", "in", "zip", "(", "ref", ",", "out", ",", "src", ")", ":", "\n", "      ", "score_sum", "+=", "self", ".", "score_sentence", "(", "r", ",", "o", ",", "s", ")", "[", "0", "]", "\n", "", "return", "score_sum", "/", "len", "(", "ref", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SentenceFactoredScorer.cache_stats": [[69, 91], ["zip", "hasattr", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "cached_scores.append", "scorers.SentenceFactoredScorer.score_sentence"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "cache_stats", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Cache sufficient statistics for caculating scores\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source corpus. Might be ignored or required \n        depending on the metric\n    Returns:\n      A tuple of cached statistics\n    \"\"\"", "\n", "if", "hasattr", "(", "self", ",", "'case_insensitive'", ")", "and", "self", ".", "case_insensitive", ":", "\n", "      ", "ref", "=", "corpus_utils", ".", "lower", "(", "ref", ")", "\n", "out", "=", "corpus_utils", ".", "lower", "(", "out", ")", "\n", "\n", "", "cached_scores", "=", "[", "]", "\n", "src", "=", "[", "None", "for", "_", "in", "ref", "]", "if", "src", "is", "None", "else", "src", "\n", "for", "r", ",", "o", ",", "s", "in", "zip", "(", "ref", ",", "out", ",", "src", ")", ":", "\n", "      ", "cached_scores", ".", "append", "(", "self", ".", "score_sentence", "(", "r", ",", "o", ",", "s", ")", "[", "0", "]", ")", "\n", "\n", "", "return", "cached_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SentenceFactoredScorer.score_cached_corpus": [[92, 105], ["numpy.array", "numpy.mean"], "methods", ["None"], ["", "def", "score_cached_corpus", "(", "self", ",", "sent_ids", ",", "cached_stats", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus with cache\n\n    Args:\n      sent_ids: The sentence ids for reference and output corpora\n      cached_stats: A tuple of cached statistics\n\n    Returns:\n      A tuple containing a single value for the score and a string summarizing auxiliary information\n    \"\"\"", "\n", "cached_stats", "=", "np", ".", "array", "(", "cached_stats", ")", "\n", "return", "np", ".", "mean", "(", "cached_stats", "[", "sent_ids", "]", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer.__init__": [[110, 113], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "weights", "=", "(", "0.25", ",", "0.25", ",", "0.25", ",", "0.25", ")", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "weights", "=", "weights", "\n", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer.scale": [[114, 117], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer.score_corpus": [[118, 132], ["scorers.BleuScorer.cache_stats", "scorers.BleuScorer.score_cached_corpus", "range", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus"], ["", "def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using BLEU score\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source courpus. Ignored if passed\n\n    Returns:\n      A tuple containing a single value for the BLEU score and a string summarizing auxiliary information\n    \"\"\"", "\n", "cached_stats", "=", "self", ".", "cache_stats", "(", "ref", ",", "out", ")", "\n", "return", "self", ".", "score_cached_corpus", "(", "range", "(", "len", "(", "ref", ")", ")", ",", "cached_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer.score_sentence": [[133, 135], ["NotImplementedError"], "methods", ["None"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"Sentence-level calculation is not implemented in BleuScorer as it is usually 0.\"", "\n", "\"Consider using SentenceBleuScorer (string sentbleu) instead.\"", ")", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer._precision": [[137, 161], ["compare_mt.ngram_utils.sent_ngrams_list", "compare_mt.ngram_utils.sent_ngrams_list", "collections.Counter", "collections.Counter", "collections.Counter.items", "max", "min"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.sent_ngrams_list", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.sent_ngrams_list"], ["", "def", "_precision", "(", "self", ",", "ref", ",", "out", ",", "n", ")", ":", "\n", "    ", "\"\"\"\n    Caculate n-gram precision \n\n    Args:\n      ref: A reference sentence\n      out: An output sentence\n\n    Returns:\n      Numerator and denominator of the precision\n    \"\"\"", "\n", "out_ngram", "=", "ngram_utils", ".", "sent_ngrams_list", "(", "out", ",", "n", ")", "\n", "ref_ngram", "=", "ngram_utils", ".", "sent_ngrams_list", "(", "ref", ",", "n", ")", "\n", "out_cnt", "=", "Counter", "(", "out_ngram", ")", "\n", "ref_cnt", "=", "Counter", "(", "ref_ngram", ")", "\n", "\n", "num", "=", "0", "\n", "denom", "=", "0", "\n", "for", "ngram", ",", "o_cnt", "in", "out_cnt", ".", "items", "(", ")", ":", "\n", "      ", "num", "+=", "min", "(", "o_cnt", ",", "ref_cnt", "[", "ngram", "]", ")", "\n", "denom", "+=", "o_cnt", "\n", "", "denom", "=", "max", "(", "1", ",", "denom", ")", "\n", "\n", "return", "num", ",", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer.cache_stats": [[162, 187], ["zip", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "range", "cached_stats.append", "prec.append", "len", "scorers.BleuScorer._precision", "len", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer._precision"], ["", "def", "cache_stats", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Cache sufficient statistics for caculating BLEU score\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source courpus. Ignored if passed\n\n    Returns:\n      A list of cached statistics\n    \"\"\"", "\n", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "ref", "=", "corpus_utils", ".", "lower", "(", "ref", ")", "\n", "out", "=", "corpus_utils", ".", "lower", "(", "out", ")", "\n", "\n", "", "cached_stats", "=", "[", "]", "\n", "\n", "for", "r", ",", "o", "in", "zip", "(", "ref", ",", "out", ")", ":", "\n", "      ", "prec", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "1", ",", "len", "(", "self", ".", "weights", ")", "+", "1", ")", ":", "\n", "        ", "prec", ".", "append", "(", "self", ".", "_precision", "(", "r", ",", "o", ",", "n", ")", ")", "\n", "", "cached_stats", ".", "append", "(", "(", "len", "(", "r", ")", ",", "len", "(", "o", ")", ",", "prec", ")", ")", "\n", "\n", "", "return", "cached_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer.score_cached_corpus": [[188, 229], ["zip", "collections.Counter", "collections.Counter", "enumerate", "len", "range", "min", "math.log", "math.exp", "math.exp", "len"], "methods", ["None"], ["", "def", "score_cached_corpus", "(", "self", ",", "sent_ids", ",", "cached_stats", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using BLEU score with cache\n\n    Args:\n      sent_ids: The sentence ids for reference and output corpora\n      cached_stats: A list of cached statistics\n\n    Returns:\n      A tuple containing a single value for the BLEU score and a string summarizing auxiliary information\n    \"\"\"", "\n", "if", "len", "(", "cached_stats", ")", "==", "0", ":", "\n", "      ", "return", "0.0", ",", "None", "\n", "\n", "", "cached_ref_len", ",", "cached_out_len", ",", "cached_prec", "=", "zip", "(", "*", "cached_stats", ")", "\n", "\n", "num_prec", "=", "Counter", "(", ")", "\n", "denom_prec", "=", "Counter", "(", ")", "\n", "\n", "ref_len", "=", "0", "\n", "out_len", "=", "0", "\n", "for", "sent_id", "in", "sent_ids", ":", "\n", "      ", "ref_len", "+=", "cached_ref_len", "[", "sent_id", "]", "\n", "out_len", "+=", "cached_out_len", "[", "sent_id", "]", "\n", "for", "n", "in", "range", "(", "1", ",", "len", "(", "self", ".", "weights", ")", "+", "1", ")", ":", "\n", "        ", "num", ",", "denom", "=", "cached_prec", "[", "sent_id", "]", "[", "n", "-", "1", "]", "\n", "num_prec", "[", "n", "]", "+=", "num", "\n", "denom_prec", "[", "n", "]", "+=", "denom", "\n", "\n", "", "", "if", "num_prec", "[", "1", "]", "==", "0", ":", "\n", "      ", "return", "0", ",", "None", "\n", "\n", "", "prec", "=", "0", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "weights", ",", "start", "=", "1", ")", ":", "\n", "      ", "p", "=", "num_prec", "[", "i", "]", "/", "denom_prec", "[", "i", "]", "if", "denom_prec", "[", "i", "]", "!=", "0", "else", "0", "\n", "p", "=", "math", ".", "log", "(", "p", ")", "if", "p", ">", "0", "else", "0", "\n", "prec", "+=", "p", "*", "w", "\n", "\n", "", "bp", "=", "min", "(", "1", ",", "math", ".", "exp", "(", "1", "-", "ref_len", "/", "out_len", ")", ")", "if", "out_len", "!=", "0", "else", "0", "\n", "\n", "return", "self", ".", "scale", "*", "bp", "*", "math", ".", "exp", "(", "prec", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer.name": [[230, 232], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"BLEU\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.BleuScorer.idstr": [[233, 235], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"bleu\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SentBleuScorer.__init__": [[240, 242], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SentBleuScorer.scale": [[243, 246], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SentBleuScorer.score_sentence": [[247, 265], ["nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.sentence_bleu", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a single sentence with sentence-level smoothed BLEU score\n\n    Args:\n      ref: A reference sentence\n      out: An output sentence\n      src: A source sentence. Ignored if passed\n\n    Returns:\n      The sentence-level BLEU score, and None\n    \"\"\"", "\n", "chencherry", "=", "nltk", ".", "translate", ".", "bleu_score", ".", "SmoothingFunction", "(", ")", "\n", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "bleu_score", "=", "nltk", ".", "translate", ".", "bleu_score", ".", "sentence_bleu", "(", "[", "corpus_utils", ".", "lower", "(", "ref", ")", "]", ",", "corpus_utils", ".", "lower", "(", "out", ")", ",", "smoothing_function", "=", "chencherry", ".", "method2", ")", "\n", "", "else", ":", "\n", "      ", "bleu_score", "=", "nltk", ".", "translate", ".", "bleu_score", ".", "sentence_bleu", "(", "[", "ref", "]", ",", "out", ",", "smoothing_function", "=", "chencherry", ".", "method2", ")", "\n", "", "return", "self", ".", "scale", "*", "bleu_score", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SentBleuScorer.name": [[266, 268], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"sentence-level BLEU\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SentBleuScorer.idstr": [[269, 271], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"sentbleu\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.LengthScorer.score_corpus": [[276, 293], ["sum", "sum", "len", "len"], "methods", ["None"], ["def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the length ratio for a corpus\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source courpus. Ignored if passed\n\n    Returns:\n      A tuple containing a single value for the length ratio and a string summarizing auxiliary information\n    \"\"\"", "\n", "ref_words", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "ref", "]", ")", "\n", "out_words", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "out", "]", ")", "\n", "if", "ref_words", "==", "0", ":", "\n", "      ", "return", "0.0", ",", "f'ref={ref_words}, out={out_words}'", "\n", "", "return", "self", ".", "scale", "*", "out_words", "/", "ref_words", ",", "f'ref={ref_words}, out={out_words}'", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.LengthScorer.score_sentence": [[294, 309], ["len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a single sentence by length ratio\n\n    Args:\n      ref: A reference sentence\n      out: An output sentence\n      src: A source sentence. Ignored if passed\n\n    Returns:\n      The length, and a string summarizing the length of the reference and output sentence\n    \"\"\"", "\n", "if", "len", "(", "ref", ")", "==", "0", ":", "\n", "      ", "return", "0.0", ",", "f\"ref={len(ref)}, out={len(out)}\"", "\n", "", "return", "len", "(", "out", ")", "/", "len", "(", "ref", ")", ",", "f\"ref={len(ref)}, out={len(out)}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.LengthScorer.name": [[310, 312], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"length ratio\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.LengthScorer.idstr": [[313, 315], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"lengthrat\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ExactMatchScorer.score_corpus": [[320, 337], ["zip", "float", "len"], "methods", ["None"], ["def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the percentage of exact matches in a corpus\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source courpus. Ignored if passed\n\n    Returns:\n      A tuple containing a single value for the exact match percentage and None\n    \"\"\"", "\n", "matches", "=", "0", "\n", "for", "r", ",", "o", "in", "zip", "(", "ref", ",", "out", ")", ":", "\n", "      ", "if", "r", "==", "o", ":", "\n", "        ", "matches", "+=", "1", "\n", "", "", "return", "float", "(", "matches", ")", "/", "len", "(", "ref", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ExactMatchScorer.score_sentence": [[338, 351], ["None"], "methods", ["None"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a single sentence by exact match\n\n    Args:\n      ref: A reference sentence\n      out: An output sentence\n      src: A source sentence. Ignored if passed\n\n    Returns:\n      1 if exact matches 0, and None\n    \"\"\"", "\n", "return", "1.0", "if", "ref", "==", "out", "else", "0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ExactMatchScorer.name": [[352, 354], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"exact match\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ExactMatchScorer.idstr": [[355, 357], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"exact\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RibesScorer.__init__": [[362, 367], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "order", "=", "-", "1", ",", "alpha", "=", "0.25", ",", "beta", "=", "0.1", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "order", "=", "order", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RibesScorer.scale": [[368, 371], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RibesScorer._kendall_tau_distance": [[372, 391], ["len", "range", "range"], "methods", ["None"], ["", "def", "_kendall_tau_distance", "(", "self", ",", "alignment", ")", ":", "\n", "    ", "\"\"\"\n    Caculate the Kendall's tau distance for RIBES\n\n    Args:\n      alignment: an alignment represented as a list of integers\n\n    Returns:\n      The Kendall's tau distance\n    \"\"\"", "\n", "dis", "=", "0", "\n", "n", "=", "len", "(", "alignment", ")", "\n", "if", "n", "<=", "1", ":", "\n", "      ", "return", "0", "\n", "", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "n", ")", ":", "\n", "        ", "if", "alignment", "[", "j", "]", ">", "alignment", "[", "i", "]", ":", "\n", "          ", "dis", "+=", "1", "\n", "", "", "", "return", "2", "*", "dis", "/", "(", "n", "*", "n", "-", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RibesScorer.score_sentence": [[392, 409], ["compare_mt.align_utils.ngram_context_align", "scorers.RibesScorer._kendall_tau_distance", "min", "len", "len", "len", "len", "math.exp", "len", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.align_utils.ngram_context_align", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RibesScorer._kendall_tau_distance"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a single sentence with RIBES score\n\n    Args:\n      ref: A reference sentence\n      out: An output sentence\n      src: A source sentence. Ignored if passed\n\n    Returns:\n      The RIBES score, and None\n    \"\"\"", "\n", "alignment", "=", "align_utils", ".", "ngram_context_align", "(", "ref", ",", "out", ",", "order", "=", "self", ".", "order", ",", "case_insensitive", "=", "self", ".", "case_insensitive", ")", "\n", "kt_dis", "=", "self", ".", "_kendall_tau_distance", "(", "alignment", ")", "\n", "prec", "=", "len", "(", "alignment", ")", "/", "len", "(", "out", ")", "if", "len", "(", "out", ")", "!=", "0", "else", "0", "\n", "bp", "=", "min", "(", "1", ",", "math", ".", "exp", "(", "1", "-", "len", "(", "ref", ")", "/", "len", "(", "out", ")", ")", ")", "if", "len", "(", "out", ")", "!=", "0", "else", "0", "\n", "return", "self", ".", "scale", "*", "kt_dis", "*", "(", "prec", "**", "self", ".", "alpha", ")", "*", "(", "bp", "**", "self", ".", "beta", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RibesScorer.name": [[410, 412], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"RIBES\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RibesScorer.idstr": [[413, 415], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"ribes\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SacreBleuScorer.__init__": [[422, 428], ["sacrebleu.BLEU"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "smooth_method", "=", "'exp'", ",", "smooth_value", "=", "0", ",", "effective_order", "=", "False", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "smooth_method", "=", "smooth_method", "\n", "self", ".", "smooth_value", "=", "smooth_value", "\n", "self", ".", "effective_order", "=", "effective_order", "\n", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "self", ".", "bleu", "=", "sacrebleu", ".", "BLEU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SacreBleuScorer.scale": [[429, 432], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SacreBleuScorer.score_sentence": [[433, 435], ["NotImplementedError"], "methods", ["None"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\"Sentence-level calculation is not implemented in SacreBleuScorer as it is usually 0.\"", "\n", "\"Consider using SentenceBleuScorer (string sentbleu) instead.\"", ")", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SacreBleuScorer.score_corpus": [[437, 440], ["scorers.SacreBleuScorer.cache_stats", "scorers.SacreBleuScorer.score_cached_corpus", "range", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus"], ["", "def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "cached_stats", "=", "self", ".", "cache_stats", "(", "ref", ",", "out", ")", "\n", "return", "self", ".", "score_cached_corpus", "(", "range", "(", "len", "(", "ref", ")", ")", ",", "cached_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SacreBleuScorer.cache_stats": [[441, 460], ["scorers.SacreBleuScorer.bleu._extract_corpus_statistics", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "cache_stats", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Cache sufficient statistics for caculating SacreBLEU score\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source courpus. Ignored if passed\n\n    Returns:\n      A list of cached statistics\n    \"\"\"", "\n", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "ref", "=", "corpus_utils", ".", "lower", "(", "ref", ")", "\n", "out", "=", "corpus_utils", ".", "lower", "(", "out", ")", "\n", "", "ref", "=", "[", "' '", ".", "join", "(", "x", ")", "for", "x", "in", "ref", "]", "\n", "out", "=", "[", "' '", ".", "join", "(", "x", ")", "for", "x", "in", "out", "]", "\n", "\n", "return", "self", ".", "bleu", ".", "_extract_corpus_statistics", "(", "out", ",", "[", "ref", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SacreBleuScorer.score_cached_corpus": [[461, 483], ["numpy.sum", "len", "numpy.array", "scorers.SacreBleuScorer.bleu.compute_bleu", "list", "int", "int"], "methods", ["None"], ["", "def", "score_cached_corpus", "(", "self", ",", "sent_ids", ",", "cached_stats", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using SacreBLEU score with cache\n\n    Args:\n      sent_ids: The sentence ids for reference and output corpora\n      cached_stats: A list of cached statistics\n\n    Returns:\n      A tuple containing a single value for the SacreBLEU score and a string summarizing auxiliary information\n    \"\"\"", "\n", "if", "len", "(", "cached_stats", ")", "==", "0", ":", "\n", "      ", "return", "0.0", ",", "None", "\n", "\n", "", "stats", "=", "np", ".", "sum", "(", "np", ".", "array", "(", "cached_stats", ")", "[", "list", "(", "sent_ids", ")", "]", ",", "0", ")", "\n", "\n", "return", "self", ".", "bleu", ".", "compute_bleu", "(", "correct", "=", "stats", "[", "2", ":", "2", "+", "self", ".", "bleu", ".", "max_ngram_order", "]", ",", "\n", "total", "=", "stats", "[", "2", "+", "self", ".", "bleu", ".", "max_ngram_order", ":", "]", ",", "\n", "sys_len", "=", "int", "(", "stats", "[", "0", "]", ")", ",", "ref_len", "=", "int", "(", "stats", "[", "1", "]", ")", ",", "\n", "smooth_method", "=", "self", ".", "smooth_method", ",", "\n", "smooth_value", "=", "self", ".", "smooth_value", ",", "\n", "effective_order", "=", "self", ".", "effective_order", ")", ".", "score", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SacreBleuScorer.name": [[484, 486], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"SacreBleuScorer\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.SacreBleuScorer.idstr": [[487, 489], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"sacrebleu\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.__init__": [[497, 499], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.scale": [[500, 503], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.chrf_score": [[504, 511], ["nltk.translate.chrf_score.corpus_chrf", "nltk.translate.chrf_score.corpus_chrf", "nltk.translate.chrf_score.corpus_chrf", "nltk.translate.chrf_score.corpus_chrf"], "methods", ["None"], ["", "def", "chrf_score", "(", "self", ",", "refs", ",", "out", ")", ":", "\n", "    ", "return", "self", ".", "scale", "*", "nltk", ".", "translate", ".", "chrf_score", ".", "corpus_chrf", "(", "\n", "[", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "ref", "]", "for", "ref", "in", "refs", "]", ",", "\n", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "out", "]", ",", "\n", "max_len", "=", "6", ",", "# Order 6 n-grams", "\n", "beta", "=", "2.0", ",", "# F2 score", "\n", "ignore_whitespace", "=", "True", "# No whitespaces", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.score_corpus": [[513, 530], ["scorers.ChrFScorer.chrf_score", "scorers.ChrFScorer.chrf_score", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.chrf_score", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.chrf_score", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using ChrF score\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source courpus. Ignored if passed\n\n    Returns:\n      A tuple containing a single value for the ChrF score and a string summarizing auxiliary information\n    \"\"\"", "\n", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "chrf", "=", "self", ".", "chrf_score", "(", "[", "[", "corpus_utils", ".", "lower", "(", "x", ")", "]", "for", "x", "in", "ref", "]", ",", "corpus_utils", ".", "lower", "(", "out", ")", ")", "\n", "", "else", ":", "\n", "      ", "chrf", "=", "self", ".", "chrf_score", "(", "[", "[", "x", "]", "for", "x", "in", "ref", "]", ",", "out", ")", "\n", "", "return", "chrf", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.score_sentence": [[531, 533], ["scorers.ChrFScorer.chrf_score"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.chrf_score"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "chrf_score", "(", "[", "ref", "]", ",", "[", "out", "]", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.name": [[534, 536], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"ChrF\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.ChrFScorer.idstr": [[537, 539], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"chrf\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.__init__": [[544, 549], ["nltk.stem.porter.PorterStemmer", "nltk.stem.porter.PorterStemmer", "nltk.stem.porter.PorterStemmer", "nltk.stem.porter.PorterStemmer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "rouge_type", ",", "score_type", "=", "'fmeasure'", ",", "use_stemmer", "=", "False", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "rouge_type", "=", "rouge_type", "\n", "self", ".", "score_type", "=", "score_type", "\n", "self", ".", "_stemmer", "=", "nltk", ".", "stem", ".", "porter", ".", "PorterStemmer", "(", ")", "if", "use_stemmer", "else", "None", "\n", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.scale": [[550, 553], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.score_sentence": [[554, 592], ["compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "compare_mt.rouge.rouge_scorer._score_lcs", "scorers.RougeScorer.tokenize", "scorers.RougeScorer.tokenize", "compare_mt.rouge.rouge_scorer._summary_level_lcs", "re.match", "scorers.RougeScorer._stemmer.stem", "scorers.RougeScorer._stemmer.stem", "scorers.RougeScorer.tokenize", "scorers.RougeScorer.tokenize", "int", "compare_mt.rouge.rouge_scorer._create_ngrams", "compare_mt.rouge.rouge_scorer._create_ngrams", "compare_mt.rouge.rouge_scorer._score_ngrams", "ValueError", "ValueError", "len", "len", "scorers.RougeScorer.get_sents", "scorers.RougeScorer.get_sents", "scorers.RougeScorer.tokenize", "scorers.RougeScorer.tokenize", "ValueError"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._score_lcs", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._summary_level_lcs", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.CachedPorterStemmer.stem", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.CachedPorterStemmer.stem", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._create_ngrams", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._create_ngrams", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._score_ngrams", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.get_sents", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.get_sents", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "ref", "=", "corpus_utils", ".", "lower", "(", "ref", ")", "\n", "out", "=", "corpus_utils", ".", "lower", "(", "out", ")", "\n", "\n", "", "if", "self", ".", "_stemmer", ":", "\n", "      ", "ref", "=", "[", "self", ".", "_stemmer", ".", "stem", "(", "x", ")", "if", "len", "(", "x", ")", ">", "3", "else", "x", "for", "x", "in", "ref", "]", "\n", "out", "=", "[", "self", ".", "_stemmer", ".", "stem", "(", "x", ")", "if", "len", "(", "x", ")", ">", "3", "else", "x", "for", "x", "in", "out", "]", "\n", "\n", "", "if", "self", ".", "rouge_type", "==", "'rougeL'", ":", "\n", "      ", "ref", ",", "out", "=", "self", ".", "tokenize", "(", "\" \"", ".", "join", "(", "ref", ")", ")", ",", "self", ".", "tokenize", "(", "\" \"", ".", "join", "(", "out", ")", ")", "\n", "scores", "=", "rouge_scorer", ".", "_score_lcs", "(", "ref", ",", "out", ")", "\n", "", "elif", "self", ".", "rouge_type", "==", "'rougeLsum'", ":", "\n", "      ", "refs", "=", "[", "self", ".", "tokenize", "(", "s", ")", "for", "s", "in", "self", ".", "get_sents", "(", "ref", ")", "]", "\n", "outs", "=", "[", "self", ".", "tokenize", "(", "s", ")", "for", "s", "in", "self", ".", "get_sents", "(", "out", ")", "]", "\n", "scores", "=", "rouge_scorer", ".", "_summary_level_lcs", "(", "refs", ",", "outs", ")", "\n", "", "elif", "re", ".", "match", "(", "r\"rouge[0-9]$\"", ",", "self", ".", "rouge_type", ")", ":", "\n", "      ", "ref", ",", "out", "=", "self", ".", "tokenize", "(", "\" \"", ".", "join", "(", "ref", ")", ")", ",", "self", ".", "tokenize", "(", "\" \"", ".", "join", "(", "out", ")", ")", "\n", "n", "=", "int", "(", "self", ".", "rouge_type", "[", "5", ":", "]", ")", "\n", "if", "n", "<=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"rougen requires positive n: {self.rouge_type}\"", ")", "\n", "", "ref_ngrams", "=", "rouge_scorer", ".", "_create_ngrams", "(", "ref", ",", "n", ")", "\n", "out_ngrams", "=", "rouge_scorer", ".", "_create_ngrams", "(", "out", ",", "n", ")", "\n", "scores", "=", "rouge_scorer", ".", "_score_ngrams", "(", "ref_ngrams", ",", "out_ngrams", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "f\"Invalid rouge type: {self.rouge_type}\"", ")", "\n", "\n", "\n", "", "if", "self", ".", "score_type", "==", "'fmeasure'", ":", "\n", "      ", "score_value", "=", "scores", ".", "fmeasure", "\n", "", "elif", "self", ".", "score_type", "==", "'precision'", ":", "\n", "      ", "score_value", "=", "scores", ".", "precision", "\n", "", "elif", "self", ".", "score_type", "==", "'recall'", ":", "\n", "      ", "score_value", "=", "scores", ".", "recall", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "f\"Invalid score type: {self.score_type}\"", ")", "\n", "\n", "", "return", "self", ".", "scale", "*", "score_value", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.get_sents": [[593, 598], ["len"], "methods", ["None"], ["", "def", "get_sents", "(", "self", ",", "tokens", ")", ":", "\n", "# assume sentences are separated by \".\"", "\n", "    ", "sents", "=", "\" \"", ".", "join", "(", "tokens", ")", ".", "split", "(", "\".\"", ")", "\n", "sents", "=", "[", "x", "for", "x", "in", "sents", "if", "len", "(", "x", ")", "]", "\n", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.tokenize": [[599, 604], ["re.sub", "re.split", "len"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "tokens", ")", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "r\"[^a-zA-Z0-9]+\"", ",", "\" \"", ",", "tokens", ")", "\n", "tokens", "=", "re", ".", "split", "(", "r\"\\s+\"", ",", "text", ")", "\n", "tokens", "=", "[", "x", "for", "x", "in", "tokens", "if", "len", "(", "x", ")", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.name": [[605, 607], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "rouge_type", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.idstr": [[608, 610], ["scorers.RougeScorer.rouge_type.lower"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "rouge_type", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer.__init__": [[615, 620], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sub_pen", "=", "1.0", ",", "ins_pen", "=", "1.0", ",", "del_pen", "=", "1.0", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "sub_pen", "=", "1.0", "\n", "self", ".", "ins_pen", "=", "1.0", "\n", "self", ".", "del_pen", "=", "1.0", "\n", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer.scale": [[621, 624], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer.score_corpus": [[625, 639], ["scorers.WERScorer.cache_stats", "scorers.WERScorer.score_cached_corpus", "numpy.arange", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus"], ["", "def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using WER\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source courpus. Ignored if passed\n\n    Returns:\n      A tuple containing a single value for the WER and None\n    \"\"\"", "\n", "cached_stats", "=", "self", ".", "cache_stats", "(", "ref", ",", "out", ")", "\n", "return", "self", ".", "score_cached_corpus", "(", "np", ".", "arange", "(", "len", "(", "ref", ")", ")", ",", "cached_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer.score_sentence": [[640, 642], ["scorers.WERScorer.score_corpus"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "score_corpus", "(", "[", "ref", "]", ",", "[", "out", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer.cache_stats": [[643, 660], ["zip", "cached_stats.append", "len", "scorers.WERScorer._edit_distance"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer._edit_distance"], ["", "def", "cache_stats", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Cache sufficient statistics for caculating WER\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n\n    Returns:\n      A list of cached statistics\n    \"\"\"", "\n", "cached_stats", "=", "[", "]", "\n", "\n", "for", "r", ",", "o", "in", "zip", "(", "ref", ",", "out", ")", ":", "\n", "      ", "cached_stats", ".", "append", "(", "(", "len", "(", "r", ")", ",", "self", ".", "_edit_distance", "(", "r", ",", "o", ")", ")", ")", "\n", "\n", "", "return", "cached_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer.score_cached_corpus": [[661, 680], ["zip", "numpy.sum", "len", "numpy.array", "numpy.array", "numpy.sum"], "methods", ["None"], ["", "def", "score_cached_corpus", "(", "self", ",", "sent_ids", ",", "cached_stats", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus with cache\n\n    Args:\n      sent_ids: The sentence ids for reference and output corpora\n      cached_stats: A list of cached statistics\n\n    Returns:\n      A tuple containing a single value for the score and a string summarizing auxiliary information\n    \"\"\"", "\n", "if", "len", "(", "cached_stats", ")", "==", "0", ":", "\n", "      ", "return", "0.0", ",", "None", "\n", "\n", "", "cached_ref_len", ",", "cached_edit_distance", "=", "zip", "(", "*", "cached_stats", ")", "\n", "cached_ref_len", ",", "cached_edit_distance", "=", "np", ".", "array", "(", "cached_ref_len", ")", ",", "np", ".", "array", "(", "cached_edit_distance", ")", "\n", "denom", "=", "np", ".", "sum", "(", "cached_ref_len", "[", "sent_ids", "]", ")", "\n", "wer", "=", "np", ".", "sum", "(", "cached_edit_distance", "[", "sent_ids", "]", ")", "/", "denom", "if", "denom", "!=", "0", "else", "0", "\n", "return", "self", ".", "scale", "*", "wer", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer._edit_distance": [[681, 707], ["numpy.zeros", "range", "range", "range", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "len", "len", "numpy.expand_dims", "numpy.array", "len", "range", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "_edit_distance", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "ref", "=", "corpus_utils", ".", "lower", "(", "ref", ")", "\n", "out", "=", "corpus_utils", ".", "lower", "(", "out", ")", "\n", "\n", "", "sp1", "=", "len", "(", "ref", ")", "+", "1", "\n", "tp1", "=", "len", "(", "out", ")", "+", "1", "\n", "scores", "=", "np", ".", "zeros", "(", "(", "sp1", ",", "tp1", ")", ")", "\n", "equals", "=", "(", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "ref", ")", ",", "axis", "=", "1", ")", "==", "np", ".", "array", "(", "out", ")", ")", "\n", "scores", "[", ":", ",", "0", "]", "=", "range", "(", "sp1", ")", "\n", "scores", "[", "0", ",", ":", "]", "=", "range", "(", "tp1", ")", "\n", "\n", "# Forward edit distance", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "ref", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "0", ",", "len", "(", "out", ")", ")", ":", "\n", "        ", "my_action", "=", "0", "if", "equals", "[", "i", ",", "j", "]", "else", "1", "\n", "my_score", "=", "scores", "[", "i", ",", "j", "]", "+", "my_action", "*", "self", ".", "sub_pen", "\n", "del_score", "=", "scores", "[", "i", ",", "j", "+", "1", "]", "+", "self", ".", "del_pen", "\n", "if", "del_score", "<", "my_score", ":", "\n", "          ", "my_score", "=", "del_score", "\n", "", "ins_score", "=", "scores", "[", "i", "+", "1", ",", "j", "]", "+", "self", ".", "ins_pen", "\n", "if", "ins_score", "<", "my_score", ":", "\n", "          ", "my_score", "=", "ins_score", "\n", "", "scores", "[", "i", "+", "1", ",", "j", "+", "1", "]", "=", "my_score", "\n", "\n", "", "", "return", "scores", "[", "-", "1", ",", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer.name": [[708, 710], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"Word Error Rate\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.WERScorer.idstr": [[711, 713], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"wer\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer.__init__": [[718, 722], ["scorers.METEORScorer._get_weights_and_parameters"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer._get_weights_and_parameters"], ["def", "__init__", "(", "self", ",", "meteor_directory", ",", "options", "=", "None", ")", ":", "\n", "    ", "self", ".", "meteor_directory", "=", "meteor_directory", "\n", "self", ".", "options", "=", "options", "\n", "self", ".", "weights", ",", "self", ".", "parameters", "=", "self", ".", "_get_weights_and_parameters", "(", "options", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer.scale": [[723, 726], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer.score_corpus": [[727, 738], ["scorers.METEORScorer.cache_stats", "scorers.METEORScorer.score_cached_corpus", "numpy.arange", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus"], ["", "def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using METEOR score\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n    Returns:\n      A tuple containing a single value for the METEOR score and a string summarizing auxiliary information\n    \"\"\"", "\n", "cached_stats", "=", "self", ".", "cache_stats", "(", "ref", ",", "out", ")", "\n", "return", "self", ".", "score_cached_corpus", "(", "np", ".", "arange", "(", "len", "(", "ref", ")", ")", ",", "cached_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer.score_sentence": [[739, 741], ["scorers.METEORScorer.score_corpus"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ")", ":", "\n", "    ", "return", "self", ".", "score_corpus", "(", "[", "ref", "]", ",", "[", "out", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer.cache_stats": [[742, 774], ["tempfile.TemporaryDirectory", "compare_mt.corpus_utils.write_tokens", "compare_mt.corpus_utils.write_tokens", "subprocess.Popen", "[].decode().split", "tuple", "cached_stats.append", "[].decode", "float", "stat_str.split", "subprocess.Popen.communicate"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.write_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.write_tokens"], ["", "def", "cache_stats", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Cache sufficient statistics for caculating METEOR score\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source courpus. Ignored if passed\n    Returns:\n      A list of cached statistics\n    \"\"\"", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "directory", ":", "\n", "      ", "ref_name", "=", "directory", "+", "'/ref'", "\n", "out_name", "=", "directory", "+", "'/out'", "\n", "\n", "corpus_utils", ".", "write_tokens", "(", "ref_name", ",", "ref", ")", "\n", "corpus_utils", ".", "write_tokens", "(", "out_name", ",", "out", ")", "\n", "\n", "cached_stats", "=", "[", "]", "\n", "\n", "command", "=", "f'java -Xmx2G -jar {self.meteor_directory}/meteor-*.jar {out_name} {ref_name} '", "\n", "if", "self", ".", "options", ":", "\n", "        ", "command", "+=", "self", ".", "options", "\n", "", "command", "+=", "' -ssOut'", "\n", "\n", "p", "=", "subprocess", ".", "Popen", "(", "command", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "shell", "=", "True", ")", "\n", "stats", "=", "p", ".", "communicate", "(", ")", "[", "0", "]", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", "'\\n'", ")", "[", ":", "-", "1", "]", "\n", "\n", "for", "stat_str", "in", "stats", ":", "\n", "        ", "stat", "=", "tuple", "(", "float", "(", "x", ")", "for", "x", "in", "stat_str", ".", "split", "(", ")", ")", "\n", "cached_stats", ".", "append", "(", "stat", ")", "\n", "\n", "", "", "return", "cached_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer.score_cached_corpus": [[775, 838], ["numpy.array", "numpy.sum", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.sum", "numpy.sum", "len", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "float", "math.pow", "float"], "methods", ["None"], ["", "def", "score_cached_corpus", "(", "self", ",", "sent_ids", ",", "cached_stats", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using METEOR score with cache\n    Args:\n      sent_ids: The sentence ids for reference and output corpora\n      cached_stats: A list of cached statistics\n    Returns:\n      A tuple containing a single value for the METEOR score and a string summarizing auxiliary information\n    \"\"\"", "\n", "if", "len", "(", "cached_stats", ")", "==", "0", ":", "\n", "      ", "return", "0.0", ",", "None", "\n", "\n", "", "cached_stats", "=", "np", ".", "array", "(", "cached_stats", ")", "\n", "\n", "# compute sufficient statistics", "\n", "sent_stats", "=", "cached_stats", "[", "sent_ids", "]", "\n", "\n", "# num_total_chunks = sum(num_sent_chunks) - minus_chunk", "\n", "minus_chunk", "=", "0", "\n", "for", "stat", "in", "sent_stats", ":", "\n", "      ", "out_len", "=", "stat", "[", "0", "]", "\n", "ref_len", "=", "stat", "[", "1", "]", "\n", "out_total_match", "=", "stat", "[", "4", "]", "+", "stat", "[", "6", "]", "+", "stat", "[", "8", "]", "+", "stat", "[", "10", "]", "+", "stat", "[", "12", "]", "+", "stat", "[", "14", "]", "+", "stat", "[", "16", "]", "+", "stat", "[", "18", "]", "\n", "ref_total_match", "=", "stat", "[", "5", "]", "+", "stat", "[", "7", "]", "+", "stat", "[", "9", "]", "+", "stat", "[", "11", "]", "+", "stat", "[", "13", "]", "+", "stat", "[", "15", "]", "+", "stat", "[", "17", "]", "+", "stat", "[", "19", "]", "\n", "if", "out_len", "==", "out_total_match", "and", "ref_len", "==", "ref_total_match", "and", "stat", "[", "-", "3", "]", "==", "1", ":", "\n", "        ", "minus_chunk", "+=", "1", "\n", "\n", "", "", "cal_stats", "=", "np", ".", "sum", "(", "sent_stats", ",", "0", ")", "\n", "cal_stats", "[", "20", "]", "-=", "minus_chunk", "\n", "\n", "# rename", "\n", "alpha", ",", "beta", ",", "gamma", ",", "delta", "=", "self", ".", "parameters", "\n", "out_len", ",", "ref_len", "=", "cal_stats", "[", "0", "]", ",", "cal_stats", "[", "1", "]", "\n", "out_func_words", ",", "ref_func_words", "=", "cal_stats", "[", "2", "]", ",", "cal_stats", "[", "3", "]", "\n", "out_content_match_stage", "=", "np", ".", "array", "(", "[", "cal_stats", "[", "4", "]", ",", "cal_stats", "[", "8", "]", ",", "cal_stats", "[", "12", "]", ",", "cal_stats", "[", "16", "]", "]", ")", "\n", "ref_content_match_stage", "=", "np", ".", "array", "(", "[", "cal_stats", "[", "5", "]", ",", "cal_stats", "[", "9", "]", ",", "cal_stats", "[", "13", "]", ",", "cal_stats", "[", "17", "]", "]", ")", "\n", "out_func_match_stage", "=", "np", ".", "array", "(", "[", "cal_stats", "[", "6", "]", ",", "cal_stats", "[", "10", "]", ",", "cal_stats", "[", "14", "]", ",", "cal_stats", "[", "18", "]", "]", ")", "\n", "ref_func_match_stage", "=", "np", ".", "array", "(", "[", "cal_stats", "[", "7", "]", ",", "cal_stats", "[", "11", "]", ",", "cal_stats", "[", "15", "]", ",", "cal_stats", "[", "19", "]", "]", ")", "\n", "chunks", "=", "cal_stats", "[", "20", "]", "\n", "out_word_match", ",", "ref_word_match", "=", "cal_stats", "[", "21", "]", ",", "cal_stats", "[", "22", "]", "\n", "\n", "# compute the METEOR score", "\n", "out_weighted_len", "=", "delta", "*", "(", "out_len", "-", "out_func_words", ")", "+", "(", "1.0", "-", "delta", ")", "*", "out_func_words", "\n", "ref_weighted_len", "=", "delta", "*", "(", "ref_len", "-", "ref_func_words", ")", "+", "(", "1.0", "-", "delta", ")", "*", "ref_func_words", "\n", "\n", "out_weighted_match", "=", "np", ".", "sum", "(", "self", ".", "weights", "*", "(", "out_content_match_stage", "*", "delta", "+", "out_func_match_stage", "*", "(", "1", "-", "delta", ")", ")", ")", "\n", "ref_weighted_match", "=", "np", ".", "sum", "(", "self", ".", "weights", "*", "(", "ref_content_match_stage", "*", "delta", "+", "ref_func_match_stage", "*", "(", "1", "-", "delta", ")", ")", ")", "\n", "\n", "prec", "=", "out_weighted_match", "/", "out_weighted_len", "if", "out_weighted_len", "!=", "0", "else", "0", "\n", "recall", "=", "ref_weighted_match", "/", "ref_weighted_len", "if", "ref_weighted_len", "!=", "0", "else", "0", "\n", "fmean", "=", "1.0", "/", "(", "(", "1.0", "-", "alpha", ")", "/", "prec", "+", "alpha", "/", "recall", ")", "if", "prec", "!=", "0", "and", "recall", "!=", "0", "else", "0", "\n", "\n", "out_total_match", "=", "np", ".", "sum", "(", "out_content_match_stage", ")", "+", "np", ".", "sum", "(", "out_func_match_stage", ")", "\n", "ref_total_match", "=", "np", ".", "sum", "(", "ref_content_match_stage", ")", "+", "np", ".", "sum", "(", "ref_func_match_stage", ")", "\n", "\n", "frag", "=", "float", "(", "chunks", ")", "/", "(", "float", "(", "out_word_match", "+", "ref_word_match", ")", "/", "2", ")", "\n", "frag", "=", "0", "if", "out_total_match", "==", "out_len", "and", "ref_total_match", "==", "ref_len", "and", "chunks", "==", "1", "else", "frag", "\n", "\n", "frag_penalty", "=", "gamma", "*", "math", ".", "pow", "(", "frag", ",", "beta", ")", "\n", "\n", "score", "=", "fmean", "*", "(", "1.0", "-", "frag_penalty", ")", "\n", "\n", "return", "self", ".", "scale", "*", "score", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer._get_weights_and_parameters": [[839, 864], ["numpy.zeros", "numpy.zeros", "tempfile.TemporaryDirectory", "compare_mt.corpus_utils.write_tokens", "compare_mt.corpus_utils.write_tokens", "subprocess.Popen", "[].decode().split", "range", "numpy.array", "numpy.array", "[].decode().split.index", "[].decode().split.index", "float", "float", "[].decode", "subprocess.Popen.communicate"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.write_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.write_tokens"], ["", "def", "_get_weights_and_parameters", "(", "self", ",", "options", ")", ":", "\n", "    ", "if", "self", ".", "options", "is", "None", ":", "\n", "      ", "return", "(", "np", ".", "array", "(", "[", "1.0", ",", "0.6", ",", "0.8", ",", "0.6", "]", ")", ",", "np", ".", "array", "(", "[", "0.85", ",", "0.2", ",", "0.6", ",", "0.75", "]", ")", ")", "\n", "\n", "", "weights", ",", "parameters", "=", "np", ".", "zeros", "(", "4", ")", ",", "np", ".", "zeros", "(", "4", ")", "\n", "# a simple and (maybe) slow way to obtain weights and parameters", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "directory", ":", "\n", "      ", "ref_name", "=", "directory", "+", "'/ref'", "\n", "out_name", "=", "directory", "+", "'/out'", "\n", "\n", "corpus_utils", ".", "write_tokens", "(", "ref_name", ",", "[", "[", "\"test\"", "]", "]", ")", "\n", "corpus_utils", ".", "write_tokens", "(", "out_name", ",", "[", "[", "\"test\"", "]", "]", ")", "\n", "\n", "command", "=", "f'java -Xmx2G -jar {self.meteor_directory}/meteor-*.jar {out_name} {ref_name} {options}'", "\n", "\n", "p", "=", "subprocess", ".", "Popen", "(", "command", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "shell", "=", "True", ")", "\n", "stats", "=", "p", ".", "communicate", "(", ")", "[", "0", "]", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", ")", "\n", "\n", "weights_index", "=", "stats", ".", "index", "(", "'Weights:'", ")", "+", "1", "\n", "params_index", "=", "stats", ".", "index", "(", "'Parameters:'", ")", "+", "1", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "weights", "[", "i", "]", "=", "float", "(", "stats", "[", "weights_index", "+", "i", "]", ")", "\n", "parameters", "[", "i", "]", "=", "float", "(", "stats", "[", "params_index", "+", "i", "]", ")", "\n", "\n", "", "", "return", "weights", ",", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer.name": [[865, 867], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"METEOR\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.METEORScorer.idstr": [[868, 870], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"meteor\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.COMETScorer.__init__": [[875, 880], ["torch.cuda.is_available", "download_model"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_name", "=", "\"wmt-large-da-estimator-1719\"", ")", ":", "\n", "    ", "import", "torch", "\n", "from", "comet", ".", "models", "import", "download_model", "\n", "self", ".", "cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "self", ".", "model", "=", "download_model", "(", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.COMETScorer.scale": [[881, 884], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.COMETScorer.score_sentence": [[885, 904], ["scorers.COMETScorer.model.predict"], "methods", ["None"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a single sentence with sentence-level COMET score\n\n    Args:\n      ref: A reference sentence\n      out: An output sentence\n      src: A source sentence\n\n    Returns:\n      The sentence-level COMET  score, and None\n    \"\"\"", "\n", "assert", "src", "is", "not", "None", ",", "\"COMET requires source\"", "\n", "\n", "data", "=", "[", "\n", "{", "\"src\"", ":", "\" \"", ".", "join", "(", "src", ")", ",", "\"mt\"", ":", "\" \"", ".", "join", "(", "out", ")", ",", "\"ref\"", ":", "\" \"", ".", "join", "(", "ref", ")", "}", "\n", "]", "\n", "score", "=", "self", ".", "model", ".", "predict", "(", "data", ",", "cuda", "=", "self", ".", "cuda", ")", "[", "1", "]", "[", "0", "]", "\n", "return", "self", ".", "scale", "*", "score", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.COMETScorer.name": [[905, 907], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"sentence-level COMET\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.COMETScorer.idstr": [[908, 910], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"comet\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.__init__": [[919, 922], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "weights", "=", "(", "0.25", ",", "0.25", ",", "0.25", ",", "0.25", ")", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "weights", "=", "weights", "\n", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.scale": [[923, 926], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale", "(", "self", ")", ":", "\n", "    ", "return", "global_scorer_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus": [[927, 941], ["scorers.GleuScorer.cache_stats", "scorers.GleuScorer.score_cached_corpus", "range", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus"], ["", "def", "score_corpus", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using GLEU score\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source corpus. Required\n\n    Returns:\n      A tuple containing a single value for the GLEU score and a string summarizing auxiliary information\n    \"\"\"", "\n", "cached_stats", "=", "self", ".", "cache_stats", "(", "ref", ",", "out", ",", "src", ")", "\n", "return", "self", ".", "score_cached_corpus", "(", "range", "(", "len", "(", "ref", ")", ")", ",", "cached_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence": [[942, 960], ["scorers.GleuScorer.cache_stats", "scorers.GleuScorer.score_cached_corpus", "range", "max", "max"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus"], ["", "def", "score_sentence", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Score a sentence using GLEU score\n\n    Args:\n      ref: A reference sentence\n      out: An output sentence\n      src: A source sentence. Required\n\n    Returns:\n      A tuple containing a single value for the GLEU score and a string summarizing auxiliary information\n    \"\"\"", "\n", "cached_stats", "=", "self", ".", "cache_stats", "(", "[", "ref", "]", ",", "[", "out", "]", ",", "[", "src", "]", ")", "\n", "# Smooth according to https://github.com/cnap/gec-ranking/blob/master/scripts/gleu.py", "\n", "stat", "=", "cached_stats", "[", "0", "]", "\n", "cached_stats", "[", "0", "]", "=", "(", "stat", "[", "0", "]", ",", "stat", "[", "1", "]", ",", "\n", "[", "(", "max", "(", "num", ",", "1", ")", ",", "max", "(", "denom", ",", "1", ")", ")", "for", "num", ",", "denom", "in", "stat", "[", "2", "]", "]", ")", "\n", "return", "self", ".", "score_cached_corpus", "(", "range", "(", "1", ")", ",", "cached_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer._precision": [[961, 990], ["compare_mt.ngram_utils.sent_ngrams_list", "compare_mt.ngram_utils.sent_ngrams_list", "compare_mt.ngram_utils.sent_ngrams_list", "collections.Counter", "collections.Counter", "collections.Counter", "max", "sum", "sum", "sum", "collections.Counter.values", "out_join_ref.values"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.sent_ngrams_list", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.sent_ngrams_list", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.sent_ngrams_list"], ["", "def", "_precision", "(", "self", ",", "ref", ",", "out", ",", "src", ",", "n", ")", ":", "\n", "    ", "\"\"\"\n    Calcualte GLEU-specific n-gram precision\n\n    Args:\n      ref: A reference sentence\n      out: An output sentence\n      src: A source sentence\n\n    Returns:\n      Numerator and denominator of the precision\n    \"\"\"", "\n", "ref_ngram", "=", "ngram_utils", ".", "sent_ngrams_list", "(", "ref", ",", "n", ")", "\n", "out_ngram", "=", "ngram_utils", ".", "sent_ngrams_list", "(", "out", ",", "n", ")", "\n", "src_ngram", "=", "ngram_utils", ".", "sent_ngrams_list", "(", "src", ",", "n", ")", "\n", "ref_cnt", "=", "Counter", "(", "ref_ngram", ")", "\n", "out_cnt", "=", "Counter", "(", "out_ngram", ")", "\n", "src_cnt", "=", "Counter", "(", "src_ngram", ")", "\n", "\n", "out_join_ref", "=", "out_cnt", "&", "ref_cnt", "\n", "out_join_src", "=", "out_cnt", "&", "src_cnt", "\n", "\n", "num", "=", "sum", "(", "out_join_ref", ".", "values", "(", ")", ")", "-", "sum", "(", "(", "out_join_src", "-", "out_join_ref", ")", ".", "values", "(", ")", ")", "\n", "# According to https://github.com/cnap/gec-ranking/blob/master/scripts/gleu.py", "\n", "num", "=", "max", "(", "num", ",", "0", ")", "\n", "denom", "=", "sum", "(", "out_cnt", ".", "values", "(", ")", ")", "\n", "\n", "return", "num", ",", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats": [[991, 1015], ["zip", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "range", "cached_stats.append", "prec.append", "len", "scorers.GleuScorer._precision", "len", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer._precision"], ["", "def", "cache_stats", "(", "self", ",", "ref", ",", "out", ",", "src", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Cache sufficient statistics for calculating BLEU score\n\n    Args:\n      ref: A reference corpus\n      out: An output corpus\n      src: A source corpus. Required.\n\n    Returns:\n      A list of cached statistics\n    \"\"\"", "\n", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "ref", "=", "corpus_utils", ".", "lower", "(", "ref", ")", "\n", "out", "=", "corpus_utils", ".", "lower", "(", "out", ")", "\n", "src", "=", "corpus_utils", ".", "lower", "(", "src", ")", "\n", "\n", "", "cached_stats", "=", "[", "]", "\n", "for", "r", ",", "o", ",", "s", "in", "zip", "(", "ref", ",", "out", ",", "src", ")", ":", "\n", "      ", "prec", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "1", ",", "len", "(", "self", ".", "weights", ")", "+", "1", ")", ":", "\n", "        ", "prec", ".", "append", "(", "self", ".", "_precision", "(", "r", ",", "o", ",", "s", ",", "n", ")", ")", "\n", "", "cached_stats", ".", "append", "(", "(", "len", "(", "r", ")", ",", "len", "(", "o", ")", ",", "prec", ")", ")", "\n", "", "return", "cached_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus": [[1016, 1057], ["zip", "collections.Counter", "collections.Counter", "any", "enumerate", "len", "range", "map", "math.log", "min", "itertools.chain", "math.exp", "math.exp", "len", "collections.Counter.values", "collections.Counter.values"], "methods", ["None"], ["", "def", "score_cached_corpus", "(", "self", ",", "sent_ids", ",", "cached_stats", ")", ":", "\n", "    ", "\"\"\"\n    Score a corpus using GLEU score with cache\n\n    Args:\n      sent_ids: The sentence ids for reference and output corpora\n      cached_stats: A list of cached statistics\n\n    Returns:\n      A tuple containing a single value for the GLEU score and a string summarizing auxiliary information\n    \"\"\"", "\n", "if", "len", "(", "cached_stats", ")", "==", "0", ":", "\n", "      ", "return", "0.0", ",", "None", "\n", "\n", "", "cached_ref_len", ",", "cached_out_len", ",", "cached_prec", "=", "zip", "(", "*", "cached_stats", ")", "\n", "\n", "num_prec", "=", "Counter", "(", ")", "\n", "denom_prec", "=", "Counter", "(", ")", "\n", "\n", "ref_len", "=", "0", "\n", "out_len", "=", "0", "\n", "for", "sent_id", "in", "sent_ids", ":", "\n", "      ", "ref_len", "+=", "cached_ref_len", "[", "sent_id", "]", "\n", "out_len", "+=", "cached_out_len", "[", "sent_id", "]", "\n", "for", "n", "in", "range", "(", "1", ",", "len", "(", "self", ".", "weights", ")", "+", "1", ")", ":", "\n", "        ", "num", ",", "denom", "=", "cached_prec", "[", "sent_id", "]", "[", "n", "-", "1", "]", "\n", "num_prec", "[", "n", "]", "+=", "num", "\n", "denom_prec", "[", "n", "]", "+=", "denom", "\n", "\n", "# According to https://github.com/cnap/gec-ranking/blob/master/scripts/gleu.py", "\n", "", "", "if", "any", "(", "map", "(", "lambda", "x", ":", "x", "==", "0", ",", "chain", "(", "num_prec", ".", "values", "(", ")", ",", "denom_prec", ".", "values", "(", ")", ")", ")", ")", ":", "\n", "      ", "return", "0", ",", "None", "\n", "\n", "", "prec", "=", "0", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "weights", ",", "start", "=", "1", ")", ":", "\n", "      ", "p", "=", "math", ".", "log", "(", "num_prec", "[", "i", "]", "/", "denom_prec", "[", "i", "]", ")", "\n", "prec", "+=", "p", "*", "w", "\n", "\n", "", "bp", "=", "min", "(", "1", ",", "math", ".", "exp", "(", "1", "-", "ref_len", "/", "out_len", ")", ")", "if", "out_len", "!=", "0", "else", "0", "\n", "\n", "return", "self", ".", "scale", "*", "bp", "*", "math", ".", "exp", "(", "prec", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.name": [[1058, 1060], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"GLEU\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.idstr": [[1061, 1063], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"gleu\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile": [[1064, 1102], ["scorers.BleuScorer", "scorers.SacreBleuScorer", "scorers.SentBleuScorer", "scorers.LengthScorer", "scorers.RibesScorer", "scorers.ChrFScorer", "re.match", "scorers.RougeScorer", "scorers.WERScorer", "scorers.METEORScorer", "ValueError", "scorers.ExactMatchScorer", "scorers.COMETScorer", "scorers.GleuScorer", "ValueError"], "function", ["None"], ["", "", "def", "create_scorer_from_profile", "(", "profile", ",", "case_insensitive", "=", "False", ",", "meteor_directory", "=", "None", ",", "options", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Create a scorer from a profile string\n  Args:\n    profile: a profile string of \"bleu\" for BLEU or \"length\" for length ratio\n    case_insensitive: A boolean specifying whether to turn on the case insensitive option\n\n  Returns:\n    A scorer to perform the appropriate scoring\n  \"\"\"", "\n", "if", "profile", "==", "'bleu'", ":", "\n", "    ", "return", "BleuScorer", "(", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "if", "profile", "==", "'sacrebleu'", ":", "\n", "    ", "return", "SacreBleuScorer", "(", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "elif", "profile", "==", "'sentbleu'", ":", "\n", "    ", "return", "SentBleuScorer", "(", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "elif", "profile", "==", "'length'", ":", "\n", "    ", "return", "LengthScorer", "(", ")", "\n", "", "elif", "profile", "==", "'ribes'", ":", "\n", "    ", "return", "RibesScorer", "(", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "elif", "profile", "==", "'chrf'", ":", "\n", "    ", "return", "ChrFScorer", "(", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "elif", "re", ".", "match", "(", "r\"rouge[0-9L](sum)?$\"", ",", "profile", ")", ":", "\n", "    ", "return", "RougeScorer", "(", "rouge_type", "=", "profile", ",", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "elif", "profile", "==", "'wer'", ":", "\n", "    ", "return", "WERScorer", "(", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "elif", "profile", "==", "'meteor'", ":", "\n", "    ", "if", "meteor_directory", "==", "None", ":", "\n", "      ", "raise", "ValueError", "(", "\"Must specify the directory of the METEOR source code.\"", ")", "\n", "", "return", "METEORScorer", "(", "meteor_directory", "=", "meteor_directory", ",", "options", "=", "options", ")", "\n", "", "elif", "profile", "==", "'exact'", ":", "\n", "    ", "return", "ExactMatchScorer", "(", ")", "\n", "", "elif", "profile", "==", "'comet'", ":", "\n", "    ", "return", "COMETScorer", "(", ")", "\n", "", "elif", "profile", "==", "'gleu'", ":", "\n", "    ", "return", "GleuScorer", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "f'Invalid profile for scorer {profile}'", ".", "format", "(", "profile", "=", "profile", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.set_bucket_cutoffs": [[12, 23], ["enumerate", "bucketers.Bucketer.bucket_strs.append", "bucketers.Bucketer.bucket_strs.append", "bucketers.Bucketer.bucket_strs.append", "bucketers.Bucketer.bucket_strs.append"], "methods", ["None"], ["  ", "def", "set_bucket_cutoffs", "(", "self", ",", "bucket_cutoffs", ",", "num_type", "=", "'int'", ")", ":", "\n", "    ", "self", ".", "bucket_cutoffs", "=", "bucket_cutoffs", "\n", "self", ".", "bucket_strs", "=", "[", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "bucket_cutoffs", ")", ":", "\n", "      ", "if", "i", "==", "0", ":", "\n", "        ", "self", ".", "bucket_strs", ".", "append", "(", "f'<{x}'", ")", "\n", "", "elif", "num_type", "==", "'int'", "and", "x", "-", "1", "==", "bucket_cutoffs", "[", "i", "-", "1", "]", ":", "\n", "        ", "self", ".", "bucket_strs", ".", "append", "(", "f'{x-1}'", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "bucket_strs", ".", "append", "(", "f'[{bucket_cutoffs[i-1]},{x})'", ")", "\n", "", "", "self", ".", "bucket_strs", ".", "append", "(", "f'>={x}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.cutoff_into_bucket": [[24, 29], ["enumerate", "len"], "methods", ["None"], ["", "def", "cutoff_into_bucket", "(", "self", ",", "value", ")", ":", "\n", "    ", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "bucket_cutoffs", ")", ":", "\n", "      ", "if", "value", "<", "v", ":", "\n", "        ", "return", "i", "\n", "", "", "return", "len", "(", "self", ".", "bucket_cutoffs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_bucket": [[32, 44], ["NotImplementedError"], "methods", ["None"], ["  ", "def", "calc_bucket", "(", "self", ",", "val", ",", "label", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the bucket for a particular word\n\n    Args:\n      val: The word to calculate the bucket for\n      label: If there's a label on the target word, add it\n\n    Returns:\n      An integer ID of the bucket\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "'calc_bucket must be implemented in subclasses of WordBucketer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_trg_matches": [[45, 62], ["collections.defaultdict", "enumerate", "enumerate", "ref_pos[].append", "enumerate", "collections.defaultdict.get", "out_word_cnts.get", "len"], "methods", ["None"], ["", "def", "_calc_trg_matches", "(", "self", ",", "ref_sent", ",", "out_sents", ")", ":", "\n", "    ", "ref_pos", "=", "defaultdict", "(", "lambda", ":", "[", "]", ")", "\n", "out_matches", "=", "[", "[", "-", "1", "for", "_", "in", "s", "]", "for", "s", "in", "out_sents", "]", "\n", "ref_matches", "=", "[", "[", "-", "1", "for", "_", "in", "ref_sent", "]", "for", "_", "in", "out_sents", "]", "\n", "for", "ri", ",", "ref_word", "in", "enumerate", "(", "ref_sent", ")", ":", "\n", "      ", "ref_pos", "[", "ref_word", "]", ".", "append", "(", "ri", ")", "\n", "", "for", "oai", ",", "out_sent", "in", "enumerate", "(", "out_sents", ")", ":", "\n", "      ", "out_word_cnts", "=", "{", "}", "\n", "for", "oi", ",", "out_word", "in", "enumerate", "(", "out_sent", ")", ":", "\n", "        ", "ref_poss", "=", "ref_pos", ".", "get", "(", "out_word", ",", "None", ")", "\n", "if", "ref_poss", ":", "\n", "          ", "out_word_cnt", "=", "out_word_cnts", ".", "get", "(", "out_word", ",", "0", ")", "\n", "if", "out_word_cnt", "<", "len", "(", "ref_poss", ")", ":", "\n", "            ", "out_matches", "[", "oai", "]", "[", "oi", "]", "=", "ref_poss", "[", "out_word_cnt", "]", "\n", "ref_matches", "[", "oai", "]", "[", "ref_poss", "[", "out_word_cnt", "]", "]", "=", "oi", "\n", "", "out_word_cnts", "[", "out_word", "]", "=", "out_word_cnt", "+", "1", "\n", "", "", "", "return", "out_matches", ",", "ref_matches", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_trg_buckets_and_matches": [[63, 105], ["bucketers.WordBucketer._calc_trg_matches", "enumerate", "len", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "bucketers.WordBucketer.calc_bucket", "itertools.zip_longest", "enumerate", "isinstance", "zip", "zip", "compare_mt.corpus_utils.lower", "itertools.zip_longest", "itertools.zip_longest", "out_buck.append", "isinstance", "compare_mt.corpus_utils.lower", "bucketers.WordBucketer.calc_bucket"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_trg_matches", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.calc_bucket", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.calc_bucket"], ["", "def", "_calc_trg_buckets_and_matches", "(", "self", ",", "ref_sent", ",", "ref_label", ",", "out_sents", ",", "out_labels", ")", ":", "\n", "# Initial setup for special cases", "\n", "    ", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "ref_sent", "=", "[", "corpus_utils", ".", "lower", "(", "w", ")", "for", "w", "in", "ref_sent", "]", "\n", "out_sents", "=", "[", "[", "corpus_utils", ".", "lower", "(", "w", ")", "for", "w", "in", "out_sent", "]", "for", "out_sent", "in", "out_sents", "]", "\n", "", "if", "not", "ref_label", ":", "\n", "      ", "ref_label", "=", "[", "]", "\n", "out_labels", "=", "[", "[", "]", "for", "_", "in", "out_sents", "]", "\n", "# Get matches", "\n", "", "out_matches", ",", "_", "=", "self", ".", "_calc_trg_matches", "(", "ref_sent", ",", "out_sents", ")", "\n", "# Process the reference, getting the bucket", "\n", "ref_buckets", "=", "[", "self", ".", "calc_bucket", "(", "w", ",", "label", "=", "l", ")", "for", "(", "w", ",", "l", ")", "in", "itertools", ".", "zip_longest", "(", "ref_sent", ",", "ref_label", ")", "]", "\n", "# Process each of the outputs, finding matches", "\n", "out_buckets", "=", "[", "[", "]", "for", "_", "in", "out_sents", "]", "\n", "for", "oai", ",", "(", "out_sent", ",", "out_label", ",", "match", ",", "out_buck", ")", "in", "enumerate", "(", "itertools", ".", "zip_longest", "(", "out_sents", ",", "out_labels", ",", "out_matches", ",", "out_buckets", ")", ")", ":", "\n", "      ", "for", "oi", ",", "(", "w", ",", "l", ",", "m", ")", "in", "enumerate", "(", "itertools", ".", "zip_longest", "(", "out_sent", ",", "out_label", ",", "match", ")", ")", ":", "\n", "        ", "out_buck", ".", "append", "(", "self", ".", "calc_bucket", "(", "w", ",", "label", "=", "l", ")", "if", "m", "<", "0", "else", "ref_buckets", "[", "m", "]", ")", "\n", "# Calculate totals for each sentence", "\n", "", "", "num_buckets", "=", "len", "(", "self", ".", "bucket_strs", ")", "\n", "num_outs", "=", "len", "(", "out_sents", ")", "\n", "my_ref_total", "=", "np", ".", "zeros", "(", "num_buckets", ",", "dtype", "=", "int", ")", "\n", "my_out_totals", "=", "np", ".", "zeros", "(", "(", "num_outs", ",", "num_buckets", ")", ",", "dtype", "=", "int", ")", "\n", "my_out_matches", "=", "np", ".", "zeros", "(", "(", "num_outs", ",", "num_buckets", ")", ",", "dtype", "=", "int", ")", "\n", "for", "b", "in", "ref_buckets", ":", "\n", "      ", "if", "isinstance", "(", "b", ",", "list", ")", ":", "\n", "        ", "for", "bi", "in", "b", ":", "\n", "          ", "my_ref_total", "[", "bi", "]", "+=", "1", "\n", "", "", "else", ":", "\n", "        ", "my_ref_total", "[", "b", "]", "+=", "1", "\n", "", "", "for", "oi", ",", "(", "obs", ",", "ms", ")", "in", "enumerate", "(", "zip", "(", "out_buckets", ",", "out_matches", ")", ")", ":", "\n", "      ", "for", "b", ",", "m", "in", "zip", "(", "obs", ",", "ms", ")", ":", "\n", "        ", "if", "isinstance", "(", "b", ",", "list", ")", ":", "\n", "          ", "for", "bi", "in", "b", ":", "\n", "            ", "my_out_totals", "[", "oi", ",", "bi", "]", "+=", "1", "\n", "if", "m", ">=", "0", ":", "\n", "              ", "my_out_matches", "[", "oi", ",", "bi", "]", "+=", "1", "\n", "", "", "", "else", ":", "\n", "          ", "my_out_totals", "[", "oi", ",", "b", "]", "+=", "1", "\n", "if", "m", ">=", "0", ":", "\n", "            ", "my_out_matches", "[", "oi", ",", "b", "]", "+=", "1", "\n", "", "", "", "", "return", "my_ref_total", ",", "my_out_totals", ",", "my_out_matches", ",", "ref_buckets", ",", "out_buckets", ",", "out_matches", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_src_buckets_and_matches": [[106, 136], ["bucketers.WordBucketer._calc_trg_matches", "len", "len", "numpy.zeros", "numpy.zeros", "numpy.broadcast_to", "enumerate", "bucketers.WordBucketer.calc_bucket", "src_aligns[].append", "numpy.reshape", "zip", "zip", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "itertools.zip_longest", "compare_mt.corpus_utils.lower", "len", "all"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_trg_matches", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.calc_bucket", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "_calc_src_buckets_and_matches", "(", "self", ",", "src_sent", ",", "src_label", ",", "ref_sent", ",", "ref_aligns", ",", "out_sents", ")", ":", "\n", "# Initial setup for special cases", "\n", "    ", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "src_sent", "=", "[", "corpus_utils", ".", "lower", "(", "w", ")", "for", "w", "in", "src_sent", "]", "\n", "ref_sent", "=", "[", "corpus_utils", ".", "lower", "(", "w", ")", "for", "w", "in", "ref_sent", "]", "\n", "out_sents", "=", "[", "[", "corpus_utils", ".", "lower", "(", "w", ")", "for", "w", "in", "out_sent", "]", "for", "out_sent", "in", "out_sents", "]", "\n", "", "if", "not", "src_label", ":", "\n", "      ", "src_label", "=", "[", "]", "\n", "# Get matches", "\n", "", "_", ",", "ref_matches", "=", "self", ".", "_calc_trg_matches", "(", "ref_sent", ",", "out_sents", ")", "\n", "# Process the source, getting the bucket", "\n", "src_buckets", "=", "[", "self", ".", "calc_bucket", "(", "w", ",", "label", "=", "l", ")", "for", "(", "w", ",", "l", ")", "in", "itertools", ".", "zip_longest", "(", "src_sent", ",", "src_label", ")", "]", "\n", "# For each source word, find the reference words that need to be correct", "\n", "src_aligns", "=", "[", "[", "]", "for", "_", "in", "src_sent", "]", "\n", "for", "src", ",", "trg", "in", "ref_aligns", ":", "\n", "      ", "src_aligns", "[", "src", "]", ".", "append", "(", "trg", ")", "\n", "# Calculate totals for each sentence", "\n", "", "num_buckets", "=", "len", "(", "self", ".", "bucket_strs", ")", "\n", "num_outs", "=", "len", "(", "out_sents", ")", "\n", "my_ref_total", "=", "np", ".", "zeros", "(", "num_buckets", ",", "dtype", "=", "int", ")", "\n", "my_out_matches", "=", "np", ".", "zeros", "(", "(", "num_outs", ",", "num_buckets", ")", ",", "dtype", "=", "int", ")", "\n", "for", "src_bucket", "in", "src_buckets", ":", "\n", "      ", "my_ref_total", "[", "src_bucket", "]", "+=", "1", "\n", "", "my_out_totals", "=", "np", ".", "broadcast_to", "(", "np", ".", "reshape", "(", "my_ref_total", ",", "(", "1", ",", "num_buckets", ")", ")", ",", "(", "num_outs", ",", "num_buckets", ")", ")", "\n", "for", "oai", ",", "(", "out_sent", ",", "ref_match", ")", "in", "enumerate", "(", "zip", "(", "out_sents", ",", "ref_matches", ")", ")", ":", "\n", "      ", "for", "src_bucket", ",", "src_align", "in", "zip", "(", "src_buckets", ",", "src_aligns", ")", ":", "\n", "        ", "if", "len", "(", "src_align", ")", "!=", "0", ":", "\n", "          ", "if", "all", "(", "[", "ref_match", "[", "x", "]", ">=", "0", "for", "x", "in", "src_align", "]", ")", ":", "\n", "            ", "my_out_matches", "[", "oai", ",", "src_bucket", "]", "+=", "1", "\n", "", "", "", "", "return", "my_ref_total", ",", "my_out_totals", ",", "my_out_matches", ",", "src_buckets", ",", "src_aligns", ",", "ref_matches", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_statistics": [[137, 218], ["len", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "enumerate", "hasattr", "itertools.zip_longest", "my_ref_total_list.append", "my_out_totals_list.append", "my_out_matches_list.append", "range", "bucketers.WordBucketer._calc_src_buckets_and_matches", "bucketers.WordBucketer._calc_trg_buckets_and_matches", "range", "ostatistics.append", "float", "float"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_src_buckets_and_matches", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer._calc_trg_buckets_and_matches"], ["", "def", "calc_statistics", "(", "self", ",", "ref", ",", "outs", ",", "\n", "src", "=", "None", ",", "\n", "ref_labels", "=", "None", ",", "out_labels", "=", "None", ",", "\n", "ref_aligns", "=", "None", ",", "src_labels", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Calculate match statistics, bucketed by the type of word we have, and IDs of example sentences to show.\n    This must be used with a subclass that has self.bucket_strs defined, and self.calc_bucket(word) implemented.\n\n    Args:\n      ref: The reference corpus\n      outs: A list of output corpora\n      src: Source sentences.\n           If src is set, it will use ref_aligns, out_aligns, and src_labels.\n           Otherwise, it will use ref_labels and out_labels.\n      ref_labels: Labels of the reference corpus (optional)\n      out_labels: Labels of the output corpora (should be specified iff ref_labels is)\n\n    Returns:\n      statistics: containing a list of equal length to out, containing for each system\n        both_tot: the frequency of a particular bucket appearing in both output and reference\n        ref_tot: the frequency of a particular bucket appearing in just reference\n        out_tot: the frequency of a particular bucket appearing in just output\n        rec: recall of the bucket\n        prec: precision of the bucket\n        fmeas: f1-measure of the bucket\n      my_ref_total_list: containing a list of statistics of the reference\n      my_out_matches_list: containing a list of statistics of the outputs\n    \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'case_insensitive'", ")", ":", "\n", "      ", "self", ".", "case_insensitive", "=", "False", "\n", "\n", "# Dimensions", "\n", "", "num_buckets", "=", "len", "(", "self", ".", "bucket_strs", ")", "\n", "num_outs", "=", "len", "(", "outs", ")", "\n", "\n", "# Initialize the sufficient statistics for prec/rec/fmeas", "\n", "ref_total", "=", "np", ".", "zeros", "(", "num_buckets", ",", "dtype", "=", "int", ")", "\n", "out_totals", "=", "np", ".", "zeros", "(", "(", "num_outs", ",", "num_buckets", ")", ",", "dtype", "=", "int", ")", "\n", "out_matches", "=", "np", ".", "zeros", "(", "(", "num_outs", ",", "num_buckets", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "my_ref_total_list", "=", "[", "]", "\n", "my_out_totals_list", "=", "[", "]", "\n", "my_out_matches_list", "=", "[", "]", "\n", "\n", "# Step through the sentences", "\n", "for", "rsi", ",", "(", "ref_sent", ",", "ref_label", ")", "in", "enumerate", "(", "itertools", ".", "zip_longest", "(", "ref", ",", "ref_labels", "if", "ref_labels", "else", "[", "]", ")", ")", ":", "\n", "      ", "if", "src", ":", "\n", "        ", "my_ref_total", ",", "my_out_totals", ",", "my_out_matches", ",", "_", ",", "_", ",", "_", "=", "self", ".", "_calc_src_buckets_and_matches", "(", "src", "[", "rsi", "]", ",", "\n", "src_labels", "[", "rsi", "]", "if", "src_labels", "else", "None", ",", "\n", "ref_sent", ",", "\n", "ref_aligns", "[", "rsi", "]", ",", "\n", "[", "x", "[", "rsi", "]", "for", "x", "in", "outs", "]", ")", "\n", "", "else", ":", "\n", "        ", "my_ref_total", ",", "my_out_totals", ",", "my_out_matches", ",", "_", ",", "_", ",", "_", "=", "self", ".", "_calc_trg_buckets_and_matches", "(", "ref_sent", ",", "\n", "ref_label", ",", "\n", "[", "x", "[", "rsi", "]", "for", "x", "in", "outs", "]", ",", "\n", "[", "x", "[", "rsi", "]", "for", "x", "in", "out_labels", "]", "if", "out_labels", "else", "None", ")", "\n", "", "ref_total", "+=", "my_ref_total", "\n", "out_totals", "+=", "my_out_totals", "\n", "out_matches", "+=", "my_out_matches", "\n", "\n", "my_ref_total_list", ".", "append", "(", "my_ref_total", ")", "\n", "my_out_totals_list", ".", "append", "(", "my_out_totals", ")", "\n", "my_out_matches_list", ".", "append", "(", "my_out_matches", ")", "\n", "\n", "# Calculate statistics", "\n", "", "statistics", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_outs", ")", "]", "\n", "for", "oi", ",", "ostatistics", "in", "enumerate", "(", "statistics", ")", ":", "\n", "      ", "for", "bi", "in", "range", "(", "num_buckets", ")", ":", "\n", "        ", "mcnt", ",", "ocnt", ",", "rcnt", "=", "out_matches", "[", "oi", ",", "bi", "]", ",", "out_totals", "[", "oi", ",", "bi", "]", ",", "ref_total", "[", "bi", "]", "\n", "if", "mcnt", "==", "0", ":", "\n", "          ", "rec", ",", "prec", ",", "fmeas", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "", "else", ":", "\n", "          ", "rec", "=", "mcnt", "/", "float", "(", "rcnt", ")", "\n", "prec", "=", "mcnt", "/", "float", "(", "ocnt", ")", "\n", "fmeas", "=", "2", "*", "prec", "*", "rec", "/", "(", "prec", "+", "rec", ")", "\n", "", "ostatistics", ".", "append", "(", "(", "mcnt", ",", "rcnt", ",", "ocnt", ",", "rec", ",", "prec", ",", "fmeas", ")", ")", "\n", "\n", "", "", "return", "statistics", ",", "my_ref_total_list", ",", "my_out_totals_list", ",", "my_out_matches_list", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_bucket_details": [[219, 264], ["numpy.array().sum", "len", "list", "int", "numpy.array", "numpy.array", "numpy.array", "range", "range", "range", "numpy.ceil", "numpy.random.choice", "range", "range", "numpy.array", "range", "rt_arr[].sum", "ot_arr[].sum", "om_arr[].sum", "range", "range", "intervals[].append", "range", "[].append", "len", "zip", "list", "list.sort", "bounds.append", "float", "float", "int", "int"], "methods", ["None"], ["", "def", "calc_bucket_details", "(", "self", ",", "my_ref_total_list", ",", "my_out_totals_list", ",", "my_out_matches_list", ",", "num_samples", "=", "1000", ",", "sample_ratio", "=", "0.5", ")", ":", "\n", "\n", "    ", "ref_total", "=", "np", ".", "array", "(", "my_ref_total_list", ")", ".", "sum", "(", "0", ")", "\n", "\n", "num_outs", ",", "num_buckets", "=", "my_out_totals_list", "[", "0", "]", ".", "shape", "\n", "n", "=", "len", "(", "my_ref_total_list", ")", "\n", "ids", "=", "list", "(", "range", "(", "n", ")", ")", "\n", "sample_size", "=", "int", "(", "np", ".", "ceil", "(", "n", "*", "sample_ratio", ")", ")", "\n", "rt_arr", "=", "np", ".", "array", "(", "my_ref_total_list", ")", "\n", "ot_arr", "=", "np", ".", "array", "(", "my_out_totals_list", ")", "\n", "om_arr", "=", "np", ".", "array", "(", "my_out_matches_list", ")", "\n", "statistics", "=", "[", "[", "[", "]", "for", "__", "in", "range", "(", "num_buckets", ")", "]", "for", "_", "in", "range", "(", "num_outs", ")", "]", "\n", "for", "_", "in", "range", "(", "num_samples", ")", ":", "\n", "      ", "reduced_ids", "=", "np", ".", "random", ".", "choice", "(", "ids", ",", "size", "=", "sample_size", ",", "replace", "=", "True", ")", "\n", "reduced_ref_total", ",", "reduced_out_totals", ",", "reduced_out_matches", "=", "rt_arr", "[", "reduced_ids", "]", ".", "sum", "(", "0", ")", ",", "ot_arr", "[", "reduced_ids", "]", ".", "sum", "(", "0", ")", ",", "om_arr", "[", "reduced_ids", "]", ".", "sum", "(", "0", ")", "\n", "# Calculate accuracy on the reduced sample and save stats", "\n", "for", "oi", "in", "range", "(", "num_outs", ")", ":", "\n", "        ", "for", "bi", "in", "range", "(", "num_buckets", ")", ":", "\n", "          ", "mcnt", ",", "ocnt", ",", "rcnt", "=", "reduced_out_matches", "[", "oi", ",", "bi", "]", ",", "reduced_out_totals", "[", "oi", ",", "bi", "]", ",", "reduced_ref_total", "[", "bi", "]", "\n", "if", "mcnt", "==", "0", ":", "\n", "            ", "rec", ",", "prec", ",", "fmeas", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "", "else", ":", "\n", "            ", "rec", "=", "mcnt", "/", "float", "(", "rcnt", ")", "\n", "prec", "=", "mcnt", "/", "float", "(", "ocnt", ")", "\n", "fmeas", "=", "2", "*", "prec", "*", "rec", "/", "(", "prec", "+", "rec", ")", "\n", "", "statistics", "[", "oi", "]", "[", "bi", "]", ".", "append", "(", "(", "mcnt", ",", "rcnt", ",", "ocnt", ",", "rec", ",", "prec", ",", "fmeas", ")", ")", "\n", "\n", "", "", "", "intervals", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_outs", ")", "]", "\n", "for", "oi", "in", "range", "(", "num_outs", ")", ":", "\n", "      ", "for", "bi", "in", "range", "(", "num_buckets", ")", ":", "\n", "        ", "if", "len", "(", "statistics", "[", "oi", "]", "[", "bi", "]", ")", ">", "0", ":", "\n", "          ", "_", ",", "_", ",", "_", ",", "recs", ",", "precs", ",", "fmeas", "=", "zip", "(", "*", "statistics", "[", "oi", "]", "[", "bi", "]", ")", "\n", "", "else", ":", "\n", "          ", "recs", ",", "precs", ",", "fmeas", "=", "[", "0.0", "]", ",", "[", "0.0", "]", ",", "[", "0.0", "]", "\n", "# The first three elements (intervals of mcnt, ocnt and rcnt) are None", "\n", "", "bounds", "=", "[", "None", ",", "None", ",", "None", "]", "\n", "for", "x", "in", "[", "recs", ",", "precs", ",", "fmeas", "]", ":", "\n", "          ", "x", "=", "list", "(", "x", ")", "\n", "x", ".", "sort", "(", ")", "\n", "lower_bound", "=", "x", "[", "int", "(", "num_samples", "*", "0.025", ")", "]", "\n", "upper_bound", "=", "x", "[", "int", "(", "num_samples", "*", "0.975", ")", "]", "\n", "bounds", ".", "append", "(", "(", "lower_bound", ",", "upper_bound", ")", ")", "\n", "", "intervals", "[", "oi", "]", ".", "append", "(", "bounds", ")", "\n", "\n", "", "", "return", "ref_total", ",", "intervals", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_examples": [[265, 318], ["len", "numpy.zeros", "enumerate", "numpy.argsort", "enumerate", "zip", "enumerate", "my_out_matches.sum", "range", "my_out_matches.sum", "fexamples.append"], "methods", ["None"], ["", "def", "calc_examples", "(", "self", ",", "num_sents", ",", "num_outs", ",", "\n", "statistics", ",", "\n", "my_ref_total_list", ",", "my_out_matches_list", ",", "\n", "num_examples", "=", "5", ")", ":", "\n", "    ", "\"\"\"\n    Calculate examples based the computed statistics.\n\n    Args:\n      num_sents: number of sentences\n      num_outs: number of outputs\n      statistics: containing a list of equal length to out, containing for each system\n        both_tot: the frequency of a particular bucket appearing in both output and reference\n        ref_tot: the frequency of a particular bucket appearing in just reference\n        out_tot: the frequency of a particular bucket appearing in just output\n        rec: recall of the bucket\n        prec: precision of the bucket\n        fmeas: f1-measure of the bucket\n      my_ref_total_list: containing a list of statistics of the reference\n      my_out_matches_list: containing a list of statistics of the outputs\n      num_examples: number of examples to print\n\n    Returns:\n      example: containing a list of examples to print\n    \"\"\"", "\n", "num_buckets", "=", "len", "(", "self", ".", "bucket_strs", ")", "\n", "num_examp_feats", "=", "3", "\n", "example_scores", "=", "np", ".", "zeros", "(", "(", "num_sents", ",", "num_examp_feats", ",", "num_buckets", ")", ")", "\n", "\n", "# Step through the sentences", "\n", "for", "rsi", ",", "(", "my_ref_total", ",", "my_out_matches", ")", "in", "enumerate", "(", "zip", "(", "my_ref_total_list", ",", "my_out_matches_list", ")", ")", ":", "\n", "\n", "# Scoring of examples across different dimensions:", "\n", "#  0: overall variance of matches", "\n", "      ", "example_scores", "[", "rsi", ",", "0", "]", "=", "(", "my_out_matches", "/", "(", "my_ref_total", "+", "1e-10", ")", ".", "reshape", "(", "(", "1", ",", "num_buckets", ")", ")", ")", ".", "std", "(", "axis", "=", "0", ")", "\n", "#  1: overall percentage of matches", "\n", "example_scores", "[", "rsi", ",", "1", "]", "=", "my_out_matches", ".", "sum", "(", "axis", "=", "0", ")", "/", "(", "my_ref_total", "*", "num_outs", "+", "1e-10", ")", "\n", "#  2: overall percentage of misses", "\n", "example_scores", "[", "rsi", ",", "2", "]", "=", "(", "my_ref_total", "*", "num_outs", "-", "my_out_matches", ".", "sum", "(", "axis", "=", "0", ")", ")", "/", "(", "my_ref_total", "*", "num_outs", "+", "1e-10", ")", "\n", "\n", "# Calculate statistics", "\n", "# Find top-5 examples of each class", "\n", "", "examples", "=", "[", "[", "(", "'Examples where some systems were good, some were bad'", ",", "[", "]", ")", ",", "\n", "(", "'Examples where all systems were good'", ",", "[", "]", ")", ",", "\n", "(", "'Examples where all systems were bad'", ",", "[", "]", ")", "]", "for", "_", "in", "range", "(", "num_buckets", ")", "]", "\n", "# NOTE: This could be made faster with argpartition, but the complexity is probably not worth it", "\n", "topn", "=", "np", ".", "argsort", "(", "-", "example_scores", ",", "axis", "=", "0", ")", "\n", "for", "bi", ",", "bexamples", "in", "enumerate", "(", "examples", ")", ":", "\n", "      ", "for", "fi", ",", "(", "_", ",", "fexamples", ")", "in", "enumerate", "(", "bexamples", ")", ":", "\n", "        ", "for", "si", "in", "topn", "[", ":", "num_examples", ",", "fi", ",", "bi", "]", ":", "\n", "          ", "if", "example_scores", "[", "si", ",", "fi", ",", "bi", "]", ">", "0", ":", "\n", "            ", "fexamples", ".", "append", "(", "si", ")", "\n", "\n", "", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_source_bucketed_matches": [[319, 377], ["itertools.zip_longest", "hasattr", "collections.defaultdict", "enumerate", "enumerate", "enumerate", "bucketers.WordBucketer.calc_bucket", "bucketers.WordBucketer.calc_bucket", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "float", "float"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.calc_bucket", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.calc_bucket", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "calc_source_bucketed_matches", "(", "self", ",", "src", ",", "ref", ",", "out", ",", "ref_aligns", ",", "out_aligns", ",", "src_labels", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the number of matches, bucketed by the type of word we have\n    This must be used with a subclass that has self.bucket_strs defined, and self.calc_bucket(word) implemented.\n\n    Args:\n      src: The source corpus\n      ref: The reference corpus\n      out: The output corpus\n      ref_aligns: Alignments of the reference corpus\n      out_aligns: Alignments of the output corpus\n      src_labels: Labels of the source corpus (optional)\n\n    Returns:\n      A tuple containing:\n        both_tot: the frequency of a particular bucket appearing in both output and reference\n        ref_tot: the frequency of a particular bucket appearing in just reference\n        out_tot: the frequency of a particular bucket appearing in just output\n        rec: recall of the bucket\n        prec: precision of the bucket\n        fmeas: f1-measure of the bucket\n    \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'case_insensitive'", ")", ":", "\n", "      ", "self", ".", "case_insensitive", "=", "False", "\n", "\n", "", "src_labels", "=", "src_labels", "if", "src_labels", "else", "[", "]", "\n", "matches", "=", "[", "[", "0", ",", "0", ",", "0", "]", "for", "x", "in", "self", ".", "bucket_strs", "]", "\n", "for", "src_sent", ",", "ref_sent", ",", "out_sent", ",", "ref_align", ",", "out_align", ",", "src_lab", "in", "itertools", ".", "zip_longest", "(", "src", ",", "ref", ",", "out", ",", "ref_aligns", ",", "out_aligns", ",", "src_labels", ")", ":", "\n", "      ", "ref_cnt", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "ref_sent", ")", ":", "\n", "        ", "if", "self", ".", "case_insensitive", ":", "\n", "          ", "word", "=", "corpus_utils", ".", "lower", "(", "word", ")", "\n", "", "ref_cnt", "[", "word", "]", "+=", "1", "\n", "", "for", "i", ",", "(", "src_index", ",", "trg_index", ")", "in", "enumerate", "(", "out_align", ")", ":", "\n", "        ", "src_word", "=", "src_sent", "[", "src_index", "]", "\n", "word", "=", "out_sent", "[", "trg_index", "]", "\n", "if", "self", ".", "case_insensitive", ":", "\n", "          ", "word", "=", "corpus_utils", ".", "lower", "(", "word", ")", "\n", "", "bucket", "=", "self", ".", "calc_bucket", "(", "src_word", ",", "\n", "label", "=", "src_lab", "[", "src_index", "]", "if", "src_lab", "else", "None", ")", "\n", "if", "ref_cnt", "[", "word", "]", ">", "0", ":", "\n", "          ", "ref_cnt", "[", "word", "]", "-=", "1", "\n", "matches", "[", "bucket", "]", "[", "0", "]", "+=", "1", "\n", "", "matches", "[", "bucket", "]", "[", "2", "]", "+=", "1", "\n", "", "for", "i", ",", "(", "src_index", ",", "trg_index", ")", "in", "enumerate", "(", "ref_align", ")", ":", "\n", "        ", "src_word", "=", "src_sent", "[", "src_index", "]", "\n", "bucket", "=", "self", ".", "calc_bucket", "(", "src_word", ",", "\n", "label", "=", "src_lab", "[", "src_index", "]", "if", "src_lab", "else", "None", ")", "\n", "matches", "[", "bucket", "]", "[", "1", "]", "+=", "1", "\n", "\n", "", "", "for", "both_tot", ",", "ref_tot", ",", "out_tot", "in", "matches", ":", "\n", "      ", "if", "both_tot", "==", "0", ":", "\n", "        ", "rec", ",", "prec", ",", "fmeas", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "", "else", ":", "\n", "        ", "rec", "=", "both_tot", "/", "float", "(", "ref_tot", ")", "\n", "prec", "=", "both_tot", "/", "float", "(", "out_tot", ")", "\n", "fmeas", "=", "2", "*", "prec", "*", "rec", "/", "(", "prec", "+", "rec", ")", "\n", "", "yield", "both_tot", ",", "ref_tot", ",", "out_tot", ",", "rec", ",", "prec", ",", "fmeas", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_bucketed_likelihoods": [[378, 414], ["zip", "hasattr", "type", "compare_mt.corpus_utils.load_tokens", "len", "len", "ValueError", "zip", "len", "len", "ValueError", "bucketers.WordBucketer.calc_bucket", "compare_mt.corpus_utils.lower", "float"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.calc_bucket", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "", "def", "calc_bucketed_likelihoods", "(", "self", ",", "corpus", ",", "likelihoods", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the average of log likelihoods, bucketed by the type of word/label we have\n    This must be used with a subclass that has self.bucket_strs defined, and self.calc_bucket(word) implemented.\n\n    Args:\n      corpus: The text/label corpus over which we compute the likelihoods\n      likelihoods: The log-likelihoods corresponding to each word/label in the corpus\n\n    Returns:\n      the average log-likelihood bucketed by the type of word/label we have\n    \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'case_insensitive'", ")", ":", "\n", "      ", "self", ".", "case_insensitive", "=", "False", "\n", "\n", "", "if", "type", "(", "corpus", ")", "==", "str", ":", "\n", "      ", "corpus", "=", "corpus_utils", ".", "load_tokens", "(", "corpus", ")", "\n", "", "bucketed_likelihoods", "=", "[", "[", "0.0", ",", "0", "]", "for", "_", "in", "self", ".", "bucket_strs", "]", "\n", "if", "len", "(", "corpus", ")", "!=", "len", "(", "likelihoods", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Corpus and likelihoods should have the same size.\"", ")", "\n", "", "for", "sent", ",", "list_of_likelihoods", "in", "zip", "(", "corpus", ",", "likelihoods", ")", ":", "\n", "      ", "if", "len", "(", "sent", ")", "!=", "len", "(", "list_of_likelihoods", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Each sentence of the corpus should have likelihood value for each word\"", ")", "\n", "\n", "", "for", "word", ",", "ll", "in", "zip", "(", "sent", ",", "list_of_likelihoods", ")", ":", "\n", "        ", "if", "self", ".", "case_insensitive", ":", "\n", "          ", "word", "=", "corpus_utils", ".", "lower", "(", "word", ")", "\n", "", "bucket", "=", "self", ".", "calc_bucket", "(", "word", ",", "label", "=", "word", ")", "\n", "bucketed_likelihoods", "[", "bucket", "]", "[", "0", "]", "+=", "ll", "\n", "bucketed_likelihoods", "[", "bucket", "]", "[", "1", "]", "+=", "1", "\n", "\n", "", "", "for", "ll", ",", "count", "in", "bucketed_likelihoods", ":", "\n", "      ", "if", "count", "!=", "0", ":", "\n", "        ", "yield", "ll", "/", "float", "(", "count", ")", "\n", "", "else", ":", "\n", "        ", "yield", "\"NA\"", "# not applicable", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.FreqWordBucketer.__init__": [[418, 473], ["bucketers.FreqWordBucketer.set_bucket_cutoffs", "collections.defaultdict", "print", "open", "print", "compare_mt.corpus_utils.iterate_tokens", "line.strip().split", "print", "ValueError", "len", "print", "int", "line.strip", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.set_bucket_cutoffs", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.iterate_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.SentenceExampleReport.print", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["  ", "def", "__init__", "(", "self", ",", "\n", "freq_counts", "=", "None", ",", "freq_count_file", "=", "None", ",", "freq_corpus_file", "=", "None", ",", "freq_data", "=", "None", ",", "\n", "bucket_cutoffs", "=", "None", ",", "\n", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    A bucketer that buckets words by their frequency.\n\n    Args:\n      freq_counts: A dictionary containing word/count data.\n      freq_count_file: A file containing counts for each word in tab-separated word, count format.\n                       Ignored if freq_counts exists.\n      freq_corpus_file: A file with a corpus used for collecting counts. Ignored if freq_count_file exists.\n      freq_data: A tokenized corpus from which counts can be calculated. Ignored if freq_corpus_file exists.\n      bucket_cutoffs: Cutoffs for each bucket.\n                      The first bucket will be range(0,bucket_cutoffs[0]).\n                      Middle buckets will be range(bucket_cutoffs[i],bucket_cutoffs[i-1].\n                      Final bucket will be everything greater than bucket_cutoffs[-1].\n      case_insensitive: A boolean specifying whether to turn on the case insensitive option.\n    \"\"\"", "\n", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "if", "not", "freq_counts", ":", "\n", "      ", "freq_counts", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "if", "freq_count_file", "!=", "None", ":", "\n", "        ", "print", "(", "f'Reading frequency from \"{freq_count_file}\"'", ")", "\n", "with", "open", "(", "freq_count_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "          ", "for", "line", "in", "f", ":", "\n", "            ", "cols", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "cols", ")", "!=", "2", ":", "\n", "              ", "print", "(", "f'Bad line in counts file {freq_count_file}, ignoring:\\n{line}'", ")", "\n", "", "else", ":", "\n", "              ", "word", ",", "freq", "=", "cols", "\n", "if", "self", ".", "case_insensitive", ":", "\n", "                ", "word", "=", "corpus_utils", ".", "lower", "(", "word", ")", "\n", "", "freq_counts", "[", "word", "]", "=", "int", "(", "freq", ")", "\n", "", "", "", "", "elif", "freq_corpus_file", ":", "\n", "        ", "print", "(", "f'Reading frequency from \"{freq_corpus_file}\"'", ")", "\n", "for", "words", "in", "corpus_utils", ".", "iterate_tokens", "(", "freq_corpus_file", ")", ":", "\n", "          ", "for", "word", "in", "words", ":", "\n", "            ", "if", "self", ".", "case_insensitive", ":", "\n", "              ", "word", "=", "corpus_utils", ".", "lower", "(", "word", ")", "\n", "", "freq_counts", "[", "word", "]", "+=", "1", "\n", "", "", "", "elif", "freq_data", ":", "\n", "        ", "print", "(", "'Reading frequency from the reference'", ")", "\n", "for", "words", "in", "freq_data", ":", "\n", "          ", "for", "word", "in", "words", ":", "\n", "            ", "if", "self", ".", "case_insensitive", ":", "\n", "              ", "word", "=", "corpus_utils", ".", "lower", "(", "word", ")", "\n", "", "freq_counts", "[", "word", "]", "+=", "1", "\n", "", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Must have at least one source of frequency counts for FreqWordBucketer'", ")", "\n", "", "", "self", ".", "freq_counts", "=", "freq_counts", "\n", "\n", "if", "bucket_cutoffs", "is", "None", ":", "\n", "      ", "bucket_cutoffs", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "10", ",", "100", ",", "1000", "]", "\n", "", "self", ".", "set_bucket_cutoffs", "(", "bucket_cutoffs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.FreqWordBucketer.calc_bucket": [[474, 478], ["bucketers.FreqWordBucketer.cutoff_into_bucket", "compare_mt.corpus_utils.lower", "bucketers.FreqWordBucketer.freq_counts.get"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.cutoff_into_bucket", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "calc_bucket", "(", "self", ",", "word", ",", "label", "=", "None", ")", ":", "\n", "    ", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "word", "=", "corpus_utils", ".", "lower", "(", "word", ")", "\n", "", "return", "self", ".", "cutoff_into_bucket", "(", "self", ".", "freq_counts", ".", "get", "(", "word", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.FreqWordBucketer.name": [[479, 481], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"frequency\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.FreqWordBucketer.idstr": [[482, 484], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"freq\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.CaseWordBucketer.__init__": [[487, 493], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    A bucketer that buckets words by whether they're all all lower-case (lower), all upper-case (upper),\n    title case (title), or other.\n    \"\"\"", "\n", "self", ".", "bucket_strs", "=", "[", "'lower'", ",", "'upper'", ",", "'title'", ",", "'other'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.CaseWordBucketer.calc_bucket": [[494, 503], ["word.islower", "word.isupper", "word.istitle"], "methods", ["None"], ["", "def", "calc_bucket", "(", "self", ",", "word", ",", "label", "=", "None", ")", ":", "\n", "    ", "if", "word", ".", "islower", "(", ")", ":", "\n", "      ", "return", "0", "\n", "", "elif", "word", ".", "isupper", "(", ")", ":", "\n", "      ", "return", "1", "\n", "", "elif", "word", ".", "istitle", "(", ")", ":", "\n", "      ", "return", "2", "\n", "", "else", ":", "\n", "      ", "return", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.CaseWordBucketer.name": [[504, 506], ["None"], "methods", ["None"], ["", "", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"case\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.CaseWordBucketer.idstr": [[507, 509], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"case\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LabelWordBucketer.__init__": [[512, 527], ["len", "collections.defaultdict", "enumerate", "type", "label_set.split.split.split"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "\n", "label_set", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    A bucketer that buckets words by their labels.\n\n    Args:\n      label_set: The set of labels to use as buckets. This can be a list, or a string separated by '+'s.\n    \"\"\"", "\n", "if", "type", "(", "label_set", ")", "==", "str", ":", "\n", "      ", "label_set", "=", "label_set", ".", "split", "(", "'+'", ")", "\n", "", "self", ".", "bucket_strs", "=", "label_set", "+", "[", "'other'", "]", "\n", "label_set_len", "=", "len", "(", "label_set", ")", "\n", "self", ".", "bucket_map", "=", "defaultdict", "(", "lambda", ":", "label_set_len", ")", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label_set", ")", ":", "\n", "      ", "self", ".", "bucket_map", "[", "l", "]", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LabelWordBucketer.calc_bucket": [[528, 532], ["ValueError"], "methods", ["None"], ["", "", "def", "calc_bucket", "(", "self", ",", "word", ",", "label", "=", "None", ")", ":", "\n", "    ", "if", "not", "label", ":", "\n", "      ", "raise", "ValueError", "(", "'When calculating buckets by label, label must be non-zero'", ")", "\n", "", "return", "self", ".", "bucket_map", "[", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LabelWordBucketer.name": [[533, 535], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"labels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LabelWordBucketer.idstr": [[536, 538], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"labels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.MultiLabelWordBucketer.__init__": [[541, 556], ["len", "collections.defaultdict", "enumerate", "type", "label_set.split.split.split"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "\n", "label_set", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    A bucketer that buckets words by one or multiple labels.\n\n    Args:\n      label_set: The set of labels to use as buckets. This can be a list, or a string separated by '+'s.\n    \"\"\"", "\n", "if", "type", "(", "label_set", ")", "==", "str", ":", "\n", "      ", "label_set", "=", "label_set", ".", "split", "(", "'+'", ")", "\n", "", "self", ".", "bucket_strs", "=", "label_set", "+", "[", "'other'", "]", "\n", "label_set_len", "=", "len", "(", "label_set", ")", "\n", "self", ".", "bucket_map", "=", "defaultdict", "(", "lambda", ":", "label_set_len", ")", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label_set", ")", ":", "\n", "      ", "self", ".", "bucket_map", "[", "l", "]", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.MultiLabelWordBucketer.calc_bucket": [[557, 562], ["label.split.split.split", "ValueError"], "methods", ["None"], ["", "", "def", "calc_bucket", "(", "self", ",", "word", ",", "label", "=", "None", ")", ":", "\n", "    ", "if", "not", "label", ":", "\n", "      ", "raise", "ValueError", "(", "'When calculating buckets by label, label must be non-zero'", ")", "\n", "", "label", "=", "label", ".", "split", "(", "'+'", ")", "\n", "return", "[", "self", ".", "bucket_map", "[", "l", "]", "for", "l", "in", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.MultiLabelWordBucketer.name": [[563, 565], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"multilabels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.MultiLabelWordBucketer.idstr": [[566, 568], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"multilabels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelWordBucketer.__init__": [[571, 585], ["bucketers.NumericalLabelWordBucketer.set_bucket_cutoffs"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.set_bucket_cutoffs"], ["  ", "def", "__init__", "(", "self", ",", "\n", "bucket_cutoffs", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    A bucketer that buckets words by labels that are numerical values.\n\n    Args:\n      bucket_cutoffs: Cutoffs for each bucket.\n                      The first bucket will be range(0,bucket_cutoffs[0]).\n                      Middle buckets will be range(bucket_cutoffs[i],bucket_cutoffs[i-1].\n                      Final bucket will be everything greater than bucket_cutoffs[-1].\n    \"\"\"", "\n", "if", "bucket_cutoffs", "is", "None", ":", "\n", "      ", "bucket_cutoffs", "=", "[", "0.25", ",", "0.5", ",", "0.75", "]", "\n", "", "self", ".", "set_bucket_cutoffs", "(", "bucket_cutoffs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelWordBucketer.calc_bucket": [[586, 591], ["bucketers.NumericalLabelWordBucketer.cutoff_into_bucket", "ValueError", "float"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.cutoff_into_bucket"], ["", "def", "calc_bucket", "(", "self", ",", "word", ",", "label", "=", "None", ")", ":", "\n", "    ", "if", "label", ":", "\n", "      ", "return", "self", ".", "cutoff_into_bucket", "(", "float", "(", "label", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "'When calculating buckets by label must be non-zero'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelWordBucketer.name": [[592, 594], ["None"], "methods", ["None"], ["", "", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"numerical labels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelWordBucketer.idstr": [[595, 597], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"numlabels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.SentenceBucketer.calc_bucket": [[600, 615], ["NotImplementedError"], "methods", ["None"], ["  ", "def", "calc_bucket", "(", "self", ",", "val", ",", "ref", "=", "None", ",", "src", "=", "None", ",", "out_label", "=", "None", ",", "ref_label", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the bucket for a particular sentence\n\n    Args:\n      val: The sentence to calculate the bucket for\n      ref: The reference sentence, if it exists\n      src: The source sentence, if it exists\n      ref_labels: The label of the reference sentence, if it exists\n      out_labels: The label of the output sentence, if it exists\n\n    Returns:\n      An integer ID of the bucket\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "'calc_bucket must be implemented in subclasses of SentenceBucketer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.SentenceBucketer.create_bucketed_corpus": [[616, 634], ["enumerate", "zip", "bucketers.SentenceBucketer.calc_bucket", "[].append", "[].append", "[].append"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.calc_bucket"], ["", "def", "create_bucketed_corpus", "(", "self", ",", "out", ",", "ref", "=", "None", ",", "src", "=", "None", ",", "ref_labels", "=", "None", ",", "out_labels", "=", "None", ")", ":", "\n", "    ", "bucketed_corpus", "=", "[", "(", "[", "]", ",", "[", "]", "if", "ref", "else", "None", ",", "[", "]", ")", "for", "_", "in", "self", ".", "bucket_strs", "]", "\n", "if", "ref", "is", "None", ":", "\n", "      ", "ref", "=", "out", "\n", "\n", "", "if", "ref_labels", "is", "None", ":", "\n", "      ", "ref_labels", "=", "out_labels", "\n", "\n", "", "src", "=", "[", "None", "for", "_", "in", "out", "]", "if", "src", "is", "None", "else", "src", "\n", "\n", "for", "i", ",", "(", "out_words", ",", "ref_words", ",", "src_words", ")", "in", "enumerate", "(", "zip", "(", "out", ",", "ref", ",", "src", ")", ")", ":", "\n", "      ", "bucket", "=", "self", ".", "calc_bucket", "(", "out_words", ",", "ref_words", ",", "src_words", ",", "label", "=", "(", "ref_labels", "[", "i", "]", "[", "0", "]", "if", "ref_labels", "else", "None", ")", ")", "\n", "\n", "bucketed_corpus", "[", "bucket", "]", "[", "0", "]", ".", "append", "(", "out_words", ")", "\n", "bucketed_corpus", "[", "bucket", "]", "[", "1", "]", ".", "append", "(", "ref_words", ")", "\n", "bucketed_corpus", "[", "bucket", "]", "[", "2", "]", ".", "append", "(", "src_words", ")", "\n", "\n", "", "return", "bucketed_corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.ScoreSentenceBucketer.__init__": [[641, 648], ["compare_mt.scorers.create_scorer_from_profile", "bucketers.ScoreSentenceBucketer.set_bucket_cutoffs", "range"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.set_bucket_cutoffs"], ["def", "__init__", "(", "self", ",", "score_type", ",", "bucket_cutoffs", "=", "None", ",", "case_insensitive", "=", "False", ")", ":", "\n", "    ", "self", ".", "score_type", "=", "score_type", "\n", "self", ".", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "score_type", ")", "\n", "if", "bucket_cutoffs", "is", "None", ":", "\n", "      ", "bucket_cutoffs", "=", "[", "x", "*", "self", ".", "scorer", ".", "scale", "/", "10.0", "for", "x", "in", "range", "(", "1", ",", "10", ")", "]", "\n", "", "self", ".", "set_bucket_cutoffs", "(", "bucket_cutoffs", ",", "num_type", "=", "'float'", ")", "\n", "self", ".", "case_insensitive", "=", "case_insensitive", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.ScoreSentenceBucketer.calc_bucket": [[649, 654], ["bucketers.ScoreSentenceBucketer.cutoff_into_bucket", "bucketers.ScoreSentenceBucketer.cutoff_into_bucket", "bucketers.ScoreSentenceBucketer.scorer.score_sentence", "bucketers.ScoreSentenceBucketer.scorer.score_sentence", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.lower"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.cutoff_into_bucket", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.cutoff_into_bucket", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower"], ["", "def", "calc_bucket", "(", "self", ",", "val", ",", "ref", "=", "None", ",", "src", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "    ", "if", "self", ".", "case_insensitive", ":", "\n", "      ", "return", "self", ".", "cutoff_into_bucket", "(", "self", ".", "scorer", ".", "score_sentence", "(", "corpus_utils", ".", "lower", "(", "ref", ")", ",", "corpus_utils", ".", "lower", "(", "val", ")", ")", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "cutoff_into_bucket", "(", "self", ".", "scorer", ".", "score_sentence", "(", "ref", ",", "val", ",", "src", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.ScoreSentenceBucketer.name": [[655, 657], ["bucketers.ScoreSentenceBucketer.scorer.name"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name"], ["", "", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "scorer", ".", "name", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.ScoreSentenceBucketer.idstr": [[658, 660], ["bucketers.ScoreSentenceBucketer.scorer.idstr"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.idstr"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "scorer", ".", "idstr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LengthSentenceBucketer.__init__": [[666, 670], ["bucketers.LengthSentenceBucketer.set_bucket_cutoffs"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.set_bucket_cutoffs"], ["def", "__init__", "(", "self", ",", "bucket_cutoffs", "=", "None", ")", ":", "\n", "    ", "if", "bucket_cutoffs", "is", "None", ":", "\n", "      ", "bucket_cutoffs", "=", "[", "10", ",", "20", ",", "30", ",", "40", ",", "50", ",", "60", "]", "\n", "", "self", ".", "set_bucket_cutoffs", "(", "bucket_cutoffs", ",", "num_type", "=", "'int'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LengthSentenceBucketer.calc_bucket": [[671, 673], ["bucketers.LengthSentenceBucketer.cutoff_into_bucket", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.cutoff_into_bucket"], ["", "def", "calc_bucket", "(", "self", ",", "val", ",", "ref", "=", "None", ",", "src", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "cutoff_into_bucket", "(", "len", "(", "ref", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LengthSentenceBucketer.name": [[674, 676], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"length\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LengthSentenceBucketer.idstr": [[677, 679], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"length\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LengthDiffSentenceBucketer.__init__": [[685, 689], ["bucketers.LengthDiffSentenceBucketer.set_bucket_cutoffs"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.set_bucket_cutoffs"], ["def", "__init__", "(", "self", ",", "bucket_cutoffs", "=", "None", ")", ":", "\n", "    ", "if", "bucket_cutoffs", "is", "None", ":", "\n", "      ", "bucket_cutoffs", "=", "[", "-", "20", ",", "-", "10", ",", "-", "5", ",", "-", "4", ",", "-", "3", ",", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "11", ",", "21", "]", "\n", "", "self", ".", "set_bucket_cutoffs", "(", "bucket_cutoffs", ",", "num_type", "=", "'int'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LengthDiffSentenceBucketer.calc_bucket": [[690, 692], ["bucketers.LengthDiffSentenceBucketer.cutoff_into_bucket", "len", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.cutoff_into_bucket"], ["", "def", "calc_bucket", "(", "self", ",", "val", ",", "ref", "=", "None", ",", "src", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "cutoff_into_bucket", "(", "len", "(", "val", ")", "-", "len", "(", "ref", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LengthDiffSentenceBucketer.name": [[693, 695], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"len(output)-len(reference)\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LengthDiffSentenceBucketer.idstr": [[696, 698], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"lengthdiff\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LabelSentenceBucketer.__init__": [[701, 715], ["len", "collections.defaultdict", "enumerate", "type", "label_set.split.split.split"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "label_set", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    A bucketer that buckets sentences by their labels.\n\n    Args:\n      label_set: The set of labels to use as buckets. This can be a list, or a string separated by '+'s.\n    \"\"\"", "\n", "if", "type", "(", "label_set", ")", "==", "str", ":", "\n", "      ", "label_set", "=", "label_set", ".", "split", "(", "'+'", ")", "\n", "", "self", ".", "bucket_strs", "=", "label_set", "+", "[", "'other'", "]", "\n", "label_set_len", "=", "len", "(", "label_set", ")", "\n", "self", ".", "bucket_map", "=", "defaultdict", "(", "lambda", ":", "label_set_len", ")", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label_set", ")", ":", "\n", "      ", "self", ".", "bucket_map", "[", "l", "]", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LabelSentenceBucketer.calc_bucket": [[716, 718], ["None"], "methods", ["None"], ["", "", "def", "calc_bucket", "(", "self", ",", "val", ",", "ref", "=", "None", ",", "src", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "bucket_map", "[", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LabelSentenceBucketer.name": [[719, 721], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"labels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.LabelSentenceBucketer.idstr": [[722, 724], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"labels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.MultiLabelSentenceBucketer.__init__": [[727, 741], ["len", "collections.defaultdict", "enumerate", "type", "label_set.split.split.split"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "label_set", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    A bucketer that buckets sentences by their labels.\n\n    Args:\n      label_set: The set of labels to use as buckets. This can be a list, or a string separated by '+'s.\n    \"\"\"", "\n", "if", "type", "(", "label_set", ")", "==", "str", ":", "\n", "      ", "label_set", "=", "label_set", ".", "split", "(", "'+'", ")", "\n", "", "self", ".", "bucket_strs", "=", "label_set", "+", "[", "'other'", "]", "\n", "label_set_len", "=", "len", "(", "label_set", ")", "\n", "self", ".", "bucket_map", "=", "defaultdict", "(", "lambda", ":", "label_set_len", ")", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label_set", ")", ":", "\n", "      ", "self", ".", "bucket_map", "[", "l", "]", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.MultiLabelSentenceBucketer.calc_bucket": [[742, 745], ["label.split.split.split"], "methods", ["None"], ["", "", "def", "calc_bucket", "(", "self", ",", "val", ",", "ref", "=", "None", ",", "src", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "    ", "label", "=", "label", ".", "split", "(", "'+'", ")", "\n", "return", "[", "self", ".", "bucket_map", "[", "l", "]", "for", "l", "in", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.MultiLabelSentenceBucketer.name": [[746, 748], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"multilabels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.MultiLabelSentenceBucketer.idstr": [[749, 751], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"multilabels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.__init__": [[754, 767], ["bucketers.NumericalLabelSentenceBucketer.set_bucket_cutoffs"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.set_bucket_cutoffs"], ["  ", "def", "__init__", "(", "self", ",", "bucket_cutoffs", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    A bucketer that buckets sentences by labels that are numerical values.\n\n    Args:\n      bucket_cutoffs: Cutoffs for each bucket.\n                      The first bucket will be range(0,bucket_cutoffs[0]).\n                      Middle buckets will be range(bucket_cutoffs[i],bucket_cutoffs[i-1].\n                      Final bucket will be everything greater than bucket_cutoffs[-1].\n    \"\"\"", "\n", "if", "bucket_cutoffs", "is", "None", ":", "\n", "      ", "bucket_cutoffs", "=", "[", "0.25", ",", "0.5", ",", "0.75", "]", "\n", "", "self", ".", "set_bucket_cutoffs", "(", "bucket_cutoffs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.calc_bucket": [[768, 770], ["bucketers.NumericalLabelSentenceBucketer.cutoff_into_bucket", "float"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.Bucketer.cutoff_into_bucket"], ["", "def", "calc_bucket", "(", "self", ",", "val", ",", "ref", "=", "None", ",", "src", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "cutoff_into_bucket", "(", "float", "(", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.name": [[771, 773], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "\"numerical labels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.NumericalLabelSentenceBucketer.idstr": [[774, 776], ["None"], "methods", ["None"], ["", "def", "idstr", "(", "self", ")", ":", "\n", "    ", "return", "\"numlabels\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.create_word_bucketer_from_profile": [[777, 805], ["type", "bucketers.FreqWordBucketer", "bucketers.CaseWordBucketer", "compare_mt.arg_utils.parse_intfloat", "bucketers.LabelWordBucketer", "bucket_cutoffs.split", "bucketers.MultiLabelWordBucketer", "bucketers.NumericalLabelWordBucketer", "ValueError"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_intfloat"], ["", "", "def", "create_word_bucketer_from_profile", "(", "bucket_type", ",", "\n", "freq_counts", "=", "None", ",", "freq_count_file", "=", "None", ",", "freq_corpus_file", "=", "None", ",", "freq_data", "=", "None", ",", "\n", "label_set", "=", "None", ",", "\n", "bucket_cutoffs", "=", "None", ",", "\n", "case_insensitive", "=", "False", ")", ":", "\n", "  ", "if", "type", "(", "bucket_cutoffs", ")", "==", "str", ":", "\n", "    ", "bucket_cutoffs", "=", "[", "arg_utils", ".", "parse_intfloat", "(", "x", ")", "for", "x", "in", "bucket_cutoffs", ".", "split", "(", "':'", ")", "]", "\n", "", "if", "bucket_type", "==", "'freq'", ":", "\n", "    ", "return", "FreqWordBucketer", "(", "\n", "freq_counts", "=", "freq_counts", ",", "\n", "freq_count_file", "=", "freq_count_file", ",", "\n", "freq_corpus_file", "=", "freq_corpus_file", ",", "\n", "freq_data", "=", "freq_data", ",", "\n", "bucket_cutoffs", "=", "bucket_cutoffs", ",", "\n", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "if", "bucket_type", "==", "'case'", ":", "\n", "    ", "return", "CaseWordBucketer", "(", ")", "\n", "", "elif", "bucket_type", "==", "'label'", ":", "\n", "    ", "return", "LabelWordBucketer", "(", "\n", "label_set", "=", "label_set", ")", "\n", "", "elif", "bucket_type", "==", "'multilabel'", ":", "\n", "    ", "return", "MultiLabelWordBucketer", "(", "\n", "label_set", "=", "label_set", ")", "\n", "", "elif", "bucket_type", "==", "'numlabel'", ":", "\n", "    ", "return", "NumericalLabelWordBucketer", "(", "\n", "bucket_cutoffs", "=", "bucket_cutoffs", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "f'Illegal bucket type {bucket_type}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.create_sentence_bucketer_from_profile": [[806, 828], ["type", "bucketers.ScoreSentenceBucketer", "compare_mt.arg_utils.parse_intfloat", "bucketers.LengthSentenceBucketer", "bucket_cutoffs.split", "bucketers.LengthDiffSentenceBucketer", "bucketers.LabelSentenceBucketer", "bucketers.MultiLabelSentenceBucketer", "bucketers.NumericalLabelSentenceBucketer", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_intfloat"], ["", "", "def", "create_sentence_bucketer_from_profile", "(", "bucket_type", ",", "\n", "score_type", "=", "None", ",", "\n", "bucket_cutoffs", "=", "None", ",", "\n", "label_set", "=", "None", ",", "\n", "case_insensitive", "=", "False", ")", ":", "\n", "  ", "if", "type", "(", "bucket_cutoffs", ")", "==", "str", ":", "\n", "    ", "bucket_cutoffs", "=", "[", "arg_utils", ".", "parse_intfloat", "(", "x", ")", "for", "x", "in", "bucket_cutoffs", ".", "split", "(", "':'", ")", "]", "\n", "", "if", "bucket_type", "==", "'score'", ":", "\n", "    ", "return", "ScoreSentenceBucketer", "(", "score_type", ",", "bucket_cutoffs", "=", "bucket_cutoffs", ",", "case_insensitive", "=", "case_insensitive", ")", "\n", "", "elif", "bucket_type", "==", "'length'", ":", "\n", "    ", "return", "LengthSentenceBucketer", "(", "bucket_cutoffs", "=", "bucket_cutoffs", ")", "\n", "", "elif", "bucket_type", "==", "'lengthdiff'", ":", "\n", "    ", "return", "LengthDiffSentenceBucketer", "(", "bucket_cutoffs", "=", "bucket_cutoffs", ")", "\n", "", "elif", "bucket_type", "==", "'label'", ":", "\n", "    ", "return", "LabelSentenceBucketer", "(", "label_set", "=", "label_set", ")", "\n", "", "elif", "bucket_type", "==", "'multilabel'", ":", "\n", "    ", "return", "MultiLabelSentenceBucketer", "(", "\n", "label_set", "=", "label_set", ")", "\n", "", "elif", "bucket_type", "==", "'numlabel'", ":", "\n", "    ", "return", "NumericalLabelSentenceBucketer", "(", "bucket_cutoffs", "=", "bucket_cutoffs", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "f'Illegal bucket type {bucket_type}'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.CachedPorterStemmer.__init__": [[23, 25], ["nltk.stem.porter.PorterStemmer.__init__"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer.RougeScorer.__init__"], ["def", "__init__", "(", "self", ",", "mode", "=", "PorterStemmer", ".", "NLTK_EXTENSIONS", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.CachedPorterStemmer.stem": [[26, 29], ["functools.lru_cache", "super().stem"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.CachedPorterStemmer.stem"], ["", "@", "lru_cache", "(", "maxsize", "=", "50000", ")", "\n", "def", "stem", "(", "self", ",", "word", ",", "to_lowercase", "=", "True", ")", ":", "\n", "    ", "return", "super", "(", ")", ".", "stem", "(", "word", ",", "to_lowercase", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.extract_cache_dicts": [[4, 13], ["zip", "len", "len", "ValueError", "len"], "function", ["None"], ["def", "extract_cache_dicts", "(", "cache_dicts", ",", "key_list", ",", "num_out", ")", ":", "\n", "  ", "if", "cache_dicts", "is", "not", "None", ":", "\n", "    ", "if", "len", "(", "cache_dicts", ")", "!=", "num_out", ":", "\n", "       ", "raise", "ValueError", "(", "f'Length of cache_dicts should be equal to the number of output files!'", ")", "\n", "", "if", "len", "(", "key_list", ")", "==", "1", ":", "\n", "      ", "return", "[", "c", "[", "key_list", "[", "0", "]", "]", "for", "c", "in", "cache_dicts", "]", "\n", "", "return", "zip", "(", "*", "[", "[", "c", "[", "k", "]", "for", "k", "in", "key_list", "]", "for", "c", "in", "cache_dicts", "]", ")", "\n", "\n", "", "return", "[", "None", "]", "*", "len", "(", "key_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.return_cache_dict": [[14, 20], ["len", "ValueError", "zip"], "function", ["None"], ["", "def", "return_cache_dict", "(", "key_list", ",", "value_list", ")", ":", "\n", "  ", "for", "v", "in", "value_list", ":", "\n", "    ", "if", "len", "(", "v", ")", "!=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "f'Only support caching for one system at a time!'", ")", "\n", "", "", "cache_dict", "=", "{", "k", ":", "v", "[", "0", "]", "for", "(", "k", ",", "v", ")", "in", "zip", "(", "key_list", ",", "value_list", ")", "}", "\n", "return", "cache_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report": [[23, 88], ["int", "float", "compare_mt.scorers.create_scorer_from_profile", "compare_mt.cache_utils.extract_cache_dicts", "compare_mt.reporters.ScoreReport", "reporters.ScoreReport.generate_report", "type", "len", "zip", "compare_mt.cache_utils.return_cache_dict", "range", "compare_mt.sign_utils.eval_with_paired_bootstrap", "list", "len", "range", "zip", "len", "direcs.append", "scorers.create_scorer_from_profile.score_corpus", "scorers.create_scorer_from_profile.cache_stats"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.extract_cache_dicts", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.generate_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.return_cache_dict", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.sign_utils.eval_with_paired_bootstrap", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats"], ["def", "generate_score_report", "(", "\n", "ref", ",", "outs", ",", "\n", "src", "=", "None", ",", "\n", "score_type", "=", "'bleu'", ",", "\n", "bootstrap", "=", "0", ",", "prob_thresh", "=", "0.05", ",", "\n", "meteor_directory", "=", "None", ",", "options", "=", "None", ",", "\n", "title", "=", "None", ",", "\n", "case_insensitive", "=", "False", ",", "\n", "to_cache", "=", "False", ",", "\n", "cache_dicts", "=", "None", "\n", ")", ":", "\n", "  ", "\"\"\"\n  Generate a report comparing overall scores of system(s) in both plain text and graphs.\n\n  Args:\n    ref: Tokens from the reference\n    outs: Tokens from the output file(s)\n    src: Tokens for the source \n    score_type: A string specifying the scoring type (bleu/length)\n    bootstrap: Number of samples for significance test (0 to disable)\n    prob_thresh: P-value threshold for significance test\n    meteor_directory: Path to the directory of the METEOR code\n    options: Options when using external program\n    compare_directions: A string specifying which systems to compare \n    title: A string specifying the caption of the printed table\n    case_insensitive: A boolean specifying whether to turn on the case insensitive option\n    to_cache: Return a list of computed statistics if True\n    cache_dicts: A list of dictionaries that store cached statistics for each output\n  \"\"\"", "\n", "# check and set parameters", "\n", "bootstrap", "=", "int", "(", "bootstrap", ")", "\n", "prob_thresh", "=", "float", "(", "prob_thresh", ")", "\n", "if", "type", "(", "case_insensitive", ")", "==", "str", ":", "\n", "    ", "case_insensitive", "=", "True", "if", "case_insensitive", "==", "'True'", "else", "False", "\n", "\n", "# compute statistics", "\n", "", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "score_type", ",", "case_insensitive", "=", "case_insensitive", ",", "meteor_directory", "=", "meteor_directory", ",", "options", "=", "options", ")", "\n", "\n", "cache_key_list", "=", "[", "'scores'", ",", "'strs'", ",", "'sign_stats'", "]", "\n", "scores", ",", "strs", ",", "sign_stats", "=", "cache_utils", ".", "extract_cache_dicts", "(", "cache_dicts", ",", "cache_key_list", ",", "len", "(", "outs", ")", ")", "\n", "if", "cache_dicts", "is", "None", ":", "\n", "    ", "scores", ",", "strs", "=", "zip", "(", "*", "[", "scorer", ".", "score_corpus", "(", "ref", ",", "out", ",", "src", "=", "src", ")", "for", "out", "in", "outs", "]", ")", "\n", "\n", "", "if", "to_cache", ":", "\n", "    ", "cache_dict", "=", "cache_utils", ".", "return_cache_dict", "(", "cache_key_list", ",", "[", "scores", ",", "strs", ",", "[", "scorer", ".", "cache_stats", "(", "ref", ",", "outs", "[", "0", "]", ",", "src", "=", "src", ")", "]", "]", ")", "\n", "return", "cache_dict", "\n", "\n", "", "if", "bootstrap", "!=", "0", ":", "\n", "    ", "direcs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "scores", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "scores", ")", ")", ":", "\n", "        ", "direcs", ".", "append", "(", "(", "i", ",", "j", ")", ")", "\n", "", "", "wins", ",", "sys_stats", "=", "sign_utils", ".", "eval_with_paired_bootstrap", "(", "ref", ",", "outs", ",", "src", ",", "scorer", ",", "direcs", ",", "num_samples", "=", "bootstrap", ",", "cache_stats", "=", "sign_stats", ")", "\n", "wins", "=", "list", "(", "zip", "(", "direcs", ",", "wins", ")", ")", "\n", "", "else", ":", "\n", "    ", "wins", "=", "sys_stats", "=", "None", "\n", "\n", "# generate reports", "\n", "", "reporter", "=", "reporters", ".", "ScoreReport", "(", "scorer", "=", "scorer", ",", "scores", "=", "scores", ",", "strs", "=", "strs", ",", "\n", "wins", "=", "wins", ",", "sys_stats", "=", "sys_stats", ",", "prob_thresh", "=", "prob_thresh", ",", "\n", "title", "=", "title", ")", "\n", "reporter", ".", "generate_report", "(", "output_fig_file", "=", "f'score-{score_type}-{bootstrap}'", ",", "\n", "output_fig_format", "=", "'pdf'", ",", "\n", "output_directory", "=", "'outputs'", ")", "\n", "return", "reporter", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_word_accuracy_report": [[89, 182], ["compare_mt.bucketers.create_word_bucketer_from_profile", "compare_mt.cache_utils.extract_cache_dicts", "bucketers.create_word_bucketer_from_profile.calc_examples", "compare_mt.reporters.WordReport", "reporters.WordReport.generate_report", "type", "type", "type", "compare_mt.corpus_utils.load_tokens", "compare_mt.arg_utils.parse_files", "enumerate", "len", "bucketers.create_word_bucketer_from_profile.calc_statistics", "list", "list", "len", "len", "bucketers.create_word_bucketer_from_profile.calc_bucket_details", "compare_mt.cache_utils.return_cache_dict", "compare_mt.corpus_utils.load_tokens", "len", "len", "ValueError", "zip", "numpy.concatenate", "numpy.concatenate", "len", "len", "ValueError"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.create_word_bucketer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.extract_cache_dicts", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_examples", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.generate_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_files", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_statistics", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_bucket_details", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.return_cache_dict", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens"], ["", "def", "generate_word_accuracy_report", "(", "ref", ",", "outs", ",", "\n", "src", "=", "None", ",", "\n", "acc_type", "=", "'fmeas'", ",", "bucket_type", "=", "'freq'", ",", "bucket_cutoffs", "=", "None", ",", "\n", "freq_count_file", "=", "None", ",", "freq_corpus_file", "=", "None", ",", "\n", "label_set", "=", "None", ",", "\n", "ref_labels", "=", "None", ",", "out_labels", "=", "None", ",", "\n", "title", "=", "None", ",", "\n", "case_insensitive", "=", "False", ",", "\n", "output_bucket_details", "=", "False", ",", "\n", "to_cache", "=", "False", ",", "\n", "cache_dicts", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Generate a report comparing the word accuracy in both plain text and graphs.\n\n  Args:\n    ref: Tokens from the reference\n    outs: Tokens from the output file(s)\n    src: Tokens from the source\n    acc_type: The type of accuracy to show (prec/rec/fmeas). Can also have multiple separated by '+'.\n    bucket_type: A string specifying the way to bucket words together to calculate F-measure (freq/tag)\n    bucket_cutoffs: The boundaries between buckets, specified as a colon-separated string.\n    freq_corpus_file: When using \"freq\" as a bucketer, which corpus to use to calculate frequency.\n                      By default this uses the frequency in the reference test set, but it's often more informative\n                      to use the frequency in the training set, in which case you specify the path of the\n                      training corpus.\n    freq_count_file: An alternative to freq_corpus that uses a count file in \"word\\tfreq\" format.\n    ref_labels: either a filename of a file full of reference labels, or a list of strings corresponding to `ref`.\n    out_labels: output labels. must be specified if ref_labels is specified.\n    title: A string specifying the caption of the printed table\n    case_insensitive: A boolean specifying whether to turn on the case insensitive option\n    output_bucket_details: A boolean specifying whether to output the number of words in each bucket\n    to_cache: Return a list of computed statistics if True\n    cache_dicts: A list of dictionaries that store cached statistics for each output\n  \"\"\"", "\n", "# check and set parameters", "\n", "if", "type", "(", "case_insensitive", ")", "==", "str", ":", "\n", "    ", "case_insensitive", "=", "True", "if", "case_insensitive", "==", "'True'", "else", "False", "\n", "", "if", "type", "(", "output_bucket_details", ")", "==", "str", ":", "\n", "    ", "output_bucket_details", "=", "True", "if", "output_bucket_details", "==", "'True'", "else", "False", "\n", "\n", "", "if", "type", "(", "ref_labels", ")", "==", "str", ":", "\n", "    ", "ref_labels", "=", "corpus_utils", ".", "load_tokens", "(", "ref_labels", ")", "\n", "", "if", "out_labels", "is", "not", "None", ":", "\n", "    ", "out_label_files", "=", "arg_utils", ".", "parse_files", "(", "out_labels", ")", "\n", "out_labels", "=", "[", "corpus_utils", ".", "load_tokens", "(", "x", ")", "for", "x", "in", "out_label_files", "]", "\n", "if", "len", "(", "out_labels", ")", "!=", "len", "(", "outs", ")", ":", "\n", "      ", "raise", "ValueError", "(", "f'The number of output files should be equal to the number of output labels.'", ")", "\n", "", "for", "i", ",", "(", "o", ",", "ol", ")", "in", "enumerate", "(", "zip", "(", "outs", ",", "out_labels", ")", ")", ":", "\n", "      ", "if", "len", "(", "o", ")", "!=", "len", "(", "ol", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f'The labels in {out_label_files[i]} do not match the length of the output file {outs[i]}.'", ")", "\n", "\n", "# compute statistics", "\n", "", "", "", "bucketer", "=", "bucketers", ".", "create_word_bucketer_from_profile", "(", "bucket_type", ",", "\n", "bucket_cutoffs", "=", "bucket_cutoffs", ",", "\n", "freq_count_file", "=", "freq_count_file", ",", "\n", "freq_corpus_file", "=", "freq_corpus_file", ",", "\n", "freq_data", "=", "ref", ",", "\n", "label_set", "=", "label_set", ",", "\n", "case_insensitive", "=", "case_insensitive", ")", "\n", "\n", "cache_key_list", "=", "[", "'statistics'", ",", "'my_ref_total_list'", ",", "'my_out_totals_list'", ",", "'my_out_matches_list'", "]", "\n", "statistics", ",", "my_ref_total_list", ",", "my_out_totals_list", ",", "my_out_matches_list", "=", "cache_utils", ".", "extract_cache_dicts", "(", "cache_dicts", ",", "cache_key_list", ",", "len", "(", "outs", ")", ")", "\n", "if", "cache_dicts", "is", "None", ":", "\n", "    ", "statistics", ",", "my_ref_total_list", ",", "my_out_totals_list", ",", "my_out_matches_list", "=", "bucketer", ".", "calc_statistics", "(", "ref", ",", "outs", ",", "ref_labels", "=", "ref_labels", ",", "out_labels", "=", "out_labels", ")", "\n", "", "else", ":", "\n", "    ", "my_ref_total_list", "=", "my_ref_total_list", "[", "0", "]", "\n", "my_out_totals_list", "=", "list", "(", "np", ".", "concatenate", "(", "my_out_totals_list", ",", "1", ")", ")", "\n", "my_out_matches_list", "=", "list", "(", "np", ".", "concatenate", "(", "my_out_matches_list", ",", "1", ")", ")", "\n", "", "examples", "=", "bucketer", ".", "calc_examples", "(", "len", "(", "ref", ")", ",", "len", "(", "outs", ")", ",", "statistics", ",", "my_ref_total_list", ",", "my_out_matches_list", ")", "\n", "\n", "bucket_cnts", ",", "bucket_intervals", "=", "bucketer", ".", "calc_bucket_details", "(", "my_ref_total_list", ",", "my_out_totals_list", ",", "my_out_matches_list", ")", "if", "output_bucket_details", "else", "(", "None", ",", "None", ")", "\n", "\n", "if", "to_cache", ":", "\n", "    ", "cache_dict", "=", "cache_utils", ".", "return_cache_dict", "(", "cache_key_list", ",", "[", "statistics", ",", "[", "my_ref_total_list", "]", ",", "[", "my_out_totals_list", "]", ",", "[", "my_out_matches_list", "]", "]", ")", "\n", "return", "cache_dict", "\n", "\n", "# generate reports", "\n", "", "reporter", "=", "reporters", ".", "WordReport", "(", "bucketer", "=", "bucketer", ",", "\n", "statistics", "=", "statistics", ",", "\n", "examples", "=", "examples", ",", "\n", "bucket_cnts", "=", "bucket_cnts", ",", "\n", "bucket_intervals", "=", "bucket_intervals", ",", "\n", "src_sents", "=", "src", ",", "\n", "ref_sents", "=", "ref", ",", "\n", "ref_labels", "=", "ref_labels", ",", "\n", "out_sents", "=", "outs", ",", "\n", "out_labels", "=", "out_labels", ",", "\n", "acc_type", "=", "acc_type", ",", "header", "=", "\"Word Accuracy Analysis\"", ",", "\n", "title", "=", "title", ")", "\n", "reporter", ".", "generate_report", "(", "output_fig_file", "=", "f'word-acc'", ",", "\n", "output_fig_format", "=", "'pdf'", ",", "\n", "output_directory", "=", "'outputs'", ")", "\n", "return", "reporter", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_src_word_accuracy_report": [[184, 275], ["compare_mt.corpus_utils.load_alignments", "compare_mt.bucketers.create_word_bucketer_from_profile", "compare_mt.cache_utils.extract_cache_dicts", "bucketers.create_word_bucketer_from_profile.calc_examples", "compare_mt.reporters.WordReport", "reporters.WordReport.generate_report", "type", "type", "ValueError", "ValueError", "type", "compare_mt.corpus_utils.load_tokens", "len", "list", "list", "bucketers.create_word_bucketer_from_profile.calc_statistics", "len", "len", "bucketers.create_word_bucketer_from_profile.calc_bucket_details", "compare_mt.cache_utils.return_cache_dict", "numpy.concatenate", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_alignments", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.create_word_bucketer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.extract_cache_dicts", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_examples", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.generate_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_statistics", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.WordBucketer.calc_bucket_details", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.return_cache_dict"], ["", "def", "generate_src_word_accuracy_report", "(", "ref", ",", "outs", ",", "src", ",", "ref_align_file", "=", "None", ",", "\n", "acc_type", "=", "'rec'", ",", "bucket_type", "=", "'freq'", ",", "bucket_cutoffs", "=", "None", ",", "\n", "freq_count_file", "=", "None", ",", "freq_corpus_file", "=", "None", ",", "\n", "label_set", "=", "None", ",", "\n", "src_labels", "=", "None", ",", "\n", "title", "=", "None", ",", "\n", "case_insensitive", "=", "False", ",", "\n", "output_bucket_details", "=", "False", ",", "\n", "to_cache", "=", "False", ",", "\n", "cache_dicts", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Generate a report for source word analysis in both plain text and graphs.\n\n  Args:\n    ref: Tokens from the reference\n    outs: Tokens from the output file(s)\n    src: Tokens from the source\n    ref_align_file: Alignment file for the reference\n    acc_type: The type of accuracy to show (prec/rec/fmeas). Can also have multiple separated by '+'.\n    bucket_type: A string specifying the way to bucket words together to calculate F-measure (freq/tag)\n    bucket_cutoffs: The boundaries between buckets, specified as a colon-separated string.\n    freq_corpus_file: When using \"freq\" as a bucketer, which corpus to use to calculate frequency.\n                      By default this uses the frequency in the reference test set, but it's often more informative\n                      se the frequency in the training set, in which case you specify the path of the target side\n                      he training corpus.\n    freq_count_file: An alternative to freq_corpus that uses a count file in \"word\\tfreq\" format.\n    src_labels: either a filename of a file full of source labels, or a list of strings corresponding to `ref`.\n    title: A string specifying the caption of the printed table\n    case_insensitive: A boolean specifying whether to turn on the case insensitive option\n    output_bucket_details: A boolean specifying whether to output the number of words in each bucket\n    to_cache: Return a list of computed statistics if True\n    cache_dicts: A list of dictionaries that store cached statistics for each output\n  \"\"\"", "\n", "# check and set parameters", "\n", "if", "type", "(", "case_insensitive", ")", "==", "str", ":", "\n", "    ", "case_insensitive", "=", "True", "if", "case_insensitive", "==", "'True'", "else", "False", "\n", "", "if", "type", "(", "output_bucket_details", ")", "==", "str", ":", "\n", "    ", "output_bucket_details", "=", "True", "if", "output_bucket_details", "==", "'True'", "else", "False", "\n", "\n", "", "if", "acc_type", "!=", "'rec'", ":", "\n", "    ", "raise", "ValueError", "(", "\"Source word analysis can only use recall as an accuracy type\"", ")", "\n", "", "if", "not", "src", "or", "not", "ref_align_file", ":", "\n", "    ", "raise", "ValueError", "(", "\"Must specify the source and the alignment file when performing source analysis.\"", ")", "\n", "", "if", "type", "(", "src_labels", ")", "==", "str", ":", "\n", "    ", "src_labels", "=", "corpus_utils", ".", "load_tokens", "(", "src_labels", ")", "\n", "\n", "", "ref_align", "=", "corpus_utils", ".", "load_alignments", "(", "ref_align_file", ")", "\n", "\n", "# compute statistics", "\n", "bucketer", "=", "bucketers", ".", "create_word_bucketer_from_profile", "(", "bucket_type", ",", "\n", "bucket_cutoffs", "=", "bucket_cutoffs", ",", "\n", "freq_count_file", "=", "freq_count_file", ",", "\n", "freq_corpus_file", "=", "freq_corpus_file", ",", "\n", "freq_data", "=", "src", ",", "\n", "label_set", "=", "label_set", ",", "\n", "case_insensitive", "=", "case_insensitive", ")", "\n", "\n", "cache_key_list", "=", "[", "'statistics'", ",", "'my_ref_total_list'", ",", "'my_out_totals_list'", ",", "'my_out_matches_list'", "]", "\n", "statistics", ",", "my_ref_total_list", ",", "my_out_totals_list", ",", "my_out_matches_list", "=", "cache_utils", ".", "extract_cache_dicts", "(", "cache_dicts", ",", "cache_key_list", ",", "len", "(", "outs", ")", ")", "\n", "if", "cache_dicts", "is", "not", "None", ":", "\n", "    ", "my_ref_total_list", "=", "my_ref_total_list", "[", "0", "]", "\n", "my_out_totals_list", "=", "list", "(", "np", ".", "concatenate", "(", "my_out_totals_list", ",", "1", ")", ")", "\n", "my_out_matches_list", "=", "list", "(", "np", ".", "concatenate", "(", "my_out_matches_list", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "    ", "statistics", ",", "my_ref_total_list", ",", "my_out_totals_list", ",", "my_out_matches_list", "=", "bucketer", ".", "calc_statistics", "(", "ref", ",", "outs", ",", "src", "=", "src", ",", "src_labels", "=", "src_labels", ",", "ref_aligns", "=", "ref_align", ")", "\n", "", "examples", "=", "bucketer", ".", "calc_examples", "(", "len", "(", "ref", ")", ",", "len", "(", "outs", ")", ",", "statistics", ",", "my_ref_total_list", ",", "my_out_matches_list", ")", "\n", "\n", "bucket_cnts", ",", "bucket_intervals", "=", "bucketer", ".", "calc_bucket_details", "(", "my_ref_total_list", ",", "my_out_totals_list", ",", "my_out_matches_list", ")", "if", "output_bucket_details", "else", "(", "None", ",", "None", ")", "\n", "\n", "if", "to_cache", ":", "\n", "    ", "cache_dict", "=", "cache_utils", ".", "return_cache_dict", "(", "cache_key_list", ",", "[", "statistics", ",", "[", "my_ref_total_list", "]", ",", "[", "my_out_totals_list", "]", ",", "[", "my_out_matches_list", "]", "]", ")", "\n", "return", "cache_dict", "\n", "\n", "# generate reports", "\n", "", "reporter", "=", "reporters", ".", "WordReport", "(", "bucketer", "=", "bucketer", ",", "\n", "statistics", "=", "statistics", ",", "\n", "examples", "=", "examples", ",", "\n", "bucket_cnts", "=", "bucket_cnts", ",", "\n", "bucket_intervals", "=", "bucket_intervals", ",", "\n", "src_sents", "=", "src", ",", "\n", "ref_sents", "=", "ref", ",", "\n", "ref_aligns", "=", "ref_align", ",", "\n", "out_sents", "=", "outs", ",", "\n", "src_labels", "=", "src_labels", ",", "\n", "acc_type", "=", "acc_type", ",", "header", "=", "\"Source Word Accuracy Analysis\"", ",", "\n", "title", "=", "title", ")", "\n", "\n", "reporter", ".", "generate_report", "(", "output_fig_file", "=", "f'src-word-acc'", ",", "\n", "output_fig_format", "=", "'pdf'", ",", "\n", "output_directory", "=", "'outputs'", ")", "\n", "return", "reporter", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_bucketed_report": [[276, 376], ["compare_mt.bucketers.create_sentence_bucketer_from_profile", "compare_mt.cache_utils.extract_cache_dicts", "compare_mt.reporters.SentenceReport", "reporters.SentenceReport.generate_report", "type", "type", "len", "compare_mt.cache_utils.return_cache_dict", "compare_mt.corpus_utils.load_tokens", "len", "len", "ValueError", "compare_mt.arg_utils.parse_files", "zip", "len", "compare_mt.scorers.create_scorer_from_profile", "ValueError", "bucketers.create_sentence_bucketer_from_profile.create_bucketed_corpus", "len", "bucket_cnt_calculator", "type", "len", "len", "ValueError", "enumerate", "aggregator", "bucketers.create_sentence_bucketer_from_profile.create_bucketed_corpus", "bucket_interval_calculator", "compare_mt.corpus_utils.load_tokens", "len", "len", "ValueError", "scorers.create_scorer_from_profile.score_corpus", "compare_mt.sign_utils.eval_with_paired_bootstrap", "enumerate", "type"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.create_sentence_bucketer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.extract_cache_dicts", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.generate_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.return_cache_dict", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_files", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.SentenceBucketer.create_bucketed_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.bucketers.SentenceBucketer.create_bucketed_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.sign_utils.eval_with_paired_bootstrap"], ["", "def", "generate_sentence_bucketed_report", "(", "ref", ",", "outs", ",", "src", "=", "None", ",", "\n", "bucket_type", "=", "'score'", ",", "bucket_cutoffs", "=", "None", ",", "\n", "statistic_type", "=", "'count'", ",", "\n", "score_measure", "=", "'sentbleu'", ",", "\n", "label_set", "=", "None", ",", "\n", "ref_labels", "=", "None", ",", "out_labels", "=", "None", ",", "\n", "title", "=", "None", ",", "\n", "case_insensitive", "=", "False", ",", "\n", "output_bucket_details", "=", "False", ",", "\n", "to_cache", "=", "False", ",", "\n", "cache_dicts", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Generate a report of sentences by bucket in both plain text and graphs\n\n  Args:\n    ref: Tokens from the reference\n    outs: Tokens from the output file(s)\n    bucket_type: The type of bucketing method to use\n    score_measure: If using 'score' as either bucket_type or statistic_type, which scorer to use\n    ref_labels: either a filename of a file full of reference labels, or a list of strings corresponding to `ref`. Would overwrite out_labels if specified.\n    out_labels: output labels. \n    title: A string specifying the caption of the printed table\n    case_insensitive: A boolean specifying whether to turn on the case insensitive option\n    output_bucket_details: A boolean specifying whether to output the number of words in each bucket\n    to_cache: Return a list of computed statistics if True\n    cache_dicts: A list of dictionaries that store cached statistics for each output\n  \"\"\"", "\n", "# check and set parameters", "\n", "if", "type", "(", "case_insensitive", ")", "==", "str", ":", "\n", "    ", "case_insensitive", "=", "True", "if", "case_insensitive", "==", "'True'", "else", "False", "\n", "", "if", "type", "(", "output_bucket_details", ")", "==", "str", ":", "\n", "    ", "output_bucket_details", "=", "True", "if", "output_bucket_details", "==", "'True'", "else", "False", "\n", "\n", "", "if", "ref_labels", "is", "not", "None", ":", "\n", "    ", "ref_labels", "=", "corpus_utils", ".", "load_tokens", "(", "ref_labels", ")", "if", "type", "(", "ref_labels", ")", "==", "str", "else", "ref_labels", "\n", "if", "len", "(", "ref_labels", ")", "!=", "len", "(", "ref", ")", ":", "\n", "      ", "raise", "ValueError", "(", "f'The number of labels should be equal to the number of sentences.'", ")", "\n", "\n", "", "", "elif", "out_labels", "is", "not", "None", ":", "\n", "    ", "out_labels", "=", "arg_utils", ".", "parse_files", "(", "out_labels", ")", "\n", "if", "len", "(", "out_labels", ")", "!=", "len", "(", "outs", ")", ":", "\n", "      ", "raise", "ValueError", "(", "f'The number of output files should be equal to the number of output labels.'", ")", "\n", "\n", "", "out_labels", "=", "[", "corpus_utils", ".", "load_tokens", "(", "out_label", ")", "if", "type", "(", "out_label", ")", "==", "str", "else", "out_label", "for", "out_label", "in", "out_labels", "]", "\n", "for", "out", ",", "out_label", "in", "zip", "(", "outs", ",", "out_labels", ")", ":", "\n", "      ", "if", "len", "(", "out_label", ")", "!=", "len", "(", "out", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f'The number of labels should be equal to the number of sentences.'", ")", "\n", "\n", "# compute statistics", "\n", "", "", "", "bucketer", "=", "bucketers", ".", "create_sentence_bucketer_from_profile", "(", "bucket_type", ",", "bucket_cutoffs", "=", "bucket_cutoffs", ",", "\n", "score_type", "=", "score_measure", ",", "label_set", "=", "label_set", ",", "case_insensitive", "=", "case_insensitive", ")", "\n", "\n", "src", "=", "[", "None", "for", "_", "in", "ref", "]", "if", "src", "is", "None", "else", "src", "\n", "\n", "if", "statistic_type", "==", "'count'", ":", "\n", "    ", "scorer", "=", "None", "\n", "if", "bucket_type", "!=", "'score'", "and", "bucket_type", "!=", "'lengthdiff'", ":", "\n", "      ", "ref", "=", "ref_label", "=", "None", "\n", "", "aggregator", "=", "lambda", "out", ",", "refs", ",", "src", ":", "len", "(", "out", ")", "\n", "", "elif", "statistic_type", "==", "'score'", ":", "\n", "    ", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "score_measure", ",", "case_insensitive", "=", "case_insensitive", ")", "\n", "aggregator", "=", "lambda", "out", ",", "ref", ",", "src", ":", "scorer", ".", "score_corpus", "(", "ref", ",", "out", ",", "src", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "f'Illegal statistic_type {statistic_type}'", ")", "\n", "\n", "\n", "", "cache_key_list", "=", "[", "'stats'", "]", "\n", "stats", "=", "cache_utils", ".", "extract_cache_dicts", "(", "cache_dicts", ",", "cache_key_list", ",", "len", "(", "outs", ")", ")", "\n", "\n", "if", "cache_dicts", "is", "None", ":", "\n", "    ", "bcs", "=", "[", "bucketer", ".", "create_bucketed_corpus", "(", "out", ",", "ref", "=", "ref", ",", "src", "=", "src", ",", "ref_labels", "=", "ref_labels", "if", "ref_labels", "else", "None", ",", "out_labels", "=", "out_labels", "[", "i", "]", "if", "out_labels", "else", "None", ")", "for", "i", ",", "out", "in", "enumerate", "(", "outs", ")", "]", "\n", "stats", "=", "[", "[", "aggregator", "(", "out", ",", "ref", ",", "src", ")", "for", "(", "out", ",", "ref", ",", "src", ")", "in", "bc", "]", "for", "bc", "in", "bcs", "]", "\n", "\n", "", "if", "output_bucket_details", "and", "statistic_type", "==", "'score'", ":", "\n", "    ", "bucket_cnt_calculator", "=", "lambda", "out", ",", "ref", ",", "src", ":", "len", "(", "out", ")", "\n", "bucket_interval_calculator", "=", "lambda", "out", ",", "ref", ":", "sign_utils", ".", "eval_with_paired_bootstrap", "(", "ref", ",", "[", "out", "]", ",", "src", ",", "scorer", ",", "None", ")", "[", "1", "]", "[", "0", "]", "\n", "if", "cache_dicts", "is", "not", "None", ":", "# we don't cache bcs", "\n", "      ", "bcs", "=", "[", "bucketer", ".", "create_bucketed_corpus", "(", "out", ",", "ref", "=", "ref", ",", "src", "=", "src", ",", "ref_labels", "=", "ref_labels", "if", "ref_labels", "else", "None", ",", "out_labels", "=", "out_labels", "[", "i", "]", "if", "out_labels", "else", "None", ")", "for", "i", ",", "out", "in", "enumerate", "(", "outs", ")", "]", "\n", "", "bucket_cnts", "=", "[", "bucket_cnt_calculator", "(", "out", ",", "ref", ",", "src", ")", "for", "(", "out", ",", "ref", ",", "src", ")", "in", "bcs", "[", "0", "]", "]", "\n", "bucket_intervals", "=", "[", "[", "bucket_interval_calculator", "(", "out", ",", "ref", ",", "src", ")", "for", "(", "out", ",", "ref", ",", "src", ")", "in", "bc", "]", "for", "bc", "in", "bcs", "]", "\n", "", "else", ":", "\n", "    ", "bucket_cnts", "=", "bucket_intervals", "=", "None", "\n", "\n", "\n", "", "if", "to_cache", ":", "\n", "    ", "cache_dict", "=", "cache_utils", ".", "return_cache_dict", "(", "cache_key_list", ",", "[", "stats", "]", ")", "\n", "return", "cache_dict", "\n", "\n", "# generate reports", "\n", "", "reporter", "=", "reporters", ".", "SentenceReport", "(", "bucketer", "=", "bucketer", ",", "\n", "sys_stats", "=", "stats", ",", "\n", "statistic_type", "=", "statistic_type", ",", "scorer", "=", "scorer", ",", "\n", "bucket_cnts", "=", "bucket_cnts", ",", "\n", "bucket_intervals", "=", "bucket_intervals", ",", "\n", "title", "=", "title", ")", "\n", "\n", "reporter", ".", "generate_report", "(", "output_fig_file", "=", "f'sentence-{statistic_type}-{score_measure}'", ",", "\n", "output_fig_format", "=", "'pdf'", ",", "\n", "output_directory", "=", "'outputs'", ")", "\n", "return", "reporter", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_ngram_report": [[378, 471], ["compare_mt.cache_utils.extract_cache_dicts", "compare_mt.arg_utils.parse_compare_directions", "compare_mt.reporters.NgramReport", "reporters.NgramReport.generate_report", "int", "int", "int", "float", "type", "compare_mt.arg_utils.parse_files", "type", "enumerate", "len", "zip", "compare_mt.cache_utils.return_cache_dict", "sorted", "type", "len", "len", "ValueError", "compare_mt.corpus_utils.lower", "compare_mt.corpus_utils.load_tokens", "scores.append", "score.items", "compare_mt.corpus_utils.lower", "type", "compare_mt.corpus_utils.load_tokens", "range", "compare_mt.stat_utils.extract_salient_features", "scores.append", "operator.itemgetter", "type", "len", "compare_mt.ngram_utils.compare_ngrams", "compare_mt.stat_utils.extract_salient_features", "scores.append", "ValueError", "zip", "compare_mt.stat_utils.extract_salient_features"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.extract_cache_dicts", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_compare_directions", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.generate_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_files", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.return_cache_dict", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.stat_utils.extract_salient_features", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.ngram_utils.compare_ngrams", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.stat_utils.extract_salient_features", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.stat_utils.extract_salient_features"], ["", "def", "generate_ngram_report", "(", "ref", ",", "outs", ",", "\n", "min_ngram_length", "=", "1", ",", "max_ngram_length", "=", "4", ",", "\n", "report_length", "=", "50", ",", "alpha", "=", "1.0", ",", "compare_type", "=", "'match'", ",", "\n", "ref_labels", "=", "None", ",", "out_labels", "=", "None", ",", "\n", "compare_directions", "=", "'0-1'", ",", "\n", "title", "=", "None", ",", "\n", "case_insensitive", "=", "False", ",", "\n", "to_cache", "=", "False", ",", "\n", "cache_dicts", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Generate a report comparing aggregate n-gram statistics in both plain text and graphs\n\n  Args:\n    ref: Tokens from the reference\n    outs: Tokens from the output file(s)\n    min_ngram_length: minimum n-gram length\n    max_ngram_length: maximum n-gram length\n    report_length: the number of n-grams to report\n    alpha: when sorting n-grams for salient features, the smoothing coefficient. A higher smoothing coefficient\n           will result in more frequent phenomena (sometimes this is good).\n    compare_type: what type of statistic to compare\n                  (match: n-grams that match the reference, over: over-produced ngrams, under: under-produced ngrams)\n    ref_labels: either a filename of a file full of reference labels, or a list of strings corresponding to `ref`.\n                If specified, will aggregate statistics over labels instead of n-grams.\n    out_labels: output labels. must be specified if ref_labels is specified.\n    compare_directions: A string specifying which systems to compare\n    title: A string specifying the caption of the printed table\n    case_insensitive: A boolean specifying whether to turn on the case insensitive option\n    to_cache: Return a list of computed statistics if True\n    cache_dicts: A list of dictionaries that store cached statistics for each output\n  \"\"\"", "\n", "# check and set parameters", "\n", "min_ngram_length", ",", "max_ngram_length", ",", "report_length", "=", "int", "(", "min_ngram_length", ")", ",", "int", "(", "max_ngram_length", ")", ",", "int", "(", "report_length", ")", "\n", "alpha", "=", "float", "(", "alpha", ")", "if", "type", "(", "alpha", ")", "==", "str", "else", "alpha", "\n", "if", "type", "(", "case_insensitive", ")", "==", "str", ":", "\n", "    ", "case_insensitive", "=", "True", "if", "case_insensitive", "==", "'True'", "else", "False", "\n", "\n", "", "if", "out_labels", "is", "not", "None", ":", "\n", "    ", "out_labels", "=", "arg_utils", ".", "parse_files", "(", "out_labels", ")", "\n", "if", "len", "(", "out_labels", ")", "!=", "len", "(", "outs", ")", ":", "\n", "      ", "raise", "ValueError", "(", "f'The number of output files should be equal to the number of output labels.'", ")", "\n", "\n", "", "", "if", "type", "(", "ref_labels", ")", "==", "str", ":", "\n", "    ", "label_files_str", "=", "f'    ref_labels={ref_labels},'", "\n", "for", "i", ",", "out_label", "in", "enumerate", "(", "out_labels", ")", ":", "\n", "      ", "label_files_str", "+=", "f' out{i}_labels={out_label},'", "\n", "", "label_files", "=", "(", "label_files_str", ")", "\n", "", "else", ":", "\n", "    ", "label_files", "=", "None", "\n", "\n", "# compute statistics", "\n", "", "cache_key_list", "=", "[", "'totals'", ",", "'matches'", ",", "'overs'", ",", "'unders'", "]", "\n", "totals", ",", "matches", ",", "overs", ",", "unders", "=", "cache_utils", ".", "extract_cache_dicts", "(", "cache_dicts", ",", "cache_key_list", ",", "len", "(", "outs", ")", ")", "\n", "if", "cache_dicts", "is", "None", ":", "\n", "    ", "if", "not", "type", "(", "ref_labels", ")", "==", "str", "and", "case_insensitive", ":", "\n", "      ", "ref", "=", "corpus_utils", ".", "lower", "(", "ref", ")", "\n", "outs", "=", "[", "corpus_utils", ".", "lower", "(", "out", ")", "for", "out", "in", "outs", "]", "\n", "\n", "", "ref_labels", "=", "corpus_utils", ".", "load_tokens", "(", "ref_labels", ")", "if", "type", "(", "ref_labels", ")", "==", "str", "else", "ref_labels", "\n", "out_labels", "=", "[", "corpus_utils", ".", "load_tokens", "(", "out_labels", "[", "i", "]", ")", "if", "not", "out_labels", "is", "None", "else", "None", "for", "i", "in", "range", "(", "len", "(", "outs", ")", ")", "]", "\n", "totals", ",", "matches", ",", "overs", ",", "unders", "=", "zip", "(", "*", "[", "ngram_utils", ".", "compare_ngrams", "(", "ref", ",", "out", ",", "ref_labels", "=", "ref_labels", ",", "out_labels", "=", "out_label", ",", "\n", "min_length", "=", "min_ngram_length", ",", "max_length", "=", "max_ngram_length", ")", "for", "out", ",", "out_label", "in", "zip", "(", "outs", ",", "out_labels", ")", "]", ")", "\n", "\n", "", "if", "to_cache", ":", "\n", "    ", "cache_dict", "=", "cache_utils", ".", "return_cache_dict", "(", "cache_key_list", ",", "[", "totals", ",", "matches", ",", "overs", ",", "unders", "]", ")", "\n", "return", "cache_dict", "\n", "\n", "", "direcs", "=", "arg_utils", ".", "parse_compare_directions", "(", "compare_directions", ")", "\n", "scores", "=", "[", "]", "\n", "for", "(", "left", ",", "right", ")", "in", "direcs", ":", "\n", "    ", "if", "compare_type", "==", "'match'", ":", "\n", "      ", "scores", ".", "append", "(", "stat_utils", ".", "extract_salient_features", "(", "matches", "[", "left", "]", ",", "matches", "[", "right", "]", ",", "alpha", "=", "alpha", ")", ")", "\n", "", "elif", "compare_type", "==", "'over'", ":", "\n", "      ", "scores", ".", "append", "(", "stat_utils", ".", "extract_salient_features", "(", "overs", "[", "left", "]", ",", "overs", "[", "right", "]", ",", "alpha", "=", "alpha", ")", ")", "\n", "", "elif", "compare_type", "==", "'under'", ":", "\n", "      ", "scores", ".", "append", "(", "stat_utils", ".", "extract_salient_features", "(", "unders", "[", "left", "]", ",", "unders", "[", "right", "]", ",", "alpha", "=", "alpha", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "f'Illegal compare_type \"{compare_type}\"'", ")", "\n", "", "", "scorelist", "=", "[", "sorted", "(", "score", ".", "items", "(", ")", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "for", "score", "in", "scores", "]", "\n", "\n", "# generate reports", "\n", "reporter", "=", "reporters", ".", "NgramReport", "(", "scorelist", "=", "scorelist", ",", "report_length", "=", "report_length", ",", "\n", "min_ngram_length", "=", "min_ngram_length", ",", "\n", "max_ngram_length", "=", "max_ngram_length", ",", "\n", "matches", "=", "matches", ",", "\n", "compare_type", "=", "compare_type", ",", "alpha", "=", "alpha", ",", "\n", "compare_directions", "=", "direcs", ",", "\n", "label_files", "=", "label_files", ",", "\n", "title", "=", "title", ")", "\n", "reporter", ".", "generate_report", "(", "output_fig_file", "=", "f'ngram-min{min_ngram_length}-max{max_ngram_length}-{compare_type}'", ",", "\n", "output_fig_format", "=", "'pdf'", ",", "\n", "output_directory", "=", "'outputs'", ")", "\n", "return", "reporter", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_examples": [[472, 546], ["int", "compare_mt.scorers.create_scorer_from_profile", "compare_mt.cache_utils.extract_cache_dicts", "compare_mt.arg_utils.parse_compare_directions", "compare_mt.reporters.SentenceExampleReport", "reporters.SentenceExampleReport.generate_report", "type", "len", "compare_mt.cache_utils.return_cache_dict", "set", "enumerate", "scorediff_list.sort", "scorediff_lists.append", "zip", "scores.append", "strs.append", "zip", "set.add", "scorediff_list.append", "scorers.create_scorer_from_profile.score_sentence", "scores_i.append", "strs_i.append", "tuple", "tuple", "tuple", "tuple", "tuple", "tuple"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.extract_cache_dicts", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_compare_directions", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.Report.generate_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.return_cache_dict", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "generate_sentence_examples", "(", "ref", ",", "outs", ",", "src", "=", "None", ",", "\n", "score_type", "=", "'sentbleu'", ",", "\n", "report_length", "=", "10", ",", "\n", "compare_directions", "=", "'0-1'", ",", "\n", "title", "=", "None", ",", "\n", "case_insensitive", "=", "False", ",", "\n", "to_cache", "=", "False", ",", "\n", "cache_dicts", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  Generate examples of sentences that satisfy some criterion, usually score of one system better\n\n  Args:\n    ref: Tokens from the reference\n    outs: Tokens from the output file(s)\n    src: Tokens from the source (optional)\n    score_type: The type of scorer to use\n    report_length: Number of sentences to print for each system being better or worse\n    compare_directions: A string specifying which systems to compare\n    title: A string specifying the caption of the printed table\n    case_insensitive: A boolean specifying whether to turn on the case insensitive option\n    to_cache: Return a list of computed statistics if True\n    cache_dicts: A list of dictionaries that store cached statistics for each output\n  \"\"\"", "\n", "# check and set parameters", "\n", "report_length", "=", "int", "(", "report_length", ")", "\n", "if", "type", "(", "case_insensitive", ")", "==", "str", ":", "\n", "    ", "case_insensitive", "=", "True", "if", "case_insensitive", "==", "'True'", "else", "False", "\n", "\n", "\n", "# compute statistics", "\n", "", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "score_type", ",", "case_insensitive", "=", "case_insensitive", ")", "\n", "\n", "cache_key_list", "=", "[", "'scores'", ",", "'strs'", "]", "\n", "scores", ",", "strs", "=", "cache_utils", ".", "extract_cache_dicts", "(", "cache_dicts", ",", "cache_key_list", ",", "len", "(", "outs", ")", ")", "\n", "src", "=", "[", "None", "for", "_", "in", "ref", "]", "if", "src", "is", "None", "else", "src", "\n", "if", "cache_dicts", "is", "None", ":", "\n", "    ", "scores", ",", "strs", "=", "[", "]", ",", "[", "]", "\n", "for", "out", "in", "outs", ":", "\n", "      ", "scores_i", ",", "strs_i", "=", "[", "]", ",", "[", "]", "\n", "for", "(", "r", ",", "o", ",", "s", ")", "in", "zip", "(", "ref", ",", "out", ",", "src", ")", ":", "\n", "        ", "score", ",", "string", "=", "scorer", ".", "score_sentence", "(", "r", ",", "o", ",", "s", ")", "\n", "scores_i", ".", "append", "(", "score", ")", "\n", "strs_i", ".", "append", "(", "string", ")", "\n", "", "scores", ".", "append", "(", "scores_i", ")", "\n", "strs", ".", "append", "(", "strs_i", ")", "\n", "\n", "", "", "if", "to_cache", ":", "\n", "    ", "cache_dict", "=", "cache_utils", ".", "return_cache_dict", "(", "cache_key_list", ",", "[", "scores", ",", "strs", "]", ")", "\n", "return", "cache_dict", "\n", "\n", "", "direcs", "=", "arg_utils", ".", "parse_compare_directions", "(", "compare_directions", ")", "\n", "\n", "scorediff_lists", "=", "[", "]", "\n", "for", "(", "left", ",", "right", ")", "in", "direcs", ":", "\n", "    ", "scorediff_list", "=", "[", "]", "\n", "deduplicate_set", "=", "set", "(", ")", "\n", "for", "i", ",", "(", "o1", ",", "o2", ",", "r", ")", "in", "enumerate", "(", "zip", "(", "outs", "[", "left", "]", ",", "outs", "[", "right", "]", ",", "ref", ")", ")", ":", "\n", "      ", "if", "(", "tuple", "(", "o1", ")", ",", "tuple", "(", "o2", ")", ",", "tuple", "(", "r", ")", ")", "in", "deduplicate_set", ":", "\n", "        ", "continue", "\n", "", "deduplicate_set", ".", "add", "(", "(", "tuple", "(", "o1", ")", ",", "tuple", "(", "o2", ")", ",", "tuple", "(", "r", ")", ")", ")", "\n", "s1", ",", "str1", "=", "scores", "[", "left", "]", "[", "i", "]", ",", "strs", "[", "left", "]", "[", "i", "]", "\n", "s2", ",", "str2", "=", "scores", "[", "right", "]", "[", "i", "]", ",", "strs", "[", "right", "]", "[", "i", "]", "\n", "scorediff_list", ".", "append", "(", "(", "s2", "-", "s1", ",", "s1", ",", "s2", ",", "str1", ",", "str2", ",", "i", ")", ")", "\n", "", "scorediff_list", ".", "sort", "(", ")", "\n", "scorediff_lists", ".", "append", "(", "scorediff_list", ")", "\n", "\n", "# generate reports", "\n", "", "reporter", "=", "reporters", ".", "SentenceExampleReport", "(", "report_length", "=", "report_length", ",", "scorediff_lists", "=", "scorediff_lists", ",", "\n", "scorer", "=", "scorer", ",", "\n", "ref", "=", "ref", ",", "outs", "=", "outs", ",", "src", "=", "src", ",", "\n", "compare_directions", "=", "direcs", ",", "\n", "title", "=", "title", ")", "\n", "reporter", ".", "generate_report", "(", ")", "\n", "return", "reporter", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.main": [[547, 670], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "compare_mt.formatting.fmt.set_decimals", "compare_mt.corpus_utils.load_tokens", "tuple", "numpy.seed", "compare_mt.corpus_utils.load_tokens", "compare_mt.corpus_utils.load_tokens", "len", "len", "ValueError", "len", "compare_mt.reporters.generate_html_report", "compare_mt.reporters.launch_http_server", "float", "compare_mt.reporters.generate_html_report", "range", "parser.parse_args.fig_size.split", "reports.append", "reports.append", "tempfile.TemporaryDirectory", "len", "len", "len", "func", "func", "compare_mt.arg_utils.parse_profile", "compare_mt.arg_utils.parse_profile"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.formatting.Formatter.set_decimals", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.generate_html_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.launch_http_server", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.reporters.generate_html_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.arg_utils.parse_profile"], ["", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Program to compare MT results'", ",", "\n", "epilog", "=", "f'For more details, see {source_code_url}'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'ref_file'", ",", "type", "=", "str", ",", "\n", "help", "=", "'A path to a correct reference file'", ")", "\n", "parser", ".", "add_argument", "(", "'out_files'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "\n", "help", "=", "'Paths to system outputs'", ")", "\n", "parser", ".", "add_argument", "(", "'--sys_names'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Names for each system, must be same number as output files'", ")", "\n", "parser", ".", "add_argument", "(", "'--src_file'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'A path to the source file'", ")", "\n", "parser", ".", "add_argument", "(", "'--fig_size'", ",", "type", "=", "str", ",", "default", "=", "'6x4.5'", ",", "\n", "help", "=", "'The size of figures, in \"width x height\" format.'", ")", "\n", "parser", ".", "add_argument", "(", "'--compare_scores'", ",", "type", "=", "str", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "[", "'score_type=bleu'", ",", "'score_type=length'", "]", ",", "\n", "help", "=", "\"\"\"\n                      Compare scores. Can specify arguments in 'arg1=val1,arg2=val2,...' format.\n                      See documentation for 'generate_score_report' to see which arguments are available.\n                      \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--compare_word_accuracies'", ",", "type", "=", "str", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "[", "'bucket_type=freq'", "]", ",", "\n", "help", "=", "\"\"\"\n                      Compare word accuracies by buckets. Can specify arguments in 'arg1=val1,arg2=val2,...' format.\n                      See documentation for 'generate_word_accuracy_report' to see which arguments are available.\n                      \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--compare_src_word_accuracies'", ",", "type", "=", "str", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"\"\"\n                      Source analysis. Can specify arguments in 'arg1=val1,arg2=val2,...' format.\n                      See documentation for 'generate_src_word_accuracy_report' to see which arguments are available.\n                      \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--compare_sentence_buckets'", ",", "type", "=", "str", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "[", "'bucket_type=length,statistic_type=score,score_measure=bleu'", ",", "\n", "'bucket_type=lengthdiff'", ",", "\n", "'bucket_type=score,score_measure=sentbleu'", "]", ",", "\n", "help", "=", "\"\"\"\n                      Compare sentence counts by buckets. Can specify arguments in 'arg1=val1,arg2=val2,...' format.\n                      See documentation for 'generate_sentence_buckets_report' to see which arguments are available.\n                      \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--compare_ngrams'", ",", "type", "=", "str", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "[", "'compare_type=match'", "]", ",", "\n", "help", "=", "\"\"\"\n                      Compare ngrams. Can specify arguments in 'arg1=val1,arg2=val2,...' format.\n                      See documentation for 'generate_ngram_report' to see which arguments are available.\n                      \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--compare_sentence_examples'", ",", "type", "=", "str", ",", "nargs", "=", "'*'", ",", "\n", "default", "=", "[", "'score_type=sentbleu'", "]", ",", "\n", "help", "=", "\"\"\"\n                      Compare sentences. Can specify arguments in 'arg1=val1,arg2=val2,...' format.\n                      See documentation for 'generate_sentence_examples' to see which arguments are available.\n                      \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--output_directory'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"\"\"\n                      A path to a directory where a graphical report will be saved. Open index.html in the directory\n                      to read the report.\n                      \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--report_title'", ",", "type", "=", "str", ",", "default", "=", "'compare-mt Analysis Report'", ",", "\n", "help", "=", "\"\"\"\n                      The name of the HTML report.\n                      \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--decimals'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "\"Number of decimals to print for floating point numbers\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Seed for random number generation\"", ")", "\n", "parser", ".", "add_argument", "(", "'--scorer_scale'", ",", "type", "=", "float", ",", "default", "=", "100", ",", "choices", "=", "[", "1", ",", "100", "]", ",", "\n", "help", "=", "\"Set the scale of BLEU, METEOR, WER, chrF and COMET to 0-1 or 0-100 (default 0-100)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--http'", ",", "type", "=", "int", ",", "dest", "=", "'bind_port'", ",", "\n", "help", "=", "'Launch an HTTP server at specified port to view results.'", "\n", "'Disabled by default, but specifying a port number enabled it.'", ")", "\n", "parser", ".", "add_argument", "(", "'-v'", ",", "'--version'", ",", "action", "=", "'version'", ",", "version", "=", "f'%(prog)s {__version__}'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Set formatting", "\n", "formatting", ".", "fmt", ".", "set_decimals", "(", "args", ".", "decimals", ")", "\n", "\n", "# Set random seed", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "    ", "npr", ".", "seed", "(", "args", ".", "seed", ")", "\n", "\n", "# Set scale", "\n", "", "scorers", ".", "global_scorer_scale", "=", "args", ".", "scorer_scale", "\n", "\n", "ref", "=", "corpus_utils", ".", "load_tokens", "(", "args", ".", "ref_file", ")", "\n", "outs", "=", "[", "corpus_utils", ".", "load_tokens", "(", "x", ")", "for", "x", "in", "args", ".", "out_files", "]", "\n", "\n", "src", "=", "corpus_utils", ".", "load_tokens", "(", "args", ".", "src_file", ")", "if", "args", ".", "src_file", "else", "None", "\n", "reporters", ".", "sys_names", "=", "args", ".", "sys_names", "if", "args", ".", "sys_names", "else", "[", "f'sys{i+1}'", "for", "i", "in", "range", "(", "len", "(", "outs", ")", ")", "]", "\n", "reporters", ".", "fig_size", "=", "tuple", "(", "[", "float", "(", "x", ")", "for", "x", "in", "args", ".", "fig_size", ".", "split", "(", "'x'", ")", "]", ")", "\n", "if", "len", "(", "reporters", ".", "sys_names", ")", "!=", "len", "(", "outs", ")", ":", "\n", "    ", "raise", "ValueError", "(", "f'len(sys_names) != len(outs) -- {len(reporters.sys_names)} != {len(outs)}'", ")", "\n", "\n", "", "reports", "=", "[", "]", "\n", "\n", "report_types", "=", "[", "\n", "(", "args", ".", "compare_scores", ",", "generate_score_report", ",", "'Aggregate Scores'", ",", "True", ")", ",", "\n", "(", "args", ".", "compare_word_accuracies", ",", "generate_word_accuracy_report", ",", "'Word Accuracies'", ",", "False", ")", ",", "\n", "(", "args", ".", "compare_src_word_accuracies", ",", "generate_src_word_accuracy_report", ",", "'Source Word Accuracies'", ",", "True", ")", ",", "\n", "(", "args", ".", "compare_sentence_buckets", ",", "generate_sentence_bucketed_report", ",", "'Sentence Buckets'", ",", "True", ")", "]", "\n", "if", "len", "(", "outs", ")", ">", "1", ":", "\n", "    ", "report_types", "+=", "[", "\n", "(", "args", ".", "compare_ngrams", ",", "generate_ngram_report", ",", "'Characteristic N-grams'", ",", "False", ")", ",", "\n", "(", "args", ".", "compare_sentence_examples", ",", "generate_sentence_examples", ",", "'Sentence Examples'", ",", "True", ")", ",", "\n", "]", "\n", "\n", "", "for", "arg", ",", "func", ",", "name", ",", "use_src", "in", "report_types", ":", "\n", "    ", "if", "arg", "is", "not", "None", ":", "\n", "      ", "if", "use_src", ":", "\n", "        ", "reports", ".", "append", "(", "(", "name", ",", "[", "func", "(", "ref", ",", "outs", ",", "src", ",", "**", "arg_utils", ".", "parse_profile", "(", "x", ")", ")", "for", "x", "in", "arg", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "reports", ".", "append", "(", "(", "name", ",", "[", "func", "(", "ref", ",", "outs", ",", "**", "arg_utils", ".", "parse_profile", "(", "x", ")", ")", "for", "x", "in", "arg", "]", ")", ")", "\n", "\n", "# Write all reports into a single html file", "\n", "", "", "", "if", "args", ".", "output_directory", "!=", "None", ":", "\n", "    ", "reporters", ".", "generate_html_report", "(", "reports", ",", "args", ".", "output_directory", ",", "args", ".", "report_title", ")", "\n", "\n", "", "if", "args", ".", "bind_port", ":", "\n", "    ", "out_dir", "=", "args", ".", "output_directory", "\n", "if", "not", "out_dir", ":", "\n", "      ", "out_dir", "=", "tempfile", ".", "TemporaryDirectory", "(", ")", ".", "name", "\n", "reporters", ".", "generate_html_report", "(", "reports", ",", "out_dir", ",", "args", ".", "report_title", ")", "\n", "", "reporters", ".", "launch_http_server", "(", "out_dir", ",", "bind_port", "=", "args", ".", "bind_port", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io.compute_scores_and_write_to_csv": [[28, 56], ["io._glob", "io._glob", "io._compute_scores", "io._write_aggregates_to_csv", "io._write_scores_to_csv", "aggregator.add_scores", "aggregator.aggregate"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._glob", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._glob", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._compute_scores", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._write_aggregates_to_csv", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._write_scores_to_csv", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.BootstrapAggregator.add_scores", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.BootstrapAggregator.aggregate"], ["def", "compute_scores_and_write_to_csv", "(", "target_filepattern", ",", "\n", "prediction_filepattern", ",", "\n", "output_filename", ",", "\n", "scorer", ",", "\n", "aggregator", ",", "\n", "delimiter", "=", "\"\\n\"", ")", ":", "\n", "  ", "\"\"\"Runs aggregate score calculations and outputs results to a CSV file.\n\n  Args:\n    target_filepattern: Pattern for files containing target text.\n    prediction_filepattern: Pattern for files containing prediction text.\n    output_filename: Name of file to write results to.\n    scorer: A BaseScorer object to compute scores.\n    aggregator: An aggregator to aggregate scores. If None, outputs are\n      per-example scores.\n    delimiter: Record delimiter.\n  \"\"\"", "\n", "\n", "target_filenames", "=", "_glob", "(", "target_filepattern", ")", "\n", "prediction_filenames", "=", "_glob", "(", "prediction_filepattern", ")", "\n", "scores", "=", "_compute_scores", "(", "target_filenames", ",", "prediction_filenames", ",", "scorer", ",", "\n", "delimiter", ")", "\n", "if", "aggregator", ":", "\n", "    ", "for", "score", "in", "scores", ":", "\n", "      ", "aggregator", ".", "add_scores", "(", "score", ")", "\n", "", "_write_aggregates_to_csv", "(", "output_filename", ",", "aggregator", ".", "aggregate", "(", ")", ")", "\n", "", "else", ":", "\n", "    ", "_write_scores_to_csv", "(", "output_filename", ",", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._glob": [[58, 60], ["glob.glob"], "function", ["None"], ["", "", "def", "_glob", "(", "filepattern", ")", ":", "\n", "  ", "return", "glob", ".", "glob", "(", "filepattern", ")", "# pylint: disable=unreachable", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._open": [[62, 64], ["open"], "function", ["None"], ["", "def", "_open", "(", "filepattern", ",", "mode", "=", "\"r\"", ")", ":", "\n", "  ", "return", "open", "(", "filepattern", ",", "mode", ")", "# pylint: disable=unreachable", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._record_gen": [[66, 78], ["io._open", "f.read().split", "absl.logging.warn", "f.read"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._open"], ["", "def", "_record_gen", "(", "filename", ",", "delimiter", ")", ":", "\n", "  ", "\"\"\"Opens file and yields records separated by delimiter.\"\"\"", "\n", "with", "_open", "(", "filename", ")", "as", "f", ":", "\n", "    ", "records", "=", "f", ".", "read", "(", ")", ".", "split", "(", "delimiter", ")", "\n", "", "if", "records", "[", "-", "1", "]", ":", "\n", "# Need a final delimiter at end of file to be able to detect an empty last", "\n", "# record.", "\n", "    ", "logging", ".", "warn", "(", "\"Expected delimiter at end of file\"", ")", "\n", "", "else", ":", "\n", "    ", "records", "=", "records", "[", ":", "-", "1", "]", "\n", "", "for", "record", "in", "records", ":", "\n", "    ", "yield", "record", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._compute_scores": [[80, 116], ["zip", "ValueError", "sorted", "sorted", "absl.logging.info", "absl.logging.info", "io._record_gen", "io._record_gen", "itertools.zip_longest", "len", "len", "len", "scores.append", "ValueError", "scorer.score", "len", "len"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._record_gen", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._record_gen", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer.RougeScorer.score"], ["", "", "def", "_compute_scores", "(", "target_filenames", ",", "prediction_filenames", ",", "scorer", ",", "delimiter", ")", ":", "\n", "  ", "\"\"\"Computes aggregates scores across the given target and prediction files.\n\n  Args:\n    target_filenames: List of filenames from which to read target lines.\n    prediction_filenames: List of filenames from which to read prediction lines.\n    scorer: A BaseScorer object to compute scores.\n    delimiter: string delimiter between each record in input files\n  Returns:\n    A list of dicts mapping score_type to Score objects.\n  Raises:\n    ValueError: If invalid targets or predictions are provided.\n  \"\"\"", "\n", "\n", "if", "(", "len", "(", "target_filenames", ")", "<", "1", "or", "\n", "len", "(", "target_filenames", ")", "!=", "len", "(", "prediction_filenames", ")", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"Must have equal and positive number of target and \"", "\n", "\"prediction files. Found: %d target files, %d prediction \"", "\n", "\"files.\"", "%", "(", "len", "(", "target_filenames", ")", ",", "\n", "len", "(", "prediction_filenames", ")", ")", ")", "\n", "\n", "", "scores", "=", "[", "]", "\n", "for", "target_filename", ",", "prediction_filename", "in", "zip", "(", "\n", "sorted", "(", "target_filenames", ")", ",", "sorted", "(", "prediction_filenames", ")", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Reading targets from %s.\"", ",", "target_filename", ")", "\n", "logging", ".", "info", "(", "\"Reading predictions from %s.\"", ",", "prediction_filename", ")", "\n", "targets", "=", "_record_gen", "(", "target_filename", ",", "delimiter", ")", "\n", "preds", "=", "_record_gen", "(", "prediction_filename", ",", "delimiter", ")", "\n", "for", "target_rec", ",", "prediction_rec", "in", "itertools", ".", "zip_longest", "(", "targets", ",", "preds", ")", ":", "\n", "      ", "if", "target_rec", "is", "None", "or", "prediction_rec", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Must have equal number of lines across target and \"", "\n", "\"prediction files. Mismatch between files: %s, %s.\"", "%", "\n", "(", "target_filename", ",", "prediction_filename", ")", ")", "\n", "", "scores", ".", "append", "(", "scorer", ".", "score", "(", "target_rec", ",", "prediction_rec", ")", ")", "\n", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._write_aggregates_to_csv": [[118, 145], ["absl.logging.info", "absl.logging.info", "io._open", "output_file.write", "sorted", "aggregates.items", "output_file.write", "output_file.write", "output_file.write"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._open"], ["", "def", "_write_aggregates_to_csv", "(", "output_filename", ",", "aggregates", ")", ":", "\n", "  ", "\"\"\"Writes aggregate scores to an output CSV file.\n\n  Output file is a comma separated where each line has the format:\n    score_type-(P|R|F),low_ci,mean,high_ci\n\n  P/R/F indicates whether the score is a precision, recall or f-measure.\n\n  Args:\n    output_filename: Name of file to write results to.\n    aggregates: A dict mapping each score_type to a AggregateScore object.\n  \"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"Writing results to %s.\"", ",", "output_filename", ")", "\n", "with", "_open", "(", "output_filename", ",", "\"w\"", ")", "as", "output_file", ":", "\n", "    ", "output_file", ".", "write", "(", "\"score_type,low,mid,high\\n\"", ")", "\n", "for", "score_type", ",", "aggregate", "in", "sorted", "(", "aggregates", ".", "items", "(", ")", ")", ":", "\n", "      ", "output_file", ".", "write", "(", "\"%s-R,%f,%f,%f\\n\"", "%", "\n", "(", "score_type", ",", "aggregate", ".", "low", ".", "recall", ",", "aggregate", ".", "mid", ".", "recall", ",", "\n", "aggregate", ".", "high", ".", "recall", ")", ")", "\n", "output_file", ".", "write", "(", "\"%s-P,%f,%f,%f\\n\"", "%", "\n", "(", "score_type", ",", "aggregate", ".", "low", ".", "precision", ",", "\n", "aggregate", ".", "mid", ".", "precision", ",", "aggregate", ".", "high", ".", "precision", ")", ")", "\n", "output_file", ".", "write", "(", "\"%s-F,%f,%f,%f\\n\"", "%", "\n", "(", "score_type", ",", "aggregate", ".", "low", ".", "fmeasure", ",", "\n", "aggregate", ".", "mid", ".", "fmeasure", ",", "aggregate", ".", "high", ".", "fmeasure", ")", ")", "\n", "", "", "logging", ".", "info", "(", "\"Finished writing results.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._write_scores_to_csv": [[147, 179], ["sorted", "absl.logging.info", "absl.logging.info", "len", "absl.logging.warn", "scores[].keys", "io._open", "out_file.write", "out_file.write", "enumerate", "out_file.write", "out_file.write", "out_file.write", "out_file.write"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io._open"], ["", "def", "_write_scores_to_csv", "(", "output_filename", ",", "scores", ")", ":", "\n", "  ", "\"\"\"Writes scores for each individual example to an output CSV file.\n\n  Output file is a comma separated where each line has the format:\n    id,score1,score2,score3,...\n\n  The header row indicates the type of each score column.\n\n  Args:\n    output_filename: Name of file to write results to.\n    scores: A list of dicts mapping each score_type to a Score object.\n  \"\"\"", "\n", "\n", "if", "len", "(", "scores", ")", "<", "1", ":", "\n", "    ", "logging", ".", "warn", "(", "\"No scores to write\"", ")", "\n", "return", "\n", "", "rouge_types", "=", "sorted", "(", "scores", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\"Writing results to %s.\"", ",", "output_filename", ")", "\n", "with", "_open", "(", "output_filename", ",", "\"w\"", ")", "as", "out_file", ":", "\n", "    ", "out_file", ".", "write", "(", "\"id\"", ")", "\n", "for", "rouge_type", "in", "rouge_types", ":", "\n", "      ", "out_file", ".", "write", "(", "\",{t}-P,{t}-R,{t}-F\"", ".", "format", "(", "t", "=", "rouge_type", ")", ")", "\n", "", "out_file", ".", "write", "(", "\"\\n\"", ")", "\n", "for", "i", ",", "result", "in", "enumerate", "(", "scores", ")", ":", "\n", "      ", "out_file", ".", "write", "(", "\"%d\"", "%", "i", ")", "\n", "for", "rouge_type", "in", "rouge_types", ":", "\n", "        ", "out_file", ".", "write", "(", "\",%f,%f,%f\"", "%", "\n", "(", "result", "[", "rouge_type", "]", ".", "precision", ",", "result", "[", "rouge_type", "]", ".", "recall", ",", "\n", "result", "[", "rouge_type", "]", ".", "fmeasure", ")", ")", "\n", "", "out_file", ".", "write", "(", "\"\\n\"", ")", "\n", "", "", "logging", ".", "info", "(", "\"Finished writing results.\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize": [[28, 53], ["re.sub.lower", "re.sub", "re.split", "six.ensure_str", "EMPTY_OR_INVALID_TOKENS.match", "stemmer.stem", "six.ensure_str", "len"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.lower", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.CachedPorterStemmer.stem"], ["def", "tokenize", "(", "text", ",", "stemmer", ")", ":", "\n", "  ", "\"\"\"Tokenize input text into a list of tokens.\n  This approach aims to replicate the approach taken by Chin-Yew Lin in\n  the original ROUGE implementation.\n  Args:\n    text: A text blob to tokenize.\n    stemmer: An optional stemmer.\n  Returns:\n    A list of string tokens extracted from input text.\n  \"\"\"", "\n", "\n", "# Convert everything to lowercase.", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "# Replace any non-alpha-numeric characters with spaces.", "\n", "text", "=", "re", ".", "sub", "(", "r\"[^a-z0-9]+\"", ",", "\" \"", ",", "six", ".", "ensure_str", "(", "text", ")", ")", "\n", "\n", "tokens", "=", "re", ".", "split", "(", "r\"\\s+\"", ",", "text", ")", "\n", "if", "stemmer", ":", "\n", "# Only stem words more than 3 characters long.", "\n", "    ", "tokens", "=", "[", "stemmer", ".", "stem", "(", "x", ")", "if", "len", "(", "x", ")", ">", "3", "else", "x", "for", "x", "in", "tokens", "]", "\n", "\n", "# One final check to drop any empty or invalid tokens.", "\n", "", "tokens", "=", "[", "x", "for", "x", "in", "tokens", "if", "EMPTY_OR_INVALID_TOKENS", ".", "match", "(", "six", ".", "ensure_str", "(", "x", ")", ")", "]", "\n", "\n", "return", "tokens", "\n", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge.main": [[66, 78], ["compare_mt.rouge.rouge_scorer.RougeScorer", "compare_mt.rouge.io.compute_scores_and_write_to_csv", "len", "absl.app.UsageError", "compare_mt.rouge.scoring.BootstrapAggregator"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.io.compute_scores_and_write_to_csv"], ["def", "main", "(", "argv", ")", ":", "\n", "  ", "if", "len", "(", "argv", ")", ">", "1", ":", "\n", "    ", "raise", "app", ".", "UsageError", "(", "\"Too many command-line arguments.\"", ")", "\n", "", "scorer", "=", "rouge_scorer", ".", "RougeScorer", "(", "FLAGS", ".", "rouge_types", ",", "FLAGS", ".", "use_stemmer", ")", "\n", "aggregator", "=", "scoring", ".", "BootstrapAggregator", "(", ")", "if", "FLAGS", ".", "aggregate", "else", "None", "\n", "io", ".", "compute_scores_and_write_to_csv", "(", "\n", "FLAGS", ".", "target_filepattern", ",", "\n", "FLAGS", ".", "prediction_filepattern", ",", "\n", "FLAGS", ".", "output_filename", ",", "\n", "scorer", ",", "\n", "aggregator", ",", "\n", "delimiter", "=", "FLAGS", ".", "delimiter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.BaseScorer.score": [[42, 52], ["None"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "score", "(", "self", ",", "target", ",", "prediction", ")", ":", "\n", "    ", "\"\"\"Calculates score between the target and prediction.\n\n    Args:\n      target: Text containing the target (ground truth) text.\n      prediction: Text containing the predicted text.\n    Returns:\n      A dict mapping each score_type (string) to Score object.\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.BootstrapAggregator.__init__": [[79, 100], ["collections.defaultdict", "ValueError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "confidence_interval", "=", "0.95", ",", "\n", "n_samples", "=", "1000", ")", ":", "\n", "    ", "\"\"\"Initializes a BootstrapAggregator object.\n\n    Args:\n      confidence_interval: Confidence interval to compute on the mean as a\n        decimal.\n      n_samples: Number of samples to use for bootstrap resampling.\n    Raises:\n      ValueError: If invalid argument is given.\n    \"\"\"", "\n", "\n", "if", "confidence_interval", "<", "0", "or", "confidence_interval", ">", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"confidence_interval must be in range [0, 1]\"", ")", "\n", "", "if", "n_samples", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"n_samples must be positive\"", ")", "\n", "\n", "", "self", ".", "_n_samples", "=", "n_samples", "\n", "self", ".", "_confidence_interval", "=", "confidence_interval", "\n", "self", ".", "_scores", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.BootstrapAggregator.add_scores": [[101, 111], ["six.iteritems", "scoring.BootstrapAggregator._scores[].append"], "methods", ["None"], ["", "def", "add_scores", "(", "self", ",", "scores", ")", ":", "\n", "    ", "\"\"\"Adds a sample for future aggregation.\n\n    Args:\n      scores: Dict mapping score_type strings to Score object.\n    \"\"\"", "\n", "\n", "for", "score_type", ",", "score", "in", "six", ".", "iteritems", "(", "scores", ")", ":", "\n", "      ", "self", ".", "_scores", "[", "score_type", "]", ".", "append", "(", "(", "score", ".", "precision", ",", "score", ".", "recall", ",", "\n", "score", ".", "fmeasure", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.BootstrapAggregator.aggregate": [[112, 133], ["six.iteritems", "numpy.vstack", "scoring.BootstrapAggregator._bootstrap_resample", "tuple", "scoring.AggregateScore", "scoring.Score", "six.moves.xrange"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.BootstrapAggregator._bootstrap_resample"], ["", "", "def", "aggregate", "(", "self", ")", ":", "\n", "    ", "\"\"\"Aggregates scores previously added using add_scores.\n\n    Returns:\n      A dict mapping score_type to AggregateScore objects.\n    \"\"\"", "\n", "\n", "result", "=", "{", "}", "\n", "for", "score_type", ",", "scores", "in", "six", ".", "iteritems", "(", "self", ".", "_scores", ")", ":", "\n", "# Stack scores into a 2-d matrix of (sample, measure).", "\n", "      ", "score_matrix", "=", "np", ".", "vstack", "(", "scores", ")", "\n", "# Percentiles are returned as (interval, measure).", "\n", "percentiles", "=", "self", ".", "_bootstrap_resample", "(", "score_matrix", ")", "\n", "# Extract the three intervals (low, mid, high).", "\n", "intervals", "=", "tuple", "(", "(", "Score", "(", "\n", "precision", "=", "percentiles", "[", "j", ",", "0", "]", ",", "\n", "recall", "=", "percentiles", "[", "j", ",", "1", "]", ",", "\n", "fmeasure", "=", "percentiles", "[", "j", ",", "2", "]", ")", "for", "j", "in", "xrange", "(", "3", ")", ")", ")", "\n", "result", "[", "score_type", "]", "=", "AggregateScore", "(", "\n", "low", "=", "intervals", "[", "0", "]", ",", "mid", "=", "intervals", "[", "1", "]", ",", "high", "=", "intervals", "[", "2", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.BootstrapAggregator._bootstrap_resample": [[134, 160], ["numpy.zeros", "six.moves.xrange", "numpy.percentile", "numpy.random.choice", "numpy.mean", "numpy.array", "numpy.arange"], "methods", ["None"], ["", "def", "_bootstrap_resample", "(", "self", ",", "matrix", ")", ":", "\n", "    ", "\"\"\"Performs bootstrap resampling on a matrix of scores.\n\n    Args:\n      matrix: A 2-d matrix of (sample, measure).\n    Returns:\n      A 2-d matrix of (bounds, measure). There are three bounds: low (row 0),\n      mid (row 1) and high (row 2). Mid is always the mean, while low and high\n      bounds are specified by self._confidence_interval (which defaults to 0.95\n      meaning it will return the 2.5th and 97.5th percentiles for a 95%\n      confidence interval on the mean).\n    \"\"\"", "\n", "\n", "# Matrix of (bootstrap sample, measure).", "\n", "sample_mean", "=", "np", ".", "zeros", "(", "(", "self", ".", "_n_samples", ",", "matrix", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "xrange", "(", "self", ".", "_n_samples", ")", ":", "\n", "      ", "sample_idx", "=", "np", ".", "random", ".", "choice", "(", "\n", "np", ".", "arange", "(", "matrix", ".", "shape", "[", "0", "]", ")", ",", "size", "=", "matrix", ".", "shape", "[", "0", "]", ")", "\n", "sample", "=", "matrix", "[", "sample_idx", ",", ":", "]", "\n", "sample_mean", "[", "i", ",", ":", "]", "=", "np", ".", "mean", "(", "sample", ",", "axis", "=", "0", ")", "\n", "\n", "# Take percentiles on the estimate of the mean using bootstrap samples.", "\n", "# Final result is a (bounds, measure) matrix.", "\n", "", "percentile_delta", "=", "(", "1", "-", "self", ".", "_confidence_interval", ")", "/", "2", "\n", "q", "=", "100", "*", "np", ".", "array", "(", "[", "percentile_delta", ",", "0.5", ",", "1", "-", "percentile_delta", "]", ")", "\n", "return", "np", ".", "percentile", "(", "sample_mean", ",", "q", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.fmeasure": [[162, 169], ["None"], "function", ["None"], ["", "", "def", "fmeasure", "(", "precision", ",", "recall", ")", ":", "\n", "  ", "\"\"\"Computes f-measure given precision and recall values.\"\"\"", "\n", "\n", "if", "precision", "+", "recall", ">", "0", ":", "\n", "    ", "return", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "", "else", ":", "\n", "    ", "return", "0.0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer.RougeScorer.__init__": [[52, 67], ["compare_mt.cache_utils.CachedPorterStemmer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "rouge_types", ",", "use_stemmer", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initializes a new RougeScorer.\n    Valid rouge types that can be computed are:\n      rougen (e.g. rouge1, rouge2): n-gram based scoring.\n      rougeL: Longest common subsequence based scoring.\n    Args:\n      rouge_types: A list of rouge types to calculate.\n      use_stemmer: Bool indicating whether Porter stemmer should be used to\n        strip word suffixes to improve matching.\n    Returns:\n      A dict mapping rouge types to Score tuples.\n    \"\"\"", "\n", "\n", "self", ".", "rouge_types", "=", "rouge_types", "\n", "self", ".", "_stemmer", "=", "CachedPorterStemmer", "(", ")", "if", "use_stemmer", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer.RougeScorer.score": [[68, 114], ["compare_mt.rouge.tokenize.tokenize", "compare_mt.rouge.tokenize.tokenize", "rouge_scorer._score_lcs", "rouge_scorer._summary_level_lcs", "re.match", "six.ensure_str().split", "compare_mt.rouge.tokenize.tokenize", "compare_mt.rouge.tokenize.tokenize", "six.ensure_str", "int", "rouge_scorer._create_ngrams", "rouge_scorer._create_ngrams", "rouge_scorer._score_ngrams", "ValueError", "rouge_scorer.RougeScorer.score.get_sents"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._score_lcs", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._summary_level_lcs", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.tokenize.tokenize", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._create_ngrams", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._create_ngrams", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._score_ngrams", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.RougeScorer.get_sents"], ["", "def", "score", "(", "self", ",", "target", ",", "prediction", ")", ":", "\n", "    ", "\"\"\"Calculates rouge scores between the target and prediction.\n    Args:\n      target: Text containing the target (ground truth) text.\n      prediction: Text containing the predicted text.\n    Returns:\n      A dict mapping each rouge type to a Score object.\n    Raises:\n      ValueError: If an invalid rouge type is encountered.\n    \"\"\"", "\n", "\n", "target_tokens", "=", "tokenize", ".", "tokenize", "(", "target", ",", "self", ".", "_stemmer", ")", "\n", "prediction_tokens", "=", "tokenize", ".", "tokenize", "(", "prediction", ",", "self", ".", "_stemmer", ")", "\n", "result", "=", "{", "}", "\n", "\n", "for", "rouge_type", "in", "self", ".", "rouge_types", ":", "\n", "      ", "if", "rouge_type", "==", "\"rougeL\"", ":", "\n", "# Rouge from longest common subsequences.", "\n", "        ", "scores", "=", "_score_lcs", "(", "target_tokens", ",", "prediction_tokens", ")", "\n", "", "elif", "rouge_type", "==", "\"rougeLsum\"", ":", "\n", "# Note: Does not support multi-line text.", "\n", "        ", "def", "get_sents", "(", "text", ")", ":", "\n", "# Assume sentences are separated by newline.", "\n", "          ", "sents", "=", "six", ".", "ensure_str", "(", "text", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "sents", "=", "[", "x", "for", "x", "in", "sents", "if", "len", "(", "x", ")", "]", "\n", "return", "sents", "\n", "\n", "", "target_tokens_list", "=", "[", "\n", "tokenize", ".", "tokenize", "(", "s", ",", "self", ".", "_stemmer", ")", "for", "s", "in", "get_sents", "(", "target", ")", "]", "\n", "prediction_tokens_list", "=", "[", "\n", "tokenize", ".", "tokenize", "(", "s", ",", "self", ".", "_stemmer", ")", "for", "s", "in", "get_sents", "(", "prediction", ")", "]", "\n", "scores", "=", "_summary_level_lcs", "(", "target_tokens_list", ",", "\n", "prediction_tokens_list", ")", "\n", "", "elif", "re", ".", "match", "(", "r\"rouge[0-9]$\"", ",", "six", ".", "ensure_str", "(", "rouge_type", ")", ")", ":", "\n", "# Rouge from n-grams.", "\n", "        ", "n", "=", "int", "(", "rouge_type", "[", "5", ":", "]", ")", "\n", "if", "n", "<=", "0", ":", "\n", "          ", "raise", "ValueError", "(", "\"rougen requires positive n: %s\"", "%", "rouge_type", ")", "\n", "", "target_ngrams", "=", "_create_ngrams", "(", "target_tokens", ",", "n", ")", "\n", "prediction_ngrams", "=", "_create_ngrams", "(", "prediction_tokens", ",", "n", ")", "\n", "scores", "=", "_score_ngrams", "(", "target_ngrams", ",", "prediction_ngrams", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid rouge type: %s\"", "%", "rouge_type", ")", "\n", "", "result", "[", "rouge_type", "]", "=", "scores", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._create_ngrams": [[116, 129], ["collections.Counter", "tuple", "six.moves.range", "len"], "function", ["None"], ["", "", "def", "_create_ngrams", "(", "tokens", ",", "n", ")", ":", "\n", "  ", "\"\"\"Creates ngrams from the given list of tokens.\n  Args:\n    tokens: A list of tokens from which ngrams are created.\n    n: Number of tokens to use, e.g. 2 for bigrams.\n  Returns:\n    A dictionary mapping each bigram to the number of occurrences.\n  \"\"\"", "\n", "\n", "ngrams", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "ngram", "in", "(", "tuple", "(", "tokens", "[", "i", ":", "i", "+", "n", "]", ")", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", "-", "n", "+", "1", ")", ")", ":", "\n", "    ", "ngrams", "[", "ngram", "]", "+=", "1", "\n", "", "return", "ngrams", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._score_lcs": [[131, 152], ["rouge_scorer._lcs_table", "compare_mt.rouge.scoring.fmeasure", "compare_mt.rouge.scoring.Score", "compare_mt.rouge.scoring.Score", "len", "len"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._lcs_table", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.fmeasure"], ["", "def", "_score_lcs", "(", "target_tokens", ",", "prediction_tokens", ")", ":", "\n", "  ", "\"\"\"Computes LCS (Longest Common Subsequence) rouge scores.\n  Args:\n    target_tokens: Tokens from the target text.\n    prediction_tokens: Tokens from the predicted text.\n  Returns:\n    A Score object containing computed scores.\n  \"\"\"", "\n", "\n", "if", "not", "target_tokens", "or", "not", "prediction_tokens", ":", "\n", "    ", "return", "scoring", ".", "Score", "(", "precision", "=", "0", ",", "recall", "=", "0", ",", "fmeasure", "=", "0", ")", "\n", "\n", "# Compute length of LCS from the bottom up in a table (DP appproach).", "\n", "", "lcs_table", "=", "_lcs_table", "(", "target_tokens", ",", "prediction_tokens", ")", "\n", "lcs_length", "=", "lcs_table", "[", "-", "1", "]", "[", "-", "1", "]", "\n", "\n", "precision", "=", "lcs_length", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "lcs_length", "/", "len", "(", "target_tokens", ")", "\n", "fmeasure", "=", "scoring", ".", "fmeasure", "(", "precision", ",", "recall", ")", "\n", "\n", "return", "scoring", ".", "Score", "(", "precision", "=", "precision", ",", "recall", "=", "recall", ",", "fmeasure", "=", "fmeasure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._lcs_table": [[154, 166], ["len", "len", "six.moves.range", "six.moves.range", "six.moves.range", "max"], "function", ["None"], ["", "def", "_lcs_table", "(", "ref", ",", "can", ")", ":", "\n", "  ", "\"\"\"Create 2-d LCS score table.\"\"\"", "\n", "rows", "=", "len", "(", "ref", ")", "\n", "cols", "=", "len", "(", "can", ")", "\n", "lcs_table", "=", "[", "[", "0", "]", "*", "(", "cols", "+", "1", ")", "for", "_", "in", "range", "(", "rows", "+", "1", ")", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "rows", "+", "1", ")", ":", "\n", "    ", "for", "j", "in", "range", "(", "1", ",", "cols", "+", "1", ")", ":", "\n", "      ", "if", "ref", "[", "i", "-", "1", "]", "==", "can", "[", "j", "-", "1", "]", ":", "\n", "        ", "lcs_table", "[", "i", "]", "[", "j", "]", "=", "lcs_table", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "+", "1", "\n", "", "else", ":", "\n", "        ", "lcs_table", "[", "i", "]", "[", "j", "]", "=", "max", "(", "lcs_table", "[", "i", "-", "1", "]", "[", "j", "]", ",", "lcs_table", "[", "i", "]", "[", "j", "-", "1", "]", ")", "\n", "", "", "", "return", "lcs_table", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._backtrack_norec": [[168, 183], ["len", "len", "lcs.insert"], "function", ["None"], ["", "def", "_backtrack_norec", "(", "t", ",", "ref", ",", "can", ")", ":", "\n", "  ", "\"\"\"Read out LCS.\"\"\"", "\n", "i", "=", "len", "(", "ref", ")", "\n", "j", "=", "len", "(", "can", ")", "\n", "lcs", "=", "[", "]", "\n", "while", "i", ">", "0", "and", "j", ">", "0", ":", "\n", "    ", "if", "ref", "[", "i", "-", "1", "]", "==", "can", "[", "j", "-", "1", "]", ":", "\n", "      ", "lcs", ".", "insert", "(", "0", ",", "i", "-", "1", ")", "\n", "i", "-=", "1", "\n", "j", "-=", "1", "\n", "", "elif", "t", "[", "i", "]", "[", "j", "-", "1", "]", ">", "t", "[", "i", "-", "1", "]", "[", "j", "]", ":", "\n", "      ", "j", "-=", "1", "\n", "", "else", ":", "\n", "      ", "i", "-=", "1", "\n", "", "", "return", "lcs", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._summary_level_lcs": [[185, 227], ["sum", "sum", "collections.Counter", "collections.Counter", "compare_mt.rouge.scoring.fmeasure", "compare_mt.rouge.scoring.Score", "compare_mt.rouge.scoring.Score", "six.moves.map", "six.moves.map", "compare_mt.rouge.scoring.Score", "collections.Counter.update", "collections.Counter.update", "rouge_scorer._union_lcs"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.fmeasure", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._union_lcs"], ["", "def", "_summary_level_lcs", "(", "ref_sent", ",", "can_sent", ")", ":", "\n", "  ", "\"\"\"ROUGE: Summary-level LCS, section 3.2 in ROUGE paper.\n  Args:\n    ref_sent: list of tokenized reference sentences\n    can_sent: list of tokenized candidate sentences\n  Returns:\n    summary level ROUGE score\n  \"\"\"", "\n", "if", "not", "ref_sent", "or", "not", "can_sent", ":", "\n", "    ", "return", "scoring", ".", "Score", "(", "precision", "=", "0", ",", "recall", "=", "0", ",", "fmeasure", "=", "0", ")", "\n", "\n", "", "m", "=", "sum", "(", "map", "(", "len", ",", "ref_sent", ")", ")", "\n", "n", "=", "sum", "(", "map", "(", "len", ",", "can_sent", ")", ")", "\n", "if", "not", "n", "or", "not", "m", ":", "\n", "    ", "return", "scoring", ".", "Score", "(", "precision", "=", "0", ",", "recall", "=", "0", ",", "fmeasure", "=", "0", ")", "\n", "\n", "# get token counts to prevent double counting", "\n", "", "token_cnts_r", "=", "collections", ".", "Counter", "(", ")", "\n", "token_cnts_c", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "s", "in", "ref_sent", ":", "\n", "# s is a list of tokens", "\n", "    ", "token_cnts_r", ".", "update", "(", "s", ")", "\n", "", "for", "s", "in", "can_sent", ":", "\n", "    ", "token_cnts_c", ".", "update", "(", "s", ")", "\n", "\n", "", "hits", "=", "0", "\n", "for", "r", "in", "ref_sent", ":", "\n", "    ", "lcs", "=", "_union_lcs", "(", "r", ",", "can_sent", ")", "\n", "# Prevent double-counting:", "\n", "# The paper describes just computing hits += len(_union_lcs()),", "\n", "# but the implementation prevents double counting. We also", "\n", "# implement this as in version 1.5.5.", "\n", "for", "t", "in", "lcs", ":", "\n", "      ", "if", "token_cnts_c", "[", "t", "]", ">", "0", "and", "token_cnts_r", "[", "t", "]", ">", "0", ":", "\n", "        ", "hits", "+=", "1", "\n", "token_cnts_c", "[", "t", "]", "-=", "1", "\n", "token_cnts_r", "[", "t", "]", "-=", "1", "\n", "\n", "", "", "", "recall", "=", "hits", "/", "m", "\n", "precision", "=", "hits", "/", "n", "\n", "fmeasure", "=", "scoring", ".", "fmeasure", "(", "precision", ",", "recall", ")", "\n", "return", "scoring", ".", "Score", "(", "precision", "=", "precision", ",", "recall", "=", "recall", ",", "fmeasure", "=", "fmeasure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._union_lcs": [[229, 239], ["rouge_scorer.lcs_ind", "rouge_scorer._find_union"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer.lcs_ind", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._find_union"], ["", "def", "_union_lcs", "(", "ref", ",", "c_list", ")", ":", "\n", "  ", "\"\"\"Find union LCS between a ref sentence and list of candidate sentences.\n  Args:\n    ref: list of tokens\n    c_list: list of list of indices for LCS into reference summary\n  Returns:\n    List of tokens in ref representing union LCS.\n  \"\"\"", "\n", "lcs_list", "=", "[", "lcs_ind", "(", "ref", ",", "c", ")", "for", "c", "in", "c_list", "]", "\n", "return", "[", "ref", "[", "i", "]", "for", "i", "in", "_find_union", "(", "lcs_list", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._find_union": [[241, 244], ["sorted", "list", "set().union", "set"], "function", ["None"], ["", "def", "_find_union", "(", "lcs_list", ")", ":", "\n", "  ", "\"\"\"Finds union LCS given a list of LCS.\"\"\"", "\n", "return", "sorted", "(", "list", "(", "set", "(", ")", ".", "union", "(", "*", "lcs_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer.lcs_ind": [[246, 250], ["rouge_scorer._lcs_table", "rouge_scorer._backtrack_norec"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._lcs_table", "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._backtrack_norec"], ["", "def", "lcs_ind", "(", "ref", ",", "can", ")", ":", "\n", "  ", "\"\"\"Returns one of the longest lcs.\"\"\"", "\n", "t", "=", "_lcs_table", "(", "ref", ",", "can", ")", "\n", "return", "_backtrack_norec", "(", "t", ",", "ref", ",", "can", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.rouge.rouge_scorer._score_ngrams": [[252, 275], ["six.iterkeys", "sum", "sum", "compare_mt.rouge.scoring.fmeasure", "compare_mt.rouge.scoring.Score", "min", "target_ngrams.values", "prediction_ngrams.values", "max", "max"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.rouge.scoring.fmeasure"], ["", "def", "_score_ngrams", "(", "target_ngrams", ",", "prediction_ngrams", ")", ":", "\n", "  ", "\"\"\"Compute n-gram based rouge scores.\n  Args:\n    target_ngrams: A Counter object mapping each ngram to number of\n      occurrences for the target text.\n    prediction_ngrams: A Counter object mapping each ngram to number of\n      occurrences for the prediction text.\n  Returns:\n    A Score object containing computed scores.\n  \"\"\"", "\n", "\n", "intersection_ngrams_count", "=", "0", "\n", "for", "ngram", "in", "six", ".", "iterkeys", "(", "target_ngrams", ")", ":", "\n", "    ", "intersection_ngrams_count", "+=", "min", "(", "target_ngrams", "[", "ngram", "]", ",", "\n", "prediction_ngrams", "[", "ngram", "]", ")", "\n", "", "target_ngrams_count", "=", "sum", "(", "target_ngrams", ".", "values", "(", ")", ")", "\n", "prediction_ngrams_count", "=", "sum", "(", "prediction_ngrams", ".", "values", "(", ")", ")", "\n", "\n", "precision", "=", "intersection_ngrams_count", "/", "max", "(", "prediction_ngrams_count", ",", "1", ")", "\n", "recall", "=", "intersection_ngrams_count", "/", "max", "(", "target_ngrams_count", ",", "1", ")", "\n", "fmeasure", "=", "scoring", ".", "fmeasure", "(", "precision", ",", "recall", ")", "\n", "\n", "return", "scoring", ".", "Score", "(", "precision", "=", "precision", ",", "recall", "=", "recall", ",", "fmeasure", "=", "fmeasure", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestScoreCache.setUpClass": [[34, 37], ["test_cache._get_example_data"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out1", ",", "self", ".", "out2", "=", "_get_example_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestScoreCache.test_score_cache": [[38, 50], ["compare_mt.compare_mt_main.generate_score_report", "compare_mt.compare_mt_main.generate_score_report", "test_cache.TestScoreCache.assertTrue", "test_cache.TestScoreCache.assertTrue", "test_cache.TestScoreCache.assertAlmostEqual", "compare_mt.compare_mt_main.generate_score_report", "compare_mt.compare_mt_main.generate_score_report", "test_cache.TestScoreCache.assertTrue", "test_cache.TestScoreCache.assertTrue", "test_cache.TestScoreCache.assertTrue", "range"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report"], ["", "def", "test_score_cache", "(", "self", ")", ":", "\n", "    ", "cached_stats1", "=", "compare_mt_main", ".", "generate_score_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", "]", ",", "to_cache", "=", "True", ")", "\n", "cached_stats2", "=", "compare_mt_main", ".", "generate_score_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out2", "]", ",", "to_cache", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "'scores'", "in", "cached_stats1", "and", "'strs'", "in", "cached_stats1", "and", "'sign_stats'", "in", "cached_stats1", ")", "\n", "self", ".", "assertTrue", "(", "'scores'", "in", "cached_stats2", "and", "'strs'", "in", "cached_stats2", "and", "'sign_stats'", "in", "cached_stats2", ")", "\n", "self", ".", "assertAlmostEqual", "(", "cached_stats1", "[", "'scores'", "]", ",", "22.44", ",", "places", "=", "1", ")", "\n", "reporters", ".", "sys_names", "=", "[", "f'sys{i+1}'", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "cached_report", "=", "compare_mt_main", ".", "generate_score_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "cache_dicts", "=", "[", "cached_stats1", ",", "cached_stats2", "]", ",", "title", "=", "'Aggregate Scores'", ")", "\n", "ori_report", "=", "compare_mt_main", ".", "generate_score_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "title", "=", "'Aggregate Scores'", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "scores", "==", "ori_report", ".", "scores", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "strs", "==", "ori_report", ".", "strs", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "wins", "==", "ori_report", ".", "wins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestScoreCache.test_score_cache_bootstrap": [[51, 63], ["compare_mt.compare_mt_main.generate_score_report", "compare_mt.compare_mt_main.generate_score_report", "test_cache.TestScoreCache.assertTrue", "test_cache.TestScoreCache.assertTrue", "test_cache.TestScoreCache.assertAlmostEqual", "compare_mt.compare_mt_main.generate_score_report", "compare_mt.compare_mt_main.generate_score_report", "test_cache.TestScoreCache.assertTrue", "test_cache.TestScoreCache.assertTrue", "test_cache.TestScoreCache.assertTrue", "range"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_score_report"], ["", "def", "test_score_cache_bootstrap", "(", "self", ")", ":", "\n", "    ", "cached_stats1", "=", "compare_mt_main", ".", "generate_score_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", "]", ",", "to_cache", "=", "True", ")", "\n", "cached_stats2", "=", "compare_mt_main", ".", "generate_score_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out2", "]", ",", "to_cache", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "'scores'", "in", "cached_stats1", "and", "'strs'", "in", "cached_stats1", "and", "'sign_stats'", "in", "cached_stats1", ")", "\n", "self", ".", "assertTrue", "(", "'scores'", "in", "cached_stats2", "and", "'strs'", "in", "cached_stats2", "and", "'sign_stats'", "in", "cached_stats2", ")", "\n", "self", ".", "assertAlmostEqual", "(", "cached_stats1", "[", "'scores'", "]", ",", "22.44", ",", "places", "=", "1", ")", "\n", "reporters", ".", "sys_names", "=", "[", "f'sys{i+1}'", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "cached_report", "=", "compare_mt_main", ".", "generate_score_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "cache_dicts", "=", "[", "cached_stats1", ",", "cached_stats2", "]", ",", "bootstrap", "=", "5", ",", "title", "=", "'Aggregate Scores'", ")", "\n", "ori_report", "=", "compare_mt_main", ".", "generate_score_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "bootstrap", "=", "5", ",", "title", "=", "'Aggregate Scores'", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "scores", "==", "ori_report", ".", "scores", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "strs", "==", "ori_report", ".", "strs", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "wins", "==", "ori_report", ".", "wins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestWordAccCache.setUpClass": [[66, 69], ["test_cache._get_example_data"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out1", ",", "self", ".", "out2", "=", "_get_example_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestWordAccCache.test_wordacc_cache": [[70, 79], ["compare_mt.compare_mt_main.generate_word_accuracy_report", "compare_mt.compare_mt_main.generate_word_accuracy_report", "test_cache.TestWordAccCache.assertTrue", "test_cache.TestWordAccCache.assertTrue", "compare_mt.compare_mt_main.generate_word_accuracy_report", "compare_mt.compare_mt_main.generate_word_accuracy_report", "test_cache.TestWordAccCache.assertTrue", "test_cache.TestWordAccCache.assertTrue"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_word_accuracy_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_word_accuracy_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_word_accuracy_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_word_accuracy_report"], ["", "def", "test_wordacc_cache", "(", "self", ")", ":", "\n", "    ", "cached_stats1", "=", "compare_mt_main", ".", "generate_word_accuracy_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", "]", ",", "to_cache", "=", "True", ")", "\n", "cached_stats2", "=", "compare_mt_main", ".", "generate_word_accuracy_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out2", "]", ",", "to_cache", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "'statistics'", "in", "cached_stats1", "and", "'my_ref_total_list'", "in", "cached_stats1", "and", "'my_out_matches_list'", "in", "cached_stats1", ")", "\n", "self", ".", "assertTrue", "(", "'statistics'", "in", "cached_stats2", "and", "'my_ref_total_list'", "in", "cached_stats2", "and", "'my_out_matches_list'", "in", "cached_stats2", ")", "\n", "ori_report", "=", "compare_mt_main", ".", "generate_word_accuracy_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ")", "\n", "cached_report", "=", "compare_mt_main", ".", "generate_word_accuracy_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "cache_dicts", "=", "[", "cached_stats1", ",", "cached_stats2", "]", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "statistics", "==", "ori_report", ".", "statistics", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "examples", "==", "ori_report", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestSrcWordAccCache.setUpClass": [[82, 89], ["os.path.join", "test_cache._get_example_data", "os.path.join", "compare_mt.corpus_utils.load_tokens", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "example_path", "=", "os", ".", "path", ".", "join", "(", "compare_mt_root", ",", "\"example\"", ")", "\n", "self", ".", "ref", ",", "self", ".", "out1", ",", "self", ".", "out2", "=", "_get_example_data", "(", ")", "\n", "src_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.orig.slk\"", ")", "\n", "self", ".", "src", "=", "load_tokens", "(", "src_file", ")", "\n", "self", ".", "ref_align_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.ref.align\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestSrcWordAccCache.test_src_wordacc_cache": [[90, 99], ["compare_mt.compare_mt_main.generate_src_word_accuracy_report", "compare_mt.compare_mt_main.generate_src_word_accuracy_report", "test_cache.TestSrcWordAccCache.assertTrue", "test_cache.TestSrcWordAccCache.assertTrue", "compare_mt.compare_mt_main.generate_src_word_accuracy_report", "compare_mt.compare_mt_main.generate_src_word_accuracy_report", "test_cache.TestSrcWordAccCache.assertTrue", "test_cache.TestSrcWordAccCache.assertTrue"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_src_word_accuracy_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_src_word_accuracy_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_src_word_accuracy_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_src_word_accuracy_report"], ["", "def", "test_src_wordacc_cache", "(", "self", ")", ":", "\n", "    ", "cached_stats1", "=", "compare_mt_main", ".", "generate_src_word_accuracy_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", "]", ",", "self", ".", "src", ",", "ref_align_file", "=", "self", ".", "ref_align_file", ",", "to_cache", "=", "True", ")", "\n", "cached_stats2", "=", "compare_mt_main", ".", "generate_src_word_accuracy_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out2", "]", ",", "self", ".", "src", ",", "ref_align_file", "=", "self", ".", "ref_align_file", ",", "to_cache", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "'statistics'", "in", "cached_stats1", "and", "'my_ref_total_list'", "in", "cached_stats1", "and", "'my_out_matches_list'", "in", "cached_stats1", ")", "\n", "self", ".", "assertTrue", "(", "'statistics'", "in", "cached_stats2", "and", "'my_ref_total_list'", "in", "cached_stats2", "and", "'my_out_matches_list'", "in", "cached_stats2", ")", "\n", "ori_report", "=", "compare_mt_main", ".", "generate_src_word_accuracy_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "self", ".", "src", ",", "ref_align_file", "=", "self", ".", "ref_align_file", ")", "\n", "cached_report", "=", "compare_mt_main", ".", "generate_src_word_accuracy_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "self", ".", "src", ",", "ref_align_file", "=", "self", ".", "ref_align_file", ",", "cache_dicts", "=", "[", "cached_stats1", ",", "cached_stats2", "]", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "statistics", "==", "ori_report", ".", "statistics", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "examples", "==", "ori_report", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestSentBucketCache.setUpClass": [[102, 105], ["test_cache._get_example_data"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out1", ",", "self", ".", "out2", "=", "_get_example_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestSentBucketCache.test_sentbucket_cache": [[106, 114], ["compare_mt.compare_mt_main.generate_sentence_bucketed_report", "compare_mt.compare_mt_main.generate_sentence_bucketed_report", "test_cache.TestSentBucketCache.assertTrue", "test_cache.TestSentBucketCache.assertTrue", "compare_mt.compare_mt_main.generate_sentence_bucketed_report", "compare_mt.compare_mt_main.generate_sentence_bucketed_report", "test_cache.TestSentBucketCache.assertTrue"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_bucketed_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_bucketed_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_bucketed_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_bucketed_report"], ["", "def", "test_sentbucket_cache", "(", "self", ")", ":", "\n", "    ", "cached_stats1", "=", "compare_mt_main", ".", "generate_sentence_bucketed_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", "]", ",", "to_cache", "=", "True", ")", "\n", "cached_stats2", "=", "compare_mt_main", ".", "generate_sentence_bucketed_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out2", "]", ",", "to_cache", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "'stats'", "in", "cached_stats1", ")", "\n", "self", ".", "assertTrue", "(", "'stats'", "in", "cached_stats2", ")", "\n", "ori_report", "=", "compare_mt_main", ".", "generate_sentence_bucketed_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ")", "\n", "cached_report", "=", "compare_mt_main", ".", "generate_sentence_bucketed_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "cache_dicts", "=", "[", "cached_stats1", ",", "cached_stats2", "]", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "sys_stats", "==", "ori_report", ".", "sys_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestNgramCache.setUpClass": [[117, 120], ["test_cache._get_example_data"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out1", ",", "self", ".", "out2", "=", "_get_example_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestNgramCache.test_ngram_cache": [[121, 130], ["compare_mt.compare_mt_main.generate_ngram_report", "compare_mt.compare_mt_main.generate_ngram_report", "test_cache.TestNgramCache.assertTrue", "test_cache.TestNgramCache.assertTrue", "compare_mt.compare_mt_main.generate_ngram_report", "compare_mt.compare_mt_main.generate_ngram_report", "test_cache.TestNgramCache.assertTrue", "range"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_ngram_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_ngram_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_ngram_report", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_ngram_report"], ["", "def", "test_ngram_cache", "(", "self", ")", ":", "\n", "    ", "reporters", ".", "sys_names", "=", "[", "f'sys{i+1}'", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "cached_stats1", "=", "compare_mt_main", ".", "generate_ngram_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", "]", ",", "to_cache", "=", "True", ")", "\n", "cached_stats2", "=", "compare_mt_main", ".", "generate_ngram_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out2", "]", ",", "to_cache", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "'totals'", "in", "cached_stats1", "and", "'matches'", "in", "cached_stats1", "and", "'overs'", "in", "cached_stats1", "and", "'unders'", "in", "cached_stats1", ")", "\n", "self", ".", "assertTrue", "(", "'totals'", "in", "cached_stats2", "and", "'matches'", "in", "cached_stats2", "and", "'overs'", "in", "cached_stats2", "and", "'unders'", "in", "cached_stats2", ")", "\n", "ori_report", "=", "compare_mt_main", ".", "generate_ngram_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ")", "\n", "cached_report", "=", "compare_mt_main", ".", "generate_ngram_report", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "cache_dicts", "=", "[", "cached_stats1", ",", "cached_stats2", "]", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "scorelist", "==", "ori_report", ".", "scorelist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestSentExamCache.setUpClass": [[133, 136], ["test_cache._get_example_data"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out1", ",", "self", ".", "out2", "=", "_get_example_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestSentExamCache.test_sentexam_cache": [[137, 146], ["compare_mt.compare_mt_main.generate_sentence_examples", "compare_mt.compare_mt_main.generate_sentence_examples", "test_cache.TestSentExamCache.assertTrue", "test_cache.TestSentExamCache.assertTrue", "compare_mt.compare_mt_main.generate_sentence_examples", "compare_mt.compare_mt_main.generate_sentence_examples", "test_cache.TestSentExamCache.assertTrue", "range"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_examples", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_examples", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_examples", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.compare_mt_main.generate_sentence_examples"], ["", "def", "test_sentexam_cache", "(", "self", ")", ":", "\n", "    ", "reporters", ".", "sys_names", "=", "[", "f'sys{i+1}'", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "cached_stats1", "=", "compare_mt_main", ".", "generate_sentence_examples", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", "]", ",", "to_cache", "=", "True", ")", "\n", "cached_stats2", "=", "compare_mt_main", ".", "generate_sentence_examples", "(", "self", ".", "ref", ",", "[", "self", ".", "out2", "]", ",", "to_cache", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "'scores'", "in", "cached_stats1", "and", "'strs'", "in", "cached_stats1", ")", "\n", "self", ".", "assertTrue", "(", "'scores'", "in", "cached_stats2", "and", "'strs'", "in", "cached_stats2", ")", "\n", "ori_report", "=", "compare_mt_main", ".", "generate_sentence_examples", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ")", "\n", "cached_report", "=", "compare_mt_main", ".", "generate_sentence_examples", "(", "self", ".", "ref", ",", "[", "self", ".", "out1", ",", "self", ".", "out2", "]", ",", "cache_dicts", "=", "[", "cached_stats1", ",", "cached_stats2", "]", ")", "\n", "self", ".", "assertTrue", "(", "cached_report", ".", "scorediff_lists", "==", "ori_report", ".", "scorediff_lists", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache.TestCachedPorterStemmer.test_stem": [[148, 155], ["compare_mt.cache_utils.CachedPorterStemmer", "nltk.stem.porter.PorterStemmer", "test_cache.TestCachedPorterStemmer.assertEqual", "nltk.stem.porter.PorterStemmer.stem", "compare_mt.cache_utils.CachedPorterStemmer.stem"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.CachedPorterStemmer.stem", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.cache_utils.CachedPorterStemmer.stem"], ["  ", "def", "test_stem", "(", "self", ")", ":", "\n", "    ", "cached_stemmer", "=", "CachedPorterStemmer", "(", ")", "\n", "stemmer", "=", "PorterStemmer", "(", ")", "\n", "words", "=", "[", "\"cats\"", ",", "\"citizen\"", ",", "\"best\"", ",", "\"citizen\"", "\"cats\"", "]", "\n", "\n", "for", "w", "in", "words", ":", "\n", "      ", "self", ".", "assertEqual", "(", "stemmer", ".", "stem", "(", "w", ")", ",", "cached_stemmer", ".", "stem", "(", "w", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache._get_example_data": [[17, 23], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "compare_mt.corpus_utils.load_tokens"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens"], ["def", "_get_example_data", "(", ")", ":", "\n", "  ", "example_path", "=", "os", ".", "path", ".", "join", "(", "compare_mt_root", ",", "\"example\"", ")", "\n", "ref_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.ref.eng\"", ")", "\n", "out1_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.sys1.eng\"", ")", "\n", "out2_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.sys2.eng\"", ")", "\n", "return", "[", "load_tokens", "(", "x", ")", "for", "x", "in", "(", "ref_file", ",", "out1_file", ",", "out2_file", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_cache._get_example_data_detokenized": [[24, 30], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "compare_mt.corpus_utils.load_tokens"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens"], ["", "def", "_get_example_data_detokenized", "(", ")", ":", "\n", "  ", "example_path", "=", "os", ".", "path", ".", "join", "(", "compare_mt_root", ",", "\"example\"", ")", "\n", "ref_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.ref.detok.eng\"", ")", "\n", "out1_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.sys1.detok.eng\"", ")", "\n", "out2_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.sys2.detok.eng\"", ")", "\n", "return", "[", "load_tokens", "(", "x", ")", "for", "x", "in", "(", "ref_file", ",", "out1_file", ",", "out2_file", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestBleuScorer.setUpClass": [[30, 38], ["test_scorers._get_example_data", "list", "compare_mt.scorers.create_scorer_from_profile", "test_scorers.TestBleuScorer.scorer.cache_stats", "test_scorers.TestBleuScorer.scorer.cache_stats", "range", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.cache_stats"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out1", ",", "self", ".", "out2", "=", "_get_example_data", "(", ")", "\n", "self", ".", "ids", "=", "list", "(", "range", "(", "len", "(", "self", ".", "ref", ")", ")", ")", "\n", "self", ".", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "\"bleu\"", ",", "case_insensitive", "=", "False", ")", "\n", "self", ".", "cache_stats1", "=", "self", ".", "scorer", ".", "cache_stats", "(", "self", ".", "ref", ",", "self", ".", "out1", ")", "\n", "self", ".", "cache_stats2", "=", "self", ".", "scorer", ".", "cache_stats", "(", "self", ".", "ref", ",", "self", ".", "out2", ")", "\n", "self", ".", "n_random_retries", "=", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestBleuScorer.test_score_corpus": [[39, 43], ["test_scorers.TestBleuScorer.scorer.score_corpus", "test_scorers.TestBleuScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "test_score_corpus", "(", "self", ")", ":", "\n", "    ", "bleu", ",", "_", "=", "self", ".", "scorer", ".", "score_corpus", "(", "self", ".", "ref", ",", "self", ".", "out1", ")", "\n", "# Compare to moses multi-bleu.pl", "\n", "self", ".", "assertAlmostEqual", "(", "bleu", ",", "22.44", ",", "places", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestBleuScorer.test_score_sentence": [[44, 50], ["test_scorers.TestBleuScorer.assertRaises", "test_scorers.TestBleuScorer.scorer.score_sentence"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "test_score_sentence", "(", "self", ")", ":", "\n", "\n", "    ", "def", "should_raise", "(", ")", ":", "\n", "      ", "return", "self", ".", "scorer", ".", "score_sentence", "(", "self", ".", "ref", "[", "0", "]", ",", "self", ".", "out1", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "assertRaises", "(", "NotImplementedError", ",", "should_raise", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestBleuScorer.test_score_cached_corpus": [[52, 70], ["range", "numpy.random.shuffle", "test_scorers.TestBleuScorer.scorer.score_cached_corpus", "test_scorers.TestBleuScorer.scorer.score_cached_corpus", "test_scorers.TestBleuScorer.scorer.score_corpus", "test_scorers.TestBleuScorer.scorer.score_corpus", "test_scorers.TestBleuScorer.assertAlmostEqual", "test_scorers.TestBleuScorer.assertAlmostEqual", "int", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "test_score_cached_corpus", "(", "self", ")", ":", "\n", "    ", "for", "_", "in", "range", "(", "self", ".", "n_random_retries", ")", ":", "\n", "      ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "ids", ")", "\n", "random_ids", "=", "self", ".", "ids", "[", ":", "int", "(", "len", "(", "self", ".", "ids", ")", "*", "0.5", ")", "]", "\n", "\n", "# compare-mt implementation", "\n", "my_sys1_score", ",", "_", "=", "self", ".", "scorer", ".", "score_cached_corpus", "(", "random_ids", ",", "self", ".", "cache_stats1", ")", "\n", "my_sys2_score", ",", "_", "=", "self", ".", "scorer", ".", "score_cached_corpus", "(", "random_ids", ",", "self", ".", "cache_stats2", ")", "\n", "\n", "# nltk implementation", "\n", "random_ref", "=", "[", "self", ".", "ref", "[", "i", "]", "for", "i", "in", "random_ids", "]", "\n", "random_sys1", "=", "[", "self", ".", "out1", "[", "i", "]", "for", "i", "in", "random_ids", "]", "\n", "random_sys2", "=", "[", "self", ".", "out2", "[", "i", "]", "for", "i", "in", "random_ids", "]", "\n", "nltk_sys1_score", ",", "_", "=", "self", ".", "scorer", ".", "score_corpus", "(", "random_ref", ",", "random_sys1", ")", "\n", "nltk_sys2_score", ",", "_", "=", "self", ".", "scorer", ".", "score_corpus", "(", "random_ref", ",", "random_sys2", ")", "\n", "\n", "self", ".", "assertAlmostEqual", "(", "my_sys1_score", ",", "nltk_sys1_score", ")", "\n", "self", ".", "assertAlmostEqual", "(", "my_sys2_score", ",", "nltk_sys2_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestSentBleuScorer.setUpClass": [[74, 78], ["test_scorers._get_example_data", "compare_mt.scorers.create_scorer_from_profile"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out", ",", "_", "=", "_get_example_data", "(", ")", "\n", "self", ".", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "\"sentbleu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestSentBleuScorer.test_score_sentence": [[79, 83], ["test_scorers.TestSentBleuScorer.scorer.score_sentence", "test_scorers.TestSentBleuScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "test_score_sentence", "(", "self", ")", ":", "\n", "    ", "bleu", ",", "_", "=", "self", ".", "scorer", ".", "score_sentence", "(", "self", ".", "ref", "[", "0", "]", ",", "self", ".", "out", "[", "0", "]", ")", "\n", "# compare to nltk", "\n", "self", ".", "assertAlmostEqual", "(", "bleu", ",", "32.44376694160122", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestSentBleuScorer.test_score_corpus": [[84, 91], ["test_scorers.TestSentBleuScorer.scorer.score_corpus", "sum", "len", "test_scorers.TestSentBleuScorer.assertAlmostEqual", "test_scorers.TestSentBleuScorer.scorer.score_sentence", "zip"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "test_score_corpus", "(", "self", ")", ":", "\n", "    ", "sent_bleu_corpus", ",", "_", "=", "self", ".", "scorer", ".", "score_corpus", "(", "self", ".", "ref", ",", "self", ".", "out", ")", "\n", "avg_sent_bleu", "=", "sum", "(", "[", "self", ".", "scorer", ".", "score_sentence", "(", "ref_sent", ",", "out_sent", ")", "[", "0", "]", "\n", "for", "ref_sent", ",", "out_sent", "in", "zip", "(", "self", ".", "ref", ",", "self", ".", "out", ")", "]", ")", "\n", "avg_sent_bleu", "/=", "len", "(", "self", ".", "ref", ")", "\n", "# compare to sacrebleu --force --metrics=chrf", "\n", "self", ".", "assertAlmostEqual", "(", "sent_bleu_corpus", ",", "avg_sent_bleu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestLengthScorer.setUpClass": [[95, 99], ["test_scorers._get_example_data", "compare_mt.scorers.create_scorer_from_profile"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out", ",", "_", "=", "_get_example_data", "(", ")", "\n", "self", ".", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "\"length\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestLengthScorer.test_score_sentence": [[100, 104], ["test_scorers.TestLengthScorer.scorer.score_sentence", "test_scorers.TestLengthScorer.assertAlmostEqual", "test_scorers.TestLengthScorer.assertEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "test_score_sentence", "(", "self", ")", ":", "\n", "    ", "length_ratio", ",", "desc", "=", "self", ".", "scorer", ".", "score_sentence", "(", "self", ".", "ref", "[", "0", "]", ",", "self", ".", "out", "[", "0", "]", ")", "\n", "self", ".", "assertAlmostEqual", "(", "length_ratio", ",", "22", "/", "24", ")", "\n", "self", ".", "assertEqual", "(", "desc", ",", "\"ref=24, out=22\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestLengthScorer.test_score_corpus": [[105, 109], ["test_scorers.TestLengthScorer.scorer.score_corpus", "test_scorers.TestLengthScorer.assertAlmostEqual", "test_scorers.TestLengthScorer.assertEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "test_score_corpus", "(", "self", ")", ":", "\n", "    ", "length_ratio_corpus", ",", "desc", "=", "self", ".", "scorer", ".", "score_corpus", "(", "self", ".", "ref", ",", "self", ".", "out", ")", "\n", "self", ".", "assertAlmostEqual", "(", "length_ratio_corpus", ",", "45672", "/", "48183", ")", "\n", "self", ".", "assertEqual", "(", "desc", ",", "\"ref=48183, out=45672\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestRibesScorer.setUpClass": [[114, 118], ["test_scorers._get_example_data", "compare_mt.scorers.create_scorer_from_profile"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out", ",", "_", "=", "_get_example_data", "(", ")", "\n", "self", ".", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "\"ribes\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestRibesScorer.test_score_sentence": [[119, 122], ["test_scorers.TestRibesScorer.scorer.score_sentence", "test_scorers.TestRibesScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "test_score_sentence", "(", "self", ")", ":", "\n", "    ", "ribes", ",", "_", "=", "self", ".", "scorer", ".", "score_sentence", "(", "self", ".", "ref", "[", "0", "]", ",", "self", ".", "out", "[", "0", "]", ")", "\n", "self", ".", "assertAlmostEqual", "(", "ribes", ",", "84.9014", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestRibesScorer.test_score_corpus": [[123, 126], ["test_scorers.TestRibesScorer.scorer.score_corpus", "test_scorers.TestRibesScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "test_score_corpus", "(", "self", ")", ":", "\n", "    ", "ribes_corpus", ",", "_", "=", "self", ".", "scorer", ".", "score_corpus", "(", "self", ".", "ref", ",", "self", ".", "out", ")", "\n", "self", ".", "assertAlmostEqual", "(", "ribes_corpus", ",", "80.0020", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestChrFScorer.setUpClass": [[130, 134], ["test_scorers._get_example_data", "compare_mt.scorers.create_scorer_from_profile"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out", ",", "_", "=", "_get_example_data", "(", ")", "\n", "self", ".", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "\"chrf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestChrFScorer.test_chrf_sentence": [[135, 139], ["test_scorers.TestChrFScorer.scorer.score_sentence", "test_scorers.TestChrFScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "test_chrf_sentence", "(", "self", ")", ":", "\n", "    ", "chrf", ",", "_", "=", "self", ".", "scorer", ".", "score_sentence", "(", "self", ".", "ref", "[", "0", "]", ",", "self", ".", "out", "[", "0", "]", ")", "\n", "# compare to sacrebleu --force --metrics=chrf", "\n", "self", ".", "assertAlmostEqual", "(", "chrf", ",", "59", ",", "places", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestChrFScorer.test_chrf_corpus": [[140, 144], ["test_scorers.TestChrFScorer.scorer.score_corpus", "test_scorers.TestChrFScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "test_chrf_corpus", "(", "self", ")", ":", "\n", "    ", "chrf", ",", "_", "=", "self", ".", "scorer", ".", "score_corpus", "(", "self", ".", "ref", ",", "self", ".", "out", ")", "\n", "# compare to sacrebleu --force --metrics=chrf", "\n", "self", ".", "assertAlmostEqual", "(", "chrf", ",", "48", ",", "places", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestSacreBleuScorer.setUpClass": [[148, 152], ["test_scorers._get_example_data_detokenized", "compare_mt.scorers.create_scorer_from_profile"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data_detokenized", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "self", ")", ":", "\n", "    ", "self", ".", "ref", ",", "self", ".", "out", ",", "_", "=", "_get_example_data_detokenized", "(", ")", "\n", "self", ".", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "\"sacrebleu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestSacreBleuScorer.test_detok_bleu_corpus": [[153, 157], ["test_scorers.TestSacreBleuScorer.scorer.score_corpus", "test_scorers.TestSacreBleuScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "test_detok_bleu_corpus", "(", "self", ")", ":", "\n", "    ", "detok_bleu", ",", "_", "=", "self", ".", "scorer", ".", "score_corpus", "(", "self", ".", "ref", ",", "self", ".", "out", ")", "\n", "# compare to sacrebleu", "\n", "self", ".", "assertAlmostEqual", "(", "detok_bleu", ",", "21.7", ",", "places", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestGleuScorer.setUpClass": [[161, 167], ["os.path.join", "compare_mt.scorers.create_scorer_from_profile", "compare_mt.corpus_utils.load_tokens", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.create_scorer_from_profile", "home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens"], ["  ", "@", "classmethod", "\n", "def", "setUpClass", "(", "cls", ")", "->", "None", ":", "\n", "    ", "example_path", "=", "os", ".", "path", ".", "join", "(", "compare_mt_root", ",", "\"example\"", ")", "\n", "filenames", "=", "[", "\"ted.ref.eng\"", ",", "\"ted.sys1.eng\"", ",", "\"ted.orig.slk\"", "]", "\n", "cls", ".", "ref", ",", "cls", ".", "out", ",", "cls", ".", "src", "=", "[", "load_tokens", "(", "os", ".", "path", ".", "join", "(", "example_path", ",", "name", ")", ")", "for", "name", "in", "filenames", "]", "\n", "cls", ".", "scorer", "=", "scorers", ".", "create_scorer_from_profile", "(", "\"gleu\"", ",", "case_insensitive", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestGleuScorer.test_score_corpus": [[168, 172], ["test_scorers.TestGleuScorer.scorer.score_corpus", "test_scorers.TestGleuScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_corpus"], ["", "def", "test_score_corpus", "(", "self", ")", ":", "\n", "    ", "gleu", ",", "_", "=", "self", ".", "scorer", ".", "score_corpus", "(", "self", ".", "ref", ",", "self", ".", "out", ",", "self", ".", "src", ")", "\n", "# Compare to https://github.com/cnap/gec-ranking", "\n", "self", ".", "assertAlmostEqual", "(", "gleu", ",", "22.39", ",", "places", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestGleuScorer.test_score_sentence": [[173, 180], ["test_scorers.TestGleuScorer.scorer.score_sentence", "test_scorers.TestGleuScorer.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_sentence"], ["", "def", "test_score_sentence", "(", "self", ")", ":", "\n", "    ", "src", "=", "\"A simple src sentence of test .\"", ".", "split", "(", ")", "\n", "ref", "=", "\"A simple source sentence for testing .\"", ".", "split", "(", ")", "\n", "out", "=", "\"A simple src sentence for testing .\"", ".", "split", "(", ")", "\n", "gleu", ",", "_", "=", "self", ".", "scorer", ".", "score_sentence", "(", "ref", ",", "out", ",", "src", ")", "\n", "# Compare to https://github.com/cnap/gec-ranking", "\n", "self", ".", "assertAlmostEqual", "(", "gleu", ",", "33.03", ",", "places", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers.TestGleuScorer.test_score_cached_corpus": [[181, 189], ["test_scorers.TestGleuScorer.scorer.score_cached_corpus", "test_scorers.TestGleuScorer.assertEqual", "range", "len"], "methods", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.scorers.GleuScorer.score_cached_corpus"], ["", "def", "test_score_cached_corpus", "(", "self", ")", ":", "\n", "    ", "cached_stats", "=", "[", "\n", "(", "9", ",", "2", ",", "[", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", ",", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", "]", ")", ",", "\n", "(", "4", ",", "13", ",", "[", "(", "4", ",", "13", ")", ",", "(", "2", ",", "12", ")", ",", "(", "0", ",", "11", ")", ",", "(", "0", ",", "10", ")", "]", ")", ",", "\n", "(", "10", ",", "10", ",", "[", "(", "6", ",", "10", ")", ",", "(", "4", ",", "9", ")", ",", "(", "1", ",", "8", ")", ",", "(", "0", ",", "7", ")", "]", ")", "\n", "]", "\n", "gleu", ",", "_", "=", "self", ".", "scorer", ".", "score_cached_corpus", "(", "range", "(", "len", "(", "cached_stats", ")", ")", ",", "cached_stats", ")", "\n", "self", ".", "assertEqual", "(", "gleu", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data": [[13, 19], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "compare_mt.corpus_utils.load_tokens"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens"], ["def", "_get_example_data", "(", ")", ":", "\n", "  ", "example_path", "=", "os", ".", "path", ".", "join", "(", "compare_mt_root", ",", "\"example\"", ")", "\n", "ref_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.ref.eng\"", ")", "\n", "out1_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.sys1.eng\"", ")", "\n", "out2_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.sys2.eng\"", ")", "\n", "return", "[", "load_tokens", "(", "x", ")", "for", "x", "in", "(", "ref_file", ",", "out1_file", ",", "out2_file", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_compare-mt.tests.test_scorers._get_example_data_detokenized": [[20, 26], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "compare_mt.corpus_utils.load_tokens"], "function", ["home.repos.pwc.inspect_result.neulab_compare-mt.compare_mt.corpus_utils.load_tokens"], ["", "def", "_get_example_data_detokenized", "(", ")", ":", "\n", "  ", "example_path", "=", "os", ".", "path", ".", "join", "(", "compare_mt_root", ",", "\"example\"", ")", "\n", "ref_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.ref.detok.eng\"", ")", "\n", "out1_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.sys1.detok.eng\"", ")", "\n", "out2_file", "=", "os", ".", "path", ".", "join", "(", "example_path", ",", "\"ted.sys2.detok.eng\"", ")", "\n", "return", "[", "load_tokens", "(", "x", ")", "for", "x", "in", "(", "ref_file", ",", "out1_file", ",", "out2_file", ")", "]", "\n", "\n"]]}