{"home.repos.pwc.inspect_result.serrano-s_attn-tests.None.plain_model_test.evaluate": [[24, 78], ["allennlp.common.checks.check_for_gpu", "torch.no_grad", "model.eval", "open", "open.write", "data_iterator", "logger.info", "allennlp.common.tqdm.Tqdm.tqdm", "print", "open.close", "model.get_metrics", "[].size", "allennlp.nn.util.move_to_device", "model", "numpy.argmax", "range", "model.get_metrics", "Tqdm.tqdm.set_description", "data_iterator.get_num_batches", "output_dict[].data.numpy", "output_dict[].data.cpu().numpy", "batch[].data.numpy", "batch[].data.cpu().numpy", "open.write", "open.write", "any", "logger.warning", "str", "output_dict[].data.cpu", "batch[].data.cpu", "str", "str", "metric_name.startswith", "int", "int", "model.get_metrics.items", "name.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HierarchicalAttentionNetwork.get_metrics", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HierarchicalAttentionNetwork.get_metrics"], ["def", "evaluate", "(", "model", ":", "Model", ",", "\n", "instances", ":", "Iterable", "[", "Instance", "]", ",", "\n", "data_iterator", ":", "DataIterator", ",", "\n", "cuda_device", ":", "int", ",", "\n", "label_fname", ":", "str", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "_warned_tqdm_ignores_underscores", "=", "False", "\n", "check_for_gpu", "(", "cuda_device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "label_file", "=", "open", "(", "label_fname", ",", "'w'", ")", "\n", "label_file", ".", "write", "(", "'real_label,guessed_label\\n'", ")", "\n", "\n", "iterator", "=", "data_iterator", "(", "instances", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "False", ")", "\n", "logger", ".", "info", "(", "\"Iterating over dataset\"", ")", "\n", "generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "iterator", ",", "total", "=", "data_iterator", ".", "get_num_batches", "(", "instances", ")", ")", "\n", "total_num_inst", "=", "0", "\n", "for", "batch", "in", "generator_tqdm", ":", "\n", "            ", "num_inst", "=", "batch", "[", "'tokens'", "]", "[", "'tokens'", "]", ".", "size", "(", "0", ")", "\n", "total_num_inst", "+=", "num_inst", "\n", "batch", "=", "util", ".", "move_to_device", "(", "batch", ",", "cuda_device", ")", "\n", "\n", "output_dict", "=", "model", "(", "**", "batch", ")", "\n", "if", "cuda_device", "==", "-", "1", ":", "\n", "                ", "output_matrix", "=", "output_dict", "[", "'label_logits'", "]", ".", "data", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "output_matrix", "=", "output_dict", "[", "'label_logits'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "output_labels", "=", "np", ".", "argmax", "(", "output_matrix", ",", "axis", "=", "1", ")", "\n", "if", "cuda_device", "==", "-", "1", ":", "\n", "                ", "true_labels", "=", "batch", "[", "'label'", "]", ".", "data", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "true_labels", "=", "batch", "[", "'label'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "assert", "true_labels", ".", "shape", "[", "0", "]", "==", "output_labels", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "true_labels", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "label_file", ".", "write", "(", "str", "(", "int", "(", "true_labels", "[", "i", "]", ")", ")", "+", "','", ")", "\n", "label_file", ".", "write", "(", "str", "(", "int", "(", "output_labels", "[", "i", "]", ")", ")", "+", "'\\n'", ")", "\n", "\n", "", "metrics", "=", "model", ".", "get_metrics", "(", ")", "\n", "if", "(", "not", "_warned_tqdm_ignores_underscores", "and", "\n", "any", "(", "metric_name", ".", "startswith", "(", "\"_\"", ")", "for", "metric_name", "in", "metrics", ")", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Metrics with names beginning with \\\"_\\\" will \"", "\n", "\"not be logged to the tqdm progress bar.\"", ")", "\n", "_warned_tqdm_ignores_underscores", "=", "True", "\n", "", "description", "=", "', '", ".", "join", "(", "[", "\"%s: %.2f\"", "%", "(", "name", ",", "value", ")", "for", "name", ",", "value", "\n", "in", "metrics", ".", "items", "(", ")", "if", "not", "name", ".", "startswith", "(", "\"_\"", ")", "]", ")", "+", "\" ||\"", "\n", "generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "\n", "", "print", "(", "\"NUM INSTANCES ITERATED OVER: \"", "+", "str", "(", "total_num_inst", ")", ")", "\n", "label_file", ".", "close", "(", ")", "\n", "\n", "return", "model", ".", "get_metrics", "(", "reset", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.plain_model_test.main": [[80, 171], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "print", "print", "print", "print", "logging.getLogger().setLevel", "allennlp.common.util.import_submodules", "allennlp.common.util.import_submodules", "allennlp.models.archival.load_archive", "allennlp.common.util.prepare_environment", "model.eval", "config.pop", "logger.info", "DatasetReader.from_params.read", "config.pop", "allennlp.data.iterators.DataIterator.from_params", "DataIterator.from_params.index_with", "plain_model_test.evaluate", "logger.info", "logger.info", "evaluate.items", "print", "print", "logging.getLogger", "logging.getLogger", "parser.parse_args.include_package.strip", "allennlp.common.util.import_submodules", "model._output_logit.get_output_dim", "allennlp.training.metrics.F1Measure", "allennlp.data.dataset_readers.dataset_reader.DatasetReader.from_params", "allennlp.data.dataset_readers.dataset_reader.DatasetReader.from_params", "config.pop", "logger.info", "logging.getLogger", "open", "config.pop", "json.dumps", "open", "json.dump", "parser.parse_args.input_file.rfind", "parser.parse_args.input_file.rfind", "parser.parse_args.weights_file.rfind", "parser.parse_args.input_file.rfind", "l.strip", "f.readlines"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.plain_model_test.evaluate", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.get_output_dim", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "'--input-file'", ",", "type", "=", "str", ",", "help", "=", "'path to the file containing the evaluation data'", ")", "\n", "parser", ".", "add_argument", "(", "'--output-file'", ",", "type", "=", "str", ",", "help", "=", "'path to output file'", ")", "\n", "parser", ".", "add_argument", "(", "'--weights-file'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'a path that overrides which weights file to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--cuda-device'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "'id of GPU to use (if any)'", ")", "\n", "parser", ".", "add_argument", "(", "'--overrides'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "'a JSON structure used to override the experiment configuration'", ")", "\n", "parser", ".", "add_argument", "(", "'--include-package'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--archive-file'", ",", "type", "=", "str", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "'/'", "in", "args", ".", "weights_file", ":", "\n", "        ", "label_file", "=", "args", ".", "weights_file", "[", ":", "args", ".", "weights_file", ".", "rfind", "(", "'/'", ")", "+", "1", "]", "\n", "", "else", ":", "\n", "        ", "label_file", "=", "''", "\n", "", "label_file", "+=", "(", "args", ".", "input_file", "[", "args", ".", "input_file", ".", "rfind", "(", "'/'", ")", "+", "1", ":", "args", ".", "input_file", ".", "rfind", "(", "'.'", ")", "]", "if", "'/'", "in", "args", ".", "input_file", "else", "\n", "args", ".", "input_file", "[", ":", "args", ".", "input_file", ".", "rfind", "(", "'.'", ")", "]", ")", "\n", "label_file", "+=", "'_reallabel_guessedlabel.csv'", "\n", "print", "(", "\"Will write labels to \"", "+", "label_file", ")", "\n", "print", "(", "\"Evaluating on \"", "+", "args", ".", "input_file", ")", "\n", "print", "(", "\"Archive file being used is \"", "+", "args", ".", "archive_file", ")", "\n", "print", "(", "\"Weights file being used is \"", "+", "args", ".", "weights_file", ")", "\n", "print", "(", ")", "\n", "\n", "logging", ".", "getLogger", "(", "'allennlp.common.params'", ")", ".", "disabled", "=", "True", "\n", "logging", ".", "getLogger", "(", "'allennlp.nn.initializers'", ")", ".", "disabled", "=", "True", "\n", "logging", ".", "getLogger", "(", "'allennlp.modules.token_embedders.embedding'", ")", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "if", "args", ".", "include_package", ".", "strip", "(", ")", "!=", "''", ":", "\n", "        ", "import_submodules", "(", "args", ".", "include_package", ")", "\n", "", "import_submodules", "(", "\"attn_tests_lib\"", ")", "\n", "import_submodules", "(", "\"textcat\"", ")", "\n", "\n", "if", "args", ".", "overrides", "!=", "''", ":", "\n", "        ", "with", "open", "(", "args", ".", "overrides", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "args", ".", "overrides", "=", "\" \"", ".", "join", "(", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "f", ".", "readlines", "(", ")", "]", ")", "\n", "", "", "archive", "=", "load_archive", "(", "args", ".", "archive_file", ",", "args", ".", "cuda_device", ",", "args", ".", "overrides", ",", "args", ".", "weights_file", ")", "\n", "config", "=", "archive", ".", "config", "\n", "prepare_environment", "(", "config", ")", "\n", "model", "=", "archive", ".", "model", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "model", ".", "_output_logit", ".", "get_output_dim", "(", ")", "==", "2", ":", "\n", "        ", "model", ".", "calculate_f1", "=", "True", "\n", "model", ".", "_f1", "=", "F1Measure", "(", "1", ")", "\n", "\n", "", "validation_dataset_reader_params", "=", "config", ".", "pop", "(", "'validation_dataset_reader'", ",", "None", ")", "\n", "if", "validation_dataset_reader_params", "is", "not", "None", ":", "\n", "        ", "dataset_reader", "=", "DatasetReader", ".", "from_params", "(", "validation_dataset_reader_params", ")", "\n", "", "else", ":", "\n", "        ", "dataset_reader", "=", "DatasetReader", ".", "from_params", "(", "config", ".", "pop", "(", "'dataset_reader'", ")", ")", "\n", "", "evaluation_data_path", "=", "args", ".", "input_file", "\n", "logger", ".", "info", "(", "\"Reading evaluation data from %s\"", ",", "evaluation_data_path", ")", "\n", "instances", "=", "dataset_reader", ".", "read", "(", "evaluation_data_path", ")", "\n", "\n", "iterator_params", "=", "config", ".", "pop", "(", "\"validation_iterator\"", ",", "None", ")", "\n", "if", "iterator_params", "is", "None", ":", "\n", "        ", "iterator_params", "=", "config", ".", "pop", "(", "\"iterator\"", ")", "\n", "", "new_param_dict", "=", "{", "'type'", ":", "'basic'", "}", "\n", "if", "'batch_size'", "in", "iterator_params", ".", "params", ":", "\n", "        ", "new_param_dict", "[", "'batch_size'", "]", "=", "iterator_params", ".", "params", "[", "'batch_size'", "]", "\n", "", "if", "'maximum_samples_per_batch'", "in", "iterator_params", ".", "params", ":", "\n", "        ", "new_param_dict", "[", "'maximum_samples_per_batch'", "]", "=", "iterator_params", ".", "params", "[", "'maximum_samples_per_batch'", "]", "\n", "", "iterator_params", ".", "params", "=", "new_param_dict", "\n", "iterator", "=", "DataIterator", ".", "from_params", "(", "iterator_params", ")", "\n", "iterator", ".", "index_with", "(", "model", ".", "vocab", ")", "\n", "\n", "metrics", "=", "evaluate", "(", "model", ",", "instances", ",", "iterator", ",", "args", ".", "cuda_device", ",", "label_file", ")", "\n", "\n", "logger", ".", "info", "(", "\"Finished evaluating.\"", ")", "\n", "logger", ".", "info", "(", "\"Metrics:\"", ")", "\n", "for", "key", ",", "metric", "in", "metrics", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"%s: %s\"", ",", "key", ",", "metric", ")", "\n", "\n", "", "print", "(", "'\\n'", "+", "json", ".", "dumps", "(", "metrics", ",", "indent", "=", "4", ")", ")", "\n", "print", "(", "\"Successfully wrote labels to \"", "+", "label_file", ")", "\n", "\n", "output_file", "=", "args", ".", "output_file", "\n", "if", "output_file", ":", "\n", "        ", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "file", ":", "\n", "            ", "json", ".", "dump", "(", "metrics", ",", "file", ",", "indent", "=", "4", ")", "\n", "", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params": [[623, 653], ["allennlp.models.model.Model.from_params", "vocab.save_to_files", "all_datasets.get", "all_datasets.get", "params.pop", "params.pop.pop", "allennlp.models.model.Model.from_params.named_parameters", "allennlp_internal_functions.get_frozen_and_tunable_parameter_names", "logger.info", "logger.info", "train_model.TrainerPieces", "os.path.join", "any", "logger.info", "logger.info", "params.pop", "parameter.requires_grad_", "re.search"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.get_frozen_and_tunable_parameter_names"], ["def", "from_params", "(", "params", ":", "Params", ",", "iterator", ",", "val_iterator", ",", "vocab", ",", "all_datasets", ",", "\n", "serialization_dir", ":", "str", ",", "recover", ":", "bool", "=", "False", ")", "->", "'TrainerPieces'", ":", "\n", "        ", "model", "=", "Model", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "params", ".", "pop", "(", "'model'", ")", ")", "\n", "\n", "# Initializing the model can have side effect of expanding the vocabulary", "\n", "vocab", ".", "save_to_files", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"vocabulary\"", ")", ")", "\n", "\n", "train_data", "=", "all_datasets", "[", "'train'", "]", "\n", "validation_data", "=", "all_datasets", ".", "get", "(", "'validation'", ")", "\n", "test_data", "=", "all_datasets", ".", "get", "(", "'test'", ")", "\n", "\n", "trainer_params", "=", "params", ".", "pop", "(", "\"trainer\"", ")", "\n", "no_grad_regexes", "=", "trainer_params", ".", "pop", "(", "\"no_grad\"", ",", "(", ")", ")", "\n", "for", "name", ",", "parameter", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "any", "(", "re", ".", "search", "(", "regex", ",", "name", ")", "for", "regex", "in", "no_grad_regexes", ")", ":", "\n", "                ", "parameter", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "", "", "frozen_parameter_names", ",", "tunable_parameter_names", "=", "get_frozen_and_tunable_parameter_names", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Following parameters are Frozen  (without gradient):\"", ")", "\n", "for", "name", "in", "frozen_parameter_names", ":", "\n", "            ", "logger", ".", "info", "(", "name", ")", "\n", "", "logger", ".", "info", "(", "\"Following parameters are Tunable (with gradient):\"", ")", "\n", "for", "name", "in", "tunable_parameter_names", ":", "\n", "            ", "logger", ".", "info", "(", "name", ")", "\n", "\n", "", "return", "TrainerPieces", "(", "model", ",", "iterator", ",", "\n", "train_data", ",", "validation_data", ",", "test_data", ",", "\n", "val_iterator", ",", "trainer_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.edit_config_file_to_have_gpu": [[38, 53], ["open", "open.close", "os.rename", "open", "open.write", "len", "line[].isdigit", "str", "line.index"], "function", ["None"], ["def", "edit_config_file_to_have_gpu", "(", "filename", ",", "gpu_num", ")", ":", "\n", "    ", "temp_filename", "=", "filename", "+", "\".temp\"", "\n", "new_f", "=", "open", "(", "temp_filename", ",", "'w'", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "'\"cuda_device\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "gpu_num", ")", "+", "line_end", "\n", "", "new_f", ".", "write", "(", "line", ")", "\n", "", "", "new_f", ".", "close", "(", ")", "\n", "os", ".", "rename", "(", "temp_filename", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.remove_pretrained_embedding_params": [[55, 62], ["params.keys", "params.values", "isinstance", "train_model.remove_pretrained_embedding_params"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.remove_pretrained_embedding_params"], ["", "def", "remove_pretrained_embedding_params", "(", "params", ":", "Params", ")", ":", "\n", "    ", "keys", "=", "params", ".", "keys", "(", ")", "\n", "if", "'pretrained_file'", "in", "keys", ":", "\n", "        ", "del", "params", "[", "'pretrained_file'", "]", "\n", "", "for", "value", "in", "params", ".", "values", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "Params", ")", ":", "\n", "            ", "remove_pretrained_embedding_params", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.modified_model_load": [[64, 99], ["os.path.join", "allennlp.data.Vocabulary.from_files", "config.get", "train_model.remove_pretrained_embedding_params", "allennlp.models.model.Model.from_params", "torch.load", "Model.from_params.load_state_dict", "os.path.join", "Model.from_params.cuda", "Model.from_params.cpu", "allennlp.device_mapping"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.remove_pretrained_embedding_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params"], ["", "", "", "def", "modified_model_load", "(", "\n", "config", ":", "Params", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "weights_file", ":", "str", "=", "None", ",", "\n", "cuda_device", ":", "int", "=", "-", "1", ")", "->", "Model", ":", "\n", "    ", "\"\"\"\n    Instantiates an already-trained model, based on the experiment\n    configuration and some optional overrides.\n    \"\"\"", "\n", "weights_file", "=", "weights_file", "or", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "_DEFAULT_WEIGHTS", ")", "\n", "\n", "# Load vocabulary from file", "\n", "vocab_dir", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "'vocabulary'", ")", "\n", "# If the config specifies a vocabulary subclass, we need to use it.", "\n", "vocab", "=", "Vocabulary", ".", "from_files", "(", "vocab_dir", ")", "\n", "\n", "model_params", "=", "config", ".", "get", "(", "'model'", ")", "\n", "\n", "# The experiment config tells us how to _train_ a model, including where to get pre-trained", "\n", "# embeddings from.  We're now _loading_ the model, so those embeddings will already be", "\n", "# stored in our weights.  We don't need any pretrained weight file anymore, and we don't", "\n", "# want the code to look for it, so we remove it from the parameters here.", "\n", "remove_pretrained_embedding_params", "(", "model_params", ")", "\n", "model", "=", "Model", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "model_params", ")", "\n", "model_state", "=", "torch", ".", "load", "(", "weights_file", ",", "map_location", "=", "util", ".", "device_mapping", "(", "cuda_device", ")", ")", "\n", "model", ".", "load_state_dict", "(", "model_state", ",", "strict", "=", "False", ")", "\n", "\n", "# Force model to cpu or gpu, as appropriate, to make sure that the embeddings are", "\n", "# in sync with the weights", "\n", "if", "cuda_device", ">=", "0", ":", "\n", "        ", "model", ".", "cuda", "(", "cuda_device", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "cpu", "(", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.load_prev_best_model": [[101, 108], ["train_model.edit_config_file_to_have_gpu", "allennlp.common.Params.from_file", "train_model.modified_model_load", "s_dir.endswith", "os.path.join"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.edit_config_file_to_have_gpu", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.modified_model_load"], ["", "def", "load_prev_best_model", "(", "s_dir", ")", ":", "\n", "    ", "if", "not", "s_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "s_dir", "+=", "'/'", "\n", "", "edit_config_file_to_have_gpu", "(", "s_dir", "+", "\"config.json\"", ",", "-", "1", ")", "\n", "loaded_prev_params", "=", "Params", ".", "from_file", "(", "os", ".", "path", ".", "join", "(", "s_dir", ",", "s_dir", "+", "\"config.json\"", ")", ",", "\"\"", ")", "\n", "model", "=", "modified_model_load", "(", "loaded_prev_params", ",", "s_dir", ",", "cuda_device", "=", "-", "1", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.transfer_prev_model_weights_to_new_model": [[110, 121], ["prev_model.named_parameters", "new_model.named_parameters", "dict", "dict_params2[].data.copy_"], "function", ["None"], ["", "def", "transfer_prev_model_weights_to_new_model", "(", "prev_model", ",", "new_model", ")", ":", "\n", "    ", "params1", "=", "prev_model", ".", "named_parameters", "(", ")", "\n", "params2", "=", "new_model", ".", "named_parameters", "(", ")", "\n", "\n", "dict_params2", "=", "dict", "(", "params2", ")", "\n", "\n", "for", "name1", ",", "param1", "in", "params1", ":", "\n", "        ", "if", "name1", "in", "dict_params2", ":", "\n", "            ", "dict_params2", "[", "name1", "]", ".", "data", ".", "copy_", "(", "param1", ".", "data", ")", "\n", "\n", "", "", "return", "new_model", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.train_model_but_load_prev_model_weights": [[123, 251], ["allennlp.common.util.prepare_environment", "allennlp.commands.train.create_serialization_dir", "allennlp.common.util.prepare_global_logging", "params.params.get().get", "isinstance", "params.to_file", "allennlp_internal_functions.datasets_from_params", "set", "logger.info", "allennlp.data.Vocabulary.from_params", "allennlp.models.model.Model.from_params", "train_model.transfer_prev_model_weights_to_new_model", "Vocabulary.from_params.save_to_files", "allennlp.data.iterators.data_iterator.DataIterator.from_params", "DataIterator.from_params.index_with", "params.pop", "allennlp_internal_functions.datasets_from_params.get", "allennlp_internal_functions.datasets_from_params.get", "params.pop", "params.pop.pop", "transfer_prev_model_weights_to_new_model.named_parameters", "allennlp.training.trainer.Trainer.from_params", "params.pop_bool", "params.assert_empty", "allennlp.models.archival.archive_model", "logger.info", "os.path.join", "torch.load", "best_model.load_state_dict", "allennlp_internal_functions.dump_metrics", "allennlp.common.checks.check_for_gpu", "os.path.join", "params.pop", "params.pop", "os.path.join", "params.pop", "allennlp.data.iterators.data_iterator.DataIterator.from_params", "DataIterator.from_params.index_with", "any", "Trainer.from_params.train", "logger.info", "allennlp.commands.evaluate.evaluate", "allennlp.commands.evaluate.evaluate.items", "os.path.join", "params.params.get", "allennlp.common.checks.check_for_gpu", "allennlp.common.checks.ConfigurationError", "params.pop", "parameter.requires_grad_", "os.path.exists", "logger.info", "allennlp_internal_functions.datasets_from_params.items", "re.search", "os.path.join", "logging.info", "allennlp.models.archival.archive_model"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.datasets_from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.transfer_prev_model_weights_to_new_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.dump_metrics", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.plain_model_test.evaluate"], ["", "def", "train_model_but_load_prev_model_weights", "(", "params", ":", "Params", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "prev_best_model", ":", "Model", ",", "\n", "file_friendly_logging", ":", "bool", "=", "False", ",", "\n", "recover", ":", "bool", "=", "False", ",", "\n", "force", ":", "bool", "=", "False", ")", "->", "Model", ":", "\n", "    ", "\"\"\"\n    Trains the model specified in the given :class:`Params` object, using the data and training\n    parameters also specified in that object, and saves the results in ``serialization_dir``.\n    Parameters\n    ----------\n    params : ``Params``\n        A parameter object specifying an AllenNLP Experiment.\n    serialization_dir : ``str``\n        The directory in which to save results and logs.\n    file_friendly_logging : ``bool``, optional (default=False)\n        If ``True``, we add newlines to tqdm output, even on an interactive terminal, and we slow\n        down tqdm's output to only once every 10 seconds.\n    recover : ``bool``, optional (default=False)\n        If ``True``, we will try to recover a training run from an existing serialization\n        directory.  This is only intended for use when something actually crashed during the middle\n        of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n    Returns\n    -------\n    best_model: ``Model``\n        The model with the best epoch weights.\n    \"\"\"", "\n", "prepare_environment", "(", "params", ")", "\n", "\n", "create_serialization_dir", "(", "params", ",", "serialization_dir", ",", "recover", ")", "\n", "prepare_global_logging", "(", "serialization_dir", ",", "file_friendly_logging", ")", "\n", "\n", "cuda_device", "=", "params", ".", "params", ".", "get", "(", "'trainer'", ")", ".", "get", "(", "'cuda_device'", ",", "-", "1", ")", "\n", "if", "isinstance", "(", "cuda_device", ",", "list", ")", ":", "\n", "        ", "for", "device", "in", "cuda_device", ":", "\n", "            ", "check_for_gpu", "(", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "check_for_gpu", "(", "cuda_device", ")", "\n", "\n", "", "params", ".", "to_file", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", ")", "\n", "\n", "all_datasets", "=", "datasets_from_params", "(", "params", ")", "\n", "datasets_for_vocab_creation", "=", "set", "(", "params", ".", "pop", "(", "\"datasets_for_vocab_creation\"", ",", "all_datasets", ")", ")", "\n", "\n", "for", "dataset", "in", "datasets_for_vocab_creation", ":", "\n", "        ", "if", "dataset", "not", "in", "all_datasets", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"invalid 'dataset_for_vocab_creation' {dataset}\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"From dataset instances, %s will be considered for vocabulary creation.\"", ",", "\n", "\", \"", ".", "join", "(", "datasets_for_vocab_creation", ")", ")", "\n", "vocab", "=", "Vocabulary", ".", "from_params", "(", "\n", "params", ".", "pop", "(", "\"vocabulary\"", ",", "{", "}", ")", ",", "\n", "(", "instance", "for", "key", ",", "dataset", "in", "all_datasets", ".", "items", "(", ")", "\n", "for", "instance", "in", "dataset", "\n", "if", "key", "in", "datasets_for_vocab_creation", ")", "\n", ")", "\n", "\n", "model", "=", "Model", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "params", ".", "pop", "(", "'model'", ")", ")", "\n", "model", "=", "transfer_prev_model_weights_to_new_model", "(", "prev_best_model", ",", "model", ")", "\n", "\n", "# Initializing the model can have side effect of expanding the vocabulary", "\n", "vocab", ".", "save_to_files", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"vocabulary\"", ")", ")", "\n", "\n", "iterator", "=", "DataIterator", ".", "from_params", "(", "params", ".", "pop", "(", "\"iterator\"", ")", ")", "\n", "iterator", ".", "index_with", "(", "vocab", ")", "\n", "validation_iterator_params", "=", "params", ".", "pop", "(", "\"validation_iterator\"", ",", "None", ")", "\n", "if", "validation_iterator_params", ":", "\n", "        ", "validation_iterator", "=", "DataIterator", ".", "from_params", "(", "validation_iterator_params", ")", "\n", "validation_iterator", ".", "index_with", "(", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "validation_iterator", "=", "None", "\n", "\n", "", "train_data", "=", "all_datasets", "[", "'train'", "]", "\n", "validation_data", "=", "all_datasets", ".", "get", "(", "'validation'", ")", "\n", "test_data", "=", "all_datasets", ".", "get", "(", "'test'", ")", "\n", "\n", "trainer_params", "=", "params", ".", "pop", "(", "\"trainer\"", ")", "\n", "no_grad_regexes", "=", "trainer_params", ".", "pop", "(", "\"no_grad\"", ",", "(", ")", ")", "\n", "for", "name", ",", "parameter", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "any", "(", "re", ".", "search", "(", "regex", ",", "name", ")", "for", "regex", "in", "no_grad_regexes", ")", ":", "\n", "            ", "parameter", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "", "", "trainer", "=", "Trainer", ".", "from_params", "(", "model", "=", "model", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "iterator", "=", "iterator", ",", "\n", "train_data", "=", "train_data", ",", "\n", "validation_data", "=", "validation_data", ",", "\n", "params", "=", "trainer_params", ",", "\n", "validation_iterator", "=", "validation_iterator", ")", "\n", "\n", "evaluate_on_test", "=", "params", ".", "pop_bool", "(", "\"evaluate_on_test\"", ",", "False", ")", "\n", "params", ".", "assert_empty", "(", "'base train command'", ")", "\n", "\n", "try", ":", "\n", "        ", "metrics", "=", "trainer", ".", "train", "(", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "# if we have completed an epoch, try to create a model archive.", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "_DEFAULT_WEIGHTS", ")", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\"Training interrupted by the user. Attempting to create \"", "\n", "\"a model archive using the current best epoch weights.\"", ")", "\n", "archive_model", "(", "serialization_dir", ",", "files_to_archive", "=", "params", ".", "files_to_archive", ")", "\n", "", "raise", "\n", "\n", "# Now tar up results", "\n", "", "archive_model", "(", "serialization_dir", ",", "files_to_archive", "=", "params", ".", "files_to_archive", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loading the best epoch weights.\"", ")", "\n", "best_model_state_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "'best.th'", ")", "\n", "best_model_state", "=", "torch", ".", "load", "(", "best_model_state_path", ")", "\n", "best_model", "=", "model", "\n", "best_model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "\n", "if", "test_data", "and", "evaluate_on_test", ":", "\n", "        ", "logger", ".", "info", "(", "\"The model will be evaluated using the best epoch weights.\"", ")", "\n", "test_metrics", "=", "evaluate", "(", "\n", "best_model", ",", "test_data", ",", "validation_iterator", "or", "iterator", ",", "\n", "cuda_device", "=", "trainer", ".", "_cuda_devices", "[", "0", "]", "# pylint: disable=protected-access", "\n", ")", "\n", "for", "key", ",", "value", "in", "test_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"test_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "", "elif", "test_data", ":", "\n", "        ", "logger", ".", "info", "(", "\"To evaluate on the test set after training, pass the \"", "\n", "\"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\"", ")", "\n", "\n", "", "dump_metrics", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"metrics.json\"", ")", ",", "metrics", ",", "log", "=", "True", ")", "\n", "\n", "return", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.load_model_from_serialization_dir": [[253, 329], ["allennlp.common.Params.from_file", "Params.from_file.to_file", "Params.from_file.get().get", "train_model.modified_model_load", "s_dir.endswith", "os.path.isfile", "os.rename", "os.path.isfile", "os.rename", "os.path.isfile", "os.path.join", "allennlp.common.Params.from_file", "Params.from_file.get().get", "open", "Params.from_file.get", "str", "str", "open", "Params.from_file.get", "str", "int", "f.write", "f.write", "f.write", "len", "line[].isdigit", "line[].strip", "int", "len", "line[].isdigit", "line[].strip", "int", "len", "line[].isdigit", "line[].strip", "str", "str", "str", "line.rfind", "line.index", "line.rfind", "line.index", "line.rfind", "line.index"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.modified_model_load"], ["", "def", "load_model_from_serialization_dir", "(", "s_dir", ",", "training_config_filename", ",", "cuda_device", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"\n    Function not currently in use. This is from back when I was trying to keep each successive\n    addition to the model's training in the same serialization directory.\n    :param s_dir:\n    :param training_config_filename:\n    :param cuda_device:\n    :return:\n    \"\"\"", "\n", "if", "not", "s_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "s_dir", "+=", "'/'", "\n", "", "if", "training_config_filename", "!=", "s_dir", "+", "\"config.json\"", ":", "\n", "        ", "counter", "=", "1", "\n", "new_config_name", "=", "s_dir", "+", "\"config\"", "+", "str", "(", "counter", ")", "+", "\".json\"", "\n", "while", "os", ".", "path", ".", "isfile", "(", "new_config_name", ")", ":", "\n", "            ", "counter", "+=", "1", "\n", "new_config_name", "=", "s_dir", "+", "\"config\"", "+", "str", "(", "counter", ")", "+", "\".json\"", "\n", "", "os", ".", "rename", "(", "s_dir", "+", "\"config.json\"", ",", "new_config_name", ")", "\n", "training_config_changed", "=", "True", "\n", "", "else", ":", "\n", "        ", "training_config_changed", "=", "False", "\n", "", "if", "training_config_changed", "and", "os", ".", "path", ".", "isfile", "(", "s_dir", "+", "\"random_seeds.txt\"", ")", ":", "\n", "        ", "new_name", "=", "s_dir", "+", "\"random_seeds\"", "+", "str", "(", "counter", ")", "+", "\".txt\"", "\n", "os", ".", "rename", "(", "s_dir", "+", "\"random_seeds.txt\"", ",", "new_name", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "s_dir", "+", "\"random_seeds.txt\"", ")", ":", "\n", "# try to make one from the given config file", "\n", "        ", "rand_seeds", "=", "[", "None", ",", "None", ",", "None", "]", "\n", "with", "open", "(", "training_config_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "'\"random_seed\"'", "in", "line", ":", "\n", "                    ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", ":", "\n", "                        ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "rand_seed", "=", "int", "(", "line", "[", "line", ".", "index", "(", "':'", ")", "+", "1", ":", "line", ".", "rfind", "(", "line_end", ")", "]", ".", "strip", "(", ")", ")", "\n", "rand_seeds", "[", "0", "]", "=", "rand_seed", "\n", "", "elif", "'\"numpy_seed\"'", "in", "line", ":", "\n", "                    ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", ":", "\n", "                        ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "rand_seed", "=", "int", "(", "line", "[", "line", ".", "index", "(", "':'", ")", "+", "1", ":", "line", ".", "rfind", "(", "line_end", ")", "]", ".", "strip", "(", ")", ")", "\n", "rand_seeds", "[", "1", "]", "=", "rand_seed", "\n", "", "elif", "'\"pytorch_seed\"'", "in", "line", ":", "\n", "                    ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", ":", "\n", "                        ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "rand_seed", "=", "int", "(", "line", "[", "line", ".", "index", "(", "':'", ")", "+", "1", ":", "line", ".", "rfind", "(", "line_end", ")", "]", ".", "strip", "(", ")", ")", "\n", "rand_seeds", "[", "2", "]", "=", "rand_seed", "\n", "", "", "", "if", "not", "(", "rand_seeds", "[", "0", "]", "is", "None", "and", "rand_seeds", "[", "1", "]", "is", "None", "and", "rand_seeds", "[", "2", "]", "is", "None", ")", ":", "\n", "            ", "with", "open", "(", "s_dir", "+", "\"random_seeds.txt\"", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "if", "rand_seeds", "[", "0", "]", "is", "not", "None", ":", "\n", "                    ", "f", ".", "write", "(", "\"random_seed: \"", "+", "str", "(", "rand_seeds", "[", "0", "]", ")", "+", "\"\\n\"", ")", "\n", "", "if", "rand_seeds", "[", "1", "]", "is", "not", "None", ":", "\n", "                    ", "f", ".", "write", "(", "\"numpy_seed: \"", "+", "str", "(", "rand_seeds", "[", "1", "]", ")", "+", "\"\\n\"", ")", "\n", "", "if", "rand_seeds", "[", "2", "]", "is", "not", "None", ":", "\n", "                    ", "f", ".", "write", "(", "\"pytorch_seed: \"", "+", "str", "(", "rand_seeds", "[", "2", "]", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "", "loaded_params", "=", "Params", ".", "from_file", "(", "training_config_filename", ",", "\"\"", ")", "\n", "loaded_params", ".", "to_file", "(", "os", ".", "path", ".", "join", "(", "s_dir", ",", "s_dir", "+", "\"config.json\"", ")", ")", "\n", "\n", "cur_optim_params", "=", "loaded_params", ".", "get", "(", "\"trainer\"", ")", ".", "get", "(", "\"optimizer\"", ")", "\n", "if", "not", "training_config_changed", ":", "\n", "        ", "prev_optim_params", "=", "cur_optim_params", "\n", "", "else", ":", "\n", "# \"new_config_name\" sounds like a mistake, but it's \"new\" because it's the new name for the old file", "\n", "        ", "prev_params", "=", "Params", ".", "from_file", "(", "new_config_name", ",", "\"\"", ")", "\n", "prev_optim_params", "=", "prev_params", ".", "get", "(", "\"trainer\"", ")", ".", "get", "(", "\"optimizer\"", ")", "\n", "\n", "", "model", "=", "modified_model_load", "(", "loaded_params", ",", "s_dir", ",", "cuda_device", "=", "cuda_device", ")", "\n", "return", "model", ",", "loaded_params", ",", "prev_optim_params", ",", "cur_optim_params", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.modified_train_model": [[331, 492], ["train_model.load_model_from_serialization_dir", "allennlp.common.util.prepare_environment", "allennlp.common.util.prepare_global_logging", "params.params.get().get", "isinstance", "allennlp_internal_functions.datasets_from_params", "set", "logger.info", "allennlp.data.Vocabulary.from_params", "params.pop", "allennlp.data.iterators.data_iterator.DataIterator.from_params", "DataIterator.from_params.index_with", "params.pop", "allennlp_internal_functions.datasets_from_params.get", "allennlp_internal_functions.datasets_from_params.get", "params.pop", "params.pop.pop", "model.named_parameters", "allennlp.training.trainer.Trainer.from_params", "params.pop_bool", "params.assert_empty", "allennlp.models.archival.archive_model", "logger.info", "os.path.join", "torch.load", "best_model.load_state_dict", "allennlp_internal_functions.dump_metrics", "allennlp.common.checks.check_for_gpu", "params.pop", "params.pop", "params.pop", "allennlp.data.iterators.data_iterator.DataIterator.from_params", "DataIterator.from_params.index_with", "any", "Trainer.from_params.train", "logger.info", "allennlp.commands.evaluate.evaluate", "allennlp.commands.evaluate.evaluate.items", "os.path.join", "params.params.get", "allennlp.common.checks.check_for_gpu", "allennlp.common.checks.ConfigurationError", "parameter.requires_grad_", "cur_optimizer_params.as_flat_dict().keys", "prev_optimizer_params.as_flat_dict().keys", "os.path.exists", "logger.info", "allennlp_internal_functions.datasets_from_params.items", "re.search", "model.named_parameters", "param_dict.keys", "os.path.join", "logging.info", "allennlp.models.archival.archive_model", "cur_optimizer_params.as_flat_dict", "prev_optimizer_params.as_flat_dict", "keys_to_del.append", "keys_already_in_dict.append", "cur_optimizer_params.get"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.load_model_from_serialization_dir", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.datasets_from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.dump_metrics", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.plain_model_test.evaluate"], ["", "def", "modified_train_model", "(", "serialization_dir", ",", "\n", "training_config_filename", ",", "\n", "cuda_device", "=", "-", "1", ",", "\n", "file_friendly_logging", ":", "bool", "=", "False", ")", "->", "Model", ":", "\n", "    ", "\"\"\"\n        Function not currently in use. This is from back when I was trying to keep each successive\n        addition to the model's training in the same serialization directory.\n\n    Trains the model specified in the given :class:`Params` object, using the data and training\n    parameters also specified in that object, and saves the results in ``serialization_dir``.\n    Parameters\n    ----------\n    serialization_dir : ``str``\n        The directory in which to save results and logs.\n    file_friendly_logging : ``bool``, optional (default=False)\n        If ``True``, we add newlines to tqdm output, even on an interactive terminal, and we slow\n        down tqdm's output to only once every 10 seconds.\n    recover : ``bool``, optional (default=False)\n        If ``True``, we will try to recover a training run from an existing serialization\n        directory.  This is only intended for use when something actually crashed during the middle\n        of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n    Returns\n    -------\n    best_model: ``Model``\n        The model with the best epoch weights.\n    \"\"\"", "\n", "model", ",", "params", ",", "prev_optimizer_params", ",", "cur_optimizer_params", "=", "load_model_from_serialization_dir", "(", "serialization_dir", ",", "training_config_filename", ",", "cuda_device", "=", "cuda_device", ")", "\n", "prepare_environment", "(", "params", ")", "\n", "\n", "prepare_global_logging", "(", "serialization_dir", ",", "file_friendly_logging", ")", "\n", "\n", "cuda_device", "=", "params", ".", "params", ".", "get", "(", "'trainer'", ")", ".", "get", "(", "'cuda_device'", ",", "-", "1", ")", "\n", "if", "isinstance", "(", "cuda_device", ",", "list", ")", ":", "\n", "        ", "for", "device", "in", "cuda_device", ":", "\n", "            ", "check_for_gpu", "(", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "check_for_gpu", "(", "cuda_device", ")", "\n", "\n", "", "all_datasets", "=", "datasets_from_params", "(", "params", ")", "\n", "datasets_for_vocab_creation", "=", "set", "(", "params", ".", "pop", "(", "\"datasets_for_vocab_creation\"", ",", "all_datasets", ")", ")", "\n", "\n", "for", "dataset", "in", "datasets_for_vocab_creation", ":", "\n", "        ", "if", "dataset", "not", "in", "all_datasets", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"invalid 'dataset_for_vocab_creation' {dataset}\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"From dataset instances, %s will be considered for vocabulary creation.\"", ",", "\n", "\", \"", ".", "join", "(", "datasets_for_vocab_creation", ")", ")", "\n", "vocab", "=", "Vocabulary", ".", "from_params", "(", "\n", "params", ".", "pop", "(", "\"vocabulary\"", ",", "{", "}", ")", ",", "\n", "(", "instance", "for", "key", ",", "dataset", "in", "all_datasets", ".", "items", "(", ")", "\n", "for", "instance", "in", "dataset", "\n", "if", "key", "in", "datasets_for_vocab_creation", ")", "\n", ")", "\n", "\n", "params", ".", "pop", "(", "'model'", ")", "\n", "\n", "iterator", "=", "DataIterator", ".", "from_params", "(", "params", ".", "pop", "(", "\"iterator\"", ")", ")", "\n", "iterator", ".", "index_with", "(", "vocab", ")", "\n", "validation_iterator_params", "=", "params", ".", "pop", "(", "\"validation_iterator\"", ",", "None", ")", "\n", "if", "validation_iterator_params", ":", "\n", "        ", "validation_iterator", "=", "DataIterator", ".", "from_params", "(", "validation_iterator_params", ")", "\n", "validation_iterator", ".", "index_with", "(", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "validation_iterator", "=", "None", "\n", "\n", "", "train_data", "=", "all_datasets", "[", "'train'", "]", "\n", "validation_data", "=", "all_datasets", ".", "get", "(", "'validation'", ")", "\n", "test_data", "=", "all_datasets", ".", "get", "(", "'test'", ")", "\n", "\n", "trainer_params", "=", "params", ".", "pop", "(", "\"trainer\"", ")", "\n", "no_grad_regexes", "=", "trainer_params", ".", "pop", "(", "\"no_grad\"", ",", "(", ")", ")", "\n", "for", "name", ",", "parameter", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "any", "(", "re", ".", "search", "(", "regex", ",", "name", ")", "for", "regex", "in", "no_grad_regexes", ")", ":", "\n", "            ", "parameter", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "", "", "list_of_cur_optimizer_param_keys", "=", "[", "key", "for", "key", "in", "cur_optimizer_params", ".", "as_flat_dict", "(", ")", ".", "keys", "(", ")", "]", "\n", "list_of_prev_optimizer_param_keys", "=", "[", "key", "for", "key", "in", "prev_optimizer_params", ".", "as_flat_dict", "(", ")", ".", "keys", "(", ")", "]", "\n", "optimizer_params_match", "=", "True", "\n", "for", "key", "in", "list_of_cur_optimizer_param_keys", ":", "\n", "        ", "if", "key", "not", "in", "list_of_prev_optimizer_param_keys", ":", "\n", "            ", "optimizer_params_match", "=", "False", "\n", "break", "\n", "", "", "for", "key", "in", "list_of_prev_optimizer_param_keys", ":", "\n", "        ", "if", "key", "not", "in", "list_of_cur_optimizer_param_keys", ":", "\n", "            ", "optimizer_params_match", "=", "False", "\n", "break", "\n", "", "", "if", "not", "optimizer_params_match", ":", "\n", "# a list of each p is what will be passed to the optimizer constructor while constructing Trainer--", "\n", "# adjust if necessary (i.e., if we changed optimizers)", "\n", "        ", "model_params", "=", "[", "[", "n", ",", "p", "]", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "assert", "\"parameter_groups\"", "not", "in", "list_of_cur_optimizer_param_keys", ",", "\"Current way of dealing with optimizer change doesn't take parameter groups into account\"", "\n", "assert", "\"parameter_groups\"", "not", "in", "list_of_prev_optimizer_param_keys", ",", "\"Current way of dealing with optimizer change doesn't take parameter groups into account\"", "\n", "for", "param_tup", "in", "model_params", ":", "\n", "# modify the second element of param_tup in-place (it's a dict) to match the keys specified in", "\n", "# cur_optimizer_params", "\n", "            ", "param_dict", "=", "param_tup", "[", "1", "]", "\n", "keys_to_del", "=", "[", "]", "\n", "keys_already_in_dict", "=", "[", "]", "\n", "try", ":", "\n", "                ", "for", "key", "in", "param_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "not", "key", "in", "list_of_cur_optimizer_param_keys", ":", "\n", "                        ", "keys_to_del", ".", "append", "(", "key", ")", "\n", "", "else", ":", "\n", "                        ", "keys_already_in_dict", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "keys_to_del", ":", "\n", "                    ", "del", "param_dict", "[", "key", "]", "\n", "", "for", "key_to_have", "in", "list_of_cur_optimizer_param_keys", ":", "\n", "                    ", "if", "key_to_have", "!=", "\"type\"", "and", "key_to_have", "not", "in", "keys_already_in_dict", ":", "\n", "                        ", "param_dict", "[", "key_to_have", "]", "=", "cur_optimizer_params", ".", "get", "(", "key_to_have", ")", "\n", "", "", "", "except", ":", "\n", "                ", "pass", "\n", "\n", "", "", "", "trainer", "=", "Trainer", ".", "from_params", "(", "model", "=", "model", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "iterator", "=", "iterator", ",", "\n", "train_data", "=", "train_data", ",", "\n", "validation_data", "=", "validation_data", ",", "\n", "params", "=", "trainer_params", ",", "\n", "validation_iterator", "=", "validation_iterator", ")", "\n", "\n", "evaluate_on_test", "=", "params", ".", "pop_bool", "(", "\"evaluate_on_test\"", ",", "False", ")", "\n", "params", ".", "assert_empty", "(", "'base train command'", ")", "\n", "\n", "try", ":", "\n", "        ", "metrics", "=", "trainer", ".", "train", "(", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "# if we have completed an epoch, try to create a model archive.", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "_DEFAULT_WEIGHTS", ")", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\"Training interrupted by the user. Attempting to create \"", "\n", "\"a model archive using the current best epoch weights.\"", ")", "\n", "archive_model", "(", "serialization_dir", ",", "files_to_archive", "=", "params", ".", "files_to_archive", ")", "\n", "", "raise", "\n", "\n", "# Now tar up results", "\n", "", "archive_model", "(", "serialization_dir", ",", "files_to_archive", "=", "params", ".", "files_to_archive", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loading the best epoch weights.\"", ")", "\n", "best_model_state_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "'best.th'", ")", "\n", "best_model_state", "=", "torch", ".", "load", "(", "best_model_state_path", ")", "\n", "best_model", "=", "model", "\n", "best_model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "\n", "if", "test_data", "and", "evaluate_on_test", ":", "\n", "        ", "logger", ".", "info", "(", "\"The model will be evaluated using the best epoch weights.\"", ")", "\n", "test_metrics", "=", "evaluate", "(", "\n", "best_model", ",", "test_data", ",", "validation_iterator", "or", "iterator", ",", "\n", "cuda_device", "=", "trainer", ".", "_cuda_devices", "[", "0", "]", "# pylint: disable=protected-access", "\n", ")", "\n", "for", "key", ",", "value", "in", "test_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"test_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "", "elif", "test_data", ":", "\n", "        ", "logger", ".", "info", "(", "\"To evaluate on the test set after training, pass the \"", "\n", "\"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\"", ")", "\n", "\n", "", "dump_metrics", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"metrics.json\"", ")", ",", "metrics", ",", "log", "=", "True", ")", "\n", "\n", "return", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.get_config_filenames_matching": [[494, 498], ["list", "glob.glob", "len", "str"], "function", ["None"], ["", "def", "get_config_filenames_matching", "(", "expression", ")", ":", "\n", "    ", "matching_filenames", "=", "list", "(", "glob", "(", "expression", ")", ")", "\n", "assert", "len", "(", "matching_filenames", ")", ">", "0", ",", "\"No matching config files found for \"", "+", "str", "(", "expression", ")", "\n", "return", "matching_filenames", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.modify_param": [[500, 507], ["param_set_to_modify.pop", "isinstance", "val.as_dict.as_dict"], "function", ["None"], ["", "def", "modify_param", "(", "param_set_to_modify", ",", "name_of_param", ",", "val", ")", ":", "\n", "    ", "if", "val", "is", "None", ":", "\n", "        ", "param_set_to_modify", ".", "pop", "(", "name_of_param", ",", "None", ")", "\n", "", "else", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "Params", ")", ":", "\n", "            ", "val", "=", "val", ".", "as_dict", "(", ")", "\n", "", "param_set_to_modify", ".", "params", "[", "name_of_param", "]", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.train_seq_models_reuse_iterator": [[509, 604], ["os.path.isfile", "allennlp_internal_functions.datasets_from_params", "set", "allennlp.data.Vocabulary.from_params", "allennlp.data.iterators.data_iterator.DataIterator.from_params", "DataIterator.from_params.index_with", "Params.from_file.pop", "print", "allennlp.common.Params.from_file", "allennlp.common.Params.from_file", "allennlp.common.Params.from_file", "allennlp.common.Params.from_file", "Params.from_file.pop", "Params.from_file.pop", "Params.from_file.pop", "allennlp.data.iterators.data_iterator.DataIterator.from_params", "DataIterator.from_params.index_with", "train_model.get_config_filenames_matching", "train_model.edit_config_file_to_have_gpu", "base_filename.rfind", "train_model.get_config_filenames_matching", "Params.from_file.pop", "allennlp.common.Params.from_file", "print", "base_filename.rfind", "allennlp_internal_functions.datasets_from_params.items", "print", "train_model.train_model_given_params_and_iterators", "train_model.modify_param", "print", "len", "len", "print", "print", "cur_config_filename.rfind"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.datasets_from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.get_config_filenames_matching", "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.edit_config_file_to_have_gpu", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.get_config_filenames_matching", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.train_model_given_params_and_iterators", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.modify_param"], ["", "", "def", "train_seq_models_reuse_iterator", "(", "base_filename", ",", "output_dir_base", ",", "gpu", ")", ":", "\n", "    ", "processed_filenames", "=", "{", "}", "\n", "base_filename_prefix", "=", "base_filename", "[", ":", "base_filename", ".", "rfind", "(", "'.'", ")", "]", "\n", "filename_expression", "=", "base_filename_prefix", "+", "'*'", "+", "base_filename", "[", "base_filename", ".", "rfind", "(", "'.'", ")", ":", "]", "\n", "if", "os", ".", "path", ".", "isfile", "(", "base_filename", ")", ":", "\n", "        ", "params_to_pull_iterator_from", "=", "Params", ".", "from_file", "(", "base_filename", ",", "\"\"", ")", "\n", "params_for_copying", "=", "Params", ".", "from_file", "(", "base_filename", ",", "\"\"", ")", "\n", "", "else", ":", "\n", "        ", "filename_to_pull", "=", "get_config_filenames_matching", "(", "filename_expression", ")", "[", "0", "]", "\n", "params_to_pull_iterator_from", "=", "Params", ".", "from_file", "(", "filename_to_pull", ",", "\"\"", ")", "\n", "params_for_copying", "=", "Params", ".", "from_file", "(", "filename_to_pull", ",", "\"\"", ")", "\n", "\n", "", "all_datasets", "=", "datasets_from_params", "(", "params_to_pull_iterator_from", ")", "\n", "datasets_for_vocab_creation", "=", "set", "(", "params_to_pull_iterator_from", ".", "pop", "(", "\"datasets_for_vocab_creation\"", ",", "all_datasets", ")", ")", "\n", "\n", "vocab", "=", "Vocabulary", ".", "from_params", "(", "\n", "params_to_pull_iterator_from", ".", "pop", "(", "\"vocabulary\"", ",", "{", "}", ")", ",", "\n", "(", "instance", "for", "key", ",", "dataset", "in", "all_datasets", ".", "items", "(", ")", "\n", "for", "instance", "in", "dataset", "\n", "if", "key", "in", "datasets_for_vocab_creation", ")", "\n", ")", "\n", "\n", "iterator", "=", "DataIterator", ".", "from_params", "(", "params_to_pull_iterator_from", ".", "pop", "(", "\"iterator\"", ")", ")", "\n", "iterator", ".", "index_with", "(", "vocab", ")", "\n", "validation_iterator_params", "=", "params_to_pull_iterator_from", ".", "pop", "(", "\"validation_iterator\"", ",", "None", ")", "\n", "if", "validation_iterator_params", ":", "\n", "        ", "validation_iterator", "=", "DataIterator", ".", "from_params", "(", "validation_iterator_params", ")", "\n", "validation_iterator", ".", "index_with", "(", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "validation_iterator", "=", "None", "\n", "\n", "", "params_to_copy", "=", "[", "\n", "\"validation_iterator\"", ",", "\n", "\"vocabulary\"", ",", "\n", "\"iterator\"", ",", "\n", "\"dataset_reader\"", ",", "\n", "\"datasets_for_vocab_creation\"", ",", "\n", "\"train_data_path\"", ",", "\n", "\"validation_data_path\"", "\n", "]", "\n", "copied_param_vals", "=", "[", "(", "param_name", ",", "params_for_copying", ".", "pop", "(", "param_name", ",", "None", ")", ")", "for", "param_name", "in", "params_to_copy", "]", "\n", "\n", "while", "True", ":", "\n", "        ", "config_filenames", "=", "get_config_filenames_matching", "(", "filename_expression", ")", "\n", "cur_config_filename", "=", "None", "\n", "for", "config_filename", "in", "config_filenames", ":", "\n", "            ", "if", "not", "config_filename", "in", "processed_filenames", ":", "\n", "                ", "processed_filenames", "[", "config_filename", "]", "=", "0", "\n", "cur_config_filename", "=", "config_filename", "\n", "break", "\n", "\n", "", "", "if", "cur_config_filename", "is", "None", ":", "\n", "            ", "break", "\n", "\n", "", "edit_config_file_to_have_gpu", "(", "cur_config_filename", ",", "gpu", ")", "\n", "\n", "progressing_ok", "=", "True", "\n", "try", ":", "\n", "            ", "params", "=", "Params", ".", "from_file", "(", "cur_config_filename", ",", "\"\"", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"Could not properly read params from \"", "+", "cur_config_filename", "+", "\"; skipping.\"", ")", "\n", "progressing_ok", "=", "False", "\n", "\n", "", "if", "progressing_ok", ":", "\n", "            ", "try", ":", "\n", "                ", "for", "param_tup", "in", "copied_param_vals", ":", "\n", "                    ", "modify_param", "(", "params", ",", "param_tup", "[", "0", "]", ",", "param_tup", "[", "1", "]", ")", "\n", "", "", "except", ":", "\n", "                ", "print", "(", "\"Something went wrong while modifying params in \"", "+", "cur_config_filename", ")", "\n", "progressing_ok", "=", "False", "\n", "\n", "", "", "if", "progressing_ok", ":", "\n", "            ", "print", "(", "\"Starting to train model from \"", "+", "cur_config_filename", ")", "\n", "\n", "", "if", "progressing_ok", ":", "\n", "            ", "try", ":", "\n", "                ", "cur_config_filename", "=", "cur_config_filename", "[", ":", "cur_config_filename", ".", "rfind", "(", "'.'", ")", "]", "\n", "last_letters_to_take", "=", "len", "(", "cur_config_filename", ")", "-", "len", "(", "base_filename_prefix", ")", "\n", "if", "last_letters_to_take", ">", "0", ":", "\n", "                    ", "tag_to_append_to_dir", "=", "cur_config_filename", "[", "(", "-", "1", "*", "last_letters_to_take", ")", ":", "]", "\n", "", "else", ":", "\n", "                    ", "tag_to_append_to_dir", "=", "''", "\n", "", "serialization_dir", "=", "output_dir_base", "+", "tag_to_append_to_dir", "\n", "", "except", ":", "\n", "                ", "progressing_ok", "=", "False", "\n", "print", "(", "\"Could not properly assemble a serialization directory\"", ")", "\n", "\n", "", "", "if", "progressing_ok", ":", "\n", "            ", "try", ":", "\n", "                ", "train_model_given_params_and_iterators", "(", "params", ",", "serialization_dir", ",", "iterator", ",", "\n", "validation_iterator", ",", "vocab", ",", "all_datasets", ",", "params_to_copy", ")", "\n", "", "except", ":", "\n", "                ", "progressing_ok", "=", "False", "\n", "print", "(", "\"Training model failed for some reason; skipping to next model.\"", ")", "\n", "", "", "", "print", "(", "\"Done processing all config files.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.train_model_given_params_and_iterators": [[655, 752], ["allennlp.common.util.prepare_environment", "allennlp.commands.train.create_serialization_dir", "allennlp.common.util.prepare_global_logging", "params.params.get().get", "allennlp.common.checks.check_for_gpu", "params.to_file", "params.pop_bool", "params.get().get", "train_model.TrainerPieces.from_params", "allennlp.training.trainer.Trainer.from_params", "params.assert_empty", "allennlp.models.archival.archive_model", "allennlp_internal_functions.dump_metrics", "os.path.join", "params.pop", "str", "Trainer.from_params.train", "logger.info", "allennlp.commands.evaluate.evaluate", "allennlp.commands.evaluate.evaluate.items", "allennlp_internal_functions.cleanup_global_logging", "os.path.join", "params.params.get", "params.get", "os.path.exists", "logger.info", "os.path.join", "logging.info", "allennlp.models.archival.archive_model"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.dump_metrics", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.plain_model_test.evaluate", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.cleanup_global_logging"], ["", "", "def", "train_model_given_params_and_iterators", "(", "params", ",", "serialization_dir", ",", "iterator", ",", "validation_iterator", ",", "vocab", ",", "\n", "all_datasets", ",", "copied_but_unused_params", ",", "\n", "file_friendly_logging", ":", "bool", "=", "False", ",", "\n", "recover", ":", "bool", "=", "False", ",", "\n", "force", ":", "bool", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n        Trains the model specified in the given :class:`Params` object, using the data and training\n        parameters also specified in that object, and saves the results in ``serialization_dir``.\n        Parameters\n        ----------\n        params : ``Params``\n            A parameter object specifying an AllenNLP Experiment.\n        serialization_dir : ``str``\n            The directory in which to save results and logs.\n        file_friendly_logging : ``bool``, optional (default=False)\n            If ``True``, we add newlines to tqdm output, even on an interactive terminal, and we slow\n            down tqdm's output to only once every 10 seconds.\n        recover : ``bool``, optional (default=False)\n            If ``True``, we will try to recover a training run from an existing serialization\n            directory.  This is only intended for use when something actually crashed during the middle\n            of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n        force : ``bool``, optional (default=False)\n            If ``True``, we will overwrite the serialization directory if it already exists.\n        Returns\n        -------\n        best_model: ``Model``\n            The model with the best epoch weights.\n        \"\"\"", "\n", "prepare_environment", "(", "params", ")", "\n", "create_serialization_dir", "(", "params", ",", "serialization_dir", ",", "recover", ",", "force", ")", "\n", "stdout_handler", "=", "prepare_global_logging", "(", "serialization_dir", ",", "file_friendly_logging", ")", "\n", "\n", "cuda_device", "=", "params", ".", "params", ".", "get", "(", "'trainer'", ")", ".", "get", "(", "'cuda_device'", ",", "-", "1", ")", "\n", "check_for_gpu", "(", "cuda_device", ")", "\n", "\n", "params", ".", "to_file", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", ")", "\n", "\n", "for", "param_name", "in", "copied_but_unused_params", ":", "\n", "        ", "params", ".", "pop", "(", "param_name", ",", "None", ")", "\n", "\n", "", "evaluate_on_test", "=", "params", ".", "pop_bool", "(", "\"evaluate_on_test\"", ",", "False", ")", "\n", "\n", "trainer_type", "=", "params", ".", "get", "(", "\"trainer\"", ",", "{", "}", ")", ".", "get", "(", "\"type\"", ",", "\"default\"", ")", "\n", "\n", "assert", "trainer_type", "==", "\"default\"", ",", "\"Trainer type is given as \"", "+", "str", "(", "trainer_type", ")", "\n", "# Special logic to instantiate backward-compatible trainer.", "\n", "\n", "pieces", "=", "TrainerPieces", ".", "from_params", "(", "params", ",", "iterator", ",", "validation_iterator", ",", "vocab", ",", "all_datasets", ",", "\n", "serialization_dir", ",", "recover", ")", "# pylint: disable=no-member", "\n", "trainer", "=", "Trainer", ".", "from_params", "(", "\n", "model", "=", "pieces", ".", "model", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "iterator", "=", "pieces", ".", "iterator", ",", "\n", "train_data", "=", "pieces", ".", "train_dataset", ",", "\n", "validation_data", "=", "pieces", ".", "validation_dataset", ",", "\n", "params", "=", "pieces", ".", "params", ",", "\n", "validation_iterator", "=", "pieces", ".", "validation_iterator", ")", "\n", "evaluation_iterator", "=", "pieces", ".", "validation_iterator", "or", "pieces", ".", "iterator", "\n", "evaluation_dataset", "=", "pieces", ".", "test_dataset", "\n", "\n", "params", ".", "assert_empty", "(", "'base train command'", ")", "\n", "\n", "try", ":", "\n", "        ", "metrics", "=", "trainer", ".", "train", "(", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "# if we have completed an epoch, try to create a model archive.", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "_DEFAULT_WEIGHTS", ")", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\"Training interrupted by the user. Attempting to create \"", "\n", "\"a model archive using the current best epoch weights.\"", ")", "\n", "archive_model", "(", "serialization_dir", ",", "files_to_archive", "=", "params", ".", "files_to_archive", ")", "\n", "", "raise", "\n", "\n", "# Evaluate", "\n", "", "if", "evaluation_dataset", "and", "evaluate_on_test", ":", "\n", "        ", "logger", ".", "info", "(", "\"The model will be evaluated using the best epoch weights.\"", ")", "\n", "test_metrics", "=", "evaluate", "(", "trainer", ".", "model", ",", "evaluation_dataset", ",", "evaluation_iterator", ",", "\n", "cuda_device", "=", "trainer", ".", "_cuda_devices", "[", "0", "]", ",", "# pylint: disable=protected-access,", "\n", "# TODO(brendanr): Pass in an arg following Joel's trainer refactor.", "\n", "batch_weight_key", "=", "\"\"", ")", "\n", "\n", "for", "key", ",", "value", "in", "test_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"test_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "", "elif", "evaluation_dataset", ":", "\n", "        ", "logger", ".", "info", "(", "\"To evaluate on the test set after training, pass the \"", "\n", "\"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\"", ")", "\n", "\n", "", "if", "stdout_handler", "is", "not", "None", ":", "\n", "        ", "cleanup_global_logging", "(", "stdout_handler", ")", "\n", "\n", "# Now tar up results", "\n", "", "archive_model", "(", "serialization_dir", ",", "files_to_archive", "=", "params", ".", "files_to_archive", ")", "\n", "dump_metrics", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"metrics.json\"", ")", ",", "metrics", ",", "log", "=", "True", ")", "\n", "\n", "# We count on the trainer to have the model with best weights", "\n", "return", "trainer", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.main": [[754, 831], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "allennlp.common.util.import_submodules", "allennlp.common.util.import_submodules", "train_model.edit_config_file_to_have_gpu", "parser.parse_args.train_multiple_models.lower().startswith", "parser.parse_args.output_dir_base.endswith", "os.path.isdir", "os.makedirs", "parser.parse_args.dir_with_config_files.endswith", "train_model.train_seq_models_reuse_iterator", "os.path.isdir", "parser.parse_args.train_multiple_models.lower", "print", "allennlp.commands.train.train_model_from_file", "print", "os.path.isdir", "output_dir.endswith", "os.path.isdir", "allennlp.common.Params.from_file", "train_model.load_prev_best_model", "train_model.train_model_but_load_prev_model_weights", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.edit_config_file_to_have_gpu", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.train_seq_models_reuse_iterator", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.load_prev_best_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.train_model_but_load_prev_model_weights"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The type of model to train\"", ",", "\n", "choices", "=", "[", "'hanrnn'", ",", "'hanconv'", ",", "'flanrnn'", ",", "'flanconv'", ",", "'han_encless'", ",", "'flan_encless'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset-name\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Which dataset to train the model on\"", ",", "\n", "choices", "=", "[", "'amazon'", ",", "'yahoo10cat'", ",", "'yelp'", ",", "'imdb'", ",", "'whateverDatasetYouHaveInMind'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpu\"", ",", "type", "=", "int", ",", "required", "=", "True", ",", "\n", "help", "=", "\"GPU to use (can supply -1 if not using GPU)\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--optional-model-tag\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Optional tag to append to end of model serialization dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-multiple-models\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "'False'", ",", "\n", "help", "=", "\"Whether to train multiple models on the same data, reusing the loaded iterator\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--crashed-last-time\"", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Whether we're resuming from a crashed run\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-existing-model\"", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Whether we're resuming from a preexisting model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--continue-on-same-config-file\"", ",", "type", "=", "bool", ",", "required", "=", "False", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Whether we're resuming from an interrupted run\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output-dir-base\"", ",", "required", "=", "False", ",", "\n", "default", "=", "base_serialized_models_dir", ",", "\n", "help", "=", "\"Which directory each individual model's serialization directory sits in\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dir-with-config-files\"", ",", "required", "=", "False", ",", "type", "=", "str", ",", "\n", "default", "=", "directory_with_config_files", ",", "\n", "help", "=", "\"Base directory for all config files\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "not", "args", ".", "output_dir_base", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "args", ".", "output_dir_base", "+=", "'/'", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "output_dir_base", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir_base", ")", "\n", "", "if", "not", "args", ".", "dir_with_config_files", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "args", ".", "dir_with_config_files", "+=", "'/'", "\n", "", "output_dir", "=", "args", ".", "output_dir_base", "+", "args", ".", "dataset_name", "+", "'-'", "+", "args", ".", "model", "\n", "if", "args", ".", "optional_model_tag", "!=", "''", ":", "\n", "        ", "output_dir", "+=", "'-'", "+", "args", ".", "optional_model_tag", "\n", "", "if", "not", "args", ".", "continue_on_same_config_file", "and", "not", "args", ".", "train_existing_model", ":", "\n", "        ", "assert", "not", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ",", "\"Output dir \"", "+", "str", "(", "output_dir", ")", "+", "\" must not already exist.\"", "\n", "\n", "# allows config file to reference the module nicknames registered directly above custom class declarations", "\n", "", "import_submodules", "(", "'attn_tests_lib'", ")", "\n", "import_submodules", "(", "'textcat'", ")", "\n", "\n", "config_file", "=", "args", ".", "dir_with_config_files", "+", "args", ".", "dataset_name", "+", "corresponding_config_files", "[", "args", ".", "model", "]", "\n", "edit_config_file_to_have_gpu", "(", "config_file", ",", "args", ".", "gpu", ")", "\n", "\n", "if", "args", ".", "train_multiple_models", ".", "lower", "(", ")", ".", "startswith", "(", "'t'", ")", ":", "\n", "        ", "train_seq_models_reuse_iterator", "(", "config_file", ",", "output_dir", ",", "args", ".", "gpu", ")", "\n", "", "elif", "args", ".", "continue_on_same_config_file", "or", "(", "not", "args", ".", "train_existing_model", ")", ":", "\n", "        ", "print", "(", "\"Starting to train model from \"", "+", "config_file", ")", "\n", "train_model_from_file", "(", "config_file", ",", "output_dir", ",", "recover", "=", "args", ".", "continue_on_same_config_file", ")", "\n", "", "else", ":", "# train existing model", "\n", "        ", "print", "(", "\"Starting to train model from \"", "+", "config_file", ")", "\n", "# figure out which output dir we should actually be using-- will have a number tacked on", "\n", "# to the end of it. figure out which one.", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", "\n", "if", "output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "output_dir", "=", "output_dir", "[", ":", "-", "1", "]", "\n", "\n", "", "original_output_dir", "=", "output_dir", "\n", "\n", "next_available_ind", "=", "2", "\n", "while", "os", ".", "path", ".", "isdir", "(", "original_output_dir", "+", "\"-\"", "+", "str", "(", "next_available_ind", ")", ")", ":", "\n", "            ", "next_available_ind", "+=", "1", "\n", "", "output_dir", "=", "original_output_dir", "+", "\"-\"", "+", "str", "(", "next_available_ind", ")", "+", "'/'", "\n", "\n", "output_dir_to_load_prev_best_model_from", "=", "original_output_dir", "\n", "if", "next_available_ind", ">", "2", ":", "\n", "            ", "output_dir_to_load_prev_best_model_from", "+=", "\"-\"", "+", "str", "(", "next_available_ind", "-", "1", ")", "+", "'/'", "\n", "\n", "# loaded onto cpu", "\n", "", "new_params", "=", "Params", ".", "from_file", "(", "config_file", ",", "\"\"", ")", "\n", "prev_best_model", "=", "load_prev_best_model", "(", "output_dir_to_load_prev_best_model_from", ")", "\n", "\n", "return", "train_model_but_load_prev_model_weights", "(", "new_params", ",", "output_dir", ",", "prev_best_model", ",", "False", ",", "False", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.OriginalOutputDistIterator.__init__": [[678, 693], ["open", "f.readline().strip", "f.readline().strip.split", "range", "len", "len", "f.readline", "field.startswith", "field.startswith"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "original_output_filename", ")", ":", "\n", "        ", "self", ".", "original_output_filename", "=", "original_output_filename", "\n", "self", ".", "starting_field_of_output_dist", "=", "None", "\n", "self", ".", "ending_field_plus_1_of_output_dist", "=", "None", "\n", "with", "open", "(", "original_output_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "first_line", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", "'\\n'", ")", "\n", "fields", "=", "first_line", ".", "split", "(", "','", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "fields", ")", ")", ":", "\n", "                ", "field", "=", "fields", "[", "i", "]", "\n", "if", "field", ".", "startswith", "(", "\"log_output_val_\"", ")", "and", "self", ".", "starting_field_of_output_dist", "is", "None", ":", "\n", "                    ", "self", ".", "starting_field_of_output_dist", "=", "i", "\n", "", "elif", "self", ".", "starting_field_of_output_dist", "is", "not", "None", "and", "not", "field", ".", "startswith", "(", "\"log_output_val_\"", ")", ":", "\n", "                    ", "self", ".", "ending_field_plus_1_of_output_dist", "=", "i", "\n", "", "", "if", "self", ".", "ending_field_plus_1_of_output_dist", "is", "None", ":", "\n", "                ", "self", ".", "ending_field_plus_1_of_output_dist", "=", "len", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.OriginalOutputDistIterator.__iter__": [[694, 706], ["open", "line.strip", "float", "numpy.array", "line.strip().split", "line.strip"], "methods", ["None"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "original_output_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "first_line", "=", "True", "\n", "for", "line", "in", "f", ":", "\n", "                ", "if", "first_line", ":", "\n", "                    ", "first_line", "=", "False", "\n", "", "elif", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "dist", "=", "[", "float", "(", "x", ")", "for", "x", "in", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "','", ")", "[", "self", ".", "starting_field_of_output_dist", ":", "\n", "self", ".", "ending_field_plus_1_of_output_dist", "]", "]", "\n", "yield", "np", ".", "array", "(", "dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.load_testing_models_in_eval_mode_from_serialization_dir": [[53, 73], ["allennlp.common.Params.from_file", "allennlp.models.model.Model.load", "getattr", "attn_tests_lib.TalkativeSimpleHanAttention", "setattr", "attn_tests_lib.ClassifierFromAttnAndInputVects", "model.cuda.eval", "just_the_classifier.cuda.eval", "model.cuda.cuda", "just_the_classifier.cuda.cuda"], "function", ["None"], ["def", "load_testing_models_in_eval_mode_from_serialization_dir", "(", "s_dir", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "\n", "total_num_test_instances", ",", "training_config_filename", ",", "\n", "name_of_attn_layer_to_replace", "=", "\"_sentence_attention\"", ",", "\n", "cuda_device", "=", "-", "1", ")", ":", "\n", "    ", "loaded_params", "=", "Params", ".", "from_file", "(", "training_config_filename", ",", "\"\"", ")", "\n", "model", "=", "Model", ".", "load", "(", "loaded_params", ",", "s_dir", ",", "cuda_device", "=", "cuda_device", ")", "\n", "\n", "original_attn_layer", "=", "getattr", "(", "model", ",", "name_of_attn_layer_to_replace", ")", "\n", "talkative_attn_layer", "=", "attn_tests_lib", ".", "TalkativeSimpleHanAttention", "(", "original_attn_layer", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "\n", "total_num_test_instances", ")", "\n", "setattr", "(", "model", ",", "name_of_attn_layer_to_replace", ",", "talkative_attn_layer", ")", "\n", "just_the_classifier", "=", "attn_tests_lib", ".", "ClassifierFromAttnAndInputVects", "(", "model", ".", "_output_logit", ")", "\n", "if", "cuda_device", ">=", "0", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", "device", "=", "cuda_device", ")", "\n", "just_the_classifier", "=", "just_the_classifier", ".", "cuda", "(", "device", "=", "cuda_device", ")", "\n", "", "model", "=", "model", ".", "eval", "(", ")", "\n", "just_the_classifier", "=", "just_the_classifier", ".", "eval", "(", ")", "\n", "return", "model", ",", "just_the_classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.set_up_inorder_test_loader": [[75, 119], ["print", "allennlp.common.Params.from_file", "Params.from_file.pop", "allennlp.data.dataset_readers.DatasetReader.from_params", "allennlp.data.iterators.BasicIterator.index_with", "open", "model_folder.endswith", "Params.from_file.pop", "allennlp.data.iterators.BasicIterator", "allennlp.data.iterators.BasicIterator", "allennlp.data.Vocabulary.from_files", "print", "allennlp.data.iterators.BasicIterator._create_batches", "print", "DatasetReader.from_params._read", "batch.index_instances", "tokens.size", "str", "line.strip", "batch.as_tensor_dict", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator._create_batches", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader._read"], ["", "def", "set_up_inorder_test_loader", "(", "data_file", ",", "batch_size", ",", "max_samples_per_batch", ",", "vocab_dir_name", ",", "model_folder", ",", "\n", "check_num_iterated", "=", "False", ",", "loading_han", "=", "True", ")", ":", "\n", "# make sure the number of test instances that the iterator will present is equal to the number of test", "\n", "# instances that we think we're iterating through", "\n", "# first, get that second number: how many test instances do we *think* we should be iterating through?", "\n", "    ", "print", "(", "\"Calculating the number of instances expected from the test set iterator...\"", ")", "\n", "num_instances_expected", "=", "-", "1", "# to account for first line", "\n", "with", "open", "(", "data_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "!=", "''", ":", "\n", "                ", "num_instances_expected", "+=", "1", "\n", "\n", "", "", "", "if", "not", "model_folder", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_folder", "+=", "'/'", "\n", "\n", "# now construct the iterator", "\n", "", "config", "=", "Params", ".", "from_file", "(", "model_folder", "+", "'config.json'", ")", "\n", "reader_params", "=", "config", ".", "pop", "(", "'validation_dataset_reader'", ",", "None", ")", "\n", "if", "reader_params", "is", "None", ":", "\n", "        ", "reader_params", "=", "config", ".", "pop", "(", "'dataset_reader'", ",", "None", ")", "\n", "", "dataset_reader", "=", "DatasetReader", ".", "from_params", "(", "reader_params", ")", "\n", "\n", "if", "loading_han", ":", "\n", "        ", "dataset_iterator", "=", "BasicIterator", "(", "batch_size", "=", "batch_size", ",", "\n", "maximum_samples_per_batch", "=", "(", "\"list_num_tokens\"", ",", "max_samples_per_batch", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset_iterator", "=", "BasicIterator", "(", "batch_size", "=", "batch_size", ",", "\n", "maximum_samples_per_batch", "=", "(", "\"num_tokens\"", ",", "max_samples_per_batch", ")", ")", "\n", "", "dataset_iterator", ".", "index_with", "(", "Vocabulary", ".", "from_files", "(", "vocab_dir_name", ")", ")", "\n", "\n", "# now iterate through and make sure the number of instances we pass matches what we expect", "\n", "if", "check_num_iterated", ":", "\n", "        ", "print", "(", "\"Checking how many instances the iterator actually goes through...\"", ")", "\n", "num_instances_found", "=", "0", "\n", "for", "batch", "in", "dataset_iterator", ".", "_create_batches", "(", "dataset_reader", ".", "_read", "(", "data_file", ")", ",", "shuffle", "=", "False", ")", ":", "\n", "            ", "batch", ".", "index_instances", "(", "dataset_iterator", ".", "vocab", ")", "\n", "tokens", "=", "batch", ".", "as_tensor_dict", "(", ")", "[", "'tokens'", "]", "[", "'tokens'", "]", "\n", "num_instances_found", "+=", "tokens", ".", "size", "(", "0", ")", "\n", "\n", "", "assert", "num_instances_expected", "==", "num_instances_found", ",", "(", "\"From file, expected \"", "+", "str", "(", "num_instances_expected", ")", "+", "\n", "\" test instances, but dataset iterator turned up \"", "+", "\n", "str", "(", "num_instances_found", ")", ")", "\n", "print", "(", "\"Found correct number of instances in test iterator.\"", ")", "\n", "", "return", "dataset_reader", ",", "dataset_iterator", ",", "num_instances_expected", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_gradients_wrt_attention": [[121, 140], ["differentiable_function_on_output", "differentiable_function_on_output.backward", "str", "gradient_reporting_classifier", "open", "pickle.load", "torch.autograd.Variable", "allennlp.nn.util.move_to_device", "util.move_to_device.size", "attention_weights.size", "str", "attention_weights.size"], "function", ["None"], ["", "def", "get_gradients_wrt_attention", "(", "attention_weights", ",", "corr_vects", ",", "gradient_reporting_classifier", ",", "\n", "differentiable_function_on_output", ",", "base_filename", ",", "starting_ind", ",", "gpu", ")", ":", "\n", "# make classifier collect gradients", "\n", "    ", "gradient_reporting_classifier", ".", "_temp_filename", "=", "base_filename", "+", "str", "(", "starting_ind", ")", "+", "'-'", "+", "str", "(", "starting_ind", "+", "attention_weights", ".", "size", "(", "0", ")", "-", "1", ")", "\n", "model_presoftmax_output", "=", "gradient_reporting_classifier", "(", "corr_vects", ",", "\n", "torch", ".", "autograd", ".", "Variable", "(", "attention_weights", ",", "\n", "requires_grad", "=", "True", ")", ")", "[", "'label_logits'", "]", "\n", "thing_to_differentiate", "=", "differentiable_function_on_output", "(", "model_presoftmax_output", ")", "\n", "thing_to_differentiate", ".", "backward", "(", ")", "\n", "\n", "# open gradtients file, process it", "\n", "with", "open", "(", "gradient_reporting_classifier", ".", "_temp_filename", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "corr_grad_for_attn", "=", "pickle", ".", "load", "(", "f", ")", "\n", "if", "gpu", "!=", "-", "1", ":", "\n", "            ", "corr_grad_for_attn", "=", "util", ".", "move_to_device", "(", "corr_grad_for_attn", ",", "gpu", ")", "\n", "", "assert", "corr_grad_for_attn", ".", "size", "(", ")", "==", "attention_weights", ".", "size", "(", ")", "\n", "\n", "", "return", "corr_grad_for_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.set_up_gradient_reporting_classifier": [[142, 148], ["attn_tests_lib.GradientReportingClassifierFromAttnAndInputVects", "reporting_classifier.train.train", "copy.deepcopy"], "function", ["None"], ["", "def", "set_up_gradient_reporting_classifier", "(", "vanilla_classifier", ")", ":", "\n", "    ", "reporting_classifier", "=", "attn_tests_lib", ".", "GradientReportingClassifierFromAttnAndInputVects", "(", "\n", "deepcopy", "(", "vanilla_classifier", ".", "_classification_module", ")", ")", "\n", "reporting_classifier", "=", "reporting_classifier", ".", "train", "(", ")", "\n", "return", "reporting_classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.exp_highest_val_over_sum_exp_all_vals": [[150, 155], ["torch.exp", "torch.sum", "torch.max"], "function", ["None"], ["", "def", "exp_highest_val_over_sum_exp_all_vals", "(", "output_logits", ")", ":", "\n", "    ", "output_logits", "=", "torch", ".", "exp", "(", "output_logits", ")", "\n", "max_vals", "=", "torch", ".", "max", "(", "output_logits", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "denoms", "=", "torch", ".", "sum", "(", "output_logits", ",", "dim", "=", "1", ")", "\n", "return", "(", "max_vals", "/", "denoms", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_gradient_and_gradmult_based_stats": [[157, 268], ["attn_tests_lib.IntermediateBatchIterator", "iter", "tqdm.tqdm", "os.path.isfile", "test_model.OriginalOutputDistIterator", "corr_vector_dir.endswith", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "test_model.set_up_gradient_reporting_classifier", "iter", "allennlp.nn.util.move_to_device", "range", "range", "print", "print", "test_model.write_grad_and_gradmult_stats_file", "test_model.write_gradsignmult_stats_file", "grad_getting_classifier.cuda.cuda", "attn_tests_lib.GradientsIterator", "int", "copy.deepcopy", "allennlp.nn.util.move_to_device", "allennlp.nn.util.move_to_device", "copy.deepcopy", "allennlp.nn.util.move_to_device", "test_model.get_gradients_wrt_attention", "next", "allennlp.nn.util.move_to_device", "test_model.handle_loop_body_for_grad_and_gradmult_stats", "test_model.handle_loop_body_for_gradsignmult_stats", "len", "len", "len", "len", "len", "len", "math.ceil", "torch.cat.size", "util.move_to_device.size", "torch.cat.size", "util.move_to_device.size", "torch.cat.size", "util.move_to_device.size", "torch.cat", "str", "str", "torch.cat.new_zeros", "util.move_to_device.size", "str", "str", "torch.cat.size", "str", "str", "util.move_to_device.size", "torch.cat.size"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.set_up_gradient_reporting_classifier", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_grad_and_gradmult_stats_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_gradsignmult_stats_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_gradients_wrt_attention", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.handle_loop_body_for_grad_and_gradmult_stats", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.handle_loop_body_for_gradsignmult_stats"], ["", "def", "get_gradient_and_gradmult_based_stats", "(", "classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "original_output_filename", ",", "grad_based_stats_filename", ",", "\n", "grads_have_already_been_collected", "=", "False", ",", "function_of_grad", "=", "'grad_and_gradmult'", ",", "\n", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "assert", "function_of_grad", "==", "'grad_and_gradmult'", "or", "function_of_grad", "==", "'gradsignmult'", "\n", "assert", "not", "os", ".", "path", ".", "isfile", "(", "grad_based_stats_filename", ")", "\n", "batch_iterator", "=", "IntermediateBatchIterator", "(", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ")", "\n", "next_available_ind", "=", "1", "\n", "lists_to_write_to_file", "=", "[", "]", "\n", "corr_output_yielder", "=", "iter", "(", "OriginalOutputDistIterator", "(", "original_output_filename", ")", ")", "\n", "if", "not", "corr_vector_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "corr_vector_dir", "+=", "'/'", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "corr_vector_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "corr_vector_dir", ")", "\n", "", "base_filename", "=", "corr_vector_dir", "+", "'gradients/'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "base_filename", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "base_filename", ")", "\n", "", "base_filename", "+=", "'gradient_wrt_attn_weights_'", "\n", "if", "not", "grads_have_already_been_collected", ":", "\n", "        ", "grad_getting_classifier", "=", "set_up_gradient_reporting_classifier", "(", "vanilla_classifier", "=", "classifier", ")", "\n", "if", "gpu", "!=", "-", "1", ":", "\n", "            ", "grad_getting_classifier", "=", "grad_getting_classifier", ".", "cuda", "(", "device", "=", "gpu", ")", "\n", "", "", "else", ":", "\n", "        ", "grads_iterator", "=", "iter", "(", "GradientsIterator", "(", "batch_size", ",", "base_filename", ",", "gpu", "=", "gpu", ")", ")", "\n", "", "total_num_dist_calcs", "=", "0", "\n", "min_calculated_kl", "=", "1000", "\n", "total_num_negative_kl_dist_calcs", "=", "0", "\n", "min_calculated_js", "=", "1000", "\n", "total_num_negative_js_dist_calcs", "=", "0", "\n", "for", "batch_tup", "in", "tqdm", "(", "batch_iterator", ",", "total", "=", "int", "(", "ceil", "(", "batch_iterator", ".", "num_instances", "/", "batch_iterator", ".", "batch_size", ")", ")", ",", "\n", "desc", "=", "\"Calculating \"", "+", "function_of_grad", "+", "\"-based decision flip stats\"", ")", ":", "\n", "        ", "list_of_lens", "=", "batch_tup", "[", "2", "]", "\n", "original_attn_weights", "=", "util", ".", "move_to_device", "(", "batch_tup", "[", "0", "]", ",", "gpu", ")", "\n", "if", "not", "grads_have_already_been_collected", ":", "\n", "            ", "original_attn_weights_for_backpropagating", "=", "deepcopy", "(", "original_attn_weights", ")", "\n", "original_attn_weights_for_backpropagating", "=", "util", ".", "move_to_device", "(", "original_attn_weights_for_backpropagating", ",", "\n", "gpu", ")", "\n", "corr_vects", "=", "util", ".", "move_to_device", "(", "batch_tup", "[", "1", "]", ",", "gpu", ")", "\n", "corr_vects_for_later", "=", "deepcopy", "(", "corr_vects", ")", "\n", "corr_vects_for_later", "=", "util", ".", "move_to_device", "(", "corr_vects_for_later", ",", "gpu", ")", "\n", "\n", "function_of_presoftmax_output", "=", "exp_highest_val_over_sum_exp_all_vals", "\n", "\n", "corr_grads_tensor", "=", "get_gradients_wrt_attention", "(", "original_attn_weights_for_backpropagating", ",", "corr_vects", ",", "\n", "grad_getting_classifier", ",", "function_of_presoftmax_output", ",", "\n", "base_filename", ",", "next_available_ind", ",", "gpu", ")", "\n", "", "else", ":", "\n", "            ", "corr_grads_tensor", "=", "next", "(", "grads_iterator", ")", "\n", "assert", "corr_grads_tensor", ".", "size", "(", "0", ")", "==", "original_attn_weights", ".", "size", "(", "0", ")", "\n", "if", "corr_grads_tensor", ".", "size", "(", "1", ")", "!=", "original_attn_weights", ".", "size", "(", "1", ")", ":", "\n", "# this could happen if we had to assemble corr_grads from different arrays due to diff batch size", "\n", "# when computing gradients", "\n", "                ", "if", "corr_grads_tensor", ".", "size", "(", "1", ")", "<", "original_attn_weights", ".", "size", "(", "1", ")", ":", "\n", "                    ", "corr_grads_tensor", "=", "corr_grads_tensor", "[", ":", ",", ":", "original_attn_weights", ".", "size", "(", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "corr_grads_tensor", "=", "torch", ".", "cat", "(", "[", "corr_grads_tensor", ",", "\n", "corr_grads_tensor", ".", "new_zeros", "(", "(", "corr_grads_tensor", ".", "size", "(", "0", ")", ",", "\n", "original_attn_weights", ".", "size", "(", "1", ")", "-", "corr_grads_tensor", ".", "size", "(", "1", ")", ")", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "", "", "corr_vects_for_later", "=", "util", ".", "move_to_device", "(", "batch_tup", "[", "1", "]", ",", "gpu", ")", "\n", "\n", "", "if", "function_of_grad", "==", "'grad_and_gradmult'", ":", "\n", "            ", "next_available_ind", ",", "neg_calculation_artifacts_info_tup_plaingrad", ",", "neg_calculation_artifacts_info_tup_gradmult", ",", "lists_to_write_to_file_additions", "=", "handle_loop_body_for_grad_and_gradmult_stats", "(", "corr_grads_tensor", ",", "original_attn_weights", ",", "list_of_lens", ",", "\n", "corr_output_yielder", ",", "next_available_ind", ",", "gpu", ",", "classifier", ",", "\n", "batch_tup", ",", "corr_vects_for_later", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "", "else", ":", "\n", "# not *really* calculation artifacts for plaingrad, but we name it that for compatibility", "\n", "            ", "next_available_ind", ",", "neg_calculation_artifacts_info_tup_plaingrad", ",", "lists_to_write_to_file_additions", "=", "handle_loop_body_for_gradsignmult_stats", "(", "corr_grads_tensor", ",", "original_attn_weights", ",", "list_of_lens", ",", "\n", "corr_output_yielder", ",", "next_available_ind", ",", "gpu", ",", "classifier", ",", "\n", "batch_tup", ",", "corr_vects_for_later", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "neg_calculation_artifacts_info_tup_gradmult", "=", "[", "]", "\n", "", "lists_to_write_to_file", "+=", "lists_to_write_to_file_additions", "\n", "\n", "total_num_dist_calcs", "+=", "(", "len", "(", "list_of_lens", ")", "*", "len", "(", "neg_calculation_artifacts_info_tup_plaingrad", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neg_calculation_artifacts_info_tup_plaingrad", ")", ")", ":", "\n", "            ", "local_tup", "=", "neg_calculation_artifacts_info_tup_plaingrad", "[", "i", "]", "\n", "if", "local_tup", "[", "0", "]", "<", "min_calculated_kl", ":", "\n", "                ", "min_calculated_kl", "=", "local_tup", "[", "0", "]", "\n", "", "total_num_negative_kl_dist_calcs", "+=", "local_tup", "[", "1", "]", "\n", "if", "local_tup", "[", "2", "]", "<", "min_calculated_js", ":", "\n", "                ", "min_calculated_js", "=", "local_tup", "[", "2", "]", "\n", "", "total_num_negative_js_dist_calcs", "+=", "local_tup", "[", "3", "]", "\n", "", "total_num_dist_calcs", "+=", "(", "len", "(", "list_of_lens", ")", "*", "len", "(", "neg_calculation_artifacts_info_tup_gradmult", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neg_calculation_artifacts_info_tup_gradmult", ")", ")", ":", "\n", "            ", "local_tup", "=", "neg_calculation_artifacts_info_tup_gradmult", "[", "i", "]", "\n", "if", "local_tup", "[", "0", "]", "<", "min_calculated_kl", ":", "\n", "                ", "min_calculated_kl", "=", "local_tup", "[", "0", "]", "\n", "", "total_num_negative_kl_dist_calcs", "+=", "local_tup", "[", "1", "]", "\n", "if", "local_tup", "[", "2", "]", "<", "min_calculated_js", ":", "\n", "                ", "min_calculated_js", "=", "local_tup", "[", "2", "]", "\n", "", "total_num_negative_js_dist_calcs", "+=", "local_tup", "[", "3", "]", "\n", "", "", "if", "total_num_dist_calcs", ">", "0", ":", "\n", "# at least one instance was iterated over", "\n", "        ", "print", "(", "str", "(", "total_num_negative_kl_dist_calcs", ")", "+", "' / '", "+", "str", "(", "total_num_dist_calcs", ")", "+", "\n", "' calculated KL divs while calculating grad-based stats were negative; '", "+", "\n", "'lowest calculated KL div was '", "+", "str", "(", "min_calculated_kl", ")", "+", "\n", "' (should be close to 0. see test_divergences() in debugging.py for sanity checks)'", ")", "\n", "print", "(", "str", "(", "total_num_negative_js_dist_calcs", ")", "+", "' / '", "+", "str", "(", "total_num_dist_calcs", ")", "+", "\n", "' calculated JS divs while calculating grad-based stats were negative; '", "+", "\n", "'lowest calculated JS div was '", "+", "str", "(", "min_calculated_js", ")", "+", "\n", "' (should be close to 0. see test_divergences() in debugging.py for sanity checks)'", ")", "\n", "\n", "", "if", "function_of_grad", "==", "'grad_and_gradmult'", ":", "\n", "        ", "write_grad_and_gradmult_stats_file", "(", "grad_based_stats_filename", ",", "lists_to_write_to_file", ")", "\n", "", "else", ":", "\n", "        ", "write_gradsignmult_stats_file", "(", "grad_based_stats_filename", ",", "lists_to_write_to_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_gradsignmult_stats_file": [[270, 285], ["print", "open", "f.write", "tqdm.tqdm", "f.write", "str"], "function", ["None"], ["", "", "def", "write_gradsignmult_stats_file", "(", "grad_based_stats_filename", ",", "lists_to_write_to_file", ")", ":", "\n", "    ", "with", "open", "(", "grad_based_stats_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'id,seq_len,needed_to_rem_x_topsignmult_items_for_decflip,'", "+", "\n", "'needed_to_rem_x_topsignmult_probmass_for_decflip,'", "+", "\n", "'needed_to_rem_frac_x_topsignmult_items_for_decflip,'", "+", "\n", "'gradsignmult_klhighest,gradsignmult_jshighest,gradsignmult_decfliphighest,gradsignmult_kl2ndhighest,'", "+", "\n", "'gradsignmult_js2ndhighest,gradsignmult_decflip2ndhighest\\n'", ")", "\n", "prev_id", "=", "-", "1", "\n", "for", "instance_list", "in", "tqdm", "(", "lists_to_write_to_file", ",", "desc", "=", "\"Writing dec flip stats file\"", ")", ":", "\n", "            ", "assert", "prev_id", "<", "instance_list", "[", "0", "]", "\n", "prev_id", "=", "instance_list", "[", "0", "]", "\n", "f", ".", "write", "(", "str", "(", "instance_list", "[", "0", "]", ")", "+", "','", "+", "instance_list", "[", "1", "]", "+", "','", "+", "instance_list", "[", "2", "]", "+", "','", "+", "instance_list", "[", "3", "]", "+", "\n", "','", "+", "instance_list", "[", "4", "]", "+", "','", "+", "instance_list", "[", "5", "]", "+", "','", "+", "instance_list", "[", "6", "]", "+", "','", "+", "\n", "instance_list", "[", "7", "]", "+", "','", "+", "instance_list", "[", "8", "]", "+", "','", "+", "instance_list", "[", "9", "]", "+", "','", "+", "instance_list", "[", "10", "]", "+", "'\\n'", ")", "\n", "", "", "print", "(", "\"Done writing gradsignmult-based decision-flip stats file.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.handle_loop_body_for_gradsignmult_stats": [[287, 338], ["range", "numpy.array", "numpy.array", "test_model.get_first_v_second_stats_for_batch", "test_model.get_inds_of_sorted_attnshaped_vals", "torch.from_numpy", "allennlp.nn.util.move_to_device", "torch.from_numpy", "allennlp.nn.util.move_to_device", "test_model.get_dec_flip_info_for_batch", "len", "range", "len", "np.array.append", "original_attn_weights.new_ones", "numpy.argmax", "numpy.arange", "len", "lists_to_write_to_file_additions.append", "next", "original_attn_weights.size", "zero_out_by.cpu().numpy", "int", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "int", "zero_out_by.cpu", "len"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_first_v_second_stats_for_batch", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_inds_of_sorted_attnshaped_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_info_for_batch"], ["", "def", "handle_loop_body_for_gradsignmult_stats", "(", "corr_grads_tensor", ",", "original_attn_weights", ",", "list_of_lens", ",", "\n", "corr_output_yielder", ",", "next_available_ind", ",", "gpu", ",", "classifier", ",", "\n", "batch_tup", ",", "corr_vects_for_later", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "lists_to_write_to_file_additions", "=", "[", "]", "\n", "list_of_original_log_np_arrays", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "        ", "list_of_original_log_np_arrays", ".", "append", "(", "next", "(", "corr_output_yielder", ")", ")", "\n", "", "list_of_original_log_np_arrays", "=", "np", ".", "array", "(", "list_of_original_log_np_arrays", ")", "\n", "original_dists", "=", "np", ".", "array", "(", "list_of_original_log_np_arrays", ")", "\n", "\n", "multipliers", "=", "original_attn_weights", ".", "new_ones", "(", "original_attn_weights", ".", "size", "(", ")", ")", "[", "corr_grads_tensor", "<", "0", "]", "=", "-", "1", "\n", "zero_out_by", "=", "original_attn_weights", "*", "multipliers", "\n", "\n", "_", ",", "list_of_batch_results_gradsignmult", ",", "neg_calculation_artifacts_info_tup_gradsignmult", "=", "get_first_v_second_stats_for_batch", "(", "next_available_ind", ",", "gpu", ",", "original_attn_weights", ",", "classifier", ",", "\n", "batch_tup", "[", "1", "]", ",", "batch_tup", "[", "2", "]", ",", "list_of_original_log_np_arrays", ",", "\n", "zero_out_by", "=", "zero_out_by", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "\n", "inds_in_dec_order", ",", "_", "=", "get_inds_of_sorted_attnshaped_vals", "(", "zero_out_by", ",", "list_of_lens", ")", "\n", "# remove highest-gradsignmult-value element first", "\n", "\n", "original_labels", "=", "torch", ".", "from_numpy", "(", "np", ".", "argmax", "(", "original_dists", ",", "axis", "=", "1", ")", ")", "\n", "original_labels", "=", "util", ".", "move_to_device", "(", "original_labels", ",", "gpu", ")", "\n", "\n", "corr_instance_inds", "=", "torch", ".", "from_numpy", "(", "np", ".", "arange", "(", "start", "=", "next_available_ind", ",", "\n", "stop", "=", "(", "next_available_ind", "+", "len", "(", "list_of_lens", ")", ")", ")", ")", "\n", "corr_instance_inds", "=", "util", ".", "move_to_device", "(", "corr_instance_inds", ",", "gpu", ")", "\n", "\n", "lists_to_write_from_top_gradsignmult", "=", "get_dec_flip_info_for_batch", "(", "inds_in_dec_order", ",", "corr_instance_inds", ",", "\n", "original_labels", ",", "corr_vects_for_later", ",", "\n", "original_attn_weights", ",", "classifier", ")", "\n", "next_available_ind", "+=", "len", "(", "list_of_lens", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "        ", "top_gradsignmult_list", "=", "lists_to_write_from_top_gradsignmult", "[", "i", "]", "\n", "top_singlestats_gradsignmult", "=", "list_of_batch_results_gradsignmult", "[", "i", "]", "\n", "assert", "top_gradsignmult_list", "[", "0", "]", "==", "int", "(", "top_singlestats_gradsignmult", "[", "0", "]", ")", ",", "str", "(", "top_gradsignmult_list", "[", "0", "]", ")", "+", "', '", "+", "str", "(", "int", "(", "top_singlestats_gradsignmult", "[", "0", "]", ")", ")", "\n", "instance_list", "=", "[", "top_gradsignmult_list", "[", "0", "]", ",", "\n", "str", "(", "list_of_lens", "[", "i", "]", ")", ",", "\n", "str", "(", "top_gradsignmult_list", "[", "2", "]", ")", ",", "\n", "str", "(", "top_gradsignmult_list", "[", "3", "]", ")", ",", "\n", "str", "(", "top_gradsignmult_list", "[", "4", "]", ")", ",", "\n", "str", "(", "top_singlestats_gradsignmult", "[", "1", "]", ")", ",", "# kl div highest", "\n", "str", "(", "top_singlestats_gradsignmult", "[", "2", "]", ")", ",", "# js div highest", "\n", "str", "(", "top_singlestats_gradsignmult", "[", "3", "]", ")", ",", "# decision flip highest", "\n", "str", "(", "top_singlestats_gradsignmult", "[", "4", "]", ")", ",", "# kl div 2nd highest", "\n", "str", "(", "top_singlestats_gradsignmult", "[", "5", "]", ")", ",", "# js div 2nd highest", "\n", "str", "(", "top_singlestats_gradsignmult", "[", "6", "]", ")", "]", "# decision flip 2nd highest", "\n", "lists_to_write_to_file_additions", ".", "append", "(", "instance_list", ")", "\n", "", "return", "next_available_ind", ",", "neg_calculation_artifacts_info_tup_gradsignmult", ",", "lists_to_write_to_file_additions", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_grad_and_gradmult_stats_file": [[340, 359], ["print", "open", "f.write", "tqdm.tqdm", "f.write", "str"], "function", ["None"], ["", "def", "write_grad_and_gradmult_stats_file", "(", "grad_based_stats_filename", ",", "lists_to_write_to_file", ")", ":", "\n", "    ", "with", "open", "(", "grad_based_stats_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'id,seq_len,needed_to_rem_x_top_items_for_decflip,needed_to_rem_x_top_probmass_for_decflip,'", "+", "\n", "'needed_to_rem_frac_x_top_items_for_decflip,needed_to_rem_x_top_multitems_for_decflip,'", "+", "\n", "'needed_to_rem_x_top_multprobmass_for_decflip,needed_to_rem_frac_x_top_multitems_for_decflip,'", "+", "\n", "'plaingrad_klhighest,plaingrad_jshighest,plaingrad_decfliphighest,plaingrad_kl2ndhighest,'", "+", "\n", "'plaingrad_js2ndhighest,plaingrad_decflip2ndhighest,gradmult_klhighest,gradmult_jshighest,'", "+", "\n", "'gradmult_decfliphighest,gradmult_kl2ndhighest,gradmult_js2ndhighest,gradmult_decflip2ndhighest\\n'", ")", "\n", "prev_id", "=", "-", "1", "\n", "for", "instance_list", "in", "tqdm", "(", "lists_to_write_to_file", ",", "desc", "=", "\"Writing dec flip stats file\"", ")", ":", "\n", "            ", "assert", "prev_id", "<", "instance_list", "[", "0", "]", "\n", "prev_id", "=", "instance_list", "[", "0", "]", "\n", "f", ".", "write", "(", "str", "(", "instance_list", "[", "0", "]", ")", "+", "','", "+", "instance_list", "[", "1", "]", "+", "','", "+", "instance_list", "[", "2", "]", "+", "','", "+", "instance_list", "[", "3", "]", "+", "\n", "','", "+", "instance_list", "[", "4", "]", "+", "','", "+", "instance_list", "[", "5", "]", "+", "','", "+", "instance_list", "[", "6", "]", "+", "','", "+", "\n", "instance_list", "[", "7", "]", "+", "','", "+", "instance_list", "[", "8", "]", "+", "','", "+", "instance_list", "[", "9", "]", "+", "','", "+", "instance_list", "[", "10", "]", "+", "\n", "','", "+", "instance_list", "[", "11", "]", "+", "','", "+", "instance_list", "[", "12", "]", "+", "','", "+", "instance_list", "[", "13", "]", "+", "\n", "','", "+", "instance_list", "[", "14", "]", "+", "','", "+", "instance_list", "[", "15", "]", "+", "','", "+", "instance_list", "[", "16", "]", "+", "\n", "','", "+", "instance_list", "[", "17", "]", "+", "','", "+", "instance_list", "[", "18", "]", "+", "','", "+", "instance_list", "[", "19", "]", "+", "'\\n'", ")", "\n", "", "", "print", "(", "\"Done writing gradient-based and gradmult-based decision-flip stats file.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.handle_loop_body_for_grad_and_gradmult_stats": [[361, 437], ["range", "numpy.array", "numpy.array", "test_model.get_first_v_second_stats_for_batch", "test_model.get_first_v_second_stats_for_batch", "test_model.get_inds_of_sorted_attnshaped_vals", "test_model.get_inds_of_sorted_attnshaped_vals", "torch.from_numpy", "allennlp.nn.util.move_to_device", "torch.from_numpy", "allennlp.nn.util.move_to_device", "test_model.get_dec_flip_info_for_batch", "test_model.get_dec_flip_info_for_batch", "len", "range", "len", "np.array.append", "numpy.argmax", "numpy.arange", "len", "lists_to_write_to_file_additions.append", "next", "corr_grads_tensor.cpu().numpy", "attn_times_grads.cpu().numpy", "int", "str", "int", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "corr_grads_tensor.cpu", "attn_times_grads.cpu", "len"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_first_v_second_stats_for_batch", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_first_v_second_stats_for_batch", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_inds_of_sorted_attnshaped_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_inds_of_sorted_attnshaped_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_info_for_batch", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_info_for_batch"], ["", "def", "handle_loop_body_for_grad_and_gradmult_stats", "(", "corr_grads_tensor", ",", "original_attn_weights", ",", "list_of_lens", ",", "\n", "corr_output_yielder", ",", "next_available_ind", ",", "gpu", ",", "classifier", ",", "\n", "batch_tup", ",", "corr_vects_for_later", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "lists_to_write_to_file_additions", "=", "[", "]", "\n", "attn_times_grads", "=", "corr_grads_tensor", "*", "original_attn_weights", "\n", "\n", "list_of_original_log_np_arrays", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "        ", "list_of_original_log_np_arrays", ".", "append", "(", "next", "(", "corr_output_yielder", ")", ")", "\n", "", "list_of_original_log_np_arrays", "=", "np", ".", "array", "(", "list_of_original_log_np_arrays", ")", "\n", "original_dists", "=", "np", ".", "array", "(", "list_of_original_log_np_arrays", ")", "\n", "_", ",", "list_of_batch_results_plaingrad", ",", "neg_calculation_artifacts_info_tup_plaingrad", "=", "get_first_v_second_stats_for_batch", "(", "next_available_ind", ",", "gpu", ",", "original_attn_weights", ",", "classifier", ",", "\n", "batch_tup", "[", "1", "]", ",", "batch_tup", "[", "2", "]", ",", "list_of_original_log_np_arrays", ",", "\n", "zero_out_by", "=", "corr_grads_tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "_", ",", "list_of_batch_results_gradmult", ",", "neg_calculation_artifacts_info_tup_gradmult", "=", "get_first_v_second_stats_for_batch", "(", "next_available_ind", ",", "gpu", ",", "original_attn_weights", ",", "classifier", ",", "\n", "batch_tup", "[", "1", "]", ",", "batch_tup", "[", "2", "]", ",", "list_of_original_log_np_arrays", ",", "\n", "zero_out_by", "=", "attn_times_grads", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "\n", "inds_in_dec_order", ",", "_", "=", "get_inds_of_sorted_attnshaped_vals", "(", "corr_grads_tensor", ",", "list_of_lens", ")", "\n", "inds_in_dec_order_by_mult", ",", "_", "=", "get_inds_of_sorted_attnshaped_vals", "(", "attn_times_grads", ",", "list_of_lens", ")", "\n", "\n", "# remove highest-gradient element first", "\n", "\n", "original_labels", "=", "torch", ".", "from_numpy", "(", "np", ".", "argmax", "(", "original_dists", ",", "axis", "=", "1", ")", ")", "\n", "original_labels", "=", "util", ".", "move_to_device", "(", "original_labels", ",", "gpu", ")", "\n", "\n", "corr_instance_inds", "=", "torch", ".", "from_numpy", "(", "np", ".", "arange", "(", "start", "=", "next_available_ind", ",", "\n", "stop", "=", "(", "next_available_ind", "+", "len", "(", "list_of_lens", ")", ")", ")", ")", "\n", "corr_instance_inds", "=", "util", ".", "move_to_device", "(", "corr_instance_inds", ",", "gpu", ")", "\n", "\n", "lists_to_write_from_top", "=", "get_dec_flip_info_for_batch", "(", "inds_in_dec_order", ",", "corr_instance_inds", ",", "original_labels", ",", "\n", "corr_vects_for_later", ",", "original_attn_weights", ",", "classifier", ",", "\n", "print_10_output_for_debugging", "=", "False", ")", "\n", "lists_to_write_from_top_mult", "=", "get_dec_flip_info_for_batch", "(", "inds_in_dec_order_by_mult", ",", "corr_instance_inds", ",", "\n", "original_labels", ",", "corr_vects_for_later", ",", "\n", "original_attn_weights", ",", "classifier", ")", "\n", "\n", "next_available_ind", "+=", "len", "(", "list_of_lens", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "        ", "top_list", "=", "lists_to_write_from_top", "[", "i", "]", "\n", "top_mult_list", "=", "lists_to_write_from_top_mult", "[", "i", "]", "\n", "top_singlestats_plaingrad", "=", "list_of_batch_results_plaingrad", "[", "i", "]", "\n", "top_singlestats_gradmult", "=", "list_of_batch_results_gradmult", "[", "i", "]", "\n", "assert", "top_list", "[", "0", "]", "==", "top_mult_list", "[", "0", "]", "\n", "assert", "top_list", "[", "0", "]", "==", "int", "(", "top_singlestats_plaingrad", "[", "0", "]", ")", ",", "str", "(", "top_list", "[", "0", "]", ")", "+", "', '", "+", "str", "(", "top_singlestats_plaingrad", "[", "0", "]", ")", "\n", "assert", "top_list", "[", "0", "]", "==", "int", "(", "top_singlestats_gradmult", "[", "0", "]", ")", ",", "str", "(", "top_list", "[", "0", "]", ")", "+", "', '", "+", "str", "(", "top_singlestats_gradmult", "[", "0", "]", ")", "\n", "instance_list", "=", "[", "top_list", "[", "0", "]", ",", "\n", "str", "(", "list_of_lens", "[", "i", "]", ")", ",", "\n", "str", "(", "top_list", "[", "2", "]", ")", ",", "\n", "str", "(", "top_list", "[", "3", "]", ")", ",", "\n", "str", "(", "top_list", "[", "4", "]", ")", ",", "\n", "str", "(", "top_mult_list", "[", "2", "]", ")", ",", "\n", "str", "(", "top_mult_list", "[", "3", "]", ")", ",", "\n", "str", "(", "top_mult_list", "[", "4", "]", ")", ",", "\n", "str", "(", "top_singlestats_plaingrad", "[", "1", "]", ")", ",", "# kl div highest", "\n", "str", "(", "top_singlestats_plaingrad", "[", "2", "]", ")", ",", "# js div highest", "\n", "str", "(", "top_singlestats_plaingrad", "[", "3", "]", ")", ",", "# decision flip highest", "\n", "str", "(", "top_singlestats_plaingrad", "[", "4", "]", ")", ",", "# kl div 2nd highest", "\n", "str", "(", "top_singlestats_plaingrad", "[", "5", "]", ")", ",", "# js div 2nd highest", "\n", "str", "(", "top_singlestats_plaingrad", "[", "6", "]", ")", ",", "# decision flip 2nd highest", "\n", "str", "(", "top_singlestats_gradmult", "[", "1", "]", ")", ",", "\n", "str", "(", "top_singlestats_gradmult", "[", "2", "]", ")", ",", "\n", "str", "(", "top_singlestats_gradmult", "[", "3", "]", ")", ",", "\n", "str", "(", "top_singlestats_gradmult", "[", "4", "]", ")", ",", "\n", "str", "(", "top_singlestats_gradmult", "[", "5", "]", ")", ",", "\n", "str", "(", "top_singlestats_gradmult", "[", "6", "]", ")", "]", "\n", "lists_to_write_to_file_additions", ".", "append", "(", "instance_list", ")", "\n", "\n", "", "return", "next_available_ind", ",", "neg_calculation_artifacts_info_tup_plaingrad", ",", "neg_calculation_artifacts_info_tup_gradmult", ",", "lists_to_write_to_file_additions", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_batch_size_max_samples_per_batch_from_config_file": [[439, 480], ["open", "len", "int", "line[].isdigit", "len", "int", "line[].isdigit", "line[].isdigit", "line[].isdigit", "len", "int", "line[].isdigit", "line[].strip().strip().strip", "line[].isdigit", "line[].strip().strip", "line[].strip", "line[].strip().strip().strip.index"], "function", ["None"], ["", "def", "get_batch_size_max_samples_per_batch_from_config_file", "(", "config_filename", ")", ":", "\n", "    ", "looking_for_max_samples", "=", "False", "\n", "batch_size", "=", "None", "\n", "max_samples_per_batch", "=", "None", "\n", "vocab_dir", "=", "None", "\n", "with", "open", "(", "config_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "looking_for_max_samples", ":", "\n", "                ", "start_counter", "=", "0", "\n", "end_counter", "=", "len", "(", "line", ")", "\n", "while", "start_counter", "<", "end_counter", "and", "not", "line", "[", "start_counter", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "start_counter", "+=", "1", "\n", "", "if", "start_counter", "==", "end_counter", ":", "\n", "                    ", "continue", "\n", "", "while", "not", "line", "[", "end_counter", "-", "1", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "end_counter", "-=", "1", "\n", "", "max_samples_per_batch", "=", "int", "(", "line", "[", "start_counter", ":", "end_counter", "]", ")", "\n", "looking_for_max_samples", "=", "False", "\n", "", "elif", "'\"batch_size\"'", "in", "line", ":", "\n", "                ", "start_counter", "=", "0", "\n", "end_counter", "=", "len", "(", "line", ")", "\n", "while", "not", "line", "[", "start_counter", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "start_counter", "+=", "1", "\n", "", "while", "not", "line", "[", "end_counter", "-", "1", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "end_counter", "-=", "1", "\n", "", "batch_size", "=", "int", "(", "line", "[", "start_counter", ":", "end_counter", "]", ")", "\n", "", "elif", "'\"maximum_samples_per_batch\"'", "in", "line", ":", "\n", "                ", "start_counter", "=", "0", "\n", "end_counter", "=", "len", "(", "line", ")", "\n", "while", "start_counter", "<", "end_counter", "and", "not", "line", "[", "start_counter", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "start_counter", "+=", "1", "\n", "", "if", "start_counter", "==", "end_counter", ":", "\n", "                    ", "looking_for_max_samples", "=", "True", "\n", "continue", "\n", "", "while", "not", "line", "[", "end_counter", "-", "1", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "end_counter", "-=", "1", "\n", "", "max_samples_per_batch", "=", "int", "(", "line", "[", "start_counter", ":", "end_counter", "]", ")", "\n", "", "elif", "'\"directory_path\"'", "in", "line", ":", "\n", "                ", "line", "=", "line", "[", "line", ".", "index", "(", "':'", ")", "+", "1", ":", "]", ".", "strip", "(", ")", ".", "strip", "(", "'\"'", ")", ".", "strip", "(", "\"'\"", ")", "\n", "vocab_dir", "=", "line", "\n", "", "", "", "return", "batch_size", ",", "max_samples_per_batch", ",", "vocab_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists": [[482, 506], ["range", "numpy.exp", "numpy.sum", "entropies.append", "scipy.misc.logsumexp", "str", "numpy.sum", "print", "str", "str", "numpy.sum", "str"], "function", ["None"], ["", "def", "get_entropy_of_dists", "(", "log_dists", ",", "lengths_of_dists", ",", "suppress_warnings", "=", "False", ",", "return_min_entropy_and_num_neg", "=", "False", ")", ":", "\n", "    ", "entropies", "=", "[", "]", "\n", "if", "return_min_entropy_and_num_neg", ":", "\n", "        ", "total_num_neg", "=", "0", "\n", "min_entropy", "=", "0", "\n", "", "for", "i", "in", "range", "(", "log_dists", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "log_dist", "=", "log_dists", "[", "i", ",", ":", "lengths_of_dists", "[", "i", "]", "]", "\n", "log_dist", "=", "log_dist", "-", "logsumexp", "(", "log_dist", ")", "\n", "exp_dist", "=", "np", ".", "exp", "(", "log_dist", ")", "\n", "total", "=", "np", ".", "sum", "(", "exp_dist", ")", "\n", "assert", ".98", "<", "total", "<", "1.02", ",", "str", "(", "exp_dist", ")", "+", "'\\n'", "+", "str", "(", "np", ".", "sum", "(", "exp_dist", ")", ")", "+", "\"\\n\"", "+", "str", "(", "log_dist", ")", "\n", "entropy", "=", "-", "1", "*", "np", ".", "sum", "(", "log_dist", "*", "exp_dist", ")", "\n", "if", "entropy", "<", "0", ":", "\n", "            ", "if", "not", "suppress_warnings", ":", "\n", "                ", "print", "(", "\"Calculated an entropy of \"", "+", "str", "(", "entropy", ")", ")", "\n", "", "if", "return_min_entropy_and_num_neg", ":", "\n", "                ", "total_num_neg", "+=", "1", "\n", "if", "entropy", "<", "min_entropy", ":", "\n", "                    ", "min_entropy", "=", "entropy", "\n", "", "", "", "entropies", ".", "append", "(", "entropy", ")", "\n", "", "if", "return_min_entropy_and_num_neg", ":", "\n", "        ", "return", "entropies", ",", "min_entropy", ",", "total_num_neg", "\n", "", "else", ":", "\n", "        ", "return", "entropies", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_kl_div_of_dists": [[508, 539], ["numpy.log", "range", "kl_divs.append", "log_dists.sum", "new_log_dists.sum", "scipy.misc.logsumexp", "scipy.misc.logsumexp", "print", "numpy.exp", "str"], "function", ["None"], ["", "", "def", "get_kl_div_of_dists", "(", "log_dists", ",", "new_log_dists", ",", "suppress_warnings", "=", "False", ",", "return_min_kl_div_and_num_neg", "=", "False", ")", ":", "\n", "    ", "kl_divs", "=", "[", "]", "\n", "mult_by", "=", "10", "\n", "# calculate constants by which to adjust log distributions prior to logsumexp computation;", "\n", "# these seem to put most distributions in a range where logsumexp works with reasonable precision", "\n", "arr_of_vals_to_add_to_log_dists", "=", "4", "-", "(", "log_dists", ".", "sum", "(", "axis", "=", "1", ")", "/", "log_dists", ".", "shape", "[", "1", "]", ")", "\n", "arr_of_vals_to_add_to_new_log_dists", "=", "-", "10", "-", "(", "new_log_dists", ".", "sum", "(", "axis", "=", "1", ")", "/", "new_log_dists", ".", "shape", "[", "1", "]", ")", "\n", "log_mult_by", "=", "np", ".", "log", "(", "mult_by", ")", "\n", "if", "return_min_kl_div_and_num_neg", ":", "\n", "        ", "total_num_neg", "=", "0", "\n", "min_kl_div", "=", "0", "\n", "", "for", "i", "in", "range", "(", "log_dists", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "log_dist", "=", "log_dists", "[", "i", "]", "-", "logsumexp", "(", "log_dists", "[", "i", "]", "+", "arr_of_vals_to_add_to_log_dists", "[", "i", "]", ")", "+", "arr_of_vals_to_add_to_log_dists", "[", "i", "]", "\n", "new_log_dist", "=", "new_log_dists", "[", "i", "]", "-", "logsumexp", "(", "new_log_dists", "[", "i", "]", "+", "arr_of_vals_to_add_to_new_log_dists", "[", "i", "]", ")", "+", "arr_of_vals_to_add_to_new_log_dists", "[", "i", "]", "\n", "new_log_dist_minus_log_dist", "=", "new_log_dist", "-", "log_dist", "\n", "kl_div", "=", "(", "np", ".", "exp", "(", "new_log_dist", "+", "log_mult_by", ")", "*", "new_log_dist_minus_log_dist", ")", ".", "sum", "(", ")", "\n", "kl_div", "=", "kl_div", "/", "mult_by", "\n", "if", "kl_div", "<", "0", ":", "\n", "            ", "if", "not", "suppress_warnings", ":", "\n", "                ", "print", "(", "\"Calculated a kl div of \"", "+", "str", "(", "kl_div", ")", ")", "\n", "", "if", "return_min_kl_div_and_num_neg", ":", "\n", "                ", "total_num_neg", "+=", "1", "\n", "if", "kl_div", "<", "min_kl_div", ":", "\n", "                    ", "min_kl_div", "=", "kl_div", "\n", "", "", "", "kl_divs", ".", "append", "(", "kl_div", ")", "\n", "", "if", "return_min_kl_div_and_num_neg", ":", "\n", "        ", "return", "kl_divs", ",", "min_kl_div", ",", "total_num_neg", "\n", "", "else", ":", "\n", "        ", "return", "kl_divs", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_js_div_of_dists": [[541, 572], ["range", "numpy.reshape", "numpy.reshape", "numpy.reshape", "js_divs.append", "log_dists.sum", "new_log_dists.sum", "scipy.misc.logsumexp", "scipy.misc.logsumexp", "scipy.misc.logsumexp", "float", "print", "numpy.concatenate", "numpy.log", "test_model.get_kl_div_of_dists", "test_model.get_kl_div_of_dists", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_kl_div_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_kl_div_of_dists"], ["", "", "def", "get_js_div_of_dists", "(", "log_dists", ",", "new_log_dists", ",", "suppress_warnings", "=", "False", ",", "return_min_js_div_and_num_neg", "=", "False", ")", ":", "\n", "    ", "js_divs", "=", "[", "]", "\n", "# calculate constants by which to adjust log distributions prior to logsumexp computation;", "\n", "# these seem to put most distributions in a range where logsumexp works with reasonable precision", "\n", "arr_of_vals_to_add_to_log_dists", "=", "4", "-", "(", "log_dists", ".", "sum", "(", "axis", "=", "1", ")", "/", "log_dists", ".", "shape", "[", "1", "]", ")", "\n", "arr_of_vals_to_add_to_new_log_dists", "=", "-", "10", "-", "(", "new_log_dists", ".", "sum", "(", "axis", "=", "1", ")", "/", "new_log_dists", ".", "shape", "[", "1", "]", ")", "\n", "if", "return_min_js_div_and_num_neg", ":", "\n", "        ", "total_num_neg", "=", "0", "\n", "min_js_div", "=", "1000", "\n", "", "for", "i", "in", "range", "(", "log_dists", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "p", "=", "log_dists", "[", "i", "]", "-", "logsumexp", "(", "log_dists", "[", "i", "]", "+", "arr_of_vals_to_add_to_log_dists", "[", "i", "]", ")", "+", "arr_of_vals_to_add_to_log_dists", "[", "i", "]", "\n", "p", "=", "np", ".", "reshape", "(", "p", ",", "(", "1", ",", "log_dists", ".", "shape", "[", "1", "]", ")", ")", "\n", "q", "=", "new_log_dists", "[", "i", "]", "-", "logsumexp", "(", "new_log_dists", "[", "i", "]", "+", "arr_of_vals_to_add_to_new_log_dists", "[", "i", "]", ")", "+", "arr_of_vals_to_add_to_new_log_dists", "[", "i", "]", "\n", "q", "=", "np", ".", "reshape", "(", "q", ",", "(", "1", ",", "log_dists", ".", "shape", "[", "1", "]", ")", ")", "\n", "m", "=", "np", ".", "reshape", "(", "logsumexp", "(", "np", ".", "concatenate", "(", "[", "p", ",", "q", "]", ",", "axis", "=", "0", ")", ",", "axis", "=", "0", ")", "-", "float", "(", "np", ".", "log", "(", "2", ")", ")", ",", "(", "1", ",", "log_dists", ".", "shape", "[", "1", "]", ")", ")", "\n", "js_div", "=", "(", "get_kl_div_of_dists", "(", "m", ",", "p", ",", "suppress_warnings", "=", "suppress_warnings", ")", "[", "0", "]", "+", "\n", "get_kl_div_of_dists", "(", "m", ",", "q", ",", "suppress_warnings", "=", "suppress_warnings", ")", "[", "0", "]", ")", "/", "2", "\n", "if", "js_div", "<", "0", ":", "\n", "            ", "if", "not", "suppress_warnings", ":", "\n", "                ", "print", "(", "\"Calculated a js div of \"", "+", "str", "(", "js_div", ")", ")", "\n", "", "if", "return_min_js_div_and_num_neg", ":", "\n", "                ", "total_num_neg", "+=", "1", "\n", "if", "js_div", "<", "min_js_div", ":", "\n", "                    ", "min_js_div", "=", "js_div", "\n", "", "", "", "js_divs", ".", "append", "(", "js_div", ")", "\n", "", "if", "return_min_js_div_and_num_neg", ":", "\n", "        ", "return", "js_divs", ",", "min_js_div", ",", "total_num_neg", "\n", "", "else", ":", "\n", "        ", "return", "js_divs", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_attn_div_from_unif_stats": [[574, 615], ["attn_tests_lib.AttentionIterator", "tqdm.tqdm", "print", "iter", "len", "numpy.array", "test_model.get_kl_div_of_dists", "test_model.get_js_div_of_dists", "float", "float", "instance_info_list.append", "print", "print", "open", "f.write", "numpy.zeros", "f.write", "numpy.log", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_kl_div_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_js_div_of_dists"], ["", "", "def", "get_attn_div_from_unif_stats", "(", "attn_weight_filename", ",", "attn_div_from_unif_filename", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "instance_info_list", "=", "[", "]", "\n", "attn_iterator", "=", "AttentionIterator", "(", "attn_weight_filename", ",", "return_log_attn_vals", "=", "True", ")", "\n", "instance_ind", "=", "0", "# equivalent to the total num of dists iterated over", "\n", "min_js_div", "=", "1000", "\n", "total_num_neg_calculated_js_vals", "=", "0", "\n", "min_kl_div", "=", "1000", "\n", "total_num_neg_calculated_kl_vals", "=", "0", "\n", "for", "log_attn_dist", "in", "tqdm", "(", "iter", "(", "attn_iterator", ")", ",", "desc", "=", "\"Calculating attn divs from unif\"", ")", ":", "\n", "        ", "instance_ind", "+=", "1", "\n", "num_attn_items", "=", "len", "(", "log_attn_dist", ")", "\n", "corr_log_unif_dist", "=", "np", ".", "zeros", "(", "(", "1", ",", "num_attn_items", ")", ",", "dtype", "=", "float", ")", "+", "np", ".", "log", "(", "[", "1", "/", "num_attn_items", "]", ")", "[", "0", "]", "\n", "np_log_attn_dist", "=", "np", ".", "array", "(", "[", "log_attn_dist", "]", ")", "\n", "kl_div", ",", "local_min_kl", ",", "num_neg_kl", "=", "get_kl_div_of_dists", "(", "corr_log_unif_dist", ",", "np_log_attn_dist", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ",", "\n", "return_min_kl_div_and_num_neg", "=", "True", ")", "\n", "js_div", ",", "local_min_js", ",", "num_neg_js", "=", "get_js_div_of_dists", "(", "corr_log_unif_dist", ",", "np_log_attn_dist", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ",", "\n", "return_min_js_div_and_num_neg", "=", "True", ")", "\n", "kl_div", "=", "float", "(", "kl_div", "[", "0", "]", ")", "\n", "js_div", "=", "float", "(", "js_div", "[", "0", "]", ")", "\n", "if", "local_min_kl", "<", "min_kl_div", ":", "\n", "            ", "min_kl_div", "=", "local_min_kl", "\n", "", "if", "local_min_js", "<", "min_js_div", ":", "\n", "            ", "min_js_div", "=", "local_min_js", "\n", "", "total_num_neg_calculated_kl_vals", "+=", "num_neg_kl", "\n", "total_num_neg_calculated_js_vals", "+=", "num_neg_js", "\n", "instance_info_list", ".", "append", "(", "(", "str", "(", "instance_ind", ")", ",", "str", "(", "num_attn_items", ")", ",", "str", "(", "kl_div", ")", ",", "str", "(", "js_div", ")", ")", ")", "\n", "", "if", "instance_ind", ">", "0", ":", "\n", "# at least one instance was iterated over", "\n", "        ", "print", "(", "str", "(", "total_num_neg_calculated_kl_vals", ")", "+", "' / '", "+", "str", "(", "instance_ind", ")", "+", "\n", "' calculated KL divs from unif dists to attn dists were negative; lowest calculated KL div was '", "+", "\n", "str", "(", "min_kl_div", ")", "+", "' (should be close to 0. see test_divergences() in debugging.py for sanity checks)'", ")", "\n", "print", "(", "str", "(", "total_num_neg_calculated_js_vals", ")", "+", "' / '", "+", "str", "(", "instance_ind", ")", "+", "\n", "' calculated JS divs from unif dists to attn dists were negative; lowest calculated JS div was '", "+", "\n", "str", "(", "min_js_div", ")", "+", "' (should be close to 0. see test_divergences() in debugging.py for sanity checks)'", ")", "\n", "", "with", "open", "(", "attn_div_from_unif_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"id,attn_seq_len,attn_kl_div_from_unif,attn_js_div_from_unif\\n\"", ")", "\n", "for", "info_list", "in", "instance_info_list", ":", "\n", "            ", "f", ".", "write", "(", "info_list", "[", "0", "]", "+", "','", "+", "info_list", "[", "1", "]", "+", "','", "+", "info_list", "[", "2", "]", "+", "','", "+", "info_list", "[", "3", "]", "+", "'\\n'", ")", "\n", "", "", "print", "(", "\"Done writing attn_div_from_unif stats.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_two_highest_and_inds": [[617, 652], ["isinstance", "range", "len"], "function", ["None"], ["", "def", "get_two_highest_and_inds", "(", "list_to_check", ",", "dont_check_at_ind_x_or_greater", "=", "None", ")", ":", "\n", "    ", "highest_val", "=", "-", "1", "\n", "highest_ind", "=", "-", "1", "\n", "second_highest_val", "=", "-", "1", "\n", "second_highest_ind", "=", "-", "1", "\n", "lowest_val", "=", "100000", "\n", "lowest_ind", "=", "-", "1", "\n", "second_lowest_val", "=", "100000", "\n", "second_lowest_ind", "=", "-", "1", "\n", "if", "isinstance", "(", "list_to_check", ",", "list", ")", ":", "\n", "        ", "list_len", "=", "len", "(", "list_to_check", ")", "\n", "", "else", ":", "\n", "        ", "list_len", "=", "list_to_check", ".", "shape", "[", "0", "]", "\n", "", "if", "dont_check_at_ind_x_or_greater", "is", "None", ":", "\n", "        ", "dont_check_at_ind_x_or_greater", "=", "list_len", "\n", "", "for", "i", "in", "range", "(", "dont_check_at_ind_x_or_greater", ")", ":", "\n", "        ", "val", "=", "list_to_check", "[", "i", "]", "\n", "if", "val", ">", "highest_val", ":", "\n", "            ", "second_highest_val", "=", "highest_val", "\n", "second_highest_ind", "=", "highest_ind", "\n", "highest_val", "=", "val", "\n", "highest_ind", "=", "i", "\n", "", "elif", "val", ">", "second_highest_val", ":", "\n", "            ", "second_highest_val", "=", "val", "\n", "second_highest_ind", "=", "i", "\n", "", "if", "val", "<", "lowest_val", ":", "\n", "            ", "second_lowest_val", "=", "lowest_val", "\n", "second_lowest_ind", "=", "lowest_ind", "\n", "lowest_val", "=", "val", "\n", "lowest_ind", "=", "i", "\n", "", "elif", "val", "<", "second_lowest_val", ":", "\n", "            ", "second_lowest_val", "=", "val", "\n", "second_lowest_ind", "=", "i", "\n", "", "", "return", "highest_val", ",", "highest_ind", ",", "second_highest_val", ",", "second_highest_ind", ",", "lowest_val", ",", "lowest_ind", ",", "second_lowest_val", ",", "second_lowest_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.make_zeroed_out_copies_for_highest_2ndhighest_lowest_2ndlowest": [[654, 675], ["two_dim_arr.clone", "two_dim_arr.clone", "two_dim_arr.clone", "two_dim_arr.clone", "range", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "test_model.get_two_highest_and_inds", "test_model.get_two_highest_and_inds"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_two_highest_and_inds", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_two_highest_and_inds"], ["", "def", "make_zeroed_out_copies_for_highest_2ndhighest_lowest_2ndlowest", "(", "two_dim_arr", ",", "true_lengths", ",", "other_arr_to_sort_by", "=", "None", ")", ":", "\n", "    ", "highest_zeroed_out", "=", "two_dim_arr", ".", "clone", "(", ")", "\n", "second_highest_zeroed_out", "=", "two_dim_arr", ".", "clone", "(", ")", "\n", "lowest_zeroed_out", "=", "two_dim_arr", ".", "clone", "(", ")", "\n", "second_lowest_zeroed_out", "=", "two_dim_arr", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "two_dim_arr", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "other_arr_to_sort_by", "is", "None", ":", "\n", "            ", "_", ",", "highest_ind", ",", "_", ",", "second_highest_ind", ",", "_", ",", "lowest_ind", ",", "_", ",", "second_lowest_ind", "=", "get_two_highest_and_inds", "(", "two_dim_arr", "[", "i", "]", ",", "dont_check_at_ind_x_or_greater", "=", "true_lengths", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "_", ",", "highest_ind", ",", "_", ",", "second_highest_ind", ",", "_", ",", "lowest_ind", ",", "_", ",", "second_lowest_ind", "=", "get_two_highest_and_inds", "(", "other_arr_to_sort_by", "[", "i", "]", ",", "dont_check_at_ind_x_or_greater", "=", "true_lengths", "[", "i", "]", ")", "\n", "", "highest_zeroed_out", "[", "i", ",", "highest_ind", "]", "=", "0", "\n", "second_highest_zeroed_out", "[", "i", ",", "second_highest_ind", "]", "=", "0", "\n", "lowest_zeroed_out", "[", "i", ",", "lowest_ind", "]", "=", "0", "\n", "second_lowest_zeroed_out", "[", "i", ",", "second_lowest_ind", "]", "=", "0", "\n", "", "highest_zeroed_out", "=", "normalize", "(", "highest_zeroed_out", ",", "p", "=", "1", ",", "dim", "=", "1", ")", "\n", "second_highest_zeroed_out", "=", "normalize", "(", "second_highest_zeroed_out", ",", "p", "=", "1", ",", "dim", "=", "1", ")", "\n", "lowest_zeroed_out", "=", "normalize", "(", "lowest_zeroed_out", ",", "p", "=", "1", ",", "dim", "=", "1", ")", "\n", "second_lowest_zeroed_out", "=", "normalize", "(", "second_lowest_zeroed_out", ",", "p", "=", "1", ",", "dim", "=", "1", ")", "\n", "return", "highest_zeroed_out", ",", "second_highest_zeroed_out", ",", "lowest_zeroed_out", ",", "second_lowest_zeroed_out", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_onerun_diff_from_original_stats": [[708, 724], ["new_output_dict[].data.cpu().numpy", "numpy.argmax", "numpy.argmax", "test_model.get_kl_div_of_dists", "test_model.get_js_div_of_dists", "numpy.zeros", "new_output_dict[].data.cpu"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_kl_div_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_js_div_of_dists"], ["", "", "", "", "", "def", "get_onerun_diff_from_original_stats", "(", "new_output_dict", ",", "log_original_np_output_arrays", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "logits", "=", "new_output_dict", "[", "\"label_logits\"", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "old_decisions", "=", "np", ".", "argmax", "(", "log_original_np_output_arrays", ",", "axis", "=", "1", ")", "\n", "new_decisions", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", "\n", "decision_flips_arr", "=", "np", ".", "zeros", "(", "old_decisions", ".", "shape", "[", "0", "]", ")", "-", "1", "\n", "dec_flipped", "=", "(", "old_decisions", "!=", "new_decisions", ")", "\n", "decision_flips_arr", "[", "dec_flipped", "]", "=", "new_decisions", "[", "dec_flipped", "]", "\n", "\n", "kl_divs", ",", "local_min_kl", ",", "num_neg_kl", "=", "get_kl_div_of_dists", "(", "log_original_np_output_arrays", ",", "logits", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ",", "\n", "return_min_kl_div_and_num_neg", "=", "True", ")", "\n", "js_divs", ",", "local_min_js", ",", "num_neg_js", "=", "get_js_div_of_dists", "(", "log_original_np_output_arrays", ",", "logits", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ",", "\n", "return_min_js_div_and_num_neg", "=", "True", ")", "\n", "return", "kl_divs", ",", "js_divs", ",", "decision_flips_arr", ",", "local_min_kl", ",", "num_neg_kl", ",", "local_min_js", ",", "num_neg_js", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.binary_search_for_first_ind_with_num_geq": [[726, 745], ["arr.size"], "function", ["None"], ["", "def", "binary_search_for_first_ind_with_num_geq", "(", "arr", ",", "x", ")", ":", "\n", "    ", "possible_start", "=", "0", "\n", "len_of_arr", "=", "arr", ".", "size", "(", "0", ")", "\n", "possible_end_plus_1", "=", "len_of_arr", "\n", "check", "=", "(", "possible_start", "+", "possible_end_plus_1", ")", "//", "2", "\n", "found", "=", "False", "\n", "while", "not", "found", ":", "\n", "        ", "if", "arr", "[", "check", "]", ">=", "x", "and", "arr", "[", "check", "-", "1", "]", "<", "x", ":", "\n", "            ", "found", "=", "True", "\n", "", "elif", "check", "==", "len_of_arr", "-", "1", ":", "\n", "            ", "check", "=", "len_of_arr", "\n", "found", "=", "True", "\n", "", "elif", "arr", "[", "check", "]", "<", "x", ":", "\n", "            ", "possible_start", "=", "check", "+", "1", "\n", "check", "=", "(", "possible_start", "+", "possible_end_plus_1", ")", "//", "2", "\n", "", "elif", "arr", "[", "check", "-", "1", "]", ">=", "x", ":", "\n", "            ", "possible_end_plus_1", "=", "check", "\n", "check", "=", "(", "possible_start", "+", "possible_end_plus_1", ")", "//", "2", "\n", "", "", "return", "check", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_inds_of_sorted_attnshaped_vals": [[747, 768], ["str", "original_vals.sort", "sorted_corr_inds_dec.cpu().numpy.cpu().numpy", "range", "int", "allennlp.nn.util.move_to_device", "original_vals.size", "list", "list.copy", "attn_inds_in_dec_order.copy.reverse", "sorted_attn_inds_decreasing_order.append", "sorted_attn_inds_increasing_order.append", "allennlp.nn.util.get_mask_from_sequence_lengths().float", "sorted_corr_inds_dec.cpu().numpy.cpu", "allennlp.nn.util.get_mask_from_sequence_lengths", "str.rfind", "torch.LongTensor", "original_vals.size"], "function", ["None"], ["", "def", "get_inds_of_sorted_attnshaped_vals", "(", "original_vals", ",", "list_of_lens", ")", ":", "\n", "    ", "sorted_attn_inds_increasing_order", "=", "[", "]", "\n", "sorted_attn_inds_decreasing_order", "=", "[", "]", "\n", "device", "=", "str", "(", "original_vals", ".", "device", ")", "\n", "is_cuda", "=", "'cpu'", "not", "in", "device", "\n", "if", "is_cuda", ":", "\n", "        ", "gpu", "=", "int", "(", "device", "[", "device", ".", "rfind", "(", "':'", ")", "+", "1", ":", "]", ")", "\n", "", "add_to_tensor", "=", "(", "1000000", "*", "util", ".", "get_mask_from_sequence_lengths", "(", "torch", ".", "LongTensor", "(", "list_of_lens", ")", ",", "\n", "original_vals", ".", "size", "(", "1", ")", ")", ".", "float", "(", ")", ")", "-", "1000000", "\n", "if", "is_cuda", ":", "\n", "        ", "add_to_tensor", "=", "util", ".", "move_to_device", "(", "add_to_tensor", ",", "gpu", ")", "\n", "", "original_vals", "=", "original_vals", "+", "add_to_tensor", "# disadvantage padding in favor of negative gradient vals", "\n", "sorted_attn_weights_dec", ",", "sorted_corr_inds_dec", "=", "original_vals", ".", "sort", "(", "1", ",", "descending", "=", "True", ")", "\n", "sorted_corr_inds_dec", "=", "sorted_corr_inds_dec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", "in", "range", "(", "original_vals", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "attn_inds_in_dec_order", "=", "list", "(", "sorted_corr_inds_dec", "[", "i", ",", ":", "list_of_lens", "[", "i", "]", "]", ")", "\n", "attn_inds_in_inc_order", "=", "attn_inds_in_dec_order", ".", "copy", "(", ")", "\n", "attn_inds_in_inc_order", ".", "reverse", "(", ")", "\n", "sorted_attn_inds_decreasing_order", ".", "append", "(", "attn_inds_in_dec_order", ")", "\n", "sorted_attn_inds_increasing_order", ".", "append", "(", "attn_inds_in_inc_order", ")", "\n", "", "return", "sorted_attn_inds_decreasing_order", ",", "sorted_attn_inds_increasing_order", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_randomized_order_copies_of_lists": [[770, 778], ["range", "range", "ls.copy", "random.shuffle", "num_copies_lists[].append"], "function", ["None"], ["", "def", "get_randomized_order_copies_of_lists", "(", "lists", ",", "num_copies", ")", ":", "\n", "    ", "num_copies_lists", "=", "[", "[", "]", "for", "i", "in", "range", "(", "num_copies", ")", "]", "\n", "for", "ls", "in", "lists", ":", "\n", "        ", "for", "i", "in", "range", "(", "num_copies", ")", ":", "\n", "            ", "new_ls", "=", "ls", ".", "copy", "(", ")", "\n", "shuffle", "(", "new_ls", ")", "\n", "num_copies_lists", "[", "i", "]", ".", "append", "(", "new_ls", ")", "\n", "", "", "return", "num_copies_lists", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_stats_and_rand": [[780, 951], ["attn_tests_lib.IntermediateBatchIterator", "os.path.isfile", "iter", "tqdm.tqdm", "print", "print", "test_model.OriginalOutputDistIterator", "len", "allennlp.nn.util.move_to_device", "allennlp.nn.util.move_to_device", "range", "numpy.array", "torch.from_numpy", "allennlp.nn.util.move_to_device", "torch.from_numpy", "allennlp.nn.util.move_to_device", "test_model.get_inds_of_sorted_attnshaped_vals", "test_model.get_randomized_order_copies_of_lists", "test_model.get_dec_flip_info_for_batch", "test_model.get_dec_flip_info_for_batch", "range", "len", "range", "open", "tqdm.tqdm", "int", "len", "len", "list_of_original_np_arrays.append", "numpy.argmax", "numpy.arange", "test_model.get_dec_flip_info_for_batch", "range", "len", "lists_to_write_to_file.append", "os.path.isfile", "open", "os.path.isfile", "open", "range", "test_model.write_part_of_header_and_reorder", "test_model.write_part_of_header_and_reorder", "test_model.write_part_of_header_and_reorder", "test_model.write_part_of_header_and_reorder", "test_model.write_part_of_header_and_reorder", "test_model.write_part_of_header_and_reorder", "line.strip().split.strip().split", "int", "math.ceil", "len", "next", "len", "len", "len", "str", "str", "str", "str", "str", "str", "str", "str", "f.write", "f.write", "f.write", "len", "reordered_pieces.append", "f.write", "f.write", "f.write", "f.write", "f.write", "f.write", "f.write", "range", "f.write", "len", "rand_result_list.append", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "str", "f.write", "line.strip().split.strip", "len", "str", "str", "str", "str", "str", "str", "str", "len", "str", "str", "str", "str", "str", "str", "str", "float", "float", "float", "float", "float", "float", "len", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_inds_of_sorted_attnshaped_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_randomized_order_copies_of_lists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_info_for_batch", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_info_for_batch", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_info_for_batch", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_part_of_header_and_reorder", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_part_of_header_and_reorder", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_part_of_header_and_reorder", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_part_of_header_and_reorder", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_part_of_header_and_reorder", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_part_of_header_and_reorder"], ["", "def", "get_dec_flip_stats_and_rand", "(", "classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "original_output_filename", ",", "dec_flip_stats_filename", ",", "rand_results_filename", ",", "\n", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "batch_iterator", "=", "IntermediateBatchIterator", "(", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ")", "\n", "next_available_ind", "=", "1", "\n", "\n", "# figure out whether that's actually next_available_ind or not", "\n", "if", "os", ".", "path", ".", "isfile", "(", "dec_flip_stats_filename", ")", ":", "\n", "        ", "last_used_ind", "=", "None", "\n", "with", "open", "(", "dec_flip_stats_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "tqdm", "(", "f", ",", "desc", "=", "\"Determining what next available ind is\"", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "if", "len", "(", "line", ")", ">", "1", ":", "\n", "                    ", "last_used_ind", "=", "line", "[", "0", "]", "\n", "", "", "try", ":", "\n", "                ", "last_used_ind", "=", "int", "(", "last_used_ind", ")", "\n", "", "except", ":", "\n", "                ", "last_used_ind", "=", "None", "\n", "", "", "if", "last_used_ind", "is", "not", "None", ":", "\n", "            ", "next_available_ind", "=", "last_used_ind", "+", "1", "\n", "\n", "", "", "corr_output_yielder", "=", "iter", "(", "OriginalOutputDistIterator", "(", "original_output_filename", ")", ")", "\n", "starting_ind_of_batch", "=", "1", "\n", "havent_found_start_yet", "=", "True", "\n", "for", "batch_tup", "in", "tqdm", "(", "batch_iterator", ",", "total", "=", "int", "(", "ceil", "(", "batch_iterator", ".", "num_instances", "/", "batch_iterator", ".", "batch_size", ")", ")", ",", "\n", "desc", "=", "\"Calculating decision flip and rand stats\"", ")", ":", "\n", "        ", "list_of_lens", "=", "batch_tup", "[", "2", "]", "\n", "if", "starting_ind_of_batch", "+", "len", "(", "list_of_lens", ")", "<=", "next_available_ind", ":", "\n", "            ", "starting_ind_of_batch", "+=", "len", "(", "list_of_lens", ")", "\n", "continue", "# we've already covered all the instances in this batch", "\n", "", "elif", "havent_found_start_yet", ":", "\n", "            ", "havent_found_start_yet", "=", "False", "\n", "# could potentially repeat some ids, but at least ensures each instance is correctly labeled", "\n", "next_available_ind", "=", "starting_ind_of_batch", "\n", "", "starting_ind_of_batch", "+=", "len", "(", "list_of_lens", ")", "\n", "\n", "lists_to_write_to_file", "=", "[", "]", "\n", "rand_result_list", "=", "[", "]", "\n", "\n", "original_attn_weights", "=", "util", ".", "move_to_device", "(", "batch_tup", "[", "0", "]", ",", "gpu", ")", "\n", "corr_vects", "=", "util", ".", "move_to_device", "(", "batch_tup", "[", "1", "]", ",", "gpu", ")", "\n", "\n", "list_of_original_np_arrays", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "            ", "list_of_original_np_arrays", ".", "append", "(", "next", "(", "corr_output_yielder", ")", ")", "\n", "", "original_dists", "=", "np", ".", "array", "(", "list_of_original_np_arrays", ")", "\n", "original_labels", "=", "torch", ".", "from_numpy", "(", "np", ".", "argmax", "(", "original_dists", ",", "axis", "=", "1", ")", ")", "\n", "original_labels", "=", "util", ".", "move_to_device", "(", "original_labels", ",", "gpu", ")", "\n", "\n", "corr_instance_inds", "=", "torch", ".", "from_numpy", "(", "np", ".", "arange", "(", "start", "=", "next_available_ind", ",", "\n", "stop", "=", "(", "next_available_ind", "+", "len", "(", "list_of_lens", ")", ")", ")", ")", "\n", "corr_instance_inds", "=", "util", ".", "move_to_device", "(", "corr_instance_inds", ",", "gpu", ")", "\n", "\n", "inds_in_dec_order", ",", "inds_in_inc_order", "=", "get_inds_of_sorted_attnshaped_vals", "(", "original_attn_weights", ",", "list_of_lens", ")", "\n", "inds_in_rand_orders", "=", "get_randomized_order_copies_of_lists", "(", "inds_in_dec_order", ",", "num_rand_samples_to_take", ")", "\n", "\n", "lists_to_write_from_top", "=", "get_dec_flip_info_for_batch", "(", "inds_in_dec_order", ",", "corr_instance_inds", ",", "original_labels", ",", "\n", "corr_vects", ",", "original_attn_weights", ",", "classifier", ",", "\n", "print_10_output_for_debugging", "=", "False", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "lists_to_write_from_bottom", "=", "get_dec_flip_info_for_batch", "(", "inds_in_inc_order", ",", "corr_instance_inds", ",", "original_labels", ",", "\n", "corr_vects", ",", "original_attn_weights", ",", "classifier", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "for", "i", "in", "range", "(", "num_rand_samples_to_take", ")", ":", "\n", "            ", "rand_results", ",", "weight_kl_js", "=", "get_dec_flip_info_for_batch", "(", "inds_in_rand_orders", "[", "i", "]", ",", "corr_instance_inds", ",", "\n", "original_labels", ",", "corr_vects", ",", "\n", "original_attn_weights", ",", "classifier", ",", "\n", "get_attnvals_kljsdivs_for_first_inds", "=", "original_dists", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "assert", "len", "(", "rand_results", ")", "==", "len", "(", "lists_to_write_from_top", ")", "\n", "for", "local_inst_ind", "in", "range", "(", "len", "(", "rand_results", ")", ")", ":", "\n", "                ", "w", "=", "weight_kl_js", "[", "local_inst_ind", "]", "\n", "res", "=", "rand_results", "[", "local_inst_ind", "]", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "rand_result_list", ".", "append", "(", "[", "lists_to_write_from_top", "[", "local_inst_ind", "]", "[", "0", "]", ",", "\n", "str", "(", "list_of_lens", "[", "local_inst_ind", "]", ")", ",", "\n", "str", "(", "float", "(", "w", "[", "0", "]", ")", ")", ",", "# attn weight randomly pulled out", "\n", "str", "(", "float", "(", "w", "[", "1", "]", ")", ")", ",", "# kl div resulting from running that", "\n", "str", "(", "float", "(", "w", "[", "2", "]", ")", ")", ",", "# js div resulting from running that", "\n", "str", "(", "res", "[", "2", "]", ")", ",", "# num random weights that had to be zeroed before dec flip", "\n", "str", "(", "res", "[", "3", "]", ")", ",", "# prob mass \"\" \"\" \"\" \"\"", "\n", "str", "(", "res", "[", "4", "]", ")", "]", ")", "# frac of weights \"\" \"\" \"\"", "\n", "", "else", ":", "\n", "                    ", "list_to_add_to", "=", "rand_result_list", "[", "-", "1", "*", "(", "len", "(", "rand_results", ")", "-", "local_inst_ind", ")", "]", "\n", "assert", "list_to_add_to", "[", "0", "]", "==", "lists_to_write_from_top", "[", "local_inst_ind", "]", "[", "0", "]", "\n", "list_to_add_to", ".", "append", "(", "str", "(", "float", "(", "w", "[", "0", "]", ")", ")", ")", "\n", "list_to_add_to", ".", "append", "(", "str", "(", "float", "(", "w", "[", "1", "]", ")", ")", ")", "\n", "list_to_add_to", ".", "append", "(", "str", "(", "float", "(", "w", "[", "2", "]", ")", ")", ")", "\n", "list_to_add_to", ".", "append", "(", "str", "(", "res", "[", "2", "]", ")", ")", "\n", "list_to_add_to", ".", "append", "(", "str", "(", "res", "[", "3", "]", ")", ")", "\n", "list_to_add_to", ".", "append", "(", "str", "(", "res", "[", "4", "]", ")", ")", "\n", "", "", "", "next_available_ind", "+=", "len", "(", "list_of_lens", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "            ", "top_list", "=", "lists_to_write_from_top", "[", "i", "]", "\n", "bottom_list", "=", "lists_to_write_from_bottom", "[", "i", "]", "\n", "assert", "top_list", "[", "0", "]", "==", "bottom_list", "[", "0", "]", "and", "top_list", "[", "1", "]", "==", "bottom_list", "[", "1", "]", ",", "str", "(", "top_list", "[", ":", "2", "]", ")", "+", "\", \"", "+", "str", "(", "bottom_list", "[", ":", "2", "]", ")", "\n", "instance_list", "=", "[", "top_list", "[", "0", "]", ",", "\n", "str", "(", "list_of_lens", "[", "i", "]", ")", ",", "\n", "str", "(", "top_list", "[", "2", "]", ")", ",", "\n", "str", "(", "top_list", "[", "3", "]", ")", ",", "\n", "str", "(", "top_list", "[", "4", "]", ")", ",", "\n", "str", "(", "bottom_list", "[", "2", "]", ")", ",", "\n", "str", "(", "bottom_list", "[", "3", "]", ")", ",", "\n", "str", "(", "bottom_list", "[", "4", "]", ")", "]", "\n", "lists_to_write_to_file", ".", "append", "(", "instance_list", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "dec_flip_stats_filename", ")", ":", "\n", "            ", "need_to_add_header_line", "=", "True", "\n", "", "else", ":", "\n", "            ", "need_to_add_header_line", "=", "False", "\n", "", "with", "open", "(", "dec_flip_stats_filename", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "if", "need_to_add_header_line", ":", "\n", "                ", "f", ".", "write", "(", "'id,seq_len,needed_to_rem_x_top_items_for_decflip,needed_to_rem_x_top_probmass_for_decflip,'", "+", "\n", "'needed_to_rem_frac_x_top_items_for_decflip,needed_to_rem_x_bottom_items_for_decflip,'", "+", "\n", "'needed_to_rem_x_bottom_probmass_for_decflip,needed_to_rem_frac_x_bottom_items_for_decflip\\n'", ")", "\n", "", "prev_id", "=", "0", "\n", "for", "instance_list", "in", "lists_to_write_to_file", ":", "\n", "                ", "assert", "prev_id", "<", "instance_list", "[", "0", "]", "\n", "prev_id", "=", "instance_list", "[", "0", "]", "\n", "f", ".", "write", "(", "str", "(", "instance_list", "[", "0", "]", ")", "+", "','", "+", "instance_list", "[", "1", "]", "+", "','", "+", "instance_list", "[", "2", "]", "+", "','", "+", "instance_list", "[", "3", "]", "+", "\n", "','", "+", "instance_list", "[", "4", "]", "+", "','", "+", "instance_list", "[", "5", "]", "+", "','", "+", "instance_list", "[", "6", "]", "+", "','", "+", "\n", "instance_list", "[", "7", "]", "+", "'\\n'", ")", "\n", "", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "rand_results_filename", ")", ":", "\n", "            ", "need_to_add_header_line", "=", "True", "\n", "", "else", ":", "\n", "            ", "need_to_add_header_line", "=", "False", "\n", "", "with", "open", "(", "rand_results_filename", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "dont_write_header", "=", "not", "need_to_add_header_line", "\n", "reordered_pieces", "=", "[", "]", "\n", "if", "need_to_add_header_line", ":", "\n", "                ", "f", ".", "write", "(", "'id,seq_len,'", ")", "\n", "", "for", "instance_ind", "in", "range", "(", "len", "(", "rand_result_list", ")", ")", ":", "\n", "                ", "reordered_pieces", ".", "append", "(", "[", "rand_result_list", "[", "instance_ind", "]", "[", "0", "]", ",", "rand_result_list", "[", "instance_ind", "]", "[", "1", "]", "]", ")", "\n", "\n", "", "write_part_of_header_and_reorder", "(", "'attn_weight_extracted_'", ",", "2", ",", "f", ",", "rand_result_list", ",", "\n", "reordered_pieces", ",", "dont_write_header", "=", "dont_write_header", ")", "\n", "if", "need_to_add_header_line", ":", "\n", "                ", "f", ".", "write", "(", "','", ")", "\n", "", "write_part_of_header_and_reorder", "(", "'kl_div_'", ",", "3", ",", "f", ",", "rand_result_list", ",", "\n", "reordered_pieces", ",", "dont_write_header", "=", "dont_write_header", ")", "\n", "if", "need_to_add_header_line", ":", "\n", "                ", "f", ".", "write", "(", "','", ")", "\n", "", "write_part_of_header_and_reorder", "(", "'js_div_'", ",", "4", ",", "f", ",", "rand_result_list", ",", "\n", "reordered_pieces", ",", "dont_write_header", "=", "dont_write_header", ")", "\n", "if", "need_to_add_header_line", ":", "\n", "                ", "f", ".", "write", "(", "','", ")", "\n", "", "write_part_of_header_and_reorder", "(", "'needed_to_rem_x_items_for_decflip_'", ",", "5", ",", "f", ",", "rand_result_list", ",", "\n", "reordered_pieces", ",", "dont_write_header", "=", "dont_write_header", ")", "\n", "if", "need_to_add_header_line", ":", "\n", "                ", "f", ".", "write", "(", "','", ")", "\n", "", "write_part_of_header_and_reorder", "(", "'needed_to_rem_x_probmass_for_decflip_'", ",", "6", ",", "f", ",", "rand_result_list", ",", "\n", "reordered_pieces", ",", "dont_write_header", "=", "dont_write_header", ")", "\n", "if", "need_to_add_header_line", ":", "\n", "                ", "f", ".", "write", "(", "','", ")", "\n", "", "write_part_of_header_and_reorder", "(", "'needed_to_rem_frac_x_for_decflip_'", ",", "7", ",", "f", ",", "rand_result_list", ",", "\n", "reordered_pieces", ",", "dont_write_header", "=", "dont_write_header", ")", "\n", "if", "need_to_add_header_line", ":", "\n", "                ", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n", "", "prev_id", "=", "0", "\n", "for", "instance_list", "in", "reordered_pieces", ":", "\n", "                ", "assert", "prev_id", "<", "instance_list", "[", "0", "]", "\n", "prev_id", "=", "instance_list", "[", "0", "]", "\n", "f", ".", "write", "(", "str", "(", "instance_list", "[", "0", "]", ")", "+", "','", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "instance_list", ")", "-", "1", ")", ":", "\n", "                    ", "f", ".", "write", "(", "instance_list", "[", "i", "]", "+", "','", ")", "\n", "", "f", ".", "write", "(", "instance_list", "[", "-", "1", "]", "+", "'\\n'", ")", "\n", "\n", "", "", "", "print", "(", "\"Done writing decision-flip stats file.\"", ")", "\n", "print", "(", "\"Done writing rand-order stats file.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_stats_for_rand_nontop": [[953, 1070], ["attn_tests_lib.IntermediateBatchIterator", "iter", "tqdm.tqdm", "print", "print", "print", "print", "print", "test_model.OriginalOutputDistIterator", "iter", "allennlp.nn.util.move_to_device", "allennlp.nn.util.move_to_device", "range", "numpy.array", "torch.from_numpy", "allennlp.nn.util.move_to_device", "torch.from_numpy", "allennlp.nn.util.move_to_device", "test_model.get_inds_of_sorted_attnshaped_vals", "range", "test_model.get_dec_flip_info_for_batch", "len", "range", "open", "f.write", "tqdm.tqdm", "attn_tests_lib.GradientsIterator", "int", "len", "list_of_original_np_arrays.append", "numpy.argmax", "numpy.arange", "next", "allennlp.nn.util.move_to_device", "len", "rand_nontop_ind_lists.append", "zeroed_weights.append", "len", "lists_to_write_to_file.append", "str", "str", "str", "str", "f.write", "math.ceil", "next", "torch.cat.size", "util.move_to_device.size", "torch.cat.size", "util.move_to_device.size", "allennlp.nn.util.move_to_device", "len", "float", "float", "float", "str", "str", "str", "str", "str", "torch.cat.size", "util.move_to_device.size", "torch.cat", "allennlp.nn.util.get_mask_from_sequence_lengths().float", "len", "random.randint", "float", "float", "len", "torch.cat.new_zeros", "allennlp.nn.util.get_mask_from_sequence_lengths", "util.move_to_device.new_ones", "len", "util.move_to_device.size", "torch.LongTensor", "torch.cat.size", "util.move_to_device.size", "torch.cat.size", "util.move_to_device.size", "torch.cat.size", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_inds_of_sorted_attnshaped_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_info_for_batch"], ["", "def", "get_dec_flip_stats_for_rand_nontop", "(", "classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "original_output_filename", ",", "dec_flip_rand_nontop_stats_filename", ",", "\n", "order_type", "=", "'attn'", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "batch_iterator", "=", "IntermediateBatchIterator", "(", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ")", "\n", "next_available_ind", "=", "1", "\n", "lists_to_write_to_file", "=", "[", "]", "\n", "corr_output_yielder", "=", "iter", "(", "OriginalOutputDistIterator", "(", "original_output_filename", ")", ")", "\n", "num_neg_kldivs", "=", "0", "\n", "num_neg_jsdivs", "=", "0", "\n", "num_pos_kldivs", "=", "0", "\n", "num_pos_jsdivs", "=", "0", "\n", "if", "order_type", "!=", "'attn'", ":", "\n", "        ", "assert", "order_type", "==", "'grad'", "or", "order_type", "==", "'gradmult'", "or", "order_type", "==", "'gradsignmult'", "\n", "# set up a gradients iterator", "\n", "base_filename", "=", "corr_vector_dir", "+", "'gradients/'", "\n", "base_filename", "+=", "'gradient_wrt_attn_weights_'", "\n", "grad_iterator", "=", "iter", "(", "GradientsIterator", "(", "batch_size", ",", "base_filename", ",", "gpu", "=", "gpu", ")", ")", "\n", "", "for", "batch_tup", "in", "tqdm", "(", "batch_iterator", ",", "total", "=", "int", "(", "ceil", "(", "batch_iterator", ".", "num_instances", "/", "batch_iterator", ".", "batch_size", ")", ")", ",", "\n", "desc", "=", "\"Calculating rand nontop decision flip stats\"", ")", ":", "\n", "        ", "list_of_lens", "=", "batch_tup", "[", "2", "]", "\n", "original_attn_weights", "=", "util", ".", "move_to_device", "(", "batch_tup", "[", "0", "]", ",", "gpu", ")", "\n", "corr_vects", "=", "util", ".", "move_to_device", "(", "batch_tup", "[", "1", "]", ",", "gpu", ")", "\n", "\n", "list_of_original_np_arrays", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "            ", "list_of_original_np_arrays", ".", "append", "(", "next", "(", "corr_output_yielder", ")", ")", "\n", "", "original_dists", "=", "np", ".", "array", "(", "list_of_original_np_arrays", ")", "\n", "original_labels", "=", "torch", ".", "from_numpy", "(", "np", ".", "argmax", "(", "original_dists", ",", "axis", "=", "1", ")", ")", "\n", "original_labels", "=", "util", ".", "move_to_device", "(", "original_labels", ",", "gpu", ")", "\n", "\n", "corr_instance_inds", "=", "torch", ".", "from_numpy", "(", "np", ".", "arange", "(", "start", "=", "next_available_ind", ",", "\n", "stop", "=", "(", "next_available_ind", "+", "len", "(", "list_of_lens", ")", ")", ")", ")", "\n", "corr_instance_inds", "=", "util", ".", "move_to_device", "(", "corr_instance_inds", ",", "gpu", ")", "\n", "\n", "if", "order_type", "==", "'attn'", ":", "\n", "            ", "ranking", "=", "original_attn_weights", "\n", "", "else", ":", "\n", "# get next gradient values", "\n", "            ", "corr_grads", "=", "next", "(", "grad_iterator", ")", "\n", "assert", "corr_grads", ".", "size", "(", "0", ")", "==", "original_attn_weights", ".", "size", "(", "0", ")", "\n", "if", "corr_grads", ".", "size", "(", "1", ")", "!=", "original_attn_weights", ".", "size", "(", "1", ")", ":", "\n", "# this could happen if we had to assemble corr_grads from different arrays due to diff batch size", "\n", "# when computing gradients", "\n", "                ", "if", "corr_grads", ".", "size", "(", "1", ")", "<", "original_attn_weights", ".", "size", "(", "1", ")", ":", "\n", "                    ", "corr_grads", "=", "corr_grads", "[", ":", ",", ":", "original_attn_weights", ".", "size", "(", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "corr_grads", "=", "torch", ".", "cat", "(", "[", "corr_grads", ",", "\n", "corr_grads", ".", "new_zeros", "(", "(", "corr_grads", ".", "size", "(", "0", ")", ",", "\n", "original_attn_weights", ".", "size", "(", "1", ")", "-", "corr_grads", ".", "size", "(", "1", ")", ")", ")", "]", ",", "\n", "dim", "=", "1", ")", "\n", "", "", "add_to_tensor", "=", "(", "1000000", "*", "util", ".", "get_mask_from_sequence_lengths", "(", "torch", ".", "LongTensor", "(", "list_of_lens", ")", ",", "\n", "corr_grads", ".", "size", "(", "1", ")", ")", ".", "float", "(", ")", ")", "-", "1000000", "\n", "if", "gpu", "!=", "-", "1", ":", "\n", "                ", "add_to_tensor", "=", "util", ".", "move_to_device", "(", "add_to_tensor", ",", "gpu", ")", "\n", "", "add_to_tensor", "=", "util", ".", "move_to_device", "(", "add_to_tensor", ",", "gpu", ")", "\n", "if", "order_type", "==", "'grad'", ":", "\n", "                ", "ranking", "=", "corr_grads", "\n", "", "elif", "order_type", "==", "'gradmult'", ":", "\n", "                ", "ranking", "=", "corr_grads", "*", "original_attn_weights", "\n", "", "elif", "order_type", "==", "'gradsignmult'", ":", "\n", "                ", "multipliers", "=", "original_attn_weights", ".", "new_ones", "(", "original_attn_weights", ".", "size", "(", ")", ")", "[", "corr_grads", "<", "0", "]", "=", "-", "1", "\n", "ranking", "=", "original_attn_weights", "*", "multipliers", "\n", "", "ranking", "=", "ranking", "+", "add_to_tensor", "# disadvantage padding in favor of negative gradient vals", "\n", "\n", "", "inds_in_dec_order", ",", "inds_in_inc_order", "=", "get_inds_of_sorted_attnshaped_vals", "(", "ranking", ",", "list_of_lens", ")", "\n", "\n", "rand_nontop_ind_lists", "=", "[", "]", "\n", "zeroed_weights", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inds_in_dec_order", ")", ")", ":", "\n", "            ", "ind_list", "=", "inds_in_dec_order", "[", "i", "]", "\n", "if", "len", "(", "ind_list", ")", "==", "1", ":", "\n", "                ", "ind_pulled", "=", "0", "# we'll just filter this out during processing", "\n", "", "elif", "len", "(", "ind_list", ")", "==", "2", ":", "\n", "                ", "ind_pulled", "=", "1", "\n", "", "else", ":", "\n", "                ", "ind_pulled", "=", "random", ".", "randint", "(", "1", ",", "len", "(", "ind_list", ")", "-", "1", ")", "\n", "", "rand_nontop_ind_lists", ".", "append", "(", "[", "ind_pulled", "]", ")", "\n", "zeroed_weights", ".", "append", "(", "float", "(", "original_attn_weights", "[", "i", ",", "ind_pulled", "]", ")", ")", "\n", "", "lists_to_write", ",", "val_kldivs", "=", "get_dec_flip_info_for_batch", "(", "rand_nontop_ind_lists", ",", "corr_instance_inds", ",", "original_labels", ",", "corr_vects", ",", "\n", "original_attn_weights", ",", "classifier", ",", "print_10_output_for_debugging", "=", "False", ",", "\n", "get_attnvals_kljsdivs_for_first_inds", "=", "original_dists", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "next_available_ind", "+=", "len", "(", "list_of_lens", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "            ", "weight_kl_js", "=", "val_kldivs", "[", "i", "]", "\n", "assert", "weight_kl_js", "[", "0", "]", "==", "zeroed_weights", "[", "i", "]", "\n", "removed_one_nontop_rand", "=", "lists_to_write", "[", "i", "]", "\n", "if", "float", "(", "weight_kl_js", "[", "1", "]", ")", ">", "0", ":", "\n", "                ", "num_pos_kldivs", "+=", "1", "\n", "", "else", ":", "\n", "                ", "num_neg_kldivs", "+=", "1", "\n", "", "if", "float", "(", "weight_kl_js", "[", "2", "]", ")", ">", "0", ":", "\n", "                ", "num_pos_jsdivs", "+=", "1", "\n", "", "else", ":", "\n", "                ", "num_neg_jsdivs", "+=", "1", "\n", "", "instance_list", "=", "[", "removed_one_nontop_rand", "[", "0", "]", ",", "\n", "str", "(", "list_of_lens", "[", "i", "]", ")", ",", "\n", "str", "(", "removed_one_nontop_rand", "[", "2", "]", ")", ",", "\n", "str", "(", "zeroed_weights", "[", "i", "]", ")", ",", "\n", "str", "(", "float", "(", "weight_kl_js", "[", "1", "]", ")", ")", ",", "\n", "str", "(", "float", "(", "weight_kl_js", "[", "2", "]", ")", ")", "]", "\n", "lists_to_write_to_file", ".", "append", "(", "instance_list", ")", "\n", "", "", "print", "(", "\"Num neg KL divs: \"", "+", "str", "(", "num_neg_kldivs", ")", ")", "\n", "print", "(", "\"Num pos KL divs: \"", "+", "str", "(", "num_pos_kldivs", ")", ")", "\n", "print", "(", "\"Num neg JS divs: \"", "+", "str", "(", "num_neg_jsdivs", ")", ")", "\n", "print", "(", "\"Num pos JS divs: \"", "+", "str", "(", "num_pos_jsdivs", ")", ")", "\n", "\n", "with", "open", "(", "dec_flip_rand_nontop_stats_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'id,seq_len,not_negone_if_rand_caused_decflip,zeroed_weight,rand_kl_div,rand_js_div\\n'", ")", "\n", "prev_id", "=", "-", "1", "\n", "for", "instance_list", "in", "tqdm", "(", "lists_to_write_to_file", ",", "desc", "=", "\"Writing dec flip stats file\"", ")", ":", "\n", "            ", "assert", "prev_id", "<", "instance_list", "[", "0", "]", "\n", "prev_id", "=", "instance_list", "[", "0", "]", "\n", "f", ".", "write", "(", "str", "(", "instance_list", "[", "0", "]", ")", "+", "','", "+", "instance_list", "[", "1", "]", "+", "','", "+", "instance_list", "[", "2", "]", "+", "','", "+", "instance_list", "[", "3", "]", "+", "\n", "','", "+", "instance_list", "[", "4", "]", "+", "','", "+", "instance_list", "[", "5", "]", "+", "'\\n'", ")", "\n", "", "", "print", "(", "\"Done writing rand nontop stats file.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.write_part_of_header_and_reorder": [[1072, 1083], ["range", "range", "len", "f.write", "f.write", "range", "str"], "function", ["None"], ["", "def", "write_part_of_header_and_reorder", "(", "header_piece", ",", "ind_offset", ",", "f", ",", "rand_result_list", ",", "reordered_pieces", ",", "is_end", "=", "False", ",", "dont_write_header", "=", "False", ")", ":", "\n", "    ", "if", "not", "dont_write_header", ":", "\n", "        ", "for", "i", "in", "range", "(", "num_rand_samples_to_take", ")", ":", "\n", "            ", "f", ".", "write", "(", "header_piece", "+", "str", "(", "i", ")", ")", "\n", "if", "(", "not", "is_end", ")", "and", "i", "<", "num_rand_samples_to_take", "-", "1", ":", "\n", "                ", "f", ".", "write", "(", "','", ")", "\n", "", "", "", "for", "instance_ind", "in", "range", "(", "len", "(", "rand_result_list", ")", ")", ":", "\n", "        ", "cur_list", "=", "reordered_pieces", "[", "instance_ind", "]", "\n", "original_list", "=", "rand_result_list", "[", "instance_ind", "]", "\n", "cur_list", "+=", "[", "original_list", "[", "6", "*", "j", "+", "ind_offset", "]", "for", "j", "in", "range", "(", "num_rand_samples_to_take", ")", "]", "\n", "reordered_pieces", "[", "instance_ind", "]", "=", "cur_list", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_info_for_batch": [[1085, 1176], ["original_attn_weights.clone", "sorted", "len", "len", "range", "torch.nn.functional.normalize", "torch.max", "range", "range", "original_attn_weights_zeroed[].append", "mod_output.size", "str", "range", "input", "mod_output.cpu().numpy", "test_model.get_kl_div_of_dists", "test_model.get_js_div_of_dists", "range", "len", "len", "range", "val_kldivs[].append", "classifier", "str", "print", "print", "val_kldivs[].append", "val_kldivs[].append", "sorted.append", "len", "mod_output.size", "mod_output.cpu", "len", "int", "int", "sorted.append", "mod_output.cpu().numpy", "int", "int", "int", "float", "float", "len", "sum", "mod_output.cpu", "len"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_kl_div_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_js_div_of_dists"], ["", "", "def", "get_dec_flip_info_for_batch", "(", "sorted_attn_inds", ",", "corr_instance_inds", ",", "original_labels", ",", "corr_vects", ",", "\n", "original_attn_weights", ",", "classifier", ",", "get_attnvals_kljsdivs_for_first_inds", "=", "None", ",", "\n", "print_10_output_for_debugging", "=", "False", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "lists_to_write_to_file", "=", "[", "]", "\n", "done", "=", "False", "\n", "new_attn_weights", "=", "original_attn_weights", ".", "clone", "(", ")", "\n", "lens_of_attn_dists", "=", "[", "len", "(", "attn_inds", ")", "for", "attn_inds", "in", "sorted_attn_inds", "]", "\n", "original_attn_weights_zeroed", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "sorted_attn_inds", ")", ")", "]", "\n", "if", "get_attnvals_kljsdivs_for_first_inds", "is", "not", "None", ":", "\n", "        ", "val_kldivs", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "sorted_attn_inds", ")", ")", "]", "\n", "", "first_time", "=", "True", "\n", "while", "not", "done", ":", "\n", "        ", "cur_num_instances_remaining", "=", "len", "(", "lens_of_attn_dists", ")", "\n", "# all sorted_attn_inds lists here will have len > 0 and represent instances we want to run again", "\n", "for", "instance_ind", "in", "range", "(", "cur_num_instances_remaining", ")", ":", "\n", "            ", "ind_list", "=", "sorted_attn_inds", "[", "instance_ind", "]", "\n", "index_to_pull", "=", "ind_list", "[", "0", "]", "\n", "original_attn_weights_zeroed", "[", "instance_ind", "]", ".", "append", "(", "\n", "original_attn_weights", "[", "instance_ind", ",", "index_to_pull", "]", ")", "\n", "if", "first_time", "and", "get_attnvals_kljsdivs_for_first_inds", "is", "not", "None", ":", "\n", "                ", "val_kldivs", "[", "instance_ind", "]", ".", "append", "(", "original_attn_weights", "[", "instance_ind", ",", "index_to_pull", "]", ")", "\n", "", "new_attn_weights", "[", "instance_ind", ",", "sorted_attn_inds", "[", "instance_ind", "]", "[", "0", "]", "]", "=", "0", "\n", "del", "sorted_attn_inds", "[", "instance_ind", "]", "[", "0", "]", "\n", "\n", "", "new_attn_weights", "=", "normalize", "(", "new_attn_weights", ",", "p", "=", "1", ",", "dim", "=", "1", ")", "\n", "mod_output", "=", "classifier", "(", "corr_vects", ",", "new_attn_weights", ")", "[", "\"label_logits\"", "]", ".", "data", "\n", "assert", "mod_output", ".", "size", "(", "0", ")", "==", "corr_instance_inds", ".", "shape", "[", "0", "]", ",", "str", "(", "mod_output", ".", "size", "(", ")", ")", "+", "', '", "+", "str", "(", "corr_instance_inds", ".", "shape", "[", "0", "]", ")", "\n", "if", "print_10_output_for_debugging", ":", "\n", "            ", "for", "i", "in", "range", "(", "corr_instance_inds", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "if", "corr_instance_inds", "[", "i", "]", "==", "10", ":", "\n", "                    ", "ind_to_print", "=", "i", "\n", "break", "\n", "", "elif", "i", "==", "corr_instance_inds", ".", "shape", "[", "0", "]", "-", "1", ":", "\n", "                    ", "ind_to_print", "=", "None", "\n", "", "", "if", "ind_to_print", "is", "None", ":", "\n", "                ", "print", "(", "\"Finished processing instance 10 already; no further output for it\"", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "mod_output", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "ind_to_print", "]", ")", "\n", "", "input", "(", ")", "\n", "", "if", "first_time", "and", "get_attnvals_kljsdivs_for_first_inds", "is", "not", "None", ":", "\n", "            ", "old_log_dists", "=", "get_attnvals_kljsdivs_for_first_inds", "\n", "new_log_dists", "=", "mod_output", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "kl_divs", "=", "get_kl_div_of_dists", "(", "old_log_dists", ",", "new_log_dists", ",", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "js_divs", "=", "get_js_div_of_dists", "(", "old_log_dists", ",", "new_log_dists", ",", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "for", "i", "in", "range", "(", "cur_num_instances_remaining", ")", ":", "\n", "                ", "val_kldivs", "[", "i", "]", ".", "append", "(", "kl_divs", "[", "i", "]", ")", "\n", "val_kldivs", "[", "i", "]", ".", "append", "(", "js_divs", "[", "i", "]", ")", "\n", "", "", "_", ",", "new_labels", "=", "torch", ".", "max", "(", "mod_output", ",", "1", ")", "\n", "\n", "stayed_same_mask", "=", "(", "new_labels", "==", "original_labels", ")", "\n", "\n", "for", "i", "in", "range", "(", "cur_num_instances_remaining", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "if", "len", "(", "sorted_attn_inds", "[", "i", "]", ")", "==", "0", "and", "new_labels", "[", "i", "]", "==", "original_labels", "[", "i", "]", ":", "\n", "# this is one of the instances that doesn't need any input", "\n", "                ", "list_to_write", "=", "[", "int", "(", "corr_instance_inds", "[", "i", "]", ")", ",", "\n", "int", "(", "lens_of_attn_dists", "[", "i", "]", ")", ",", "\n", "-", "1", ",", "\n", "-", "1", ",", "\n", "-", "1", "]", "\n", "lists_to_write_to_file", ".", "append", "(", "list_to_write", ")", "\n", "stayed_same_mask", "[", "i", "]", "=", "0", "\n", "del", "lens_of_attn_dists", "[", "i", "]", "\n", "del", "original_attn_weights_zeroed", "[", "i", "]", "\n", "del", "sorted_attn_inds", "[", "i", "]", "\n", "", "elif", "new_labels", "[", "i", "]", "!=", "original_labels", "[", "i", "]", ":", "\n", "                ", "zeroed_weights", "=", "original_attn_weights_zeroed", "[", "i", "]", "\n", "list_to_write", "=", "[", "int", "(", "corr_instance_inds", "[", "i", "]", ")", ",", "\n", "int", "(", "lens_of_attn_dists", "[", "i", "]", ")", ",", "\n", "int", "(", "len", "(", "zeroed_weights", ")", ")", ",", "\n", "float", "(", "sum", "(", "zeroed_weights", ")", ")", ",", "\n", "float", "(", "len", "(", "zeroed_weights", ")", "/", "lens_of_attn_dists", "[", "i", "]", ")", "]", "\n", "lists_to_write_to_file", ".", "append", "(", "list_to_write", ")", "\n", "del", "lens_of_attn_dists", "[", "i", "]", "\n", "del", "original_attn_weights_zeroed", "[", "i", "]", "\n", "del", "sorted_attn_inds", "[", "i", "]", "\n", "\n", "", "", "corr_instance_inds", "=", "corr_instance_inds", "[", "stayed_same_mask", "]", "\n", "corr_vects", "=", "corr_vects", "[", "stayed_same_mask", "]", "\n", "new_attn_weights", "=", "new_attn_weights", "[", "stayed_same_mask", "]", "\n", "original_attn_weights", "=", "original_attn_weights", "[", "stayed_same_mask", "]", "\n", "original_labels", "=", "original_labels", "[", "stayed_same_mask", "]", "\n", "if", "len", "(", "lens_of_attn_dists", ")", "==", "0", ":", "\n", "            ", "done", "=", "True", "\n", "", "first_time", "=", "False", "\n", "\n", "", "lists_to_write_to_file", "=", "sorted", "(", "lists_to_write_to_file", ",", "key", "=", "(", "lambda", "x", ":", "x", "[", "0", "]", ")", ",", "reverse", "=", "False", ")", "\n", "if", "get_attnvals_kljsdivs_for_first_inds", "is", "not", "None", ":", "\n", "        ", "return", "lists_to_write_to_file", ",", "val_kldivs", "\n", "", "else", ":", "\n", "        ", "return", "lists_to_write_to_file", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_first_v_second_stats_for_batch": [[1178, 1236], ["test_model.make_zeroed_out_copies_for_highest_2ndhighest_lowest_2ndlowest", "allennlp.nn.util.move_to_device", "allennlp.nn.util.move_to_device", "allennlp.nn.util.move_to_device", "allennlp.nn.util.move_to_device", "allennlp.nn.util.move_to_device", "classifier", "classifier", "classifier", "classifier", "test_model.get_onerun_diff_from_original_stats", "test_model.get_onerun_diff_from_original_stats", "test_model.get_onerun_diff_from_original_stats", "test_model.get_onerun_diff_from_original_stats", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "len", "batch_results_lists.append", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.make_zeroed_out_copies_for_highest_2ndhighest_lowest_2ndlowest", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_onerun_diff_from_original_stats", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_onerun_diff_from_original_stats", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_onerun_diff_from_original_stats", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_onerun_diff_from_original_stats"], ["", "", "def", "get_first_v_second_stats_for_batch", "(", "next_available_ind", ",", "gpu", ",", "original_attn_weights", ",", "classifier", ",", "\n", "corresponding_vects", ",", "list_of_lens", ",", "list_of_original_log_np_arrays", ",", "\n", "zero_out_by", "=", "None", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "attn_zero_highest", ",", "attn_zero_2ndhighest", ",", "attn_zero_lowest", ",", "attn_zero_2ndlowest", "=", "make_zeroed_out_copies_for_highest_2ndhighest_lowest_2ndlowest", "(", "original_attn_weights", ",", "list_of_lens", ",", "\n", "other_arr_to_sort_by", "=", "zero_out_by", ")", "\n", "attn_zero_highest", ",", "attn_zero_2ndhighest", ",", "attn_zero_lowest", ",", "attn_zero_2ndlowest", "=", "Variable", "(", "attn_zero_highest", ")", ",", "Variable", "(", "attn_zero_2ndhighest", ")", ",", "Variable", "(", "attn_zero_lowest", ")", ",", "Variable", "(", "attn_zero_2ndlowest", ")", "\n", "\n", "attn_zero_highest", "=", "util", ".", "move_to_device", "(", "attn_zero_highest", ",", "gpu", ")", "\n", "attn_zero_2ndhighest", "=", "util", ".", "move_to_device", "(", "attn_zero_2ndhighest", ",", "gpu", ")", "\n", "attn_zero_lowest", "=", "util", ".", "move_to_device", "(", "attn_zero_lowest", ",", "gpu", ")", "\n", "attn_zero_2ndlowest", "=", "util", ".", "move_to_device", "(", "attn_zero_2ndlowest", ",", "gpu", ")", "\n", "corresponding_vects", "=", "util", ".", "move_to_device", "(", "corresponding_vects", ",", "gpu", ")", "\n", "\n", "output_dict_zero_highest", "=", "classifier", "(", "corresponding_vects", ",", "attn_zero_highest", ")", "\n", "output_dict_zero_second_highest", "=", "classifier", "(", "corresponding_vects", ",", "attn_zero_2ndhighest", ")", "\n", "output_dict_zero_lowest", "=", "classifier", "(", "corresponding_vects", ",", "attn_zero_lowest", ")", "\n", "output_dict_zero_second_lowest", "=", "classifier", "(", "corresponding_vects", ",", "attn_zero_2ndlowest", ")", "\n", "kl_divs_1", ",", "js_divs_1", ",", "decision_flips_arr_1", ",", "local_min_kl_1", ",", "num_neg_kl_1", ",", "local_min_js_1", ",", "num_neg_js_1", "=", "get_onerun_diff_from_original_stats", "(", "output_dict_zero_highest", ",", "list_of_original_log_np_arrays", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "kl_divs_2", ",", "js_divs_2", ",", "decision_flips_arr_2", ",", "local_min_kl_2", ",", "num_neg_kl_2", ",", "local_min_js_2", ",", "num_neg_js_2", "=", "get_onerun_diff_from_original_stats", "(", "output_dict_zero_second_highest", ",", "list_of_original_log_np_arrays", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "kl_divs_1_low", ",", "js_divs_1_low", ",", "decision_flips_arr_1_low", ",", "local_min_kl_1_low", ",", "num_neg_kl_1_low", ",", "local_min_js_1_low", ",", "num_neg_js_1_low", "=", "get_onerun_diff_from_original_stats", "(", "output_dict_zero_lowest", ",", "list_of_original_log_np_arrays", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "kl_divs_2_low", ",", "js_divs_2_low", ",", "decision_flips_arr_2_low", ",", "local_min_kl_2_low", ",", "num_neg_kl_2_low", ",", "local_min_js_2_low", ",", "num_neg_js_2_low", "=", "get_onerun_diff_from_original_stats", "(", "output_dict_zero_second_lowest", ",", "list_of_original_log_np_arrays", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "\n", "batch_results_lists", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "        ", "list_to_append", "=", "[", "str", "(", "next_available_ind", ")", ",", "\n", "str", "(", "kl_divs_1", "[", "i", "]", ")", ",", "\n", "str", "(", "js_divs_1", "[", "i", "]", ")", ",", "\n", "str", "(", "decision_flips_arr_1", "[", "i", "]", ")", ",", "\n", "str", "(", "kl_divs_2", "[", "i", "]", ")", ",", "\n", "str", "(", "js_divs_2", "[", "i", "]", ")", ",", "\n", "str", "(", "decision_flips_arr_2", "[", "i", "]", ")", ",", "\n", "str", "(", "kl_divs_1_low", "[", "i", "]", ")", ",", "\n", "str", "(", "js_divs_1_low", "[", "i", "]", ")", ",", "\n", "str", "(", "decision_flips_arr_1_low", "[", "i", "]", ")", ",", "\n", "str", "(", "kl_divs_2_low", "[", "i", "]", ")", ",", "\n", "str", "(", "js_divs_2_low", "[", "i", "]", ")", ",", "\n", "str", "(", "decision_flips_arr_2_low", "[", "i", "]", ")", "]", "\n", "batch_results_lists", ".", "append", "(", "list_to_append", ")", "\n", "next_available_ind", "+=", "1", "\n", "", "return", "next_available_ind", ",", "batch_results_lists", ",", "(", "(", "local_min_kl_1", ",", "num_neg_kl_1", ",", "local_min_js_1", ",", "num_neg_js_1", ")", ",", "\n", "(", "local_min_kl_2", ",", "num_neg_kl_2", ",", "local_min_js_2", ",", "num_neg_js_2", ")", ",", "\n", "(", "local_min_kl_1_low", ",", "num_neg_kl_1_low", ",", "local_min_js_1_low", ",", "\n", "num_neg_js_1_low", ")", ",", "\n", "(", "local_min_kl_2_low", ",", "num_neg_kl_2_low", ",", "local_min_js_2_low", ",", "\n", "num_neg_js_2_low", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_first_v_second_stats": [[1238, 1294], ["attn_tests_lib.IntermediateBatchIterator", "iter", "tqdm.tqdm", "print", "test_model.OriginalOutputDistIterator", "range", "numpy.array", "test_model.get_first_v_second_stats_for_batch", "range", "print", "print", "open", "f.write", "tqdm.tqdm", "int", "len", "np.array.append", "lists_to_write_to_file.append", "len", "len", "len", "f.write", "math.ceil", "next", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_first_v_second_stats_for_batch"], ["", "def", "get_first_v_second_stats", "(", "classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "original_output_filename", ",", "first_v_second_filename", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "batch_iterator", "=", "IntermediateBatchIterator", "(", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ")", "\n", "corr_output_yielder", "=", "iter", "(", "OriginalOutputDistIterator", "(", "original_output_filename", ")", ")", "\n", "next_available_ind", "=", "1", "\n", "lists_to_write_to_file", "=", "[", "]", "\n", "total_num_dist_calcs", "=", "0", "\n", "total_num_negative_kl_dist_calcs", "=", "0", "\n", "total_num_negative_js_dist_calcs", "=", "0", "\n", "min_calculated_kl", "=", "1000", "\n", "min_calculated_js", "=", "1000", "\n", "for", "batch_tup", "in", "tqdm", "(", "batch_iterator", ",", "total", "=", "int", "(", "ceil", "(", "batch_iterator", ".", "num_instances", "/", "batch_iterator", ".", "batch_size", ")", ")", ",", "\n", "desc", "=", "'Collecting highest-attn-weight vs second-highest-attn-weight stats'", ")", ":", "\n", "        ", "original_attn_weights", "=", "batch_tup", "[", "0", "]", "\n", "list_of_lens", "=", "batch_tup", "[", "2", "]", "\n", "\n", "list_of_original_log_np_arrays", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_lens", ")", ")", ":", "\n", "            ", "list_of_original_log_np_arrays", ".", "append", "(", "next", "(", "corr_output_yielder", ")", ")", "\n", "", "list_of_original_log_np_arrays", "=", "np", ".", "array", "(", "list_of_original_log_np_arrays", ")", "\n", "\n", "next_available_ind", ",", "list_of_batch_results", ",", "neg_calculation_artifacts_info_tup", "=", "get_first_v_second_stats_for_batch", "(", "next_available_ind", ",", "gpu", ",", "original_attn_weights", ",", "classifier", ",", "\n", "batch_tup", "[", "1", "]", ",", "batch_tup", "[", "2", "]", ",", "list_of_original_log_np_arrays", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "for", "batch_results_list", "in", "list_of_batch_results", ":", "\n", "            ", "lists_to_write_to_file", ".", "append", "(", "batch_results_list", ")", "\n", "", "total_num_dist_calcs", "+=", "(", "len", "(", "list_of_lens", ")", "*", "len", "(", "neg_calculation_artifacts_info_tup", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neg_calculation_artifacts_info_tup", ")", ")", ":", "\n", "            ", "local_tup", "=", "neg_calculation_artifacts_info_tup", "[", "i", "]", "\n", "if", "local_tup", "[", "0", "]", "<", "min_calculated_kl", ":", "\n", "                ", "min_calculated_kl", "=", "local_tup", "[", "0", "]", "\n", "", "total_num_negative_kl_dist_calcs", "+=", "local_tup", "[", "1", "]", "\n", "if", "local_tup", "[", "2", "]", "<", "min_calculated_js", ":", "\n", "                ", "min_calculated_js", "=", "local_tup", "[", "2", "]", "\n", "", "total_num_negative_js_dist_calcs", "+=", "local_tup", "[", "3", "]", "\n", "", "", "if", "total_num_dist_calcs", ">", "0", ":", "\n", "# at least one instance was iterated over", "\n", "        ", "print", "(", "str", "(", "total_num_negative_kl_dist_calcs", ")", "+", "' / '", "+", "str", "(", "total_num_dist_calcs", ")", "+", "\n", "' calculated KL divs from original output dist to modified outputs were negative; '", "+", "\n", "'lowest calculated KL div was '", "+", "str", "(", "min_calculated_kl", ")", "+", "\n", "' (should be close to 0. see test_divergences() in debugging.py for sanity checks)'", ")", "\n", "print", "(", "str", "(", "total_num_negative_js_dist_calcs", ")", "+", "' / '", "+", "str", "(", "total_num_dist_calcs", ")", "+", "\n", "' calculated JS divs from original output dist to modified outputs were negative; '", "+", "\n", "'lowest calculated JS div was '", "+", "str", "(", "min_calculated_js", ")", "+", "\n", "' (should be close to 0. see test_divergences() in debugging.py for sanity checks)'", ")", "\n", "\n", "", "with", "open", "(", "first_v_second_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'id,kl_div_zero_highest,js_div_zero_highest,dec_flip_highest,kl_div_zero_2ndhighest,'", "+", "\n", "'js_div_zero_2ndhighest,dec_flip_2ndhighest,kl_div_zero_lowest,js_div_zero_lowest,dec_flip_lowest,'", "+", "\n", "'kl_div_zero_2ndlowest,js_div_zero_2ndlowest,dec_flip_2ndlowest\\n'", ")", "\n", "for", "instance", "in", "tqdm", "(", "lists_to_write_to_file", ",", "desc", "=", "\"Writing 1st-v-2nd file\"", ")", ":", "\n", "            ", "f", ".", "write", "(", "instance", "[", "0", "]", "+", "','", "+", "instance", "[", "1", "]", "+", "','", "+", "instance", "[", "2", "]", "+", "','", "+", "instance", "[", "3", "]", "+", "','", "+", "instance", "[", "4", "]", "+", "\n", "','", "+", "instance", "[", "5", "]", "+", "','", "+", "instance", "[", "6", "]", "+", "','", "+", "instance", "[", "7", "]", "+", "','", "+", "instance", "[", "8", "]", "+", "','", "+", "\n", "instance", "[", "9", "]", "+", "','", "+", "instance", "[", "10", "]", "+", "','", "+", "instance", "[", "11", "]", "+", "','", "+", "instance", "[", "12", "]", "+", "'\\n'", ")", "\n", "", "", "print", "(", "\"Done making first-vs-second output file.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.do_unchanged_run_and_collect_results": [[1296, 1417], ["test_iterator", "test_iterator.get_num_batches", "tqdm.tqdm", "attn_tests_lib.load_log_unnormalized_attn_dists", "attn_tests_lib.load_attn_dists", "tqdm.tqdm", "print", "test_data._read", "allennlp.nn.util.move_to_device", "torch.sum().cpu().data.numpy().astype", "list", "model", "output_dict[].data.cpu().numpy", "numpy.argmax", "batch[].data.cpu().numpy", "test_model.get_entropy_of_dists", "range", "range", "test_model.get_two_highest_and_inds", "numpy.exp", "numpy.exp", "numpy.exp", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "list_to_add_to.append", "open", "f.write", "range", "f.write", "tqdm.tqdm", "tokens_.size", "tokens_.size", "tokens_[].view", "tokens_.new_zeros().float", "torch.nonzero", "inds_of_nonzero_rows.view.view", "sentence_level_mask.view.view", "allennlp.nn.util.get_text_field_mask().float", "print", "exit", "list_of_instance_infos.append", "len", "test_model.get_entropy_of_dists", "test_model.get_entropy_of_dists", "test_model.get_entropy_of_dists", "test_model.get_entropy_of_dists", "str", "f.write", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "f.write", "range", "f.write", "torch.sum().cpu().data.numpy", "output_dict[].data.cpu", "batch[].data.cpu", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "f.write", "tokens_.new_zeros", "allennlp.nn.util.get_text_field_mask", "len", "str", "str", "str", "str", "torch.sum().cpu", "torch.sum"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.load_log_unnormalized_attn_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.load_attn_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader._read", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_two_highest_and_inds", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists"], ["", "def", "do_unchanged_run_and_collect_results", "(", "model", ",", "test_iterator", ",", "test_data", ",", "gpu", ",", "attn_weight_filename", ",", "\n", "unchanged_results_filename", ",", "test_data_file", ",", "suppress_warnings", "=", "False", ",", "\n", "is_han", "=", "True", ")", ":", "\n", "    ", "test_generator", "=", "test_iterator", "(", "test_data", ".", "_read", "(", "test_data_file", ")", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "False", ")", "\n", "num_test_batches", "=", "test_iterator", ".", "get_num_batches", "(", "test_data", ")", "\n", "test_generator_tqdm", "=", "tqdm", "(", "test_generator", ",", "total", "=", "num_test_batches", ",", "desc", "=", "\"Collecting output stats\"", ")", "\n", "list_of_instance_infos", "=", "[", "]", "\n", "num_output_classes", "=", "None", "\n", "next_available_instance_ind", "=", "1", "# indexing starts at 1", "\n", "stop_at_10", "=", "False", "\n", "instance_inds_passed", "=", "0", "\n", "list_of_lengths", "=", "[", "]", "\n", "for", "batch", "in", "test_generator_tqdm", ":", "\n", "        ", "batch", "=", "util", ".", "move_to_device", "(", "batch", ",", "gpu", ")", "\n", "\n", "tokens_", "=", "batch", "[", "'tokens'", "]", "[", "'tokens'", "]", "\n", "if", "is_han", ":", "\n", "            ", "batch_size", "=", "tokens_", ".", "size", "(", "0", ")", "\n", "max_num_sents", "=", "tokens_", ".", "size", "(", "1", ")", "\n", "first_token_ind_in_each_sentence", "=", "tokens_", "[", ":", ",", ":", ",", "0", "]", ".", "view", "(", "batch_size", "*", "max_num_sents", ")", "\n", "sentence_level_mask", "=", "tokens_", ".", "new_zeros", "(", "batch_size", "*", "max_num_sents", ")", ".", "float", "(", ")", "\n", "inds_of_nonzero_rows", "=", "torch", ".", "nonzero", "(", "first_token_ind_in_each_sentence", ")", "\n", "inds_of_nonzero_rows", "=", "inds_of_nonzero_rows", ".", "view", "(", "inds_of_nonzero_rows", ".", "shape", "[", "0", "]", ")", "\n", "sentence_level_mask", "[", "inds_of_nonzero_rows", "]", "=", "1", "\n", "sentence_level_mask", "=", "sentence_level_mask", ".", "view", "(", "batch_size", ",", "max_num_sents", ")", "\n", "final_layer_mask", "=", "sentence_level_mask", "\n", "", "else", ":", "\n", "            ", "final_layer_mask", "=", "util", ".", "get_text_field_mask", "(", "{", "\"tokens\"", ":", "tokens_", "}", ")", ".", "float", "(", ")", "\n", "", "one_d_arr_of_lengths", "=", "torch", ".", "sum", "(", "final_layer_mask", ",", "dim", "=", "1", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "astype", "(", "int", ")", "\n", "list_of_lengths", "+=", "list", "(", "one_d_arr_of_lengths", ")", "\n", "\n", "output_dict", "=", "model", "(", "tokens", "=", "batch", "[", "'tokens'", "]", ")", "\n", "output_log_dists", "=", "output_dict", "[", "\"label_logits\"", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "instance_inds_passed", "+=", "output_log_dists", ".", "shape", "[", "0", "]", "\n", "if", "stop_at_10", "and", "instance_inds_passed", ">=", "10", ":", "\n", "            ", "num_from_end_to_backtrack", "=", "instance_inds_passed", "-", "10", "\n", "print", "(", "output_log_dists", "[", "output_log_dists", ".", "shape", "[", "0", "]", "-", "1", "-", "num_from_end_to_backtrack", "]", ")", "\n", "exit", "(", "1", ")", "\n", "", "if", "num_output_classes", "is", "None", ":", "\n", "            ", "num_output_classes", "=", "output_log_dists", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "assert", "num_output_classes", "==", "output_log_dists", ".", "shape", "[", "1", "]", "\n", "", "original_labels_guessed", "=", "np", ".", "argmax", "(", "output_log_dists", ",", "axis", "=", "1", ")", "\n", "actual_labels", "=", "batch", "[", "\"label\"", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "output_dist_entropies", "=", "get_entropy_of_dists", "(", "output_log_dists", ",", "\n", "[", "output_log_dists", ".", "shape", "[", "1", "]", "]", "*", "output_log_dists", ".", "shape", "[", "0", "]", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "for", "i", "in", "range", "(", "actual_labels", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "instance_info", "=", "[", "next_available_instance_ind", ",", "\n", "actual_labels", "[", "i", "]", ",", "\n", "original_labels_guessed", "[", "i", "]", ",", "\n", "output_log_dists", "[", "i", "]", ",", "# this is a 1-d array", "\n", "output_dist_entropies", "[", "i", "]", "]", "\n", "list_of_instance_infos", ".", "append", "(", "instance_info", ")", "\n", "next_available_instance_ind", "+=", "1", "\n", "\n", "", "", "log_attn_dists", ",", "corr_inds", "=", "load_log_unnormalized_attn_dists", "(", "attn_weight_filename", ")", "\n", "attn_dists", ",", "_", "=", "load_attn_dists", "(", "attn_weight_filename", ")", "\n", "total_num_instances", "=", "next_available_instance_ind", "-", "1", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "attn_dists", ")", ")", ",", "total", "=", "total_num_instances", ",", "desc", "=", "\"Collecting corresponding attn stats\"", ")", ":", "\n", "        ", "corr_ind", "=", "corr_inds", "[", "i", "]", "\n", "attn_vals", "=", "attn_dists", "[", "i", "]", "\n", "log_attn_vals", "=", "log_attn_dists", "[", "i", "]", "\n", "attn_entropy", "=", "get_entropy_of_dists", "(", "np", ".", "array", "(", "[", "log_attn_vals", "]", ")", ",", "[", "len", "(", "log_attn_vals", ")", "]", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "[", "0", "]", "\n", "_", ",", "ind_of_highest", ",", "_", ",", "ind_of_second_highest", ",", "_", ",", "ind_of_lowest", ",", "_", ",", "ind_of_second_lowest", "=", "get_two_highest_and_inds", "(", "log_attn_vals", ",", "dont_check_at_ind_x_or_greater", "=", "list_of_lengths", "[", "i", "]", ")", "\n", "ratio_of_2nd_to_1st", "=", "np", ".", "exp", "(", "log_attn_vals", "[", "ind_of_second_highest", "]", "-", "log_attn_vals", "[", "ind_of_highest", "]", ")", "\n", "ratio_of_2nd_to_1st_low", "=", "np", ".", "exp", "(", "log_attn_vals", "[", "ind_of_second_lowest", "]", "-", "log_attn_vals", "[", "ind_of_lowest", "]", ")", "\n", "entropy_of_1st_2nd_dist", "=", "get_entropy_of_dists", "(", "np", ".", "array", "(", "[", "[", "log_attn_vals", "[", "ind_of_highest", "]", ",", "\n", "log_attn_vals", "[", "ind_of_second_highest", "]", "]", "]", ")", ",", "[", "2", "]", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "[", "0", "]", "\n", "entropy_of_1st_2nd_dist_low", "=", "get_entropy_of_dists", "(", "np", ".", "array", "(", "[", "[", "log_attn_vals", "[", "ind_of_lowest", "]", ",", "\n", "log_attn_vals", "[", "ind_of_second_lowest", "]", "]", "]", ")", ",", "[", "2", "]", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "[", "0", "]", "\n", "ratio_of_last_to_1st", "=", "np", ".", "exp", "(", "log_attn_vals", "[", "ind_of_lowest", "]", "-", "log_attn_vals", "[", "ind_of_highest", "]", ")", "\n", "entropy_of_last_1st_dist", "=", "get_entropy_of_dists", "(", "np", ".", "array", "(", "[", "[", "log_attn_vals", "[", "ind_of_lowest", "]", ",", "\n", "log_attn_vals", "[", "ind_of_highest", "]", "]", "]", ")", ",", "[", "2", "]", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "[", "0", "]", "\n", "assert", "list_of_instance_infos", "[", "corr_ind", "-", "1", "]", "[", "0", "]", "==", "corr_ind", ",", "str", "(", "list_of_instance_infos", "[", "corr_ind", "-", "1", "]", "[", "0", "]", ")", "+", "\", \"", "+", "str", "(", "corr_ind", ")", "\n", "list_to_add_to", "=", "list_of_instance_infos", "[", "corr_ind", "-", "1", "]", "\n", "list_to_add_to", ".", "append", "(", "attn_entropy", ")", "\n", "list_to_add_to", ".", "append", "(", "ratio_of_2nd_to_1st", ")", "\n", "list_to_add_to", ".", "append", "(", "entropy_of_1st_2nd_dist", ")", "\n", "list_to_add_to", ".", "append", "(", "ratio_of_2nd_to_1st_low", ")", "\n", "list_to_add_to", ".", "append", "(", "entropy_of_1st_2nd_dist_low", ")", "\n", "list_to_add_to", ".", "append", "(", "ratio_of_last_to_1st", ")", "\n", "list_to_add_to", ".", "append", "(", "entropy_of_last_1st_dist", ")", "\n", "\n", "", "with", "open", "(", "unchanged_results_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"id,actual_label,orig_label_guessed,output_entropy,attn_entropy,\"", "+", "\n", "\"weight1st2nd_ratio_high,weight1st2nd_entropy_high,weight1st2nd_ratio_low,weight1st2nd_entropy_low,\"", "+", "\n", "\"weight1stlast_ratio,weight1stlast_entropy,\"", ")", "\n", "for", "i", "in", "range", "(", "num_output_classes", "-", "1", ")", ":", "\n", "            ", "f", ".", "write", "(", "\"log_output_val_\"", "+", "str", "(", "i", ")", "+", "\",\"", ")", "\n", "", "f", ".", "write", "(", "\"log_output_val_\"", "+", "str", "(", "num_output_classes", "-", "1", ")", "+", "\"\\n\"", ")", "\n", "\n", "for", "instance_info", "in", "tqdm", "(", "list_of_instance_infos", ",", "desc", "=", "\"Writing original-model stats to file\"", ")", ":", "\n", "            ", "id", "=", "str", "(", "instance_info", "[", "0", "]", ")", "\n", "actual_label", "=", "str", "(", "instance_info", "[", "1", "]", ")", "\n", "orig_label_guessed", "=", "str", "(", "instance_info", "[", "2", "]", ")", "\n", "output_entropy", "=", "str", "(", "instance_info", "[", "4", "]", ")", "\n", "attn_entropy", "=", "str", "(", "instance_info", "[", "5", "]", ")", "\n", "weight1st2nd_ratio", "=", "str", "(", "instance_info", "[", "6", "]", ")", "\n", "weight1st2nd_entropy", "=", "str", "(", "instance_info", "[", "7", "]", ")", "\n", "weight1st2nd_ratio_low", "=", "str", "(", "instance_info", "[", "8", "]", ")", "\n", "weight1st2nd_entropy_low", "=", "str", "(", "instance_info", "[", "9", "]", ")", "\n", "weight1stlast_ratio", "=", "str", "(", "instance_info", "[", "10", "]", ")", "\n", "weight1stlast_entropy", "=", "str", "(", "instance_info", "[", "11", "]", ")", "\n", "output_vals", "=", "instance_info", "[", "3", "]", "\n", "f", ".", "write", "(", "id", "+", "','", "+", "actual_label", "+", "','", "+", "orig_label_guessed", "+", "','", "+", "output_entropy", "+", "','", "+", "\n", "attn_entropy", "+", "','", "+", "weight1st2nd_ratio", "+", "','", "+", "weight1st2nd_entropy", "+", "','", "+", "\n", "weight1st2nd_ratio_low", "+", "','", "+", "weight1st2nd_entropy_low", "+", "','", "+", "weight1stlast_ratio", "+", "','", "+", "\n", "weight1stlast_entropy", "+", "','", ")", "\n", "for", "i", "in", "range", "(", "num_output_classes", "-", "1", ")", ":", "\n", "                ", "f", ".", "write", "(", "str", "(", "output_vals", "[", "i", "]", ")", "+", "','", ")", "\n", "", "f", ".", "write", "(", "str", "(", "output_vals", "[", "num_output_classes", "-", "1", "]", ")", "+", "'\\n'", ")", "\n", "", "", "print", "(", "\"Done running tests on original model.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.run_tests": [[1419, 1478], ["os.path.isfile", "test_model.get_batch_size_max_samples_per_batch_from_config_file", "test_model.set_up_inorder_test_loader", "test_model.load_testing_models_in_eval_mode_from_serialization_dir", "test_model.do_unchanged_run_and_collect_results", "test_model.get_first_v_second_stats", "test_model.get_dec_flip_stats_and_rand", "test_model.get_gradient_and_gradmult_based_stats", "test_model.get_dec_flip_stats_for_rand_nontop", "test_model.get_attn_div_from_unif_stats", "test_model.get_gradient_and_gradmult_based_stats", "test_model.get_dec_flip_stats_for_rand_nontop", "test_model.get_dec_flip_stats_for_rand_nontop", "test_model.get_dec_flip_stats_for_rand_nontop", "s_dir.endswith", "output_dir.endswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_batch_size_max_samples_per_batch_from_config_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.set_up_inorder_test_loader", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.load_testing_models_in_eval_mode_from_serialization_dir", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.do_unchanged_run_and_collect_results", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_first_v_second_stats", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_stats_and_rand", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_gradient_and_gradmult_based_stats", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_stats_for_rand_nontop", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_attn_div_from_unif_stats", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_gradient_and_gradmult_based_stats", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_stats_for_rand_nontop", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_stats_for_rand_nontop", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_dec_flip_stats_for_rand_nontop"], ["", "def", "run_tests", "(", "s_dir", ",", "output_dir", ",", "test_data_file", ",", "attn_layer_to_replace", ",", "attn_weight_filename", ",", "\n", "name_of_layer_to_replace", ",", "gpu", ",", "loading_han", ",", "suppress_warnings", "=", "False", ")", ":", "\n", "    ", "if", "not", "s_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "s_dir", "+=", "'/'", "\n", "", "training_config_filename", "=", "s_dir", "+", "\"config.json\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "training_config_filename", ")", ",", "\"Could not find \"", "+", "training_config_filename", "\n", "batch_size", ",", "max_samples_per_batch", ",", "vocab_dir", "=", "get_batch_size_max_samples_per_batch_from_config_file", "(", "training_config_filename", ")", "\n", "dataset_reader", ",", "dataset_iterator", ",", "total_num_test_instances", "=", "set_up_inorder_test_loader", "(", "test_data_file", ",", "batch_size", ",", "max_samples_per_batch", ",", "vocab_dir", ",", "s_dir", ",", "\n", "loading_han", "=", "loading_han", ")", "\n", "if", "not", "output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "output_dir", "+=", "'/'", "\n", "", "corr_vector_dir", "=", "output_dir", "+", "name_of_layer_to_replace", "+", "'_corresponding_vects/'", "\n", "unchanged_results_filename", "=", "output_dir", "+", "unchanged_fname", "\n", "first_v_second_filename", "=", "output_dir", "+", "first_v_second_fname", "\n", "dec_flip_stats_filename", "=", "output_dir", "+", "dec_flip_stats_fname", "\n", "rand_results_filename", "=", "output_dir", "+", "rand_results_fname", "\n", "grad_based_stats_filename", "=", "output_dir", "+", "grad_based_stats_fname", "\n", "dec_flip_rand_nontopbyattn_stats_filename", "=", "output_dir", "+", "dec_flip_rand_nontop_stats_fname", "\n", "attn_div_from_unif_filename", "=", "output_dir", "+", "attn_div_from_unif_fname", "\n", "gradsignmult_based_stats_filename", "=", "output_dir", "+", "gradsignmult_based_stats_fname", "\n", "dec_flip_rand_nontopbygrad_stats_filename", "=", "output_dir", "+", "dec_flip_rand_nontopbygrad_stats_fname", "\n", "dec_flip_rand_nontopbygradmult_stats_filename", "=", "output_dir", "+", "dec_flip_rand_nontopbygradmult_stats_fname", "\n", "dec_flip_rand_nontopbygradsignmult_stats_filename", "=", "output_dir", "+", "dec_flip_rand_nontopbygradsignmult_stats_fname", "\n", "model", ",", "just_the_classifier", "=", "load_testing_models_in_eval_mode_from_serialization_dir", "(", "s_dir", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "\n", "total_num_test_instances", ",", "training_config_filename", ",", "\n", "name_of_attn_layer_to_replace", "=", "attn_layer_to_replace", ",", "\n", "cuda_device", "=", "gpu", ")", "\n", "do_unchanged_run_and_collect_results", "(", "model", ",", "dataset_iterator", ",", "dataset_reader", ",", "gpu", ",", "attn_weight_filename", ",", "\n", "unchanged_results_filename", ",", "test_data_file", ",", "is_han", "=", "loading_han", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_first_v_second_stats", "(", "just_the_classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "unchanged_results_filename", ",", "first_v_second_filename", ",", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_dec_flip_stats_and_rand", "(", "just_the_classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "unchanged_results_filename", ",", "dec_flip_stats_filename", ",", "rand_results_filename", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_gradient_and_gradmult_based_stats", "(", "just_the_classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "unchanged_results_filename", ",", "grad_based_stats_filename", ",", "\n", "grads_have_already_been_collected", "=", "False", ",", "function_of_grad", "=", "'grad_and_gradmult'", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_dec_flip_stats_for_rand_nontop", "(", "just_the_classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "unchanged_results_filename", ",", "dec_flip_rand_nontopbyattn_stats_filename", ",", "\n", "order_type", "=", "'attn'", ",", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_attn_div_from_unif_stats", "(", "attn_weight_filename", ",", "attn_div_from_unif_filename", ",", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_gradient_and_gradmult_based_stats", "(", "just_the_classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "unchanged_results_filename", ",", "gradsignmult_based_stats_filename", ",", "\n", "grads_have_already_been_collected", "=", "True", ",", "function_of_grad", "=", "'gradsignmult'", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_dec_flip_stats_for_rand_nontop", "(", "just_the_classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "unchanged_results_filename", ",", "dec_flip_rand_nontopbygrad_stats_filename", ",", "\n", "order_type", "=", "'grad'", ",", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_dec_flip_stats_for_rand_nontop", "(", "just_the_classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "unchanged_results_filename", ",", "dec_flip_rand_nontopbygradmult_stats_filename", ",", "\n", "order_type", "=", "'gradmult'", ",", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "get_dec_flip_stats_for_rand_nontop", "(", "just_the_classifier", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "gpu", ",", "\n", "unchanged_results_filename", ",", "dec_flip_rand_nontopbygradsignmult_stats_filename", ",", "\n", "order_type", "=", "'gradsignmult'", ",", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.main": [[1480, 1547], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "allennlp.common.util.import_submodules", "allennlp.common.util.import_submodules", "parser.parse_args.print_all_warnings.lower().startswith", "os.path.isdir", "test_model.run_tests", "parser.parse_args.base_serialized_models_dir.endswith", "parser.parse_args.base_data_dir.endswith", "parser.parse_args.base_output_dir.endswith", "os.path.isdir", "os.makedirs", "parser.parse_args.model_folder_name.endswith", "output_dir.endswith", "parser.parse_args.print_all_warnings.lower", "print", "exit"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.run_tests"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--model-folder-name\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The local name of the serialization directory used while training the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test-data-file\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The file containing the test data\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--gpu\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Which GPU device to run the testing on\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--optional-folder-tag\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "''", ",", "\n", "help", "=", "'Tag to tack onto output folder'", ")", "\n", "parser", ".", "add_argument", "(", "\"--print-all-warnings\"", ",", "required", "=", "False", ",", "type", "=", "str", ",", "default", "=", "'False'", ",", "\n", "help", "=", "'Whether to print all negative-entropy-calculation warnings instead of just a summary'", ")", "\n", "parser", ".", "add_argument", "(", "\"--base-serialized-models-dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "base_serialized_models_directory", ",", "\n", "help", "=", "\"The dir to prepend to --model-folder-name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--base-data-dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "base_data_directory", ",", "\n", "help", "=", "\"The dir to prepend to --test-data-file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--base-output-dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "base_output_directory", ",", "\n", "help", "=", "\"The local name of the output directory for this training run\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--attn-weight-filename\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "'attn_weights_by_instance.txt'", ",", "\n", "help", "=", "'The local name of the file that will contain the attn weights'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "import_submodules", "(", "'attn_tests_lib'", ")", "\n", "import_submodules", "(", "'textcat'", ")", "\n", "\n", "if", "args", ".", "print_all_warnings", ".", "lower", "(", ")", ".", "startswith", "(", "'f'", ")", ":", "\n", "        ", "suppress_warnings", "=", "True", "\n", "", "else", ":", "\n", "        ", "suppress_warnings", "=", "False", "\n", "", "is_han", "=", "(", "'-han'", "in", "args", ".", "model_folder_name", ")", "\n", "if", "is_han", ":", "\n", "        ", "attn_layer_to_replace", "=", "\"_sentence_attention\"", "\n", "model_is_han", "=", "True", "\n", "", "elif", "not", "is_han", ":", "\n", "        ", "attn_layer_to_replace", "=", "\"_word_attention\"", "\n", "model_is_han", "=", "False", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"ERROR: haven't yet specified which attn layer to replace if not han.\"", ")", "\n", "exit", "(", "1", ")", "\n", "", "if", "not", "args", ".", "base_serialized_models_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "args", ".", "base_serialized_models_dir", "+=", "'/'", "\n", "", "if", "not", "args", ".", "base_data_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "args", ".", "base_data_dir", "+=", "'/'", "\n", "", "if", "not", "args", ".", "base_output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "args", ".", "base_output_dir", "+=", "'/'", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "base_output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "base_output_dir", ")", "\n", "", "if", "not", "args", ".", "model_folder_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "args", ".", "model_folder_name", "+=", "'/'", "\n", "", "assert", "os", ".", "path", ".", "isdir", "(", "args", ".", "base_output_dir", ")", "\n", "output_dir", "=", "args", ".", "base_output_dir", "+", "args", ".", "model_folder_name", "\n", "if", "args", ".", "optional_folder_tag", "!=", "''", ":", "\n", "        ", "output_dir", "=", "output_dir", "[", ":", "-", "1", "]", "+", "'-'", "+", "args", ".", "optional_folder_tag", "\n", "", "if", "not", "output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "output_dir", "+=", "'/'", "\n", "", "args", ".", "attn_weight_filename", "=", "output_dir", "+", "attn_layer_to_replace", "+", "'_'", "+", "args", ".", "attn_weight_filename", "\n", "args", ".", "model_folder_name", "=", "args", ".", "base_serialized_models_dir", "+", "args", ".", "model_folder_name", "\n", "args", ".", "test_data_file", "=", "args", ".", "base_data_dir", "+", "args", ".", "test_data_file", "\n", "run_tests", "(", "args", ".", "model_folder_name", ",", "output_dir", ",", "args", ".", "test_data_file", ",", "attn_layer_to_replace", ",", "\n", "args", ".", "attn_weight_filename", ",", "attn_layer_to_replace", ",", "args", ".", "gpu", ",", "model_is_han", ",", "\n", "suppress_warnings", "=", "suppress_warnings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.datasets_from_params": [[17, 50], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.from_params", "params.pop", "params.pop", "logger.info", "DatasetReader.from_params.read", "params.pop", "params.pop", "params.pop", "logger.info", "allennlp.data.dataset_readers.dataset_reader.DatasetReader.from_params", "logger.info", "DatasetReader.from_params.read", "logger.info", "DatasetReader.from_params.read"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params"], ["def", "datasets_from_params", "(", "params", ":", "Params", ")", "->", "Dict", "[", "str", ",", "Iterable", "[", "Instance", "]", "]", ":", "\n", "    ", "\"\"\"\n    This method is just copied from AllenNLP.\n\n    Load all the datasets specified by the config.\n    \"\"\"", "\n", "dataset_reader", "=", "DatasetReader", ".", "from_params", "(", "params", ".", "pop", "(", "'dataset_reader'", ")", ")", "\n", "validation_dataset_reader_params", "=", "params", ".", "pop", "(", "\"validation_dataset_reader\"", ",", "None", ")", "\n", "\n", "validation_and_test_dataset_reader", ":", "DatasetReader", "=", "dataset_reader", "\n", "if", "validation_dataset_reader_params", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using a separate dataset reader to load validation and test data.\"", ")", "\n", "validation_and_test_dataset_reader", "=", "DatasetReader", ".", "from_params", "(", "validation_dataset_reader_params", ")", "\n", "\n", "", "train_data_path", "=", "params", ".", "pop", "(", "'train_data_path'", ")", "\n", "logger", ".", "info", "(", "\"Reading training data from %s\"", ",", "train_data_path", ")", "\n", "train_data", "=", "dataset_reader", ".", "read", "(", "train_data_path", ")", "\n", "\n", "datasets", ":", "Dict", "[", "str", ",", "Iterable", "[", "Instance", "]", "]", "=", "{", "\"train\"", ":", "train_data", "}", "\n", "\n", "validation_data_path", "=", "params", ".", "pop", "(", "'validation_data_path'", ",", "None", ")", "\n", "if", "validation_data_path", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Reading validation data from %s\"", ",", "validation_data_path", ")", "\n", "validation_data", "=", "validation_and_test_dataset_reader", ".", "read", "(", "validation_data_path", ")", "\n", "datasets", "[", "\"validation\"", "]", "=", "validation_data", "\n", "\n", "", "test_data_path", "=", "params", ".", "pop", "(", "\"test_data_path\"", ",", "None", ")", "\n", "if", "test_data_path", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Reading test data from %s\"", ",", "test_data_path", ")", "\n", "test_data", "=", "validation_and_test_dataset_reader", ".", "read", "(", "test_data_path", ")", "\n", "datasets", "[", "\"test\"", "]", "=", "test_data", "\n", "\n", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.debug_vocab": [[52, 134], ["allennlp.common.Params.from_file", "allennlp.common.util.prepare_global_logging", "allennlp.common.checks.check_for_gpu", "debugging.datasets_from_params", "set", "logger.info", "allennlp.data.Vocabulary.from_params", "allennlp.models.model.Model.from_params", "print", "print", "print", "print", "print", "any", "print", "print", "print", "print", "any", "print", "print", "Params.from_file.get().get", "Params.from_file.pop", "Params.from_file.pop", "allennlp.common.checks.ConfigurationError", "Params.from_file.pop", "str", "str", "allennlp.common.util.namespace_match", "str", "str", "str", "allennlp.common.util.namespace_match", "str", "str", "Params.from_file.get", "datasets_from_params.items", "list", "len", "len"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.datasets_from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params"], ["", "def", "debug_vocab", "(", "parameter_filename", ":", "str", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "overrides", ":", "str", "=", "\"\"", ",", "\n", "file_friendly_logging", ":", "bool", "=", "False", ",", "\n", "recover", ":", "bool", "=", "False", ",", "\n", "force", ":", "bool", "=", "False", ")", "->", "Model", ":", "\n", "    ", "\"\"\"\n    A wrapper around :func:`train_model` which loads the params from a file.\n\n    Parameters\n    ----------\n    parameter_filename : ``str``\n        A json parameter file specifying an AllenNLP experiment.\n    serialization_dir : ``str``\n        The directory in which to save results and logs. We just pass this along to\n        :func:`train_model`.\n    overrides : ``str``\n        A JSON string that we will use to override values in the input parameter file.\n    file_friendly_logging : ``bool``, optional (default=False)\n        If ``True``, we make our output more friendly to saved model files.  We just pass this\n        along to :func:`train_model`.\n    recover : ``bool`, optional (default=False)\n        If ``True``, we will try to recover a training run from an existing serialization\n        directory.  This is only intended for use when something actually crashed during the middle\n        of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n    force : ``bool``, optional (default=False)\n        If ``True``, we will overwrite the serialization directory if it already exists.\n    \"\"\"", "\n", "# Load the experiment config from a file and pass it to ``train_model``.", "\n", "params", "=", "Params", ".", "from_file", "(", "parameter_filename", ",", "overrides", ")", "\n", "\n", "prepare_global_logging", "(", "serialization_dir", ",", "file_friendly_logging", ")", "\n", "\n", "check_for_gpu", "(", "params", ".", "get", "(", "'trainer'", ")", ".", "get", "(", "'cuda_device'", ",", "-", "1", ")", ")", "\n", "\n", "all_datasets", "=", "datasets_from_params", "(", "params", ")", "\n", "datasets_for_vocab_creation", "=", "set", "(", "params", ".", "pop", "(", "\"datasets_for_vocab_creation\"", ",", "all_datasets", ")", ")", "\n", "\n", "for", "dataset", "in", "datasets_for_vocab_creation", ":", "\n", "        ", "if", "dataset", "not", "in", "all_datasets", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"invalid 'dataset_for_vocab_creation' {dataset}\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"From dataset instances, %s will be considered for vocabulary creation.\"", ",", "\n", "\", \"", ".", "join", "(", "datasets_for_vocab_creation", ")", ")", "\n", "vocab", "=", "Vocabulary", ".", "from_params", "(", "\n", "params", ".", "pop", "(", "\"vocabulary\"", ",", "{", "}", ")", ",", "\n", "(", "instance", "for", "key", ",", "dataset", "in", "all_datasets", ".", "items", "(", ")", "\n", "for", "instance", "in", "dataset", "\n", "if", "key", "in", "datasets_for_vocab_creation", ")", "\n", ")", "\n", "\n", "model", "=", "Model", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "params", ".", "pop", "(", "'model'", ")", ")", "\n", "\n", "vocab", "=", "model", ".", "vocab", "\n", "vocab_namespace_dict", "=", "vocab", ".", "_token_to_index", "\n", "vocab_oov_token", "=", "vocab", ".", "_oov_token", "\n", "vocab_non_padded_namespaces", "=", "vocab", ".", "_non_padded_namespaces", "# this is a set", "\n", "\n", "vocab_tokens_dict", "=", "vocab_namespace_dict", "[", "'tokens'", "]", "\n", "vocab_labels_dict", "=", "vocab_namespace_dict", "[", "'labels'", "]", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"Vocab's OOV token: \"", "+", "vocab_oov_token", ")", "\n", "print", "(", "\"Non-padded namespaces in vocab: \"", "+", "str", "(", "list", "(", "vocab_non_padded_namespaces", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n", "print", "(", "\"Number of words in vocab's tokens dict: \"", "+", "str", "(", "len", "(", "vocab_tokens_dict", ")", ")", ")", "\n", "if", "any", "(", "namespace_match", "(", "pattern", ",", "'tokens'", ")", "for", "pattern", "in", "vocab_non_padded_namespaces", ")", ":", "\n", "        ", "is_padded", "=", "False", "\n", "", "else", ":", "\n", "        ", "is_padded", "=", "True", "\n", "", "print", "(", "\"tokens will return True for is_padded: \"", "+", "str", "(", "is_padded", ")", ")", "\n", "print", "(", "\"Vocab's OOV token is in its tokens dict (should be True): \"", "+", "str", "(", "vocab_oov_token", "in", "vocab_tokens_dict", ")", ")", "\n", "print", "(", ")", "\n", "\n", "print", "(", "\"Number of words in vocab's labels dict: \"", "+", "str", "(", "len", "(", "vocab_labels_dict", ")", ")", ")", "\n", "if", "any", "(", "namespace_match", "(", "pattern", ",", "'labels'", ")", "for", "pattern", "in", "vocab_non_padded_namespaces", ")", ":", "\n", "        ", "is_padded", "=", "False", "\n", "", "else", ":", "\n", "        ", "is_padded", "=", "True", "\n", "", "print", "(", "\"labels will return True for is_padded: \"", "+", "str", "(", "is_padded", ")", ")", "\n", "print", "(", "\"Vocab's OOV token is in its labels dict (should be False): \"", "+", "str", "(", "vocab_oov_token", "in", "vocab_labels_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.load_config_file_print_params": [[136, 139], ["allennlp.common.Params.from_file", "debugging.print_params_at_depth"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.print_params_at_depth"], ["", "def", "load_config_file_print_params", "(", "params_fname", ":", "str", ",", "param_depth", ":", "int", "=", "-", "1", ")", ":", "\n", "    ", "params", "=", "Params", ".", "from_file", "(", "params_fname", ")", "\n", "print_params_at_depth", "(", "params", ",", "1", ",", "depth_cap", "=", "param_depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.print_params_at_depth": [[141, 155], ["isinstance", "item.keys", "print", "isinstance", "print", "print", "debugging.print_params_at_depth", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.print_params_at_depth"], ["", "def", "print_params_at_depth", "(", "item", ",", "cur_depth", ":", "int", ",", "depth_cap", ":", "int", ")", ":", "\n", "    ", "if", "depth_cap", "!=", "-", "1", "and", "cur_depth", ">", "depth_cap", ":", "\n", "        ", "return", "\n", "", "tab_prepend", "=", "''", "\n", "if", "cur_depth", ">=", "1", ":", "\n", "        ", "tab_prepend", "=", "''", ".", "join", "(", "[", "'\\t'", "]", "*", "(", "cur_depth", "-", "1", ")", ")", "\n", "", "if", "isinstance", "(", "item", ",", "Params", ")", ":", "\n", "        ", "for", "key", "in", "item", ".", "keys", "(", ")", ":", "\n", "            ", "print", "(", "tab_prepend", "+", "key", ",", "end", "=", "''", ")", "\n", "if", "not", "isinstance", "(", "item", "[", "key", "]", ",", "Params", ")", ":", "\n", "                ", "print", "(", "\" : \"", "+", "str", "(", "item", "[", "key", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", ")", "\n", "print_params_at_depth", "(", "item", "[", "key", "]", ",", "cur_depth", "+", "1", ",", "depth_cap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.calculate_nonlog_kl_divergence": [[157, 163], ["range", "len", "len", "len", "numpy.log"], "function", ["None"], ["", "", "", "", "def", "calculate_nonlog_kl_divergence", "(", "from_dist", ",", "to_dist", ")", ":", "\n", "    ", "assert", "len", "(", "from_dist", ")", "==", "len", "(", "to_dist", ")", "\n", "total", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "from_dist", ")", ")", ":", "\n", "        ", "total", "+=", "to_dist", "[", "i", "]", "*", "np", ".", "log", "(", "to_dist", "[", "i", "]", "/", "from_dist", "[", "i", "]", ")", "\n", "", "return", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.calculate_nonlog_js_divergence": [[165, 172], ["range", "len", "len", "len", "midpoint_dist.append", "debugging.calculate_nonlog_kl_divergence", "debugging.calculate_nonlog_kl_divergence"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.calculate_nonlog_kl_divergence", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.calculate_nonlog_kl_divergence"], ["", "def", "calculate_nonlog_js_divergence", "(", "from_dist", ",", "to_dist", ")", ":", "\n", "    ", "assert", "len", "(", "from_dist", ")", "==", "len", "(", "to_dist", ")", "\n", "midpoint_dist", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "from_dist", ")", ")", ":", "\n", "        ", "midpoint_dist", ".", "append", "(", "(", "from_dist", "[", "i", "]", "+", "to_dist", "[", "i", "]", ")", "/", "2", ")", "\n", "", "return", ".5", "*", "calculate_nonlog_kl_divergence", "(", "midpoint_dist", ",", "from_dist", ")", "+", ".5", "*", "calculate_nonlog_kl_divergence", "(", "midpoint_dist", ",", "to_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.test_divergences": [[174, 239], ["print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.array", "numpy.array", "numpy.log", "numpy.log", "get_kl_div_of_dists", "get_js_div_of_dists", "print", "print", "print", "print", "print", "get_kl_div_of_dists", "get_js_div_of_dists", "print", "print", "print", "print", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "debugging.calculate_nonlog_kl_divergence", "debugging.calculate_nonlog_js_divergence", "debugging.calculate_nonlog_kl_divergence", "debugging.calculate_nonlog_js_divergence"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_kl_div_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_js_div_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_kl_div_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_js_div_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.calculate_nonlog_kl_divergence", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.calculate_nonlog_js_divergence", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.calculate_nonlog_kl_divergence", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.debugging.calculate_nonlog_js_divergence"], ["", "def", "test_divergences", "(", ")", ":", "\n", "\n", "\n", "    ", "\"\"\"# Calculated a kl div of -0.11142599918864647\n    log_dist_from = np.array([[-5.320183, -5.004407, -3.739851, -2.4476514, -1.146145, 0.20984331, 1.1307197, 0.9277696, -0.45606202, -1.5285392]])#np.array([[-1.704001, -0.21752474, 0.46928683, 1.1984, 1.8707601, 0.4779932,\n                    #           -1.3708279, -3.6425877, -5.238203, -6.296172]])\n    log_dist_to = np.array([[-5.3201814, -5.004406, -3.7398503, -2.4476511, -1.1461449, 0.20984319, 1.1307195, 0.92776954, -0.45606202, -1.5285391]])#np.array([[-1.7040007, -0.21752474, 0.4692869, 1.1984, 1.8707601, 0.47799325,\n                  #           -1.3708278, -3.6425874, -5.238202, -6.296171]])\n\n    log_dist_from = np.load(\"log_arr_from.npy\")\n    log_dist_to = np.load(\"log_arr_to.npy\")\n    log_dist_from = np.reshape(log_dist_from, (1, log_dist_from.shape[0]))\n    log_dist_to = np.reshape(log_dist_to, (1, log_dist_to.shape[0]))\n\n\n    log_dist_from_preexp = log_dist_from[0] - logsumexp(log_dist_from[0])\n    dist_from = list(np.exp(log_dist_from_preexp))\n    log_dist_to_preexp = log_dist_to[0] - logsumexp(log_dist_to[0])\n    dist_to = list(np.exp(log_dist_to_preexp))\n\n    print(log_dist_from_preexp)\n    print(log_dist_to_preexp)\n    print()\"\"\"", "\n", "\n", "dist_from", "=", "[", ".6", ",", ".3", ",", ".1", "]", "\n", "dist_to", "=", "[", ".2", ",", ".4", ",", ".4", "]", "\n", "dist_from_2", "=", "[", ".7", ",", ".1", ",", ".2", "]", "\n", "dist_to_2", "=", "[", ".6", ",", ".3", ",", ".1", "]", "\n", "\n", "print", "(", "dist_from", ")", "\n", "print", "(", "dist_to", ")", "\n", "\n", "print", "(", "\"Actual KL divergence: \"", "+", "str", "(", "calculate_nonlog_kl_divergence", "(", "dist_from", ",", "dist_to", ")", ")", ")", "\n", "print", "(", "\"Actual JS divergence: \"", "+", "str", "(", "calculate_nonlog_js_divergence", "(", "dist_from", ",", "dist_to", ")", ")", ")", "\n", "print", "(", ")", "\n", "print", "(", "dist_from_2", ")", "\n", "print", "(", "dist_to_2", ")", "\n", "print", "(", "\"Actual KL divergence: \"", "+", "str", "(", "calculate_nonlog_kl_divergence", "(", "dist_from_2", ",", "dist_to_2", ")", ")", ")", "\n", "print", "(", "\"Actual JS divergence: \"", "+", "str", "(", "calculate_nonlog_js_divergence", "(", "dist_from_2", ",", "dist_to_2", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n", "log_dist_from", "=", "np", ".", "array", "(", "[", "dist_from", ",", "dist_from_2", "]", ")", "\n", "log_dist_to", "=", "np", ".", "array", "(", "[", "dist_to", ",", "dist_to_2", "]", ")", "\n", "log_dist_from", "=", "np", ".", "log", "(", "log_dist_from", ")", "\n", "log_dist_to", "=", "np", ".", "log", "(", "log_dist_to", ")", "\n", "\n", "kl_divs", "=", "get_kl_div_of_dists", "(", "log_dist_from", ",", "log_dist_to", ")", "\n", "js_divs", "=", "get_js_div_of_dists", "(", "log_dist_from", ",", "log_dist_to", ")", "\n", "\n", "print", "(", "\"Calculated KL divergence for dist 1: \"", "+", "str", "(", "kl_divs", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Calculated JS divergence for dist 1: \"", "+", "str", "(", "js_divs", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Calculated KL divergence for dist 2: \"", "+", "str", "(", "kl_divs", "[", "1", "]", ")", ")", "\n", "print", "(", "\"Calculated JS divergence for dist 2: \"", "+", "str", "(", "js_divs", "[", "1", "]", ")", ")", "\n", "print", "(", ")", "\n", "\n", "log_dist_from", "+=", "5", "\n", "log_dist_to", "-=", "7", "\n", "\n", "kl_divs", "=", "get_kl_div_of_dists", "(", "log_dist_from", ",", "log_dist_to", ")", "\n", "js_divs", "=", "get_js_div_of_dists", "(", "log_dist_from", ",", "log_dist_to", ")", "\n", "\n", "print", "(", "\"Calculated KL divergence after adjusting log constant for dist 1: \"", "+", "str", "(", "kl_divs", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Calculated JS divergence after adjusting log constant for dist 1: \"", "+", "str", "(", "js_divs", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Calculated KL divergence after adjusting log constant for dist 2: \"", "+", "str", "(", "kl_divs", "[", "1", "]", ")", ")", "\n", "print", "(", "\"Calculated JS divergence after adjusting log constant for dist 2: \"", "+", "str", "(", "js_divs", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.load_in_data_table": [[140, 354], ["print", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "print", "print", "numpy.concatenate", "print", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "len", "numpy.reshape", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "len", "len", "len", "print", "len", "len", "str", "len", "numpy.any", "numpy.any", "numpy.any", "numpy.any", "numpy.any", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "print", "numpy.zeros", "numpy.concatenate", "numpy.nonzero", "numpy.nonzero", "numpy.nonzero", "print", "print", "exit", "numpy.nonzero", "numpy.nonzero", "str", "numpy.nonzero", "str", "str", "str", "len", "str", "numpy.nonzero", "test_model.first_v_second_fname", "test_model.dec_flip_stats_fname", "test_model.rand_results_fname", "test_model.unchanged_fname", "test_model.grad_based_stats_fname", "test_model.attn_div_from_unif_fname", "test_model.gradsignmult_based_stats_fname", "test_model.dec_flip_rand_nontopbygrad_stats_fname", "test_model.dec_flip_rand_nontopbygradmult_stats_fname", "test_model.dec_flip_rand_nontopbygradsignmult_stats_fname", "test_model.first_v_second_fname", "test_model.dec_flip_stats_fname", "test_model.rand_results_fname", "test_model.unchanged_fname", "test_model.grad_based_stats_fname", "test_model.attn_div_from_unif_fname", "test_model.gradsignmult_based_stats_fname", "test_model.dec_flip_rand_nontopbygrad_stats_fname", "test_model.dec_flip_rand_nontopbygradmult_stats_fname", "test_model.dec_flip_rand_nontopbygradsignmult_stats_fname"], "function", ["None"], ["def", "load_in_data_table", "(", "first_v_second_filename", ",", "dec_flip_stats_filename", ",", "rand_results_filename", ",", "unchanged_filename", ",", "\n", "grad_based_stats_filename", ",", "dec_flip_rand_nontop_stats_filename", ",", "attn_div_from_unif_filename", ",", "\n", "gradsignmult_based_stats_filename", ",", "dec_flip_rand_nontopbygrad_stats_filename", ",", "\n", "dec_flip_rand_nontopbygradmult_stats_filename", ",", "\n", "dec_flip_rand_nontopbygradsignmult_stats_filename", ")", ":", "\n", "    ", "print", "(", "\"Loading in raw CSV files\"", ")", "\n", "first_v_second", "=", "np", ".", "genfromtxt", "(", "first_v_second_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "dec_flip_stats", "=", "np", ".", "genfromtxt", "(", "dec_flip_stats_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "rand_stats", "=", "np", ".", "genfromtxt", "(", "rand_results_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "unchanged", "=", "np", ".", "genfromtxt", "(", "unchanged_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "grad_stats", "=", "np", ".", "genfromtxt", "(", "grad_based_stats_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "nontop_stats", "=", "np", ".", "genfromtxt", "(", "dec_flip_rand_nontop_stats_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "attn_div_stats", "=", "np", ".", "genfromtxt", "(", "attn_div_from_unif_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "gradsignmult_stats", "=", "np", ".", "genfromtxt", "(", "gradsignmult_based_stats_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "nontop_by_grad_stats", "=", "np", ".", "genfromtxt", "(", "dec_flip_rand_nontopbygrad_stats_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "nontop_by_gradmult_stats", "=", "np", ".", "genfromtxt", "(", "dec_flip_rand_nontopbygradmult_stats_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "nontop_by_gradsignmult_stats", "=", "np", ".", "genfromtxt", "(", "dec_flip_rand_nontopbygradsignmult_stats_filename", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ")", "\n", "\n", "if", "len", "(", "first_v_second", ".", "shape", ")", "==", "1", ":", "\n", "        ", "first_v_second", "=", "np", ".", "reshape", "(", "first_v_second", ",", "(", "1", ",", "first_v_second", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "dec_flip_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "dec_flip_stats", "=", "np", ".", "reshape", "(", "dec_flip_stats", ",", "(", "1", ",", "dec_flip_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "rand_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "rand_stats", "=", "np", ".", "reshape", "(", "rand_stats", ",", "(", "1", ",", "rand_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "unchanged", ".", "shape", ")", "==", "1", ":", "\n", "        ", "unchanged", "=", "np", ".", "reshape", "(", "unchanged", ",", "(", "1", ",", "unchanged", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "grad_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "grad_stats", "=", "np", ".", "reshape", "(", "grad_stats", ",", "(", "1", ",", "grad_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "nontop_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "nontop_stats", "=", "np", ".", "reshape", "(", "nontop_stats", ",", "(", "1", ",", "nontop_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "attn_div_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "attn_div_stats", "=", "np", ".", "reshape", "(", "attn_div_stats", ",", "(", "1", ",", "attn_div_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "gradsignmult_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "gradsignmult_stats", "=", "np", ".", "reshape", "(", "gradsignmult_stats", ",", "(", "1", ",", "gradsignmult_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "nontop_by_grad_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "nontop_by_grad_stats", "=", "np", ".", "reshape", "(", "nontop_by_grad_stats", ",", "(", "1", ",", "nontop_by_grad_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "nontop_by_gradmult_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "nontop_by_gradmult_stats", "=", "np", ".", "reshape", "(", "nontop_by_gradmult_stats", ",", "(", "1", ",", "nontop_by_gradmult_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "if", "len", "(", "nontop_by_gradsignmult_stats", ".", "shape", ")", "==", "1", ":", "\n", "        ", "nontop_by_gradsignmult_stats", "=", "np", ".", "reshape", "(", "nontop_by_gradsignmult_stats", ",", "(", "1", ",", "nontop_by_gradsignmult_stats", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "", "print", "(", "\"Checking that ID tags match up in records from each file before concatenating\"", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "dec_flip_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "dec_flip_stats", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "rand_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "rand_stats", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "unchanged", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "unchanged", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "grad_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "grad_stats", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "nontop_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "nontop_stats", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "attn_div_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "attn_div_stats", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "gradsignmult_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "gradsignmult_stats", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "nontop_by_grad_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "nontop_by_grad_stats", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "nontop_by_gradmult_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "nontop_by_gradmult_stats", ".", "shape", ")", "\n", "assert", "first_v_second", ".", "shape", "[", "0", "]", "==", "nontop_by_gradsignmult_stats", ".", "shape", "[", "0", "]", ",", "str", "(", "first_v_second", ".", "shape", ")", "+", "', '", "+", "str", "(", "nontop_by_gradsignmult_stats", ".", "shape", ")", "\n", "diffs_bet_first_v_second_and_dec_flip_stats", "=", "first_v_second", "[", ":", ",", "0", "]", "-", "dec_flip_stats", "[", ":", ",", "0", "]", "\n", "diffs_bet_first_v_second_and_rand_stats", "=", "first_v_second", "[", ":", ",", "0", "]", "-", "rand_stats", "[", ":", ",", "0", "]", "\n", "diffs_bet_first_v_second_and_unchanged", "=", "first_v_second", "[", ":", ",", "0", "]", "-", "unchanged", "[", ":", ",", "0", "]", "\n", "assert", "len", "(", "np", ".", "nonzero", "(", "diffs_bet_first_v_second_and_dec_flip_stats", ")", "[", "0", "]", ")", "==", "0", ",", "\"Some inds in first_v_second and dec_flip_stats didn't match\"", "\n", "assert", "len", "(", "np", ".", "nonzero", "(", "diffs_bet_first_v_second_and_rand_stats", ")", "[", "0", "]", ")", "==", "0", ",", "\"Some inds in first_v_second and rand_stats didn't match\"", "\n", "assert", "len", "(", "np", ".", "nonzero", "(", "diffs_bet_first_v_second_and_unchanged", ")", "[", "0", "]", ")", "==", "0", ",", "\"Some inds in first_v_second and unchanged didn't match\"", "\n", "assert", "DEC_FLIP_ZERO_2NDLOWEST", "==", "first_v_second", ".", "shape", "[", "1", "]", "-", "1", "\n", "assert", "NEEDED_REM_BOTTOM_FRAC_X_FOR_DECFLIP", "==", "first_v_second", ".", "shape", "[", "1", "]", "+", "dec_flip_stats", ".", "shape", "[", "1", "]", "-", "1", "\n", "global", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", ",", "EXTRACTED_SINGLE_WEIGHT_KL_START", ",", "EXTRACTED_SINGLE_WEIGHT_KL_END", ",", "EXTRACTED_SINGLE_WEIGHT_JS_START", ",", "EXTRACTED_SINGLE_WEIGHT_JS_END", ",", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", ",", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_END", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", ",", "ACTUAL_LABEL", ",", "ORIG_LABEL_GUESSED", ",", "OUTPUT_ENTROPY", ",", "ATTN_ENTROPY", ",", "WEIGHT_1ST2ND_RATIO", ",", "WEIGHT_1ST2ND_ENTROPY", ",", "WEIGHT_LAST2NDLAST_RATIO", ",", "WEIGHT_LAST2NDLAST_ENTROPY", ",", "WEIGHT_1STLAST_RATIO", ",", "WEIGHT_1STLAST_ENTROPY", ",", "STARTING_IND_OF_OUTPUT_CLASSES", ",", "LAST_IND_OF_OUTPUT_CLASSES", ",", "ID_DUPLICATE", ",", "ATTN_SEQ_LEN_DUPLICATE2_FOR_TESTING", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADMULT", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", ",", "KL_DIV_ZERO_HIGHESTGRAD", ",", "JS_DIV_ZERO_HIGHESTGRAD", ",", "DEC_FLIP_ZERO_HIGHESTGRAD", ",", "KL_DIV_ZERO_2NDHIGHESTGRAD", ",", "JS_DIV_ZERO_2NDHIGHESTGRAD", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRAD", ",", "KL_DIV_ZERO_HIGHESTGRADMULT", ",", "JS_DIV_ZERO_HIGHESTGRADMULT", ",", "DEC_FLIP_ZERO_HIGHESTGRADMULT", ",", "KL_DIV_ZERO_2NDHIGHESTGRADMULT", ",", "JS_DIV_ZERO_2NDHIGHESTGRADMULT", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRADMULT", ",", "NONTOP_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "NONTOP_RAND_ZEROED_WEIGHT", ",", "NONTOP_RAND_KL_DIV", ",", "NONTOP_RAND_JS_DIV", ",", "ATTN_KL_DIV_FROM_UNIF", ",", "ATTN_JS_DIV_FROM_UNIF", ",", "ID_DUPLICATE_2", ",", "ATTN_SEQ_LEN_DUPLICATE3_FOR_TESTING", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADSIGNMULT", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADSIGNMULT", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADSIGNMULT", ",", "KL_DIV_ZERO_HIGHESTGRADSIGNMULT", ",", "JS_DIV_ZERO_HIGHESTGRADSIGNMULT", ",", "DEC_FLIP_ZERO_HIGHESTGRADSIGNMULT", ",", "KL_DIV_ZERO_2NDHIGHESTGRADSIGNMULT", ",", "JS_DIV_ZERO_2NDHIGHESTGRADSIGNMULT", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRADSIGNMULT", ",", "NONTOPBYGRAD_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "NONTOPBYGRAD_RAND_ZEROED_WEIGHT", ",", "NONTOPBYGRAD_RAND_KL_DIV", ",", "NONTOPBYGRAD_RAND_JS_DIV", ",", "NONTOPBYGRADMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "NONTOPBYGRADMULT_RAND_ZEROED_WEIGHT", ",", "NONTOPBYGRADMULT_RAND_KL_DIV", ",", "NONTOPBYGRADMULT_RAND_JS_DIV", ",", "NONTOPBYGRADSIGNMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "NONTOPBYGRADSIGNMULT_RAND_ZEROED_WEIGHT", ",", "NONTOPBYGRADSIGNMULT_RAND_KL_DIV", ",", "NONTOPBYGRADSIGNMULT_RAND_JS_DIV", "\n", "if", "LAST_IND_OF_OUTPUT_CLASSES", "is", "None", ":", "\n", "        ", "num_rand_ind_orders_sampled", "=", "(", "rand_stats", ".", "shape", "[", "1", "]", "-", "2", ")", "//", "6", "\n", "assert", "num_rand_ind_orders_sampled", "==", "(", "rand_stats", ".", "shape", "[", "1", "]", "-", "2", ")", "/", "6", ",", "\"Didn't divide evenly: rand_stats.shape[1] was \"", "+", "str", "(", "rand_stats", ".", "shape", "[", "1", "]", ")", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "=", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", "+", "num_rand_ind_orders_sampled", "-", "1", "\n", "EXTRACTED_SINGLE_WEIGHT_KL_START", "=", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "\n", "EXTRACTED_SINGLE_WEIGHT_KL_END", "=", "EXTRACTED_SINGLE_WEIGHT_KL_START", "+", "num_rand_ind_orders_sampled", "-", "1", "\n", "EXTRACTED_SINGLE_WEIGHT_JS_START", "=", "EXTRACTED_SINGLE_WEIGHT_KL_END", "+", "1", "\n", "EXTRACTED_SINGLE_WEIGHT_JS_END", "=", "EXTRACTED_SINGLE_WEIGHT_JS_START", "+", "num_rand_ind_orders_sampled", "-", "1", "\n", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", "=", "EXTRACTED_SINGLE_WEIGHT_JS_END", "+", "1", "\n", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", "=", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", "+", "num_rand_ind_orders_sampled", "-", "1", "\n", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "=", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", "+", "1", "\n", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_END", "=", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "+", "num_rand_ind_orders_sampled", "-", "1", "\n", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "=", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_END", "+", "1", "\n", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "+", "num_rand_ind_orders_sampled", "-", "1", "\n", "assert", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "==", "first_v_second", ".", "shape", "[", "1", "]", "+", "dec_flip_stats", ".", "shape", "[", "1", "]", "+", "rand_stats", ".", "shape", "[", "1", "]", "-", "1", "\n", "ACTUAL_LABEL", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "ORIG_LABEL_GUESSED", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "OUTPUT_ENTROPY", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "ATTN_ENTROPY", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "WEIGHT_1ST2ND_RATIO", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "WEIGHT_1ST2ND_ENTROPY", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "WEIGHT_LAST2NDLAST_RATIO", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "WEIGHT_LAST2NDLAST_ENTROPY", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "WEIGHT_1STLAST_RATIO", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "WEIGHT_1STLAST_ENTROPY", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "STARTING_IND_OF_OUTPUT_CLASSES", "+=", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "LAST_IND_OF_OUTPUT_CLASSES", "=", "unchanged", ".", "shape", "[", "1", "]", "+", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "\n", "ID_DUPLICATE", "+=", "LAST_IND_OF_OUTPUT_CLASSES", "\n", "ATTN_SEQ_LEN_DUPLICATE2_FOR_TESTING", "=", "ID_DUPLICATE", "+", "1", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "=", "ATTN_SEQ_LEN_DUPLICATE2_FOR_TESTING", "+", "1", "\n", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "=", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "+", "1", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "=", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "+", "1", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADMULT", "=", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "+", "1", "\n", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "=", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADMULT", "+", "1", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "=", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "+", "1", "\n", "KL_DIV_ZERO_HIGHESTGRAD", "=", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "+", "1", "\n", "JS_DIV_ZERO_HIGHESTGRAD", "=", "KL_DIV_ZERO_HIGHESTGRAD", "+", "1", "\n", "DEC_FLIP_ZERO_HIGHESTGRAD", "=", "JS_DIV_ZERO_HIGHESTGRAD", "+", "1", "\n", "KL_DIV_ZERO_2NDHIGHESTGRAD", "=", "DEC_FLIP_ZERO_HIGHESTGRAD", "+", "1", "\n", "JS_DIV_ZERO_2NDHIGHESTGRAD", "=", "KL_DIV_ZERO_2NDHIGHESTGRAD", "+", "1", "\n", "DEC_FLIP_ZERO_2NDHIGHESTGRAD", "=", "JS_DIV_ZERO_2NDHIGHESTGRAD", "+", "1", "\n", "KL_DIV_ZERO_HIGHESTGRADMULT", "=", "DEC_FLIP_ZERO_2NDHIGHESTGRAD", "+", "1", "\n", "JS_DIV_ZERO_HIGHESTGRADMULT", "=", "KL_DIV_ZERO_HIGHESTGRADMULT", "+", "1", "\n", "DEC_FLIP_ZERO_HIGHESTGRADMULT", "=", "JS_DIV_ZERO_HIGHESTGRADMULT", "+", "1", "\n", "KL_DIV_ZERO_2NDHIGHESTGRADMULT", "=", "DEC_FLIP_ZERO_HIGHESTGRADMULT", "+", "1", "\n", "JS_DIV_ZERO_2NDHIGHESTGRADMULT", "=", "KL_DIV_ZERO_2NDHIGHESTGRADMULT", "+", "1", "\n", "DEC_FLIP_ZERO_2NDHIGHESTGRADMULT", "=", "JS_DIV_ZERO_2NDHIGHESTGRADMULT", "+", "1", "\n", "\n", "NONTOP_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "=", "NONTOP_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "+", "DEC_FLIP_ZERO_2NDHIGHESTGRADMULT", "\n", "NONTOP_RAND_ZEROED_WEIGHT", "=", "NONTOP_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "+", "1", "\n", "NONTOP_RAND_KL_DIV", "=", "NONTOP_RAND_ZEROED_WEIGHT", "+", "1", "\n", "NONTOP_RAND_JS_DIV", "=", "NONTOP_RAND_KL_DIV", "+", "1", "\n", "\n", "ATTN_KL_DIV_FROM_UNIF", "=", "ATTN_KL_DIV_FROM_UNIF", "+", "NONTOP_RAND_JS_DIV", "\n", "ATTN_JS_DIV_FROM_UNIF", "=", "ATTN_KL_DIV_FROM_UNIF", "+", "1", "\n", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADSIGNMULT", "=", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADSIGNMULT", "+", "ATTN_JS_DIV_FROM_UNIF", "\n", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADSIGNMULT", "=", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADSIGNMULT", "+", "1", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADSIGNMULT", "=", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADSIGNMULT", "+", "1", "\n", "KL_DIV_ZERO_HIGHESTGRADSIGNMULT", "=", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADSIGNMULT", "+", "1", "\n", "JS_DIV_ZERO_HIGHESTGRADSIGNMULT", "=", "KL_DIV_ZERO_HIGHESTGRADSIGNMULT", "+", "1", "\n", "DEC_FLIP_ZERO_HIGHESTGRADSIGNMULT", "=", "JS_DIV_ZERO_HIGHESTGRADSIGNMULT", "+", "1", "\n", "KL_DIV_ZERO_2NDHIGHESTGRADSIGNMULT", "=", "DEC_FLIP_ZERO_HIGHESTGRADSIGNMULT", "+", "1", "\n", "JS_DIV_ZERO_2NDHIGHESTGRADSIGNMULT", "=", "KL_DIV_ZERO_2NDHIGHESTGRADSIGNMULT", "+", "1", "\n", "DEC_FLIP_ZERO_2NDHIGHESTGRADSIGNMULT", "=", "JS_DIV_ZERO_2NDHIGHESTGRADSIGNMULT", "+", "1", "\n", "\n", "NONTOPBYGRAD_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "=", "NONTOPBYGRAD_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "+", "DEC_FLIP_ZERO_2NDHIGHESTGRADSIGNMULT", "\n", "NONTOPBYGRAD_RAND_ZEROED_WEIGHT", "=", "NONTOPBYGRAD_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "+", "1", "\n", "NONTOPBYGRAD_RAND_KL_DIV", "=", "NONTOPBYGRAD_RAND_ZEROED_WEIGHT", "+", "1", "\n", "NONTOPBYGRAD_RAND_JS_DIV", "=", "NONTOPBYGRAD_RAND_KL_DIV", "+", "1", "\n", "\n", "NONTOPBYGRADMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "=", "NONTOPBYGRADMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "+", "NONTOPBYGRAD_RAND_JS_DIV", "\n", "NONTOPBYGRADMULT_RAND_ZEROED_WEIGHT", "=", "NONTOPBYGRADMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "+", "1", "\n", "NONTOPBYGRADMULT_RAND_KL_DIV", "=", "NONTOPBYGRADMULT_RAND_ZEROED_WEIGHT", "+", "1", "\n", "NONTOPBYGRADMULT_RAND_JS_DIV", "=", "NONTOPBYGRADMULT_RAND_KL_DIV", "+", "1", "\n", "\n", "NONTOPBYGRADSIGNMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "=", "NONTOPBYGRADSIGNMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "+", "NONTOPBYGRADMULT_RAND_JS_DIV", "\n", "NONTOPBYGRADSIGNMULT_RAND_ZEROED_WEIGHT", "=", "NONTOPBYGRADSIGNMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "+", "1", "\n", "NONTOPBYGRADSIGNMULT_RAND_KL_DIV", "=", "NONTOPBYGRADSIGNMULT_RAND_ZEROED_WEIGHT", "+", "1", "\n", "NONTOPBYGRADSIGNMULT_RAND_JS_DIV", "=", "NONTOPBYGRADSIGNMULT_RAND_KL_DIV", "+", "1", "\n", "\n", "print", "(", "\"Found \"", "+", "str", "(", "\n", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", ")", "+", "\" different output classes\"", ")", "\n", "", "elif", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", ">", "unchanged", ".", "shape", "[", "1", "]", "-", "11", ":", "\n", "# pad unchanged with columns of zeroes", "\n", "        ", "print", "(", "\"Found \"", "+", "str", "(", "unchanged", ".", "shape", "[", "1", "]", "-", "11", ")", "+", "\" different output classes\"", ")", "\n", "num_cols_to_add", "=", "(", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", ")", "-", "(", "unchanged", ".", "shape", "[", "1", "]", "-", "11", ")", "\n", "padding_cols", "=", "np", ".", "zeros", "(", "shape", "=", "(", "unchanged", ".", "shape", "[", "0", "]", ",", "num_cols_to_add", ")", ")", "\n", "unchanged", "=", "np", ".", "concatenate", "(", "[", "unchanged", ",", "padding_cols", "]", ",", "axis", "=", "1", ")", "\n", "", "elif", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", "==", "unchanged", ".", "shape", "[", "1", "]", "-", "11", ":", "\n", "        ", "print", "(", "\"Found \"", "+", "str", "(", "\n", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", ")", "+", "\" different output classes\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"ERROR: previous tables were loaded in with fewer output classes, which code is currently not equipped to handle.\"", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "", "print", "(", "\"Starting to concatenate data into one table\"", ")", "\n", "data_table", "=", "np", ".", "concatenate", "(", "[", "first_v_second", ",", "dec_flip_stats", ",", "rand_stats", ",", "unchanged", ",", "grad_stats", ",", "nontop_stats", ",", "\n", "attn_div_stats", ",", "gradsignmult_stats", ",", "nontop_by_grad_stats", ",", "nontop_by_gradmult_stats", ",", "\n", "nontop_by_gradsignmult_stats", "]", ",", "\n", "axis", "=", "1", ")", "\n", "assert", "len", "(", "np", ".", "nonzero", "(", "data_table", "[", ":", ",", "ATTN_SEQ_LEN", "]", "-", "data_table", "[", ":", ",", "ATTN_SEQ_LEN_DUPLICATE_FOR_TESTING", "]", ")", "[", "0", "]", ")", "==", "0", "\n", "assert", "len", "(", "np", ".", "nonzero", "(", "data_table", "[", ":", ",", "ATTN_SEQ_LEN", "]", "-", "data_table", "[", ":", ",", "ATTN_SEQ_LEN_DUPLICATE2_FOR_TESTING", "]", ")", "[", "0", "]", ")", "==", "0", ",", "str", "(", "len", "(", "np", ".", "nonzero", "(", "data_table", "[", ":", ",", "ATTN_SEQ_LEN", "]", "-", "data_table", "[", ":", ",", "ATTN_SEQ_LEN_DUPLICATE2_FOR_TESTING", "]", ")", "[", "0", "]", ")", ")", "+", "' / '", "+", "str", "(", "data_table", ".", "shape", "[", "0", "]", ")", "+", "\" don't match. First ten: \"", "+", "str", "(", "data_table", "[", ":", "10", ",", "ATTN_SEQ_LEN_DUPLICATE2_FOR_TESTING", "]", ")", "\n", "assert", "len", "(", "np", ".", "nonzero", "(", "data_table", "[", ":", ",", "ID", "]", "-", "data_table", "[", ":", ",", "ID_DUPLICATE", "]", ")", "[", "0", "]", ")", "==", "0", "\n", "assert", "not", "np", ".", "any", "(", "data_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", ">", "1", ")", "\n", "assert", "not", "np", ".", "any", "(", "data_table", "[", ":", ",", "NEEDED_REM_BOTTOM_FRAC_X_FOR_DECFLIP", "]", ">", "1", ")", "\n", "assert", "not", "np", ".", "any", "(", "data_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", ">", "1", ")", "\n", "assert", "not", "np", ".", "any", "(", "data_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", ">", "1", ")", "\n", "assert", "not", "np", ".", "any", "(", "data_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADSIGNMULT", "]", ">", "1", ")", "\n", "assert", "data_table", ".", "shape", "[", "1", "]", "-", "1", "==", "NONTOPBYGRADSIGNMULT_RAND_JS_DIV", "\n", "print", "(", ")", "\n", "return", "data_table", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_test_accuracy": [[356, 358], ["numpy.sum"], "function", ["None"], ["", "def", "get_test_accuracy", "(", "table", ")", ":", "\n", "    ", "return", "np", ".", "sum", "(", "table", "[", ":", ",", "ACTUAL_LABEL", "]", "==", "table", "[", ":", ",", "ORIG_LABEL_GUESSED", "]", ")", "/", "table", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.run_mcnemars_test": [[360, 364], ["statsmodels.sandbox.stats.runs.mcnemar", "print", "str", "str"], "function", ["None"], ["", "def", "run_mcnemars_test", "(", "lower_list", ",", "higher_list", ",", "tag", ")", ":", "\n", "    ", "chi_square_stat", ",", "p_val", "=", "mcnemar", "(", "lower_list", ",", "y", "=", "higher_list", ")", "\n", "print", "(", "\"McNemar's results for \"", "+", "tag", "+", "\": chi-square stat = \"", "+", "str", "(", "chi_square_stat", ")", "+", "\", p-val = \"", "+", "str", "(", "p_val", ")", ")", "\n", "return", "chi_square_stat", ",", "p_val", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.report_frac_for_model": [[366, 401], ["numpy.mean", "numpy.std", "print", "print", "print", "numpy.reshape", "print", "str", "numpy.logical_and", "print", "numpy.logical_and", "print", "str", "numpy.logical_and", "print", "numpy.logical_and", "print", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and"], "function", ["None"], ["", "def", "report_frac_for_model", "(", "which", ",", "table", ")", ":", "\n", "    ", "if", "which", "==", "'from_top'", ":", "\n", "        ", "vals", "=", "table", "[", "np", ".", "logical_and", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "]", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "\n", "print", "(", "\"Removing from top:                             \"", ",", "end", "=", "''", ")", "\n", "", "elif", "which", "==", "'from_bottom'", ":", "\n", "        ", "vals", "=", "table", "[", "np", ".", "logical_and", "(", "table", "[", ":", ",", "NEEDED_REM_BOTTOM_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "]", "[", ":", ",", "NEEDED_REM_BOTTOM_FRAC_X_FOR_DECFLIP", "]", "\n", "print", "(", "\"Removing from bottom:                          \"", ",", "end", "=", "''", ")", "\n", "", "elif", "which", "==", "'avg_random'", ":", "\n", "        ", "vals", "=", "table", "[", "np", ".", "logical_and", "(", "table", "[", ":", ",", "NEEDED_REM_BOTTOM_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "]", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", ":", "\n", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "+", "1", "]", "\n", "vals", "=", "np", ".", "reshape", "(", "vals", ",", "vals", ".", "shape", "[", "0", "]", "*", "vals", ".", "shape", "[", "1", "]", ")", "\n", "print", "(", "\"Removing in a random order:                    \"", ",", "end", "=", "''", ")", "\n", "", "elif", "which", "==", "'from_top_grad'", ":", "\n", "        ", "vals", "=", "table", "[", "np", ".", "logical_and", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "]", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "\n", "print", "(", "\"Removing from top **GRADIENTS**:               \"", ",", "end", "=", "''", ")", "\n", "", "elif", "which", "==", "'from_top_grad_mult'", ":", "\n", "        ", "vals", "=", "table", "[", "np", ".", "logical_and", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "]", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "\n", "print", "(", "\"Removing from top **GRADIENTS * ATTNWEIGHTS**: \"", ",", "end", "=", "''", ")", "\n", "", "elif", "which", "==", "'from_top_gradsignmult'", ":", "\n", "        ", "vals", "=", "table", "[", "np", ".", "logical_and", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADSIGNMULT", "]", "!=", "-", "1", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "]", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADSIGNMULT", "]", "\n", "print", "(", "\"Removing from top **GRADIENT SIGN * ATTNWEIGHTS**: \"", ",", "end", "=", "''", ")", "\n", "", "elif", "which", "==", "'from_top_probmass'", ":", "\n", "        ", "vals", "=", "table", "[", "np", ".", "logical_and", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "!=", "-", "1", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "]", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "\n", "print", "(", "\"Removing from top, av probmass removed:        \"", ",", "end", "=", "''", ")", "\n", "", "m", "=", "np", ".", "mean", "(", "vals", ")", "\n", "sd", "=", "np", ".", "std", "(", "vals", ")", "\n", "print", "(", "\"Needed to remove mean of \"", "+", "str", "(", "m", ")", "+", "\" (std dev \"", "+", "str", "(", "sd", ")", "+", "\")\"", ")", "\n", "return", "m", ",", "sd", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_label_distrib_for_rows": [[403, 420], ["numpy.argmax", "range", "print", "print", "print", "print", "print", "numpy.sum", "numpy.sum", "actual_label_summary.append", "guessed_label_summary.append", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "print_label_distrib_for_rows", "(", "rows", ",", "tag", ")", ":", "\n", "    ", "actual_labels", "=", "rows", "[", ":", ",", "ACTUAL_LABEL", "]", "\n", "guessed_labels", "=", "np", ".", "argmax", "(", "rows", "[", ":", ",", "STARTING_IND_OF_OUTPUT_CLASSES", ":", "LAST_IND_OF_OUTPUT_CLASSES", "+", "1", "]", ",", "axis", "=", "1", ")", "\n", "actual_label_summary", "=", "[", "]", "\n", "guessed_label_summary", "=", "[", "]", "\n", "for", "possible_label", "in", "range", "(", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", ")", ":", "\n", "        ", "num_of_that_actual_label", "=", "np", ".", "sum", "(", "actual_labels", "==", "possible_label", ")", "\n", "if", "num_of_that_actual_label", ">", "0", ":", "\n", "            ", "actual_label_summary", ".", "append", "(", "str", "(", "possible_label", ")", "+", "\": \"", "+", "str", "(", "num_of_that_actual_label", ")", ")", "\n", "", "num_of_that_guessed_label", "=", "np", ".", "sum", "(", "guessed_labels", "==", "possible_label", ")", "\n", "if", "num_of_that_guessed_label", ">", "0", ":", "\n", "            ", "guessed_label_summary", ".", "append", "(", "str", "(", "possible_label", ")", "+", "\": \"", "+", "str", "(", "num_of_that_guessed_label", ")", ")", "\n", "", "", "print", "(", "\"FOR \"", "+", "str", "(", "tag", ")", "+", "\" ROWS:\"", ")", "\n", "print", "(", "\"\\tActual labels:\\n\\t\"", ",", "end", "=", "''", ")", "\n", "print", "(", "'   '", ".", "join", "(", "actual_label_summary", ")", ")", "\n", "print", "(", "\"\\tGuessed labels:\\n\\t\"", ",", "end", "=", "''", ")", "\n", "print", "(", "'   '", ".", "join", "(", "guessed_label_summary", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_default_class_info": [[422, 494], ["print", "numpy.union1d", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.setdiff1d", "numpy.setdiff1d", "print", "print", "test_model.get_entropy_of_dists", "test_model.get_entropy_of_dists", "process_test_outputs.print_label_distrib_for_rows", "process_test_outputs.print_label_distrib_for_rows", "test_model.get_entropy_of_dists", "print", "numpy.union1d", "print", "print", "len", "numpy.mean", "numpy.std", "print", "len", "numpy.mean", "numpy.std", "print", "len", "numpy.mean", "numpy.std", "print", "numpy.any", "numpy.setdiff1d", "numpy.setdiff1d", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "numpy.sum", "str", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_label_distrib_for_rows", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_label_distrib_for_rows", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.test_model.get_entropy_of_dists"], ["", "def", "get_default_class_info", "(", "table", ")", ":", "\n", "    ", "print", "(", "\"NEVER-FLIPPED ANALYSIS:\"", ")", "\n", "default_class_rows_by_grad", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "<", "0", "]", "\n", "default_class_rows", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "<", "0", "]", "\n", "default_class_rows_from_bottom", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_BOTTOM_FRAC_X_FOR_DECFLIP", "]", "<", "0", "]", "\n", "default_class_rows_at_least_one_random", "=", "table", "[", "np", ".", "any", "(", "table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", ":", "\n", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "+", "1", "]", "<", "0", ",", "\n", "axis", "=", "1", ")", "]", "\n", "default_class_rows_for_random", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "<", "0", "]", "\n", "every_never_change_instance", "=", "np", ".", "union1d", "(", "np", ".", "union1d", "(", "default_class_rows", "[", ":", ",", "0", "]", ",", "\n", "default_class_rows_from_bottom", "[", ":", ",", "0", "]", ")", ",", "\n", "default_class_rows_at_least_one_random", "[", ":", ",", "0", "]", ")", "\n", "print", "(", "\"Removing by grad, there are \"", "+", "str", "(", "default_class_rows_by_grad", ".", "shape", "[", "0", "]", ")", "+", "\" instances in this category.\"", ")", "\n", "print", "(", "\"Removing from top, there are \"", "+", "str", "(", "default_class_rows", ".", "shape", "[", "0", "]", ")", "+", "\" instances in this category.\"", ")", "\n", "print", "(", "\"Removing in a (1) random order, there are \"", "+", "str", "(", "default_class_rows_for_random", ".", "shape", "[", "0", "]", ")", "+", "\" instances in this category.\"", ")", "\n", "print", "(", "\"Removing in a random order, there are \"", "+", "str", "(", "default_class_rows_at_least_one_random", ".", "shape", "[", "0", "]", ")", "+", "\n", "\" intances where at least one of the \"", "+", "\n", "str", "(", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "-", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "+", "1", ")", "+", "\n", "\" random runs never flipped.\"", ")", "\n", "print", "(", "\"Removing from bottom, there are \"", "+", "str", "(", "default_class_rows_from_bottom", ".", "shape", "[", "0", "]", ")", "+", "\n", "\" instances in this category.\"", ")", "\n", "print", "(", "\"Found \"", "+", "str", "(", "every_never_change_instance", ".", "shape", "[", "0", "]", ")", "+", "\" instances in any of those categories.\"", ")", "\n", "from_top_not_in_from_bottom", "=", "np", ".", "setdiff1d", "(", "default_class_rows", "[", ":", ",", "0", "]", ",", "default_class_rows_from_bottom", "[", ":", ",", "0", "]", ")", ".", "shape", "[", "0", "]", "\n", "from_bottom_not_in_from_top", "=", "np", ".", "setdiff1d", "(", "default_class_rows_from_bottom", "[", ":", ",", "0", "]", ",", "default_class_rows", "[", ":", ",", "0", "]", ")", ".", "shape", "[", "0", "]", "\n", "print", "(", "str", "(", "from_top_not_in_from_bottom", ")", "+", "\" of those from-top instances aren't also from-bottom instances.\"", ")", "\n", "print", "(", "str", "(", "from_bottom_not_in_from_top", ")", "+", "\" of those from-bottom instances aren't also from-top instances.\"", ")", "\n", "from_rand_not_in_from_top", "=", "np", ".", "setdiff1d", "(", "default_class_rows_at_least_one_random", "[", ":", ",", "0", "]", ",", "default_class_rows", "[", ":", ",", "0", "]", ")", "\n", "from_rand_not_in_from_bottom", "=", "np", ".", "setdiff1d", "(", "default_class_rows_at_least_one_random", "[", ":", ",", "0", "]", ",", "\n", "default_class_rows_from_bottom", "[", ":", ",", "0", "]", ")", "\n", "print", "(", "str", "(", "from_rand_not_in_from_bottom", ".", "shape", "[", "0", "]", ")", "+", "\n", "\" of those at-least-one-rand instances aren't also from-bottom instances.\"", ")", "\n", "print", "(", "str", "(", "from_rand_not_in_from_top", ".", "shape", "[", "0", "]", ")", "+", "\n", "\" of those at-least-one-rand instances aren't also from-top instances.\"", ")", "\n", "\n", "output_log_dists", "=", "default_class_rows", "[", ":", ",", "STARTING_IND_OF_OUTPUT_CLASSES", ":", "LAST_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "\n", "if", "default_class_rows", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "        ", "default_class", "=", "default_class_rows", "[", "0", ",", "ORIG_LABEL_GUESSED", "]", "\n", "print", "(", "str", "(", "default_class_rows", ".", "shape", "[", "0", "]", ")", "+", "' / '", "+", "str", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "ORIG_LABEL_GUESSED", "]", "==", "default_class", ")", ")", "+", "' ('", "+", "\n", "str", "(", "default_class_rows", ".", "shape", "[", "0", "]", "/", "np", ".", "sum", "(", "table", "[", ":", ",", "ORIG_LABEL_GUESSED", "]", "==", "default_class", ")", ")", "+", "\n", "'%) of instances originally guessed as label '", "+", "str", "(", "default_class", ")", "+", "\" never flipped from top\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"There were NO default class rows.\"", ")", "\n", "", "def_output_entropies", "=", "get_entropy_of_dists", "(", "output_log_dists", ",", "\n", "[", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "*", "\n", "output_log_dists", ".", "shape", "[", "0", "]", ")", "\n", "output_log_dists_from_bottom", "=", "default_class_rows_from_bottom", "[", ":", ",", "\n", "STARTING_IND_OF_OUTPUT_CLASSES", ":", "LAST_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "\n", "def_output_entropies_bot", "=", "get_entropy_of_dists", "(", "output_log_dists_from_bottom", ",", "\n", "[", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "*", "\n", "output_log_dists_from_bottom", ".", "shape", "[", "0", "]", ")", "\n", "print_label_distrib_for_rows", "(", "default_class_rows", ",", "tag", "=", "\"NEVER-FLIPPED-FROM-TOP\"", ")", "\n", "print_label_distrib_for_rows", "(", "default_class_rows_from_bottom", ",", "tag", "=", "\"NEVER-FLIPPED-FROM-BOTTOM\"", ")", "\n", "non_default_class_rows", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", ">", "0", "]", "\n", "assert", "default_class_rows", ".", "shape", "[", "0", "]", "+", "non_default_class_rows", ".", "shape", "[", "0", "]", "==", "table", ".", "shape", "[", "0", "]", ",", "\"Shouldn't be any 0s\"", "\n", "output_log_dists", "=", "non_default_class_rows", "[", ":", ",", "STARTING_IND_OF_OUTPUT_CLASSES", ":", "LAST_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "\n", "nondef_output_entropies", "=", "get_entropy_of_dists", "(", "output_log_dists", ",", "\n", "[", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "*", "\n", "output_log_dists", ".", "shape", "[", "0", "]", ")", "\n", "if", "len", "(", "def_output_entropies", ")", ">", "0", ":", "\n", "        ", "m", "=", "np", ".", "mean", "(", "def_output_entropies", ")", "\n", "sd", "=", "np", ".", "std", "(", "def_output_entropies", ")", "\n", "print", "(", "\"Never-flipped from-top output distrib entropies have mean \"", "+", "str", "(", "m", ")", "+", "\" and std dev \"", "+", "str", "(", "sd", ")", "+", "\".\"", ")", "\n", "", "if", "len", "(", "def_output_entropies_bot", ")", ">", "0", ":", "\n", "        ", "m", "=", "np", ".", "mean", "(", "def_output_entropies_bot", ")", "\n", "sd", "=", "np", ".", "std", "(", "def_output_entropies_bot", ")", "\n", "print", "(", "\"Never-flipped from-bottom output distrib entropies have mean \"", "+", "str", "(", "m", ")", "+", "\" and std dev \"", "+", "\n", "str", "(", "sd", ")", "+", "\".\"", ")", "\n", "", "if", "len", "(", "nondef_output_entropies", ")", ">", "0", ":", "\n", "        ", "m", "=", "np", ".", "mean", "(", "nondef_output_entropies", ")", "\n", "sd", "=", "np", ".", "std", "(", "nondef_output_entropies", ")", "\n", "print", "(", "\"All other output distrib entropies have mean \"", "+", "str", "(", "m", ")", "+", "\" and std dev \"", "+", "str", "(", "sd", ")", "+", "\".\"", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.make_and_save_hist": [[496, 533], ["matplotlib.figure", "matplotlib.hist", "matplotlib.xlim", "matplotlib.title", "matplotlib.savefig", "matplotlib.close", "len", "max", "min", "min", "max", "numpy.arange", "numpy.arange", "min", "max", "min", "min", "max", "max", "math.fabs", "math.fabs"], "function", ["None"], ["", "def", "make_and_save_hist", "(", "data", ",", "fname", ",", "title", "=", "''", ",", "bin_size", "=", "None", ",", "have_left_bin_edge_at", "=", "None", ",", "num_bins", "=", "None", ",", "\n", "make_log_scale", "=", "False", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "assert", "not", "(", "bin_size", "is", "not", "None", "and", "num_bins", "is", "not", "None", ")", "\n", "if", "bin_size", "is", "not", "None", ":", "\n", "        ", "bins", "=", "[", "i", "for", "i", "in", "np", ".", "arange", "(", "min", "(", "data", ")", ",", "max", "(", "data", ")", "+", "bin_size", ",", "bin_size", ")", "]", "\n", "", "else", ":", "\n", "        ", "if", "num_bins", "is", "None", ":", "\n", "            ", "num_bins", "=", "20", "# just assume this is fine", "\n", "", "bin_size", "=", "(", "max", "(", "data", ")", "-", "min", "(", "data", ")", ")", "*", "1.01", "//", "num_bins", "\n", "bins", "=", "[", "i", "for", "i", "in", "np", ".", "arange", "(", "min", "(", "data", ")", ",", "max", "(", "data", ")", "+", "bin_size", ",", "bin_size", ")", "]", "\n", "", "if", "have_left_bin_edge_at", "is", "not", "None", ":", "\n", "# find the closest bin edge, and adjust so it's at have_left_bin_edge_at", "\n", "        ", "if", "len", "(", "bins", ")", ">", "1", ":", "\n", "            ", "closest", "=", "None", "\n", "for", "left_bin_edge", "in", "bins", "[", ":", "-", "1", "]", ":", "\n", "                ", "if", "closest", "is", "None", ":", "\n", "                    ", "closest", "=", "left_bin_edge", "\n", "", "elif", "fabs", "(", "left_bin_edge", "-", "have_left_bin_edge_at", ")", "<", "fabs", "(", "closest", "-", "have_left_bin_edge_at", ")", ":", "\n", "                    ", "closest", "=", "left_bin_edge", "\n", "", "", "val_to_add", "=", "have_left_bin_edge_at", "-", "closest", "\n", "bins", "=", "[", "i", "+", "val_to_add", "for", "i", "in", "bins", "]", "\n", "", "else", ":", "\n", "            ", "if", "bins", "[", "0", "]", "<", "have_left_bin_edge_at", ":", "\n", "                ", "while", "have_left_bin_edge_at", ">", "bins", "[", "0", "]", ":", "\n", "                    ", "have_left_bin_edge_at", "-=", "bin_size", "\n", "", "bins", "[", "0", "]", "=", "have_left_bin_edge_at", "\n", "", "elif", "bins", "[", "0", "]", ">=", "have_left_bin_edge_at", ":", "\n", "                ", "while", "have_left_bin_edge_at", "+", "bin_size", "<=", "bins", "[", "0", "]", ":", "\n", "                    ", "have_left_bin_edge_at", "+=", "bin_size", "\n", "", "bins", "[", "0", "]", "=", "have_left_bin_edge_at", "\n", "", "", "", "plt", ".", "hist", "(", "data", ",", "bins", "=", "bins", ",", "log", "=", "make_log_scale", ")", "\n", "expand_window_by", "=", "(", "max", "(", "data", ")", "-", "min", "(", "data", ")", ")", "/", "20", "\n", "plt", ".", "xlim", "(", "min", "(", "data", ")", "-", "expand_window_by", ",", "max", "(", "data", ")", "+", "expand_window_by", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "savefig", "(", "fname", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.make_and_save_plot": [[535, 558], ["isinstance", "isinstance", "matplotlib.figure", "matplotlib.scatter", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.close", "len", "len", "len", "len", "max", "min", "min", "max", "max", "min", "min", "max"], "function", ["None"], ["", "def", "make_and_save_plot", "(", "data_x", ",", "data_y", ",", "fname", ",", "title", "=", "''", ",", "x_title", "=", "''", ",", "y_title", "=", "''", ",", "marker_size", "=", "2", ")", ":", "\n", "    ", "if", "isinstance", "(", "data_x", ",", "list", ")", ":", "\n", "        ", "len_x", "=", "len", "(", "data_x", ")", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "data_x", ".", "shape", ")", "==", "1", "\n", "len_x", "=", "data_x", ".", "shape", "[", "0", "]", "\n", "", "if", "isinstance", "(", "data_y", ",", "list", ")", ":", "\n", "        ", "len_y", "=", "len", "(", "data_y", ")", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "data_y", ".", "shape", ")", "==", "1", "\n", "len_y", "=", "data_y", ".", "shape", "[", "0", "]", "\n", "", "assert", "len_x", "==", "len_y", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "scatter", "(", "data_x", ",", "data_y", ",", "s", "=", "marker_size", ")", "\n", "expand_x_window_by", "=", "(", "max", "(", "data_x", ")", "-", "min", "(", "data_x", ")", ")", "/", "20", "\n", "plt", ".", "xlim", "(", "min", "(", "data_x", ")", "-", "expand_x_window_by", ",", "max", "(", "data_x", ")", "+", "expand_x_window_by", ")", "\n", "expand_y_window_by", "=", "(", "max", "(", "data_y", ")", "-", "min", "(", "data_y", ")", ")", "/", "20", "\n", "plt", ".", "ylim", "(", "min", "(", "data_y", ")", "-", "expand_y_window_by", ",", "max", "(", "data_y", ")", "+", "expand_y_window_by", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "xlabel", "(", "x_title", ")", "\n", "plt", ".", "ylabel", "(", "y_title", ")", "\n", "plt", ".", "savefig", "(", "fname", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance": [[560, 585], ["numpy.array", "open", "line[].strip().split", "min", "numpy.exp", "list", "weights.append", "line[].strip().split.strip", "float", "sorted", "line[].strip", "numpy.sum", "line[].strip().split.index"], "function", ["None"], ["", "def", "get_np_arr_of_one_attn_weight_per_instance", "(", "ind", ",", "is_han", ",", "data_directory", ",", "\n", "ind_corresponds_to_weight_sorted_in_dec_order", "=", "True", ")", ":", "\n", "    ", "weights", "=", "[", "]", "\n", "if", "is_han", ":", "\n", "        ", "filename", "=", "data_directory", "+", "'_sentence_attention_attn_weights_by_instance.txt'", "\n", "", "else", ":", "\n", "        ", "filename", "=", "data_directory", "+", "'_word_attention_attn_weights_by_instance.txt'", "\n", "", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                ", "continue", "\n", "", "line", "=", "line", "[", "line", ".", "index", "(", "':'", ")", "+", "1", ":", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "log_unnormalized_attn_weights", "=", "[", "float", "(", "x", ")", "for", "x", "in", "line", "]", "\n", "min_val", "=", "min", "(", "log_unnormalized_attn_weights", ")", "\n", "log_unnormalized_attn_weights", "=", "[", "x", "-", "min_val", "for", "x", "in", "log_unnormalized_attn_weights", "]", "\n", "unnormalized_attn_weights", "=", "np", ".", "exp", "(", "log_unnormalized_attn_weights", ")", "\n", "attn_weights", "=", "list", "(", "unnormalized_attn_weights", "/", "np", ".", "sum", "(", "unnormalized_attn_weights", ")", ")", "\n", "if", "ind_corresponds_to_weight_sorted_in_dec_order", ":", "\n", "                ", "attn_weights", "=", "sorted", "(", "attn_weights", ",", "reverse", "=", "True", ")", "\n", "", "try", ":", "\n", "                ", "weight_to_append", "=", "attn_weights", "[", "ind", "]", "\n", "", "except", "IndexError", ":", "\n", "                ", "weight_to_append", "=", "-", "1", "\n", "", "weights", ".", "append", "(", "weight_to_append", ")", "\n", "", "", "return", "np", ".", "array", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.make_kljs_correlation_plot": [[587, 621], ["process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.make_and_save_plot", "process_test_outputs.make_and_save_plot", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.make_and_save_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.make_and_save_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_kljs_correlation_plot", "(", "comparing_to_remhighest", ",", "col_to_compare_to_divergence", ",", "col_to_compare_to_corr_weight", ",", "\n", "tag_for_comparison", ":", "str", ",", "table", ",", "is_han", ",", "use_js", ":", "bool", "=", "True", ")", ":", "\n", "    ", "if", "comparing_to_remhighest", ":", "\n", "        ", "if", "use_js", ":", "\n", "            ", "div_after_extreme_removed", "=", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", "\n", "", "elif", "not", "use_js", ":", "\n", "            ", "div_after_extreme_removed", "=", "table", "[", ":", ",", "KL_DIV_ZERO_HIGHEST", "]", "\n", "", "corr_weights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "data_dir", ")", "\n", "", "elif", "not", "comparing_to_remhighest", ":", "\n", "        ", "if", "use_js", ":", "\n", "            ", "div_after_extreme_removed", "=", "table", "[", ":", ",", "JS_DIV_ZERO_LOWEST", "]", "\n", "", "elif", "not", "use_js", ":", "\n", "            ", "div_after_extreme_removed", "=", "table", "[", ":", ",", "KL_DIV_ZERO_LOWEST", "]", "\n", "", "corr_weights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "-", "1", ",", "is_han", ",", "data_dir", ")", "\n", "", "filename", "=", "image_directory", "+", "(", "\"js\"", "if", "use_js", "else", "\"kl\"", ")", "+", "\"divdiff-\"", "+", "(", "\"remhighest\"", "if", "comparing_to_remhighest", "else", "\"remlowest\"", ")", "+", "\"-\"", "+", "tag_for_comparison", "+", "\"_weightdiff-\"", "+", "(", "\"highest\"", "if", "comparing_to_remhighest", "else", "\"lowest\"", ")", "+", "\"-\"", "+", "tag_for_comparison", "+", "\".png\"", "\n", "if", "comparing_to_remhighest", ":", "\n", "        ", "x_title", "=", "\"Highest weight - \"", "+", "tag_for_comparison", "\n", "y_title", "=", "(", "\"JS\"", "if", "use_js", "else", "\"KL\"", ")", "+", "\" div w/o highest - \"", "+", "(", "\"JS\"", "if", "use_js", "else", "\"KL\"", ")", "+", "\" div w/o \"", "+", "tag_for_comparison", "\n", "title", "=", "\"(\"", "+", "x_title", "+", "\") vs (\"", "+", "y_title", "+", "\")\"", "\n", "make_and_save_plot", "(", "corr_weights", "-", "col_to_compare_to_corr_weight", ",", "\n", "div_after_extreme_removed", "-", "col_to_compare_to_divergence", ",", "\n", "filename", ",", "title", ",", "x_title", "=", "x_title", ",", "y_title", "=", "y_title", ")", "\n", "", "else", ":", "\n", "        ", "x_title", "=", "tag_for_comparison", "+", "\" - lowest weight\"", "\n", "y_title", "=", "(", "\"JS\"", "if", "use_js", "else", "\"KL\"", ")", "+", "\" div w/o \"", "+", "tag_for_comparison", "+", "\" - \"", "+", "(", "\"JS\"", "if", "use_js", "else", "\"KL\"", ")", "+", "\" div w/o lowest\"", "\n", "title", "=", "\"(\"", "+", "x_title", "+", "\") vs (\"", "+", "y_title", "+", "\")\"", "\n", "make_and_save_plot", "(", "col_to_compare_to_corr_weight", "-", "corr_weights", ",", "\n", "col_to_compare_to_divergence", "-", "div_after_extreme_removed", ",", "\n", "filename", ",", "title", ",", "x_title", "=", "x_title", ",", "y_title", "=", "y_title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.zoomed_out_vs_random_tests": [[623, 651], ["numpy.all", "numpy.clip", "numpy.sum", "numpy.clip", "numpy.divide", "numpy.logical_and", "process_test_outputs.run_mcnemars_test", "numpy.logical_and", "process_test_outputs.run_mcnemars_test", "numpy.sum", "numpy.sum", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.run_mcnemars_test", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.run_mcnemars_test"], ["", "", "def", "zoomed_out_vs_random_tests", "(", "table", ",", "is_han", ",", "produce_figs", ")", ":", "\n", "    ", "avg_rand", "=", "table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", ":", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_END", "+", "1", "]", "\n", "assert", "np", ".", "all", "(", "avg_rand", "!=", "0", ")", "\n", "avg_rand", "=", "np", ".", "clip", "(", "avg_rand", ",", "a_min", "=", "0", ",", "a_max", "=", "None", ")", "\n", "num_actual_dec_flips", "=", "np", ".", "sum", "(", "avg_rand", ">", "0", ",", "axis", "=", "1", ")", "\n", "num_actual_dec_flips", "=", "np", ".", "clip", "(", "num_actual_dec_flips", ",", "a_min", "=", "1", ",", "a_max", "=", "None", ")", "\n", "avg_rand", "=", "np", ".", "divide", "(", "np", ".", "sum", "(", "avg_rand", ",", "axis", "=", "1", ")", ",", "num_actual_dec_flips", ")", "\n", "avg_rand", "[", "avg_rand", "==", "0", "]", "=", "-", "1", "\n", "\n", "rem_from_bottom", "=", "table", "[", ":", ",", "NEEDED_REM_BOTTOM_FRAC_X_FOR_DECFLIP", "]", "\n", "rem_from_top", "=", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "\n", "\n", "from_bottom_mask", "=", "np", ".", "logical_and", "(", "rem_from_bottom", "!=", "-", "1", ",", "avg_rand", "!=", "-", "1", ")", "\n", "run_mcnemars_test", "(", "avg_rand", "[", "from_bottom_mask", "]", ",", "rem_from_bottom", "[", "from_bottom_mask", "]", ",", "tag", "=", "\"from-bottom vs avg-rand\"", ")", "\n", "from_top_mask", "=", "np", ".", "logical_and", "(", "rem_from_top", "!=", "-", "1", ",", "avg_rand", "!=", "-", "1", ")", "\n", "run_mcnemars_test", "(", "rem_from_top", "[", "from_top_mask", "]", ",", "avg_rand", "[", "from_top_mask", "]", ",", "tag", "=", "\"from-top vs avg-rand\"", ")", "\n", "\n", "avg_weight_sampled_for_extraction", "=", "np", ".", "sum", "(", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ",", "axis", "=", "1", ")", "/", "(", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "-", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", "+", "1", ")", "\n", "avg_random_js", "=", "np", ".", "sum", "(", "table", "[", ":", ",", "EXTRACTED_SINGLE_WEIGHT_JS_START", ":", "EXTRACTED_SINGLE_WEIGHT_JS_END", "+", "1", "]", ",", "axis", "=", "1", ")", "/", "(", "EXTRACTED_SINGLE_WEIGHT_JS_END", "-", "EXTRACTED_SINGLE_WEIGHT_JS_START", "+", "1", ")", "\n", "\n", "\"\"\"if produce_figs:\n        make_kljs_correlation_plot(True, avg_random_js, avg_weight_sampled_for_extraction, \"(avg) random weight\",\n                                   table, is_han)\n        make_kljs_correlation_plot(False, avg_random_js, avg_weight_sampled_for_extraction, \"(avg) random weight\",\n                                   table, is_han)\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.coarse_grained_single_attn_weight_tests": [[656, 672], ["numpy.sum", "process_test_outputs.run_mcnemars_test", "process_test_outputs.run_mcnemars_test"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.run_mcnemars_test", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.run_mcnemars_test"], ["", "def", "coarse_grained_single_attn_weight_tests", "(", "is_higher", ",", "table", ")", ":", "\n", "    ", "if", "is_higher", ":", "\n", "        ", "extreme_flipped_the_decision", "=", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "\n", "", "else", ":", "\n", "        ", "extreme_flipped_the_decision", "=", "table", "[", ":", ",", "NEEDED_REM_BOTTOM_X_FOR_DECFLIP", "]", "\n", "", "extreme_flipped_the_decision", "=", "(", "extreme_flipped_the_decision", "!=", "-", "1", ")", "\n", "avg_rand_flipped_the_decision", "=", "(", "table", "[", ":", ",", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", ":", "\n", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", "+", "1", "]", "==", "1", ")", ".", "astype", "(", "'float'", ")", "\n", "avg_rand_flipped_the_decision", "=", "np", ".", "sum", "(", "avg_rand_flipped_the_decision", ",", "axis", "=", "1", ")", "/", "(", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", "-", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", "+", "1", ")", "\n", "if", "not", "is_higher", ":", "\n", "        ", "run_mcnemars_test", "(", "extreme_flipped_the_decision", ",", "avg_rand_flipped_the_decision", ",", "\n", "\"lower has fewer decflips than rand\"", ")", "\n", "", "else", ":", "\n", "        ", "run_mcnemars_test", "(", "avg_rand_flipped_the_decision", ",", "extreme_flipped_the_decision", ",", "\n", "\"higher has more decflips than rand\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.fine_grained_single_attn_weight_tests": [[674, 693], ["process_test_outputs.run_mcnemars_test", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "print", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.run_mcnemars_test"], ["", "", "def", "fine_grained_single_attn_weight_tests", "(", "is_higher", ",", "table", ")", ":", "\n", "    ", "if", "is_higher", ":", "\n", "        ", "high_js_div", "=", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", "\n", "low_js_div", "=", "table", "[", ":", ",", "JS_DIV_ZERO_2NDHIGHEST", "]", "\n", "high_flip_outcomes", "=", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "!=", "-", "1", ")", "\n", "low_flip_outcomes", "=", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", "!=", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "high_js_div", "=", "table", "[", ":", ",", "JS_DIV_ZERO_2NDLOWEST", "]", "\n", "low_js_div", "=", "table", "[", ":", ",", "JS_DIV_ZERO_LOWEST", "]", "\n", "high_flip_outcomes", "=", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDLOWEST", "]", "!=", "-", "1", ")", "\n", "low_flip_outcomes", "=", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_LOWEST", "]", "!=", "-", "1", ")", "\n", "", "run_mcnemars_test", "(", "low_js_div", ",", "high_js_div", ",", "(", "\"rem-highest js div higher than rem-2ndhighest js div\"", "if", "is_higher", "\n", "else", "\"rem-lowest js div lower than rem-2ndlowest js div\"", ")", ")", "\n", "both_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "high_flip_outcomes", "==", "1", ",", "low_flip_outcomes", "==", "1", ")", ")", "\n", "neither_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "high_flip_outcomes", "==", "0", ",", "low_flip_outcomes", "==", "0", ")", ")", "\n", "only_higher_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "high_flip_outcomes", "==", "1", ",", "low_flip_outcomes", "==", "0", ")", ")", "\n", "only_lower_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "high_flip_outcomes", "==", "0", ",", "low_flip_outcomes", "==", "1", ")", ")", "\n", "print", "(", "\"BothFlipped: \"", "+", "str", "(", "both_flipped", ")", "+", "\"   NeitherFlipped: \"", "+", "str", "(", "neither_flipped", ")", "+", "\n", "\"   OnlyHigherFlipped: \"", "+", "str", "(", "only_higher_flipped", ")", "+", "\"   OnlyLowerFlipped: \"", "+", "str", "(", "only_lower_flipped", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.test_needed_rem_lots_vs_not": [[695, 708], ["numpy.mean", "numpy.mean", "numpy.std", "print", "numpy.mean", "numpy.std", "print", "str", "str", "str", "str"], "function", ["None"], ["", "def", "test_needed_rem_lots_vs_not", "(", "table", ")", ":", "\n", "    ", "rem_from_top", "=", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "\n", "mean_needed_rem", "=", "np", ".", "mean", "(", "rem_from_top", ")", "\n", "needed_rem_lots", "=", "table", "[", "rem_from_top", ">=", "mean_needed_rem", "]", "\n", "needed_rem_little", "=", "table", "[", "rem_from_top", "<", "mean_needed_rem", "]", "\n", "\n", "lots_m", "=", "np", ".", "mean", "(", "needed_rem_lots", "[", ":", ",", "ATTN_ENTROPY", "]", ")", "\n", "lots_sd", "=", "np", ".", "std", "(", "needed_rem_lots", "[", ":", ",", "ATTN_ENTROPY", "]", ")", "\n", "print", "(", "\"For needed-to-remove-lots, mean attn entropy was \"", "+", "str", "(", "lots_m", ")", "+", "\" (std dev \"", "+", "str", "(", "lots_sd", ")", "+", "\")\"", ")", "\n", "\n", "little_m", "=", "np", ".", "mean", "(", "needed_rem_little", "[", ":", ",", "ATTN_ENTROPY", "]", ")", "\n", "little_sd", "=", "np", ".", "std", "(", "needed_rem_little", "[", ":", ",", "ATTN_ENTROPY", "]", ")", "\n", "print", "(", "\"For needed-to-remove-little, mean attn entropy was \"", "+", "str", "(", "little_m", ")", "+", "\" (std dev \"", "+", "str", "(", "little_sd", ")", "+", "\")\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_vsrand_2x2_decflip_jointdist": [[710, 715], ["process_test_outputs.print_2x2_decflip_jointdist"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_2x2_decflip_jointdist"], ["", "def", "get_vsrand_2x2_decflip_jointdist", "(", "table", ",", "label", ",", "nonrand_column", ",", "corresponding_rand_column", ",", "is_han", ")", ":", "\n", "    ", "table", "=", "table", "[", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", "]", "# get rid of seqs of length 1 for this", "\n", "rand_flipped_decision", "=", "(", "table", "[", ":", ",", "corresponding_rand_column", "]", "!=", "-", "1", ")", "\n", "top_flipped_decision", "=", "(", "table", "[", ":", ",", "nonrand_column", "]", "!=", "-", "1", ")", "\n", "print_2x2_decflip_jointdist", "(", "rand_flipped_decision", ",", "top_flipped_decision", ",", "label", ",", "table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_vs2nd_2x2_decflip_jointdist": [[717, 722], ["process_test_outputs.print_2x2_decflip_jointdist"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_2x2_decflip_jointdist"], ["", "def", "get_vs2nd_2x2_decflip_jointdist", "(", "table", ")", ":", "\n", "    ", "table", "=", "table", "[", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", "]", "# get rid of seqs of length 1 for this", "\n", "second_flipped_decision", "=", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", "!=", "-", "1", ")", "\n", "top_flipped_decision", "=", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "!=", "-", "1", ")", "\n", "print_2x2_decflip_jointdist", "(", "second_flipped_decision", ",", "top_flipped_decision", ",", "\"Top vs. 2nd-highest\"", ",", "table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_2x2_decflip_jointdist": [[724, 736], ["numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "print", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "str", "str", "str", "str"], "function", ["None"], ["", "def", "print_2x2_decflip_jointdist", "(", "vs_flipped_decision", ",", "top_flipped_decision", ",", "label", ",", "table", ")", ":", "\n", "    ", "both_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "vs_flipped_decision", ",", "top_flipped_decision", ")", ")", "\n", "neither_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "vs_flipped_decision", ")", ",", "\n", "np", ".", "logical_not", "(", "top_flipped_decision", ")", ")", ")", "\n", "only_top_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "vs_flipped_decision", ")", ",", "\n", "top_flipped_decision", ")", ")", "\n", "only_rand_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "vs_flipped_decision", ",", "\n", "np", ".", "logical_not", "(", "top_flipped_decision", ")", ")", ")", "\n", "assert", "both_flipped", "+", "neither_flipped", "+", "only_top_flipped", "+", "only_rand_flipped", "==", "table", ".", "shape", "[", "0", "]", "\n", "print", "(", "label", "+", "\":  bothflipped:\"", "+", "str", "(", "both_flipped", "/", "table", ".", "shape", "[", "0", "]", ")", "+", "\n", "'\\tneitherflipped:'", "+", "str", "(", "neither_flipped", "/", "table", ".", "shape", "[", "0", "]", ")", "+", "'\\tonlytopflipped:'", "+", "\n", "str", "(", "only_top_flipped", "/", "table", ".", "shape", "[", "0", "]", ")", "+", "'\\tonlyotherflipped:'", "+", "str", "(", "only_rand_flipped", "/", "table", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.write_grad_labels_to_file": [[738, 774], ["just_the_model.endswith", "print", "top_level_data_folder.endswith", "just_the_model.endswith", "open", "range", "just_the_model.rfind", "just_the_model.index", "just_the_dataset_name.index", "just_the_model.rfind", "f.write", "just_the_dataset_name.rfind", "just_the_model.rfind", "f.write", "print", "str"], "function", ["None"], ["", "def", "write_grad_labels_to_file", "(", "rows_where_grad_more_efficient", ",", "model_folder_name", ",", "top_level_data_folder", ")", ":", "\n", "    ", "if", "not", "top_level_data_folder", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "top_level_data_folder", "+=", "'/'", "\n", "", "output_file", "=", "top_level_data_folder", "\n", "just_the_model", "=", "model_folder_name", "[", ":", "-", "1", "]", "\n", "just_the_model", "=", "just_the_model", "[", "just_the_model", ".", "rfind", "(", "'/'", ")", "+", "1", ":", "]", "\n", "just_the_model", "=", "just_the_model", "[", "just_the_model", ".", "index", "(", "'-'", ")", "+", "1", ":", "]", "\n", "just_the_dataset_name", "=", "model_folder_name", "[", ":", "-", "1", "]", "\n", "if", "'/'", "in", "just_the_dataset_name", ":", "\n", "        ", "just_the_dataset_name", "=", "just_the_dataset_name", "[", "just_the_dataset_name", ".", "rfind", "(", "'/'", ")", "+", "1", ":", "]", "\n", "", "if", "'-'", "in", "just_the_dataset_name", ":", "\n", "        ", "just_the_dataset_name", "=", "just_the_dataset_name", "[", ":", "just_the_dataset_name", ".", "index", "(", "'-'", ")", "]", "\n", "if", "just_the_dataset_name", "==", "''", ":", "\n", "            ", "dataset_name", "=", "'dataset'", "\n", "", "else", ":", "\n", "            ", "dataset_name", "=", "just_the_dataset_name", "\n", "", "", "else", ":", "\n", "        ", "dataset_name", "=", "'dataset'", "\n", "", "if", "just_the_model", ".", "endswith", "(", "'-train'", ")", ":", "\n", "        ", "output_file", "+=", "dataset_name", "+", "'_train'", "\n", "just_the_model", "=", "just_the_model", "[", ":", "just_the_model", ".", "rfind", "(", "'-'", ")", "]", "\n", "", "elif", "just_the_model", ".", "endswith", "(", "'-dev'", ")", ":", "\n", "        ", "output_file", "+=", "dataset_name", "+", "'_dev'", "\n", "just_the_model", "=", "just_the_model", "[", ":", "just_the_model", ".", "rfind", "(", "'-'", ")", "]", "\n", "", "else", ":", "\n", "        ", "output_file", "+=", "dataset_name", "+", "'_test'", "\n", "", "output_file", "+=", "'_attnperformancelabels_'", "+", "just_the_model", "+", "'.txt'", "\n", "with", "open", "(", "output_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "rows_where_grad_more_efficient", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "if", "rows_where_grad_more_efficient", "[", "i", "]", "==", "0", ":", "\n", "                ", "f", ".", "write", "(", "'0\\n'", ")", "\n", "", "elif", "rows_where_grad_more_efficient", "[", "i", "]", "==", "1", ":", "\n", "                ", "f", ".", "write", "(", "'1\\n'", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"ERROR: found value \"", "+", "str", "(", "rows_where_grad_more_efficient", "[", "i", "]", ")", "+", "\" in rows_where_grad_more_efficient\"", ")", "\n", "", "", "", "print", "(", "\"Successfully wrote attn performance labels to \"", "+", "output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax": [[776, 782], ["numpy.exp", "numpy.expand_dims", "numpy.expand_dims", "numpy.sum", "numpy.max"], "function", ["None"], ["", "def", "softmax", "(", "arr", ",", "axis", ")", ":", "\n", "    ", "arr", "=", "arr", "-", "np", ".", "expand_dims", "(", "np", ".", "max", "(", "arr", ",", "axis", "=", "axis", ")", ",", "axis", ")", "\n", "arr", "=", "np", ".", "exp", "(", "arr", ")", "\n", "ax_sum", "=", "np", ".", "expand_dims", "(", "np", ".", "sum", "(", "arr", ",", "axis", "=", "axis", ")", ",", "axis", ")", "\n", "p", "=", "arr", "/", "ax_sum", "\n", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.compare_outputs_by_grad": [[784, 826], ["str", "numpy.sum", "range", "process_test_outputs.softmax", "numpy.absolute", "numpy.sum", "range", "process_test_outputs.softmax", "numpy.absolute", "model_folder_name.endswith", "open", "range", "open", "range", "f.write", "f.write", "str", "str", "float", "float"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax"], ["", "def", "compare_outputs_by_grad", "(", "table", ",", "model_folder_name", ")", ":", "\n", "    ", "table", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", ">", "0", "]", "\n", "table", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", ">", "0", "]", "\n", "table", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "<", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", "]", "\n", "table", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", "<", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", "]", "\n", "\n", "grad_more_efficient", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", "<", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "]", "\n", "gme_presoftmax_outputs", "=", "grad_more_efficient", "[", ":", ",", "STARTING_IND_OF_OUTPUT_CLASSES", ":", "LAST_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "\n", "assert", "gme_presoftmax_outputs", ".", "shape", "[", "1", "]", "==", "2", ",", "str", "(", "gme_presoftmax_outputs", ".", "shape", ")", "\n", "should_not_all_be_1", "=", "np", ".", "sum", "(", "gme_presoftmax_outputs", ",", "axis", "=", "1", ")", "\n", "all_really_close_to_1", "=", "True", "\n", "for", "i", "in", "range", "(", "should_not_all_be_1", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "should_not_all_be_1", "[", "i", "]", "<", ".98", "or", "should_not_all_be_1", "[", "i", "]", ">", "1.02", ":", "\n", "            ", "all_really_close_to_1", "=", "False", "\n", "break", "\n", "", "", "assert", "not", "all_really_close_to_1", "\n", "gme_outputs", "=", "softmax", "(", "gme_presoftmax_outputs", ",", "axis", "=", "1", ")", "\n", "gme_output_diffs", "=", "np", ".", "absolute", "(", "gme_outputs", "[", ":", ",", "1", "]", "-", "gme_outputs", "[", ":", ",", "0", "]", ")", "\n", "\n", "grad_less_efficient", "=", "table", "[", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", ">", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "]", "\n", "gle_presoftmax_outputs", "=", "grad_less_efficient", "[", ":", ",", "STARTING_IND_OF_OUTPUT_CLASSES", ":", "LAST_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "\n", "assert", "gle_presoftmax_outputs", ".", "shape", "[", "1", "]", "==", "2", "\n", "should_not_all_be_1", "=", "np", ".", "sum", "(", "gle_presoftmax_outputs", ",", "axis", "=", "1", ")", "\n", "all_really_close_to_1", "=", "True", "\n", "for", "i", "in", "range", "(", "should_not_all_be_1", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "should_not_all_be_1", "[", "i", "]", "<", ".98", "or", "should_not_all_be_1", "[", "i", "]", ">", "1.02", ":", "\n", "            ", "all_really_close_to_1", "=", "False", "\n", "break", "\n", "", "", "assert", "not", "all_really_close_to_1", "\n", "gle_outputs", "=", "softmax", "(", "gle_presoftmax_outputs", ",", "axis", "=", "1", ")", "\n", "gle_output_diffs", "=", "np", ".", "absolute", "(", "gle_outputs", "[", ":", ",", "1", "]", "-", "gle_outputs", "[", ":", ",", "0", "]", ")", "\n", "\n", "if", "not", "model_folder_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_folder_name", "+=", "'/'", "\n", "", "gme_filename", "=", "model_folder_name", "+", "\"grad_more_efficient_outputclass_absvaldiffs.txt\"", "\n", "gle_filename", "=", "model_folder_name", "+", "\"grad_less_efficient_outputclass_absvaldiffs.txt\"", "\n", "with", "open", "(", "gme_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "gme_output_diffs", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "float", "(", "gme_output_diffs", "[", "i", "]", ")", ")", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "gle_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "gle_output_diffs", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "float", "(", "gle_output_diffs", "[", "i", "]", ")", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.compare_outputs_by_attndecflip": [[828, 868], ["numpy.logical_or", "numpy.sum", "range", "process_test_outputs.softmax", "numpy.absolute", "numpy.sum", "range", "process_test_outputs.softmax", "numpy.absolute", "model_folder_name.endswith", "open", "range", "open", "range", "numpy.logical_not", "f.write", "f.write", "str", "str", "float", "float"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax"], ["", "", "", "def", "compare_outputs_by_attndecflip", "(", "table", ",", "model_folder_name", ")", ":", "\n", "    ", "never_changed_mask", "=", "np", ".", "logical_or", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "==", "-", "1", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "==", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ")", "\n", "\n", "never_changed", "=", "table", "[", "never_changed_mask", "]", "\n", "nc_presoftmax_outputs", "=", "never_changed", "[", ":", ",", "STARTING_IND_OF_OUTPUT_CLASSES", ":", "LAST_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "\n", "assert", "nc_presoftmax_outputs", ".", "shape", "[", "1", "]", "==", "2", "\n", "should_not_all_be_1", "=", "np", ".", "sum", "(", "nc_presoftmax_outputs", ",", "axis", "=", "1", ")", "\n", "all_really_close_to_1", "=", "True", "\n", "for", "i", "in", "range", "(", "should_not_all_be_1", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "should_not_all_be_1", "[", "i", "]", "<", ".98", "or", "should_not_all_be_1", "[", "i", "]", ">", "1.02", ":", "\n", "            ", "all_really_close_to_1", "=", "False", "\n", "break", "\n", "", "", "assert", "not", "all_really_close_to_1", "\n", "nc_outputs", "=", "softmax", "(", "nc_presoftmax_outputs", ",", "axis", "=", "1", ")", "\n", "nc_output_diffs", "=", "np", ".", "absolute", "(", "nc_outputs", "[", ":", ",", "1", "]", "-", "nc_outputs", "[", ":", ",", "0", "]", ")", "\n", "\n", "changed", "=", "table", "[", "np", ".", "logical_not", "(", "never_changed_mask", ")", "]", "\n", "dc_presoftmax_outputs", "=", "changed", "[", ":", ",", "STARTING_IND_OF_OUTPUT_CLASSES", ":", "LAST_IND_OF_OUTPUT_CLASSES", "+", "1", "]", "\n", "assert", "dc_presoftmax_outputs", ".", "shape", "[", "1", "]", "==", "2", "\n", "should_not_all_be_1", "=", "np", ".", "sum", "(", "dc_presoftmax_outputs", ",", "axis", "=", "1", ")", "\n", "all_really_close_to_1", "=", "True", "\n", "for", "i", "in", "range", "(", "should_not_all_be_1", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "should_not_all_be_1", "[", "i", "]", "<", ".98", "or", "should_not_all_be_1", "[", "i", "]", ">", "1.02", ":", "\n", "            ", "all_really_close_to_1", "=", "False", "\n", "break", "\n", "", "", "assert", "not", "all_really_close_to_1", "\n", "dc_outputs", "=", "softmax", "(", "dc_presoftmax_outputs", ",", "axis", "=", "1", ")", "\n", "dc_output_diffs", "=", "np", ".", "absolute", "(", "dc_outputs", "[", ":", ",", "1", "]", "-", "dc_outputs", "[", ":", ",", "0", "]", ")", "\n", "\n", "if", "not", "model_folder_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_folder_name", "+=", "'/'", "\n", "", "nc_filename", "=", "model_folder_name", "+", "\"neverchangedbyattn_outputclass_absvaldiffs.txt\"", "\n", "dc_filename", "=", "model_folder_name", "+", "\"changedbyattn_outputclass_absvaldiffs.txt\"", "\n", "with", "open", "(", "nc_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "nc_output_diffs", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "float", "(", "nc_output_diffs", "[", "i", "]", ")", ")", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "dc_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "dc_output_diffs", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "float", "(", "dc_output_diffs", "[", "i", "]", ")", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.write_files_of_fracremoved_vs_attndiv": [[870, 894], ["model_folder_name.endswith", "open", "range", "open", "range", "str", "str", "f.write", "f.write", "f.write", "f.write", "f.write", "f.write", "str", "str", "str", "float", "str", "float", "float", "float"], "function", ["None"], ["", "", "", "def", "write_files_of_fracremoved_vs_attndiv", "(", "table", ",", "model_folder_name", ",", "seq_len_greater_than", ")", ":", "\n", "    ", "if", "not", "model_folder_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_folder_name", "+=", "'/'", "\n", "", "kl_file", "=", "model_folder_name", "+", "\"seqlengreaterthan\"", "+", "str", "(", "seq_len_greater_than", ")", "+", "\"_attnfracremoved_attnunifkldiv.txt\"", "\n", "js_file", "=", "model_folder_name", "+", "\"seqlengreaterthan\"", "+", "str", "(", "seq_len_greater_than", ")", "+", "\"_attnfracremoved_attnunifjsdiv.txt\"", "\n", "table", "=", "table", "[", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "seq_len_greater_than", "]", "\n", "attn_frac_removed_col", "=", "table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "\n", "kl_col", "=", "table", "[", ":", ",", "ATTN_KL_DIV_FROM_UNIF", "]", "\n", "js_col", "=", "table", "[", ":", ",", "ATTN_JS_DIV_FROM_UNIF", "]", "\n", "num_instances", "=", "table", ".", "shape", "[", "0", "]", "\n", "with", "open", "(", "kl_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "            ", "if", "attn_frac_removed_col", "[", "i", "]", ">", "0", ":", "\n", "                ", "f", ".", "write", "(", "str", "(", "float", "(", "attn_frac_removed_col", "[", "i", "]", ")", ")", "+", "','", ")", "\n", "", "else", ":", "\n", "                ", "f", ".", "write", "(", "'1.0,'", ")", "\n", "", "f", ".", "write", "(", "str", "(", "float", "(", "kl_col", "[", "i", "]", ")", ")", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "js_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "            ", "if", "attn_frac_removed_col", "[", "i", "]", ">", "0", ":", "\n", "                ", "f", ".", "write", "(", "str", "(", "float", "(", "attn_frac_removed_col", "[", "i", "]", ")", ")", "+", "','", ")", "\n", "", "else", ":", "\n", "                ", "f", ".", "write", "(", "'1.0,'", ")", "\n", "", "f", ".", "write", "(", "str", "(", "float", "(", "js_col", "[", "i", "]", ")", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.grad_more_efficient_attn_uniformity_test": [[896, 908], ["numpy.mean", "numpy.mean", "print", "print", "numpy.logical_not", "str", "str"], "function", ["None"], ["", "", "", "def", "grad_more_efficient_attn_uniformity_test", "(", "table", ",", "mask_where_grad_more_efficient", ",", "name_of_category", ")", ":", "\n", "# done by looking at JS divergence of attention from uniform.", "\n", "    ", "grad_divs", "=", "table", "[", ":", ",", "ATTN_JS_DIV_FROM_UNIF", "]", "[", "mask_where_grad_more_efficient", "]", "\n", "other_divs", "=", "table", "[", ":", ",", "ATTN_JS_DIV_FROM_UNIF", "]", "[", "np", ".", "logical_not", "(", "mask_where_grad_more_efficient", ")", "]", "\n", "grad_div_mean", "=", "np", ".", "mean", "(", "grad_divs", ")", "\n", "other_divs_mean", "=", "np", ".", "mean", "(", "other_divs", ")", "\n", "print", "(", "\"Mean attn-from-unif JS divs:   \"", "+", "name_of_category", "+", "\"-more-efficient instances:\"", "+", "str", "(", "grad_div_mean", ")", "+", "\n", "\"   All others:\"", "+", "str", "(", "other_divs_mean", ")", ")", "\n", "if", "grad_div_mean", ">=", "other_divs_mean", ":", "\n", "        ", "print", "(", "\"Means already contradict hypothesis; not bothering to run McNemar's.\"", ")", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "# data not paired, so this doesn't make sense", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_per_instance_removal_efficiency_comparison": [[913, 994], ["numpy.logical_and", "numpy.logical_and", "numpy.logical_or", "numpy.sum", "print", "process_test_outputs.grad_more_efficient_attn_uniformity_test", "numpy.all", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "int", "int", "numpy.logical_and", "numpy.logical_xor", "numpy.logical_and", "numpy.logical_and", "int", "int", "numpy.logical_and", "numpy.logical_not", "numpy.logical_and", "numpy.sum", "numpy.sum", "int", "int", "numpy.sum", "numpy.sum", "int", "int", "numpy.logical_or", "numpy.logical_and", "numpy.logical_and", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "str", "str", "str", "str", "numpy.sum", "str", "str", "str", "str", "str", "numpy.sum", "numpy.logical_and"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.grad_more_efficient_attn_uniformity_test"], ["", "", "def", "print_per_instance_removal_efficiency_comparison", "(", "table", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", ",", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", ",", "cat1_name", ",", "cat2_name", ",", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat1", ",", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat2", ")", ":", "\n", "    ", "table_of_seqs_longer_than_1_singleneg1", "=", "table", "[", "\n", "np", ".", "logical_and", "(", "np", ".", "logical_or", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "==", "-", "1", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", "==", "-", "1", ")", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "]", "\n", "table_of_seqs_longer_than_1_singleneg1", "=", "table_of_seqs_longer_than_1_singleneg1", "[", "\n", "np", ".", "logical_not", "(", "np", ".", "logical_and", "(", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "==", "-", "1", ",", "\n", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", "==", "-", "1", ")", ")", "]", "\n", "table_of_seqs_longer_than_1_no_neg1s", "=", "table", "[", "np", ".", "logical_and", "(", "np", ".", "logical_and", "(", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ",", "\n", "table", "[", ":", ",", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "!=", "-", "1", ")", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", "!=", "-", "1", ")", "]", "\n", "total_num_seqs_longer_than_1", "=", "table_of_seqs_longer_than_1_singleneg1", ".", "shape", "[", "0", "]", "+", "table_of_seqs_longer_than_1_no_neg1s", ".", "shape", "[", "0", "]", "\n", "attn_more_efficient", "=", "int", "(", "np", ".", "sum", "(", "table_of_seqs_longer_than_1_no_neg1s", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "<", "\n", "table_of_seqs_longer_than_1_no_neg1s", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", ")", ")", "+", "int", "(", "np", ".", "sum", "(", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", ">", "\n", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", ")", ")", "# we achieved a decflip with attn, not grad", "\n", "\n", "mask_for_seqs_longer_than_1_no_neg1s", "=", "(", "np", ".", "logical_and", "(", "np", ".", "logical_and", "(", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "!=", "-", "1", ")", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", "!=", "-", "1", ")", ")", "\n", "mask_for_seqs_longer_than_1_singleneg1", "=", "(", "\n", "np", ".", "logical_and", "(", "np", ".", "logical_xor", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "==", "-", "1", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", "==", "-", "1", ")", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", ")", "\n", "rows_where_cat2_more_efficient", "=", "np", ".", "logical_or", "(", "np", ".", "logical_and", "(", "mask_for_seqs_longer_than_1_no_neg1s", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", ">", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", ")", ",", "\n", "np", ".", "logical_and", "(", "mask_for_seqs_longer_than_1_singleneg1", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "<", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", ")", ")", "\n", "grad_more_efficient", "=", "np", ".", "sum", "(", "rows_where_cat2_more_efficient", ")", "\n", "assert", "(", "int", "(", "np", ".", "sum", "(", "table_of_seqs_longer_than_1_no_neg1s", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat1", "]", ">", "\n", "table_of_seqs_longer_than_1_no_neg1s", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat2", "]", ")", ")", "+", "\n", "int", "(", "np", ".", "sum", "(", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat1", "]", "<", "\n", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat2", "]", ")", ")", "==", "\n", "grad_more_efficient", ")", "\n", "assert", "rows_where_cat2_more_efficient", ".", "shape", "[", "0", "]", "==", "table", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", ")", "\n", "grad_more_efficient_attn_uniformity_test", "(", "table", ",", "rows_where_cat2_more_efficient", ",", "cat2_name", ")", "\n", "\n", "both_same", "=", "int", "(", "np", ".", "sum", "(", "table_of_seqs_longer_than_1_no_neg1s", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "==", "\n", "table_of_seqs_longer_than_1_no_neg1s", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", ")", ")", "+", "int", "(", "np", ".", "sum", "(", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "==", "\n", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", ")", ")", "\n", "assert", "(", "int", "(", "np", ".", "sum", "(", "table_of_seqs_longer_than_1_no_neg1s", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat1", "]", "==", "\n", "table_of_seqs_longer_than_1_no_neg1s", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat2", "]", ")", ")", "+", "\n", "int", "(", "np", ".", "sum", "(", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat1", "]", "==", "\n", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat2", "]", ")", ")", "==", "\n", "both_same", ")", "\n", "assert", "attn_more_efficient", "+", "grad_more_efficient", "+", "both_same", "==", "total_num_seqs_longer_than_1", "\n", "assert", "np", ".", "all", "(", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat1", "]", "!=", "\n", "table_of_seqs_longer_than_1_singleneg1", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_cat2", "]", ")", "\n", "\n", "print", "(", "\"Found \"", "+", "str", "(", "table_of_seqs_longer_than_1_singleneg1", ".", "shape", "[", "0", "]", ")", "+", "\n", "\" cases where exactly one of either \"", "+", "cat1_name", "+", "\" or \"", "+", "cat2_name", "+", "\n", "\" never flipped the decision; leaving those in for analysis.\"", ")", "\n", "print", "(", "\"REMOVING FROM ANALYSIS the \"", "+", "\n", "str", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", "==", "1", ")", ")", "+", "\" cases with an attention length of 1\"", ")", "\n", "temp_table", "=", "table", "[", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", "]", "\n", "print", "(", "\"REMOVING FROM ANALYSIS the \"", "+", "\n", "str", "(", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "temp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat1", "]", "==", "-", "1", ",", "\n", "temp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_cat2", "]", "==", "-", "1", ")", ")", ")", "+", "\n", "\" OTHER cases where neither \"", "+", "cat1_name", "+", "\" nor \"", "+", "cat2_name", "+", "\" EVER flipped the decision\"", ")", "\n", "print", "(", "\"Cases where rem_by_highest_\"", "+", "cat1_name", "+", "\" more efficient than rem_by_highest_\"", "+", "cat2_name", "+", "\": \"", ",", "end", "=", "''", ")", "\n", "print", "(", "str", "(", "attn_more_efficient", ")", "+", "\"\\t (\"", "+", "str", "(", "attn_more_efficient", "/", "total_num_seqs_longer_than_1", ")", "+", "\n", "\" of cases with attn len > 1)\"", ")", "\n", "print", "(", "\"Cases where rem_by_highest_\"", "+", "cat1_name", "+", "\" less efficient than rem_by_highest_\"", "+", "cat2_name", "+", "\": \"", ",", "end", "=", "''", ")", "\n", "print", "(", "str", "(", "grad_more_efficient", ")", "+", "\"\\t (\"", "+", "str", "(", "grad_more_efficient", "/", "total_num_seqs_longer_than_1", ")", "+", "\n", "\" of cases with attn len > 1)\"", ")", "\n", "print", "(", "\"Cases where both equally efficient: \"", ",", "end", "=", "''", ")", "\n", "print", "(", "str", "(", "both_same", ")", "+", "\"\\t (\"", "+", "str", "(", "both_same", "/", "total_num_seqs_longer_than_1", ")", "+", "\" of cases with attn len > 1)\"", ")", "\n", "print", "(", ")", "\n", "return", "rows_where_cat2_more_efficient", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.main": [[996, 1148], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.produce_figs.lower().startswith", "parser.parse_args.write_attnperf_labels.lower().startswith", "process_test_outputs.load_in_data_table", "process_test_outputs.write_files_of_fracremoved_vs_attndiv", "process_test_outputs.write_files_of_fracremoved_vs_attndiv", "print", "process_test_outputs.print_label_distrib_for_rows", "print", "process_test_outputs.report_frac_for_model", "process_test_outputs.report_frac_for_model", "process_test_outputs.report_frac_for_model", "process_test_outputs.report_frac_for_model", "process_test_outputs.report_frac_for_model", "process_test_outputs.report_frac_for_model", "process_test_outputs.report_frac_for_model", "process_test_outputs.print_per_instance_removal_efficiency_comparison", "process_test_outputs.print_per_instance_removal_efficiency_comparison", "process_test_outputs.print_per_instance_removal_efficiency_comparison", "process_test_outputs.get_vsrand_2x2_decflip_jointdist", "process_test_outputs.get_vsrand_2x2_decflip_jointdist", "process_test_outputs.get_vsrand_2x2_decflip_jointdist", "process_test_outputs.get_vsrand_2x2_decflip_jointdist", "print", "process_test_outputs.get_vs2nd_2x2_decflip_jointdist", "print", "process_test_outputs.get_default_class_info", "process_test_outputs.zoomed_out_vs_random_tests", "process_test_outputs.coarse_grained_single_attn_weight_tests", "process_test_outputs.fine_grained_single_attn_weight_tests", "print", "process_test_outputs.coarse_grained_single_attn_weight_tests", "process_test_outputs.fine_grained_single_attn_weight_tests", "print", "process_test_outputs.test_needed_rem_lots_vs_not", "print", "print", "print", "print", "default_directories.base_output_dir.endswith", "model_folder_name.endswith", "image_dir.endswith", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "process_test_outputs.compare_outputs_by_grad", "process_test_outputs.compare_outputs_by_attndecflip", "process_test_outputs.write_grad_labels_to_file", "process_test_outputs.make_and_save_hist", "parser.parse_args.produce_figs.lower", "parser.parse_args.write_attnperf_labels.lower", "model_folder_name.index", "int", "int", "int", "str", "str", "str", "numpy.sum", "numpy.sum", "numpy.sum", "process_test_outputs.get_test_accuracy", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.load_in_data_table", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.write_files_of_fracremoved_vs_attndiv", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.write_files_of_fracremoved_vs_attndiv", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_label_distrib_for_rows", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.report_frac_for_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.report_frac_for_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.report_frac_for_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.report_frac_for_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.report_frac_for_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.report_frac_for_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.report_frac_for_model", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_per_instance_removal_efficiency_comparison", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_per_instance_removal_efficiency_comparison", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.print_per_instance_removal_efficiency_comparison", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_vsrand_2x2_decflip_jointdist", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_vsrand_2x2_decflip_jointdist", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_vsrand_2x2_decflip_jointdist", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_vsrand_2x2_decflip_jointdist", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_vs2nd_2x2_decflip_jointdist", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_default_class_info", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.zoomed_out_vs_random_tests", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.coarse_grained_single_attn_weight_tests", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.fine_grained_single_attn_weight_tests", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.coarse_grained_single_attn_weight_tests", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.fine_grained_single_attn_weight_tests", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.test_needed_rem_lots_vs_not", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.compare_outputs_by_grad", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.compare_outputs_by_attndecflip", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.write_grad_labels_to_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.make_and_save_hist", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_test_accuracy"], ["", "def", "main", "(", "constrain_to_guessed_label", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--model-folder-name\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The local name of the directories associated with the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--write-attnperf-labels\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "\"True\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--base-output-dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "base_output_directory", ",", "\n", "help", "=", "\"The name of the top-level output directory containing other output directories\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--base-images-dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "base_image_dir", ",", "\n", "help", "=", "\"The directory in which to store any created plots or histograms\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--top-level-data-dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "base_data_directory", ",", "\n", "help", "=", "'Top level dir containing data (some info will be written there)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--produce-figs\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "\"Whether to produce figures as part of script\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "args", ".", "produce_figs", ".", "lower", "(", ")", ".", "startswith", "(", "'t'", ")", ":", "\n", "        ", "produce_figs", "=", "True", "\n", "", "else", ":", "\n", "        ", "produce_figs", "=", "False", "\n", "", "if", "args", ".", "write_attnperf_labels", ".", "lower", "(", ")", ".", "startswith", "(", "'t'", ")", ":", "\n", "        ", "write_attnperf", "=", "True", "\n", "", "else", ":", "\n", "        ", "write_attnperf", "=", "False", "\n", "", "base_output_dir", "=", "args", ".", "base_output_dir", "\n", "if", "not", "base_output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "base_output_dir", "+=", "'/'", "\n", "", "model_folder_name", "=", "args", ".", "model_folder_name", "\n", "if", "'-han'", "in", "model_folder_name", ":", "\n", "        ", "is_han", "=", "True", "\n", "", "else", ":", "\n", "        ", "is_han", "=", "False", "\n", "", "if", "not", "model_folder_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_folder_name", "+=", "'/'", "\n", "", "image_dir", "=", "args", ".", "base_images_dir", "\n", "if", "not", "image_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "image_dir", "+=", "'/'", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "", "global", "image_directory", ",", "dataset_output_directory", "\n", "image_directory", "=", "image_dir", "+", "model_folder_name", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "image_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_directory", ")", "\n", "", "dataset_name", "=", "model_folder_name", "[", ":", "model_folder_name", ".", "index", "(", "'-'", ")", "]", "\n", "dataset_output_directory", "=", "image_dir", "+", "dataset_name", "+", "'/'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dataset_output_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dataset_output_directory", ")", "\n", "", "file_dir", "=", "base_output_dir", "+", "model_folder_name", "\n", "global", "first_v_second_fname", ",", "dec_flip_stats_fname", ",", "rand_results_fname", ",", "unchanged_fname", ",", "data_dir", ",", "grad_based_stats_fname", ",", "dec_flip_rand_nontop_stats_fname", ",", "attn_div_from_unif_fname", ",", "gradsignmult_based_stats_fname", ",", "dec_flip_rand_nontopbygrad_stats_fname", ",", "dec_flip_rand_nontopbygradmult_stats_fname", ",", "dec_flip_rand_nontopbygradsignmult_stats_fname", "\n", "data_dir", "=", "file_dir", "\n", "first_v_second_fname", "=", "file_dir", "+", "first_v_second_fname", "\n", "dec_flip_stats_fname", "=", "file_dir", "+", "dec_flip_stats_fname", "\n", "rand_results_fname", "=", "file_dir", "+", "rand_results_fname", "\n", "unchanged_fname", "=", "file_dir", "+", "unchanged_fname", "\n", "grad_based_stats_fname", "=", "file_dir", "+", "grad_based_stats_fname", "\n", "dec_flip_rand_nontop_stats_fname", "=", "file_dir", "+", "dec_flip_rand_nontop_stats_fname", "\n", "attn_div_from_unif_fname", "=", "file_dir", "+", "attn_div_from_unif_fname", "\n", "gradsignmult_based_stats_fname", "=", "file_dir", "+", "gradsignmult_based_stats_fname", "\n", "dec_flip_rand_nontopbygrad_stats_fname", "=", "file_dir", "+", "dec_flip_rand_nontopbygrad_stats_fname", "\n", "dec_flip_rand_nontopbygradmult_stats_fname", "=", "file_dir", "+", "dec_flip_rand_nontopbygradmult_stats_fname", "\n", "dec_flip_rand_nontopbygradsignmult_stats_fname", "=", "file_dir", "+", "dec_flip_rand_nontopbygradsignmult_stats_fname", "\n", "table", "=", "load_in_data_table", "(", "first_v_second_fname", ",", "dec_flip_stats_fname", ",", "rand_results_fname", ",", "unchanged_fname", ",", "\n", "grad_based_stats_fname", ",", "dec_flip_rand_nontop_stats_fname", ",", "attn_div_from_unif_fname", ",", "\n", "gradsignmult_based_stats_fname", ",", "dec_flip_rand_nontopbygrad_stats_fname", ",", "\n", "dec_flip_rand_nontopbygradmult_stats_fname", ",", "\n", "dec_flip_rand_nontopbygradsignmult_stats_fname", ")", "\n", "if", "constrain_to_guessed_label", "is", "not", "None", ":", "\n", "        ", "table", "=", "table", "[", "table", "[", ":", ",", "ORIG_LABEL_GUESSED", "]", "==", "constrain_to_guessed_label", "]", "\n", "\n", "", "if", "LAST_IND_OF_OUTPUT_CLASSES", "-", "STARTING_IND_OF_OUTPUT_CLASSES", "==", "2", ":", "\n", "        ", "compare_outputs_by_grad", "(", "table", ",", "file_dir", ")", "\n", "compare_outputs_by_attndecflip", "(", "table", ",", "file_dir", ")", "\n", "\n", "", "write_files_of_fracremoved_vs_attndiv", "(", "table", ",", "file_dir", ",", "1", ")", "\n", "write_files_of_fracremoved_vs_attndiv", "(", "table", ",", "file_dir", ",", "5", ")", "\n", "\n", "# make sure that test results didn't get garbled-- do a couple of quick tests", "\n", "if", "table", ".", "shape", "[", "0", "]", ">", "10", ":", "\n", "        ", "assert", "int", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRADMULT", "]", "!=", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", ")", ")", ">", "0", "\n", "assert", "int", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRAD", "]", "!=", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", ")", ")", ">", "0", "\n", "assert", "int", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRADMULT", "]", "!=", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRAD", "]", ")", ")", ">", "0", "\n", "\n", "", "print", "(", "\"Test set accuracy: \"", "+", "str", "(", "get_test_accuracy", "(", "table", ")", ")", ")", "\n", "print_label_distrib_for_rows", "(", "table", ",", "\"ALL\"", ")", "\n", "print", "(", ")", "\n", "report_frac_for_model", "(", "'from_top_gradsignmult'", ",", "table", ")", "\n", "report_frac_for_model", "(", "'from_top_grad_mult'", ",", "table", ")", "\n", "report_frac_for_model", "(", "'from_top_grad'", ",", "table", ")", "\n", "report_frac_for_model", "(", "'from_top'", ",", "table", ")", "\n", "report_frac_for_model", "(", "'avg_random'", ",", "table", ")", "\n", "report_frac_for_model", "(", "'from_bottom'", ",", "table", ")", "\n", "report_frac_for_model", "(", "'from_top_probmass'", ",", "table", ")", "\n", "\n", "\"\"\"\n    grad_more_efficient = int(np.sum(table_of_seqs_longer_than_1_no_neg1s[:, NEEDED_REM_TOP_X_FOR_DECFLIP] >\n                                     table_of_seqs_longer_than_1_no_neg1s[:, NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD])) + \\\n                          int(np.sum(table_of_seqs_longer_than_1_singleneg1[:, NEEDED_REM_TOP_X_FOR_DECFLIP] <\n                                     table_of_seqs_longer_than_1_singleneg1[:, NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD]))\n    \"\"\"", "\n", "print_per_instance_removal_efficiency_comparison", "(", "table", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", ",", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADSIGNMULT", ",", "'attn'", ",", "'gradsignmult'", ",", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", ",", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADSIGNMULT", ")", "\n", "print_per_instance_removal_efficiency_comparison", "(", "table", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", ",", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRADMULT", ",", "'attn'", ",", "'gradmult'", ",", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", ",", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", ")", "\n", "rows_where_grad_more_efficient", "=", "print_per_instance_removal_efficiency_comparison", "(", "table", ",", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP", ",", "\n", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", ",", "\n", "'attn'", ",", "'grad'", ",", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", ",", "\n", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", ")", "\n", "if", "write_attnperf", ":", "\n", "        ", "write_grad_labels_to_file", "(", "rows_where_grad_more_efficient", ",", "model_folder_name", ",", "args", ".", "top_level_data_dir", ")", "\n", "\n", "", "get_vsrand_2x2_decflip_jointdist", "(", "table", ",", "\"Top-attn vs. rand nontop weight\"", ",", "DEC_FLIP_ZERO_HIGHEST", ",", "\n", "NONTOP_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "is_han", ")", "\n", "get_vsrand_2x2_decflip_jointdist", "(", "table", ",", "\"Top-GRAD vs. rand nontop weight\"", ",", "DEC_FLIP_ZERO_HIGHESTGRAD", ",", "\n", "NONTOPBYGRAD_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "is_han", ")", "\n", "get_vsrand_2x2_decflip_jointdist", "(", "table", ",", "\"Top-GRADMULT vs. rand nontop weight\"", ",", "DEC_FLIP_ZERO_HIGHESTGRADMULT", ",", "\n", "NONTOPBYGRADMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "is_han", ")", "\n", "get_vsrand_2x2_decflip_jointdist", "(", "table", ",", "\"Top-GRADSIGNMULT vs. rand nontop weight\"", ",", "DEC_FLIP_ZERO_HIGHESTGRADSIGNMULT", ",", "\n", "NONTOPBYGRADSIGNMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "is_han", ")", "\n", "print", "(", ")", "\n", "get_vs2nd_2x2_decflip_jointdist", "(", "table", ")", "\n", "print", "(", ")", "\n", "get_default_class_info", "(", "table", ")", "\n", "zoomed_out_vs_random_tests", "(", "table", ",", "is_han", ",", "produce_figs", ")", "\n", "\n", "if", "produce_figs", ":", "\n", "        ", "make_and_save_hist", "(", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ",", "dataset_output_directory", "+", "\"num_sents_test_docs.png\"", ",", "\n", "title", "=", "\"Number of sentences in test docs\"", ",", "\n", "have_left_bin_edge_at", "=", "0", ",", "bin_size", "=", "1", ",", "make_log_scale", "=", "True", ")", "\n", "", "coarse_grained_single_attn_weight_tests", "(", "True", ",", "table", ")", "\n", "fine_grained_single_attn_weight_tests", "(", "True", ",", "table", ")", "\n", "print", "(", ")", "\n", "coarse_grained_single_attn_weight_tests", "(", "False", ",", "table", ")", "\n", "fine_grained_single_attn_weight_tests", "(", "False", ",", "table", ")", "\n", "print", "(", ")", "\n", "test_needed_rem_lots_vs_not", "(", "table", ")", "\n", "\n", "print", "(", "\"needed to remove:   \"", "+", "str", "(", "table", "[", "90", ":", "100", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", ")", "+", "\" (removing from highest)\"", ")", "\n", "print", "(", "\"needed to remove:   \"", "+", "str", "(", "table", "[", "90", ":", "100", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", ")", "+", "\n", "\" (removing from highest grad)\"", ")", "\n", "print", "(", "\"sequence lens:      \"", "+", "str", "(", "table", "[", "90", ":", "100", ",", "ATTN_SEQ_LEN", "]", ")", ")", "\n", "print", "(", "\"original decisions: \"", "+", "str", "(", "table", "[", "90", ":", "100", ",", "ORIG_LABEL_GUESSED", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.test_js_divs": [[1150, 1222], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "process_test_outputs.load_in_data_table", "print", "default_directories.base_output_dir.endswith", "model_folder_name.endswith", "image_dir.endswith", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "numpy.sum", "model_folder_name.index", "int", "int", "int", "numpy.sum", "numpy.sum", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.load_in_data_table", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "test_js_divs", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--model-folder-name\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The local name of the directories associated with the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--base-output-dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "base_output_directory", ",", "\n", "help", "=", "\"The name of the top-level output directory containing other output directories\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--base-images-dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "default", "=", "base_image_dir", ",", "\n", "help", "=", "\"The directory in which to store any created plots or histograms\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "base_output_dir", "=", "args", ".", "base_output_dir", "\n", "if", "not", "base_output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "base_output_dir", "+=", "'/'", "\n", "", "model_folder_name", "=", "args", ".", "model_folder_name", "\n", "if", "'-han'", "in", "model_folder_name", ":", "\n", "        ", "is_han", "=", "True", "\n", "", "else", ":", "\n", "        ", "is_han", "=", "False", "\n", "", "if", "not", "model_folder_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_folder_name", "+=", "'/'", "\n", "", "image_dir", "=", "args", ".", "base_images_dir", "\n", "if", "not", "image_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "image_dir", "+=", "'/'", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "", "global", "image_directory", ",", "dataset_output_directory", "\n", "image_directory", "=", "image_dir", "+", "model_folder_name", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "image_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_directory", ")", "\n", "", "dataset_name", "=", "model_folder_name", "[", ":", "model_folder_name", ".", "index", "(", "'-'", ")", "]", "\n", "dataset_output_directory", "=", "image_dir", "+", "dataset_name", "+", "'/'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dataset_output_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dataset_output_directory", ")", "\n", "", "file_dir", "=", "base_output_dir", "+", "model_folder_name", "\n", "global", "first_v_second_fname", ",", "dec_flip_stats_fname", ",", "rand_results_fname", ",", "unchanged_fname", ",", "data_dir", ",", "grad_based_stats_fname", ",", "dec_flip_rand_nontop_stats_fname", ",", "attn_div_from_unif_fname", ",", "gradsignmult_based_stats_fname", ",", "dec_flip_rand_nontopbygrad_stats_fname", ",", "dec_flip_rand_nontopbygradmult_stats_fname", ",", "dec_flip_rand_nontopbygradsignmult_stats_fname", "\n", "data_dir", "=", "file_dir", "\n", "first_v_second_fname", "=", "file_dir", "+", "first_v_second_fname", "\n", "dec_flip_stats_fname", "=", "file_dir", "+", "dec_flip_stats_fname", "\n", "rand_results_fname", "=", "file_dir", "+", "rand_results_fname", "\n", "unchanged_fname", "=", "file_dir", "+", "unchanged_fname", "\n", "grad_based_stats_fname", "=", "file_dir", "+", "grad_based_stats_fname", "\n", "dec_flip_rand_nontop_stats_fname", "=", "file_dir", "+", "dec_flip_rand_nontop_stats_fname", "\n", "attn_div_from_unif_fname", "=", "file_dir", "+", "attn_div_from_unif_fname", "\n", "gradsignmult_based_stats_fname", "=", "file_dir", "+", "gradsignmult_based_stats_fname", "\n", "dec_flip_rand_nontopbygrad_stats_fname", "=", "file_dir", "+", "dec_flip_rand_nontopbygrad_stats_fname", "\n", "dec_flip_rand_nontopbygradmult_stats_fname", "=", "file_dir", "+", "dec_flip_rand_nontopbygradmult_stats_fname", "\n", "dec_flip_rand_nontopbygradsignmult_stats_fname", "=", "file_dir", "+", "dec_flip_rand_nontopbygradsignmult_stats_fname", "\n", "table", "=", "load_in_data_table", "(", "first_v_second_fname", ",", "dec_flip_stats_fname", ",", "rand_results_fname", ",", "unchanged_fname", ",", "\n", "grad_based_stats_fname", ",", "dec_flip_rand_nontop_stats_fname", ",", "attn_div_from_unif_fname", ",", "\n", "gradsignmult_based_stats_fname", ",", "dec_flip_rand_nontopbygrad_stats_fname", ",", "\n", "dec_flip_rand_nontopbygradmult_stats_fname", ",", "\n", "dec_flip_rand_nontopbygradsignmult_stats_fname", ")", "\n", "\n", "# make sure that test results didn't get garbled-- do a couple of quick tests", "\n", "if", "table", ".", "shape", "[", "0", "]", ">", "10", ":", "\n", "        ", "assert", "int", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRADMULT", "]", "!=", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", ")", ")", ">", "0", "\n", "assert", "int", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRAD", "]", "!=", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", ")", ")", ">", "0", "\n", "assert", "int", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRADMULT", "]", "!=", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHESTGRAD", "]", ")", ")", ">", "0", "\n", "\n", "", "mask", "=", "(", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", "\n", "table", "=", "table", "[", "mask", "]", "\n", "max_weights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "data_dir", ",", "\n", "ind_corresponds_to_weight_sorted_in_dec_order", "=", "True", ")", "[", "mask", "]", "\n", "high_js_divdiff_mask", "=", "(", "(", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", "-", "table", "[", ":", ",", "NONTOP_RAND_JS_DIV", "]", ")", ">", "0.1", ")", "\n", "high_js_divdiff_rows", "=", "table", "[", "high_js_divdiff_mask", "]", "\n", "max_weights", "=", "max_weights", "[", "high_js_divdiff_mask", "]", "\n", "print", "(", "np", ".", "sum", "(", "(", "max_weights", "-", "high_js_divdiff_rows", "[", ":", ",", "NONTOP_RAND_ZEROED_WEIGHT", "]", ")", "<", "0.05", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.dump_metrics": [[15, 21], ["json.dumps", "open", "metrics_file.write", "logger.info"], "function", ["None"], ["def", "dump_metrics", "(", "file_path", ":", "str", ",", "metrics", ":", "Dict", "[", "str", ",", "Any", "]", ",", "log", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "    ", "metrics_json", "=", "json", ".", "dumps", "(", "metrics", ",", "indent", "=", "2", ")", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "metrics_file", ":", "\n", "        ", "metrics_file", ".", "write", "(", "metrics_json", ")", "\n", "", "if", "log", ":", "\n", "        ", "logger", ".", "info", "(", "\"Metrics: %s\"", ",", "metrics_json", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.datasets_from_params": [[23, 54], ["allennlp.data.dataset_readers.DatasetReader.from_params", "params.pop", "params.pop", "logger.info", "DatasetReader.from_params.read", "params.pop", "params.pop", "params.pop", "logger.info", "allennlp.data.dataset_readers.DatasetReader.from_params", "logger.info", "DatasetReader.from_params.read", "logger.info", "DatasetReader.from_params.read"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params"], ["", "", "def", "datasets_from_params", "(", "params", ":", "Params", ")", "->", "Dict", "[", "str", ",", "Iterable", "[", "Instance", "]", "]", ":", "\n", "    ", "\"\"\"\n    Load all the datasets specified by the config.\n    \"\"\"", "\n", "dataset_reader", "=", "DatasetReader", ".", "from_params", "(", "params", ".", "pop", "(", "'dataset_reader'", ")", ")", "\n", "validation_dataset_reader_params", "=", "params", ".", "pop", "(", "\"validation_dataset_reader\"", ",", "None", ")", "\n", "\n", "validation_and_test_dataset_reader", ":", "DatasetReader", "=", "dataset_reader", "\n", "if", "validation_dataset_reader_params", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using a separate dataset reader to load validation and test data.\"", ")", "\n", "validation_and_test_dataset_reader", "=", "DatasetReader", ".", "from_params", "(", "validation_dataset_reader_params", ")", "\n", "\n", "", "train_data_path", "=", "params", ".", "pop", "(", "'train_data_path'", ")", "\n", "logger", ".", "info", "(", "\"Reading training data from %s\"", ",", "train_data_path", ")", "\n", "train_data", "=", "dataset_reader", ".", "read", "(", "train_data_path", ")", "\n", "\n", "datasets", ":", "Dict", "[", "str", ",", "Iterable", "[", "Instance", "]", "]", "=", "{", "\"train\"", ":", "train_data", "}", "\n", "\n", "validation_data_path", "=", "params", ".", "pop", "(", "'validation_data_path'", ",", "None", ")", "\n", "if", "validation_data_path", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Reading validation data from %s\"", ",", "validation_data_path", ")", "\n", "validation_data", "=", "validation_and_test_dataset_reader", ".", "read", "(", "validation_data_path", ")", "\n", "datasets", "[", "\"validation\"", "]", "=", "validation_data", "\n", "\n", "", "test_data_path", "=", "params", ".", "pop", "(", "\"test_data_path\"", ",", "None", ")", "\n", "if", "test_data_path", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Reading test data from %s\"", ",", "test_data_path", ")", "\n", "test_data", "=", "validation_and_test_dataset_reader", ".", "read", "(", "test_data_path", ")", "\n", "datasets", "[", "\"test\"", "]", "=", "test_data", "\n", "\n", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.get_frozen_and_tunable_parameter_names": [[56, 65], ["model.named_parameters", "frozen_parameter_names.append", "tunable_parameter_names.append"], "function", ["None"], ["", "def", "get_frozen_and_tunable_parameter_names", "(", "model", ":", "torch", ".", "nn", ".", "Module", ")", "->", "List", ":", "\n", "    ", "frozen_parameter_names", "=", "[", "]", "\n", "tunable_parameter_names", "=", "[", "]", "\n", "for", "name", ",", "parameter", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "not", "parameter", ".", "requires_grad", ":", "\n", "            ", "frozen_parameter_names", ".", "append", "(", "name", ")", "\n", "", "else", ":", "\n", "            ", "tunable_parameter_names", ".", "append", "(", "name", ")", "\n", "", "", "return", "[", "frozen_parameter_names", ",", "tunable_parameter_names", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.cleanup_global_logging": [[67, 82], ["stdout_handler.close", "logging.getLogger().removeHandler", "isinstance", "isinstance", "sys.stdout.cleanup", "sys.stderr.cleanup", "logging.getLogger"], "function", ["None"], ["", "def", "cleanup_global_logging", "(", "stdout_handler", ":", "logging", ".", "FileHandler", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    This function closes any open file handles and logs set up by `prepare_global_logging`.\n    Parameters\n    ----------\n    stdout_handler : ``logging.FileHandler``, required.\n        The file handler returned from `prepare_global_logging`, attached to the global logger.\n    \"\"\"", "\n", "stdout_handler", ".", "close", "(", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "removeHandler", "(", "stdout_handler", ")", "\n", "\n", "if", "isinstance", "(", "sys", ".", "stdout", ",", "TeeLogger", ")", ":", "\n", "        ", "sys", ".", "stdout", "=", "sys", ".", "stdout", ".", "cleanup", "(", ")", "\n", "", "if", "isinstance", "(", "sys", ".", "stderr", ",", "TeeLogger", ")", ":", "\n", "        ", "sys", ".", "stderr", "=", "sys", ".", "stderr", ".", "cleanup", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.talkative_simple_han_attn_layer.TalkativeSimpleHanAttention.__init__": [[35, 50], ["allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.__init__", "talkative_simple_han_attn_layer.TalkativeSimpleHanAttention._mlp.weight.size", "talkative_simple_han_attn_layer.TalkativeSimpleHanAttention._input_vector_dir_name.endswith"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "attn_params", ":", "SimpleHanAttention", ",", "\n", "attn_weight_filename", ",", "\n", "corr_vector_dir", ",", "\n", "total_num_test_instances", ")", "->", "None", ":", "\n", "        ", "super", "(", "TalkativeSimpleHanAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_mlp", "=", "attn_params", ".", "_mlp", "\n", "self", ".", "_context_dot_product", "=", "attn_params", ".", "_context_dot_product", "\n", "self", ".", "vec_dim", "=", "self", ".", "_mlp", ".", "weight", ".", "size", "(", "1", ")", "\n", "self", ".", "_total_num_test_instances", "=", "total_num_test_instances", "\n", "self", ".", "_attn_weight_filename", "=", "attn_weight_filename", "\n", "self", ".", "_input_vector_dir_name", "=", "corr_vector_dir", "\n", "if", "not", "self", ".", "_input_vector_dir_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "self", ".", "_input_vector_dir_name", "+=", "'/'", "\n", "", "self", ".", "_next_available_counter_ind_file", "=", "self", ".", "_input_vector_dir_name", "+", "\"next_available_counter.txt\"", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.talkative_simple_han_attn_layer.TalkativeSimpleHanAttention.get_input_dim": [[51, 54], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "vec_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.talkative_simple_han_attn_layer.TalkativeSimpleHanAttention.get_output_dim": [[55, 58], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "vec_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.talkative_simple_han_attn_layer.TalkativeSimpleHanAttention.is_bidirectional": [[59, 62], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "is_bidirectional", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.talkative_simple_han_attn_layer.TalkativeSimpleHanAttention.forward": [[63, 79], ["tokens.size", "tokens.view", "torch.tanh", "talkative_simple_han_attn_layer.TalkativeSimpleHanAttention._context_dot_product", "attn_weights.unsqueeze().expand.unsqueeze().expand.view", "talkative_simple_han_attn_layer.TalkativeSimpleHanAttention.report_unnormalized_log_attn_weights", "allennlp.nn.util.masked_softmax", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "talkative_simple_han_attn_layer.TalkativeSimpleHanAttention._mlp", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.report_unnormalized_log_attn_weights"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "tokens", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "assert", "mask", "is", "not", "None", "\n", "batch_size", ",", "sequence_length", ",", "embedding_dim", "=", "tokens", ".", "size", "(", ")", "\n", "\n", "attn_weights", "=", "tokens", ".", "view", "(", "batch_size", "*", "sequence_length", ",", "embedding_dim", ")", "\n", "attn_weights", "=", "torch", ".", "tanh", "(", "self", ".", "_mlp", "(", "attn_weights", ")", ")", "\n", "attn_weights", "=", "self", ".", "_context_dot_product", "(", "attn_weights", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "batch_size", ",", "-", "1", ")", "# batch_size x seq_len", "\n", "\n", "self", ".", "report_unnormalized_log_attn_weights", "(", "mask", "*", "attn_weights", ",", "tokens", ",", "mask", ")", "\n", "\n", "attn_weights", "=", "util", ".", "masked_softmax", "(", "attn_weights", ",", "mask", ")", "\n", "attn_weights", "=", "attn_weights", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "batch_size", ",", "sequence_length", ",", "embedding_dim", ")", "\n", "\n", "return", "tokens", "*", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.talkative_simple_han_attn_layer.TalkativeSimpleHanAttention.report_unnormalized_log_attn_weights": [[80, 118], ["numpy.save", "attn_weights.dim", "os.path.isfile", "os.path.isfile", "str", "input_vects.data.cpu().numpy", "open", "range", "open", "f.write", "os.path.isdir", "os.makedirs", "open", "int", "attn_weights.size", "f.write", "talkative_simple_han_attn_layer.binary_search_for_num_non_padded_tokens_in_instance", "str", "min", "max", "f.write", "f.write", "str", "str", "len", "print", "exit", "f.readline", "str", "attn_weights.size", "input_vects.data.cpu", "float", "str", "attn_weights.size", "os.listdir", "str", "range", "str", "str"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.binary_search_for_num_non_padded_tokens_in_instance"], ["", "def", "report_unnormalized_log_attn_weights", "(", "self", ",", "attn_weights", ",", "input_vects", ",", "mask", ")", ":", "\n", "        ", "assert", "attn_weights", ".", "dim", "(", ")", "==", "2", ",", "(", "\"Size of attn weights (\"", "+", "str", "(", "attn_weights", ".", "size", "(", ")", ")", "+", "\") indicates multiheaded attention, but \"", "+", "\n", "\"TalkativeSimpleHanAttention currently assumes single-head attention.\"", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "self", ".", "_attn_weight_filename", ")", ":", "\n", "            ", "next_available_ind", "=", "1", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "_input_vector_dir_name", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "_input_vector_dir_name", ")", "\n", "", "else", ":", "\n", "                ", "if", "len", "(", "os", ".", "listdir", "(", "self", ".", "_input_vector_dir_name", ")", ")", "!=", "0", ":", "\n", "                    ", "print", "(", "\"ERROR: couldn't find file \"", "+", "str", "(", "self", ".", "_attn_weight_filename", ")", "+", "\", but \"", "+", "\n", "self", ".", "_input_vector_dir_name", "+", "\" exists and is nonempty.\"", ")", "\n", "exit", "(", "1", ")", "\n", "", "", "", "else", ":", "\n", "            ", "assert", "os", ".", "path", ".", "isfile", "(", "self", ".", "_next_available_counter_ind_file", ")", "\n", "with", "open", "(", "self", ".", "_next_available_counter_ind_file", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "next_available_ind", "=", "int", "(", "f", ".", "readline", "(", ")", ")", "\n", "", "", "assert", "next_available_ind", "<=", "self", ".", "_total_num_test_instances", ",", "\"Looks like you're overwriting previously saved results.\"", "\n", "input_vects_filename", "=", "(", "self", ".", "_input_vector_dir_name", "+", "str", "(", "next_available_ind", ")", "+", "'-'", "+", "\n", "str", "(", "next_available_ind", "+", "attn_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "np", ".", "save", "(", "input_vects_filename", ",", "input_vects", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "with", "open", "(", "self", ".", "_attn_weight_filename", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "for", "i", "in", "range", "(", "attn_weights", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "f", ".", "write", "(", "str", "(", "next_available_ind", ")", "+", "\": \"", ")", "\n", "num_nonpadding_pieces_in_row", "=", "binary_search_for_num_non_padded_tokens_in_instance", "(", "mask", ",", "i", ")", "\n", "assert", "num_nonpadding_pieces_in_row", ">", "0", ",", "str", "(", "mask", ")", "\n", "weights_to_write", "=", "[", "float", "(", "attn_weights", "[", "i", ",", "j", "]", ")", "\n", "for", "j", "in", "range", "(", "num_nonpadding_pieces_in_row", ")", "]", "\n", "min_val", "=", "min", "(", "weights_to_write", ")", "\n", "max_val", "=", "max", "(", "weights_to_write", ")", "\n", "val_to_subtract", "=", "(", "(", "max_val", "-", "min_val", ")", "/", "2", ")", "+", "min_val", "\n", "f", ".", "write", "(", "str", "(", "\" \"", ".", "join", "(", "[", "str", "(", "w", "-", "val_to_subtract", ")", "for", "w", "in", "weights_to_write", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "next_available_ind", "+=", "1", "\n", "", "", "with", "open", "(", "self", ".", "_next_available_counter_ind_file", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "next_available_ind", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.talkative_simple_han_attn_layer.binary_search_for_num_non_padded_tokens_in_instance": [[11, 31], ["full_array.size", "full_array.dim", "full_array.size", "full_array.size"], "function", ["None"], ["def", "binary_search_for_num_non_padded_tokens_in_instance", "(", "full_array", ",", "row_ind", ")", ":", "\n", "    ", "assert", "full_array", ".", "dim", "(", ")", "==", "2", "\n", "open_for_checking_start", "=", "0", "\n", "open_for_checking_endplus1", "=", "full_array", ".", "size", "(", "1", ")", "\n", "look_at", "=", "(", "open_for_checking_start", "+", "open_for_checking_endplus1", ")", "//", "2", "\n", "first_zero_ind_identified", "=", "None", "\n", "while", "first_zero_ind_identified", "is", "None", ":", "\n", "        ", "if", "full_array", "[", "row_ind", ",", "look_at", "]", "!=", "0", ":", "\n", "            ", "open_for_checking_start", "=", "look_at", "+", "1", "\n", "", "else", ":", "\n", "            ", "if", "full_array", "[", "row_ind", ",", "look_at", "-", "1", "]", "!=", "0", ":", "\n", "                ", "first_zero_ind_identified", "=", "look_at", "\n", "", "else", ":", "\n", "                ", "open_for_checking_endplus1", "=", "look_at", "\n", "", "", "if", "open_for_checking_start", "==", "open_for_checking_endplus1", ":", "\n", "            ", "assert", "open_for_checking_endplus1", "==", "full_array", ".", "size", "(", "1", ")", "\n", "first_zero_ind_identified", "=", "full_array", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "look_at", "=", "(", "open_for_checking_start", "+", "open_for_checking_endplus1", ")", "//", "2", "\n", "", "", "return", "first_zero_ind_identified", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.flat_attention_network.FlatAttentionNetwork.__init__": [[83, 105], ["allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "torch.nn.Dropout", "vocab.get_vocab_size", "allennlp.training.metrics.CategoricalAccuracy", "torch.nn.CrossEntropyLoss", "initializer"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "document_encoder", ":", "Seq2SeqEncoder", ",", "\n", "word_attention", ":", "Seq2SeqEncoder", ",", "\n", "output_logit", ":", "FeedForward", ",", "\n", "pre_document_encoder_dropout", ":", "float", "=", "0.0", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "_text_field_embedder", "=", "text_field_embedder", "\n", "self", ".", "_word_attention", "=", "word_attention", "\n", "self", ".", "_pre_document_encoder_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "pre_document_encoder_dropout", ")", "\n", "self", ".", "_document_encoder", "=", "document_encoder", "\n", "\n", "self", ".", "_output_logit", "=", "output_logit", "\n", "\n", "self", ".", "_num_labels", "=", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "\"labels\"", ")", "\n", "self", ".", "_accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.flat_attention_network.FlatAttentionNetwork.forward": [[106, 163], ["tokens_.size", "flat_attention_network.FlatAttentionNetwork._text_field_embedder", "flat_attention_network.FlatAttentionNetwork.size", "allennlp.nn.util.get_text_field_mask().float", "flat_attention_network.FlatAttentionNetwork._pre_document_encoder_dropout", "flat_attention_network.FlatAttentionNetwork._document_encoder", "flat_attention_network.FlatAttentionNetwork._word_attention", "torch.sum", "flat_attention_network.FlatAttentionNetwork._output_logit", "torch.nn.functional.softmax", "torch.sum.view", "flat_attention_network.FlatAttentionNetwork._loss", "flat_attention_network.FlatAttentionNetwork._accuracy", "allennlp.nn.util.get_text_field_mask", "label.long().view", "label.long"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "label", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", "# pylint:disable=unused-argument", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        tokens : Dict[str, torch.LongTensor]\n            From a ``TextField``. These are tokens should be segmented into their respective sentences.\n        label : torch.IntTensor, optional (default = None)\n            From a ``LabelField``\n        metadata : ``List[Dict[str, Any]]``, optional, (default = None)\n            Metadata to persist\n\n        Returns\n        -------\n        An output dictionary consisting of:\n\n        label_logits : torch.FloatTensor\n            A tensor of shape ``(batch_size, num_labels)`` representing unnormalised log\n            probabilities of the label.\n        label_probs : torch.FloatTensor\n            A tensor of shape ``(batch_size, num_labels)`` representing probabilities of the\n            label.\n        loss : torch.FloatTensor, optional\n            A scalar loss to be optimised.\n        \"\"\"", "\n", "# tokens['tokens'] is a 2-d tensor: all_docs x max_num_words_in_any_doc", "\n", "# these tokens should NOT be sentence-segmented.", "\n", "tokens_", "=", "tokens", "[", "'tokens'", "]", "\n", "batch_size", "=", "tokens_", ".", "size", "(", "0", ")", "\n", "embedded_text", "=", "self", ".", "_text_field_embedder", "(", "tokens", ")", "\n", "batch_size", ",", "max_num_words", ",", "_", "=", "embedded_text", ".", "size", "(", ")", "\n", "\n", "# we encode each sentence with a seq2seq encoder + intra-sentence attention", "\n", "output_list", "=", "[", "]", "\n", "mask", "=", "get_text_field_mask", "(", "{", "\"tokens\"", ":", "tokens_", "}", ")", ".", "float", "(", ")", "\n", "embedded_text", "=", "self", ".", "_pre_document_encoder_dropout", "(", "embedded_text", ")", "\n", "encoded_words", "=", "self", ".", "_document_encoder", "(", "embedded_text", ",", "mask", ")", "\n", "document_repr", "=", "self", ".", "_word_attention", "(", "encoded_words", ",", "mask", ")", "\n", "document_repr", "=", "torch", ".", "sum", "(", "document_repr", ",", "1", ")", "\n", "\n", "# we encode each document with a seq2seq encoder + intra-document attention", "\n", "\n", "label_logits", "=", "self", ".", "_output_logit", "(", "document_repr", ".", "view", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "label_probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "label_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output_dict", "=", "{", "\"label_logits\"", ":", "label_logits", ",", "\"label_probs\"", ":", "label_probs", "}", "\n", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "_loss", "(", "label_logits", ",", "label", ".", "long", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "self", ".", "_accuracy", "(", "label_logits", ",", "label", ")", "\n", "output_dict", "[", "\"loss\"", "]", "=", "loss", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.flat_attention_network.FlatAttentionNetwork.get_metrics": [[164, 166], ["flat_attention_network.FlatAttentionNetwork._accuracy.get_metric"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "return", "{", "'accuracy'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.flat_attention_network.binary_search_for_num_non_padded_tokens_in_instance": [[16, 35], ["None"], "function", ["None"], ["def", "binary_search_for_num_non_padded_tokens_in_instance", "(", "full_array", ",", "allowed_start_ind", ",", "allowed_end_ind_plus1", ")", ":", "\n", "    ", "open_for_checking_start", "=", "allowed_start_ind", "\n", "open_for_checking_endplus1", "=", "allowed_end_ind_plus1", "\n", "look_at", "=", "(", "open_for_checking_start", "+", "open_for_checking_endplus1", ")", "//", "2", "\n", "first_zero_ind_identified", "=", "None", "\n", "while", "first_zero_ind_identified", "is", "None", ":", "\n", "        ", "if", "full_array", "[", "look_at", "]", "!=", "0", ":", "\n", "            ", "open_for_checking_start", "=", "look_at", "+", "1", "\n", "", "else", ":", "\n", "            ", "if", "full_array", "[", "look_at", "-", "1", "]", "!=", "0", ":", "\n", "                ", "first_zero_ind_identified", "=", "look_at", "\n", "", "else", ":", "\n", "                ", "open_for_checking_endplus1", "=", "look_at", "\n", "", "", "if", "open_for_checking_start", "==", "open_for_checking_endplus1", ":", "\n", "            ", "assert", "open_for_checking_endplus1", "==", "allowed_end_ind_plus1", "\n", "first_zero_ind_identified", "=", "allowed_end_ind_plus1", "\n", "", "else", ":", "\n", "            ", "look_at", "=", "(", "open_for_checking_start", "+", "open_for_checking_endplus1", ")", "//", "2", "\n", "", "", "return", "first_zero_ind_identified", "-", "allowed_start_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.flat_attention_network.get_endplus1_inds_in_condensed_representation": [[37, 49], ["first_token_ind_in_each_sentence.new_ones", "range", "first_token_ind_in_each_sentence.size", "flat_attention_network.binary_search_for_num_non_padded_tokens_in_instance", "torch.cumsum", "range", "min"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.binary_search_for_num_non_padded_tokens_in_instance"], ["", "def", "get_endplus1_inds_in_condensed_representation", "(", "first_token_ind_in_each_sentence", ",", "max_num_sentences_per_instance", ")", ":", "\n", "# perform binary search on each max_num_sentences_per_instance chunk to find the index of its first 0", "\n", "# (i.e., the actual num sentences + 1)", "\n", "    ", "batch_size", "=", "first_token_ind_in_each_sentence", ".", "size", "(", "0", ")", "//", "max_num_sentences_per_instance", "\n", "list_of_lengths", "=", "[", "binary_search_for_num_non_padded_tokens_in_instance", "(", "first_token_ind_in_each_sentence", ",", "\n", "i", "*", "max_num_sentences_per_instance", ",", "\n", "(", "i", "+", "1", ")", "*", "max_num_sentences_per_instance", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "tensor_to_fill", "=", "first_token_ind_in_each_sentence", ".", "new_ones", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "tensor_to_fill", "[", "i", "]", "=", "list_of_lengths", "[", "i", "]", "\n", "", "return", "torch", ".", "cumsum", "(", "tensor_to_fill", ",", "0", ")", ",", "max_num_sentences_per_instance", "-", "min", "(", "list_of_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.pass_through_encoder.PassThroughSeq2SeqEncoder.__init__": [[7, 13], ["allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_size", ":", "int", ",", "\n", "hidden_size", ":", "int", ")", "->", "None", ":", "\n", "        ", "super", "(", "PassThroughSeq2SeqEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.pass_through_encoder.PassThroughSeq2SeqEncoder.forward": [[14, 21], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "# not packed", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "# assume batch is first", "\n", "        ", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.pass_through_encoder.PassThroughSeq2SeqEncoder.is_bidirectional": [[22, 25], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "is_bidirectional", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.pass_through_encoder.PassThroughSeq2SeqEncoder.get_input_dim": [[26, 29], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.pass_through_encoder.PassThroughSeq2SeqEncoder.get_output_dim": [[30, 33], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "hidden_size", "", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.simple_han_attn_layer.SimpleHanAttention.__init__": [[12, 19], ["allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.__init__", "torch.nn.Linear", "torch.nn.Linear", "simple_han_attn_layer.SimpleHanAttention._mlp.weight.size"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_dim", ":", "int", "=", "None", ",", "\n", "context_vector_dim", ":", "int", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "SimpleHanAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_mlp", "=", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "context_vector_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "_context_dot_product", "=", "torch", ".", "nn", ".", "Linear", "(", "context_vector_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "vec_dim", "=", "self", ".", "_mlp", ".", "weight", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.simple_han_attn_layer.SimpleHanAttention.get_input_dim": [[20, 23], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "vec_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.simple_han_attn_layer.SimpleHanAttention.get_output_dim": [[24, 27], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "vec_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.simple_han_attn_layer.SimpleHanAttention.is_bidirectional": [[28, 31], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "is_bidirectional", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.simple_han_attn_layer.SimpleHanAttention.forward": [[32, 45], ["tokens.size", "tokens.view", "torch.tanh", "simple_han_attn_layer.SimpleHanAttention._context_dot_product", "attn_weights.unsqueeze().expand.unsqueeze().expand.view", "allennlp.nn.util.masked_softmax", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "simple_han_attn_layer.SimpleHanAttention._mlp", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "tokens", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "assert", "mask", "is", "not", "None", "\n", "batch_size", ",", "sequence_length", ",", "embedding_dim", "=", "tokens", ".", "size", "(", ")", "\n", "\n", "attn_weights", "=", "tokens", ".", "view", "(", "batch_size", "*", "sequence_length", ",", "embedding_dim", ")", "\n", "attn_weights", "=", "torch", ".", "tanh", "(", "self", ".", "_mlp", "(", "attn_weights", ")", ")", "\n", "attn_weights", "=", "self", ".", "_context_dot_product", "(", "attn_weights", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "batch_size", ",", "-", "1", ")", "# batch_size x seq_len", "\n", "attn_weights", "=", "util", ".", "masked_softmax", "(", "attn_weights", ",", "mask", ")", "\n", "attn_weights", "=", "attn_weights", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "batch_size", ",", "sequence_length", ",", "embedding_dim", ")", "\n", "\n", "return", "tokens", "*", "attn_weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse.__init__": [[43, 70], ["allennlp.data.iterators.bucket_iterator.BucketIterator.__init__"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "sorting_keys", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "\n", "padding_noise", ":", "float", "=", "0.1", ",", "\n", "biggest_batch_first", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "int", "=", "32", ",", "\n", "instances_per_epoch", ":", "int", "=", "None", ",", "\n", "max_instances_in_memory", ":", "int", "=", "None", ",", "\n", "cache_instances", ":", "bool", "=", "False", ",", "\n", "track_epoch", ":", "bool", "=", "False", ",", "\n", "maximum_samples_per_batch", ":", "Tuple", "[", "str", ",", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sorting_keys", ",", "padding_noise", "=", "padding_noise", ",", "biggest_batch_first", "=", "biggest_batch_first", ",", "\n", "batch_size", "=", "batch_size", ",", "instances_per_epoch", "=", "instances_per_epoch", ",", "\n", "max_instances_in_memory", "=", "max_instances_in_memory", ",", "cache_instances", "=", "cache_instances", ",", "\n", "track_epoch", "=", "track_epoch", ",", "maximum_samples_per_batch", "=", "maximum_samples_per_batch", ")", "\n", "# look out for [sentences, num_sentences]", "\n", "self", ".", "_change_create_batches", "=", "False", "\n", "for", "key", "in", "sorting_keys", ":", "\n", "            ", "if", "key", "[", "0", "]", "==", "\"sentences\"", ":", "\n", "                ", "self", ".", "_change_create_batches", "=", "True", "\n", "", "", "assert", "self", ".", "_change_create_batches", "\n", "self", ".", "training_sortable_batches", "=", "None", "\n", "self", ".", "val_sortable_batches", "=", "None", "\n", "self", ".", "penultimate_batch_train", "=", "None", "\n", "self", ".", "last_batch_train", "=", "None", "\n", "self", ".", "penultimate_batch_val", "=", "None", "\n", "self", ".", "last_batch_val", "=", "None", "\n", "self", ".", "provide_training_batches", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse._create_batches": [[71, 79], ["iter", "iter", "super()._create_batches", "extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse._modified_create_batches"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator._create_batches", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator._modified_create_batches"], ["", "@", "overrides", "\n", "def", "_create_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ",", "shuffle", ":", "bool", ")", "->", "Iterable", "[", "Batch", "]", ":", "\n", "        ", "if", "not", "self", ".", "_change_create_batches", ":", "\n", "            ", "for", "ret_val", "in", "iter", "(", "super", "(", ")", ".", "_create_batches", "(", "instances", ",", "shuffle", ")", ")", ":", "\n", "                ", "yield", "ret_val", "\n", "", "", "else", ":", "\n", "            ", "for", "ret_val", "in", "iter", "(", "self", ".", "_modified_create_batches", "(", "instances", ",", "shuffle", ")", ")", ":", "\n", "                ", "yield", "ret_val", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse._modified_create_batches": [[80, 175], ["extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse._memory_sized_lists", "sorted", "range", "sorted", "range", "extended_bucket_iterator_for_reuse.sort_by_padding_modified", "allennlp.common.util.lazy_groups_of", "extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse.training_sortable_batches.append", "extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse._memory_sized_lists", "random.shuffle", "len", "len", "iter", "extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse._ensure_batch_is_sufficiently_small", "batches.pop", "batches.pop", "batch_list.append", "extended_bucket_iterator_for_reuse.sort_by_padding_modified", "allennlp.common.util.lazy_groups_of", "extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse.val_sortable_batches.append", "sorted", "sorted", "batches.append", "len", "iter", "extended_bucket_iterator_for_reuse.ExtendedBucketIteratorForReuse._ensure_batch_is_sufficiently_small", "batches.pop", "batches.pop", "batch_list.append", "allennlp.data.dataset.Batch", "batches.append", "len", "allennlp.data.dataset.Batch"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.sort_by_padding_modified", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.sort_by_padding_modified"], ["", "", "", "def", "_modified_create_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ",", "shuffle", ":", "bool", ")", "->", "Iterable", "[", "Batch", "]", ":", "\n", "        ", "if", "self", ".", "training_sortable_batches", "is", "None", ":", "\n", "            ", "self", ".", "training_sortable_batches", "=", "[", "]", "\n", "cur_counter", "=", "0", "\n", "for", "instance_list", "in", "self", ".", "_memory_sized_lists", "(", "instances", ")", ":", "\n", "                ", "instance_list", "=", "sort_by_padding_modified", "(", "instance_list", ",", "\n", "self", ".", "_sorting_keys", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "_padding_noise", ")", "\n", "\n", "batches", "=", "[", "]", "\n", "for", "batch_instances", "in", "lazy_groups_of", "(", "iter", "(", "instance_list", ")", ",", "self", ".", "_batch_size", ")", ":", "\n", "                    ", "for", "possibly_smaller_batches", "in", "self", ".", "_ensure_batch_is_sufficiently_small", "(", "batch_instances", ")", ":", "\n", "                        ", "batches", ".", "append", "(", "Batch", "(", "possibly_smaller_batches", ")", ")", "\n", "\n", "", "", "self", ".", "move_to_front", "=", "self", ".", "_biggest_batch_first", "and", "len", "(", "batches", ")", ">", "1", "\n", "if", "self", ".", "move_to_front", ":", "\n", "# We'll actually pop the last _two_ batches, because the last one might not be full.", "\n", "                    ", "self", ".", "last_batch_train", "=", "batches", ".", "pop", "(", ")", "\n", "self", ".", "penultimate_batch_train", "=", "batches", ".", "pop", "(", ")", "\n", "\n", "", "batch_counter", "=", "0", "\n", "batch_list", "=", "[", "]", "\n", "for", "batch", "in", "batches", ":", "\n", "                    ", "batch_list", ".", "append", "(", "(", "batch_counter", ",", "batch", ")", ")", "\n", "batch_counter", "+=", "1", "\n", "", "self", ".", "training_sortable_batches", ".", "append", "(", "(", "cur_counter", ",", "batch_list", ")", ")", "\n", "cur_counter", "+=", "1", "\n", "", "instance_it", "=", "self", ".", "training_sortable_batches", "\n", "self", ".", "provide_training_batches", "=", "True", "\n", "", "elif", "self", ".", "val_sortable_batches", "is", "None", ":", "\n", "            ", "self", ".", "val_sortable_batches", "=", "[", "]", "\n", "cur_counter", "=", "0", "\n", "for", "instance_list", "in", "self", ".", "_memory_sized_lists", "(", "instances", ")", ":", "\n", "                ", "instance_list", "=", "sort_by_padding_modified", "(", "instance_list", ",", "\n", "self", ".", "_sorting_keys", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "_padding_noise", ")", "\n", "\n", "batches", "=", "[", "]", "\n", "for", "batch_instances", "in", "lazy_groups_of", "(", "iter", "(", "instance_list", ")", ",", "self", ".", "_batch_size", ")", ":", "\n", "                    ", "for", "possibly_smaller_batches", "in", "self", ".", "_ensure_batch_is_sufficiently_small", "(", "batch_instances", ")", ":", "\n", "                        ", "batches", ".", "append", "(", "Batch", "(", "possibly_smaller_batches", ")", ")", "\n", "\n", "", "", "self", ".", "move_to_front", "=", "self", ".", "_biggest_batch_first", "and", "len", "(", "batches", ")", ">", "1", "\n", "if", "self", ".", "move_to_front", ":", "\n", "# We'll actually pop the last _two_ batches, because the last one might not be full.", "\n", "                    ", "self", ".", "last_batch_val", "=", "batches", ".", "pop", "(", ")", "\n", "self", ".", "penultimate_batch_val", "=", "batches", ".", "pop", "(", ")", "\n", "\n", "", "batch_counter", "=", "0", "\n", "batch_list", "=", "[", "]", "\n", "for", "batch", "in", "batches", ":", "\n", "                    ", "batch_list", ".", "append", "(", "(", "batch_counter", ",", "batch", ")", ")", "\n", "batch_counter", "+=", "1", "\n", "", "self", ".", "val_sortable_batches", ".", "append", "(", "(", "cur_counter", ",", "batch_list", ")", ")", "\n", "cur_counter", "+=", "1", "\n", "", "instance_it", "=", "self", ".", "val_sortable_batches", "\n", "self", ".", "provide_training_batches", "=", "False", "\n", "", "elif", "self", ".", "provide_training_batches", ":", "\n", "            ", "instance_it", "=", "self", ".", "training_sortable_batches", "\n", "", "elif", "not", "self", ".", "provide_training_batches", ":", "\n", "            ", "instance_it", "=", "self", ".", "val_sortable_batches", "\n", "", "for", "instance_list", "in", "instance_it", ":", "\n", "            ", "instance_list", "=", "instance_list", "[", "1", "]", "\n", "\n", "batches", "=", "instance_list", "\n", "\n", "if", "shuffle", ":", "\n", "# NOTE: if shuffle is false, the data will still be in a different order", "\n", "# because of the bucket sorting.", "\n", "                ", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "if", "self", ".", "move_to_front", ":", "\n", "                ", "if", "self", ".", "provide_training_batches", ":", "\n", "                    ", "yield", "from", "[", "self", ".", "last_batch_train", "]", "\n", "yield", "from", "[", "self", ".", "penultimate_batch_train", "]", "\n", "", "else", ":", "\n", "                    ", "yield", "from", "[", "self", ".", "last_batch_val", "]", "\n", "yield", "from", "[", "self", ".", "penultimate_batch_val", "]", "\n", "\n", "", "", "for", "batch", "in", "batches", ":", "\n", "                ", "yield", "batch", "[", "1", "]", "\n", "\n", "", "", "if", "self", ".", "provide_training_batches", ":", "\n", "            ", "self", ".", "training_sortable_batches", "=", "sorted", "(", "self", ".", "training_sortable_batches", ",", "key", "=", "(", "lambda", "x", ":", "x", "[", "0", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "training_sortable_batches", ")", ")", ":", "\n", "                ", "self", ".", "training_sortable_batches", "[", "i", "]", "=", "(", "self", ".", "training_sortable_batches", "[", "i", "]", "[", "0", "]", ",", "\n", "sorted", "(", "self", ".", "training_sortable_batches", "[", "i", "]", "[", "1", "]", ",", "key", "=", "(", "lambda", "x", ":", "x", "[", "0", "]", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "val_sortable_batches", "=", "sorted", "(", "self", ".", "val_sortable_batches", ",", "key", "=", "(", "lambda", "x", ":", "x", "[", "0", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "val_sortable_batches", ")", ")", ":", "\n", "                ", "self", ".", "val_sortable_batches", "[", "i", "]", "=", "(", "self", ".", "val_sortable_batches", "[", "i", "]", "[", "0", "]", ",", "\n", "sorted", "(", "self", ".", "val_sortable_batches", "[", "i", "]", "[", "1", "]", ",", "key", "=", "(", "lambda", "x", ":", "x", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "", "self", ".", "provide_training_batches", "=", "not", "self", ".", "provide_training_batches", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator_for_reuse.sort_by_padding_modified": [[12, 39], ["instances_with_lengths.sort", "instance.index_fields", "instance.get_padding_lengths", "typing.cast", "instances_with_lengths.append", "len", "typing.cast.items", "allennlp.common.util.add_noise_to_dict_values"], "function", ["None"], ["def", "sort_by_padding_modified", "(", "instances", ":", "List", "[", "Instance", "]", ",", "\n", "sorting_keys", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "# pylint: disable=invalid-sequence-index", "\n", "vocab", ":", "Vocabulary", ",", "\n", "padding_noise", ":", "float", "=", "0.0", ")", "->", "List", "[", "Instance", "]", ":", "\n", "    ", "\"\"\"\n    Sorts the instances by their padding lengths, using the keys in\n    ``sorting_keys`` (in the order in which they are provided).  ``sorting_keys`` is a list of\n    ``(field_name, padding_key)`` tuples.\n    \"\"\"", "\n", "instances_with_lengths", "=", "[", "]", "\n", "for", "instance", "in", "instances", ":", "\n", "# Make sure instance is indexed before calling .get_padding", "\n", "        ", "instance", ".", "index_fields", "(", "vocab", ")", "\n", "padding_lengths", "=", "instance", ".", "get_padding_lengths", "(", ")", "\n", "padding_lengths", "[", "\"sentences\"", "]", "=", "{", "\"num_sentences\"", ":", "len", "(", "instance", ".", "fields", "[", "'tokens'", "]", ".", "field_list", ")", "}", "\n", "padding_lengths", "=", "cast", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "float", "]", "]", ",", "padding_lengths", ")", "\n", "if", "padding_noise", ">", "0.0", ":", "\n", "            ", "noisy_lengths", "=", "{", "}", "\n", "for", "field_name", ",", "field_lengths", "in", "padding_lengths", ".", "items", "(", ")", ":", "\n", "                ", "noisy_lengths", "[", "field_name", "]", "=", "add_noise_to_dict_values", "(", "field_lengths", ",", "padding_noise", ")", "\n", "", "padding_lengths", "=", "noisy_lengths", "\n", "", "instance_with_lengths", "=", "(", "[", "padding_lengths", "[", "field_name", "]", "[", "padding_key", "]", "\n", "for", "(", "field_name", ",", "padding_key", ")", "in", "sorting_keys", "]", ",", "\n", "instance", ")", "\n", "instances_with_lengths", ".", "append", "(", "instance_with_lengths", ")", "\n", "", "instances_with_lengths", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "return", "[", "instance_with_lengths", "[", "-", "1", "]", "for", "instance_with_lengths", "in", "instances_with_lengths", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.AttentionIterator.__init__": [[45, 48], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "attn_weight_filename", ",", "return_log_attn_vals", "=", "True", ")", ":", "\n", "        ", "self", ".", "attn_weight_filename", "=", "attn_weight_filename", "\n", "self", ".", "return_log_attn_vals", "=", "return_log_attn_vals", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.AttentionIterator.__iter__": [[49, 57], ["open", "intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line", "line.strip"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "attn_weight_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "corr_ind", ",", "attn_vals", "=", "get_corr_ind_and_attn_vals_out_of_line", "(", "line", ",", "return_log_attn_vals", "=", "self", ".", "return_log_attn_vals", ")", "\n", "yield", "attn_vals", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.GradientsIterator.__init__": [[60, 66], ["int", "intermediate_batch_iterator.GradientsIterator.base_filename.endswith"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "base_filename", ",", "gpu", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "gpu", "=", "gpu", "\n", "self", ".", "batch_size", "=", "int", "(", "batch_size", ")", "\n", "self", ".", "base_filename", "=", "base_filename", "\n", "if", "not", "self", ".", "base_filename", ".", "endswith", "(", "'_'", ")", ":", "\n", "            ", "self", ".", "base_filename", "+=", "'_'", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.GradientsIterator.__iter__": [[67, 111], ["sorted", "list", "len", "glob.glob.glob", "open", "pickle.load", "allennlp.nn.util.move_to_device.size", "len", "torch.cat", "allennlp.nn.util.move_to_device", "int", "cur_pieces_to_concat.append", "torch.cat", "piece_of_cur_to_hold_onto.size", "len", "torch.cat", "allennlp.nn.util.move_to_device", "x.rfind", "allennlp.nn.util.move_to_device", "allennlp.nn.util.move_to_device", "x.rfind"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "all_filenames_in_numerical_order", "=", "sorted", "(", "list", "(", "glob", "(", "self", ".", "base_filename", "+", "'*-*'", ")", ")", ",", "reverse", "=", "False", ",", "\n", "key", "=", "(", "lambda", "x", ":", "int", "(", "x", "[", "x", ".", "rfind", "(", "'_'", ")", "+", "1", ":", "x", ".", "rfind", "(", "'-'", ")", "]", ")", ")", ")", "\n", "cur_pieces_to_concat", "=", "[", "]", "\n", "num_instances_in_waiting", "=", "0", "\n", "for", "filename", "in", "all_filenames_in_numerical_order", ":", "\n", "            ", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "corr_grad_for_attn", "=", "pickle", ".", "load", "(", "f", ")", "\n", "num_instances_in_this_block", "=", "corr_grad_for_attn", ".", "size", "(", "0", ")", "\n", "sum_of_prev_plus_new", "=", "num_instances_in_waiting", "+", "num_instances_in_this_block", "\n", "if", "sum_of_prev_plus_new", ">=", "self", ".", "batch_size", ":", "\n", "                    ", "if", "sum_of_prev_plus_new", "==", "self", ".", "batch_size", ":", "\n", "                        ", "if", "len", "(", "cur_pieces_to_concat", ")", ">=", "1", ":", "\n", "                            ", "piece_to_return", "=", "torch", ".", "cat", "(", "cur_pieces_to_concat", "+", "[", "corr_grad_for_attn", "]", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "gpu", "!=", "-", "1", ":", "\n", "                                ", "piece_to_return", "=", "util", ".", "move_to_device", "(", "piece_to_return", ",", "self", ".", "gpu", ")", "\n", "", "cur_pieces_to_concat", "=", "[", "]", "\n", "num_instances_in_waiting", "=", "0", "\n", "yield", "piece_to_return", "\n", "", "else", ":", "# cur_pieces_to_concat is empty", "\n", "                            ", "if", "self", ".", "gpu", "!=", "-", "1", ":", "\n", "                                ", "corr_grad_for_attn", "=", "util", ".", "move_to_device", "(", "corr_grad_for_attn", ",", "self", ".", "gpu", ")", "\n", "", "yield", "corr_grad_for_attn", "\n", "", "", "else", ":", "\n", "# strictly greater than amount to return", "\n", "                        ", "piece_of_cur_to_return", "=", "corr_grad_for_attn", "[", "0", ":", "self", ".", "batch_size", "-", "num_instances_in_waiting", "]", "\n", "piece_of_cur_to_hold_onto", "=", "corr_grad_for_attn", "[", "self", ".", "batch_size", "-", "num_instances_in_waiting", ":", "]", "\n", "piece_to_return", "=", "torch", ".", "cat", "(", "cur_pieces_to_concat", "+", "[", "piece_of_cur_to_return", "]", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "gpu", "!=", "-", "1", ":", "\n", "                            ", "piece_to_return", "=", "util", ".", "move_to_device", "(", "piece_to_return", ",", "self", ".", "gpu", ")", "\n", "", "cur_pieces_to_concat", "=", "[", "piece_of_cur_to_hold_onto", "]", "\n", "num_instances_in_waiting", "=", "piece_of_cur_to_hold_onto", ".", "size", "(", "0", ")", "\n", "yield", "piece_to_return", "\n", "", "", "else", ":", "\n", "                    ", "cur_pieces_to_concat", ".", "append", "(", "corr_grad_for_attn", ")", "\n", "num_instances_in_waiting", "+=", "num_instances_in_this_block", "\n", "", "", "", "if", "len", "(", "cur_pieces_to_concat", ")", ">", "0", ":", "\n", "            ", "if", "len", "(", "cur_pieces_to_concat", ")", "==", "1", ":", "\n", "                ", "piece_to_return", "=", "cur_pieces_to_concat", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "piece_to_return", "=", "torch", ".", "cat", "(", "cur_pieces_to_concat", ",", "dim", "=", "0", ")", "\n", "", "if", "self", ".", "gpu", "!=", "-", "1", ":", "\n", "                ", "piece_to_return", "=", "util", ".", "move_to_device", "(", "piece_to_return", ",", "self", ".", "gpu", ")", "\n", "", "yield", "piece_to_return", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.GradientsIterator.__call__": [[112, 114], ["intermediate_batch_iterator.GradientsIterator.__iter__"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__iter__"], ["", "", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "__iter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.__init__": [[117, 139], ["corr_vector_dir.endswith", "open", "int", "line.strip", "line.index"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "attn_weight_filename", ",", "corr_vector_dir", ",", "batch_size", ",", "return_log_attn_vals", "=", "False", ",", "\n", "also_return_grads", "=", "False", ")", ":", "\n", "        ", "self", ".", "attn_weight_filename", "=", "attn_weight_filename", "\n", "if", "not", "corr_vector_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "corr_vector_dir", "+=", "'/'", "\n", "", "if", "also_return_grads", ":", "\n", "            ", "self", ".", "grad_dir", "=", "corr_vector_dir", "+", "'gradients/'", "\n", "self", ".", "also_return_grads", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "grad_dir", "=", "None", "\n", "self", ".", "also_return_grads", "=", "False", "\n", "", "self", ".", "corr_vector_dir", "=", "corr_vector_dir", "\n", "self", ".", "num_instances", "=", "0", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "return_log_attn_vals", "=", "return_log_attn_vals", "\n", "with", "open", "(", "attn_weight_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "instance_num", "=", "int", "(", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", ")", "\n", "if", "instance_num", ">", "self", ".", "num_instances", ":", "\n", "                    ", "self", ".", "num_instances", "=", "instance_num", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.__iter__": [[140, 187], ["intermediate_batch_iterator.IntermediateBatchIterator.get_next_corr_vect_np_array", "intermediate_batch_iterator.IntermediateBatchIterator.get_next_grads_np_array", "open", "intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line", "len", "seq_lens.append", "numpy.array", "list_of_attn_vals.append", "line.strip", "intermediate_batch_iterator.IntermediateBatchIterator.get_np_array_of_corr_vects", "intermediate_batch_iterator.IntermediateBatchIterator.pad_attn_weights_and_concat", "len", "len", "len", "intermediate_batch_iterator.IntermediateBatchIterator.get_np_array_of_grads", "len", "torch.from_numpy().float", "torch.autograd.Variable", "torch.from_numpy().float", "torch.autograd.Variable", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_next_corr_vect_np_array", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_next_grads_np_array", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_np_array_of_corr_vects", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.pad_attn_weights_and_concat", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_np_array_of_grads"], ["", "", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "last_instance_ind_delivered", "=", "0", "\n", "next_available_corr_vects", "=", "self", ".", "get_next_corr_vect_np_array", "(", "1", ")", "\n", "if", "self", ".", "also_return_grads", ":", "\n", "            ", "next_available_grads", "=", "self", ".", "get_next_grads_np_array", "(", "1", ")", "\n", "", "seq_lens", "=", "[", "]", "\n", "list_of_attn_vals", "=", "[", "]", "\n", "max_seq_len_in_batch", "=", "-", "1", "\n", "with", "open", "(", "self", ".", "attn_weight_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "corr_ind", ",", "attn_vals", "=", "get_corr_ind_and_attn_vals_out_of_line", "(", "line", ",", "return_log_attn_vals", "=", "self", ".", "return_log_attn_vals", ")", "\n", "seq_len", "=", "len", "(", "attn_vals", ")", "\n", "seq_lens", ".", "append", "(", "seq_len", ")", "\n", "if", "seq_len", ">", "max_seq_len_in_batch", ":", "\n", "                    ", "max_seq_len_in_batch", "=", "seq_len", "\n", "", "attn_vals", "=", "np", ".", "array", "(", "attn_vals", ")", "\n", "list_of_attn_vals", ".", "append", "(", "attn_vals", ")", "\n", "\n", "if", "len", "(", "seq_lens", ")", ">=", "self", ".", "batch_size", "or", "corr_ind", "==", "self", ".", "num_instances", ":", "\n", "# this is the end of a batch", "\n", "                    ", "next_available_corr_vects", ",", "np_corr_vect", "=", "self", ".", "get_np_array_of_corr_vects", "(", "next_available_corr_vects", ",", "max_seq_len_in_batch", ",", "\n", "len", "(", "seq_lens", ")", ",", "last_instance_ind_delivered", ")", "\n", "if", "self", ".", "also_return_grads", ":", "\n", "                        ", "next_available_grads", ",", "np_corr_grad", "=", "self", ".", "get_np_array_of_grads", "(", "next_available_grads", ",", "\n", "max_seq_len_in_batch", ",", "\n", "len", "(", "seq_lens", ")", ",", "\n", "last_instance_ind_delivered", ")", "\n", "", "np_attn_mat", "=", "self", ".", "pad_attn_weights_and_concat", "(", "list_of_attn_vals", ",", "max_seq_len_in_batch", ")", "\n", "seq_lens_to_deliver", "=", "seq_lens", "\n", "\n", "last_instance_ind_delivered", "+=", "len", "(", "seq_lens", ")", "\n", "seq_lens", "=", "[", "]", "\n", "list_of_attn_vals", "=", "[", "]", "\n", "max_seq_len_in_batch", "=", "-", "1", "\n", "if", "self", ".", "also_return_grads", ":", "\n", "                        ", "yield", "torch", ".", "from_numpy", "(", "np_attn_mat", ")", ".", "float", "(", ")", ",", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "np_corr_vect", ")", ".", "float", "(", ")", ")", ",", "seq_lens_to_deliver", ",", "np_corr_grad", "\n", "", "else", ":", "\n", "                        ", "yield", "torch", ".", "from_numpy", "(", "np_attn_mat", ")", ".", "float", "(", ")", ",", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "np_corr_vect", ")", ".", "float", "(", ")", ")", ",", "seq_lens_to_deliver", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.pad_attn_weights_and_concat": [[188, 198], ["range", "numpy.vstack", "len", "numpy.concatenate", "numpy.zeros"], "methods", ["None"], ["", "", "", "", "", "def", "pad_attn_weights_and_concat", "(", "self", ",", "list_of_attn_vals", ",", "max_seq_len_in_batch", ")", ":", "\n", "# before stacking, adjust dim 1 to equal max_seq_len_in_batch", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "list_of_attn_vals", ")", ")", ":", "\n", "            ", "piece", "=", "list_of_attn_vals", "[", "i", "]", "\n", "if", "piece", ".", "shape", "[", "0", "]", ">", "max_seq_len_in_batch", ":", "\n", "                ", "list_of_attn_vals", "[", "i", "]", "=", "piece", "[", ":", "max_seq_len_in_batch", "]", "\n", "", "elif", "piece", ".", "shape", "[", "0", "]", "<", "max_seq_len_in_batch", ":", "\n", "                ", "list_of_attn_vals", "[", "i", "]", "=", "np", ".", "concatenate", "(", "[", "piece", ",", "np", ".", "zeros", "(", "max_seq_len_in_batch", "-", "piece", ".", "shape", "[", "0", "]", ")", "]", ",", "axis", "=", "0", ")", "\n", "", "", "return", "np", ".", "vstack", "(", "list_of_attn_vals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_np_array_of_corr_vects": [[199, 228], ["range", "numpy.concatenate", "len", "pieces_to_stack.append", "intermediate_batch_iterator.IntermediateBatchIterator.get_next_corr_vect_np_array", "pieces_to_stack.append", "numpy.concatenate", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_next_corr_vect_np_array"], ["", "def", "get_np_array_of_corr_vects", "(", "self", ",", "next_available_corr_vects", ",", "max_seq_len_in_batch", ",", "batch_len", ",", "\n", "last_instance_ind_delivered", ")", ":", "\n", "        ", "pieces_to_stack", "=", "[", "]", "\n", "num_instances_included", "=", "0", "\n", "while", "num_instances_included", "<", "batch_len", ":", "\n", "            ", "num_left_to_include", "=", "batch_len", "-", "num_instances_included", "\n", "if", "num_left_to_include", ">=", "next_available_corr_vects", ".", "shape", "[", "0", "]", ":", "\n", "                ", "pieces_to_stack", ".", "append", "(", "next_available_corr_vects", ")", "\n", "last_instance_ind_delivered", "+=", "next_available_corr_vects", ".", "shape", "[", "0", "]", "\n", "num_instances_included", "+=", "next_available_corr_vects", ".", "shape", "[", "0", "]", "\n", "next_available_corr_vects", "=", "self", ".", "get_next_corr_vect_np_array", "(", "last_instance_ind_delivered", "+", "1", ")", "\n", "", "else", ":", "\n", "                ", "pieces_to_stack", ".", "append", "(", "next_available_corr_vects", "[", ":", "num_left_to_include", "]", ")", "\n", "last_instance_ind_delivered", "+=", "num_left_to_include", "\n", "num_instances_included", "+=", "num_left_to_include", "\n", "next_available_corr_vects", "=", "next_available_corr_vects", "[", "num_left_to_include", ":", "]", "\n", "\n", "# before stacking, adjust dim 1 to equal max_seq_len_in_batch", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "pieces_to_stack", ")", ")", ":", "\n", "            ", "piece", "=", "pieces_to_stack", "[", "i", "]", "\n", "if", "piece", ".", "shape", "[", "1", "]", ">", "max_seq_len_in_batch", ":", "\n", "                ", "pieces_to_stack", "[", "i", "]", "=", "piece", "[", ":", ",", ":", "max_seq_len_in_batch", ",", ":", "]", "\n", "", "elif", "piece", ".", "shape", "[", "1", "]", "<", "max_seq_len_in_batch", ":", "\n", "                ", "pieces_to_stack", "[", "i", "]", "=", "np", ".", "concatenate", "(", "[", "piece", ",", "np", ".", "zeros", "(", "(", "piece", ".", "shape", "[", "0", "]", ",", "max_seq_len_in_batch", "-", "piece", ".", "shape", "[", "1", "]", ",", "\n", "piece", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "float", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "", "np_corr_vect", "=", "np", ".", "concatenate", "(", "pieces_to_stack", ",", "axis", "=", "0", ")", "\n", "return", "next_available_corr_vects", ",", "np_corr_vect", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_np_array_of_grads": [[229, 258], ["range", "numpy.concatenate", "len", "pieces_to_stack.append", "intermediate_batch_iterator.IntermediateBatchIterator.get_next_grads_np_array", "pieces_to_stack.append", "numpy.concatenate", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_next_grads_np_array"], ["", "def", "get_np_array_of_grads", "(", "self", ",", "next_available_grads", ",", "max_seq_len_in_batch", ",", "batch_len", ",", "\n", "last_instance_ind_delivered", ")", ":", "\n", "        ", "pieces_to_stack", "=", "[", "]", "\n", "num_instances_included", "=", "0", "\n", "while", "num_instances_included", "<", "batch_len", ":", "\n", "            ", "num_left_to_include", "=", "batch_len", "-", "num_instances_included", "\n", "if", "num_left_to_include", ">=", "next_available_grads", ".", "shape", "[", "0", "]", ":", "\n", "                ", "pieces_to_stack", ".", "append", "(", "next_available_grads", ")", "\n", "last_instance_ind_delivered", "+=", "next_available_grads", ".", "shape", "[", "0", "]", "\n", "num_instances_included", "+=", "next_available_grads", ".", "shape", "[", "0", "]", "\n", "next_available_grads", "=", "self", ".", "get_next_grads_np_array", "(", "last_instance_ind_delivered", "+", "1", ")", "\n", "", "else", ":", "\n", "                ", "pieces_to_stack", ".", "append", "(", "next_available_grads", "[", ":", "num_left_to_include", "]", ")", "\n", "last_instance_ind_delivered", "+=", "num_left_to_include", "\n", "num_instances_included", "+=", "num_left_to_include", "\n", "next_available_grads", "=", "next_available_grads", "[", "num_left_to_include", ":", "]", "\n", "\n", "# before stacking, adjust dim 1 to equal max_seq_len_in_batch", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "pieces_to_stack", ")", ")", ":", "\n", "            ", "piece", "=", "pieces_to_stack", "[", "i", "]", "\n", "if", "piece", ".", "shape", "[", "1", "]", ">", "max_seq_len_in_batch", ":", "\n", "                ", "pieces_to_stack", "[", "i", "]", "=", "piece", "[", ":", ",", ":", "max_seq_len_in_batch", "]", "\n", "", "elif", "piece", ".", "shape", "[", "1", "]", "<", "max_seq_len_in_batch", ":", "\n", "                ", "pieces_to_stack", "[", "i", "]", "=", "np", ".", "concatenate", "(", "[", "piece", ",", "np", ".", "zeros", "(", "(", "piece", ".", "shape", "[", "0", "]", ",", "\n", "max_seq_len_in_batch", "-", "piece", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "float", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "", "np_corr_vect", "=", "np", ".", "concatenate", "(", "pieces_to_stack", ",", "axis", "=", "0", ")", "\n", "return", "next_available_grads", ",", "np_corr_vect", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_next_corr_vect_np_array": [[260, 267], ["glob.glob.glob", "numpy.load", "len", "str", "str", "str"], "methods", ["None"], ["", "def", "get_next_corr_vect_np_array", "(", "self", ",", "starting_ind", ")", ":", "\n", "        ", "if", "starting_ind", ">", "self", ".", "num_instances", ":", "\n", "            ", "return", "None", "\n", "", "possible_next_filenames", "=", "glob", "(", "self", ".", "corr_vector_dir", "+", "str", "(", "starting_ind", ")", "+", "'-*'", ")", "\n", "assert", "len", "(", "possible_next_filenames", ")", "==", "1", ",", "\"Query: \"", "+", "self", ".", "corr_vector_dir", "+", "str", "(", "starting_ind", ")", "+", "'-'", "+", "'\\n'", "+", "\"Found: \"", "+", "str", "(", "possible_next_filenames", ")", "\n", "return", "np", ".", "load", "(", "possible_next_filenames", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.IntermediateBatchIterator.get_next_grads_np_array": [[268, 278], ["glob.glob.glob", "pickle.load.data.cpu().numpy", "len", "str", "open", "pickle.load", "pickle.load.data.cpu", "str", "str"], "methods", ["None"], ["", "def", "get_next_grads_np_array", "(", "self", ",", "starting_ind", ")", ":", "\n", "        ", "if", "starting_ind", ">", "self", ".", "num_instances", ":", "\n", "            ", "return", "None", "\n", "", "possible_next_filenames", "=", "glob", "(", "self", ".", "grad_dir", "+", "'gradient_wrt_attn_weights_'", "+", "str", "(", "starting_ind", ")", "+", "'-*'", ")", "\n", "assert", "len", "(", "possible_next_filenames", ")", "==", "1", ",", "\"Query: \"", "+", "self", ".", "corr_vector_dir", "+", "str", "(", "starting_ind", ")", "+", "'-'", "+", "'\\n'", "+", "\"Found: \"", "+", "str", "(", "possible_next_filenames", ")", "\n", "with", "open", "(", "possible_next_filenames", "[", "0", "]", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "torch_var_tensor", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "np_array", "=", "torch_var_tensor", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "np_array", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line": [[9, 16], ["int", "float", "numpy.exp", "list", "line[].strip().split", "line.index", "numpy.max", "list.sum", "line[].strip", "line.index"], "function", ["None"], ["def", "get_corr_ind_and_attn_vals_out_of_line", "(", "line", ",", "return_log_attn_vals", "=", "False", ")", ":", "\n", "    ", "corr_ind", "=", "int", "(", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", ")", "\n", "attn_vals", "=", "[", "float", "(", "str_val", ")", "for", "str_val", "in", "line", "[", "line", ".", "index", "(", "':'", ")", "+", "1", ":", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "]", "\n", "if", "not", "return_log_attn_vals", ":", "\n", "        ", "attn_vals", "=", "np", ".", "exp", "(", "attn_vals", "-", "np", ".", "max", "(", "attn_vals", ")", ")", "\n", "attn_vals", "=", "list", "(", "attn_vals", "/", "attn_vals", ".", "sum", "(", ")", ")", "\n", "", "return", "corr_ind", ",", "attn_vals", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.load_attn_dists": [[18, 29], ["open", "intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line", "attn_dists.append", "corr_inds.append", "line.strip"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line"], ["", "def", "load_attn_dists", "(", "attn_weight_filename", ")", ":", "\n", "    ", "attn_dists", "=", "[", "]", "\n", "corr_inds", "=", "[", "]", "\n", "with", "open", "(", "attn_weight_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                ", "continue", "\n", "", "corr_ind", ",", "attn_vals", "=", "get_corr_ind_and_attn_vals_out_of_line", "(", "line", ",", "return_log_attn_vals", "=", "False", ")", "\n", "attn_dists", ".", "append", "(", "attn_vals", ")", "\n", "corr_inds", ".", "append", "(", "corr_ind", ")", "\n", "", "", "return", "attn_dists", ",", "corr_inds", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.load_log_unnormalized_attn_dists": [[31, 42], ["open", "intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line", "attn_dists.append", "corr_inds.append", "line.strip"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.intermediate_batch_iterator.get_corr_ind_and_attn_vals_out_of_line"], ["", "def", "load_log_unnormalized_attn_dists", "(", "attn_weight_filename", ")", ":", "\n", "    ", "attn_dists", "=", "[", "]", "\n", "corr_inds", "=", "[", "]", "\n", "with", "open", "(", "attn_weight_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                ", "continue", "\n", "", "corr_ind", ",", "attn_vals", "=", "get_corr_ind_and_attn_vals_out_of_line", "(", "line", ",", "return_log_attn_vals", "=", "True", ")", "\n", "attn_dists", ".", "append", "(", "attn_vals", ")", "\n", "corr_inds", ".", "append", "(", "corr_ind", ")", "\n", "", "", "return", "attn_dists", ",", "corr_inds", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator.__init__": [[44, 63], ["allennlp.data.iterators.bucket_iterator.BucketIterator.__init__"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "sorting_keys", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "\n", "padding_noise", ":", "float", "=", "0.1", ",", "\n", "biggest_batch_first", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "int", "=", "32", ",", "\n", "instances_per_epoch", ":", "int", "=", "None", ",", "\n", "max_instances_in_memory", ":", "int", "=", "None", ",", "\n", "cache_instances", ":", "bool", "=", "False", ",", "\n", "track_epoch", ":", "bool", "=", "False", ",", "\n", "maximum_samples_per_batch", ":", "Tuple", "[", "str", ",", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sorting_keys", ",", "padding_noise", "=", "padding_noise", ",", "biggest_batch_first", "=", "biggest_batch_first", ",", "\n", "batch_size", "=", "batch_size", ",", "instances_per_epoch", "=", "instances_per_epoch", ",", "\n", "max_instances_in_memory", "=", "max_instances_in_memory", ",", "cache_instances", "=", "cache_instances", ",", "\n", "track_epoch", "=", "track_epoch", ",", "maximum_samples_per_batch", "=", "maximum_samples_per_batch", ")", "\n", "# look out for [sentences, num_sentences]", "\n", "self", ".", "_change_create_batches", "=", "False", "\n", "for", "key", "in", "sorting_keys", ":", "\n", "            ", "if", "key", "[", "0", "]", "==", "\"sentences\"", ":", "\n", "                ", "self", ".", "_change_create_batches", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator._create_batches": [[64, 72], ["iter", "iter", "super()._create_batches", "extended_bucket_iterator.ExtendedBucketIterator._modified_create_batches"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator._create_batches", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator._modified_create_batches"], ["", "", "", "@", "overrides", "\n", "def", "_create_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ",", "shuffle", ":", "bool", ")", "->", "Iterable", "[", "Batch", "]", ":", "\n", "        ", "if", "not", "self", ".", "_change_create_batches", ":", "\n", "            ", "for", "ret_val", "in", "iter", "(", "super", "(", ")", ".", "_create_batches", "(", "instances", ",", "shuffle", ")", ")", ":", "\n", "                ", "yield", "ret_val", "\n", "", "", "else", ":", "\n", "            ", "for", "ret_val", "in", "iter", "(", "self", ".", "_modified_create_batches", "(", "instances", ",", "shuffle", ")", ")", ":", "\n", "                ", "yield", "ret_val", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator.old_ensure_batch_is_sufficiently_small": [[73, 113], ["list", "instance.get_padding_lengths", "instance.get_padding_lengths.items", "math.ceil", "math.ceil", "list", "instance.index_fields", "len", "len", "len", "shrunk_batches.append", "max", "float", "len"], "methods", ["None"], ["", "", "", "def", "old_ensure_batch_is_sufficiently_small", "(", "self", ",", "batch_instances", ":", "Iterable", "[", "Instance", "]", ")", "->", "List", "[", "List", "[", "Instance", "]", "]", ":", "\n", "        ", "\"\"\"\n        If self._maximum_samples_per_batch is specified, then split the batch into smaller\n        sub-batches if it exceeds the maximum size.\n        \"\"\"", "\n", "if", "self", ".", "_maximum_samples_per_batch", "is", "None", ":", "\n", "            ", "return", "[", "list", "(", "batch_instances", ")", "]", "\n", "\n", "# check if we need to break into smaller chunks", "\n", "", "key", ",", "limit", "=", "self", ".", "_maximum_samples_per_batch", "\n", "padding_length", "=", "-", "1", "\n", "list_batch_instances", "=", "list", "(", "batch_instances", ")", "\n", "for", "instance", "in", "list_batch_instances", ":", "\n", "            ", "if", "self", ".", "vocab", "is", "not", "None", ":", "\n", "# we index here to ensure that shape information is available,", "\n", "# as in some cases (with self._maximum_samples_per_batch)", "\n", "# we need access to shaping information before batches are constructed)", "\n", "                ", "instance", ".", "index_fields", "(", "self", ".", "vocab", ")", "\n", "", "field_lengths", "=", "instance", ".", "get_padding_lengths", "(", ")", "\n", "for", "_", ",", "lengths", "in", "field_lengths", ".", "items", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "padding_length", "=", "max", "(", "padding_length", ",", "\n", "lengths", "[", "key", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "", "if", "padding_length", "*", "len", "(", "list_batch_instances", ")", ">", "limit", ":", "\n", "# need to shrink", "\n", "            ", "num_samples", "=", "padding_length", "*", "len", "(", "list_batch_instances", ")", "\n", "num_shrunk_batches", "=", "math", ".", "ceil", "(", "num_samples", "/", "float", "(", "limit", ")", ")", "\n", "shrunk_batch_size", "=", "math", ".", "ceil", "(", "len", "(", "list_batch_instances", ")", "/", "num_shrunk_batches", ")", "\n", "shrunk_batches", "=", "[", "]", "\n", "start", "=", "0", "\n", "while", "start", "<", "len", "(", "list_batch_instances", ")", ":", "\n", "                ", "end", "=", "start", "+", "shrunk_batch_size", "\n", "shrunk_batches", ".", "append", "(", "list_batch_instances", "[", "start", ":", "end", "]", ")", "\n", "start", "=", "end", "\n", "", "return", "shrunk_batches", "\n", "", "else", ":", "\n", "            ", "return", "[", "list_batch_instances", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator._modified_create_batches": [[114, 141], ["extended_bucket_iterator.ExtendedBucketIterator._memory_sized_lists", "extended_bucket_iterator.sort_by_padding_modified", "allennlp.common.util.lazy_groups_of", "iter", "extended_bucket_iterator.ExtendedBucketIterator.old_ensure_batch_is_sufficiently_small", "batches.pop", "batches.pop", "random.shuffle", "batches.insert", "batches.insert", "batches.append", "len", "allennlp.data.dataset.Batch"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.sort_by_padding_modified", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.ExtendedBucketIterator.old_ensure_batch_is_sufficiently_small"], ["", "", "def", "_modified_create_batches", "(", "self", ",", "instances", ":", "Iterable", "[", "Instance", "]", ",", "shuffle", ":", "bool", ")", "->", "Iterable", "[", "Batch", "]", ":", "\n", "        ", "for", "instance_list", "in", "self", ".", "_memory_sized_lists", "(", "instances", ")", ":", "\n", "\n", "            ", "instance_list", "=", "sort_by_padding_modified", "(", "instance_list", ",", "\n", "self", ".", "_sorting_keys", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "_padding_noise", ")", "\n", "\n", "batches", "=", "[", "]", "\n", "for", "batch_instances", "in", "lazy_groups_of", "(", "iter", "(", "instance_list", ")", ",", "self", ".", "_batch_size", ")", ":", "\n", "                ", "for", "possibly_smaller_batches", "in", "self", ".", "old_ensure_batch_is_sufficiently_small", "(", "batch_instances", ")", ":", "\n", "                    ", "batches", ".", "append", "(", "Batch", "(", "possibly_smaller_batches", ")", ")", "\n", "\n", "", "", "move_to_front", "=", "self", ".", "_biggest_batch_first", "and", "len", "(", "batches", ")", ">", "1", "\n", "if", "move_to_front", ":", "\n", "# We'll actually pop the last _two_ batches, because the last one might not be full.", "\n", "                ", "last_batch", "=", "batches", ".", "pop", "(", ")", "\n", "penultimate_batch", "=", "batches", ".", "pop", "(", ")", "\n", "", "if", "shuffle", ":", "\n", "# NOTE: if shuffle is false, the data will still be in a different order", "\n", "# because of the bucket sorting.", "\n", "                ", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "if", "move_to_front", ":", "\n", "                ", "batches", ".", "insert", "(", "0", ",", "penultimate_batch", ")", "\n", "batches", ".", "insert", "(", "0", ",", "last_batch", ")", "\n", "\n", "", "yield", "from", "batches", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.extended_bucket_iterator.sort_by_padding_modified": [[13, 40], ["instances_with_lengths.sort", "instance.index_fields", "instance.get_padding_lengths", "typing.cast", "instances_with_lengths.append", "len", "typing.cast.items", "allennlp.common.util.add_noise_to_dict_values"], "function", ["None"], ["def", "sort_by_padding_modified", "(", "instances", ":", "List", "[", "Instance", "]", ",", "\n", "sorting_keys", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "# pylint: disable=invalid-sequence-index", "\n", "vocab", ":", "Vocabulary", ",", "\n", "padding_noise", ":", "float", "=", "0.0", ")", "->", "List", "[", "Instance", "]", ":", "\n", "    ", "\"\"\"\n    Sorts the instances by their padding lengths, using the keys in\n    ``sorting_keys`` (in the order in which they are provided).  ``sorting_keys`` is a list of\n    ``(field_name, padding_key)`` tuples.\n    \"\"\"", "\n", "instances_with_lengths", "=", "[", "]", "\n", "for", "instance", "in", "instances", ":", "\n", "# Make sure instance is indexed before calling .get_padding", "\n", "        ", "instance", ".", "index_fields", "(", "vocab", ")", "\n", "padding_lengths", "=", "instance", ".", "get_padding_lengths", "(", ")", "\n", "padding_lengths", "[", "\"sentences\"", "]", "=", "{", "\"num_sentences\"", ":", "len", "(", "instance", ".", "fields", "[", "'tokens'", "]", ".", "field_list", ")", "}", "\n", "padding_lengths", "=", "cast", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "float", "]", "]", ",", "padding_lengths", ")", "\n", "if", "padding_noise", ">", "0.0", ":", "\n", "            ", "noisy_lengths", "=", "{", "}", "\n", "for", "field_name", ",", "field_lengths", "in", "padding_lengths", ".", "items", "(", ")", ":", "\n", "                ", "noisy_lengths", "[", "field_name", "]", "=", "add_noise_to_dict_values", "(", "field_lengths", ",", "padding_noise", ")", "\n", "", "padding_lengths", "=", "noisy_lengths", "\n", "", "instance_with_lengths", "=", "(", "[", "padding_lengths", "[", "field_name", "]", "[", "padding_key", "]", "\n", "for", "(", "field_name", ",", "padding_key", ")", "in", "sorting_keys", "]", ",", "\n", "instance", ")", "\n", "instances_with_lengths", ".", "append", "(", "instance_with_lengths", ")", "\n", "", "instances_with_lengths", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "return", "[", "instance_with_lengths", "[", "-", "1", "]", "for", "instance_with_lengths", "in", "instances_with_lengths", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ListProxy.__init__": [[11, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "prefix", ",", "nums", ")", ":", "\n", "        ", "self", ".", "module", "=", "module", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "nums", "=", "nums", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ListProxy.__getitem__": [[16, 18], ["getattr", "str"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "module", ",", "self", ".", "prefix", "+", "str", "(", "self", ".", "nums", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ConvNetNoEmbeddings.__init__": [[21, 38], ["torch.Module.__init__", "conv_seq2seq_encoder.ListProxy", "setattr", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "conv_seq2seq_encoder.ConvNetNoEmbeddings.add_module", "getattr", "range", "len", "torch.Conv1d", "torch.Conv1d", "str", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vector_dimension", ",", "output_dimension", ",", "min_convolution_size", ",", "max_convolution_size", ",", "\n", "train_convolutions", ",", "dropout", "=", ".5", ")", ":", "\n", "        ", "super", "(", "ConvNetNoEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "vector_dimension", "\n", "self", ".", "conv_sizes", "=", "[", "i", "for", "i", "in", "range", "(", "min_convolution_size", ",", "max_convolution_size", "+", "1", ",", "2", ")", "]", "\n", "assert", "output_dimension", "%", "len", "(", "self", ".", "conv_sizes", ")", "==", "0", "\n", "for", "i", "in", "self", ".", "conv_sizes", ":", "\n", "            ", "self", ".", "add_module", "(", "\"convs_\"", "+", "str", "(", "i", ")", ",", "nn", ".", "Conv1d", "(", "vector_dimension", ",", "output_dimension", "//", "len", "(", "self", ".", "conv_sizes", ")", ",", "\n", "i", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", ")", "\n", "temp_conv", "=", "getattr", "(", "self", ",", "\"convs_\"", "+", "str", "(", "i", ")", ")", "\n", "if", "not", "train_convolutions", ":", "\n", "                ", "temp_conv", ".", "weight", ".", "requires_grad", "=", "False", "\n", "", "", "self", ".", "convs", "=", "ListProxy", "(", "self", ",", "'convs_'", ",", "self", ".", "conv_sizes", ")", "\n", "setattr", "(", "self", ",", "\"convpadding_\"", "+", "str", "(", "min_convolution_size", ")", ",", "None", ")", "\n", "self", ".", "nonlinearity", "=", "nn", ".", "ReLU", "(", ")", "# was nn.Tanh() before", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "output_dimension", "=", "output_dimension", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ConvNetNoEmbeddings.forward": [[39, 88], ["x.permute().contiguous().view.permute().contiguous().view.size", "x.permute().contiguous().view.permute().contiguous().view.size", "x.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "conv_seq2seq_encoder.ConvNetNoEmbeddings.dropout", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "mask.unsqueeze.unsqueeze.float", "range", "starting_mask.unsqueeze.unsqueeze.expand", "getattr", "conv_layer", "conv_seq2seq_encoder.ConvNetNoEmbeddings.nonlinearity", "pieces_of_x.append", "mask.unsqueeze.unsqueeze.float", "range", "mask.unsqueeze.unsqueeze.dim", "x.permute().contiguous().view.permute().contiguous().view.dim", "str", "starting_mask.unsqueeze.unsqueeze.dim", "starting_mask.unsqueeze.unsqueeze.dim", "x.permute().contiguous().view.permute().contiguous().view.dim", "starting_mask.unsqueeze.unsqueeze.unsqueeze", "x.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "getattr", "torch.autograd.Variable.expand", "torch.autograd.Variable.expand", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "mask.unsqueeze.unsqueeze.dim", "x.permute().contiguous().view.permute().contiguous().view.dim", "str", "mask.unsqueeze.unsqueeze.dim", "mask.unsqueeze.unsqueeze.dim", "x.permute().contiguous().view.permute().contiguous().view.dim", "mask.unsqueeze.unsqueeze.unsqueeze", "mask.unsqueeze.unsqueeze.expand", "x.permute().contiguous().view.permute().contiguous().view.dim", "starting_mask.unsqueeze.unsqueeze.size", "x.permute().contiguous().view.permute().contiguous().view.size", "str", "starting_mask.unsqueeze.unsqueeze.dim", "x.permute().contiguous().view.permute().contiguous().view.size", "str", "x.permute().contiguous().view.permute().contiguous().view.new_zeros", "setattr", "x.permute().contiguous().view.permute().contiguous().view.dim", "mask.unsqueeze.unsqueeze.size", "x.permute().contiguous().view.permute().contiguous().view.size", "str", "mask.unsqueeze.unsqueeze.dim", "str", "mask.unsqueeze.unsqueeze.size", "int", "x.permute().contiguous().view.permute().contiguous().view.permute", "str", "x.permute().contiguous().view.permute().contiguous().view.permute", "str", "mask.unsqueeze.unsqueeze.size", "x.permute().contiguous().view.permute().contiguous().view.size", "mask.unsqueeze.unsqueeze.dim", "str", "str", "mask.unsqueeze.unsqueeze.dim", "str", "x.permute().contiguous().view.permute().contiguous().view.size", "x.permute().contiguous().view.permute().contiguous().view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "if", "mask", "is", "not", "None", ":", "\n", "# padding for the shorter sequences isn't zero on the right unless we do this", "\n", "            ", "starting_mask", "=", "mask", ".", "float", "(", ")", "\n", "assert", "mask", ".", "dim", "(", ")", "<=", "x", ".", "dim", "(", ")", ",", "(", "\"Passed in mask with dimension \"", "+", "str", "(", "mask", ".", "dim", "(", ")", ")", "+", "\n", "\" but output-in-progress only has dimension \"", "+", "str", "(", "x", ".", "dim", "(", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "starting_mask", ".", "dim", "(", ")", ")", ":", "\n", "                ", "assert", "starting_mask", ".", "size", "(", "i", ")", "==", "x", ".", "size", "(", "i", ")", ",", "(", "\"Dimension mismatch: planned output has size \"", "+", "str", "(", "x", ".", "size", "(", ")", ")", "+", "\n", "\", but provided mask has size \"", "+", "str", "(", "mask", ".", "size", "(", ")", ")", ")", "\n", "", "while", "starting_mask", ".", "dim", "(", ")", "<", "x", ".", "dim", "(", ")", ":", "\n", "                ", "starting_mask", "=", "starting_mask", ".", "unsqueeze", "(", "starting_mask", ".", "dim", "(", ")", ")", "\n", "", "", "x", "=", "x", "*", "starting_mask", ".", "expand", "(", "*", "(", "x", ".", "size", "(", ")", ")", ")", "\n", "num_instances", "=", "x", ".", "size", "(", "0", ")", "\n", "num_items_in_seq", "=", "x", ".", "size", "(", "1", ")", "\n", "if", "getattr", "(", "self", ",", "\"convpadding_\"", "+", "str", "(", "self", ".", "conv_sizes", "[", "0", "]", ")", ")", "is", "None", ":", "\n", "            ", "for", "i", "in", "self", ".", "conv_sizes", ":", "\n", "                ", "if", "i", ">=", "3", ":", "\n", "                    ", "padding_to_add", "=", "x", ".", "new_zeros", "(", "1", ",", "self", ".", "input_dim", ",", "(", "int", "(", "(", "i", "-", "1", ")", "/", "2", ")", ")", ")", "\n", "setattr", "(", "self", ",", "\"convpadding_\"", "+", "str", "(", "i", ")", ",", "padding_to_add", ")", "\n", "# by this point, x is a 3-dim tensor: sentence x word x embedding_dimension", "\n", "", "", "", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "num_instances", ",", "self", ".", "input_dim", ",", "num_items_in_seq", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "pieces_of_x", "=", "[", "]", "\n", "# each piece_of_x_with_padding will be of size batch_size x num_output_dims_div_by_num_convs x seq_len", "\n", "for", "conv_layer", ",", "filter_size", "in", "zip", "(", "self", ".", "convs", ",", "self", ".", "conv_sizes", ")", ":", "\n", "            ", "if", "filter_size", ">=", "3", ":", "\n", "                ", "padding", "=", "getattr", "(", "self", ",", "\"convpadding_\"", "+", "str", "(", "filter_size", ")", ")", "\n", "padding", "=", "padding", ".", "expand", "(", "num_instances", ",", "padding", ".", "shape", "[", "1", "]", ",", "padding", ".", "shape", "[", "2", "]", ")", "\n", "padding", "=", "Variable", "(", "padding", ")", "\n", "piece_of_x_with_padding", "=", "torch", ".", "cat", "(", "[", "padding", ",", "x", ",", "padding", "]", ",", "2", ")", "\n", "", "else", ":", "\n", "                ", "piece_of_x_with_padding", "=", "x", "\n", "", "piece_of_x_with_padding", "=", "conv_layer", "(", "piece_of_x_with_padding", ")", "\n", "\n", "piece_of_x_with_padding", "=", "self", ".", "nonlinearity", "(", "piece_of_x_with_padding", ")", "\n", "pieces_of_x", ".", "append", "(", "piece_of_x_with_padding", ")", "\n", "", "x", "=", "torch", ".", "cat", "(", "pieces_of_x", ",", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "num_instances", ",", "num_items_in_seq", ",", "self", ".", "output_dimension", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "float", "(", ")", "\n", "assert", "mask", ".", "dim", "(", ")", "<=", "x", ".", "dim", "(", ")", ",", "(", "\"Passed in mask with dimension \"", "+", "str", "(", "mask", ".", "dim", "(", ")", ")", "+", "\n", "\" but output-in-progress only has dimension \"", "+", "str", "(", "x", ".", "dim", "(", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "mask", ".", "dim", "(", ")", ")", ":", "\n", "                ", "assert", "mask", ".", "size", "(", "i", ")", "==", "x", ".", "size", "(", "i", ")", ",", "(", "\"Dimension mismatch: planned output has size \"", "+", "str", "(", "x", ".", "size", "(", ")", ")", "+", "\n", "\", but provided mask has size \"", "+", "str", "(", "mask", ".", "size", "(", ")", ")", ")", "\n", "", "while", "mask", ".", "dim", "(", ")", "<", "x", ".", "dim", "(", ")", ":", "\n", "                ", "mask", "=", "mask", ".", "unsqueeze", "(", "mask", ".", "dim", "(", ")", ")", "\n", "", "x", "=", "x", "*", "mask", ".", "expand", "(", "*", "(", "x", ".", "size", "(", ")", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ConvSeq2SeqEncoder.__init__": [[92, 104], ["allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.__init__", "conv_seq2seq_encoder.ConvNetNoEmbeddings"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_size", ":", "int", ",", "\n", "hidden_size", ":", "int", ",", "\n", "min_conv_size", ":", "int", "=", "3", ",", "\n", "max_conv_size", ":", "int", "=", "5", ",", "\n", "dropout", ":", "float", "=", "0.3", ")", "->", "None", ":", "\n", "        ", "assert", "min_conv_size", "%", "2", "==", "1", "and", "max_conv_size", "%", "2", "==", "1", ",", "\"Both min_conv_size and max_conv_size must be odd.\"", "\n", "super", "(", "ConvSeq2SeqEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "conv_encoder", "=", "ConvNetNoEmbeddings", "(", "input_size", ",", "hidden_size", ",", "min_conv_size", ",", "max_conv_size", ",", "True", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ConvSeq2SeqEncoder.forward": [[105, 112], ["conv_seq2seq_encoder.ConvSeq2SeqEncoder.conv_encoder"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "# not packed", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "hidden_state", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "# assume batch is first", "\n", "        ", "return", "self", ".", "conv_encoder", "(", "inputs", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ConvSeq2SeqEncoder.is_bidirectional": [[113, 116], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "is_bidirectional", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ConvSeq2SeqEncoder.get_input_dim": [[117, 120], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ConvSeq2SeqEncoder.get_output_dim": [[121, 124], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.convert_list_of_instances_to_3d_torch_tensor": [[126, 141], ["copy.deepcopy", "numpy.array", "numpy.random.uniform", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy.new_ones", "torch.from_numpy.size", "torch.from_numpy.long", "len", "len", "len", "instance.append", "len"], "function", ["None"], ["", "", "def", "convert_list_of_instances_to_3d_torch_tensor", "(", "list_of_instances", ",", "third_dim", ")", ":", "\n", "    ", "list_of_instances", "=", "deepcopy", "(", "list_of_instances", ")", "\n", "max_instance_len", "=", "0", "\n", "for", "instance", "in", "list_of_instances", ":", "\n", "        ", "if", "len", "(", "instance", ")", ">", "max_instance_len", ":", "\n", "            ", "max_instance_len", "=", "len", "(", "instance", ")", "\n", "", "", "for", "instance", "in", "list_of_instances", ":", "\n", "        ", "while", "len", "(", "instance", ")", "<", "max_instance_len", ":", "\n", "            ", "instance", ".", "append", "(", "0.0", ")", "\n", "", "", "twod_arr", "=", "np", ".", "array", "(", "list_of_instances", ")", "\n", "arr_to_mult_by", "=", "np", ".", "random", ".", "uniform", "(", "1", ",", "4", ",", "[", "len", "(", "list_of_instances", ")", ",", "max_instance_len", ",", "third_dim", "]", ")", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "twod_arr", ")", "\n", "arr_to_mult_by", "=", "torch", ".", "from_numpy", "(", "arr_to_mult_by", ")", "\n", "all_ones", "=", "mask", ".", "new_ones", "(", "arr_to_mult_by", ".", "size", "(", ")", ")", "\n", "return", "(", "all_ones", "*", "arr_to_mult_by", ")", ".", "float", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.test_for_padding_usage": [[143, 172], ["conv_seq2seq_encoder.ConvSeq2SeqEncoder", "conv.eval.conv_encoder.convs_3.weight.data.copy_", "conv.eval.conv_encoder.convs_3.bias.data.copy_", "conv.eval.conv_encoder.convs_5.weight.data.copy_", "conv.eval.conv_encoder.convs_5.bias.data.copy_", "conv.eval.eval", "conv_seq2seq_encoder.convert_list_of_instances_to_3d_torch_tensor", "str", "input_tens[].view", "mask[].view", "print", "print", "print", "print", "print", "print", "print", "print", "print", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "[].data.cpu().numpy", "len", "input_tens.size", "len", "[].data.cpu().numpy", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "str", "str", "[].data.cpu", "input_tens[].view.size", "mask.cpu().numpy", "[].data.cpu", "len", "len", "mask.cpu", "conv.eval.", "conv.eval."], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.convert_list_of_instances_to_3d_torch_tensor"], ["", "def", "test_for_padding_usage", "(", ")", ":", "\n", "    ", "input_dimension", "=", "12", "\n", "output_dimension", "=", "6", "\n", "list_of_instances", "=", "[", "[", "1.0", ",", "1.0", ",", "1.0", "]", ",", "\n", "[", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", "]", ",", "\n", "[", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", "]", "]", "\n", "conv", "=", "ConvSeq2SeqEncoder", "(", "input_dimension", ",", "output_dimension", ",", "dropout", "=", "0.0", ")", "\n", "\n", "conv", ".", "conv_encoder", ".", "convs_3", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "uniform", "(", "1", ",", "4", ",", "[", "output_dimension", "//", "2", ",", "\n", "input_dimension", ",", "3", "]", ")", ")", ")", "\n", "conv", ".", "conv_encoder", ".", "convs_3", ".", "bias", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "uniform", "(", "1", ",", "4", ",", "[", "output_dimension", "//", "2", "]", ")", ")", ")", "\n", "conv", ".", "conv_encoder", ".", "convs_5", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "uniform", "(", "1", ",", "4", ",", "[", "output_dimension", "//", "2", ",", "\n", "input_dimension", ",", "5", "]", ")", ")", ")", "\n", "conv", ".", "conv_encoder", ".", "convs_5", ".", "bias", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "uniform", "(", "1", ",", "4", ",", "[", "output_dimension", "//", "2", "]", ")", ")", ")", "\n", "\n", "conv", "=", "conv", ".", "eval", "(", ")", "\n", "input_tens", ",", "mask", "=", "convert_list_of_instances_to_3d_torch_tensor", "(", "list_of_instances", ",", "input_dimension", ")", "\n", "full_to_print", "=", "str", "(", "conv", "(", "input_tens", ",", "mask", ")", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "new_inp_tensor", "=", "input_tens", "[", "0", ",", ":", "len", "(", "list_of_instances", "[", "0", "]", ")", ",", ":", "]", ".", "view", "(", "1", ",", "len", "(", "list_of_instances", "[", "0", "]", ")", ",", "input_tens", ".", "size", "(", "2", ")", ")", "\n", "new_mask", "=", "mask", "[", "0", ",", ":", "len", "(", "list_of_instances", "[", "0", "]", ")", "]", ".", "view", "(", "1", ",", "len", "(", "list_of_instances", "[", "0", "]", ")", ")", "\n", "print", "(", "mask", ")", "\n", "print", "(", "new_mask", ")", "\n", "print", "(", "\"Dimensions of new input tensor: \"", "+", "str", "(", "new_inp_tensor", ".", "size", "(", ")", ")", ")", "\n", "print", "(", "new_inp_tensor", ")", "\n", "print", "(", ")", "\n", "print", "(", "full_to_print", ")", "\n", "print", "(", "\"Mask used: \"", "+", "str", "(", "mask", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "print", "(", "conv", "(", "new_inp_tensor", ",", "new_mask", ")", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "print", "(", "\"Those should both be the same.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.classifier_from_attn_and_input_vects.ClassifierFromAttnAndInputVects.__init__": [[10, 14], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "classification_module", ":", "FeedForward", ")", "->", "None", ":", "\n", "        ", "super", "(", "ClassifierFromAttnAndInputVects", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_classification_module", "=", "classification_module", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.classifier_from_attn_and_input_vects.ClassifierFromAttnAndInputVects.forward": [[15, 46], ["input_vects.size", "input_vects.size", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.sum", "classifier_from_attn_and_input_vects.ClassifierFromAttnAndInputVects._classification_module", "torch.nn.functional.softmax", "output_token_representation.size", "torch.sum", "str", "torch.sum.view", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze", "attn_weights[].sum", "correct.float", "str", "attn_weights[].sum", "attn_weights[].sum", "torch.sum", "attn_weights[].sum", "attn_weights[].sum", "attn_weights[].sum", "attn_weights[].sum", "attn_weights[].sum", "attn_weights[].sum"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax"], ["", "def", "forward", "(", "self", ",", "\n", "input_vects", ":", "torch", ".", "Tensor", ",", "\n", "intra_sentence_attention", ":", "torch", ".", "Tensor", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# Shape: (batch_size, sequence_length, projection_dim)", "\n", "        ", "batch_size", "=", "input_vects", ".", "size", "(", "0", ")", "\n", "sequence_length", "=", "input_vects", ".", "size", "(", "1", ")", "\n", "output_token_representation", "=", "input_vects", "\n", "attn_weights", "=", "intra_sentence_attention", "\n", "\n", "attn_weights", "=", "attn_weights", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "batch_size", ",", "sequence_length", ",", "\n", "output_token_representation", ".", "size", "(", "2", ")", ")", "\n", "# Shape: (batch_size, sequence_length, [num_heads,] projection_dim [/ num_heads])", "\n", "correct", "=", "(", "(", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", ">", ".98", ")", "&", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "<", "1.02", ")", ")", "|", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "==", "0", ")", ")", "\n", "assert", "torch", ".", "sum", "(", "correct", ".", "float", "(", ")", ")", "==", "batch_size", ",", "(", "str", "(", "attn_weights", "[", "(", "(", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "<=", ".98", ")", "|", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", ">=", "1.02", ")", ")", "&", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "!=", "0", ")", ")", "]", ")", "+", "\"\\n\"", "+", "\n", "str", "(", "torch", ".", "sum", "(", "attn_weights", ",", "dim", "=", "1", ")", "[", "(", "(", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "<=", ".98", ")", "|", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", ">=", "1.02", ")", ")", "&", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "!=", "0", ")", ")", "]", ")", ")", "\n", "combined_tensors", "=", "output_token_representation", "*", "attn_weights", "\n", "\n", "document_repr", "=", "torch", ".", "sum", "(", "combined_tensors", ",", "1", ")", "\n", "\n", "label_logits", "=", "self", ".", "_classification_module", "(", "document_repr", ".", "view", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "label_probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "label_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output_dict", "=", "{", "\"label_logits\"", ":", "label_logits", ",", "\"label_probs\"", ":", "label_probs", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.classifier_from_attn_and_input_vects.GradientReportingClassifierFromAttnAndInputVects.__init__": [[61, 77], ["super().__init__", "range", "len", "dropout_module_list.__getitem__", "dropout_module_list.__setitem__"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.conv_seq2seq_encoder.ListProxy.__getitem__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "classification_module", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "temp_filename", ":", "str", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "GradientReportingClassifierFromAttnAndInputVects", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_classification_module", "=", "classification_module", "\n", "assert", "self", ".", "_classification_module", ".", "__class__", ".", "__name__", "==", "'FeedForward'", ",", "(", "\"GradientReportingClassifierFromAttnAndInputVects currently assumes a feedforward output classifier \"", "+", "\n", "\"for dropout-zeroing purposes, but given output classifier type was \"", "+", "\n", "self", ".", "_classification_module", ".", "__class__", ".", "__name__", ")", "\n", "dropout_module_list", "=", "self", ".", "_classification_module", ".", "_dropout", "\n", "# set p in all dropouts to 0", "\n", "for", "i", "in", "range", "(", "len", "(", "dropout_module_list", ")", ")", ":", "\n", "            ", "modified_dropout", "=", "dropout_module_list", ".", "__getitem__", "(", "i", ")", "\n", "modified_dropout", ".", "p", "=", "0.0", "\n", "dropout_module_list", ".", "__setitem__", "(", "i", ",", "modified_dropout", ")", "\n", "", "self", ".", "_temp_filename", "=", "temp_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.classifier_from_attn_and_input_vects.GradientReportingClassifierFromAttnAndInputVects.set_temp_filename": [[78, 80], ["None"], "methods", ["None"], ["", "def", "set_temp_filename", "(", "self", ",", "fname", ")", ":", "\n", "        ", "self", ".", "_temp_filename", "=", "fname", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.classifier_from_attn_and_input_vects.GradientReportingClassifierFromAttnAndInputVects.forward": [[81, 116], ["input_vects.size", "input_vects.size", "attn_weights.unsqueeze().expand.unsqueeze().expand.register_hook", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.sum", "classifier_from_attn_and_input_vects.GradientReportingClassifierFromAttnAndInputVects._classification_module", "torch.nn.functional.softmax", "output_token_representation.size", "torch.sum", "str", "torch.sum.view", "classifier_from_attn_and_input_vects.backward_gradient_reporting_template", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze", "attn_weights[].sum", "correct.float", "str", "attn_weights[].sum", "attn_weights[].sum", "torch.sum", "attn_weights[].sum", "attn_weights[].sum", "attn_weights[].sum", "attn_weights[].sum", "attn_weights[].sum", "attn_weights[].sum"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax", "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.classifier_from_attn_and_input_vects.backward_gradient_reporting_template"], ["", "def", "forward", "(", "self", ",", "\n", "input_vects", ":", "torch", ".", "Tensor", ",", "\n", "intra_sentence_attention", ":", "torch", ".", "Tensor", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# Shape: (batch_size, sequence_length, projection_dim)", "\n", "        ", "batch_size", "=", "input_vects", ".", "size", "(", "0", ")", "\n", "sequence_length", "=", "input_vects", ".", "size", "(", "1", ")", "\n", "output_token_representation", "=", "input_vects", "\n", "attn_weights", "=", "intra_sentence_attention", "\n", "\n", "attn_weights", ".", "register_hook", "(", "lambda", "grad", ":", "backward_gradient_reporting_template", "(", "grad", ",", "self", ".", "_temp_filename", ")", ")", "\n", "\n", "attn_weights", "=", "attn_weights", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "batch_size", ",", "sequence_length", ",", "\n", "output_token_representation", ".", "size", "(", "2", ")", ")", "\n", "# Shape: (batch_size, sequence_length, [num_heads,] projection_dim [/ num_heads])", "\n", "\n", "correct", "=", "(", "(", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", ">", ".98", ")", "&", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "<", "1.02", ")", ")", "|", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "==", "0", ")", ")", "\n", "assert", "torch", ".", "sum", "(", "correct", ".", "float", "(", ")", ")", "==", "batch_size", ",", "(", "str", "(", "attn_weights", "[", "(", "(", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "<=", ".98", ")", "|", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", ">=", "1.02", ")", ")", "&", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "!=", "0", ")", ")", "]", ")", "+", "\"\\n\"", "+", "\n", "str", "(", "torch", ".", "sum", "(", "attn_weights", ",", "dim", "=", "1", ")", "[", "(", "(", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "<=", ".98", ")", "|", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", ">=", "1.02", ")", ")", "&", "\n", "(", "attn_weights", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "!=", "0", ")", ")", "]", ")", ")", "\n", "\n", "combined_tensors", "=", "output_token_representation", "*", "attn_weights", "\n", "\n", "document_repr", "=", "torch", ".", "sum", "(", "combined_tensors", ",", "1", ")", "\n", "\n", "label_logits", "=", "self", ".", "_classification_module", "(", "document_repr", ".", "view", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "label_probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "label_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output_dict", "=", "{", "\"label_logits\"", ":", "label_logits", ",", "\"label_probs\"", ":", "label_probs", "}", "\n", "\n", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.attn_tests_lib.classifier_from_attn_and_input_vects.backward_gradient_reporting_template": [[48, 58], ["grad_input[].view", "open", "pickle.dump", "range", "torch.cat().cpu", "len", "torch.cat"], "function", ["None"], ["", "", "def", "backward_gradient_reporting_template", "(", "grad_input", ",", "filename", ")", ":", "\n", "    ", "\"\"\"\n    Wrap this in a lambda function providing the filename when registering it as a backwards hook\n    :param input:\n    :param filename:\n    :return:\n    \"\"\"", "\n", "tensors_to_cat", "=", "[", "grad_input", "[", "j", "]", ".", "view", "(", "1", ",", "-", "1", ")", "for", "j", "in", "range", "(", "len", "(", "grad_input", ")", ")", "]", "\n", "with", "open", "(", "filename", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "torch", ".", "cat", "(", "tensors_to_cat", ",", "dim", "=", "0", ")", ".", "cpu", "(", ")", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.han_paper_attn_function.HanPaperSimilarityFunction.__init__": [[9, 15], ["allennlp.modules.similarity_functions.similarity_function.SimilarityFunction.__init__", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_dim", ":", "int", ",", "\n", "context_vect_dim", ":", "int", ")", "->", "None", ":", "\n", "        ", "super", "(", "HanPaperSimilarityFunction", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_mlp", "=", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "context_vect_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "_context_dot_product", "=", "torch", ".", "nn", ".", "Linear", "(", "context_vect_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.han_paper_attn_function.HanPaperSimilarityFunction.forward": [[16, 29], ["tensor_1[].view().contiguous", "tensor_1.unsqueeze().expand.unsqueeze().expand.size", "tensor_1.unsqueeze().expand.unsqueeze().expand.view", "torch.tanh", "han_paper_attn_function.HanPaperSimilarityFunction._context_dot_product", "tensor_1.unsqueeze().expand.unsqueeze().expand.view", "tensor_1.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "tensor_1.unsqueeze().expand.unsqueeze().expand.size", "han_paper_attn_function.HanPaperSimilarityFunction._mlp", "tensor_1.unsqueeze().expand.unsqueeze().expand.size", "tensor_1.unsqueeze().expand.unsqueeze().expand.size", "tensor_1[].view", "tensor_1.unsqueeze().expand.unsqueeze().expand.size", "tensor_1.unsqueeze().expand.unsqueeze().expand.unsqueeze", "tensor_1.unsqueeze().expand.unsqueeze().expand.size", "tensor_1.unsqueeze().expand.unsqueeze().expand.size", "tensor_1.unsqueeze().expand.unsqueeze().expand.size"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "tensor_1", ":", "torch", ".", "Tensor", ",", "tensor_2", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "# un-expand tensor_1, which is the only one we'll use", "\n", "        ", "tensor_1", "=", "tensor_1", "[", ":", ",", ":", ",", "0", ",", ":", "]", ".", "view", "(", "tensor_1", ".", "size", "(", "0", ")", ",", "tensor_1", ".", "size", "(", "1", ")", ",", "tensor_1", ".", "size", "(", "3", ")", ")", ".", "contiguous", "(", ")", "\n", "\n", "# new shape: batch_size x seq_len x embedding_dim", "\n", "batch_size", "=", "tensor_1", ".", "size", "(", "0", ")", "\n", "tensor_1", "=", "tensor_1", ".", "view", "(", "batch_size", "*", "tensor_1", ".", "size", "(", "1", ")", ",", "tensor_1", ".", "size", "(", "2", ")", ")", "\n", "tensor_1", "=", "torch", ".", "tanh", "(", "self", ".", "_mlp", "(", "tensor_1", ")", ")", "\n", "tensor_1", "=", "self", ".", "_context_dot_product", "(", "tensor_1", ")", "\n", "tensor_1", "=", "tensor_1", ".", "view", "(", "batch_size", ",", "-", "1", ")", "# batch_size x seq_len", "\n", "tensor_1", "=", "tensor_1", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "tensor_1", ".", "size", "(", "1", ")", ",", "tensor_1", ".", "size", "(", "1", ")", ")", "\n", "return", "tensor_1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.__init__": [[34, 52], ["allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder.__init__", "talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder._input_vector_dir_name.endswith"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "encoder_wrapped", ":", "Seq2SeqEncoder", ",", "\n", "attn_weight_filename", ":", "str", ",", "\n", "input_vector_dir_name", ":", "str", ",", "\n", "total_num_test_instances", ":", "int", ")", "->", "None", ":", "\n", "        ", "super", "(", "TalkativeIntraSentenceAttentionEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_encoder_wrapped", "=", "encoder_wrapped", "\n", "self", ".", "_matrix_attention", "=", "encoder_wrapped", ".", "_matrix_attention", "\n", "self", ".", "_num_attention_heads", "=", "encoder_wrapped", ".", "_num_attention_heads", "\n", "self", ".", "_projection", "=", "encoder_wrapped", ".", "_projection", "\n", "self", ".", "_output_projection", "=", "encoder_wrapped", ".", "_output_projection", "\n", "self", ".", "_combination", "=", "encoder_wrapped", ".", "_combination", "\n", "self", ".", "_attn_weight_filename", "=", "attn_weight_filename", "\n", "self", ".", "_input_vector_dir_name", "=", "input_vector_dir_name", "\n", "if", "not", "self", ".", "_input_vector_dir_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "self", ".", "_input_vector_dir_name", "+=", "'/'", "\n", "", "self", ".", "_next_available_counter_ind_file", "=", "self", ".", "_input_vector_dir_name", "+", "\"next_available_counter.txt\"", "\n", "self", ".", "_total_num_test_instances", "=", "total_num_test_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.get_input_dim": [[53, 56], ["talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder._encoder_wrapped.get_input_dim"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.get_input_dim"], ["", "@", "overrides", "\n", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_encoder_wrapped", ".", "get_input_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.get_output_dim": [[57, 60], ["talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder._encoder_wrapped.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.get_output_dim"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_encoder_wrapped", ".", "get_output_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.is_bidirectional": [[61, 64], ["talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder._encoder_wrapped.is_bidirectional"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.is_bidirectional"], ["", "@", "overrides", "\n", "def", "is_bidirectional", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_encoder_wrapped", ".", "is_bidirectional", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.forward": [[65, 112], ["tokens.size", "talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder._matrix_attention", "similarity_matrix.permute.permute.contiguous", "mask.unsqueeze", "talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder._projection", "talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.report_unnormalized_log_attn_weights", "allennlp.nn.util.masked_softmax", "allennlp.nn.util.weighted_sum", "allennlp.nn.util.combine_tensors", "talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder._output_projection", "similarity_matrix.permute.permute.permute", "similarity_matrix.permute.permute.contiguous", "list", "output_token_representation.permute.permute.view", "output_token_representation.permute.permute.permute", "attended_sentence.view.view.view", "output_token_representation.permute.permute.size"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.report_unnormalized_log_attn_weights"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "tokens", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "assert", "mask", "is", "not", "None", ",", "\"TalkativeIntraSentenceAttentionEncoder requires a mask to be provided.\"", "\n", "batch_size", ",", "sequence_length", ",", "_", "=", "tokens", ".", "size", "(", ")", "\n", "# Shape: (batch_size, sequence_length, sequence_length)", "\n", "similarity_matrix", "=", "self", ".", "_matrix_attention", "(", "tokens", ",", "tokens", ")", "\n", "\n", "if", "self", ".", "_num_attention_heads", ">", "1", ":", "\n", "# In this case, the similarity matrix actually has shape", "\n", "# (batch_size, sequence_length, sequence_length, num_heads).  To make the rest of the", "\n", "# logic below easier, we'll permute this to", "\n", "# (batch_size, sequence_length, num_heads, sequence_length).", "\n", "            ", "similarity_matrix", "=", "similarity_matrix", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ")", "\n", "\n", "# Shape: (batch_size, sequence_length, [num_heads,] sequence_length)", "\n", "", "similarity_matrix", "=", "similarity_matrix", ".", "contiguous", "(", ")", "\n", "temp_mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "# Shape: (batch_size, sequence_length, projection_dim)", "\n", "output_token_representation", "=", "self", ".", "_projection", "(", "tokens", ")", "\n", "self", ".", "report_unnormalized_log_attn_weights", "(", "similarity_matrix", "*", "temp_mask", ",", "output_token_representation", ")", "\n", "\n", "intra_sentence_attention", "=", "util", ".", "masked_softmax", "(", "similarity_matrix", ".", "contiguous", "(", ")", ",", "mask", ")", "\n", "\n", "if", "self", ".", "_num_attention_heads", ">", "1", ":", "\n", "# We need to split and permute the output representation to be", "\n", "# (batch_size, num_heads, sequence_length, projection_dim / num_heads), so that we can", "\n", "# do a proper weighted sum with `intra_sentence_attention`.", "\n", "            ", "shape", "=", "list", "(", "output_token_representation", ".", "size", "(", ")", ")", "\n", "new_shape", "=", "shape", "[", ":", "-", "1", "]", "+", "[", "self", ".", "_num_attention_heads", ",", "-", "1", "]", "\n", "# Shape: (batch_size, sequence_length, num_heads, projection_dim / num_heads)", "\n", "output_token_representation", "=", "output_token_representation", ".", "view", "(", "*", "new_shape", ")", "\n", "# Shape: (batch_size, num_heads, sequence_length, projection_dim / num_heads)", "\n", "output_token_representation", "=", "output_token_representation", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "# Shape: (batch_size, sequence_length, [num_heads,] projection_dim [/ num_heads])", "\n", "", "attended_sentence", "=", "util", ".", "weighted_sum", "(", "output_token_representation", ",", "\n", "intra_sentence_attention", ")", "\n", "\n", "if", "self", ".", "_num_attention_heads", ">", "1", ":", "\n", "# Here we concatenate the weighted representation for each head.  We'll accomplish this", "\n", "# just with a resize.", "\n", "# Shape: (batch_size, sequence_length, projection_dim)", "\n", "            ", "attended_sentence", "=", "attended_sentence", ".", "view", "(", "batch_size", ",", "sequence_length", ",", "-", "1", ")", "\n", "\n", "# Shape: (batch_size, sequence_length, combination_dim)", "\n", "", "combined_tensors", "=", "util", ".", "combine_tensors", "(", "self", ".", "_combination", ",", "[", "tokens", ",", "attended_sentence", "]", ")", "\n", "return", "self", ".", "_output_projection", "(", "combined_tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.TalkativeIntraSentenceAttentionEncoder.report_unnormalized_log_attn_weights": [[113, 157], ["vects_of_attn_weights.unsqueeze().expand", "numpy.save", "os.path.isfile", "os.path.isfile", "str", "input_vects.data.cpu().numpy", "open", "range", "open", "f.write", "attn_weights.dim", "attn_weights.size", "attn_weights.size", "vects_of_attn_weights.unsqueeze", "attn_weights.size", "os.path.isdir", "os.makedirs", "open", "int", "vects_of_attn_weights.size", "f.write", "talkative_intra_sentence_attention.binary_search_for_num_non_padded_tokens_in_instance", "min", "max", "f.write", "f.write", "str", "str", "len", "print", "exit", "f.readline", "str", "vects_of_attn_weights.size", "input_vects.data.cpu", "float", "str", "attn_weights.size", "os.listdir", "str", "range", "str", "attn_weights.data.cpu().numpy", "str", "attn_weights.data.cpu", "str"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.binary_search_for_num_non_padded_tokens_in_instance"], ["", "def", "report_unnormalized_log_attn_weights", "(", "self", ",", "attn_weights", ",", "input_vects", ")", ":", "\n", "        ", "assert", "attn_weights", ".", "dim", "(", ")", "==", "3", "and", "attn_weights", ".", "size", "(", "1", ")", "==", "attn_weights", ".", "size", "(", "2", ")", ",", "(", "\"Size of attn weights (\"", "+", "str", "(", "attn_weights", ".", "size", "(", ")", ")", "+", "\") indicates multiheaded attention, but \"", "+", "\n", "\"TalkativeIntraSentenceAttentionEncoder currently assumes single-head attention.\"", ")", "\n", "vects_of_attn_weights", "=", "attn_weights", "[", ":", ",", "0", ",", ":", "]", "\n", "should_be_same_as_attn_weights", "=", "vects_of_attn_weights", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "*", "(", "attn_weights", ".", "size", "(", ")", ")", ")", "\n", "assert", "(", "attn_weights", "-", "should_be_same_as_attn_weights", ")", ".", "nonzero", "(", ")", ".", "size", "(", "0", ")", "==", "0", ",", "(", "\"Printing attn weights: \\n\"", "+", "str", "(", "attn_weights", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "+", "\"\\nPrinted attention weights, \"", "+", "\n", "\"which are not the same for every element of a single item in a sequence. \"", "+", "\n", "\"TalkativeIntraSentenceAttentionEncoder currently assumes the attention weight for each dimension \"", "+", "\n", "\"is the same.\"", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "self", ".", "_attn_weight_filename", ")", ":", "\n", "            ", "next_available_ind", "=", "1", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "_input_vector_dir_name", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "_input_vector_dir_name", ")", "\n", "", "else", ":", "\n", "                ", "if", "len", "(", "os", ".", "listdir", "(", "self", ".", "_input_vector_dir_name", ")", ")", "!=", "0", ":", "\n", "                    ", "print", "(", "\"ERROR: couldn't find file \"", "+", "str", "(", "self", ".", "_attn_weight_filename", ")", "+", "\", but \"", "+", "\n", "self", ".", "_input_vector_dir_name", "+", "\" exists and is nonempty.\"", ")", "\n", "exit", "(", "1", ")", "\n", "", "", "", "else", ":", "\n", "            ", "assert", "os", ".", "path", ".", "isfile", "(", "self", ".", "_next_available_counter_ind_file", ")", "\n", "with", "open", "(", "self", ".", "_next_available_counter_ind_file", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "next_available_ind", "=", "int", "(", "f", ".", "readline", "(", ")", ")", "\n", "", "", "assert", "next_available_ind", "<=", "self", ".", "_total_num_test_instances", ",", "\"Looks like you're overwriting previously saved results.\"", "\n", "input_vects_filename", "=", "(", "self", ".", "_input_vector_dir_name", "+", "str", "(", "next_available_ind", ")", "+", "'-'", "+", "\n", "str", "(", "next_available_ind", "+", "vects_of_attn_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "np", ".", "save", "(", "input_vects_filename", ",", "input_vects", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "with", "open", "(", "self", ".", "_attn_weight_filename", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "for", "i", "in", "range", "(", "vects_of_attn_weights", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "f", ".", "write", "(", "str", "(", "next_available_ind", ")", "+", "\": \"", ")", "\n", "num_nonpadding_pieces_in_row", "=", "binary_search_for_num_non_padded_tokens_in_instance", "(", "vects_of_attn_weights", ",", "i", ")", "\n", "weights_to_write", "=", "[", "float", "(", "vects_of_attn_weights", "[", "i", ",", "j", "]", ")", "\n", "for", "j", "in", "range", "(", "num_nonpadding_pieces_in_row", ")", "]", "\n", "min_val", "=", "min", "(", "weights_to_write", ")", "\n", "max_val", "=", "max", "(", "weights_to_write", ")", "\n", "val_to_subtract", "=", "(", "(", "max_val", "-", "min_val", ")", "/", "2", ")", "+", "min_val", "\n", "f", ".", "write", "(", "str", "(", "\" \"", ".", "join", "(", "[", "str", "(", "w", "-", "val_to_subtract", ")", "for", "w", "in", "weights_to_write", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "next_available_ind", "+=", "1", "\n", "", "", "with", "open", "(", "self", ".", "_next_available_counter_ind_file", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "next_available_ind", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.deprecated.talkative_intra_sentence_attention.binary_search_for_num_non_padded_tokens_in_instance": [[10, 30], ["full_array.size", "full_array.dim", "full_array.size", "full_array.size"], "function", ["None"], ["def", "binary_search_for_num_non_padded_tokens_in_instance", "(", "full_array", ",", "row_ind", ")", ":", "\n", "    ", "assert", "full_array", ".", "dim", "(", ")", "==", "2", "\n", "open_for_checking_start", "=", "0", "\n", "open_for_checking_endplus1", "=", "full_array", ".", "size", "(", "1", ")", "\n", "look_at", "=", "(", "open_for_checking_start", "+", "open_for_checking_endplus1", ")", "//", "2", "\n", "first_zero_ind_identified", "=", "None", "\n", "while", "first_zero_ind_identified", "is", "None", ":", "\n", "        ", "if", "full_array", "[", "row_ind", ",", "look_at", "]", "!=", "0", ":", "\n", "            ", "open_for_checking_start", "=", "look_at", "+", "1", "\n", "", "else", ":", "\n", "            ", "if", "full_array", "[", "row_ind", ",", "look_at", "-", "1", "]", "!=", "0", ":", "\n", "                ", "first_zero_ind_identified", "=", "look_at", "\n", "", "else", ":", "\n", "                ", "open_for_checking_endplus1", "=", "look_at", "\n", "", "", "if", "open_for_checking_start", "==", "open_for_checking_endplus1", ":", "\n", "            ", "assert", "open_for_checking_endplus1", "==", "full_array", ".", "size", "(", "1", ")", "\n", "first_zero_ind_identified", "=", "full_array", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "look_at", "=", "(", "open_for_checking_start", "+", "open_for_checking_endplus1", ")", "//", "2", "\n", "", "", "return", "first_zero_ind_identified", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_filenames_for_subdir": [[24, 38], ["default_directories.base_output_dir.endswith", "mid_dir.endswith"], "function", ["None"], ["def", "get_filenames_for_subdir", "(", "mid_dir", ")", ":", "\n", "    ", "global", "base_output_dir", "\n", "if", "not", "base_output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "base_output_dir", "+=", "'/'", "\n", "", "if", "not", "mid_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "mid_dir", "+=", "'/'", "\n", "", "return", "base_output_dir", "+", "mid_dir", "+", "first_v_second_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "rand_results_fname", ",", "base_output_dir", "+", "mid_dir", "+", "unchanged_fname", ",", "base_output_dir", "+", "mid_dir", "+", "grad_based_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontop_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "attn_div_from_unif_fname", ",", "base_output_dir", "+", "mid_dir", "+", "gradsignmult_based_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygrad_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygradmult_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygradsignmult_stats_fname", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num": [[104, 106], ["round"], "function", ["None"], ["", "def", "get_rounded_string_of_num", "(", "num", ")", ":", "\n", "    ", "return", "\"{:.1f}\"", ".", "format", "(", "round", "(", "100", "*", "num", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.generate_table_tex_file": [[108, 168], ["table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "table_maker.get_rounded_string_of_num", "print", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_rounded_string_of_num"], ["", "def", "generate_table_tex_file", "(", "caption", ",", "yahoo_both_onlytop_onlyrand_neither", ",", "imdb_both_onlytop_onlyrand_neither", ",", "\n", "amazon_both_onlytop_onlyrand_neither", ",", "yelp_both_onlytop_onlyrand_neither", ",", "\n", "vertical_text", ",", "tex_label", ",", "filename", ")", ":", "\n", "# numbers for each dataset should sum to 1", "\n", "    ", "str_to_ret", "=", "'\\subfloat['", "\n", "str_to_ret", "+=", "caption", "\n", "str_to_ret", "+=", "r\"\"\"]{\n\\begin{tabular}{clccllcc}\n\\multicolumn{1}{l}{}                &      & \\multicolumn{6}{c}{\\textbf{Remove random: Decision flip?}}                                                                                                                                                                                                                  \\\\\n                                          &                           & \\multicolumn{2}{c}{Yahoo}                                                                       &  &                           & \\multicolumn{2}{c}{IMDB}                                                                        \\\\\n                                          &                           & Yes                                           & No                                           &  &                           & Yes                                           & No                                           \\\\ \\cline{3-4} \\cline{7-8} \n                                          & \\multicolumn{1}{r|}{Yes} & \\multicolumn{1}{c|}{\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "yahoo_both_onlytop_onlyrand_neither", "[", "0", "]", ")", "\n", "str_to_ret", "+=", "'}                         & \\multicolumn{1}{c|}{\\cellcolor[HTML]{DAE8FC}'", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "yahoo_both_onlytop_onlyrand_neither", "[", "1", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"} &  & \\multicolumn{1}{r|}{Yes} & \\multicolumn{1}{c|}{\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "imdb_both_onlytop_onlyrand_neither", "[", "0", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"}                         & \\multicolumn{1}{c|}{\\cellcolor[HTML]{DAE8FC}\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "imdb_both_onlytop_onlyrand_neither", "[", "1", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"} \\\\ \\cline{3-4} \\cline{7-8} \n                                          & \\multicolumn{1}{r|}{No} & \\multicolumn{1}{c|}{\\cellcolor[HTML]{F8A102}\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "yahoo_both_onlytop_onlyrand_neither", "[", "2", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"} & \\multicolumn{1}{c|}{\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "yahoo_both_onlytop_onlyrand_neither", "[", "3", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"}                         &  & \\multicolumn{1}{r|}{No} & \\multicolumn{1}{c|}{\\cellcolor[HTML]{F8A102}\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "imdb_both_onlytop_onlyrand_neither", "[", "2", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"} & \\multicolumn{1}{c|}{\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "imdb_both_onlytop_onlyrand_neither", "[", "3", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"}                         \\\\ \\cline{3-4} \\cline{7-8} \n                                          &                           & \\multicolumn{1}{l}{}                           & \\multicolumn{1}{l}{}                           &  &                           & \\multicolumn{1}{l}{}                           & \\multicolumn{1}{l}{}                           \\\\\n                                          &                           & \\multicolumn{2}{c}{Amazon}                                                                      &  &                           & \\multicolumn{2}{c}{Yelp}                                                                        \\\\\n                                          &                           & Yes                                           & No                                           &  &                           & Yes                                           & No                                           \\\\ \\cline{3-4} \\cline{7-8} \n                                          & \\multicolumn{1}{r|}{Yes} & \\multicolumn{1}{c|}{\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "amazon_both_onlytop_onlyrand_neither", "[", "0", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"}                         & \\multicolumn{1}{c|}{\\cellcolor[HTML]{DAE8FC}\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "amazon_both_onlytop_onlyrand_neither", "[", "1", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"} &  & \\multicolumn{1}{r|}{Yes} & \\multicolumn{1}{c|}{\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "yelp_both_onlytop_onlyrand_neither", "[", "0", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"}                         & \\multicolumn{1}{c|}{\\cellcolor[HTML]{DAE8FC}\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "yelp_both_onlytop_onlyrand_neither", "[", "1", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"} \\\\ \\cline{3-4} \\cline{7-8} \n\\multirow{-9}{*}{\\rotatebox[origin=c]{90}{\\textbf{\"\"\"", "\n", "str_to_ret", "+=", "vertical_text", "\n", "str_to_ret", "+=", "r\"\"\"}}} & \\multicolumn{1}{r|}{No} & \\multicolumn{1}{c|}{\\cellcolor[HTML]{F8A102}\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "amazon_both_onlytop_onlyrand_neither", "[", "2", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"} & \\multicolumn{1}{c|}{\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "amazon_both_onlytop_onlyrand_neither", "[", "3", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"}                         &  & \\multicolumn{1}{r|}{No} & \\multicolumn{1}{c|}{\\cellcolor[HTML]{F8A102}\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "yelp_both_onlytop_onlyrand_neither", "[", "2", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"} & \\multicolumn{1}{c|}{\"\"\"", "\n", "str_to_ret", "+=", "get_rounded_string_of_num", "(", "yelp_both_onlytop_onlyrand_neither", "[", "3", "]", ")", "\n", "str_to_ret", "+=", "r\"\"\"}                         \\\\ \\cline{3-4} \\cline{7-8} \n\\label{\"\"\"", "\n", "str_to_ret", "+=", "tex_label", "\n", "str_to_ret", "+=", "r\"\"\"}\n\\end{tabular}\n}\"\"\"", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str_to_ret", "+", "'\\n'", ")", "\n", "", "print", "(", "\"Wrote \"", "+", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals": [[170, 175], ["table_maker.get_2x2_decflip_jointdist"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_2x2_decflip_jointdist"], ["", "def", "get_vsrand_2x2_decflip_jointdist_as_returned_vals", "(", "table", ",", "nonrand_column", ",", "corresponding_rand_column", ")", ":", "\n", "    ", "table", "=", "table", "[", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", "]", "# get rid of seqs of length 1 for this", "\n", "rand_flipped_decision", "=", "(", "table", "[", ":", ",", "corresponding_rand_column", "]", "!=", "-", "1", ")", "\n", "top_flipped_decision", "=", "(", "table", "[", ":", ",", "nonrand_column", "]", "!=", "-", "1", ")", "\n", "return", "get_2x2_decflip_jointdist", "(", "rand_flipped_decision", ",", "top_flipped_decision", ",", "table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_2x2_decflip_jointdist": [[177, 188], ["numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not"], "function", ["None"], ["", "def", "get_2x2_decflip_jointdist", "(", "vs_flipped_decision", ",", "top_flipped_decision", ",", "table", ")", ":", "\n", "    ", "both_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "vs_flipped_decision", ",", "top_flipped_decision", ")", ")", "\n", "neither_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "vs_flipped_decision", ")", ",", "\n", "np", ".", "logical_not", "(", "top_flipped_decision", ")", ")", ")", "\n", "only_top_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "vs_flipped_decision", ")", ",", "\n", "top_flipped_decision", ")", ")", "\n", "only_rand_flipped", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "vs_flipped_decision", ",", "\n", "np", ".", "logical_not", "(", "top_flipped_decision", ")", ")", ")", "\n", "assert", "both_flipped", "+", "neither_flipped", "+", "only_top_flipped", "+", "only_rand_flipped", "==", "table", ".", "shape", "[", "0", "]", "\n", "return", "[", "both_flipped", "/", "table", ".", "shape", "[", "0", "]", ",", "only_top_flipped", "/", "table", ".", "shape", "[", "0", "]", ",", "\n", "only_rand_flipped", "/", "table", ".", "shape", "[", "0", "]", ",", "neither_flipped", "/", "table", ".", "shape", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_single_table": [[190, 207], ["table_attribute_name.endswith", "table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals", "table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals", "table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals", "table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals", "table_maker.generate_table_tex_file", "model_name.lower", "globals", "globals", "globals", "globals", "model_name.lower", "table_attribute_name.rfind", "model_name.lower"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.get_vsrand_2x2_decflip_jointdist_as_returned_vals", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.generate_table_tex_file"], ["", "def", "make_single_table", "(", "i_star_col", ",", "rand_col", ",", "vertical_label", ",", "filename_suffix", ",", "model_name", ")", ":", "\n", "    ", "table_attribute_name", "=", "model_name", ".", "lower", "(", ")", "[", ":", "-", "1", "]", "\n", "if", "table_attribute_name", ".", "endswith", "(", "'noenc'", ")", ":", "\n", "        ", "table_attribute_name", "=", "table_attribute_name", "[", ":", "table_attribute_name", ".", "rfind", "(", "'noenc'", ")", "]", "+", "'encless'", "\n", "", "filename", "=", "tex_files_dir", "+", "'decflip_rand_'", "+", "filename_suffix", "+", "'_sub_'", "+", "model_name", ".", "lower", "(", ")", "[", ":", "-", "1", "]", "+", "'.tex'", "\n", "yahoo_table", "=", "globals", "(", ")", "[", "'yahoo_'", "+", "table_attribute_name", "+", "'_table'", "]", "\n", "yahoo_vals", "=", "get_vsrand_2x2_decflip_jointdist_as_returned_vals", "(", "yahoo_table", ",", "i_star_col", ",", "rand_col", ")", "\n", "imdb_table", "=", "globals", "(", ")", "[", "'imdb_'", "+", "table_attribute_name", "+", "'_table'", "]", "\n", "imdb_vals", "=", "get_vsrand_2x2_decflip_jointdist_as_returned_vals", "(", "imdb_table", ",", "i_star_col", ",", "rand_col", ")", "\n", "amazon_table", "=", "globals", "(", ")", "[", "'amazon_'", "+", "table_attribute_name", "+", "'_table'", "]", "\n", "amazon_vals", "=", "get_vsrand_2x2_decflip_jointdist_as_returned_vals", "(", "amazon_table", ",", "i_star_col", ",", "rand_col", ")", "\n", "yelp_table", "=", "globals", "(", ")", "[", "'yelp_'", "+", "table_attribute_name", "+", "'_table'", "]", "\n", "yelp_vals", "=", "get_vsrand_2x2_decflip_jointdist_as_returned_vals", "(", "yelp_table", ",", "i_star_col", ",", "rand_col", ")", "\n", "generate_table_tex_file", "(", "model_name", ",", "yahoo_vals", ",", "imdb_vals", ",", "\n", "amazon_vals", ",", "yelp_vals", ",", "\n", "vertical_label", ",", "\n", "model_name", ".", "lower", "(", ")", "[", ":", "-", "1", "]", "+", "'-rand-decflip-table-'", "+", "filename_suffix", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_set_of_six_tables": [[209, 216], ["table_maker.make_single_table", "table_maker.make_single_table", "table_maker.make_single_table", "table_maker.make_single_table", "table_maker.make_single_table", "table_maker.make_single_table", "process_test_outputs.DEC_FLIP_ZERO_HIGHEST", "process_test_outputs.NONTOP_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "process_test_outputs.DEC_FLIP_ZERO_HIGHESTGRAD", "process_test_outputs.NONTOPBYGRAD_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", "process_test_outputs.DEC_FLIP_ZERO_HIGHESTGRADMULT", "process_test_outputs.NONTOPBYGRADMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_single_table", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_single_table", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_single_table", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_single_table", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_single_table", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_single_table"], ["", "def", "make_set_of_six_tables", "(", "i_star_col", ",", "rand_col", ",", "vertical_label", ",", "filename_suffix", ")", ":", "\n", "    ", "make_single_table", "(", "i_star_col", ",", "rand_col", ",", "vertical_label", ",", "filename_suffix", ",", "'HANrnns'", ")", "\n", "make_single_table", "(", "i_star_col", ",", "rand_col", ",", "vertical_label", ",", "filename_suffix", ",", "'HANconvs'", ")", "\n", "make_single_table", "(", "i_star_col", ",", "rand_col", ",", "vertical_label", ",", "filename_suffix", ",", "'HANnoencs'", ")", "\n", "make_single_table", "(", "i_star_col", ",", "rand_col", ",", "vertical_label", ",", "filename_suffix", ",", "'FLANrnns'", ")", "\n", "make_single_table", "(", "i_star_col", ",", "rand_col", ",", "vertical_label", ",", "filename_suffix", ",", "'FLANconvs'", ")", "\n", "make_single_table", "(", "i_star_col", ",", "rand_col", ",", "vertical_label", ",", "filename_suffix", ",", "'FLANnoencs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_tables": [[218, 225], ["table_maker.make_set_of_six_tables", "table_maker.make_set_of_six_tables", "table_maker.make_set_of_six_tables"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_set_of_six_tables", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_set_of_six_tables", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.table_maker.make_set_of_six_tables"], ["", "def", "make_tables", "(", ")", ":", "\n", "    ", "make_set_of_six_tables", "(", "DEC_FLIP_ZERO_HIGHEST", ",", "NONTOP_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "\n", "r'Remove $i^\\ast$: Decision flip?'", ",", "'attn'", ")", "\n", "make_set_of_six_tables", "(", "DEC_FLIP_ZERO_HIGHESTGRAD", ",", "NONTOPBYGRAD_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "\n", "r'Remove $i^\\ast_g$: Decision flip?'", ",", "'grad'", ")", "\n", "make_set_of_six_tables", "(", "DEC_FLIP_ZERO_HIGHESTGRADMULT", ",", "NONTOPBYGRADMULT_RAND_CAUSED_DECFLIP_IF_NOT_NEGONE", ",", "\n", "r'Remove $i^\\ast_p$: Decision flip?'", ",", "'gradmult'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.get_filenames_for_subdir": [[49, 63], ["base_output_dir.endswith", "mid_dir.endswith"], "function", ["None"], ["", "def", "get_filenames_for_subdir", "(", "mid_dir", ")", ":", "\n", "    ", "global", "base_output_dir", "\n", "if", "not", "base_output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "base_output_dir", "+=", "'/'", "\n", "", "if", "not", "mid_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "mid_dir", "+=", "'/'", "\n", "", "return", "base_output_dir", "+", "mid_dir", "+", "first_v_second_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "rand_results_fname", ",", "base_output_dir", "+", "mid_dir", "+", "unchanged_fname", ",", "base_output_dir", "+", "mid_dir", "+", "grad_based_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontop_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "attn_div_from_unif_fname", ",", "base_output_dir", "+", "mid_dir", "+", "gradsignmult_based_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygrad_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygradmult_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygradsignmult_stats_fname", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_2x2_2boxplot_set": [[115, 119], ["None"], "function", ["None"], ["", "", "def", "make_2x2_2boxplot_set", "(", "list1_of_two_vallists_to_boxplot", ",", "list2_of_two_vallists_to_boxplot", ",", "\n", "list3_of_two_vallists_to_boxplot", ",", "list4_of_two_vallists_to_boxplot", ",", "list_of_colorlabels", ",", "\n", "list_of_two_color_tuples", ",", "labels_for_4_boxplot_sets", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_4_4boxplot_set": [[121, 125], ["None"], "function", ["None"], ["", "def", "make_4_4boxplot_set", "(", "list1_of_four_vallists_to_boxplot", ",", "list2_of_four_vallists_to_boxplot", ",", "\n", "list3_of_four_vallists_to_boxplot", ",", "list4_of_four_vallists_to_boxplot", ",", "list_of_colorlabels", ",", "\n", "list_of_four_color_tuples", ",", "labels_for_4_boxplot_sets", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_kdeplot": [[127, 150], ["range", "pandas.DataFrame", "matplotlib.figure", "sns.FacetGrid", "sns.FacetGrid.map", "sns.FacetGrid.set_titles", "matplotlib.savefig", "matplotlib.close", "len", "len", "len", "range", "len", "len", "len", "list_of_row_dicts.append"], "function", ["None"], ["", "def", "make_kdeplot", "(", "tuples_of_title_x_y", ",", "filename", ")", ":", "\n", "    ", "subplot_title", "=", "'Dataset'", "\n", "x_title", "=", "\"Difference in Attention Weight Magnitudes\"", "\n", "y_title", "=", "\"Log Difference in Corresponding JS Divergences\\nfrom Original Output\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "assert", "len", "(", "tuples_of_title_x_y", "[", "1", "]", ")", "==", "len", "(", "tuples_of_title_x_y", "[", "2", "]", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "tuples_of_title_x_y", ")", ")", ":", "\n", "        ", "dataset_tup", "=", "tuples_of_title_x_y", "[", "j", "]", "\n", "assert", "len", "(", "dataset_tup", "[", "1", "]", ")", "==", "len", "(", "dataset_tup", "[", "2", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset_tup", "[", "1", "]", ")", ")", ":", "\n", "            ", "list_of_row_dicts", ".", "append", "(", "{", "subplot_title", ":", "dataset_tup", "[", "0", "]", ",", "x_title", ":", "dataset_tup", "[", "1", "]", "[", "i", "]", ",", "\n", "y_title", ":", "dataset_tup", "[", "2", "]", "[", "i", "]", "}", ")", "\n", "", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "g", "=", "sns", ".", "FacetGrid", "(", "data_to_plot", ",", "col", "=", "subplot_title", ",", "hue", "=", "None", ",", "col_wrap", "=", "2", ")", "\n", "g", ".", "map", "(", "sns", ".", "kdeplot", ",", "x_title", ",", "y_title", ",", "cmap", "=", "\"Blues\"", ",", "shade", "=", "True", ",", "shade_lowest", "=", "False", ")", "\n", "g", ".", "set_titles", "(", "\"{col_name}\"", ")", "\n", "#ax = sns.kdeplot(getattr(all_rows, x_title), getattr(all_rows, y_title),", "\n", "#                 cmap = \"Blues\", shade = True, shade_lowest = False,", "\n", "#                 )", "\n", "#ax.set_title(\"Differences in Attention weight \")", "\n", "plt", ".", "savefig", "(", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_2x2_vsrand_decflip_violinplot": [[152, 169], ["sorted", "pandas.DataFrame", "sns.catplot", "matplotlib.savefig", "range", "len", "len", "len", "len", "sorted.append", "str"], "function", ["None"], ["", "def", "make_2x2_vsrand_decflip_violinplot", "(", "tuples_of_title_x_y_noneflipped", ",", "filename", ")", ":", "\n", "    ", "x_label", "=", "\"Difference in (average) zeroed attention\\nweight magnitude\"", "\n", "y_label", "=", "\"Difference in decision flip indicators\\ncompared to original output\"", "\n", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "for", "tup", "in", "tuples_of_title_x_y_noneflipped", ":", "\n", "        ", "dataset_title", "=", "tup", "[", "0", "]", "\n", "assert", "len", "(", "tup", "[", "1", "]", ")", "==", "len", "(", "tup", "[", "2", "]", ")", "\n", "assert", "len", "(", "tup", "[", "1", "]", ")", "==", "tup", "[", "3", "]", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tup", "[", "2", "]", ")", ")", ":", "\n", "            ", "list_of_row_dicts", ".", "append", "(", "{", "title_of_each_graph", ":", "dataset_title", ",", "x_label", ":", "tup", "[", "1", "]", "[", "i", "]", ",", "y_label", ":", "str", "(", "tup", "[", "2", "]", "[", "i", "]", ")", ",", "\n", "\"No Flips Occurred\"", ":", "(", "\"True\"", "if", "tup", "[", "3", "]", "[", "i", "]", "else", "\"False\"", ")", "}", ")", "\n", "", "", "list_of_row_dicts", "=", "sorted", "(", "list_of_row_dicts", ",", "key", "=", "(", "lambda", "x", ":", "1", "if", "x", "[", "\"No Flips Occurred\"", "]", "==", "\"True\"", "else", "0", ")", ")", "\n", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "g", "=", "sns", ".", "catplot", "(", "kind", "=", "'violin'", ",", "x", "=", "x_label", ",", "y", "=", "y_label", ",", "col", "=", "title_of_each_graph", ",", "hue", "=", "\"No Flips Occurred\"", ",", "palette", "=", "None", ",", "\n", "data", "=", "data_to_plot", ",", "col_wrap", "=", "2", ",", "legend", "=", "True", ",", "split", "=", "True", ",", "inner", "=", "None", ",", "orient", "=", "\"h\"", ")", "\n", "plt", ".", "savefig", "(", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_2x2_vsrand_decflip_stackplot": [[171, 316], ["math.ceil", "range", "pandas.DataFrame", "sns.FacetGrid", "matplotlib.subplots", "range", "matplotlib.savefig", "matplotlib.close", "len", "numpy.array", "numpy.array", "range", "range", "range", "print", "len", "len", "axs[].set_title", "numpy.concatenate", "numpy.concatenate", "axs[].stackplot", "numpy.sum", "numpy.sum", "str", "numpy.logical_and", "range", "numpy.sum", "range", "numpy.array", "numpy.all", "len", "len", "len", "len", "list_of_row_dicts.append", "len", "str", "numpy.sum", "numpy.sum", "numpy.sum", "str", "numpy.sum", "numpy.sum", "str", "numpy.sum", "numpy.sum", "list_of_binleft_countdist.append", "list_of_inds_in_need_of_interpolation.append", "str", "numpy.reshape", "range", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "str", "str", "len", "list_of_binleft_countdist.append", "len", "range", "numpy.sum", "len", "numpy.array", "len", "range", "numpy.all", "numpy.sum", "str", "len", "str", "range", "numpy.sum"], "function", ["None"], ["", "def", "make_2x2_vsrand_decflip_stackplot", "(", "tuples_of_title_x_y_noneflipped", ",", "filename", ",", "bin_size", ",", "vs_avg", "=", "True", ")", ":", "\n", "    ", "if", "vs_avg", ":", "\n", "        ", "x_label", "=", "\"Difference in (average) zeroed attention\\nweight magnitude\"", "\n", "", "else", ":", "\n", "        ", "x_label", "=", "\"Difference in zeroed attention\\nweight magnitude\"", "\n", "", "if", "vs_avg", ":", "\n", "        ", "y_label", "=", "[", "\"Highest didn't flip, 5/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 4/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 3/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 2/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 1/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 0/5 others flipped\"", ",", "\n", "\"Highest flipped, 5/5 others flipped\"", ",", "\n", "\"Highest flipped, 4/5 others flipped\"", ",", "\n", "\"Highest flipped, 3/5 others flipped\"", ",", "\n", "\"Highest flipped, 2/5 others flipped\"", ",", "\n", "\"Highest flipped, 1/5 others flipped\"", ",", "\n", "\"Highest flipped, 0/5 others flipped\"", "]", "\n", "", "else", ":", "\n", "        ", "y_label", "=", "[", "\"Highest didn't flip, 2nd highest flipped\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"Neither flipped\"", ",", "\n", "\"Both flipped\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"Highest flipped, 2nd highest didn't flip\"", "]", "\n", "", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "how_many_bins", "=", "ceil", "(", "1.0", "/", "bin_size", ")", "\n", "for", "dataset_ind", "in", "range", "(", "len", "(", "tuples_of_title_x_y_noneflipped", ")", ")", ":", "\n", "        ", "title", "=", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "[", "0", "]", "\n", "x", "=", "np", ".", "array", "(", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "[", "1", "]", ")", "\n", "y", "=", "np", ".", "array", "(", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "[", "2", "]", ")", "\n", "noneflipped", "=", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "[", "3", "]", "\n", "assert", "np", ".", "sum", "(", "y", "[", "noneflipped", "]", "==", "0", ")", "==", "np", ".", "sum", "(", "noneflipped", ")", ",", "str", "(", "y", "[", "noneflipped", "]", ")", "+", "', '", "+", "str", "(", "title", ")", "\n", "list_of_binleft_countdist", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "how_many_bins", ")", ":", "\n", "            ", "bin_left_edge", "=", "i", "*", "bin_size", "\n", "bin_right_edge", "=", "bin_left_edge", "+", "bin_size", "\n", "mask", "=", "np", ".", "logical_and", "(", "x", ">=", "bin_left_edge", ",", "x", "<", "bin_right_edge", ")", "\n", "available_y", "=", "y", "[", "mask", "]", "\n", "available_nonflipped", "=", "noneflipped", "[", "mask", "]", "\n", "list_of_counts", "=", "[", "0", "for", "j", "in", "range", "(", "12", ")", "]", "\n", "for", "j", "in", "range", "(", "5", ")", ":", "\n", "                ", "left_edge", "=", "-", "1.1", "+", ".2", "*", "j", "\n", "right_edge", "=", "left_edge", "+", ".2", "\n", "list_of_counts", "[", "j", "]", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "available_y", ">", "left_edge", ",", "\n", "available_y", "<", "right_edge", ")", ")", "\n", "", "list_of_counts", "[", "5", "]", "=", "np", ".", "sum", "(", "available_nonflipped", ")", "\n", "list_of_counts", "[", "6", "]", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "available_y", ">", "-", ".1", ",", "available_y", "<", ".1", ")", ")", "-", "list_of_counts", "[", "5", "]", "\n", "for", "j", "in", "range", "(", "5", ")", ":", "\n", "                ", "left_edge", "=", ".1", "+", ".2", "*", "j", "\n", "right_edge", "=", "left_edge", "+", ".2", "\n", "list_of_counts", "[", "7", "+", "j", "]", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "available_y", ">", "left_edge", ",", "\n", "available_y", "<", "right_edge", ")", ")", "\n", "", "np_arr_for_bin", "=", "np", ".", "array", "(", "list_of_counts", ")", "\n", "assert", "np", ".", "all", "(", "np_arr_for_bin", ">=", "0", ")", ",", "str", "(", "np_arr_for_bin", ")", "+", "', '", "+", "str", "(", "title", ")", "\n", "assert", "np", ".", "sum", "(", "mask", ")", "==", "np", ".", "sum", "(", "np_arr_for_bin", ")", ",", "str", "(", "np", ".", "sum", "(", "mask", ")", ")", "+", "\", \"", "+", "str", "(", "np_arr_for_bin", ")", "\n", "if", "np", ".", "sum", "(", "np_arr_for_bin", ")", "!=", "0", ":", "\n", "                ", "denom", "=", "np", ".", "sum", "(", "np_arr_for_bin", ")", "\n", "list_of_binleft_countdist", ".", "append", "(", "(", "bin_left_edge", ",", "np_arr_for_bin", "/", "denom", ")", ")", "\n", "", "elif", "len", "(", "list_of_binleft_countdist", ")", ">", "0", ":", "\n", "                ", "list_of_binleft_countdist", ".", "append", "(", "(", "bin_left_edge", ",", "None", ")", ")", "\n", "", "", "while", "list_of_binleft_countdist", "[", "-", "1", "]", "[", "1", "]", "is", "None", ":", "\n", "            ", "list_of_binleft_countdist", "=", "list_of_binleft_countdist", "[", ":", "-", "1", "]", "\n", "\n", "# now go through and interpolate for any remaining Nones in the middle", "\n", "", "list_of_inds_in_need_of_interpolation", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_binleft_countdist", ")", ")", ":", "\n", "            ", "if", "list_of_binleft_countdist", "[", "i", "]", "[", "1", "]", "is", "not", "None", ":", "\n", "                ", "if", "len", "(", "list_of_inds_in_need_of_interpolation", ")", ">", "0", ":", "\n", "# interpolate", "\n", "                    ", "endpoint_on_right", "=", "list_of_binleft_countdist", "[", "i", "]", "[", "1", "]", "\n", "step_sizes", "=", "[", "(", "endpoint_on_right", "[", "k", "]", "-", "most_recent_nonnone_on_left", "[", "k", "]", ")", "/", "\n", "(", "len", "(", "list_of_inds_in_need_of_interpolation", ")", "+", "1", ")", "for", "k", "in", "range", "(", "12", ")", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "list_of_inds_in_need_of_interpolation", ")", ")", ":", "\n", "                        ", "ind", "=", "list_of_inds_in_need_of_interpolation", "[", "j", "]", "\n", "new_array", "=", "np", ".", "array", "(", "[", "most_recent_nonnone_on_left", "[", "k", "]", "+", "step_sizes", "[", "k", "]", "*", "(", "j", "+", "1", ")", "\n", "for", "k", "in", "range", "(", "12", ")", "]", ")", "\n", "assert", "np", ".", "all", "(", "new_array", ")", ">=", "0", "\n", "assert", ".99", "<", "np", ".", "sum", "(", "new_array", ")", "<", "1.01", ",", "str", "(", "np", ".", "sum", "(", "new_array", ")", ")", "+", "', '", "+", "str", "(", "new_array", ")", "\n", "list_of_binleft_countdist", "[", "ind", "]", "=", "(", "list_of_binleft_countdist", "[", "ind", "]", "[", "0", "]", ",", "new_array", ")", "\n", "", "list_of_inds_in_need_of_interpolation", "=", "[", "]", "\n", "", "else", ":", "\n", "                    ", "most_recent_nonnone_on_left", "=", "list_of_binleft_countdist", "[", "i", "]", "[", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "list_of_inds_in_need_of_interpolation", ".", "append", "(", "i", ")", "\n", "\n", "", "", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "=", "[", "title", ",", "[", "tup", "[", "0", "]", "for", "tup", "in", "list_of_binleft_countdist", "]", ",", "\n", "[", "tup", "[", "1", "]", "for", "tup", "in", "list_of_binleft_countdist", "]", "]", "\n", "\n", "# each entry of tuples_of_title_x_y_noneflipped now in format title, list_of_bin_edges, list_of_corr_dists", "\n", "\n", "\n", "\n", "\n", "", "for", "tup", "in", "tuples_of_title_x_y_noneflipped", ":", "\n", "        ", "dataset_title", "=", "tup", "[", "0", "]", "\n", "assert", "len", "(", "tup", "[", "1", "]", ")", "==", "len", "(", "tup", "[", "2", "]", ")", "\n", "avg_pct_noflip", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "tup", "[", "1", "]", ")", ")", ":", "\n", "            ", "avg_pct_noflip", "+=", "tup", "[", "2", "]", "[", "i", "]", "[", "5", "]", "\n", "list_of_row_dicts", ".", "append", "(", "{", "title_of_each_graph", ":", "dataset_title", ",", "x_label", ":", "tup", "[", "1", "]", "[", "i", "]", ",", "\n", "y_label", "[", "0", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "0", "]", ",", "y_label", "[", "1", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "1", "]", ",", "\n", "y_label", "[", "2", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "2", "]", ",", "y_label", "[", "3", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "3", "]", ",", "\n", "y_label", "[", "4", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "4", "]", ",", "y_label", "[", "5", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "5", "]", ",", "\n", "y_label", "[", "6", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "6", "]", ",", "y_label", "[", "7", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "7", "]", ",", "\n", "y_label", "[", "8", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "8", "]", ",", "y_label", "[", "9", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "9", "]", ",", "\n", "y_label", "[", "10", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "10", "]", ",", "y_label", "[", "11", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "11", "]", "}", ")", "\n", "", "print", "(", "\"Avg pct no-flip: \"", "+", "str", "(", "avg_pct_noflip", "/", "len", "(", "tup", "[", "1", "]", ")", ")", ")", "\n", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "g", "=", "sns", ".", "FacetGrid", "(", "data_to_plot", ",", "col", "=", "title_of_each_graph", ",", "hue", "=", "None", ",", "col_wrap", "=", "2", ")", "\n", "#g = g.map(plt.stackplot, x_label, y_label[0], y_label[1], y_label[2], y_label[3], y_label[4], y_label[5],", "\n", "#          y_label[6], y_label[7], y_label[8], y_label[9], y_label[10], y_label[11], labels=y_label, colors=None)", "\n", "#g = g.set_titles(\"{col_name}\")", "\n", "data_to_plot", "=", "data_to_plot", "[", "data_to_plot", "[", "title_of_each_graph", "]", "==", "'Yahoo'", "]", "\n", "\n", "if", "len", "(", "tuples_of_title_x_y_noneflipped", ")", "==", "1", ":", "\n", "        ", "subplot_args", "=", "[", "111", "]", "\n", "", "elif", "len", "(", "tuples_of_title_x_y_noneflipped", ")", "==", "2", ":", "\n", "        ", "subplot_args", "=", "[", "121", ",", "122", "]", "\n", "", "else", ":", "\n", "        ", "subplot_args", "=", "[", "221", ",", "222", ",", "223", ",", "224", "]", "\n", "", "subplot_args", "=", "[", "221", ",", "222", ",", "223", ",", "224", "]", "\n", "\n", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "2", ",", "2", ",", "constrained_layout", "=", "True", ",", "figsize", "=", "(", "12", ",", "9", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "tuples_of_title_x_y_noneflipped", ")", ")", ":", "\n", "\n", "        ", "axs", "[", "i", "//", "2", ",", "i", "%", "2", "]", ".", "set_title", "(", "\"Dataset = \"", "+", "tuples_of_title_x_y_noneflipped", "[", "i", "]", "[", "0", "]", ")", "\n", "sample_data", "=", "tuples_of_title_x_y_noneflipped", "[", "i", "]", "\n", "ys", "=", "np", ".", "concatenate", "(", "[", "np", ".", "reshape", "(", "arr", ",", "(", "12", ",", "1", ")", ")", "for", "arr", "in", "sample_data", "[", "2", "]", "]", ",", "axis", "=", "1", ")", "\n", "ys", "=", "np", ".", "concatenate", "(", "[", "ys", "[", ":", "5", "]", ",", "ys", "[", "6", ":", "]", "]", ",", "axis", "=", "0", ")", "\n", "axs", "[", "i", "//", "2", ",", "i", "%", "2", "]", ".", "stackplot", "(", "sample_data", "[", "1", "]", ",", "ys", ",", "labels", "=", "y_label", ",", "colors", "=", "[", "'#F8A102'", ",", "'#FF9900'", ",", "'#FFB60D'", ",", "'#FFD5A6'", ",", "\n", "'#FFF1E0'", ",", "'#D6D6D6'", ",", "'#E0F6FC'", ",", "'#B3EBFC'", ",", "\n", "'#90CDFC'", ",", "'#3AAEFC'", ",", "'#85B7FF'", "]", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_fracremoved_boxplots": [[318, 357], ["pandas.DataFrame", "matplotlib.figure", "sns.boxplot", "sns.boxplot.set_title", "sns.boxplot.legend_.remove", "sns.despine", "matplotlib.savefig", "matplotlib.close", "range", "matplotlib.legend", "matplotlib.legend", "len", "list_of_row_dicts.append"], "function", ["None"], ["", "def", "make_fracremoved_boxplots", "(", "filename", ",", "list_of_ordering_names", ",", "dataset_orderingfracdistribs", ",", "model", ",", "\n", "y_axis_title", "=", "\"Fraction of Original Attention\\nWeights Removed\"", ")", ":", "\n", "    ", "if", "\"Fraction\"", "in", "y_axis_title", ":", "\n", "        ", "plot_title", "=", "\"Fractions of Original Attended Items Removed Before First Decision \"", "+", "\"Flip Occurred: \"", "+", "model", "\n", "palette", "=", "{", "\"Random\"", ":", "\"#2589CC\"", ",", "\"Attention\"", ":", "\"#80D4FF\"", ",", "\"Gradient\"", ":", "\"#D4F3FF\"", "}", "\n", "", "else", ":", "\n", "        ", "plot_title", "=", "\"Probability Masses of Original Attention Distributions Removed Before First Decision \"", "+", "\"Flip Occurred: \"", "+", "model", "\n", "palette", "=", "{", "\"Random\"", ":", "\"#A970FF\"", ",", "\"Attention\"", ":", "\"#EEA8FF\"", ",", "\"Gradient\"", ":", "\"#FFE0FF\"", "}", "\n", "", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "for", "tup", "in", "dataset_orderingfracdistribs", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "list_of_ordering_names", ")", ")", ":", "\n", "            ", "ordering_name", "=", "list_of_ordering_names", "[", "i", "]", "\n", "tup_ordering_list", "=", "tup", "[", "i", "+", "1", "]", "\n", "for", "data_point", "in", "tup_ordering_list", ":", "\n", "                ", "row_dict", "=", "{", "title_of_each_graph", ":", "tup", "[", "0", "]", ",", "\n", "\"AllTheSameInCol\"", ":", "\"filler\"", ",", "\n", "\"Ranking Scheme\"", ":", "ordering_name", ",", "\n", "y_axis_title", ":", "data_point", "}", "\n", "list_of_row_dicts", ".", "append", "(", "row_dict", ")", "\n", "", "", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "2", ")", ")", "\n", "\n", "ax", "=", "sns", ".", "boxplot", "(", "x", "=", "title_of_each_graph", ",", "y", "=", "y_axis_title", ",", "\n", "hue", "=", "\"Ranking Scheme\"", ",", "palette", "=", "palette", ",", "\n", "data", "=", "data_to_plot", ")", "\n", "ax", ".", "set_title", "(", "plot_title", ")", "\n", "ax", ".", "legend_", ".", "remove", "(", ")", "\n", "sns", ".", "despine", "(", "offset", "=", "20", ",", "trim", "=", "True", ")", "\n", "\n", "if", "'conv'", "not", "in", "model", ":", "\n", "        ", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ",", "prop", "=", "{", "'size'", ":", "10", "}", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ",", "prop", "=", "{", "'size'", ":", "10", "}", ")", "\n", "", "plt", ".", "savefig", "(", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_hists": [[359, 383], ["pandas.DataFrame", "matplotlib.figure", "sns.FacetGrid", "sns.FacetGrid.map", "matplotlib.savefig", "matplotlib.close", "range", "list_of_row_dicts.append", "print", "print"], "function", ["None"], ["", "def", "make_hists", "(", "filename", ",", "dataset_xval_tups", ",", "\n", "y_axis_title", "=", "\"Fraction of Original Attention\\nWeights Removed\"", ")", ":", "\n", "    ", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "for", "tup", "in", "dataset_xval_tups", ":", "\n", "        ", "x_vals", "=", "tup", "[", "1", "]", "\n", "try", ":", "\n", "            ", "for", "i", "in", "range", "(", "x_vals", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "row_dict", "=", "{", "title_of_each_graph", ":", "tup", "[", "0", "]", ",", "\n", "\"AllTheSameInCol\"", ":", "\"filler\"", ",", "\n", "\"Difference in Attention Weights\"", ":", "x_vals", "[", "i", "]", "}", "\n", "list_of_row_dicts", ".", "append", "(", "row_dict", ")", "\n", "", "", "except", ":", "\n", "            ", "print", "(", "x_vals", ")", "\n", "print", "(", "x_vals", ".", "shape", ")", "\n", "", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "\n", "g", "=", "sns", ".", "FacetGrid", "(", "data_to_plot", ",", "col", "=", "title_of_each_graph", ",", "sharey", "=", "False", ",", "col_wrap", "=", "2", ")", "\n", "g", ".", "map", "(", "sns", ".", "distplot", ",", "\"Difference in Attention Weights\"", ",", "kde", "=", "False", ",", "rug", "=", "False", ")", "\n", "\n", "plt", ".", "savefig", "(", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_2x2_regression_set": [[385, 414], ["pandas.DataFrame", "sns.lmplot", "print", "matplotlib.savefig", "range", "len", "len", "len", "list_of_row_dicts.append", "print"], "function", ["None"], ["", "def", "make_2x2_regression_set", "(", "tuples_of_title_x_y", ",", "filename", ",", "y_label", "=", "\"Log difference in JS divergences\\n\"", "+", "\n", "\"from original output distribution\"", ",", "vs_avg", "=", "True", ")", ":", "\n", "    ", "if", "vs_avg", ":", "\n", "        ", "x_label", "=", "\"Difference in (average) zeroed attention\\nweight magnitude\"", "\n", "", "else", ":", "\n", "        ", "x_label", "=", "\"Difference in zeroed attention weight magnitude\"", "\n", "", "if", "not", "vs_avg", ":", "\n", "        ", "y_label", "=", "\"Log difference in JS divergences from\\noriginal output distribution\"", "\n", "", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "if", "y_label", "==", "\"Differences in JS divergences\"", ":", "\n", "        ", "pass", "\n", "", "for", "tup", "in", "tuples_of_title_x_y", ":", "\n", "        ", "assert", "len", "(", "tup", "[", "1", "]", ")", "==", "len", "(", "tup", "[", "2", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "tup", "[", "1", "]", ")", ")", ":", "\n", "            ", "if", "True", "or", "\"flip\"", "in", "y_label", "or", "tup", "[", "2", "]", "[", "i", "]", "<", "2.5", ":", "\n", "                ", "list_of_row_dicts", ".", "append", "(", "{", "title_of_each_graph", ":", "tup", "[", "0", "]", ",", "x_label", ":", "tup", "[", "1", "]", "[", "i", "]", ",", "y_label", ":", "tup", "[", "2", "]", "[", "i", "]", ",", "\n", "\"AllTheSameInCol\"", ":", "\"filler\"", "}", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Excluding a data point for \"", "+", "y_label", ")", "\n", "", "", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "marker_format_dict", "=", "{", "'alpha'", ":", "0.15", ",", "'s'", ":", "2", "}", "\n", "if", "'flip'", "in", "y_label", ":", "\n", "        ", "marker_format_dict", "[", "\"s\"", "]", "=", "10", "\n", "", "g", "=", "sns", ".", "lmplot", "(", "x", "=", "x_label", ",", "y", "=", "y_label", ",", "col", "=", "title_of_each_graph", ",", "hue", "=", "\"AllTheSameInCol\"", ",", "palette", "=", "None", ",", "\n", "data", "=", "data_to_plot", ",", "col_wrap", "=", "2", ",", "legend", "=", "False", ",", "\n", "scatter_kws", "=", "marker_format_dict", ",", "sharey", "=", "False", ",", "sharex", "=", "False", ")", "\n", "print", "(", "\"Saving file to \"", "+", "filename", ")", "\n", "plt", ".", "savefig", "(", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.test_plots": [[416, 428], ["tuples_of_title_x_y.append", "tuples_of_title_x_y.append", "tuples_of_title_x_y.append", "tuples_of_title_x_y.append", "figure_maker_single_dataset.make_2x2_regression_set", "figure_maker_single_dataset.make_2x2_regression_set", "os.path.isdir", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set"], ["", "def", "test_plots", "(", ")", ":", "\n", "    ", "tuples_of_title_x_y", "=", "[", "]", "\n", "tuples_of_title_x_y", ".", "append", "(", "(", "\"Amazon\"", ",", "[", "0", ",", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", "]", ",", "[", ".1", ",", ".3", ",", ".5", ",", ".2", ",", ".4", ",", ".7", "]", ")", ")", "\n", "tuples_of_title_x_y", ".", "append", "(", "(", "\"Yelp\"", ",", "[", "0", ",", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", "]", ",", "[", ".1", ",", ".3", ",", ".5", ",", ".2", ",", ".4", ",", ".7", "]", ")", ")", "\n", "tuples_of_title_x_y", ".", "append", "(", "(", "\"Yahoo\"", ",", "[", "0", ",", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", "]", ",", "[", ".1", ",", ".3", ",", ".5", ",", ".2", ",", ".4", ",", ".7", "]", ")", ")", "\n", "tuples_of_title_x_y", ".", "append", "(", "(", "\"IMDB\"", ",", "[", "0", ",", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", "]", ",", "[", ".1", ",", ".3", ",", ".5", ",", ".2", ",", ".4", ",", ".7", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "\"testimagedir/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "\"testimagedir/\"", ")", "\n", "", "filename", "=", "\"testimagedir/regression\"", "\n", "make_2x2_regression_set", "(", "tuples_of_title_x_y", ",", "filename", ")", "\n", "filename", "=", "\"testimagedir/regression2\"", "\n", "make_2x2_regression_set", "(", "tuples_of_title_x_y", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.dec_table_size_to_keep_x_pct_of_data": [[430, 439], ["range", "numpy.array", "random.random", "rand_ind_list.append", "rand_ind_list.append"], "function", ["None"], ["", "def", "dec_table_size_to_keep_x_pct_of_data", "(", "x", ",", "table", ")", ":", "\n", "    ", "rand_ind_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "table", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "random", "(", ")", "<", "x", ":", "\n", "            ", "rand_ind_list", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "rand_ind_list", ".", "append", "(", "0", ")", "\n", "", "", "np_ind_mask", "=", "np", ".", "array", "(", "rand_ind_list", ",", "dtype", "=", "bool", ")", "\n", "return", "table", "[", "np_ind_mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_boxplots": [[441, 477], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker_single_dataset.dec_table_size_to_keep_x_pct_of_data", "figure_maker_single_dataset.make_fracremoved_boxplots", "dataset_tag.endswith", "model_tag.startswith", "len", "dataset_tag.startswith", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_fracremoved_boxplots"], ["", "def", "make_boxplots", "(", "model_tag", ",", "dataset_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "dataset_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "dataset_tag", "+=", "'/'", "\n", "", "if", "len", "(", "dataset_tag", ")", ">", "1", "and", "(", "not", "dataset_tag", ".", "startswith", "(", "'-'", ")", ")", ":", "\n", "        ", "dataset_tag", "=", "'-'", "+", "dataset_tag", "\n", "", "print", "(", "\"Starting to make fraction-removed boxplot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "model_name", "=", "'HANconv'", "+", "hanconv_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "'HANrnn'", "+", "hanrnn_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconv'", "+", "flanconv_tag", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanrnn_table", "\n", "model_name", "=", "'FLANrnn'", "+", "flanrnn_tag", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "list_of_ordering_names", "=", "[", "\"Random\"", ",", "\"Attention\"", ",", "\"Gradient\"", "]", "\n", "dataset_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "dataset_table", ")", "\n", "dataset_model_tup", "=", "(", "dataset_name", ",", "\n", "dataset_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "dataset_name", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "dataset_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "dataset_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "dataset_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "dataset_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ")", "\n", "make_fracremoved_boxplots", "(", "model_tag", "+", "\"_fracremoved_boxplots\"", ",", "list_of_ordering_names", ",", "\n", "[", "dataset_model_tup", "]", ",", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_probmass_boxplots": [[479, 516], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker_single_dataset.dec_table_size_to_keep_x_pct_of_data", "figure_maker_single_dataset.make_fracremoved_boxplots", "dataset_tag.endswith", "model_tag.startswith", "len", "dataset_tag.startswith", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_fracremoved_boxplots"], ["", "def", "make_probmass_boxplots", "(", "model_tag", ",", "dataset_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "dataset_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "dataset_tag", "+=", "'/'", "\n", "", "if", "len", "(", "dataset_tag", ")", ">", "1", "and", "(", "not", "dataset_tag", ".", "startswith", "(", "'-'", ")", ")", ":", "\n", "        ", "dataset_tag", "=", "'-'", "+", "dataset_tag", "\n", "", "print", "(", "\"Starting to make probmass-removed boxplot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "model_name", "=", "'HANconv'", "+", "hanconv_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "'HANrnn'", "+", "hanrnn_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconv'", "+", "flanconv_tag", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanrnn_table", "\n", "model_name", "=", "'FLANrnn'", "+", "flanrnn_tag", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "list_of_ordering_names", "=", "[", "\"Random\"", ",", "\"Attention\"", ",", "\"Gradient\"", "]", "\n", "dataset_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "dataset_table", ")", "\n", "dataset_model_tup", "=", "(", "dataset_name", ",", "\n", "dataset_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "[", "dataset_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "dataset_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "[", "dataset_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "dataset_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "[", "dataset_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ")", "\n", "make_fracremoved_boxplots", "(", "model_tag", "+", "\"_probmassremoved_boxplots\"", ",", "list_of_ordering_names", ",", "\n", "[", "dataset_model_tup", "]", ",", "model_name", ",", "\n", "y_axis_title", "=", "\"Probability Mass of Original\\nAttention Dist Removed\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_decflip_regression_plot": [[518, 554], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker_single_dataset.make_rand_decflip_model_tup", "figure_maker_single_dataset.make_2x2_vsrand_decflip_stackplot", "print", "model_tag.startswith", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_vsrand_decflip_stackplot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_decflip_regression_plot", "(", "model_tag", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "print", "(", "\"Starting to make decflip regression plot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "model_name", "=", "'HANconv'", "+", "hanconv_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "'HANrnn'", "+", "hanrnn_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconv'", "+", "flanconv_tag", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanrnn_table", "\n", "model_name", "=", "'FLANrnn'", "+", "flanrnn_tag", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "if", "is_han", ":", "\n", "        ", "dataset_mask", "=", "dataset_han_mask", "\n", "", "else", ":", "\n", "        ", "dataset_mask", "=", "dataset_flan_mask", "\n", "", "dataset_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "dataset_name", "+", "'-'", "+", "model_tag", ")", "[", "dataset_mask", "]", "\n", "dataset_model_tup", "=", "make_rand_decflip_model_tup", "(", "dataset_highestattnweights", ",", "dataset_table", ",", "dataset_name", ")", "\n", "\n", "#make_2x2_vsrand_decflip_violinplot([yahoo_hanrnn_tup, imdb_hanrnn_tup], \"differences_in_decflips_\" + model)", "\n", "make_2x2_vsrand_decflip_stackplot", "(", "[", "dataset_model_tup", "]", ",", "\n", "\"differences_in_decflips_\"", "+", "model", ",", ".05", ")", "\n", "print", "(", "\"Finished making a decision flip plot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_decflip_regression_plot_vs2ndhighest": [[556, 601], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker_single_dataset.make_vs2nd_decflip_model_tup", "figure_maker_single_dataset.make_2x2_vsrand_decflip_stackplot", "print", "dataset_tag.endswith", "model_tag.startswith", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "len", "dataset_tag.startswith", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_vsrand_decflip_stackplot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_decflip_regression_plot_vs2ndhighest", "(", "model_tag", ",", "dataset_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "dataset_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "dataset_tag", "+=", "'/'", "\n", "", "if", "len", "(", "dataset_tag", ")", ">", "1", "and", "(", "not", "dataset_tag", ".", "startswith", "(", "'-'", ")", ")", ":", "\n", "        ", "dataset_tag", "=", "'-'", "+", "dataset_tag", "\n", "", "print", "(", "\"Starting to make decflip plot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "model_name", "=", "'HANconv'", "+", "hanconv_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "'HANrnn'", "+", "hanrnn_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconv'", "+", "flanconv_tag", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanrnn_table", "\n", "model_name", "=", "'FLANrnn'", "+", "flanrnn_tag", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "if", "is_han", ":", "\n", "        ", "dataset_mask", "=", "dataset_han_mask", "\n", "", "else", ":", "\n", "        ", "dataset_mask", "=", "dataset_flan_mask", "\n", "", "dataset_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "dataset_name", "+", "'-'", "+", "model_tag", "+", "\n", "dataset_tag", ")", "[", "dataset_mask", "]", "\n", "dataset_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "dataset_name", "+", "'-'", "+", "model_tag", "+", "\n", "dataset_tag", ")", "[", "dataset_mask", "]", "\n", "dataset_model_tup", "=", "make_vs2nd_decflip_model_tup", "(", "dataset_highestattnweights", ",", "dataset_2ndhighestattnweights", ",", "dataset_table", ",", "\n", "dataset_name", ")", "\n", "\n", "#make_2x2_vsrand_decflip_violinplot([yahoo_hanrnn_tup, imdb_hanrnn_tup], \"differences_in_decflips_\" + model)", "\n", "make_2x2_vsrand_decflip_stackplot", "(", "[", "dataset_model_tup", "]", ",", "\"differences_in_decflips_vs2nd_\"", "+", "model", ",", ".05", ",", "\n", "vs_avg", "=", "False", ")", "\n", "print", "(", "\"Finished making a decision flip plot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_vs2nd_decflip_model_tup": [[603, 624], ["range", "list", "list", "numpy.logical_and", "len", "range", "modified_list_1.append", "modified_list_2.append", "numpy.array", "random.random", "len", "len"], "function", ["None"], ["", "def", "make_vs2nd_decflip_model_tup", "(", "highestattnweights", ",", "secondhighestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "secondhighestattnweights", ")", ",", "\n", "list", "(", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "!=", "-", "1", ")", ".", "astype", "(", "float", ")", "-", "\n", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", "!=", "-", "1", ")", ".", "astype", "(", "float", ")", ")", ",", "\n", "np", ".", "logical_and", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "==", "-", "1", ",", "\n", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", "==", "-", "1", ")", "\n", ")", "\n", "return", "model_tup", "\n", "num_points_to_plot", "=", "500", "\n", "inds_to_pick", "=", "[", "(", "True", "if", "random", "(", ")", "<", "num_points_to_plot", "/", "len", "(", "model_tup", "[", "1", "]", ")", "else", "False", ")", "for", "\n", "i", "in", "range", "(", "len", "(", "model_tup", "[", "1", "]", ")", ")", "]", "\n", "modified_list_1", "=", "[", "]", "\n", "modified_list_2", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inds_to_pick", ")", ")", ":", "\n", "        ", "if", "inds_to_pick", "[", "i", "]", ":", "\n", "            ", "modified_list_1", ".", "append", "(", "model_tup", "[", "1", "]", "[", "i", "]", ")", "\n", "modified_list_2", ".", "append", "(", "model_tup", "[", "2", "]", "[", "i", "]", ")", "\n", "", "", "modified_arr_3", "=", "model_tup", "[", "3", "]", "[", "np", ".", "array", "(", "inds_to_pick", ",", "dtype", "=", "bool", ")", "]", "\n", "return", "(", "model_tup", "[", "0", "]", ",", "modified_list_1", ",", "modified_list_2", ",", "modified_arr_3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_rand_decflip_model_tup": [[626, 655], ["numpy.logical_not().astype", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "list", "list", "numpy.logical_and", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "numpy.divide", "numpy.divide", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.multiply", "numpy.multiply"], "function", ["None"], ["", "def", "make_rand_decflip_model_tup", "(", "highestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "sampled_weights_that_were_max", "=", "(", "highestattnweights", "[", ":", ",", "None", "]", "==", "\n", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ")", "\n", "sampled_weights_that_werent_max", "=", "np", ".", "logical_not", "(", "sampled_weights_that_were_max", ")", ".", "astype", "(", "float", ")", "\n", "assert", "np", ".", "sum", "(", "sampled_weights_that_werent_max", ">", "1", ")", "==", "0", "\n", "num_sampled_weights_that_were_max", "=", "np", ".", "sum", "(", "sampled_weights_that_were_max", ",", "axis", "=", "1", ")", "\n", "all_sampled_weights_are_max", "=", "(", "num_sampled_weights_that_were_max", "==", "\n", "(", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "-", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ")", ")", "\n", "table", "=", "table", "[", "np", ".", "logical_not", "(", "all_sampled_weights_are_max", ")", "]", "\n", "highestattnweights", "=", "highestattnweights", "[", "np", ".", "logical_not", "(", "all_sampled_weights_are_max", ")", "]", "\n", "denom_array", "=", "np", ".", "sum", "(", "sampled_weights_that_werent_max", ",", "axis", "=", "1", ")", "\n", "assert", "np", ".", "sum", "(", "denom_array", "<", "0", ")", "==", "0", "\n", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "np", ".", "divide", "(", "(", "np", ".", "sum", "(", "np", ".", "multiply", "(", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ",", "\n", "sampled_weights_that_werent_max", ")", ",", "axis", "=", "1", ")", ")", ",", "\n", "denom_array", ")", ")", ",", "\n", "list", "(", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "!=", "-", "1", ")", ".", "astype", "(", "float", ")", "-", "\n", "np", ".", "divide", "(", "np", ".", "sum", "(", "np", ".", "multiply", "(", "table", "[", ":", ",", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", ":", "\n", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", "+", "1", "]", "==", "1", ",", "\n", "sampled_weights_that_werent_max", ")", ",", "axis", "=", "1", ")", ",", "\n", "denom_array", ")", ")", ",", "\n", "np", ".", "logical_and", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "==", "-", "1", ",", "\n", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", ":", "\n", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", "+", "1", "]", "==", "1", ",", "axis", "=", "1", ")", "==", "0", ")", ")", "\n", ")", "\n", "return", "model_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_vs2nd_jsdiv_model_tup": [[657, 673], ["range", "list", "list", "len", "range", "modified_list_1.append", "modified_list_2.append", "table[].astype", "table[].astype", "random.random", "len", "len"], "function", ["None"], ["", "def", "make_vs2nd_jsdiv_model_tup", "(", "highestattnweights", ",", "secondhighestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "secondhighestattnweights", ")", ",", "\n", "list", "(", "(", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", ")", ".", "astype", "(", "float", ")", "-", "\n", "(", "table", "[", ":", ",", "JS_DIV_ZERO_2NDHIGHEST", "]", ")", ".", "astype", "(", "float", ")", ")", ")", "\n", "num_points_to_plot", "=", "500", "\n", "inds_to_pick", "=", "[", "(", "True", "if", "random", "(", ")", "<", "num_points_to_plot", "/", "len", "(", "model_tup", "[", "1", "]", ")", "else", "False", ")", "for", "\n", "i", "in", "range", "(", "len", "(", "model_tup", "[", "1", "]", ")", ")", "]", "\n", "modified_list_1", "=", "[", "]", "\n", "modified_list_2", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inds_to_pick", ")", ")", ":", "\n", "        ", "if", "inds_to_pick", "[", "i", "]", ":", "\n", "            ", "modified_list_1", ".", "append", "(", "model_tup", "[", "1", "]", "[", "i", "]", ")", "\n", "modified_list_2", ".", "append", "(", "model_tup", "[", "2", "]", "[", "i", "]", ")", "\n", "", "", "return", "(", "model_tup", "[", "0", "]", ",", "modified_list_1", ",", "modified_list_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_rand_jsdiv_model_tup": [[675, 682], ["list", "list"], "function", ["None"], ["", "def", "make_rand_jsdiv_model_tup", "(", "highestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "table", "[", ":", ",", "NONTOP_RAND_ZEROED_WEIGHT", "]", ")", ",", "\n", "list", "(", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", "-", "\n", "table", "[", ":", ",", "NONTOP_RAND_JS_DIV", "]", ")", ")", "\n", "return", "model_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_rand_jsdiv_model_tup_sample5": [[684, 708], ["numpy.logical_not().astype", "numpy.sum", "list", "list", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "numpy.divide", "numpy.log", "numpy.divide", "numpy.sum", "numpy.sum", "numpy.multiply", "numpy.multiply", "numpy.log"], "function", ["None"], ["", "def", "make_rand_jsdiv_model_tup_sample5", "(", "highestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "sampled_weights_that_were_max", "=", "(", "highestattnweights", "[", ":", ",", "None", "]", "==", "\n", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ")", "\n", "sampled_weights_that_werent_max", "=", "np", ".", "logical_not", "(", "sampled_weights_that_were_max", ")", ".", "astype", "(", "float", ")", "\n", "num_sampled_weights_that_were_max", "=", "np", ".", "sum", "(", "sampled_weights_that_were_max", ",", "axis", "=", "1", ")", "\n", "all_sampled_weights_are_max", "=", "(", "num_sampled_weights_that_were_max", "==", "\n", "(", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "-", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ")", ")", "\n", "table", "=", "table", "[", "np", ".", "logical_not", "(", "all_sampled_weights_are_max", ")", "]", "\n", "highestattnweights", "=", "highestattnweights", "[", "np", ".", "logical_not", "(", "all_sampled_weights_are_max", ")", "]", "\n", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "np", ".", "divide", "(", "(", "np", ".", "sum", "(", "np", ".", "multiply", "(", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ",", "\n", "sampled_weights_that_werent_max", ")", ",", "axis", "=", "1", ")", ")", ",", "\n", "(", "-", "1", "*", "num_sampled_weights_that_were_max", "+", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "-", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ")", ")", ")", ",", "\n", "list", "(", "np", ".", "log", "(", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", ")", "-", "\n", "np", ".", "divide", "(", "np", ".", "sum", "(", "np", ".", "multiply", "(", "np", ".", "log", "(", "table", "[", ":", ",", "EXTRACTED_SINGLE_WEIGHT_JS_START", ":", "\n", "EXTRACTED_SINGLE_WEIGHT_JS_END", "+", "1", "]", ")", ",", "\n", "sampled_weights_that_werent_max", ")", ",", "axis", "=", "1", ")", ",", "\n", "(", "-", "1", "*", "num_sampled_weights_that_were_max", "+", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "-", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ")", ")", ")", ")", "\n", "return", "model_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_jsdiv_regression_plot": [[710, 762], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker_single_dataset.make_rand_jsdiv_model_tup", "figure_maker_single_dataset.convert_to_log_and_print_how_many_were_originally_negative", "figure_maker_single_dataset.sample_x_datapoints_per_tenth_on_xaxis", "figure_maker_single_dataset.make_hists", "figure_maker_single_dataset.make_2x2_regression_set", "print", "dataset_tag.endswith", "model_tag.startswith", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "len", "dataset_tag.startswith", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_hists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_jsdiv_regression_plot", "(", "model_tag", ",", "sample_x", ",", "dataset_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "dataset_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "dataset_tag", "+=", "'/'", "\n", "", "if", "len", "(", "dataset_tag", ")", ">", "1", "and", "(", "not", "dataset_tag", ".", "startswith", "(", "'-'", ")", ")", ":", "\n", "        ", "dataset_tag", "=", "'-'", "+", "dataset_tag", "\n", "", "print", "(", "\"Starting to make jsdiv regression plot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "model_name", "=", "'HANconv'", "+", "hanconv_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "'HANrnn'", "+", "hanrnn_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconv'", "+", "flanconv_tag", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanrnn_table", "\n", "model_name", "=", "'FLANrnn'", "+", "flanrnn_tag", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "if", "is_han", ":", "\n", "        ", "dataset_mask", "=", "dataset_han_mask", "\n", "", "else", ":", "\n", "        ", "dataset_mask", "=", "dataset_flan_mask", "\n", "", "dataset_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "dataset_name", "+", "'-'", "+", "model_tag", "+", "\n", "dataset_tag", ")", "[", "dataset_mask", "]", "\n", "dataset_model_tup", "=", "make_rand_jsdiv_model_tup", "(", "dataset_highestattnweights", ",", "dataset_table", ",", "dataset_name", ")", "\n", "\n", "dataset_model_tup", ",", "dataset_neg_x", "=", "convert_to_log_and_print_how_many_were_originally_negative", "(", "dataset_model_tup", ",", "\n", "dataset_tag", ")", "\n", "dataset_model_tup", "=", "sample_x_datapoints_per_tenth_on_xaxis", "(", "dataset_model_tup", ",", "sample_x", ")", "\n", "\n", "\"\"\"yahoo_model_tup = wonkysample_so_xs_are_roughly_uniform_at_random(yahoo_model_tup, sample_x)\n    imdb_model_tup = wonkysample_so_xs_are_roughly_uniform_at_random(imdb_model_tup, sample_x)\n    amazon_model_tup = wonkysample_so_xs_are_roughly_uniform_at_random(amazon_model_tup, sample_x)\n    yelp_model_tup = wonkysample_so_xs_are_roughly_uniform_at_random(yelp_model_tup, sample_x)\"\"\"", "\n", "\n", "#make_kdeplot([yahoo_model_tup, imdb_model_tup, amazon_model_tup, yelp_model_tup], \"differences_in_jsdivs_kde_\" + model)", "\n", "make_hists", "(", "\"neg_jsdivdiff_xvals_\"", "+", "model", ",", "[", "(", "dataset_name", ",", "dataset_neg_x", ")", "]", ")", "\n", "\n", "make_2x2_regression_set", "(", "[", "dataset_model_tup", "]", ",", "\n", "\"differences_in_jsdivs_\"", "+", "model", ",", "vs_avg", "=", "False", ")", "\n", "print", "(", "\"Finished making a JS div plot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.convert_to_log_and_print_how_many_were_originally_negative": [[764, 781], ["isinstance", "print", "numpy.log", "numpy.array", "numpy.min", "numpy.array", "list", "len", "len", "str", "str", "numpy.sum", "str", "numpy.sum"], "function", ["None"], ["", "def", "convert_to_log_and_print_how_many_were_originally_negative", "(", "js_model_tup", ",", "model_label_to_print_with_report", ")", ":", "\n", "    ", "convert_to_log", "=", "js_model_tup", "[", "2", "]", "\n", "if", "isinstance", "(", "convert_to_log", ",", "list", ")", ":", "\n", "        ", "convert_to_log", "=", "np", ".", "array", "(", "convert_to_log", ")", "\n", "change_back_to_list", "=", "True", "\n", "", "else", ":", "\n", "        ", "change_back_to_list", "=", "False", "\n", "", "subtract_before_logging", "=", "np", ".", "min", "(", "convert_to_log", ")", "-", ".01", "\n", "x_vals_going_with_ys", "=", "np", ".", "array", "(", "js_model_tup", "[", "1", "]", ")", "[", "convert_to_log", "<", "0", "]", "\n", "assert", "len", "(", "x_vals_going_with_ys", ".", "shape", ")", ">", "0", "and", "x_vals_going_with_ys", ".", "shape", "[", "0", "]", ">", "0", ",", "x_vals_going_with_ys", "\n", "print", "(", "js_model_tup", "[", "0", "]", "+", "\" \"", "+", "model_label_to_print_with_report", "+", "\": \"", "+", "str", "(", "np", ".", "sum", "(", "convert_to_log", "<", "0", ")", ")", "+", "\n", "\" out of \"", "+", "str", "(", "convert_to_log", ".", "shape", "[", "0", "]", ")", "+", "\" (\"", "+", "str", "(", "np", ".", "sum", "(", "convert_to_log", "<", "0", ")", "/", "convert_to_log", ".", "shape", "[", "0", "]", ")", "+", "\") JSdivdiffs were negative\"", ")", "\n", "new_y_vals", "=", "np", ".", "log", "(", "convert_to_log", "-", "subtract_before_logging", ")", "\n", "if", "change_back_to_list", ":", "\n", "        ", "new_y_vals", "=", "list", "(", "new_y_vals", ")", "\n", "", "assert", "len", "(", "js_model_tup", ")", "==", "3", "\n", "return", "[", "js_model_tup", "[", "0", "]", ",", "js_model_tup", "[", "1", "]", ",", "new_y_vals", "]", ",", "x_vals_going_with_ys", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.wonkysample_so_xs_are_roughly_uniform_at_random": [[783, 801], ["isinstance", "numpy.min", "numpy.max", "numpy.argsort", "range", "figure_maker_single_dataset.make_histogram_of_x_vals", "exit", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_histogram_of_x_vals"], ["", "def", "wonkysample_so_xs_are_roughly_uniform_at_random", "(", "js_model_tup", ",", "sample_x", ")", ":", "\n", "    ", "xs", "=", "js_model_tup", "[", "1", "]", "\n", "if", "isinstance", "(", "xs", ",", "list", ")", ":", "\n", "        ", "xs", "=", "np", ".", "array", "(", "xs", ")", "\n", "change_back_to_list", "=", "True", "\n", "", "else", ":", "\n", "        ", "change_back_to_list", "=", "False", "\n", "", "lower_bound", "=", "np", ".", "min", "(", "xs", ")", "\n", "upper_bound", "=", "np", ".", "max", "(", "xs", ")", "\n", "inds_lowest_to_highest", "=", "np", ".", "argsort", "(", "xs", ")", "\n", "for", "j", "in", "range", "(", "inds_lowest_to_highest", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "inds_lowest_to_highest", "[", "j", "]", "==", "0", ":", "\n", "            ", "ind_to_check", "=", "j", "\n", "break", "\n", "", "", "xs", "=", "xs", "[", "inds_lowest_to_highest", "]", "\n", "corr_ys", "=", "np", ".", "array", "(", "js_model_tup", "[", "2", "]", ")", "[", "inds_lowest_to_highest", "]", "\n", "make_histogram_of_x_vals", "(", "xs", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_histogram_of_x_vals": [[803, 810], ["matplotlib.figure", "sns.distplot", "matplotlib.savefig", "matplotlib.close"], "function", ["None"], ["", "def", "make_histogram_of_x_vals", "(", "x_vals", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "2", ")", ")", "\n", "\n", "ax", "=", "sns", ".", "distplot", "(", "x_vals", ",", "kde", "=", "False", ",", "rug", "=", "True", ")", "\n", "\n", "plt", ".", "savefig", "(", "'test_hist'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.subsample_so_xs_are_roughly_uniform_at_random": [[813, 870], ["isinstance", "numpy.min", "numpy.max", "numpy.argsort", "numpy.random.uniform", "numpy.sort", "numpy.array", "range", "numpy.array", "numpy.array", "list", "list", "stack_of_unchosen_val_inds.insert", "len", "len"], "function", ["None"], ["", "def", "subsample_so_xs_are_roughly_uniform_at_random", "(", "js_model_tup", ",", "sample_x", ")", ":", "\n", "    ", "xs", "=", "js_model_tup", "[", "1", "]", "\n", "if", "isinstance", "(", "xs", ",", "list", ")", ":", "\n", "        ", "xs", "=", "np", ".", "array", "(", "xs", ")", "\n", "change_back_to_list", "=", "True", "\n", "", "else", ":", "\n", "        ", "change_back_to_list", "=", "False", "\n", "", "lower_bound", "=", "np", ".", "min", "(", "xs", ")", "\n", "upper_bound", "=", "np", ".", "max", "(", "xs", ")", "\n", "inds_lowest_to_highest", "=", "np", ".", "argsort", "(", "xs", ")", "\n", "xs", "=", "xs", "[", "inds_lowest_to_highest", "]", "\n", "corr_ys", "=", "np", ".", "array", "(", "js_model_tup", "[", "2", "]", ")", "[", "inds_lowest_to_highest", "]", "\n", "pseudo_xs", "=", "np", ".", "random", ".", "uniform", "(", "lower_bound", ",", "upper_bound", ",", "size", "=", "(", "sample_x", ",", ")", ")", "\n", "np", ".", "sort", "(", "pseudo_xs", ")", "\n", "# now go through and greedily mark all values as we find vals that are closest to each pseudo_x", "\n", "bool_arr", "=", "np", ".", "array", "(", "[", "0", "]", "*", "xs", ".", "shape", "[", "0", "]", ",", "dtype", "=", "bool", ")", "\n", "stack_of_unchosen_val_inds", "=", "[", "0", "]", "\n", "next_full_arr_ind_to_right", "=", "1", "\n", "for", "ind", "in", "range", "(", "pseudo_xs", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "quit", "=", "False", "\n", "figured_out_what_to_do_with_ind", "=", "False", "\n", "while", "not", "figured_out_what_to_do_with_ind", ":", "\n", "            ", "if", "pseudo_xs", "[", "ind", "]", ">", "xs", "[", "next_full_arr_ind_to_right", "]", ":", "\n", "                ", "stack_of_unchosen_val_inds", ".", "insert", "(", "0", ",", "next_full_arr_ind_to_right", ")", "\n", "next_full_arr_ind_to_right", "+=", "1", "\n", "", "elif", "xs", "[", "next_full_arr_ind_to_right", "]", "==", "pseudo_xs", "[", "ind", "]", ":", "\n", "                ", "figured_out_what_to_do_with_ind", "=", "True", "\n", "bool_arr", "[", "next_full_arr_ind_to_right", "]", "=", "True", "\n", "next_full_arr_ind_to_right", "+=", "1", "\n", "", "else", ":", "\n", "                ", "figured_out_what_to_do_with_ind", "=", "True", "\n", "# the ind actually does appear on the right, so now's the time to choose what we pull", "\n", "if", "len", "(", "stack_of_unchosen_val_inds", ")", "==", "0", ":", "\n", "                    ", "bool_arr", "[", "next_full_arr_ind_to_right", "]", "=", "True", "\n", "next_full_arr_ind_to_right", "+=", "1", "\n", "", "else", ":", "\n", "# we have two choices. pick the closer one.", "\n", "                    ", "if", "pseudo_xs", "[", "ind", "]", "-", "xs", "[", "stack_of_unchosen_val_inds", "[", "0", "]", "]", "<", "xs", "[", "next_full_arr_ind_to_right", "]", "-", "pseudo_xs", "[", "ind", "]", ":", "\n", "# closer to previous val", "\n", "                        ", "bool_arr", "[", "stack_of_unchosen_val_inds", "[", "0", "]", "]", "=", "True", "\n", "del", "stack_of_unchosen_val_inds", "[", "0", "]", "\n", "", "else", ":", "\n", "                        ", "bool_arr", "[", "next_full_arr_ind_to_right", "]", "=", "True", "\n", "next_full_arr_ind_to_right", "+=", "1", "\n", "", "", "", "if", "next_full_arr_ind_to_right", ">=", "xs", ".", "shape", "[", "0", "]", ":", "\n", "                ", "quit", "=", "True", "\n", "if", "len", "(", "stack_of_unchosen_val_inds", ")", ">", "0", ":", "\n", "                    ", "bool_arr", "[", "stack_of_unchosen_val_inds", "[", "0", "]", "]", "=", "True", "\n", "", "figured_out_what_to_do_with_ind", "=", "True", "\n", "", "", "if", "quit", ":", "\n", "            ", "break", "\n", "", "", "new_x_vals", "=", "xs", "[", "bool_arr", "]", "\n", "new_y_vals", "=", "corr_ys", "[", "bool_arr", "]", "\n", "if", "change_back_to_list", ":", "\n", "        ", "return", "[", "js_model_tup", "[", "0", "]", ",", "list", "(", "new_x_vals", ")", ",", "list", "(", "new_y_vals", ")", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "js_model_tup", "[", "0", "]", ",", "new_x_vals", ",", "new_y_vals", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.sample_x_datapoints_per_tenth_on_xaxis": [[872, 904], ["isinstance", "range", "range", "print", "range", "numpy.array", "len", "lists_of_lists_being_built.append", "numpy.logical_and", "numpy.array", "range", "len", "isinstance", "numpy.nonzero", "len", "isinstance", "list", "new_model_tup.append", "new_model_tup.append", "numpy.array", "str", "numpy.array", "numpy.random.choice", "len"], "function", ["None"], ["", "", "def", "sample_x_datapoints_per_tenth_on_xaxis", "(", "model_tup", ",", "x", ")", ":", "\n", "    ", "x_axis_vals", "=", "model_tup", "[", "1", "]", "\n", "if", "isinstance", "(", "x_axis_vals", ",", "list", ")", ":", "\n", "        ", "x_axis_vals", "=", "np", ".", "array", "(", "x_axis_vals", ")", "\n", "", "lists_of_lists_being_built", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "model_tup", ")", ")", ":", "\n", "        ", "lists_of_lists_being_built", ".", "append", "(", "[", "]", ")", "\n", "", "num_bins", "=", "200", "\n", "for", "i", "in", "range", "(", "num_bins", ")", ":", "\n", "        ", "left_val_inclusive", "=", "i", "/", "num_bins", "\n", "right_val_exclusive", "=", "left_val_inclusive", "+", "(", "1.0", "/", "num_bins", ")", "\n", "true_where_is_option", "=", "np", ".", "logical_and", "(", "x_axis_vals", ">=", "left_val_inclusive", ",", "x_axis_vals", "<", "right_val_exclusive", ")", "\n", "possible_inds", "=", "np", ".", "nonzero", "(", "true_where_is_option", ")", "[", "0", "]", "\n", "mask_to_take", "=", "np", ".", "array", "(", "[", "0", "]", "*", "true_where_is_option", ".", "shape", "[", "0", "]", ",", "dtype", "=", "bool", ")", "\n", "if", "possible_inds", ".", "shape", "[", "0", "]", "<", "x", ":", "\n", "            ", "mask_to_take", "[", "possible_inds", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "mask_to_take", "[", "np", ".", "random", ".", "choice", "(", "possible_inds", ",", "size", "=", "x", ")", "]", "=", "1", "\n", "", "for", "j", "in", "range", "(", "1", ",", "len", "(", "model_tup", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "model_tup", "[", "j", "]", ",", "list", ")", ":", "\n", "                ", "arr_to_sample", "=", "np", ".", "array", "(", "model_tup", "[", "j", "]", ")", "\n", "", "else", ":", "\n", "                ", "arr_to_sample", "=", "model_tup", "[", "j", "]", "\n", "", "lists_of_lists_being_built", "[", "j", "-", "1", "]", "+=", "list", "(", "arr_to_sample", "[", "mask_to_take", "]", ")", "\n", "", "", "print", "(", "\"Pulled \"", "+", "str", "(", "len", "(", "lists_of_lists_being_built", "[", "0", "]", ")", ")", "+", "\" datapoints\"", ")", "\n", "new_model_tup", "=", "[", "model_tup", "[", "0", "]", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "model_tup", ")", ")", ":", "\n", "        ", "if", "isinstance", "(", "model_tup", "[", "i", "]", ",", "list", ")", ":", "\n", "            ", "new_model_tup", ".", "append", "(", "lists_of_lists_being_built", "[", "i", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "new_model_tup", ".", "append", "(", "np", ".", "array", "(", "lists_of_lists_being_built", "[", "i", "-", "1", "]", ")", ")", "\n", "", "", "return", "new_model_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.ask_where_to_split_attndiff_plots": [[906, 969], ["numpy.array", "range", "input", "print", "input", "input.startswith", "input", "len", "float", "str", "float", "isinstance", "new_low_tuple.append", "new_high_tuple.append", "isinstance", "new_low_tuple.append", "new_high_tuple.append", "list", "range", "numpy.array", "numpy.sum", "len", "list.append", "new_low_list.append", "list.append", "new_high_list.append", "new_low_list.append", "new_high_list.append", "numpy.logical_not"], "function", ["None"], ["", "def", "ask_where_to_split_attndiff_plots", "(", "model_tup", ")", ":", "\n", "    ", "np_set_of_attndiffs", "=", "np", ".", "array", "(", "model_tup", "[", "1", "]", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "val", "=", "input", "(", "\"Find pct of diffs that fall above: \"", ")", "\n", "try", ":", "\n", "            ", "val", "=", "float", "(", "val", ")", "\n", "", "except", ":", "\n", "            ", "continue", "\n", "", "print", "(", "str", "(", "np", ".", "sum", "(", "np_set_of_attndiffs", ">", "val", ")", "/", "np_set_of_attndiffs", ".", "shape", "[", "0", "]", ")", ")", "\n", "keep_going", "=", "input", "(", "\"Keep exploring? (y/n) \"", ")", "\n", "if", "keep_going", ".", "startswith", "(", "'n'", ")", ":", "\n", "            ", "done", "=", "True", "\n", "break", "\n", "", "", "have_splitting_val", "=", "False", "\n", "while", "not", "have_splitting_val", ":", "\n", "        ", "val", "=", "input", "(", "\"Splitting val? \"", ")", "\n", "try", ":", "\n", "            ", "val", "=", "float", "(", "val", ")", "\n", "have_splitting_val", "=", "True", "\n", "", "except", ":", "\n", "            ", "continue", "\n", "# now go through and create two different model_tups, one of values that fall above and other of vals", "\n", "# that fall below", "\n", "", "", "new_low_tuple", "=", "[", "model_tup", "[", "0", "]", "]", "\n", "new_high_tuple", "=", "[", "model_tup", "[", "0", "]", "]", "\n", "for", "component_ind", "in", "range", "(", "1", ",", "len", "(", "model_tup", ")", ")", ":", "\n", "        ", "comp", "=", "model_tup", "[", "component_ind", "]", "\n", "if", "component_ind", "==", "1", ":", "\n", "            ", "if", "isinstance", "(", "comp", ",", "list", ")", ":", "\n", "                ", "val_included_in_low_key", "=", "[", "]", "\n", "new_low_list", "=", "[", "]", "\n", "new_high_list", "=", "[", "]", "\n", "for", "item", "in", "comp", ":", "\n", "                    ", "if", "item", "<=", "val", ":", "\n", "                        ", "val_included_in_low_key", ".", "append", "(", "True", ")", "\n", "new_low_list", ".", "append", "(", "item", ")", "\n", "", "else", ":", "\n", "                        ", "val_included_in_low_key", ".", "append", "(", "False", ")", "\n", "new_high_list", ".", "append", "(", "item", ")", "\n", "", "", "", "else", ":", "# assume it's a numpy array", "\n", "                ", "val_included_in_low_key", "=", "list", "(", "comp", "<=", "val", ")", "\n", "new_low_list", "=", "comp", "[", "comp", "<=", "val", "]", "\n", "new_high_list", "=", "comp", "[", "comp", ">", "val", "]", "\n", "", "new_low_tuple", ".", "append", "(", "new_low_list", ")", "\n", "new_high_tuple", ".", "append", "(", "new_high_list", ")", "\n", "", "else", ":", "# assume it's a numpy array", "\n", "            ", "if", "isinstance", "(", "comp", ",", "list", ")", ":", "\n", "                ", "new_low_list", "=", "[", "]", "\n", "new_high_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "val_included_in_low_key", ")", ")", ":", "\n", "                    ", "key", "=", "val_included_in_low_key", "[", "i", "]", "\n", "if", "key", ":", "\n", "                        ", "new_low_list", ".", "append", "(", "comp", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                        ", "new_high_list", ".", "append", "(", "comp", "[", "i", "]", ")", "\n", "", "", "", "else", ":", "\n", "                ", "np_mask", "=", "np", ".", "array", "(", "val_included_in_low_key", ",", "dtype", "=", "bool", ")", "\n", "new_low_list", "=", "comp", "[", "np_mask", "]", "\n", "new_high_list", "=", "comp", "[", "np", ".", "logical_not", "(", "np_mask", ")", "]", "\n", "", "new_low_tuple", ".", "append", "(", "new_low_list", ")", "\n", "new_high_tuple", ".", "append", "(", "new_high_list", ")", "\n", "", "", "return", "new_low_tuple", ",", "new_high_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.make_jsdiv_regression_plot_vs2ndhighest": [[971, 1009], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker_single_dataset.make_vs2nd_jsdiv_model_tup", "figure_maker_single_dataset.make_2x2_regression_set", "print", "model_tag.startswith", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_jsdiv_regression_plot_vs2ndhighest", "(", "model_tag", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "print", "(", "\"Starting to make jsdiv regression plot vs 2nd highest\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "model_name", "=", "'HANconv'", "+", "hanconv_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "'HANrnn'", "+", "hanrnn_tag", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconv'", "+", "flanconv_tag", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "dataset_table", "=", "dataset_flanrnn_table", "\n", "model_name", "=", "'FLANrnn'", "+", "flanrnn_tag", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "if", "is_han", ":", "\n", "        ", "dataset_mask", "=", "dataset_han_mask", "\n", "", "else", ":", "\n", "        ", "dataset_mask", "=", "dataset_flan_mask", "\n", "", "dataset_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "dataset_name", "+", "'-'", "+", "model_tag", ")", "[", "dataset_mask", "]", "\n", "dataset_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "dataset_name", "+", "'-'", "+", "model_tag", ")", "[", "dataset_mask", "]", "\n", "dataset_model_tup", "=", "make_vs2nd_jsdiv_model_tup", "(", "dataset_highestattnweights", ",", "dataset_2ndhighestattnweights", ",", "dataset_table", ",", "\n", "dataset_name", ")", "\n", "\n", "make_2x2_regression_set", "(", "[", "dataset_model_tup", "]", ",", "\n", "\"differences_in_jsdivs_vs2nd_\"", "+", "model", ",", "vs_avg", "=", "False", ")", "\n", "print", "(", "\"Finished making a JS div plot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker_single_dataset.main": [[1011, 1033], ["figure_maker_single_dataset.make_probmass_boxplots", "figure_maker_single_dataset.make_probmass_boxplots", "figure_maker_single_dataset.make_probmass_boxplots", "figure_maker_single_dataset.make_probmass_boxplots", "figure_maker_single_dataset.make_boxplots", "figure_maker_single_dataset.make_boxplots", "figure_maker_single_dataset.make_boxplots", "figure_maker_single_dataset.make_boxplots", "figure_maker_single_dataset.make_decflip_regression_plot_vs2ndhighest", "figure_maker_single_dataset.make_decflip_regression_plot_vs2ndhighest", "figure_maker_single_dataset.make_decflip_regression_plot_vs2ndhighest", "figure_maker_single_dataset.make_decflip_regression_plot_vs2ndhighest", "figure_maker_single_dataset.make_jsdiv_regression_plot", "figure_maker_single_dataset.make_jsdiv_regression_plot", "figure_maker_single_dataset.make_jsdiv_regression_plot", "figure_maker_single_dataset.make_jsdiv_regression_plot"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_decflip_regression_plot_vs2ndhighest", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_decflip_regression_plot_vs2ndhighest", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_decflip_regression_plot_vs2ndhighest", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_decflip_regression_plot_vs2ndhighest", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot"], ["", "def", "main", "(", ")", ":", "\n", "    ", "sample_x", "=", "10", "\n", "\n", "make_probmass_boxplots", "(", "'hanrnn'", ",", "dataset_tag", "=", "hanrnn_tag", "[", "1", ":", "]", ")", "\n", "make_probmass_boxplots", "(", "'hanconv'", ",", "dataset_tag", "=", "hanconv_tag", "[", "1", ":", "]", ")", "\n", "make_probmass_boxplots", "(", "'flanrnn'", ",", "dataset_tag", "=", "flanrnn_tag", "[", "1", ":", "]", ")", "\n", "make_probmass_boxplots", "(", "'flanconv'", ",", "dataset_tag", "=", "flanconv_tag", "[", "1", ":", "]", ")", "\n", "\n", "make_boxplots", "(", "'hanrnn'", ",", "dataset_tag", "=", "hanrnn_tag", "[", "1", ":", "]", ")", "\n", "make_boxplots", "(", "'hanconv'", ",", "dataset_tag", "=", "hanconv_tag", "[", "1", ":", "]", ")", "\n", "make_boxplots", "(", "'flanrnn'", ",", "dataset_tag", "=", "flanrnn_tag", "[", "1", ":", "]", ")", "\n", "make_boxplots", "(", "'flanconv'", ",", "dataset_tag", "=", "flanconv_tag", "[", "1", ":", "]", ")", "\n", "\n", "make_decflip_regression_plot_vs2ndhighest", "(", "'hanrnn'", ",", "dataset_tag", "=", "hanrnn_tag", "[", "1", ":", "]", ")", "\n", "make_decflip_regression_plot_vs2ndhighest", "(", "'hanconv'", ",", "dataset_tag", "=", "hanconv_tag", "[", "1", ":", "]", ")", "\n", "make_decflip_regression_plot_vs2ndhighest", "(", "'flanrnn'", ",", "dataset_tag", "=", "flanrnn_tag", "[", "1", ":", "]", ")", "\n", "make_decflip_regression_plot_vs2ndhighest", "(", "'flanconv'", ",", "dataset_tag", "=", "flanconv_tag", "[", "1", ":", "]", ")", "\n", "\n", "make_jsdiv_regression_plot", "(", "'hanrnn'", ",", "sample_x", ",", "dataset_tag", "=", "hanrnn_tag", "[", "1", ":", "]", ")", "\n", "make_jsdiv_regression_plot", "(", "'hanconv'", ",", "sample_x", ",", "dataset_tag", "=", "hanconv_tag", "[", "1", ":", "]", ")", "\n", "make_jsdiv_regression_plot", "(", "'flanrnn'", ",", "sample_x", ",", "dataset_tag", "=", "flanrnn_tag", "[", "1", ":", "]", ")", "\n", "make_jsdiv_regression_plot", "(", "'flanconv'", ",", "sample_x", ",", "dataset_tag", "=", "flanconv_tag", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_filenames_for_subdir": [[37, 51], ["default_directories.base_output_dir.endswith", "mid_dir.endswith"], "function", ["None"], ["", "def", "get_filenames_for_subdir", "(", "mid_dir", ")", ":", "\n", "    ", "global", "base_output_dir", "\n", "if", "not", "base_output_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "base_output_dir", "+=", "'/'", "\n", "", "if", "not", "mid_dir", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "mid_dir", "+=", "'/'", "\n", "", "return", "base_output_dir", "+", "mid_dir", "+", "first_v_second_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "rand_results_fname", ",", "base_output_dir", "+", "mid_dir", "+", "unchanged_fname", ",", "base_output_dir", "+", "mid_dir", "+", "grad_based_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontop_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "attn_div_from_unif_fname", ",", "base_output_dir", "+", "mid_dir", "+", "gradsignmult_based_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygrad_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygradmult_stats_fname", ",", "base_output_dir", "+", "mid_dir", "+", "dec_flip_rand_nontopbygradsignmult_stats_fname", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_inds_where_grad_more_efficient": [[145, 160], ["numpy.logical_and", "numpy.logical_and", "numpy.logical_or", "numpy.logical_and", "numpy.logical_xor", "numpy.logical_and", "numpy.logical_and"], "function", ["None"], ["def", "get_inds_where_grad_more_efficient", "(", "table", ")", ":", "\n", "    ", "mask_for_seqs_longer_than_1_no_neg1s", "=", "(", "np", ".", "logical_and", "(", "np", ".", "logical_and", "(", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "!=", "-", "1", ")", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", ")", ")", "\n", "mask_for_seqs_longer_than_1_singleneg1", "=", "(", "\n", "np", ".", "logical_and", "(", "np", ".", "logical_xor", "(", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "==", "-", "1", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", "==", "-", "1", ")", ",", "\n", "table", "[", ":", ",", "ATTN_SEQ_LEN", "]", ">", "1", ")", ")", "\n", "rows_where_grad_more_efficient", "=", "np", ".", "logical_or", "(", "np", ".", "logical_and", "(", "mask_for_seqs_longer_than_1_no_neg1s", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", ">", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", ")", ",", "\n", "np", ".", "logical_and", "(", "mask_for_seqs_longer_than_1_singleneg1", ",", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP", "]", "<", "\n", "table", "[", ":", ",", "NEEDED_REM_TOP_X_FOR_DECFLIP_GRAD", "]", ")", ")", "\n", "return", "table", "[", "rows_where_grad_more_efficient", "]", "[", ":", ",", "ID", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_intersection_of_ids": [[162, 170], ["len", "range", "numpy.intersect1d", "len"], "function", ["None"], ["", "def", "get_intersection_of_ids", "(", "list_of_id_arrays", ")", ":", "\n", "    ", "if", "len", "(", "list_of_id_arrays", ")", "==", "1", ":", "\n", "        ", "return", "list_of_id_arrays", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "cur_intersection", "=", "list_of_id_arrays", "[", "-", "1", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_id_arrays", ")", "-", "1", ")", ":", "\n", "            ", "cur_intersection", "=", "np", ".", "intersect1d", "(", "cur_intersection", ",", "list_of_id_arrays", "[", "i", "]", ")", "\n", "", "return", "cur_intersection", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.attn_perf_overlap_for_model": [[172, 268], ["__import__", "getattr", "getattr", "getattr", "getattr", "numpy.setdiff1d", "numpy.setdiff1d", "np.array.astype", "numpy.sort", "range", "numpy.array", "print", "print", "range", "numpy.intersect1d", "print", "range", "range", "print", "range", "print", "sum", "print", "range", "print", "print", "figure_maker.get_inds_where_grad_more_efficient", "figure_maker.get_inds_where_grad_more_efficient", "figure_maker.get_inds_where_grad_more_efficient", "figure_maker.get_inds_where_grad_more_efficient", "print", "numpy.intersect1d", "len", "numpy.setdiff1d", "len", "range", "figure_maker.get_intersection_of_ids", "mini_strings_to_report.append", "range", "print", "len", "range", "print", "len", "print", "list_to_keep_for_flans.append", "numpy.intersect1d", "len", "len", "len", "figure_maker.get_intersection_of_ids", "mini_strings_to_report.append", "numpy.setdiff1d", "numpy.setdiff1d", "str", "str", "lists_to_intersect.append", "numpy.setdiff1d", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_inds_where_grad_more_efficient", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_inds_where_grad_more_efficient", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_inds_where_grad_more_efficient", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_inds_where_grad_more_efficient", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_intersection_of_ids", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_intersection_of_ids"], ["", "", "def", "attn_perf_overlap_for_model", "(", "data_name", ")", ":", "\n", "    ", "namespace", "=", "__import__", "(", "__name__", ")", "\n", "hanrnn_table", "=", "getattr", "(", "namespace", ",", "data_name", "+", "'_hanrnn_table'", ")", "\n", "hanconv_table", "=", "getattr", "(", "namespace", ",", "data_name", "+", "'_hanconv_table'", ")", "\n", "flanrnn_table", "=", "getattr", "(", "namespace", ",", "data_name", "+", "'_flanrnn_table'", ")", "\n", "flanconv_table", "=", "getattr", "(", "namespace", ",", "data_name", "+", "'_flanconv_table'", ")", "\n", "\n", "ids_to_remove_for_flans", "=", "np", ".", "setdiff1d", "(", "flanconv_table", "[", ":", ",", "ID", "]", ",", "hanconv_table", "[", ":", ",", "ID", "]", ")", "# more than one token, but only one sentence", "\n", "ids_to_remove_for_flans", "=", "ids_to_remove_for_flans", "\n", "ids_to_keep_for_flans", "=", "np", ".", "setdiff1d", "(", "flanconv_table", "[", ":", ",", "ID", "]", ",", "ids_to_remove_for_flans", ")", "\n", "ids_to_keep_for_flans", "=", "ids_to_keep_for_flans", ".", "astype", "(", "int", ")", "\n", "ids_to_keep_for_flans", "=", "np", ".", "sort", "(", "ids_to_keep_for_flans", ")", "\n", "list_to_keep_for_flans", "=", "[", "]", "\n", "cur_ind_in_sorted", "=", "0", "\n", "for", "ind", "in", "range", "(", "flanconv_table", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "cur_ind_in_sorted", "<", "flanconv_table", ".", "shape", "[", "0", "]", "and", "flanconv_table", "[", "ind", ",", "0", "]", "==", "ids_to_keep_for_flans", "[", "cur_ind_in_sorted", "]", ":", "\n", "            ", "list_to_keep_for_flans", ".", "append", "(", "ind", ")", "\n", "cur_ind_in_sorted", "+=", "1", "\n", "", "", "ids_to_keep_for_flans", "=", "np", ".", "array", "(", "list_to_keep_for_flans", ")", "\n", "flanconv_table", "=", "flanconv_table", "[", "ids_to_keep_for_flans", "]", "\n", "flanrnn_table", "=", "flanrnn_table", "[", "ids_to_keep_for_flans", "]", "\n", "assert", "flanconv_table", ".", "shape", "[", "0", "]", "==", "flanrnn_table", ".", "shape", "[", "0", "]", "\n", "assert", "hanconv_table", ".", "shape", "[", "0", "]", "==", "flanrnn_table", ".", "shape", "[", "0", "]", "\n", "assert", "hanrnn_table", ".", "shape", "[", "0", "]", "==", "hanconv_table", ".", "shape", "[", "0", "]", "\n", "\n", "names", "=", "[", "'hanrnn'", ",", "'hanconv'", ",", "'flanrnn'", ",", "'flanconv'", "]", "\n", "ids_where_grad_better", "=", "[", "get_inds_where_grad_more_efficient", "(", "hanrnn_table", ")", ",", "\n", "get_inds_where_grad_more_efficient", "(", "hanconv_table", ")", ",", "\n", "get_inds_where_grad_more_efficient", "(", "flanrnn_table", ")", ",", "\n", "get_inds_where_grad_more_efficient", "(", "flanconv_table", ")", "]", "\n", "\n", "print", "(", "'\\n'", "+", "data_name", "+", "' instances where attention provably not optimal:'", ")", "\n", "print", "(", "\"(FLANs now constrained down to same \"", "+", "str", "(", "flanrnn_table", ".", "shape", "[", "0", "]", ")", "+", "\" >1-sentence-len docs as HANs)\"", ")", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "tab", "=", "hanrnn_table", "\n", "", "elif", "i", "==", "1", ":", "\n", "            ", "tab", "=", "hanconv_table", "\n", "", "elif", "i", "==", "2", ":", "\n", "            ", "tab", "=", "flanrnn_table", "\n", "", "elif", "i", "==", "3", ":", "\n", "            ", "tab", "=", "flanconv_table", "\n", "", "print", "(", "names", "[", "i", "]", "+", "\" fraction bad: \"", "+", "str", "(", "ids_where_grad_better", "[", "i", "]", ".", "shape", "[", "0", "]", "/", "\n", "tab", ".", "shape", "[", "0", "]", ")", "+", "\" (\"", "+", "\n", "str", "(", "ids_where_grad_better", "[", "i", "]", ".", "shape", "[", "0", "]", ")", "+", "\" / \"", "+", "str", "(", "tab", ".", "shape", "[", "0", "]", ")", "+", "\")\"", ")", "\n", "\n", "", "inds_in_all_4", "=", "np", ".", "intersect1d", "(", "np", ".", "intersect1d", "(", "np", ".", "intersect1d", "(", "ids_where_grad_better", "[", "0", "]", ",", "\n", "ids_where_grad_better", "[", "1", "]", ")", ",", "\n", "ids_where_grad_better", "[", "2", "]", ")", ",", "ids_where_grad_better", "[", "3", "]", ")", "\n", "total_num_in_all_4", "=", "inds_in_all_4", ".", "shape", "[", "0", "]", "\n", "print", "(", "\"\\t\"", "+", "str", "(", "inds_in_all_4", ".", "shape", "[", "0", "]", ")", "+", "\" instances bad in all 4 models\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_where_grad_better", ")", ")", ":", "\n", "        ", "ids_where_grad_better", "[", "i", "]", "=", "np", ".", "setdiff1d", "(", "ids_where_grad_better", "[", "i", "]", ",", "inds_in_all_4", ")", "\n", "", "total_num_in_exactly_3", "=", "0", "\n", "mini_strings_to_report", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_where_grad_better", ")", ")", ":", "\n", "        ", "lists_to_intersect", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "ids_where_grad_better", ")", ")", ":", "\n", "            ", "if", "i", "==", "j", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "lists_to_intersect", ".", "append", "(", "ids_where_grad_better", "[", "j", "]", ")", "\n", "", "", "inds_in_this_3", "=", "get_intersection_of_ids", "(", "lists_to_intersect", ")", "\n", "mini_strings_to_report", ".", "append", "(", "\"\\t\\t\"", "+", "str", "(", "inds_in_this_3", ".", "shape", "[", "0", "]", ")", "+", "\" instances bad in exactly non-\"", "+", "\n", "names", "[", "i", "]", "+", "\" models\"", ")", "\n", "total_num_in_exactly_3", "+=", "inds_in_this_3", ".", "shape", "[", "0", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "ids_where_grad_better", ")", ")", ":", "\n", "            ", "if", "i", "!=", "j", ":", "\n", "                ", "ids_where_grad_better", "[", "j", "]", "=", "np", ".", "setdiff1d", "(", "ids_where_grad_better", "[", "j", "]", ",", "inds_in_this_3", ")", "\n", "", "", "", "print", "(", "\"\\t\"", "+", "str", "(", "total_num_in_exactly_3", ")", "+", "\" instances bad in exactly 3 models\"", ")", "\n", "for", "st", "in", "mini_strings_to_report", ":", "\n", "        ", "print", "(", "st", ")", "\n", "\n", "", "total_num_in_exactly_2", "=", "0", "\n", "mini_strings_to_report", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_where_grad_better", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "ids_where_grad_better", ")", ")", ":", "\n", "            ", "if", "j", "<=", "i", ":", "\n", "                ", "continue", "\n", "", "inds_in_this_2", "=", "get_intersection_of_ids", "(", "[", "ids_where_grad_better", "[", "i", "]", ",", "ids_where_grad_better", "[", "j", "]", "]", ")", "\n", "mini_strings_to_report", ".", "append", "(", "\"\\t\\t\"", "+", "str", "(", "inds_in_this_2", ".", "shape", "[", "0", "]", ")", "+", "\" instances bad in only \"", "+", "\n", "names", "[", "i", "]", "+", "\" and \"", "+", "names", "[", "j", "]", ")", "\n", "total_num_in_exactly_2", "+=", "inds_in_this_2", ".", "shape", "[", "0", "]", "\n", "ids_where_grad_better", "[", "i", "]", "=", "np", ".", "setdiff1d", "(", "ids_where_grad_better", "[", "i", "]", ",", "inds_in_this_2", ")", "\n", "ids_where_grad_better", "[", "j", "]", "=", "np", ".", "setdiff1d", "(", "ids_where_grad_better", "[", "j", "]", ",", "inds_in_this_2", ")", "\n", "", "", "print", "(", "\"\\t\"", "+", "str", "(", "total_num_in_exactly_2", ")", "+", "\" instances bad in exactly 2 models\"", ")", "\n", "for", "st", "in", "mini_strings_to_report", ":", "\n", "        ", "print", "(", "st", ")", "\n", "\n", "", "total_num_in_exactly_1", "=", "sum", "(", "[", "arr", ".", "shape", "[", "0", "]", "for", "arr", "in", "ids_where_grad_better", "]", ")", "\n", "print", "(", "\"\\t\"", "+", "str", "(", "total_num_in_exactly_1", ")", "+", "\" instances bad in exactly 1 model\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ids_where_grad_better", ")", ")", ":", "\n", "        ", "print", "(", "\"\\t\\t\"", "+", "str", "(", "ids_where_grad_better", "[", "i", "]", ".", "shape", "[", "0", "]", ")", "+", "\" instances bad only in \"", "+", "names", "[", "i", "]", ")", "\n", "", "print", "(", "\"\\t\"", "+", "str", "(", "hanrnn_table", ".", "shape", "[", "0", "]", "-", "total_num_in_exactly_3", "-", "total_num_in_exactly_1", "-", "\n", "total_num_in_exactly_2", "-", "total_num_in_all_4", ")", "+", "\" instances never bad\"", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.get_predicted_probabilities": [[270, 294], ["range", "print", "print", "print", "print", "print", "range", "list", "str", "str", "str", "str", "str", "list.keys"], "function", ["None"], ["", "def", "get_predicted_probabilities", "(", "p1", ",", "p2", ",", "p3", ",", "p4", ")", ":", "\n", "    ", "prob_all_4", "=", "p1", "*", "p2", "*", "p3", "*", "p4", "\n", "prob_exactly_3", "=", "(", "(", "1", "-", "p1", ")", "*", "p2", "*", "p3", "*", "p4", ")", "+", "(", "p1", "*", "(", "1", "-", "p2", ")", "*", "p3", "*", "p4", ")", "+", "(", "p1", "*", "p2", "*", "(", "1", "-", "p3", ")", "*", "p4", ")", "+", "(", "p1", "*", "p2", "*", "p3", "*", "(", "1", "-", "p4", ")", ")", "\n", "list_of_probs", "=", "[", "p1", ",", "p2", ",", "p3", ",", "p4", "]", "\n", "prob_exactly_2", "=", "0", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "4", ")", ":", "\n", "            ", "if", "j", "<=", "i", ":", "\n", "                ", "continue", "\n", "", "other_inds", "=", "{", "0", ":", "0", ",", "1", ":", "1", ",", "2", ":", "2", ",", "3", ":", "3", "}", "\n", "del", "other_inds", "[", "i", "]", "\n", "del", "other_inds", "[", "j", "]", "\n", "other_inds", "=", "list", "(", "other_inds", ".", "keys", "(", ")", ")", "\n", "prob_exactly_2", "+=", "(", "list_of_probs", "[", "i", "]", "*", "list_of_probs", "[", "j", "]", "*", "(", "1", "-", "list_of_probs", "[", "other_inds", "[", "0", "]", "]", ")", "*", "\n", "(", "1", "-", "list_of_probs", "[", "other_inds", "[", "1", "]", "]", ")", ")", "\n", "", "", "prob_exactly_1", "=", "(", "p1", "*", "(", "1", "-", "p2", ")", "*", "(", "1", "-", "p3", ")", "*", "(", "1", "-", "p4", ")", ")", "+", "(", "(", "1", "-", "p1", ")", "*", "p2", "*", "(", "1", "-", "p3", ")", "*", "(", "1", "-", "p4", ")", ")", "+", "(", "(", "1", "-", "p1", ")", "*", "(", "1", "-", "p2", ")", "*", "p3", "*", "(", "1", "-", "p4", ")", ")", "+", "(", "(", "1", "-", "p1", ")", "*", "(", "1", "-", "p2", ")", "*", "(", "1", "-", "p3", ")", "*", "p4", ")", "\n", "prob_exactly_0", "=", "(", "(", "1", "-", "p1", ")", "*", "(", "1", "-", "p2", ")", "*", "(", "1", "-", "p3", ")", "*", "(", "1", "-", "p4", ")", ")", "\n", "print", "(", "\"Prob all 4: \"", "+", "str", "(", "prob_all_4", ")", ")", "\n", "print", "(", "\"Prob exactly 3: \"", "+", "str", "(", "prob_exactly_3", ")", ")", "\n", "print", "(", "\"Prob exactly 2: \"", "+", "str", "(", "prob_exactly_2", ")", ")", "\n", "print", "(", "\"Prob exactly 1: \"", "+", "str", "(", "prob_exactly_1", ")", ")", "\n", "print", "(", "\"Prob never uninterpretable: \"", "+", "str", "(", "prob_exactly_0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_2boxplot_set": [[311, 315], ["None"], "function", ["None"], ["", "def", "make_2x2_2boxplot_set", "(", "list1_of_two_vallists_to_boxplot", ",", "list2_of_two_vallists_to_boxplot", ",", "\n", "list3_of_two_vallists_to_boxplot", ",", "list4_of_two_vallists_to_boxplot", ",", "list_of_colorlabels", ",", "\n", "list_of_two_color_tuples", ",", "labels_for_4_boxplot_sets", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_4_4boxplot_set": [[317, 321], ["None"], "function", ["None"], ["", "def", "make_4_4boxplot_set", "(", "list1_of_four_vallists_to_boxplot", ",", "list2_of_four_vallists_to_boxplot", ",", "\n", "list3_of_four_vallists_to_boxplot", ",", "list4_of_four_vallists_to_boxplot", ",", "list_of_colorlabels", ",", "\n", "list_of_four_color_tuples", ",", "labels_for_4_boxplot_sets", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_kdeplot": [[323, 346], ["range", "pandas.DataFrame", "matplotlib.figure", "seaborn.FacetGrid", "sns.FacetGrid.map", "sns.FacetGrid.set_titles", "matplotlib.savefig", "matplotlib.close", "len", "len", "len", "range", "len", "len", "len", "list_of_row_dicts.append"], "function", ["None"], ["", "def", "make_kdeplot", "(", "tuples_of_title_x_y", ",", "filename", ")", ":", "\n", "    ", "subplot_title", "=", "'Dataset'", "\n", "x_title", "=", "\"Difference in Attention Weight Magnitudes\"", "\n", "y_title", "=", "\"Log Difference in Corresponding JS Divergences\\nfrom Original Output\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "assert", "len", "(", "tuples_of_title_x_y", "[", "1", "]", ")", "==", "len", "(", "tuples_of_title_x_y", "[", "2", "]", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "tuples_of_title_x_y", ")", ")", ":", "\n", "        ", "dataset_tup", "=", "tuples_of_title_x_y", "[", "j", "]", "\n", "assert", "len", "(", "dataset_tup", "[", "1", "]", ")", "==", "len", "(", "dataset_tup", "[", "2", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset_tup", "[", "1", "]", ")", ")", ":", "\n", "            ", "list_of_row_dicts", ".", "append", "(", "{", "subplot_title", ":", "dataset_tup", "[", "0", "]", ",", "x_title", ":", "dataset_tup", "[", "1", "]", "[", "i", "]", ",", "\n", "y_title", ":", "dataset_tup", "[", "2", "]", "[", "i", "]", "}", ")", "\n", "", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "g", "=", "sns", ".", "FacetGrid", "(", "data_to_plot", ",", "col", "=", "subplot_title", ",", "hue", "=", "None", ",", "col_wrap", "=", "2", ")", "\n", "g", ".", "map", "(", "sns", ".", "kdeplot", ",", "x_title", ",", "y_title", ",", "cmap", "=", "\"Blues\"", ",", "shade", "=", "True", ",", "shade_lowest", "=", "False", ")", "\n", "g", ".", "set_titles", "(", "\"{col_name}\"", ")", "\n", "#ax = sns.kdeplot(getattr(all_rows, x_title), getattr(all_rows, y_title),", "\n", "#                 cmap = \"Blues\", shade = True, shade_lowest = False,", "\n", "#                 )", "\n", "#ax.set_title(\"Differences in Attention weight \")", "\n", "plt", ".", "savefig", "(", "images_dir", "+", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_vsrand_decflip_violinplot": [[348, 365], ["sorted", "pandas.DataFrame", "seaborn.catplot", "matplotlib.savefig", "range", "len", "len", "len", "len", "sorted.append", "str"], "function", ["None"], ["", "def", "make_2x2_vsrand_decflip_violinplot", "(", "tuples_of_title_x_y_noneflipped", ",", "filename", ")", ":", "\n", "    ", "x_label", "=", "\"Difference in (average) zeroed attention\\nweight magnitude\"", "\n", "y_label", "=", "\"Difference in decision flip indicators\\ncompared to original output\"", "\n", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "for", "tup", "in", "tuples_of_title_x_y_noneflipped", ":", "\n", "        ", "dataset_title", "=", "tup", "[", "0", "]", "\n", "assert", "len", "(", "tup", "[", "1", "]", ")", "==", "len", "(", "tup", "[", "2", "]", ")", "\n", "assert", "len", "(", "tup", "[", "1", "]", ")", "==", "tup", "[", "3", "]", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tup", "[", "2", "]", ")", ")", ":", "\n", "            ", "list_of_row_dicts", ".", "append", "(", "{", "title_of_each_graph", ":", "dataset_title", ",", "x_label", ":", "tup", "[", "1", "]", "[", "i", "]", ",", "y_label", ":", "str", "(", "tup", "[", "2", "]", "[", "i", "]", ")", ",", "\n", "\"No Flips Occurred\"", ":", "(", "\"True\"", "if", "tup", "[", "3", "]", "[", "i", "]", "else", "\"False\"", ")", "}", ")", "\n", "", "", "list_of_row_dicts", "=", "sorted", "(", "list_of_row_dicts", ",", "key", "=", "(", "lambda", "x", ":", "1", "if", "x", "[", "\"No Flips Occurred\"", "]", "==", "\"True\"", "else", "0", ")", ")", "\n", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "g", "=", "sns", ".", "catplot", "(", "kind", "=", "'violin'", ",", "x", "=", "x_label", ",", "y", "=", "y_label", ",", "col", "=", "title_of_each_graph", ",", "hue", "=", "\"No Flips Occurred\"", ",", "palette", "=", "None", ",", "\n", "data", "=", "data_to_plot", ",", "col_wrap", "=", "2", ",", "legend", "=", "True", ",", "split", "=", "True", ",", "inner", "=", "None", ",", "orient", "=", "\"h\"", ")", "\n", "plt", ".", "savefig", "(", "images_dir", "+", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_vsrand_decflip_stackplot": [[367, 512], ["math.ceil", "range", "pandas.DataFrame", "seaborn.FacetGrid", "matplotlib.subplots", "range", "matplotlib.savefig", "matplotlib.close", "len", "numpy.array", "numpy.array", "range", "range", "range", "print", "len", "len", "axs[].set_title", "numpy.concatenate", "numpy.concatenate", "axs[].stackplot", "numpy.sum", "numpy.sum", "str", "numpy.logical_and", "range", "numpy.sum", "range", "numpy.array", "numpy.all", "len", "len", "len", "len", "list_of_row_dicts.append", "len", "str", "numpy.sum", "numpy.sum", "numpy.sum", "str", "numpy.sum", "numpy.sum", "str", "numpy.sum", "numpy.sum", "list_of_binleft_countdist.append", "list_of_inds_in_need_of_interpolation.append", "str", "numpy.reshape", "range", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "str", "str", "len", "list_of_binleft_countdist.append", "len", "range", "numpy.sum", "len", "numpy.array", "len", "range", "numpy.all", "numpy.sum", "str", "len", "str", "range", "numpy.sum"], "function", ["None"], ["", "def", "make_2x2_vsrand_decflip_stackplot", "(", "tuples_of_title_x_y_noneflipped", ",", "filename", ",", "bin_size", ",", "vs_avg", "=", "True", ")", ":", "\n", "    ", "if", "vs_avg", ":", "\n", "        ", "x_label", "=", "\"Difference in (average) zeroed attention\\nweight magnitude\"", "\n", "", "else", ":", "\n", "        ", "x_label", "=", "\"Difference in zeroed attention\\nweight magnitude\"", "\n", "", "if", "vs_avg", ":", "\n", "        ", "y_label", "=", "[", "\"Highest didn't flip, 5/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 4/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 3/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 2/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 1/5 others flipped\"", ",", "\n", "\"Highest didn't flip, 0/5 others flipped\"", ",", "\n", "\"Highest flipped, 5/5 others flipped\"", ",", "\n", "\"Highest flipped, 4/5 others flipped\"", ",", "\n", "\"Highest flipped, 3/5 others flipped\"", ",", "\n", "\"Highest flipped, 2/5 others flipped\"", ",", "\n", "\"Highest flipped, 1/5 others flipped\"", ",", "\n", "\"Highest flipped, 0/5 others flipped\"", "]", "\n", "", "else", ":", "\n", "        ", "y_label", "=", "[", "\"Highest didn't flip, 2nd highest flipped\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"Neither flipped\"", ",", "\n", "\"Both flipped\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"Highest flipped, 2nd highest didn't flip\"", "]", "\n", "", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "how_many_bins", "=", "ceil", "(", "1.0", "/", "bin_size", ")", "\n", "for", "dataset_ind", "in", "range", "(", "len", "(", "tuples_of_title_x_y_noneflipped", ")", ")", ":", "\n", "        ", "title", "=", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "[", "0", "]", "\n", "x", "=", "np", ".", "array", "(", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "[", "1", "]", ")", "\n", "y", "=", "np", ".", "array", "(", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "[", "2", "]", ")", "\n", "noneflipped", "=", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "[", "3", "]", "\n", "assert", "np", ".", "sum", "(", "y", "[", "noneflipped", "]", "==", "0", ")", "==", "np", ".", "sum", "(", "noneflipped", ")", ",", "str", "(", "y", "[", "noneflipped", "]", ")", "+", "', '", "+", "str", "(", "title", ")", "\n", "list_of_binleft_countdist", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "how_many_bins", ")", ":", "\n", "            ", "bin_left_edge", "=", "i", "*", "bin_size", "\n", "bin_right_edge", "=", "bin_left_edge", "+", "bin_size", "\n", "mask", "=", "np", ".", "logical_and", "(", "x", ">=", "bin_left_edge", ",", "x", "<", "bin_right_edge", ")", "\n", "available_y", "=", "y", "[", "mask", "]", "\n", "available_nonflipped", "=", "noneflipped", "[", "mask", "]", "\n", "list_of_counts", "=", "[", "0", "for", "j", "in", "range", "(", "12", ")", "]", "\n", "for", "j", "in", "range", "(", "5", ")", ":", "\n", "                ", "left_edge", "=", "-", "1.1", "+", ".2", "*", "j", "\n", "right_edge", "=", "left_edge", "+", ".2", "\n", "list_of_counts", "[", "j", "]", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "available_y", ">", "left_edge", ",", "\n", "available_y", "<", "right_edge", ")", ")", "\n", "", "list_of_counts", "[", "5", "]", "=", "np", ".", "sum", "(", "available_nonflipped", ")", "\n", "list_of_counts", "[", "6", "]", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "available_y", ">", "-", ".1", ",", "available_y", "<", ".1", ")", ")", "-", "list_of_counts", "[", "5", "]", "\n", "for", "j", "in", "range", "(", "5", ")", ":", "\n", "                ", "left_edge", "=", ".1", "+", ".2", "*", "j", "\n", "right_edge", "=", "left_edge", "+", ".2", "\n", "list_of_counts", "[", "7", "+", "j", "]", "=", "np", ".", "sum", "(", "np", ".", "logical_and", "(", "available_y", ">", "left_edge", ",", "\n", "available_y", "<", "right_edge", ")", ")", "\n", "", "np_arr_for_bin", "=", "np", ".", "array", "(", "list_of_counts", ")", "\n", "assert", "np", ".", "all", "(", "np_arr_for_bin", ">=", "0", ")", ",", "str", "(", "np_arr_for_bin", ")", "+", "', '", "+", "str", "(", "title", ")", "\n", "assert", "np", ".", "sum", "(", "mask", ")", "==", "np", ".", "sum", "(", "np_arr_for_bin", ")", ",", "str", "(", "np", ".", "sum", "(", "mask", ")", ")", "+", "\", \"", "+", "str", "(", "np_arr_for_bin", ")", "\n", "if", "np", ".", "sum", "(", "np_arr_for_bin", ")", "!=", "0", ":", "\n", "                ", "denom", "=", "np", ".", "sum", "(", "np_arr_for_bin", ")", "\n", "list_of_binleft_countdist", ".", "append", "(", "(", "bin_left_edge", ",", "np_arr_for_bin", "/", "denom", ")", ")", "\n", "", "elif", "len", "(", "list_of_binleft_countdist", ")", ">", "0", ":", "\n", "                ", "list_of_binleft_countdist", ".", "append", "(", "(", "bin_left_edge", ",", "None", ")", ")", "\n", "", "", "while", "list_of_binleft_countdist", "[", "-", "1", "]", "[", "1", "]", "is", "None", ":", "\n", "            ", "list_of_binleft_countdist", "=", "list_of_binleft_countdist", "[", ":", "-", "1", "]", "\n", "\n", "# now go through and interpolate for any remaining Nones in the middle", "\n", "", "list_of_inds_in_need_of_interpolation", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_binleft_countdist", ")", ")", ":", "\n", "            ", "if", "list_of_binleft_countdist", "[", "i", "]", "[", "1", "]", "is", "not", "None", ":", "\n", "                ", "if", "len", "(", "list_of_inds_in_need_of_interpolation", ")", ">", "0", ":", "\n", "# interpolate", "\n", "                    ", "endpoint_on_right", "=", "list_of_binleft_countdist", "[", "i", "]", "[", "1", "]", "\n", "step_sizes", "=", "[", "(", "endpoint_on_right", "[", "k", "]", "-", "most_recent_nonnone_on_left", "[", "k", "]", ")", "/", "\n", "(", "len", "(", "list_of_inds_in_need_of_interpolation", ")", "+", "1", ")", "for", "k", "in", "range", "(", "12", ")", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "list_of_inds_in_need_of_interpolation", ")", ")", ":", "\n", "                        ", "ind", "=", "list_of_inds_in_need_of_interpolation", "[", "j", "]", "\n", "new_array", "=", "np", ".", "array", "(", "[", "most_recent_nonnone_on_left", "[", "k", "]", "+", "step_sizes", "[", "k", "]", "*", "(", "j", "+", "1", ")", "\n", "for", "k", "in", "range", "(", "12", ")", "]", ")", "\n", "assert", "np", ".", "all", "(", "new_array", ")", ">=", "0", "\n", "assert", ".99", "<", "np", ".", "sum", "(", "new_array", ")", "<", "1.01", ",", "str", "(", "np", ".", "sum", "(", "new_array", ")", ")", "+", "', '", "+", "str", "(", "new_array", ")", "\n", "list_of_binleft_countdist", "[", "ind", "]", "=", "(", "list_of_binleft_countdist", "[", "ind", "]", "[", "0", "]", ",", "new_array", ")", "\n", "", "list_of_inds_in_need_of_interpolation", "=", "[", "]", "\n", "", "else", ":", "\n", "                    ", "most_recent_nonnone_on_left", "=", "list_of_binleft_countdist", "[", "i", "]", "[", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "list_of_inds_in_need_of_interpolation", ".", "append", "(", "i", ")", "\n", "\n", "", "", "tuples_of_title_x_y_noneflipped", "[", "dataset_ind", "]", "=", "[", "title", ",", "[", "tup", "[", "0", "]", "for", "tup", "in", "list_of_binleft_countdist", "]", ",", "\n", "[", "tup", "[", "1", "]", "for", "tup", "in", "list_of_binleft_countdist", "]", "]", "\n", "\n", "# each entry of tuples_of_title_x_y_noneflipped now in format title, list_of_bin_edges, list_of_corr_dists", "\n", "\n", "\n", "\n", "\n", "", "for", "tup", "in", "tuples_of_title_x_y_noneflipped", ":", "\n", "        ", "dataset_title", "=", "tup", "[", "0", "]", "\n", "assert", "len", "(", "tup", "[", "1", "]", ")", "==", "len", "(", "tup", "[", "2", "]", ")", "\n", "avg_pct_noflip", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "tup", "[", "1", "]", ")", ")", ":", "\n", "            ", "avg_pct_noflip", "+=", "tup", "[", "2", "]", "[", "i", "]", "[", "5", "]", "\n", "list_of_row_dicts", ".", "append", "(", "{", "title_of_each_graph", ":", "dataset_title", ",", "x_label", ":", "tup", "[", "1", "]", "[", "i", "]", ",", "\n", "y_label", "[", "0", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "0", "]", ",", "y_label", "[", "1", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "1", "]", ",", "\n", "y_label", "[", "2", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "2", "]", ",", "y_label", "[", "3", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "3", "]", ",", "\n", "y_label", "[", "4", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "4", "]", ",", "y_label", "[", "5", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "5", "]", ",", "\n", "y_label", "[", "6", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "6", "]", ",", "y_label", "[", "7", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "7", "]", ",", "\n", "y_label", "[", "8", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "8", "]", ",", "y_label", "[", "9", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "9", "]", ",", "\n", "y_label", "[", "10", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "10", "]", ",", "y_label", "[", "11", "]", ":", "tup", "[", "2", "]", "[", "i", "]", "[", "11", "]", "}", ")", "\n", "", "print", "(", "\"Avg pct no-flip: \"", "+", "str", "(", "avg_pct_noflip", "/", "len", "(", "tup", "[", "1", "]", ")", ")", ")", "\n", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "g", "=", "sns", ".", "FacetGrid", "(", "data_to_plot", ",", "col", "=", "title_of_each_graph", ",", "hue", "=", "None", ",", "col_wrap", "=", "2", ")", "\n", "#g = g.map(plt.stackplot, x_label, y_label[0], y_label[1], y_label[2], y_label[3], y_label[4], y_label[5],", "\n", "#          y_label[6], y_label[7], y_label[8], y_label[9], y_label[10], y_label[11], labels=y_label, colors=None)", "\n", "#g = g.set_titles(\"{col_name}\")", "\n", "data_to_plot", "=", "data_to_plot", "[", "data_to_plot", "[", "title_of_each_graph", "]", "==", "'Yahoo'", "]", "\n", "\n", "if", "len", "(", "tuples_of_title_x_y_noneflipped", ")", "==", "1", ":", "\n", "        ", "subplot_args", "=", "[", "111", "]", "\n", "", "elif", "len", "(", "tuples_of_title_x_y_noneflipped", ")", "==", "2", ":", "\n", "        ", "subplot_args", "=", "[", "121", ",", "122", "]", "\n", "", "else", ":", "\n", "        ", "subplot_args", "=", "[", "221", ",", "222", ",", "223", ",", "224", "]", "\n", "", "subplot_args", "=", "[", "221", ",", "222", ",", "223", ",", "224", "]", "\n", "\n", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "2", ",", "2", ",", "constrained_layout", "=", "True", ",", "figsize", "=", "(", "12", ",", "9", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "tuples_of_title_x_y_noneflipped", ")", ")", ":", "\n", "\n", "        ", "axs", "[", "i", "//", "2", ",", "i", "%", "2", "]", ".", "set_title", "(", "\"Dataset = \"", "+", "tuples_of_title_x_y_noneflipped", "[", "i", "]", "[", "0", "]", ")", "\n", "sample_data", "=", "tuples_of_title_x_y_noneflipped", "[", "i", "]", "\n", "ys", "=", "np", ".", "concatenate", "(", "[", "np", ".", "reshape", "(", "arr", ",", "(", "12", ",", "1", ")", ")", "for", "arr", "in", "sample_data", "[", "2", "]", "]", ",", "axis", "=", "1", ")", "\n", "ys", "=", "np", ".", "concatenate", "(", "[", "ys", "[", ":", "5", "]", ",", "ys", "[", "6", ":", "]", "]", ",", "axis", "=", "0", ")", "\n", "axs", "[", "i", "//", "2", ",", "i", "%", "2", "]", ".", "stackplot", "(", "sample_data", "[", "1", "]", ",", "ys", ",", "labels", "=", "y_label", ",", "colors", "=", "[", "'#F8A102'", ",", "'#FF9900'", ",", "'#FFB60D'", ",", "'#FFD5A6'", ",", "\n", "'#FFF1E0'", ",", "'#D6D6D6'", ",", "'#E0F6FC'", ",", "'#B3EBFC'", ",", "\n", "'#90CDFC'", ",", "'#3AAEFC'", ",", "'#85B7FF'", "]", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "images_dir", "+", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_fracremoved_boxplots": [[514, 572], ["pandas.DataFrame", "matplotlib.figure", "seaborn.boxplot", "sns.boxplot.set_title", "sns.boxplot.set_yticks", "sns.boxplot.legend_.remove", "seaborn.despine", "matplotlib.savefig", "matplotlib.close", "range", "matplotlib.figure", "seaborn.boxplot", "sns.boxplot.set_title", "sns.boxplot.set_yticks", "sns.boxplot.legend_.remove", "seaborn.despine", "matplotlib.legend", "filename.endswith", "matplotlib.savefig", "matplotlib.close", "len", "matplotlib.legend", "matplotlib.legend", "list_of_row_dicts.append", "filename.rfind"], "function", ["None"], ["", "def", "make_fracremoved_boxplots", "(", "filename", ",", "list_of_ordering_names", ",", "dataset_orderingfracdistribs", ",", "model", ",", "\n", "y_axis_title", "=", "\"Fractions Removed\"", ")", ":", "\n", "    ", "if", "\"Fraction\"", "in", "y_axis_title", ":", "\n", "        ", "plot_title", "=", "\"Fractions of Original Attended Items Removed Before First\\nDecision \"", "+", "\"Flip Occurred: \"", "+", "model", "\n", "palette", "=", "{", "\"Random\"", ":", "\"#2589CC\"", ",", "\"Attention\"", ":", "\"#80D4FF\"", ",", "\"Gradient\"", ":", "\"#D4F3FF\"", ",", "\"Attn * Grad\"", ":", "\"#FFFFFF\"", "}", "\n", "", "else", ":", "\n", "        ", "plot_title", "=", "\"Probability Masses of Original Attention Distributions\\nRemoved Before First Decision \"", "+", "\"Flip Occurred: \"", "+", "model", "\n", "palette", "=", "{", "\"Random\"", ":", "\"#A970FF\"", ",", "\"Attention\"", ":", "\"#EEA8FF\"", ",", "\"Gradient\"", ":", "\"#FFE0FF\"", ",", "\"Attn * Grad\"", ":", "\"#FFFFFF\"", "}", "\n", "", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "for", "tup", "in", "dataset_orderingfracdistribs", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "list_of_ordering_names", ")", ")", ":", "\n", "            ", "ordering_name", "=", "list_of_ordering_names", "[", "i", "]", "\n", "tup_ordering_list", "=", "tup", "[", "i", "+", "1", "]", "\n", "for", "data_point", "in", "tup_ordering_list", ":", "\n", "                ", "row_dict", "=", "{", "title_of_each_graph", ":", "tup", "[", "0", "]", ",", "\n", "\"AllTheSameInCol\"", ":", "\"filler\"", ",", "\n", "\"Ranking Scheme\"", ":", "ordering_name", ",", "\n", "y_axis_title", ":", "data_point", "}", "\n", "list_of_row_dicts", ".", "append", "(", "row_dict", ")", "\n", "", "", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "2", ")", ")", "\n", "\n", "ax", "=", "sns", ".", "boxplot", "(", "x", "=", "title_of_each_graph", ",", "y", "=", "y_axis_title", ",", "\n", "hue", "=", "\"Ranking Scheme\"", ",", "palette", "=", "palette", ",", "\n", "data", "=", "data_to_plot", ")", "\n", "ax", ".", "set_title", "(", "plot_title", ")", "\n", "ax", ".", "set_yticks", "(", "[", "0", ",", ".25", ",", ".5", ",", ".75", ",", "1", "]", ")", "\n", "ax", ".", "legend_", ".", "remove", "(", ")", "\n", "sns", ".", "despine", "(", "offset", "=", "20", ",", "trim", "=", "True", ")", "\n", "\n", "if", "(", "'han'", "in", "model", "or", "\"HAN\"", "in", "model", ")", "and", "'rnn'", "in", "model", ":", "\n", "        ", "if", "'conv'", "not", "in", "model", ":", "\n", "            ", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ",", "prop", "=", "{", "'size'", ":", "10", "}", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ",", "prop", "=", "{", "'size'", ":", "10", "}", ")", "\n", "", "", "plt", ".", "savefig", "(", "images_dir", "+", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n", "if", "'HANnoenc'", "in", "plot_title", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "2", ")", ")", "\n", "\n", "ax", "=", "sns", ".", "boxplot", "(", "x", "=", "title_of_each_graph", ",", "y", "=", "y_axis_title", ",", "\n", "hue", "=", "\"Ranking Scheme\"", ",", "palette", "=", "palette", ",", "\n", "data", "=", "data_to_plot", ")", "\n", "ax", ".", "set_title", "(", "plot_title", ")", "\n", "ax", ".", "set_yticks", "(", "[", "0", ",", ".25", ",", ".5", ",", ".75", ",", "1", "]", ")", "\n", "ax", ".", "legend_", ".", "remove", "(", ")", "\n", "sns", ".", "despine", "(", "offset", "=", "20", ",", "trim", "=", "True", ")", "\n", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ",", "prop", "=", "{", "'size'", ":", "10", "}", ")", "\n", "if", "filename", ".", "endswith", "(", "'.png'", ")", ":", "\n", "            ", "filename", "=", "filename", "[", ":", "filename", ".", "rfind", "(", "'.'", ")", "]", "\n", "", "plt", ".", "savefig", "(", "images_dir", "+", "filename", "+", "'_withlegend'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_hists": [[574, 599], ["pandas.DataFrame", "matplotlib.figure", "seaborn.FacetGrid", "sns.FacetGrid.set", "sns.FacetGrid.map", "matplotlib.savefig", "matplotlib.close", "range", "numpy.arange", "list_of_row_dicts.append", "print", "print"], "function", ["None"], ["", "", "def", "make_hists", "(", "filename", ",", "dataset_xval_tups", ",", "\n", "y_axis_title", "=", "\"Fraction of Original Attention\\nWeights Removed\"", ")", ":", "\n", "    ", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "for", "tup", "in", "dataset_xval_tups", ":", "\n", "        ", "x_vals", "=", "tup", "[", "1", "]", "\n", "try", ":", "\n", "            ", "for", "i", "in", "range", "(", "x_vals", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "row_dict", "=", "{", "title_of_each_graph", ":", "tup", "[", "0", "]", ",", "\n", "\"AllTheSameInCol\"", ":", "\"filler\"", ",", "\n", "\"Difference in Attention Weights\"", ":", "x_vals", "[", "i", "]", "}", "\n", "list_of_row_dicts", ".", "append", "(", "row_dict", ")", "\n", "", "", "except", ":", "\n", "            ", "print", "(", "x_vals", ")", "\n", "print", "(", "x_vals", ".", "shape", ")", "\n", "", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "\n", "g", "=", "sns", ".", "FacetGrid", "(", "data_to_plot", ",", "col", "=", "title_of_each_graph", ",", "sharey", "=", "False", ",", "col_wrap", "=", "2", ",", "aspect", "=", "1.5", ")", "\n", "g", ".", "set", "(", "xticks", "=", "(", "np", ".", "arange", "(", "0.0", ",", "1.2", ",", "0.2", ")", ")", ")", "\n", "g", ".", "map", "(", "sns", ".", "distplot", ",", "\"Difference in Attention Weights\"", ",", "kde", "=", "False", ",", "rug", "=", "False", ")", "\n", "\n", "plt", ".", "savefig", "(", "images_dir", "+", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set": [[601, 639], ["pandas.DataFrame", "print", "seaborn.FacetGrid", "sns.FacetGrid.map", "sns.FacetGrid.set", "matplotlib.ylim", "matplotlib.xlim", "print", "matplotlib.savefig", "range", "len", "len", "len", "numpy.arange", "list_of_row_dicts.append", "print"], "function", ["None"], ["", "def", "make_2x2_regression_set", "(", "tuples_of_title_x_y", ",", "filename", ",", "y_label", "=", "\"Log difference in JS divergences\\n\"", "+", "\n", "\"from original output distribution\"", ",", "vs_avg", "=", "True", ")", ":", "\n", "    ", "if", "vs_avg", ":", "\n", "        ", "x_label", "=", "\"Difference in (average) zeroed attention\\nweight magnitude\"", "\n", "", "else", ":", "\n", "        ", "x_label", "=", "\"Difference in zeroed attention weight magnitude\"", "\n", "", "if", "not", "vs_avg", ":", "\n", "        ", "y_label", "=", "\"Log difference in JS divergences from\\noriginal output distribution\"", "\n", "", "title_of_each_graph", "=", "\"Dataset\"", "\n", "list_of_row_dicts", "=", "[", "]", "\n", "if", "y_label", "==", "\"Differences in JS divergences\"", ":", "\n", "        ", "pass", "\n", "", "for", "tup", "in", "tuples_of_title_x_y", ":", "\n", "        ", "assert", "len", "(", "tup", "[", "1", "]", ")", "==", "len", "(", "tup", "[", "2", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "tup", "[", "1", "]", ")", ")", ":", "\n", "            ", "if", "True", "or", "\"flip\"", "in", "y_label", "or", "tup", "[", "2", "]", "[", "i", "]", "<", "2.5", ":", "\n", "                ", "list_of_row_dicts", ".", "append", "(", "{", "title_of_each_graph", ":", "tup", "[", "0", "]", ",", "x_label", ":", "tup", "[", "1", "]", "[", "i", "]", ",", "y_label", ":", "tup", "[", "2", "]", "[", "i", "]", ",", "\n", "\"AllTheSameInCol\"", ":", "\"filler\"", "}", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Excluding a data point for \"", "+", "y_label", ")", "\n", "", "", "", "data_to_plot", "=", "pd", ".", "DataFrame", "(", "list_of_row_dicts", ")", "\n", "marker_format_dict", "=", "{", "'alpha'", ":", "0.3", ",", "'s'", ":", "2", "}", "\n", "if", "'flip'", "in", "y_label", ":", "\n", "        ", "marker_format_dict", "[", "\"s\"", "]", "=", "10", "\n", "", "print", "(", "data_to_plot", ".", "shape", ")", "\n", "\"\"\"g = sns.FacetGrid(data = data_to_plot,  col=title_of_each_graph, hue=\"AllTheSameInCol\", palette=None,\n                    col_wrap = 2, sharey=False, sharex=False) #legend=False,\n                   #scatter_kws=marker_format_dict, )\n    g = g.map(plt.scatter, x=x_label, y=y_label, )\"\"\"", "\n", "\n", "g", "=", "sns", ".", "FacetGrid", "(", "data_to_plot", ",", "col", "=", "title_of_each_graph", ",", "col_wrap", "=", "2", ",", "aspect", "=", "1.2", ")", "\n", "g", ".", "map", "(", "plt", ".", "scatter", ",", "x_label", ",", "y_label", ",", "alpha", "=", "0.15", ",", "s", "=", "2", ")", "\n", "g", ".", "set", "(", "xticks", "=", "(", "np", ".", "arange", "(", "0.0", ",", "1.2", ",", "0.2", ")", ")", ")", "\n", "plt", ".", "ylim", "(", "-", "0.05", ",", "0.45", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "1", ")", "\n", "\n", "print", "(", "\"Saving file to \"", "+", "filename", ")", "\n", "plt", ".", "savefig", "(", "images_dir", "+", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.test_plots": [[641, 653], ["tuples_of_title_x_y.append", "tuples_of_title_x_y.append", "tuples_of_title_x_y.append", "tuples_of_title_x_y.append", "figure_maker.make_2x2_regression_set", "figure_maker.make_2x2_regression_set", "os.path.isdir", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set"], ["", "def", "test_plots", "(", ")", ":", "\n", "    ", "tuples_of_title_x_y", "=", "[", "]", "\n", "tuples_of_title_x_y", ".", "append", "(", "(", "\"Amazon\"", ",", "[", "0", ",", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", "]", ",", "[", ".1", ",", ".3", ",", ".5", ",", ".2", ",", ".4", ",", ".7", "]", ")", ")", "\n", "tuples_of_title_x_y", ".", "append", "(", "(", "\"Yelp\"", ",", "[", "0", ",", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", "]", ",", "[", ".1", ",", ".3", ",", ".5", ",", ".2", ",", ".4", ",", ".7", "]", ")", ")", "\n", "tuples_of_title_x_y", ".", "append", "(", "(", "\"Yahoo\"", ",", "[", "0", ",", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", "]", ",", "[", ".1", ",", ".3", ",", ".5", ",", ".2", ",", ".4", ",", ".7", "]", ")", ")", "\n", "tuples_of_title_x_y", ".", "append", "(", "(", "\"IMDB\"", ",", "[", "0", ",", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", "]", ",", "[", ".1", ",", ".3", ",", ".5", ",", ".2", ",", ".4", ",", ".7", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "\"testimagedir/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "\"testimagedir/\"", ")", "\n", "", "filename", "=", "\"testimagedir/regression\"", "\n", "make_2x2_regression_set", "(", "tuples_of_title_x_y", ",", "filename", ")", "\n", "filename", "=", "\"testimagedir/regression2\"", "\n", "make_2x2_regression_set", "(", "tuples_of_title_x_y", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data": [[655, 664], ["range", "numpy.array", "random.random", "rand_ind_list.append", "rand_ind_list.append"], "function", ["None"], ["", "def", "dec_table_size_to_keep_x_pct_of_data", "(", "x", ",", "table", ")", ":", "\n", "    ", "rand_ind_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "table", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "random", "(", ")", "<", "x", ":", "\n", "            ", "rand_ind_list", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "rand_ind_list", ".", "append", "(", "0", ")", "\n", "", "", "np_ind_mask", "=", "np", ".", "array", "(", "rand_ind_list", ",", "dtype", "=", "bool", ")", "\n", "return", "table", "[", "np_ind_mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots": [[666, 762], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "list", "sorted", "print", "print", "print", "figure_maker.make_fracremoved_boxplots", "yahoo_tag.endswith", "len", "imdb_tag.endswith", "len", "amazon_tag.endswith", "len", "yelp_tag.endswith", "len", "model_tag.startswith", "model_tag.startswith", "str", "str", "str", "model_tag.startswith", "model_tag.startswith", "model_tag.startswith", "int", "int", "int", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_fracremoved_boxplots"], ["", "def", "make_boxplots", "(", "model_tag", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "yahoo_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yahoo_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yahoo_tag", ")", ">", "1", ":", "\n", "        ", "yahoo_tag", "=", "'-'", "+", "yahoo_tag", "\n", "", "if", "not", "imdb_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "imdb_tag", "+=", "'/'", "\n", "", "if", "len", "(", "imdb_tag", ")", ">", "1", ":", "\n", "        ", "imdb_tag", "=", "'-'", "+", "imdb_tag", "\n", "", "if", "not", "amazon_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "amazon_tag", "+=", "'/'", "\n", "", "if", "len", "(", "amazon_tag", ")", ">", "1", ":", "\n", "        ", "amazon_tag", "=", "'-'", "+", "amazon_tag", "\n", "", "if", "not", "yelp_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yelp_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yelp_tag", ")", ">", "1", ":", "\n", "        ", "yelp_tag", "=", "'-'", "+", "yelp_tag", "\n", "", "print", "(", "\"Starting to make fraction-removed boxplot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanconv_table", "\n", "imdb_table", "=", "imdb_hanconv_table", "\n", "amazon_table", "=", "amazon_hanconv_table", "\n", "yelp_table", "=", "yelp_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "model_name", "=", "'HANconvs'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanrnn_table", "\n", "imdb_table", "=", "imdb_hanrnn_table", "\n", "amazon_table", "=", "amazon_hanrnn_table", "\n", "yelp_table", "=", "yelp_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "'HANrnns'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanencless'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanencless_table", "\n", "imdb_table", "=", "imdb_hanencless_table", "\n", "amazon_table", "=", "amazon_hanencless_table", "\n", "yelp_table", "=", "yelp_hanencless_table", "\n", "model", "=", "'hanencless'", "\n", "model_name", "=", "\"HANnoencs\"", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanconv_table", "\n", "imdb_table", "=", "imdb_flanconv_table", "\n", "amazon_table", "=", "amazon_flanconv_table", "\n", "yelp_table", "=", "yelp_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconvs'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanrnn_table", "\n", "imdb_table", "=", "imdb_flanrnn_table", "\n", "amazon_table", "=", "amazon_flanrnn_table", "\n", "yelp_table", "=", "yelp_flanrnn_table", "\n", "model_name", "=", "'FLANrnns'", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanencless'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanencless_table", "\n", "imdb_table", "=", "imdb_flanencless_table", "\n", "amazon_table", "=", "amazon_flanencless_table", "\n", "yelp_table", "=", "yelp_flanencless_table", "\n", "model", "=", "'flanencless'", "\n", "model_name", "=", "\"FLANnoencs\"", "\n", "is_han", "=", "False", "\n", "", "list_of_ordering_names", "=", "[", "\"Random\"", ",", "\"Attention\"", ",", "\"Gradient\"", "]", "\n", "yahoo_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "yahoo_table", ")", "\n", "imdb_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "imdb_table", ")", "\n", "amazon_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "amazon_table", ")", "\n", "yelp_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "yelp_table", ")", "\n", "yahoo_model_tup", "=", "(", "\"Yahoo\"", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ")", "\n", "yahoo_by_attn", "=", "list", "(", "yahoo_model_tup", "[", "2", "]", ")", "\n", "sorted_yahoo_by_attn", "=", "sorted", "(", "yahoo_by_attn", ")", "\n", "print", "(", "\"Upper quartile of yahoo: \"", "+", "str", "(", "sorted_yahoo_by_attn", "[", "3", "*", "int", "(", "len", "(", "yahoo_by_attn", ")", "/", "4", ")", "]", ")", ")", "\n", "print", "(", "\"Median of yahoo: \"", "+", "str", "(", "sorted_yahoo_by_attn", "[", "int", "(", "len", "(", "yahoo_by_attn", ")", "/", "2", ")", "]", ")", ")", "\n", "print", "(", "\"Lower quartile of yahoo: \"", "+", "str", "(", "sorted_yahoo_by_attn", "[", "int", "(", "len", "(", "yahoo_by_attn", ")", "/", "4", ")", "]", ")", ")", "\n", "imdb_model_tup", "=", "(", "\"IMDB\"", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ")", "\n", "amazon_model_tup", "=", "(", "\"Amazon\"", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ")", "\n", "yelp_model_tup", "=", "(", "\"Yelp\"", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ")", "\n", "make_fracremoved_boxplots", "(", "model_tag", "+", "\"_fracremoved_boxplots\"", ",", "list_of_ordering_names", ",", "\n", "[", "yahoo_model_tup", ",", "imdb_model_tup", ",", "amazon_model_tup", ",", "yelp_model_tup", "]", ",", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots_with_four": [[764, 875], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "list", "sorted", "print", "print", "print", "model_tag.startswith", "figure_maker.make_fracremoved_boxplots", "yahoo_tag.endswith", "len", "imdb_tag.endswith", "len", "amazon_tag.endswith", "len", "yelp_tag.endswith", "len", "model_tag.startswith", "print", "range", "model_tag.startswith", "str", "str", "str", "len", "print", "model_tag.startswith", "model_tag.startswith", "str", "model_tag.startswith", "int", "int", "int", "str", "numpy.sum", "len", "len", "len", "str", "numpy.sum", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_fracremoved_boxplots"], ["", "def", "make_boxplots_with_four", "(", "model_tag", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "yahoo_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yahoo_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yahoo_tag", ")", ">", "1", ":", "\n", "        ", "yahoo_tag", "=", "'-'", "+", "yahoo_tag", "\n", "", "if", "not", "imdb_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "imdb_tag", "+=", "'/'", "\n", "", "if", "len", "(", "imdb_tag", ")", ">", "1", ":", "\n", "        ", "imdb_tag", "=", "'-'", "+", "imdb_tag", "\n", "", "if", "not", "amazon_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "amazon_tag", "+=", "'/'", "\n", "", "if", "len", "(", "amazon_tag", ")", ">", "1", ":", "\n", "        ", "amazon_tag", "=", "'-'", "+", "amazon_tag", "\n", "", "if", "not", "yelp_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yelp_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yelp_tag", ")", ">", "1", ":", "\n", "        ", "yelp_tag", "=", "'-'", "+", "yelp_tag", "\n", "", "print", "(", "\"Starting to make fraction-removed boxplot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanconv_table", "\n", "imdb_table", "=", "imdb_hanconv_table", "\n", "amazon_table", "=", "amazon_hanconv_table", "\n", "yelp_table", "=", "yelp_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "model_name", "=", "'HANconvs'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanrnn_table", "\n", "imdb_table", "=", "imdb_hanrnn_table", "\n", "amazon_table", "=", "amazon_hanrnn_table", "\n", "yelp_table", "=", "yelp_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "'HANrnns'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanencless'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanencless_table", "\n", "imdb_table", "=", "imdb_hanencless_table", "\n", "amazon_table", "=", "amazon_hanencless_table", "\n", "yelp_table", "=", "yelp_hanencless_table", "\n", "model", "=", "'hanencless'", "\n", "model_name", "=", "\"HANnoencs\"", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanconv_table", "\n", "imdb_table", "=", "imdb_flanconv_table", "\n", "amazon_table", "=", "amazon_flanconv_table", "\n", "yelp_table", "=", "yelp_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconvs'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanrnn_table", "\n", "imdb_table", "=", "imdb_flanrnn_table", "\n", "amazon_table", "=", "amazon_flanrnn_table", "\n", "yelp_table", "=", "yelp_flanrnn_table", "\n", "model_name", "=", "'FLANrnns'", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanencless'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanencless_table", "\n", "imdb_table", "=", "imdb_flanencless_table", "\n", "amazon_table", "=", "amazon_flanencless_table", "\n", "yelp_table", "=", "yelp_flanencless_table", "\n", "model", "=", "'flanencless'", "\n", "model_name", "=", "\"FLANnoencs\"", "\n", "is_han", "=", "False", "\n", "", "list_of_ordering_names", "=", "[", "\"Random\"", ",", "\"Attention\"", ",", "\"Gradient\"", ",", "\"Attn * Grad\"", "]", "\n", "yahoo_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "yahoo_table", ")", "\n", "imdb_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "imdb_table", ")", "\n", "amazon_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "amazon_table", ")", "\n", "yelp_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "yelp_table", ")", "\n", "yahoo_model_tup", "=", "(", "\"Yahoo\"", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "[", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", "]", ")", "\n", "yahoo_by_attn", "=", "list", "(", "yahoo_model_tup", "[", "2", "]", ")", "\n", "sorted_yahoo_by_attn", "=", "sorted", "(", "yahoo_by_attn", ")", "\n", "print", "(", "\"Upper quartile of yahoo: \"", "+", "str", "(", "sorted_yahoo_by_attn", "[", "3", "*", "int", "(", "len", "(", "yahoo_by_attn", ")", "/", "4", ")", "]", ")", ")", "\n", "print", "(", "\"Median of yahoo: \"", "+", "str", "(", "sorted_yahoo_by_attn", "[", "int", "(", "len", "(", "yahoo_by_attn", ")", "/", "2", ")", "]", ")", ")", "\n", "print", "(", "\"Lower quartile of yahoo: \"", "+", "str", "(", "sorted_yahoo_by_attn", "[", "int", "(", "len", "(", "yahoo_by_attn", ")", "/", "4", ")", "]", ")", ")", "\n", "imdb_model_tup", "=", "(", "\"IMDB\"", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "[", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", "]", ")", "\n", "amazon_model_tup", "=", "(", "\"Amazon\"", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "[", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", "]", ",", ")", "\n", "yelp_model_tup", "=", "(", "\"Yelp\"", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_RAND_FRAC_X_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "[", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_FRAC_X_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", "]", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'flanencless'", ")", ":", "\n", "# print stats on amazon for reporting purposes", "\n", "        ", "four_cats", "=", "[", "'random'", ",", "'attn'", ",", "'grad'", ",", "'gradmult'", "]", "\n", "print", "(", "'Amazon FLANnoenc info:'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "four_cats", ")", ")", ":", "\n", "            ", "vals", "=", "amazon_model_tup", "[", "i", "+", "1", "]", "\n", "print", "(", "'\\t'", "+", "four_cats", "[", "i", "]", "+", "'\\t>.25: '", "+", "str", "(", "np", ".", "sum", "(", "vals", ">", ".25", ")", "/", "vals", ".", "shape", "[", "0", "]", ")", "+", "'\\t>.5: '", "+", "str", "(", "np", ".", "sum", "(", "vals", ">", ".5", ")", "/", "vals", ".", "shape", "[", "0", "]", ")", "+", "'\\t>.75: '", "+", "str", "(", "np", ".", "sum", "(", "vals", ">", ".75", ")", "/", "vals", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "", "make_fracremoved_boxplots", "(", "model_tag", "+", "\"_fracremoved_boxplots\"", ",", "list_of_ordering_names", ",", "\n", "[", "yahoo_model_tup", ",", "imdb_model_tup", ",", "amazon_model_tup", ",", "yelp_model_tup", "]", ",", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots": [[877, 977], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.dec_table_size_to_keep_x_pct_of_data", "figure_maker.make_fracremoved_boxplots", "yahoo_tag.endswith", "len", "imdb_tag.endswith", "len", "amazon_tag.endswith", "len", "yelp_tag.endswith", "len", "model_tag.startswith", "model_tag.startswith", "model_tag.startswith", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.dec_table_size_to_keep_x_pct_of_data", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_fracremoved_boxplots"], ["", "def", "make_probmass_boxplots", "(", "model_tag", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "yahoo_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yahoo_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yahoo_tag", ")", ">", "1", ":", "\n", "        ", "yahoo_tag", "=", "'-'", "+", "yahoo_tag", "\n", "", "if", "not", "imdb_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "imdb_tag", "+=", "'/'", "\n", "", "if", "len", "(", "imdb_tag", ")", ">", "1", ":", "\n", "        ", "imdb_tag", "=", "'-'", "+", "imdb_tag", "\n", "", "if", "not", "amazon_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "amazon_tag", "+=", "'/'", "\n", "", "if", "len", "(", "amazon_tag", ")", ">", "1", ":", "\n", "        ", "amazon_tag", "=", "'-'", "+", "amazon_tag", "\n", "", "if", "not", "yelp_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yelp_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yelp_tag", ")", ">", "1", ":", "\n", "        ", "yelp_tag", "=", "'-'", "+", "yelp_tag", "\n", "", "print", "(", "\"Starting to make probmass-removed boxplot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanconv_table", "\n", "imdb_table", "=", "imdb_hanconv_table", "\n", "amazon_table", "=", "amazon_hanconv_table", "\n", "yelp_table", "=", "yelp_hanconv_table", "\n", "model_name", "=", "'HANconvs'", "\n", "model", "=", "'hanconv'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanrnn_table", "\n", "imdb_table", "=", "imdb_hanrnn_table", "\n", "amazon_table", "=", "amazon_hanrnn_table", "\n", "yelp_table", "=", "yelp_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "model_name", "=", "\"HANrnns\"", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanencless'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanencless_table", "\n", "imdb_table", "=", "imdb_hanencless_table", "\n", "amazon_table", "=", "amazon_hanencless_table", "\n", "yelp_table", "=", "yelp_hanencless_table", "\n", "model", "=", "'hanencless'", "\n", "model_name", "=", "\"HANnoencs\"", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanconv_table", "\n", "imdb_table", "=", "imdb_flanconv_table", "\n", "amazon_table", "=", "amazon_flanconv_table", "\n", "yelp_table", "=", "yelp_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "model_name", "=", "'FLANconvs'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanrnn_table", "\n", "imdb_table", "=", "imdb_flanrnn_table", "\n", "amazon_table", "=", "amazon_flanrnn_table", "\n", "yelp_table", "=", "yelp_flanrnn_table", "\n", "model", "=", "'flanrnn'", "\n", "model_name", "=", "'FLANrnns'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanencless'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanencless_table", "\n", "imdb_table", "=", "imdb_flanencless_table", "\n", "amazon_table", "=", "amazon_flanencless_table", "\n", "yelp_table", "=", "yelp_flanencless_table", "\n", "model", "=", "'flanencless'", "\n", "model_name", "=", "\"FLANnoencs\"", "\n", "is_han", "=", "False", "\n", "", "list_of_ordering_names", "=", "[", "\"Random\"", ",", "\"Attention\"", ",", "\"Gradient\"", ",", "\"Attn * Grad\"", "]", "\n", "yahoo_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "yahoo_table", ")", "\n", "imdb_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "imdb_table", ")", "\n", "amazon_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "amazon_table", ")", "\n", "yelp_table", "=", "dec_table_size_to_keep_x_pct_of_data", "(", "1", ",", "yelp_table", ")", "\n", "yahoo_model_tup", "=", "(", "\"Yahoo\"", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "[", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ",", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "]", "[", "\n", "yahoo_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", "]", ")", "\n", "imdb_model_tup", "=", "(", "\"IMDB\"", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "[", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ",", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "]", "[", "\n", "imdb_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", "]", ")", "\n", "amazon_model_tup", "=", "(", "\"Amazon\"", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "[", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ",", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "]", "[", "\n", "amazon_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", "]", ")", "\n", "yelp_model_tup", "=", "(", "\"Yelp\"", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_RAND_PROBMASS_FOR_DECFLIP_START", "]", "!=", "-", "1", "]", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP", "]", "!=", "-", "1", "]", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "[", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRAD", "]", "!=", "-", "1", "]", ",", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "]", "[", "\n", "yelp_table", "[", ":", ",", "NEEDED_REM_TOP_PROBMASS_FOR_DECFLIP_GRADMULT", "]", "!=", "-", "1", "]", ")", "\n", "make_fracremoved_boxplots", "(", "model_tag", "+", "\"_probmassremoved_boxplots\"", ",", "list_of_ordering_names", ",", "\n", "[", "yahoo_model_tup", ",", "imdb_model_tup", ",", "amazon_model_tup", ",", "yelp_model_tup", "]", ",", "model_name", ",", "\n", "y_axis_title", "=", "\"Probability Mass of Original\\nAttention Dist Removed\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_decflip_regression_plot": [[979, 1039], ["print", "model_tag.startswith", "figure_maker.make_rand_decflip_model_tup", "figure_maker.make_rand_decflip_model_tup", "figure_maker.make_rand_decflip_model_tup", "figure_maker.make_rand_decflip_model_tup", "figure_maker.make_2x2_vsrand_decflip_stackplot", "print", "model_tag.startswith", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_vsrand_decflip_stackplot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_decflip_regression_plot", "(", "model_tag", ")", ":", "\n", "    ", "print", "(", "\"Starting to make a decision flip plot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanconv_table", "\n", "imdb_table", "=", "imdb_hanconv_table", "\n", "amazon_table", "=", "amazon_hanconv_table", "\n", "yelp_table", "=", "yelp_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanrnn_table", "\n", "imdb_table", "=", "imdb_hanrnn_table", "\n", "amazon_table", "=", "amazon_hanrnn_table", "\n", "yelp_table", "=", "yelp_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanconv_table", "\n", "imdb_table", "=", "imdb_flanconv_table", "\n", "amazon_table", "=", "amazon_flanconv_table", "\n", "yelp_table", "=", "yelp_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanrnn_table", "\n", "imdb_table", "=", "imdb_flanrnn_table", "\n", "amazon_table", "=", "amazon_flanrnn_table", "\n", "yelp_table", "=", "yelp_flanrnn_table", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "if", "is_han", ":", "\n", "        ", "yahoo_mask", "=", "yahoo_han_mask", "\n", "imdb_mask", "=", "imdb_han_mask", "\n", "amazon_mask", "=", "amazon_han_mask", "\n", "yelp_mask", "=", "yelp_han_mask", "\n", "", "else", ":", "\n", "        ", "yahoo_mask", "=", "yahoo_flan_mask", "\n", "imdb_mask", "=", "imdb_flan_mask", "\n", "amazon_mask", "=", "amazon_flan_mask", "\n", "yelp_mask", "=", "yelp_flan_mask", "\n", "", "yahoo_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'yahoo10cat-'", "+", "model_tag", ")", "[", "yahoo_mask", "]", "\n", "yahoo_model_tup", "=", "make_rand_decflip_model_tup", "(", "yahoo_highestattnweights", ",", "yahoo_table", ",", "\"Yahoo\"", ")", "\n", "\n", "imdb_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'imdb-'", "+", "model_tag", ")", "[", "imdb_mask", "]", "\n", "imdb_model_tup", "=", "make_rand_decflip_model_tup", "(", "imdb_highestattnweights", ",", "imdb_table", ",", "\"IMDB\"", ")", "\n", "\n", "amazon_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'amazon-'", "+", "model_tag", ")", "[", "amazon_mask", "]", "\n", "amazon_model_tup", "=", "make_rand_decflip_model_tup", "(", "amazon_highestattnweights", ",", "amazon_table", ",", "\"Amazon\"", ")", "\n", "\n", "yelp_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'yelp-'", "+", "model_tag", ")", "[", "yelp_mask", "]", "\n", "yelp_model_tup", "=", "make_rand_decflip_model_tup", "(", "yelp_highestattnweights", ",", "yelp_table", ",", "\"Yelp\"", ")", "\n", "\n", "#make_2x2_vsrand_decflip_violinplot([yahoo_hanrnn_tup, imdb_hanrnn_tup], \"differences_in_decflips_\" + model)", "\n", "make_2x2_vsrand_decflip_stackplot", "(", "[", "yahoo_model_tup", ",", "imdb_model_tup", ",", "amazon_model_tup", ",", "yelp_model_tup", "]", ",", "\n", "\"differences_in_decflips_\"", "+", "model", ",", ".05", ")", "\n", "print", "(", "\"Finished making a decision flip plot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_decflip_regression_plot_vs2ndhighest": [[1041, 1137], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker.make_vs2nd_decflip_model_tup", "figure_maker.make_vs2nd_decflip_model_tup", "figure_maker.make_vs2nd_decflip_model_tup", "figure_maker.make_vs2nd_decflip_model_tup", "figure_maker.make_2x2_vsrand_decflip_stackplot", "print", "yahoo_tag.endswith", "len", "imdb_tag.endswith", "len", "amazon_tag.endswith", "len", "yelp_tag.endswith", "len", "model_tag.startswith", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_decflip_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_vsrand_decflip_stackplot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_decflip_regression_plot_vs2ndhighest", "(", "model_tag", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "yahoo_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yahoo_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yahoo_tag", ")", ">", "1", ":", "\n", "        ", "yahoo_tag", "=", "'-'", "+", "yahoo_tag", "\n", "", "if", "not", "imdb_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "imdb_tag", "+=", "'/'", "\n", "", "if", "len", "(", "imdb_tag", ")", ">", "1", ":", "\n", "        ", "imdb_tag", "=", "'-'", "+", "imdb_tag", "\n", "", "if", "not", "amazon_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "amazon_tag", "+=", "'/'", "\n", "", "if", "len", "(", "amazon_tag", ")", ">", "1", ":", "\n", "        ", "amazon_tag", "=", "'-'", "+", "amazon_tag", "\n", "", "if", "not", "yelp_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yelp_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yelp_tag", ")", ">", "1", ":", "\n", "        ", "yelp_tag", "=", "'-'", "+", "yelp_tag", "\n", "", "print", "(", "\"Starting to make a decision flip plot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanconv_table", "\n", "imdb_table", "=", "imdb_hanconv_table", "\n", "amazon_table", "=", "amazon_hanconv_table", "\n", "yelp_table", "=", "yelp_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanrnn_table", "\n", "imdb_table", "=", "imdb_hanrnn_table", "\n", "amazon_table", "=", "amazon_hanrnn_table", "\n", "yelp_table", "=", "yelp_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanconv_table", "\n", "imdb_table", "=", "imdb_flanconv_table", "\n", "amazon_table", "=", "amazon_flanconv_table", "\n", "yelp_table", "=", "yelp_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanrnn_table", "\n", "imdb_table", "=", "imdb_flanrnn_table", "\n", "amazon_table", "=", "amazon_flanrnn_table", "\n", "yelp_table", "=", "yelp_flanrnn_table", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "if", "is_han", ":", "\n", "        ", "yahoo_mask", "=", "yahoo_han_mask", "\n", "imdb_mask", "=", "imdb_han_mask", "\n", "amazon_mask", "=", "amazon_han_mask", "\n", "yelp_mask", "=", "yelp_han_mask", "\n", "", "else", ":", "\n", "        ", "yahoo_mask", "=", "yahoo_flan_mask", "\n", "imdb_mask", "=", "imdb_flan_mask", "\n", "amazon_mask", "=", "amazon_flan_mask", "\n", "yelp_mask", "=", "yelp_flan_mask", "\n", "", "yahoo_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'yahoo10cat-'", "+", "model_tag", "+", "\n", "yahoo_tag", ")", "[", "yahoo_mask", "]", "\n", "yahoo_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "'yahoo10cat-'", "+", "model_tag", "+", "\n", "yahoo_tag", ")", "[", "yahoo_mask", "]", "\n", "yahoo_model_tup", "=", "make_vs2nd_decflip_model_tup", "(", "yahoo_highestattnweights", ",", "yahoo_2ndhighestattnweights", ",", "yahoo_table", ",", "\n", "\"Yahoo\"", ")", "\n", "imdb_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'imdb-'", "+", "model_tag", "+", "\n", "imdb_tag", ")", "[", "imdb_mask", "]", "\n", "imdb_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "'imdb-'", "+", "model_tag", "+", "\n", "imdb_tag", ")", "[", "imdb_mask", "]", "\n", "imdb_model_tup", "=", "make_vs2nd_decflip_model_tup", "(", "imdb_highestattnweights", ",", "imdb_2ndhighestattnweights", ",", "imdb_table", ",", "\n", "\"IMDB\"", ")", "\n", "\n", "amazon_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'amazon-'", "+", "model_tag", "+", "\n", "amazon_tag", ")", "[", "amazon_mask", "]", "\n", "amazon_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "'amazon-'", "+", "model_tag", "+", "\n", "amazon_tag", ")", "[", "amazon_mask", "]", "\n", "amazon_model_tup", "=", "make_vs2nd_decflip_model_tup", "(", "amazon_highestattnweights", ",", "amazon_2ndhighestattnweights", ",", "amazon_table", ",", "\n", "\"Amazon\"", ")", "\n", "yelp_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'yelp-'", "+", "model_tag", "+", "\n", "yelp_tag", ")", "[", "yelp_mask", "]", "\n", "yelp_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "'yelp-'", "+", "model_tag", "+", "\n", "yelp_tag", ")", "[", "yelp_mask", "]", "\n", "yelp_model_tup", "=", "make_vs2nd_decflip_model_tup", "(", "yelp_highestattnweights", ",", "yelp_2ndhighestattnweights", ",", "yelp_table", ",", "\n", "\"Yelp\"", ")", "\n", "\n", "#make_2x2_vsrand_decflip_violinplot([yahoo_hanrnn_tup, imdb_hanrnn_tup], \"differences_in_decflips_\" + model)", "\n", "make_2x2_vsrand_decflip_stackplot", "(", "[", "yahoo_model_tup", ",", "imdb_model_tup", ",", "amazon_model_tup", ",", "yelp_model_tup", "]", ",", "\"differences_in_decflips_vs2nd_\"", "+", "model", ",", ".05", ",", "\n", "vs_avg", "=", "False", ")", "\n", "print", "(", "\"Finished making a decision flip plot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_decflip_model_tup": [[1139, 1160], ["range", "list", "list", "numpy.logical_and", "len", "range", "modified_list_1.append", "modified_list_2.append", "numpy.array", "random.random", "len", "len"], "function", ["None"], ["", "def", "make_vs2nd_decflip_model_tup", "(", "highestattnweights", ",", "secondhighestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "secondhighestattnweights", ")", ",", "\n", "list", "(", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "!=", "-", "1", ")", ".", "astype", "(", "float", ")", "-", "\n", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", "!=", "-", "1", ")", ".", "astype", "(", "float", ")", ")", ",", "\n", "np", ".", "logical_and", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "==", "-", "1", ",", "\n", "table", "[", ":", ",", "DEC_FLIP_ZERO_2NDHIGHEST", "]", "==", "-", "1", ")", "\n", ")", "\n", "return", "model_tup", "\n", "num_points_to_plot", "=", "500", "\n", "inds_to_pick", "=", "[", "(", "True", "if", "random", "(", ")", "<", "num_points_to_plot", "/", "len", "(", "model_tup", "[", "1", "]", ")", "else", "False", ")", "for", "\n", "i", "in", "range", "(", "len", "(", "model_tup", "[", "1", "]", ")", ")", "]", "\n", "modified_list_1", "=", "[", "]", "\n", "modified_list_2", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inds_to_pick", ")", ")", ":", "\n", "        ", "if", "inds_to_pick", "[", "i", "]", ":", "\n", "            ", "modified_list_1", ".", "append", "(", "model_tup", "[", "1", "]", "[", "i", "]", ")", "\n", "modified_list_2", ".", "append", "(", "model_tup", "[", "2", "]", "[", "i", "]", ")", "\n", "", "", "modified_arr_3", "=", "model_tup", "[", "3", "]", "[", "np", ".", "array", "(", "inds_to_pick", ",", "dtype", "=", "bool", ")", "]", "\n", "return", "(", "model_tup", "[", "0", "]", ",", "modified_list_1", ",", "modified_list_2", ",", "modified_arr_3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_decflip_model_tup": [[1162, 1191], ["numpy.logical_not().astype", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "list", "list", "numpy.logical_and", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "numpy.divide", "numpy.divide", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.multiply", "numpy.multiply"], "function", ["None"], ["", "def", "make_rand_decflip_model_tup", "(", "highestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "sampled_weights_that_were_max", "=", "(", "highestattnweights", "[", ":", ",", "None", "]", "==", "\n", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ")", "\n", "sampled_weights_that_werent_max", "=", "np", ".", "logical_not", "(", "sampled_weights_that_were_max", ")", ".", "astype", "(", "float", ")", "\n", "assert", "np", ".", "sum", "(", "sampled_weights_that_werent_max", ">", "1", ")", "==", "0", "\n", "num_sampled_weights_that_were_max", "=", "np", ".", "sum", "(", "sampled_weights_that_were_max", ",", "axis", "=", "1", ")", "\n", "all_sampled_weights_are_max", "=", "(", "num_sampled_weights_that_were_max", "==", "\n", "(", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "-", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ")", ")", "\n", "table", "=", "table", "[", "np", ".", "logical_not", "(", "all_sampled_weights_are_max", ")", "]", "\n", "highestattnweights", "=", "highestattnweights", "[", "np", ".", "logical_not", "(", "all_sampled_weights_are_max", ")", "]", "\n", "denom_array", "=", "np", ".", "sum", "(", "sampled_weights_that_werent_max", ",", "axis", "=", "1", ")", "\n", "assert", "np", ".", "sum", "(", "denom_array", "<", "0", ")", "==", "0", "\n", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "np", ".", "divide", "(", "(", "np", ".", "sum", "(", "np", ".", "multiply", "(", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ",", "\n", "sampled_weights_that_werent_max", ")", ",", "axis", "=", "1", ")", ")", ",", "\n", "denom_array", ")", ")", ",", "\n", "list", "(", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "!=", "-", "1", ")", ".", "astype", "(", "float", ")", "-", "\n", "np", ".", "divide", "(", "np", ".", "sum", "(", "np", ".", "multiply", "(", "table", "[", ":", ",", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", ":", "\n", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", "+", "1", "]", "==", "1", ",", "\n", "sampled_weights_that_werent_max", ")", ",", "axis", "=", "1", ")", ",", "\n", "denom_array", ")", ")", ",", "\n", "np", ".", "logical_and", "(", "table", "[", ":", ",", "DEC_FLIP_ZERO_HIGHEST", "]", "==", "-", "1", ",", "\n", "(", "np", ".", "sum", "(", "table", "[", ":", ",", "NEEDED_REM_RAND_X_FOR_DECFLIP_START", ":", "\n", "NEEDED_REM_RAND_X_FOR_DECFLIP_END", "+", "1", "]", "==", "1", ",", "axis", "=", "1", ")", "==", "0", ")", ")", "\n", ")", "\n", "return", "model_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_jsdiv_model_tup": [[1193, 1209], ["range", "list", "list", "len", "range", "modified_list_1.append", "modified_list_2.append", "table[].astype", "table[].astype", "random.random", "len", "len"], "function", ["None"], ["", "def", "make_vs2nd_jsdiv_model_tup", "(", "highestattnweights", ",", "secondhighestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "secondhighestattnweights", ")", ",", "\n", "list", "(", "(", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", ")", ".", "astype", "(", "float", ")", "-", "\n", "(", "table", "[", ":", ",", "JS_DIV_ZERO_2NDHIGHEST", "]", ")", ".", "astype", "(", "float", ")", ")", ")", "\n", "num_points_to_plot", "=", "500", "\n", "inds_to_pick", "=", "[", "(", "True", "if", "random", "(", ")", "<", "num_points_to_plot", "/", "len", "(", "model_tup", "[", "1", "]", ")", "else", "False", ")", "for", "\n", "i", "in", "range", "(", "len", "(", "model_tup", "[", "1", "]", ")", ")", "]", "\n", "modified_list_1", "=", "[", "]", "\n", "modified_list_2", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "inds_to_pick", ")", ")", ":", "\n", "        ", "if", "inds_to_pick", "[", "i", "]", ":", "\n", "            ", "modified_list_1", ".", "append", "(", "model_tup", "[", "1", "]", "[", "i", "]", ")", "\n", "modified_list_2", ".", "append", "(", "model_tup", "[", "2", "]", "[", "i", "]", ")", "\n", "", "", "return", "(", "model_tup", "[", "0", "]", ",", "modified_list_1", ",", "modified_list_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_jsdiv_model_tup": [[1211, 1218], ["list", "list"], "function", ["None"], ["", "def", "make_rand_jsdiv_model_tup", "(", "highestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "table", "[", ":", ",", "NONTOP_RAND_ZEROED_WEIGHT", "]", ")", ",", "\n", "list", "(", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", "-", "\n", "table", "[", ":", ",", "NONTOP_RAND_JS_DIV", "]", ")", ")", "\n", "return", "model_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_jsdiv_model_tup_sample5": [[1220, 1244], ["numpy.logical_not().astype", "numpy.sum", "list", "list", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "numpy.divide", "numpy.log", "numpy.divide", "numpy.sum", "numpy.sum", "numpy.multiply", "numpy.multiply", "numpy.log"], "function", ["None"], ["", "def", "make_rand_jsdiv_model_tup_sample5", "(", "highestattnweights", ",", "table", ",", "dataset_title", ")", ":", "\n", "    ", "sampled_weights_that_were_max", "=", "(", "highestattnweights", "[", ":", ",", "None", "]", "==", "\n", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ")", "\n", "sampled_weights_that_werent_max", "=", "np", ".", "logical_not", "(", "sampled_weights_that_were_max", ")", ".", "astype", "(", "float", ")", "\n", "num_sampled_weights_that_were_max", "=", "np", ".", "sum", "(", "sampled_weights_that_were_max", ",", "axis", "=", "1", ")", "\n", "all_sampled_weights_are_max", "=", "(", "num_sampled_weights_that_were_max", "==", "\n", "(", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "-", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ")", ")", "\n", "table", "=", "table", "[", "np", ".", "logical_not", "(", "all_sampled_weights_are_max", ")", "]", "\n", "highestattnweights", "=", "highestattnweights", "[", "np", ".", "logical_not", "(", "all_sampled_weights_are_max", ")", "]", "\n", "model_tup", "=", "(", "dataset_title", ",", "\n", "list", "(", "highestattnweights", "-", "\n", "np", ".", "divide", "(", "(", "np", ".", "sum", "(", "np", ".", "multiply", "(", "table", "[", ":", ",", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ":", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "]", ",", "\n", "sampled_weights_that_werent_max", ")", ",", "axis", "=", "1", ")", ")", ",", "\n", "(", "-", "1", "*", "num_sampled_weights_that_were_max", "+", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "-", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ")", ")", ")", ",", "\n", "list", "(", "np", ".", "log", "(", "table", "[", ":", ",", "JS_DIV_ZERO_HIGHEST", "]", ")", "-", "\n", "np", ".", "divide", "(", "np", ".", "sum", "(", "np", ".", "multiply", "(", "np", ".", "log", "(", "table", "[", ":", ",", "EXTRACTED_SINGLE_WEIGHT_JS_START", ":", "\n", "EXTRACTED_SINGLE_WEIGHT_JS_END", "+", "1", "]", ")", ",", "\n", "sampled_weights_that_werent_max", ")", ",", "axis", "=", "1", ")", ",", "\n", "(", "-", "1", "*", "num_sampled_weights_that_were_max", "+", "\n", "EXTRACTED_SINGLE_ATTN_WEIGHT_END", "+", "1", "-", "EXTRACTED_SINGLE_ATTN_WEIGHT_START", ")", ")", ")", ")", "\n", "return", "model_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot": [[1246, 1366], ["model_tag.endswith", "print", "model_tag.startswith", "figure_maker.make_rand_jsdiv_model_tup", "figure_maker.make_rand_jsdiv_model_tup", "figure_maker.make_rand_jsdiv_model_tup", "figure_maker.make_rand_jsdiv_model_tup", "figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "figure_maker.make_hists", "figure_maker.make_2x2_regression_set", "print", "yahoo_tag.endswith", "len", "imdb_tag.endswith", "len", "amazon_tag.endswith", "len", "yelp_tag.endswith", "len", "model_tag.startswith", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "model_tag.startswith", "model_tag.startswith", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_rand_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.convert_to_log_and_print_how_many_were_originally_negative", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.sample_x_datapoints_per_tenth_on_xaxis", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_hists", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_jsdiv_regression_plot", "(", "model_tag", ",", "sample_x", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", ":", "\n", "    ", "if", "model_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "model_tag", "=", "model_tag", "[", ":", "-", "1", "]", "\n", "", "if", "not", "yahoo_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yahoo_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yahoo_tag", ")", ">", "1", ":", "\n", "        ", "yahoo_tag", "=", "'-'", "+", "yahoo_tag", "\n", "", "if", "not", "imdb_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "imdb_tag", "+=", "'/'", "\n", "", "if", "len", "(", "imdb_tag", ")", ">", "1", ":", "\n", "        ", "imdb_tag", "=", "'-'", "+", "imdb_tag", "\n", "", "if", "not", "amazon_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "amazon_tag", "+=", "'/'", "\n", "", "if", "len", "(", "amazon_tag", ")", ">", "1", ":", "\n", "        ", "amazon_tag", "=", "'-'", "+", "amazon_tag", "\n", "", "if", "not", "yelp_tag", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "yelp_tag", "+=", "'/'", "\n", "", "if", "len", "(", "yelp_tag", ")", ">", "1", ":", "\n", "        ", "yelp_tag", "=", "'-'", "+", "yelp_tag", "\n", "", "print", "(", "\"Starting to make a JS div plot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanconv_table", "\n", "imdb_table", "=", "imdb_hanconv_table", "\n", "amazon_table", "=", "amazon_hanconv_table", "\n", "yelp_table", "=", "yelp_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanrnn_table", "\n", "imdb_table", "=", "imdb_hanrnn_table", "\n", "amazon_table", "=", "amazon_hanrnn_table", "\n", "yelp_table", "=", "yelp_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'han_encless'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanencless_table", "\n", "imdb_table", "=", "imdb_hanencless_table", "\n", "amazon_table", "=", "amazon_hanencless_table", "\n", "yelp_table", "=", "yelp_hanencless_table", "\n", "model", "=", "'hanencless'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanconv_table", "\n", "imdb_table", "=", "imdb_flanconv_table", "\n", "amazon_table", "=", "amazon_flanconv_table", "\n", "yelp_table", "=", "yelp_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanrnn_table", "\n", "imdb_table", "=", "imdb_flanrnn_table", "\n", "amazon_table", "=", "amazon_flanrnn_table", "\n", "yelp_table", "=", "yelp_flanrnn_table", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flan_encless'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanencless_table", "\n", "imdb_table", "=", "imdb_flanencless_table", "\n", "amazon_table", "=", "amazon_flanencless_table", "\n", "yelp_table", "=", "yelp_flanencless_table", "\n", "model", "=", "'flanencless'", "\n", "is_han", "=", "False", "\n", "", "if", "is_han", ":", "\n", "        ", "yahoo_mask", "=", "yahoo_han_mask", "\n", "imdb_mask", "=", "imdb_han_mask", "\n", "amazon_mask", "=", "amazon_han_mask", "\n", "yelp_mask", "=", "yelp_han_mask", "\n", "", "else", ":", "\n", "        ", "yahoo_mask", "=", "yahoo_flan_mask", "\n", "imdb_mask", "=", "imdb_flan_mask", "\n", "amazon_mask", "=", "amazon_flan_mask", "\n", "yelp_mask", "=", "yelp_flan_mask", "\n", "", "yahoo_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'yahoo10cat-'", "+", "model_tag", "+", "\n", "yahoo_tag", ")", "[", "yahoo_mask", "]", "\n", "yahoo_model_tup", "=", "make_rand_jsdiv_model_tup", "(", "yahoo_highestattnweights", ",", "yahoo_table", ",", "\"Yahoo\"", ")", "\n", "#yahoo_low, yahoo_high = ask_where_to_split_attndiff_plots(yahoo_model_tup)", "\n", "imdb_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'imdb-'", "+", "model_tag", "+", "\n", "imdb_tag", ")", "[", "imdb_mask", "]", "\n", "imdb_model_tup", "=", "make_rand_jsdiv_model_tup", "(", "imdb_highestattnweights", ",", "imdb_table", ",", "\"IMDB\"", ")", "\n", "#imdb_low, imdb_high = ask_where_to_split_attndiff_plots(imdb_model_tup)", "\n", "\n", "amazon_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'amazon-'", "+", "model_tag", "+", "\n", "amazon_tag", ")", "[", "amazon_mask", "]", "\n", "amazon_model_tup", "=", "make_rand_jsdiv_model_tup", "(", "amazon_highestattnweights", ",", "amazon_table", ",", "\"Amazon\"", ")", "\n", "\n", "#amazon_low, amazon_high = ask_where_to_split_attndiff_plots(amazon_model_tup)", "\n", "yelp_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'yelp-'", "+", "model_tag", "+", "\n", "yelp_tag", ")", "[", "yelp_mask", "]", "\n", "yelp_model_tup", "=", "make_rand_jsdiv_model_tup", "(", "yelp_highestattnweights", ",", "yelp_table", ",", "\"Yelp\"", ")", "\n", "#yelp_low, yelp_high = ask_where_to_split_attndiff_plots(yelp_model_tup)", "\n", "\n", "yahoo_model_tup", ",", "yahoo_neg_x", "=", "convert_to_log_and_print_how_many_were_originally_negative", "(", "yahoo_model_tup", ",", "\n", "model_tag", ")", "\n", "imdb_model_tup", ",", "imdb_neg_x", "=", "convert_to_log_and_print_how_many_were_originally_negative", "(", "imdb_model_tup", ",", "\n", "model_tag", ")", "\n", "amazon_model_tup", ",", "az_neg_x", "=", "convert_to_log_and_print_how_many_were_originally_negative", "(", "amazon_model_tup", ",", "\n", "model_tag", ")", "\n", "yelp_model_tup", ",", "yelp_neg_x", "=", "convert_to_log_and_print_how_many_were_originally_negative", "(", "yelp_model_tup", ",", "\n", "model_tag", ")", "\n", "\n", "yahoo_model_tup", "=", "sample_x_datapoints_per_tenth_on_xaxis", "(", "yahoo_model_tup", ",", "sample_x", ")", "\n", "imdb_model_tup", "=", "sample_x_datapoints_per_tenth_on_xaxis", "(", "imdb_model_tup", ",", "sample_x", ")", "\n", "amazon_model_tup", "=", "sample_x_datapoints_per_tenth_on_xaxis", "(", "amazon_model_tup", ",", "sample_x", ")", "\n", "yelp_model_tup", "=", "sample_x_datapoints_per_tenth_on_xaxis", "(", "yelp_model_tup", ",", "sample_x", ")", "\n", "\n", "\"\"\"yahoo_model_tup = wonkysample_so_xs_are_roughly_uniform_at_random(yahoo_model_tup, sample_x)\n    imdb_model_tup = wonkysample_so_xs_are_roughly_uniform_at_random(imdb_model_tup, sample_x)\n    amazon_model_tup = wonkysample_so_xs_are_roughly_uniform_at_random(amazon_model_tup, sample_x)\n    yelp_model_tup = wonkysample_so_xs_are_roughly_uniform_at_random(yelp_model_tup, sample_x)\"\"\"", "\n", "\n", "#make_kdeplot([yahoo_model_tup, imdb_model_tup, amazon_model_tup, yelp_model_tup], \"differences_in_jsdivs_kde_\" + model)", "\n", "make_hists", "(", "\"neg_jsdivdiff_xvals_\"", "+", "model", ",", "[", "(", "\"Yahoo\"", ",", "yahoo_neg_x", ")", ",", "(", "\"IMDB\"", ",", "imdb_neg_x", ")", ",", "(", "\"Amazon\"", ",", "az_neg_x", ")", ",", "(", "\"Yelp\"", ",", "yelp_neg_x", ")", "]", ")", "\n", "\n", "make_2x2_regression_set", "(", "[", "yahoo_model_tup", ",", "imdb_model_tup", ",", "amazon_model_tup", ",", "yelp_model_tup", "]", ",", "\n", "\"differences_in_jsdivs_\"", "+", "model", ",", "vs_avg", "=", "False", ")", "\n", "print", "(", "\"Finished making a JS div plot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.convert_to_log_and_print_how_many_were_originally_negative": [[1368, 1398], ["isinstance", "print", "numpy.array", "sorted", "numpy.array", "numpy.array", "numpy.array", "numpy.min", "numpy.array", "list", "len", "list", "list", "list", "len", "str", "str", "numpy.sum", "str", "numpy.sum"], "function", ["None"], ["", "def", "convert_to_log_and_print_how_many_were_originally_negative", "(", "js_model_tup", ",", "model_label_to_print_with_report", ")", ":", "\n", "    ", "convert_to_log", "=", "js_model_tup", "[", "2", "]", "\n", "if", "isinstance", "(", "convert_to_log", ",", "list", ")", ":", "\n", "        ", "convert_to_log", "=", "np", ".", "array", "(", "convert_to_log", ")", "\n", "change_back_to_list", "=", "True", "\n", "", "else", ":", "\n", "        ", "change_back_to_list", "=", "False", "\n", "", "subtract_before_logging", "=", "np", ".", "min", "(", "convert_to_log", ")", "-", ".01", "\n", "x_vals_going_with_ys", "=", "np", ".", "array", "(", "js_model_tup", "[", "1", "]", ")", "[", "convert_to_log", "<", "0", "]", "\n", "assert", "len", "(", "x_vals_going_with_ys", ".", "shape", ")", ">", "0", "and", "x_vals_going_with_ys", ".", "shape", "[", "0", "]", ">", "0", ",", "x_vals_going_with_ys", "\n", "print", "(", "js_model_tup", "[", "0", "]", "+", "\" \"", "+", "model_label_to_print_with_report", "+", "\": \"", "+", "str", "(", "np", ".", "sum", "(", "convert_to_log", "<", "0", ")", ")", "+", "\n", "\" out of \"", "+", "str", "(", "convert_to_log", ".", "shape", "[", "0", "]", ")", "+", "\" (\"", "+", "str", "(", "np", ".", "sum", "(", "convert_to_log", "<", "0", ")", "/", "convert_to_log", ".", "shape", "[", "0", "]", ")", "+", "\") JSdivdiffs were negative\"", ")", "\n", "#new_y_vals = np.log(convert_to_log - subtract_before_logging)", "\n", "new_y_vals", "=", "np", ".", "array", "(", "convert_to_log", ")", "\n", "if", "change_back_to_list", ":", "\n", "        ", "new_y_vals", "=", "list", "(", "new_y_vals", ")", "\n", "", "assert", "len", "(", "js_model_tup", ")", "==", "3", "\n", "\n", "sorted_y_vals", "=", "sorted", "(", "list", "(", "new_y_vals", ")", ",", "reverse", "=", "False", ")", "\n", "only_accept_yvals_below", "=", "sorted_y_vals", "[", "-", "1", "]", "#[int(len(sorted_y_vals) * 0.99)]", "\n", "new_y_vals", "=", "np", ".", "array", "(", "new_y_vals", ")", "\n", "keep", "=", "(", "new_y_vals", "<", "only_accept_yvals_below", ")", "\n", "new_y_vals", "=", "new_y_vals", "[", "keep", "]", "\n", "x_vals", "=", "np", ".", "array", "(", "js_model_tup", "[", "1", "]", ")", "\n", "x_vals", "=", "x_vals", "[", "keep", "]", "\n", "if", "change_back_to_list", ":", "\n", "        ", "x_vals", "=", "list", "(", "x_vals", ")", "\n", "new_y_vals", "=", "list", "(", "new_y_vals", ")", "\n", "\n", "", "return", "[", "js_model_tup", "[", "0", "]", ",", "x_vals", ",", "new_y_vals", "]", ",", "x_vals_going_with_ys", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.wonkysample_so_xs_are_roughly_uniform_at_random": [[1400, 1418], ["isinstance", "numpy.min", "numpy.max", "numpy.argsort", "range", "figure_maker.make_histogram_of_x_vals", "exit", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_histogram_of_x_vals"], ["", "def", "wonkysample_so_xs_are_roughly_uniform_at_random", "(", "js_model_tup", ",", "sample_x", ")", ":", "\n", "    ", "xs", "=", "js_model_tup", "[", "1", "]", "\n", "if", "isinstance", "(", "xs", ",", "list", ")", ":", "\n", "        ", "xs", "=", "np", ".", "array", "(", "xs", ")", "\n", "change_back_to_list", "=", "True", "\n", "", "else", ":", "\n", "        ", "change_back_to_list", "=", "False", "\n", "", "lower_bound", "=", "np", ".", "min", "(", "xs", ")", "\n", "upper_bound", "=", "np", ".", "max", "(", "xs", ")", "\n", "inds_lowest_to_highest", "=", "np", ".", "argsort", "(", "xs", ")", "\n", "for", "j", "in", "range", "(", "inds_lowest_to_highest", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "inds_lowest_to_highest", "[", "j", "]", "==", "0", ":", "\n", "            ", "ind_to_check", "=", "j", "\n", "break", "\n", "", "", "xs", "=", "xs", "[", "inds_lowest_to_highest", "]", "\n", "corr_ys", "=", "np", ".", "array", "(", "js_model_tup", "[", "2", "]", ")", "[", "inds_lowest_to_highest", "]", "\n", "make_histogram_of_x_vals", "(", "xs", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_histogram_of_x_vals": [[1420, 1427], ["matplotlib.figure", "seaborn.distplot", "matplotlib.savefig", "matplotlib.close"], "function", ["None"], ["", "def", "make_histogram_of_x_vals", "(", "x_vals", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "2", ")", ")", "\n", "\n", "ax", "=", "sns", ".", "distplot", "(", "x_vals", ",", "kde", "=", "False", ",", "rug", "=", "True", ")", "\n", "\n", "plt", ".", "savefig", "(", "images_dir", "+", "'test_hist'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.subsample_so_xs_are_roughly_uniform_at_random": [[1430, 1487], ["isinstance", "numpy.min", "numpy.max", "numpy.argsort", "numpy.random.uniform", "numpy.sort", "numpy.array", "range", "numpy.array", "numpy.array", "list", "list", "stack_of_unchosen_val_inds.insert", "len", "len"], "function", ["None"], ["", "def", "subsample_so_xs_are_roughly_uniform_at_random", "(", "js_model_tup", ",", "sample_x", ")", ":", "\n", "    ", "xs", "=", "js_model_tup", "[", "1", "]", "\n", "if", "isinstance", "(", "xs", ",", "list", ")", ":", "\n", "        ", "xs", "=", "np", ".", "array", "(", "xs", ")", "\n", "change_back_to_list", "=", "True", "\n", "", "else", ":", "\n", "        ", "change_back_to_list", "=", "False", "\n", "", "lower_bound", "=", "np", ".", "min", "(", "xs", ")", "\n", "upper_bound", "=", "np", ".", "max", "(", "xs", ")", "\n", "inds_lowest_to_highest", "=", "np", ".", "argsort", "(", "xs", ")", "\n", "xs", "=", "xs", "[", "inds_lowest_to_highest", "]", "\n", "corr_ys", "=", "np", ".", "array", "(", "js_model_tup", "[", "2", "]", ")", "[", "inds_lowest_to_highest", "]", "\n", "pseudo_xs", "=", "np", ".", "random", ".", "uniform", "(", "lower_bound", ",", "upper_bound", ",", "size", "=", "(", "sample_x", ",", ")", ")", "\n", "np", ".", "sort", "(", "pseudo_xs", ")", "\n", "# now go through and greedily mark all values as we find vals that are closest to each pseudo_x", "\n", "bool_arr", "=", "np", ".", "array", "(", "[", "0", "]", "*", "xs", ".", "shape", "[", "0", "]", ",", "dtype", "=", "bool", ")", "\n", "stack_of_unchosen_val_inds", "=", "[", "0", "]", "\n", "next_full_arr_ind_to_right", "=", "1", "\n", "for", "ind", "in", "range", "(", "pseudo_xs", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "quit", "=", "False", "\n", "figured_out_what_to_do_with_ind", "=", "False", "\n", "while", "not", "figured_out_what_to_do_with_ind", ":", "\n", "            ", "if", "pseudo_xs", "[", "ind", "]", ">", "xs", "[", "next_full_arr_ind_to_right", "]", ":", "\n", "                ", "stack_of_unchosen_val_inds", ".", "insert", "(", "0", ",", "next_full_arr_ind_to_right", ")", "\n", "next_full_arr_ind_to_right", "+=", "1", "\n", "", "elif", "xs", "[", "next_full_arr_ind_to_right", "]", "==", "pseudo_xs", "[", "ind", "]", ":", "\n", "                ", "figured_out_what_to_do_with_ind", "=", "True", "\n", "bool_arr", "[", "next_full_arr_ind_to_right", "]", "=", "True", "\n", "next_full_arr_ind_to_right", "+=", "1", "\n", "", "else", ":", "\n", "                ", "figured_out_what_to_do_with_ind", "=", "True", "\n", "# the ind actually does appear on the right, so now's the time to choose what we pull", "\n", "if", "len", "(", "stack_of_unchosen_val_inds", ")", "==", "0", ":", "\n", "                    ", "bool_arr", "[", "next_full_arr_ind_to_right", "]", "=", "True", "\n", "next_full_arr_ind_to_right", "+=", "1", "\n", "", "else", ":", "\n", "# we have two choices. pick the closer one.", "\n", "                    ", "if", "pseudo_xs", "[", "ind", "]", "-", "xs", "[", "stack_of_unchosen_val_inds", "[", "0", "]", "]", "<", "xs", "[", "next_full_arr_ind_to_right", "]", "-", "pseudo_xs", "[", "ind", "]", ":", "\n", "# closer to previous val", "\n", "                        ", "bool_arr", "[", "stack_of_unchosen_val_inds", "[", "0", "]", "]", "=", "True", "\n", "del", "stack_of_unchosen_val_inds", "[", "0", "]", "\n", "", "else", ":", "\n", "                        ", "bool_arr", "[", "next_full_arr_ind_to_right", "]", "=", "True", "\n", "next_full_arr_ind_to_right", "+=", "1", "\n", "", "", "", "if", "next_full_arr_ind_to_right", ">=", "xs", ".", "shape", "[", "0", "]", ":", "\n", "                ", "quit", "=", "True", "\n", "if", "len", "(", "stack_of_unchosen_val_inds", ")", ">", "0", ":", "\n", "                    ", "bool_arr", "[", "stack_of_unchosen_val_inds", "[", "0", "]", "]", "=", "True", "\n", "", "figured_out_what_to_do_with_ind", "=", "True", "\n", "", "", "if", "quit", ":", "\n", "            ", "break", "\n", "", "", "new_x_vals", "=", "xs", "[", "bool_arr", "]", "\n", "new_y_vals", "=", "corr_ys", "[", "bool_arr", "]", "\n", "if", "change_back_to_list", ":", "\n", "        ", "return", "[", "js_model_tup", "[", "0", "]", ",", "list", "(", "new_x_vals", ")", ",", "list", "(", "new_y_vals", ")", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "js_model_tup", "[", "0", "]", ",", "new_x_vals", ",", "new_y_vals", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.sample_x_datapoints_per_tenth_on_xaxis": [[1489, 1521], ["isinstance", "range", "range", "print", "range", "numpy.array", "len", "lists_of_lists_being_built.append", "numpy.logical_and", "numpy.array", "range", "len", "isinstance", "numpy.nonzero", "len", "isinstance", "list", "new_model_tup.append", "new_model_tup.append", "numpy.array", "str", "numpy.array", "numpy.random.choice", "len"], "function", ["None"], ["", "", "def", "sample_x_datapoints_per_tenth_on_xaxis", "(", "model_tup", ",", "x", ")", ":", "\n", "    ", "x_axis_vals", "=", "model_tup", "[", "1", "]", "\n", "if", "isinstance", "(", "x_axis_vals", ",", "list", ")", ":", "\n", "        ", "x_axis_vals", "=", "np", ".", "array", "(", "x_axis_vals", ")", "\n", "", "lists_of_lists_being_built", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "model_tup", ")", ")", ":", "\n", "        ", "lists_of_lists_being_built", ".", "append", "(", "[", "]", ")", "\n", "", "num_bins", "=", "200", "\n", "for", "i", "in", "range", "(", "num_bins", ")", ":", "\n", "        ", "left_val_inclusive", "=", "i", "/", "num_bins", "\n", "right_val_exclusive", "=", "left_val_inclusive", "+", "(", "1.0", "/", "num_bins", ")", "\n", "true_where_is_option", "=", "np", ".", "logical_and", "(", "x_axis_vals", ">=", "left_val_inclusive", ",", "x_axis_vals", "<", "right_val_exclusive", ")", "\n", "possible_inds", "=", "np", ".", "nonzero", "(", "true_where_is_option", ")", "[", "0", "]", "\n", "mask_to_take", "=", "np", ".", "array", "(", "[", "0", "]", "*", "true_where_is_option", ".", "shape", "[", "0", "]", ",", "dtype", "=", "bool", ")", "\n", "if", "possible_inds", ".", "shape", "[", "0", "]", "<", "x", ":", "\n", "            ", "mask_to_take", "[", "possible_inds", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "mask_to_take", "[", "np", ".", "random", ".", "choice", "(", "possible_inds", ",", "size", "=", "x", ")", "]", "=", "1", "\n", "", "for", "j", "in", "range", "(", "1", ",", "len", "(", "model_tup", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "model_tup", "[", "j", "]", ",", "list", ")", ":", "\n", "                ", "arr_to_sample", "=", "np", ".", "array", "(", "model_tup", "[", "j", "]", ")", "\n", "", "else", ":", "\n", "                ", "arr_to_sample", "=", "model_tup", "[", "j", "]", "\n", "", "lists_of_lists_being_built", "[", "j", "-", "1", "]", "+=", "list", "(", "arr_to_sample", "[", "mask_to_take", "]", ")", "\n", "", "", "print", "(", "\"Pulled \"", "+", "str", "(", "len", "(", "lists_of_lists_being_built", "[", "0", "]", ")", ")", "+", "\" datapoints\"", ")", "\n", "new_model_tup", "=", "[", "model_tup", "[", "0", "]", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "model_tup", ")", ")", ":", "\n", "        ", "if", "isinstance", "(", "model_tup", "[", "i", "]", ",", "list", ")", ":", "\n", "            ", "new_model_tup", ".", "append", "(", "lists_of_lists_being_built", "[", "i", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "new_model_tup", ".", "append", "(", "np", ".", "array", "(", "lists_of_lists_being_built", "[", "i", "-", "1", "]", ")", ")", "\n", "", "", "return", "new_model_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.ask_where_to_split_attndiff_plots": [[1523, 1586], ["numpy.array", "range", "input", "print", "input", "input.startswith", "input", "len", "float", "str", "float", "isinstance", "new_low_tuple.append", "new_high_tuple.append", "isinstance", "new_low_tuple.append", "new_high_tuple.append", "list", "range", "numpy.array", "numpy.sum", "len", "list.append", "new_low_list.append", "list.append", "new_high_list.append", "new_low_list.append", "new_high_list.append", "numpy.logical_not"], "function", ["None"], ["", "def", "ask_where_to_split_attndiff_plots", "(", "model_tup", ")", ":", "\n", "    ", "np_set_of_attndiffs", "=", "np", ".", "array", "(", "model_tup", "[", "1", "]", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "val", "=", "input", "(", "\"Find pct of diffs that fall above: \"", ")", "\n", "try", ":", "\n", "            ", "val", "=", "float", "(", "val", ")", "\n", "", "except", ":", "\n", "            ", "continue", "\n", "", "print", "(", "str", "(", "np", ".", "sum", "(", "np_set_of_attndiffs", ">", "val", ")", "/", "np_set_of_attndiffs", ".", "shape", "[", "0", "]", ")", ")", "\n", "keep_going", "=", "input", "(", "\"Keep exploring? (y/n) \"", ")", "\n", "if", "keep_going", ".", "startswith", "(", "'n'", ")", ":", "\n", "            ", "done", "=", "True", "\n", "break", "\n", "", "", "have_splitting_val", "=", "False", "\n", "while", "not", "have_splitting_val", ":", "\n", "        ", "val", "=", "input", "(", "\"Splitting val? \"", ")", "\n", "try", ":", "\n", "            ", "val", "=", "float", "(", "val", ")", "\n", "have_splitting_val", "=", "True", "\n", "", "except", ":", "\n", "            ", "continue", "\n", "# now go through and create two different model_tups, one of values that fall above and other of vals", "\n", "# that fall below", "\n", "", "", "new_low_tuple", "=", "[", "model_tup", "[", "0", "]", "]", "\n", "new_high_tuple", "=", "[", "model_tup", "[", "0", "]", "]", "\n", "for", "component_ind", "in", "range", "(", "1", ",", "len", "(", "model_tup", ")", ")", ":", "\n", "        ", "comp", "=", "model_tup", "[", "component_ind", "]", "\n", "if", "component_ind", "==", "1", ":", "\n", "            ", "if", "isinstance", "(", "comp", ",", "list", ")", ":", "\n", "                ", "val_included_in_low_key", "=", "[", "]", "\n", "new_low_list", "=", "[", "]", "\n", "new_high_list", "=", "[", "]", "\n", "for", "item", "in", "comp", ":", "\n", "                    ", "if", "item", "<=", "val", ":", "\n", "                        ", "val_included_in_low_key", ".", "append", "(", "True", ")", "\n", "new_low_list", ".", "append", "(", "item", ")", "\n", "", "else", ":", "\n", "                        ", "val_included_in_low_key", ".", "append", "(", "False", ")", "\n", "new_high_list", ".", "append", "(", "item", ")", "\n", "", "", "", "else", ":", "# assume it's a numpy array", "\n", "                ", "val_included_in_low_key", "=", "list", "(", "comp", "<=", "val", ")", "\n", "new_low_list", "=", "comp", "[", "comp", "<=", "val", "]", "\n", "new_high_list", "=", "comp", "[", "comp", ">", "val", "]", "\n", "", "new_low_tuple", ".", "append", "(", "new_low_list", ")", "\n", "new_high_tuple", ".", "append", "(", "new_high_list", ")", "\n", "", "else", ":", "# assume it's a numpy array", "\n", "            ", "if", "isinstance", "(", "comp", ",", "list", ")", ":", "\n", "                ", "new_low_list", "=", "[", "]", "\n", "new_high_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "val_included_in_low_key", ")", ")", ":", "\n", "                    ", "key", "=", "val_included_in_low_key", "[", "i", "]", "\n", "if", "key", ":", "\n", "                        ", "new_low_list", ".", "append", "(", "comp", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                        ", "new_high_list", ".", "append", "(", "comp", "[", "i", "]", ")", "\n", "", "", "", "else", ":", "\n", "                ", "np_mask", "=", "np", ".", "array", "(", "val_included_in_low_key", ",", "dtype", "=", "bool", ")", "\n", "new_low_list", "=", "comp", "[", "np_mask", "]", "\n", "new_high_list", "=", "comp", "[", "np", ".", "logical_not", "(", "np_mask", ")", "]", "\n", "", "new_low_tuple", ".", "append", "(", "new_low_list", ")", "\n", "new_high_tuple", ".", "append", "(", "new_high_list", ")", "\n", "", "", "return", "new_low_tuple", ",", "new_high_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot_vs2ndhighest": [[1588, 1657], ["print", "model_tag.startswith", "figure_maker.make_vs2nd_jsdiv_model_tup", "figure_maker.make_vs2nd_jsdiv_model_tup", "figure_maker.make_vs2nd_jsdiv_model_tup", "figure_maker.make_vs2nd_jsdiv_model_tup", "figure_maker.make_2x2_regression_set", "print", "model_tag.startswith", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "model_tag.startswith", "model_tag.startswith"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_vs2nd_jsdiv_model_tup", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_2x2_regression_set", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.get_np_arr_of_one_attn_weight_per_instance"], ["", "def", "make_jsdiv_regression_plot_vs2ndhighest", "(", "model_tag", ")", ":", "\n", "    ", "print", "(", "\"Starting to make a JS div plot\"", ")", "\n", "if", "model_tag", ".", "startswith", "(", "'hanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanconv_table", "\n", "imdb_table", "=", "imdb_hanconv_table", "\n", "amazon_table", "=", "amazon_hanconv_table", "\n", "yelp_table", "=", "yelp_hanconv_table", "\n", "model", "=", "'hanconv'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'hanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_hanrnn_table", "\n", "imdb_table", "=", "imdb_hanrnn_table", "\n", "amazon_table", "=", "amazon_hanrnn_table", "\n", "yelp_table", "=", "yelp_hanrnn_table", "\n", "model", "=", "'hanrnn'", "\n", "is_han", "=", "True", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanconv'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanconv_table", "\n", "imdb_table", "=", "imdb_flanconv_table", "\n", "amazon_table", "=", "amazon_flanconv_table", "\n", "yelp_table", "=", "yelp_flanconv_table", "\n", "model", "=", "'flanconv'", "\n", "is_han", "=", "False", "\n", "", "elif", "model_tag", ".", "startswith", "(", "'flanrnn'", ")", ":", "\n", "        ", "yahoo_table", "=", "yahoo_flanrnn_table", "\n", "imdb_table", "=", "imdb_flanrnn_table", "\n", "amazon_table", "=", "amazon_flanrnn_table", "\n", "yelp_table", "=", "yelp_flanrnn_table", "\n", "model", "=", "'flanrnn'", "\n", "is_han", "=", "False", "\n", "", "if", "is_han", ":", "\n", "        ", "yahoo_mask", "=", "yahoo_han_mask", "\n", "imdb_mask", "=", "imdb_han_mask", "\n", "amazon_mask", "=", "amazon_han_mask", "\n", "yelp_mask", "=", "yelp_han_mask", "\n", "", "else", ":", "\n", "        ", "yahoo_mask", "=", "yahoo_flan_mask", "\n", "imdb_mask", "=", "imdb_flan_mask", "\n", "amazon_mask", "=", "amazon_flan_mask", "\n", "yelp_mask", "=", "yelp_flan_mask", "\n", "", "yahoo_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'yahoo10cat-'", "+", "model_tag", ")", "[", "yahoo_mask", "]", "\n", "yahoo_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "'yahoo10cat-'", "+", "model_tag", ")", "[", "yahoo_mask", "]", "\n", "yahoo_model_tup", "=", "make_vs2nd_jsdiv_model_tup", "(", "yahoo_highestattnweights", ",", "yahoo_2ndhighestattnweights", ",", "yahoo_table", ",", "\n", "\"Yahoo\"", ")", "\n", "imdb_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'imdb-'", "+", "model_tag", ")", "[", "imdb_mask", "]", "\n", "imdb_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "'imdb-'", "+", "model_tag", ")", "[", "imdb_mask", "]", "\n", "imdb_model_tup", "=", "make_vs2nd_jsdiv_model_tup", "(", "imdb_highestattnweights", ",", "imdb_2ndhighestattnweights", ",", "imdb_table", ",", "\n", "\"IMDB\"", ")", "\n", "\n", "amazon_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'amazon-'", "+", "model_tag", ")", "[", "amazon_mask", "]", "\n", "amazon_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "'amazon-'", "+", "model_tag", ")", "[", "amazon_mask", "]", "\n", "amazon_model_tup", "=", "make_vs2nd_jsdiv_model_tup", "(", "amazon_highestattnweights", ",", "amazon_2ndhighestattnweights", ",", "amazon_table", ",", "\n", "\"Amazon\"", ")", "\n", "yelp_highestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "0", ",", "is_han", ",", "base_output_dir", "+", "'yelp-'", "+", "model_tag", ")", "[", "yelp_mask", "]", "\n", "yelp_2ndhighestattnweights", "=", "get_np_arr_of_one_attn_weight_per_instance", "(", "1", ",", "is_han", ",", "base_output_dir", "+", "'yelp-'", "+", "model_tag", ")", "[", "yelp_mask", "]", "\n", "yelp_model_tup", "=", "make_vs2nd_jsdiv_model_tup", "(", "yelp_highestattnweights", ",", "yelp_2ndhighestattnweights", ",", "yelp_table", ",", "\n", "\"Yelp\"", ")", "\n", "\n", "make_2x2_regression_set", "(", "[", "yahoo_model_tup", ",", "imdb_model_tup", ",", "amazon_model_tup", ",", "yelp_model_tup", "]", ",", "\n", "\"differences_in_jsdivs_vs2nd_\"", "+", "model", ",", "vs_avg", "=", "False", ")", "\n", "print", "(", "\"Finished making a JS div plot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.main": [[1659, 1711], ["figure_maker.make_probmass_boxplots", "figure_maker.make_probmass_boxplots", "figure_maker.make_probmass_boxplots", "figure_maker.make_probmass_boxplots", "figure_maker.make_probmass_boxplots", "figure_maker.make_probmass_boxplots", "figure_maker.make_boxplots_with_four", "figure_maker.make_boxplots_with_four", "figure_maker.make_boxplots_with_four", "figure_maker.make_boxplots_with_four", "figure_maker.make_boxplots_with_four", "figure_maker.make_boxplots_with_four", "figure_maker.make_jsdiv_regression_plot", "figure_maker.make_jsdiv_regression_plot", "figure_maker.make_jsdiv_regression_plot", "figure_maker.make_jsdiv_regression_plot", "figure_maker.make_jsdiv_regression_plot", "figure_maker.make_jsdiv_regression_plot"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_probmass_boxplots", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots_with_four", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots_with_four", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots_with_four", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots_with_four", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots_with_four", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_boxplots_with_four", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot", "home.repos.pwc.inspect_result.serrano-s_attn-tests.figure_making.figure_maker.make_jsdiv_regression_plot"], ["", "def", "main", "(", ")", ":", "\n", "    ", "sample_x", "=", "10", "\n", "assert", "yahoo_hanrnn_table", ".", "shape", "[", "1", "]", "==", "imdb_hanrnn_table", ".", "shape", "[", "1", "]", "\n", "\n", "make_probmass_boxplots", "(", "'hanrnn'", ",", "yahoo_tag", "=", "'postattnfix'", ",", "imdb_tag", "=", "'postattnfix'", ",", "\n", "amazon_tag", "=", "'fiveclassround2-4'", ",", "yelp_tag", "=", "'fiveclassround2-5smallerstep'", ")", "\n", "make_probmass_boxplots", "(", "'hanconv'", ",", "yahoo_tag", "=", "'convfix'", ",", "imdb_tag", "=", "'convfix'", ",", "\n", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_probmass_boxplots", "(", "'flanrnn'", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_probmass_boxplots", "(", "'flanconv'", ",", "yahoo_tag", "=", "'convfix'", ",", "imdb_tag", "=", "'convfix'", ",", "\n", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_probmass_boxplots", "(", "'hanencless'", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", "\n", "make_probmass_boxplots", "(", "'flanencless'", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", "\n", "\n", "\"\"\"make_boxplots('hanrnn', yahoo_tag='postattnfix', imdb_tag='postattnfix',\n                            amazon_tag='fiveclassround2-4', yelp_tag='fiveclassround2-5smallerstep')\n    make_boxplots('hanconv', yahoo_tag='convfix', imdb_tag='convfix',\n                  amazon_tag='fiveclass', yelp_tag='fiveclass')\n    make_boxplots('flanrnn', yahoo_tag='', imdb_tag='', amazon_tag='fiveclass', yelp_tag='fiveclass')\n    make_boxplots('flanconv', yahoo_tag='convfix', imdb_tag='convfix',\n                                              amazon_tag='fiveclass', yelp_tag='fiveclass')\n    make_boxplots('hanencless', yahoo_tag='', imdb_tag='', amazon_tag='', yelp_tag='')\n    make_boxplots('flanencless', yahoo_tag='', imdb_tag='', amazon_tag='', yelp_tag='')\"\"\"", "\n", "\n", "make_boxplots_with_four", "(", "'hanrnn'", ",", "yahoo_tag", "=", "'postattnfix'", ",", "imdb_tag", "=", "'postattnfix'", ",", "\n", "amazon_tag", "=", "'fiveclassround2-4'", ",", "yelp_tag", "=", "'fiveclassround2-5smallerstep'", ")", "\n", "make_boxplots_with_four", "(", "'hanconv'", ",", "yahoo_tag", "=", "'convfix'", ",", "imdb_tag", "=", "'convfix'", ",", "\n", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_boxplots_with_four", "(", "'flanrnn'", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_boxplots_with_four", "(", "'flanconv'", ",", "yahoo_tag", "=", "'convfix'", ",", "imdb_tag", "=", "'convfix'", ",", "\n", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_boxplots_with_four", "(", "'hanencless'", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", "\n", "make_boxplots_with_four", "(", "'flanencless'", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", "\n", "\n", "\"\"\"make_decflip_regression_plot_vs2ndhighest('hanrnn', yahoo_tag='postattnfix', imdb_tag='postattnfix',\n                                              amazon_tag='fiveclassround2-4', yelp_tag='fiveclassround2-5smallerstep')\n    make_decflip_regression_plot_vs2ndhighest('hanconv', yahoo_tag='convfix', imdb_tag='convfix',\n                                              amazon_tag='fiveclass', yelp_tag='fiveclass')\n    make_decflip_regression_plot_vs2ndhighest('flanrnn', yahoo_tag='', imdb_tag='', amazon_tag='fiveclass',\n                                              yelp_tag='fiveclass')\n    make_decflip_regression_plot_vs2ndhighest('flanconv', yahoo_tag='convfix', imdb_tag='convfix',\n                  amazon_tag='fiveclass', yelp_tag='fiveclass')\"\"\"", "\n", "\n", "make_jsdiv_regression_plot", "(", "'hanrnn'", ",", "sample_x", ",", "yahoo_tag", "=", "'postattnfix'", ",", "imdb_tag", "=", "'postattnfix'", ",", "amazon_tag", "=", "'fiveclassround2-4'", ",", "\n", "yelp_tag", "=", "'fiveclassround2-5smallerstep'", ")", "\n", "make_jsdiv_regression_plot", "(", "'hanconv'", ",", "sample_x", ",", "yahoo_tag", "=", "'convfix'", ",", "imdb_tag", "=", "'convfix'", ",", "\n", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_jsdiv_regression_plot", "(", "'flanrnn'", ",", "sample_x", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_jsdiv_regression_plot", "(", "'flanconv'", ",", "sample_x", ",", "yahoo_tag", "=", "'convfix'", ",", "imdb_tag", "=", "'convfix'", ",", "\n", "amazon_tag", "=", "'fiveclass'", ",", "yelp_tag", "=", "'fiveclass'", ")", "\n", "make_jsdiv_regression_plot", "(", "'han_encless'", ",", "sample_x", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", "\n", "make_jsdiv_regression_plot", "(", "'flan_encless'", ",", "sample_x", ",", "yahoo_tag", "=", "''", ",", "imdb_tag", "=", "''", ",", "amazon_tag", "=", "''", ",", "yelp_tag", "=", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.prob_predictor.get_predicted_probabilities": [[11, 31], ["range", "range", "list", "list.keys"], "function", ["None"], ["def", "get_predicted_probabilities", "(", "p1", ",", "p2", ",", "p3", ",", "p4", ")", ":", "\n", "    ", "prob_all_4", "=", "p1", "*", "p2", "*", "p3", "*", "p4", "\n", "prob_exactly_3", "=", "(", "(", "1", "-", "p1", ")", "*", "p2", "*", "p3", "*", "p4", ")", "+", "(", "p1", "*", "(", "1", "-", "p2", ")", "*", "p3", "*", "p4", ")", "+", "(", "p1", "*", "p2", "*", "(", "1", "-", "p3", ")", "*", "p4", ")", "+", "(", "p1", "*", "p2", "*", "p3", "*", "(", "1", "-", "p4", ")", ")", "\n", "list_of_probs", "=", "[", "p1", ",", "p2", ",", "p3", ",", "p4", "]", "\n", "prob_exactly_2", "=", "0", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "4", ")", ":", "\n", "            ", "if", "j", "<=", "i", ":", "\n", "                ", "continue", "\n", "", "other_inds", "=", "{", "0", ":", "0", ",", "1", ":", "1", ",", "2", ":", "2", ",", "3", ":", "3", "}", "\n", "del", "other_inds", "[", "i", "]", "\n", "del", "other_inds", "[", "j", "]", "\n", "other_inds", "=", "list", "(", "other_inds", ".", "keys", "(", ")", ")", "\n", "prob_exactly_2", "+=", "(", "list_of_probs", "[", "i", "]", "*", "list_of_probs", "[", "j", "]", "*", "(", "1", "-", "list_of_probs", "[", "other_inds", "[", "0", "]", "]", ")", "*", "\n", "(", "1", "-", "list_of_probs", "[", "other_inds", "[", "1", "]", "]", ")", ")", "\n", "", "", "prob_exactly_1", "=", "(", "p1", "*", "(", "1", "-", "p2", ")", "*", "(", "1", "-", "p3", ")", "*", "(", "1", "-", "p4", ")", ")", "+", "(", "(", "1", "-", "p1", ")", "*", "p2", "*", "(", "1", "-", "p3", ")", "*", "(", "1", "-", "p4", ")", ")", "+", "(", "(", "1", "-", "p1", ")", "*", "(", "1", "-", "p2", ")", "*", "p3", "*", "(", "1", "-", "p4", ")", ")", "+", "(", "(", "1", "-", "p1", ")", "*", "(", "1", "-", "p2", ")", "*", "(", "1", "-", "p3", ")", "*", "p4", ")", "\n", "prob_exactly_0", "=", "(", "(", "1", "-", "p1", ")", "*", "(", "1", "-", "p2", ")", "*", "(", "1", "-", "p3", ")", "*", "(", "1", "-", "p4", ")", ")", "\n", "return", "prob_all_4", ",", "prob_exactly_3", ",", "prob_exactly_2", ",", "prob_exactly_1", ",", "prob_exactly_0", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.make_rand_subset_data_file.main": [[6, 40], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "open", "old_f.readline", "random.shuffle", "open", "f.write", "random.random", "str", "line.strip", "instances.append", "f.write", "str", "len", "str"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--filename\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Local filename of data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--frac-to-take\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "\n", "help", "=", "\"How much of the data to store in the new filename\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--new-filename\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"New filename for the data\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data-dir\"", ",", "required", "=", "False", ",", "\n", "default", "=", "\"/homes/gws/sofias6/data/\"", ",", "\n", "help", "=", "\"Base data dir\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "instances", "=", "[", "]", "\n", "with", "open", "(", "args", ".", "data_dir", "+", "args", ".", "filename", ",", "'r'", ")", "as", "old_f", ":", "\n", "        ", "first_line", "=", "old_f", ".", "readline", "(", ")", "\n", "for", "line", "in", "old_f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "!=", "''", ":", "\n", "                ", "instances", ".", "append", "(", "line", ")", "\n", "", "", "shuffle", "(", "instances", ")", "\n", "\n", "", "took", "=", "0", "\n", "with", "open", "(", "args", ".", "data_dir", "+", "args", ".", "new_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "first_line", ")", "\n", "for", "instance", "in", "instances", ":", "\n", "            ", "decider", "=", "random", "(", ")", "\n", "if", "decider", "<", "args", ".", "frac_to_take", ":", "\n", "                ", "f", ".", "write", "(", "instance", ")", "\n", "took", "+=", "1", "\n", "\n", "", "", "", "print", "(", "\"Wrote \"", "+", "str", "(", "took", ")", "+", "\" / \"", "+", "str", "(", "len", "(", "instances", ")", ")", "+", "\" instances to file \"", "+", "\n", "str", "(", "args", ".", "data_dir", "+", "args", ".", "new_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.edit_config_file_to_have_gpu": [[30, 45], ["open", "open.close", "os.rename", "open", "open.write", "len", "line[].isdigit", "str", "line.index"], "function", ["None"], ["def", "edit_config_file_to_have_gpu", "(", "filename", ",", "gpu_num", ")", ":", "\n", "    ", "temp_filename", "=", "filename", "+", "\".temp\"", "\n", "new_f", "=", "open", "(", "temp_filename", ",", "'w'", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "'\"cuda_device\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "gpu_num", ")", "+", "line_end", "\n", "", "new_f", ".", "write", "(", "line", ")", "\n", "", "", "new_f", ".", "close", "(", ")", "\n", "os", ".", "rename", "(", "temp_filename", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.set_random_seeds": [[47, 76], ["open", "open.close", "os.rename", "open", "open.write", "len", "line[].isdigit", "str", "len", "line[].isdigit", "str", "len", "line[].isdigit", "str", "line.index", "line.index", "line.index"], "function", ["None"], ["", "def", "set_random_seeds", "(", "filename", ",", "rand_seed", ",", "np_seed", ",", "pytorch_seed", ")", ":", "\n", "    ", "temp_filename", "=", "filename", "+", "\".temp\"", "\n", "new_f", "=", "open", "(", "temp_filename", ",", "'w'", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "'\"random_seed\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "rand_seed", ")", "+", "line_end", "\n", "", "elif", "'\"numpy_seed\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "np_seed", ")", "+", "line_end", "\n", "", "elif", "'\"pytorch_seed\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "pytorch_seed", ")", "+", "line_end", "\n", "", "new_f", ".", "write", "(", "line", ")", "\n", "", "", "new_f", ".", "close", "(", ")", "\n", "os", ".", "rename", "(", "temp_filename", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.set_step_size_3_dropouts": [[78, 114], ["open", "open.close", "os.rename", "open", "open.write", "len", "line[].isdigit", "str", "len", "line[].isdigit", "str", "len", "line[].isdigit", "str", "len", "line.index", "line[].isdigit", "str", "line.index", "line.index", "line.index"], "function", ["None"], ["", "def", "set_step_size_3_dropouts", "(", "filename", ",", "step_size", ",", "drp1", ",", "drp2", ",", "drp3", ")", ":", "\n", "    ", "temp_filename", "=", "filename", "+", "\".temp\"", "\n", "new_f", "=", "open", "(", "temp_filename", ",", "'w'", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "'\"lr\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "(", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", "or", "line", "[", "checking_ind", "]", "==", "'.'", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "step_size", ")", "+", "line_end", "\n", "", "elif", "'\"pre_sentence_encoder_dropout\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "(", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", "or", "line", "[", "checking_ind", "]", "==", "'.'", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "drp1", ")", "+", "line_end", "\n", "", "elif", "'\"pre_document_encoder_dropout\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "(", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", "or", "line", "[", "checking_ind", "]", "==", "'.'", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "drp2", ")", "+", "line_end", "\n", "", "elif", "'\"dropout\"'", "in", "line", ":", "\n", "                ", "line_end", "=", "''", "\n", "checking_ind", "=", "len", "(", "line", ")", "-", "1", "\n", "while", "not", "(", "line", "[", "checking_ind", "]", ".", "isdigit", "(", ")", "or", "line", "[", "checking_ind", "]", "==", "'.'", ")", ":", "\n", "                    ", "line_end", "=", "line", "[", "checking_ind", ":", "]", "\n", "checking_ind", "-=", "1", "\n", "", "line", "=", "line", "[", ":", "line", ".", "index", "(", "':'", ")", "]", "+", "\": \"", "+", "str", "(", "drp3", ")", "+", "line_end", "\n", "", "new_f", ".", "write", "(", "line", ")", "\n", "", "", "new_f", ".", "close", "(", ")", "\n", "os", ".", "rename", "(", "temp_filename", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.run_hyperparam_search": [[116, 165], ["os.path.isdir", "str", "rseed.startswith", "random.seed", "range", "datetime.datetime.now", "int", "random.uniform", "hyperparam_search.set_step_size_3_dropouts", "range", "random.uniform", "hyperparam_search.set_random_seeds", "print", "hyperparam_search.train_model", "glob.glob", "glob.glob", "glob.glob", "os.rmdir", "str", "str.rfind", "range", "random.randint", "open", "f.write", "f.write", "f.write", "os.remove", "os.remove", "os.remove", "str", "range", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.set_step_size_3_dropouts", "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.set_random_seeds", "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.train_model"], ["", "def", "run_hyperparam_search", "(", "config_file", ",", "output_dir", ",", "num_configs_to_try", ")", ":", "\n", "    ", "possible_dropout_endpoints", "=", "[", ".2", ",", ".5", "]", "\n", "possible_step_endpoints", "=", "[", ".00005", ",", ".001", "]", "\n", "\n", "next_available_output_dir", "=", "1", "\n", "while", "os", ".", "path", ".", "isdir", "(", "output_dir", "+", "str", "(", "next_available_output_dir", ")", "+", "'/'", ")", ":", "\n", "        ", "next_available_output_dir", "+=", "1", "\n", "", "iterator", "=", "None", "\n", "all_datasets", "=", "None", "\n", "initial_rseed", "=", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "rseed", "=", "initial_rseed", "[", "initial_rseed", ".", "rfind", "(", "'.'", ")", "+", "1", ":", "]", "\n", "while", "rseed", ".", "startswith", "(", "'0'", ")", ":", "\n", "        ", "rseed", "=", "rseed", "[", "1", ":", "]", "\n", "", "if", "rseed", "==", "''", ":", "\n", "        ", "rseed", "=", "'1'", "\n", "", "random", ".", "seed", "(", "int", "(", "rseed", ")", ")", "\n", "for", "i", "in", "range", "(", "num_configs_to_try", "//", "2", ")", ":", "\n", "        ", "new_dropouts", "=", "[", "uniform", "(", "possible_dropout_endpoints", "[", "0", "]", ",", "possible_dropout_endpoints", "[", "1", "]", ")", "for", "i", "in", "range", "(", "3", ")", "]", "\n", "new_step_size", "=", "uniform", "(", "possible_step_endpoints", "[", "0", "]", ",", "possible_step_endpoints", "[", "1", "]", ")", "\n", "set_step_size_3_dropouts", "(", "config_file", ",", "new_step_size", ",", "new_dropouts", "[", "0", "]", ",", "new_dropouts", "[", "1", "]", ",", "new_dropouts", "[", "2", "]", ")", "\n", "\n", "for", "j", "in", "range", "(", "2", ")", ":", "\n", "            ", "sub_output_dir", "=", "output_dir", "+", "str", "(", "next_available_output_dir", ")", "+", "'/'", "\n", "next_available_output_dir", "+=", "1", "\n", "\n", "new_rand_seeds", "=", "[", "randint", "(", "1", ",", "1000", ")", "for", "i", "in", "range", "(", "3", ")", "]", "\n", "set_random_seeds", "(", "config_file", ",", "new_rand_seeds", "[", "0", "]", ",", "new_rand_seeds", "[", "1", "]", ",", "new_rand_seeds", "[", "2", "]", ")", "\n", "\n", "print", "(", "\"Starting to train model \"", "+", "str", "(", "2", "*", "i", "+", "j", "+", "1", ")", "+", "\" from \"", "+", "config_file", ")", "\n", "iterator", ",", "all_datasets", "=", "train_model", "(", "config_file", ",", "sub_output_dir", ",", "data_iter", "=", "iterator", ",", "\n", "all_datasets", "=", "all_datasets", ")", "\n", "\n", "with", "open", "(", "sub_output_dir", "+", "\"random_seeds.txt\"", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "str", "(", "new_rand_seeds", "[", "0", "]", ")", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "str", "(", "new_rand_seeds", "[", "1", "]", ")", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "str", "(", "new_rand_seeds", "[", "2", "]", ")", "+", "'\\n'", ")", "\n", "\n", "# get rid of all model's .th files and .tar.gz file: since this is a hyperparam search,", "\n", "# we just want the reported metrics, so no need to take up a bunch of extra memory", "\n", "", "filenames_to_delete", "=", "glob", "(", "sub_output_dir", "+", "'*.tar.gz'", ")", "\n", "for", "filename", "in", "filenames_to_delete", ":", "\n", "                ", "os", ".", "remove", "(", "filename", ")", "\n", "", "filenames_to_delete", "=", "glob", "(", "sub_output_dir", "+", "'*.th'", ")", "\n", "for", "filename", "in", "filenames_to_delete", ":", "\n", "                ", "os", ".", "remove", "(", "filename", ")", "\n", "", "filenames_to_delete", "=", "glob", "(", "sub_output_dir", "+", "'vocabulary/*'", ")", "\n", "for", "filename", "in", "filenames_to_delete", ":", "\n", "                ", "os", ".", "remove", "(", "filename", ")", "\n", "", "os", ".", "rmdir", "(", "sub_output_dir", "+", "'vocabulary/'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.train_model": [[167, 282], ["allennlp.common.Params.from_file", "allennlp.common.util.prepare_environment", "allennlp.commands.train.create_serialization_dir", "allennlp.common.util.prepare_global_logging", "Params.from_file.params.get().get", "isinstance", "Params.from_file.to_file", "set", "allennlp.commands.train.logger.info", "allennlp.data.Vocabulary.from_params", "allennlp.models.model.Model.from_params", "Vocabulary.from_params.save_to_files", "Params.from_file.pop", "Params.from_file.pop", "allennlp.commands.train.datasets_from_params.get", "allennlp.commands.train.datasets_from_params.get", "Params.from_file.pop", "params.pop.pop", "Model.from_params.named_parameters", "allennlp.training.trainer.Trainer.from_params", "Params.from_file.pop_bool", "Params.from_file.assert_empty", "allennlp.models.archival.archive_model", "allennlp.commands.train.logger.info", "os.path.join", "torch.load", "best_model.load_state_dict", "allennlp_internal_functions.dump_metrics", "allennlp.common.checks.check_for_gpu", "os.path.join", "allennlp.commands.train.datasets_from_params", "Params.from_file.pop", "Params.from_file.pop", "Params.from_file.pop", "Params.from_file.pop", "Params.from_file.pop", "os.path.join", "params.pop.pop", "allennlp.data.iterators.data_iterator.DataIterator.from_params", "DataIterator.from_params.index_with", "allennlp.data.iterators.data_iterator.DataIterator.from_params", "DataIterator.from_params.index_with", "any", "Trainer.from_params.train", "allennlp.commands.train.logger.info", "allennlp.commands.evaluate.evaluate", "allennlp.commands.evaluate.evaluate.items", "os.path.join", "Params.from_file.params.get", "allennlp.common.checks.check_for_gpu", "allennlp.common.checks.ConfigurationError", "Params.from_file.pop", "parameter.requires_grad_", "os.path.exists", "allennlp.commands.train.logger.info", "allennlp.commands.train.datasets_from_params.items", "re.search", "os.path.join", "logging.info", "allennlp.models.archival.archive_model"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.dump_metrics", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.allennlp_internal_functions.datasets_from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.train_model.TrainerPieces.from_params", "home.repos.pwc.inspect_result.serrano-s_attn-tests.None.plain_model_test.evaluate"], ["", "", "", "def", "train_model", "(", "config_file", ",", "sub_output_dir", ",", "data_iter", "=", "None", ",", "all_datasets", "=", "None", ")", ":", "\n", "    ", "params", "=", "Params", ".", "from_file", "(", "config_file", ",", "''", ")", "\n", "\n", "serialization_dir", "=", "sub_output_dir", "\n", "\n", "prepare_environment", "(", "params", ")", "\n", "\n", "create_serialization_dir", "(", "params", ",", "serialization_dir", ",", "False", ")", "\n", "prepare_global_logging", "(", "serialization_dir", ",", "False", ")", "\n", "\n", "cuda_device", "=", "params", ".", "params", ".", "get", "(", "'trainer'", ")", ".", "get", "(", "'cuda_device'", ",", "-", "1", ")", "\n", "if", "isinstance", "(", "cuda_device", ",", "list", ")", ":", "\n", "        ", "for", "device", "in", "cuda_device", ":", "\n", "            ", "check_for_gpu", "(", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "check_for_gpu", "(", "cuda_device", ")", "\n", "\n", "", "params", ".", "to_file", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", ")", "\n", "\n", "if", "all_datasets", "is", "None", ":", "\n", "        ", "all_datasets", "=", "datasets_from_params", "(", "params", ")", "\n", "", "else", ":", "\n", "        ", "params", ".", "pop", "(", "\"train_data_path\"", ")", "\n", "params", ".", "pop", "(", "\"validation_data_path\"", ")", "\n", "params", ".", "pop", "(", "\"dataset_reader\"", ")", "\n", "", "datasets_for_vocab_creation", "=", "set", "(", "params", ".", "pop", "(", "\"datasets_for_vocab_creation\"", ",", "all_datasets", ")", ")", "\n", "\n", "for", "dataset", "in", "datasets_for_vocab_creation", ":", "\n", "        ", "if", "dataset", "not", "in", "all_datasets", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"invalid 'dataset_for_vocab_creation' {dataset}\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"From dataset instances, %s will be considered for vocabulary creation.\"", ",", "\n", "\", \"", ".", "join", "(", "datasets_for_vocab_creation", ")", ")", "\n", "vocab", "=", "Vocabulary", ".", "from_params", "(", "\n", "params", ".", "pop", "(", "\"vocabulary\"", ",", "{", "}", ")", ",", "\n", "(", "instance", "for", "key", ",", "dataset", "in", "all_datasets", ".", "items", "(", ")", "\n", "for", "instance", "in", "dataset", "\n", "if", "key", "in", "datasets_for_vocab_creation", ")", "\n", ")", "\n", "\n", "model", "=", "Model", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "params", ".", "pop", "(", "'model'", ")", ")", "\n", "\n", "# Initializing the model can have side effect of expanding the vocabulary", "\n", "vocab", ".", "save_to_files", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"vocabulary\"", ")", ")", "\n", "\n", "intercepted_iter_params", "=", "params", ".", "pop", "(", "\"iterator\"", ")", "\n", "if", "data_iter", "is", "None", ":", "\n", "        ", "iter_type", "=", "intercepted_iter_params", ".", "pop", "(", "\"type\"", ")", "\n", "assert", "iter_type", "==", "\"extended_bucket\"", ",", "iter_type", "\n", "intercepted_iter_params", ".", "params", "[", "\"type\"", "]", "=", "\"extended_bucket_for_reuse\"", "\n", "\n", "iterator", "=", "DataIterator", ".", "from_params", "(", "intercepted_iter_params", ")", "\n", "iterator", ".", "index_with", "(", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "data_iter", "\n", "\n", "", "validation_iterator_params", "=", "params", ".", "pop", "(", "\"validation_iterator\"", ",", "None", ")", "\n", "if", "validation_iterator_params", ":", "\n", "        ", "validation_iterator", "=", "DataIterator", ".", "from_params", "(", "validation_iterator_params", ")", "\n", "validation_iterator", ".", "index_with", "(", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "validation_iterator", "=", "None", "\n", "\n", "", "train_data", "=", "all_datasets", "[", "'train'", "]", "\n", "validation_data", "=", "all_datasets", ".", "get", "(", "'validation'", ")", "\n", "test_data", "=", "all_datasets", ".", "get", "(", "'test'", ")", "\n", "\n", "trainer_params", "=", "params", ".", "pop", "(", "\"trainer\"", ")", "\n", "no_grad_regexes", "=", "trainer_params", ".", "pop", "(", "\"no_grad\"", ",", "(", ")", ")", "\n", "for", "name", ",", "parameter", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "any", "(", "re", ".", "search", "(", "regex", ",", "name", ")", "for", "regex", "in", "no_grad_regexes", ")", ":", "\n", "            ", "parameter", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "", "", "trainer", "=", "Trainer", ".", "from_params", "(", "model", "=", "model", ",", "serialization_dir", "=", "serialization_dir", ",", "iterator", "=", "iterator", ",", "\n", "train_data", "=", "train_data", ",", "validation_data", "=", "validation_data", ",", "params", "=", "trainer_params", ",", "\n", "validation_iterator", "=", "validation_iterator", ")", "\n", "\n", "evaluate_on_test", "=", "params", ".", "pop_bool", "(", "\"evaluate_on_test\"", ",", "False", ")", "\n", "params", ".", "assert_empty", "(", "'base train command'", ")", "\n", "\n", "try", ":", "\n", "        ", "metrics", "=", "trainer", ".", "train", "(", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "# if we have completed an epoch, try to create a model archive.", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "_DEFAULT_WEIGHTS", ")", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\"Training interrupted by the user. Attempting to create \"", "\n", "\"a model archive using the current best epoch weights.\"", ")", "\n", "archive_model", "(", "serialization_dir", ",", "files_to_archive", "=", "params", ".", "files_to_archive", ")", "\n", "", "raise", "\n", "\n", "# Now tar up results", "\n", "", "archive_model", "(", "serialization_dir", ",", "files_to_archive", "=", "params", ".", "files_to_archive", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loading the best epoch weights.\"", ")", "\n", "best_model_state_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "'best.th'", ")", "\n", "best_model_state", "=", "torch", ".", "load", "(", "best_model_state_path", ")", "\n", "best_model", "=", "model", "\n", "best_model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "\n", "if", "test_data", "and", "evaluate_on_test", ":", "\n", "        ", "logger", ".", "info", "(", "\"The model will be evaluated using the best epoch weights.\"", ")", "\n", "test_metrics", "=", "evaluate", "(", "\n", "best_model", ",", "test_data", ",", "validation_iterator", "or", "iterator", ",", "\n", "cuda_device", "=", "trainer", ".", "_cuda_devices", "[", "0", "]", "# pylint: disable=protected-access", "\n", ")", "\n", "for", "key", ",", "value", "in", "test_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"test_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "", "elif", "test_data", ":", "\n", "        ", "logger", ".", "info", "(", "\"To evaluate on the test set after training, pass the \"", "\n", "\"'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\"", ")", "\n", "\n", "", "dump_metrics", "(", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "\"metrics.json\"", ")", ",", "metrics", ",", "log", "=", "True", ")", "\n", "\n", "return", "iterator", ",", "all_datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.main": [[284, 319], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "allennlp.common.util.import_submodules", "hyperparam_search.edit_config_file_to_have_gpu", "hyperparam_search.run_hyperparam_search", "parser.parse_args.output_dir_base.endswith", "os.path.isdir", "os.makedirs", "parser.parse_args.dir_with_config_files.endswith", "os.path.isdir", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.edit_config_file_to_have_gpu", "home.repos.pwc.inspect_result.serrano-s_attn-tests.misc_scripts.hyperparam_search.run_hyperparam_search"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The type of model to train\"", ",", "\n", "choices", "=", "[", "'hanrnn'", ",", "'hanconv'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset-name\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Which dataset to train the model on\"", ",", "\n", "choices", "=", "[", "'amazon'", ",", "'yahoo10cat'", ",", "'yelp'", ",", "'imdb'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpu\"", ",", "type", "=", "int", ",", "required", "=", "True", ",", "\n", "help", "=", "\"GPU to use (can supply -1 if not using GPU)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-configs-to-try\"", ",", "type", "=", "int", ",", "required", "=", "True", ",", "\n", "help", "=", "\"How many different configs to randomly sample\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--output-dir-base\"", ",", "required", "=", "False", ",", "\n", "default", "=", "\"/homes/gws/sofias6/models/hyperparam_search/\"", ",", "\n", "help", "=", "\"Which directory each individual model's serialization directory sits in\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dir-with-config-files\"", ",", "required", "=", "False", ",", "\n", "default", "=", "\"/homes/gws/sofias6/textcat/attn_tests/configs/\"", ",", "\n", "help", "=", "\"Base directory for all config files\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "not", "args", ".", "output_dir_base", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "args", ".", "output_dir_base", "+=", "'/'", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "output_dir_base", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir_base", ")", "\n", "", "if", "not", "args", ".", "dir_with_config_files", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "args", ".", "dir_with_config_files", "+=", "'/'", "\n", "", "output_dir", "=", "args", ".", "output_dir_base", "+", "args", ".", "dataset_name", "+", "'-'", "+", "args", ".", "model", "+", "'/'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "import_submodules", "(", "'attn_tests_lib'", ")", "# gives us access to ConvSeq2SeqEncoder, etc.", "\n", "config_file", "=", "args", ".", "dir_with_config_files", "+", "args", ".", "dataset_name", "+", "corresponding_config_files", "[", "args", ".", "model", "]", "\n", "edit_config_file_to_have_gpu", "(", "config_file", ",", "args", ".", "gpu", ")", "\n", "\n", "run_hyperparam_search", "(", "config_file", ",", "output_dir", ",", "args", ".", "num_configs_to_try", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HierarchicalAttentionNetwork.__init__": [[49, 86], ["allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "vocab.get_vocab_size", "allennlp.training.metrics.CategoricalAccuracy", "initializer", "allennlp.training.metrics.F1Measure", "len", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "hierarchical_attention_network.HierarchicalAttentionNetwork._output_logit.get_output_dim", "len", "hierarchical_attention_network.HierarchicalAttentionNetwork._output_logit.get_output_dim", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.get_output_dim", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.get_output_dim"], ["def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "sentence_encoder", ":", "Seq2SeqEncoder", ",", "\n", "document_encoder", ":", "Seq2SeqEncoder", ",", "\n", "word_attention", ":", "Seq2SeqEncoder", ",", "\n", "sentence_attention", ":", "Seq2SeqEncoder", ",", "\n", "output_logit", ":", "FeedForward", ",", "\n", "pre_sentence_encoder_dropout", ":", "float", "=", "0.0", ",", "\n", "pre_document_encoder_dropout", ":", "float", "=", "0.0", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ",", "\n", "calculate_f1", ":", "bool", "=", "False", ",", "\n", "loss_class_weights", ":", "List", "[", "float", "]", "=", "(", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "_text_field_embedder", "=", "text_field_embedder", "\n", "self", ".", "_word_attention", "=", "word_attention", "\n", "self", ".", "_sentence_attention", "=", "sentence_attention", "\n", "self", ".", "_pre_sentence_encoder_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "pre_sentence_encoder_dropout", ")", "\n", "self", ".", "_sentence_encoder", "=", "sentence_encoder", "\n", "self", ".", "_pre_document_encoder_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "pre_document_encoder_dropout", ")", "\n", "self", ".", "_document_encoder", "=", "document_encoder", "\n", "\n", "self", ".", "_output_logit", "=", "output_logit", "\n", "\n", "self", ".", "_num_labels", "=", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "\"labels\"", ")", "\n", "self", ".", "_accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "calculate_f1", "=", "calculate_f1", "or", "(", "self", ".", "_output_logit", ".", "get_output_dim", "(", ")", "==", "2", ")", "\n", "if", "self", ".", "calculate_f1", ":", "\n", "            ", "self", ".", "_f1", "=", "F1Measure", "(", "1", ")", "\n", "", "if", "len", "(", "loss_class_weights", ")", "==", "0", ":", "\n", "            ", "self", ".", "_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "loss_class_weights", ")", "==", "self", ".", "_output_logit", ".", "get_output_dim", "(", ")", "\n", "self", ".", "_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "torch", ".", "FloatTensor", "(", "loss_class_weights", ")", ")", "# [1, 3.65]", "\n", "\n", "", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HierarchicalAttentionNetwork.forward": [[87, 160], ["tokens_.view.view.size", "tokens_.view.view.size", "tokens_[].view", "tokens_.view.view.new_zeros().float", "torch.nonzero", "inds_of_nonzero_rows.view.view.view", "sentence_level_mask.view.view.view", "hierarchical_attention_network.HierarchicalAttentionNetwork._text_field_embedder", "hierarchical_attention_network.HierarchicalAttentionNetwork.size", "hierarchical_attention_network.HierarchicalAttentionNetwork.view", "tokens_.view.view.view", "allennlp.nn.util.get_text_field_mask().float", "hierarchical_attention_network.HierarchicalAttentionNetwork._pre_sentence_encoder_dropout", "hierarchical_attention_network.HierarchicalAttentionNetwork._sentence_encoder", "hierarchical_attention_network.HierarchicalAttentionNetwork._word_attention", "torch.sum", "hierarchical_attention_network.HierarchicalAttentionNetwork.view", "hierarchical_attention_network.HierarchicalAttentionNetwork._pre_document_encoder_dropout", "hierarchical_attention_network.HierarchicalAttentionNetwork._document_encoder", "hierarchical_attention_network.HierarchicalAttentionNetwork._sentence_attention", "torch.sum", "hierarchical_attention_network.HierarchicalAttentionNetwork._output_logit", "torch.nn.functional.softmax", "hierarchical_attention_network.HierarchicalAttentionNetwork.size", "torch.sum.view", "hierarchical_attention_network.HierarchicalAttentionNetwork._loss", "hierarchical_attention_network.HierarchicalAttentionNetwork._accuracy", "tokens_.view.view.new_zeros", "allennlp.nn.util.get_text_field_mask", "label.long().view", "hierarchical_attention_network.HierarchicalAttentionNetwork._f1", "label.long"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.None.process_test_outputs.softmax"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "label", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", "# pylint:disable=unused-argument", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        tokens : Dict[str, torch.LongTensor]\n            From a ``TextField``. These are tokens should be segmented into their respective sentences.\n        label : torch.IntTensor, optional (default = None)\n            From a ``LabelField``\n        metadata : ``List[Dict[str, Any]]``, optional, (default = None)\n            Metadata to persist\n\n        Returns\n        -------\n        An output dictionary consisting of:\n\n        label_logits : torch.FloatTensor\n            A tensor of shape ``(batch_size, num_labels)`` representing unnormalised log\n            probabilities of the label.\n        label_probs : torch.FloatTensor\n            A tensor of shape ``(batch_size, num_labels)`` representing probabilities of the\n            label.\n        loss : torch.FloatTensor, optional\n            A scalar loss to be optimised.\n        \"\"\"", "\n", "# tokens['tokens'] is a 3-d tensor: all_docs x max_num_sents_in_any_doc x max_num_tokens_in_any_doc_sent", "\n", "# these tokens should be sentence-segmented.", "\n", "tokens_", "=", "tokens", "[", "'tokens'", "]", "\n", "batch_size", "=", "tokens_", ".", "size", "(", "0", ")", "\n", "max_num_sents", "=", "tokens_", ".", "size", "(", "1", ")", "\n", "first_token_ind_in_each_sentence", "=", "tokens_", "[", ":", ",", ":", ",", "0", "]", ".", "view", "(", "batch_size", "*", "max_num_sents", ")", "\n", "sentence_level_mask", "=", "tokens_", ".", "new_zeros", "(", "batch_size", "*", "max_num_sents", ")", ".", "float", "(", ")", "\n", "inds_of_nonzero_rows", "=", "torch", ".", "nonzero", "(", "first_token_ind_in_each_sentence", ")", "\n", "inds_of_nonzero_rows", "=", "inds_of_nonzero_rows", ".", "view", "(", "inds_of_nonzero_rows", ".", "shape", "[", "0", "]", ")", "\n", "sentence_level_mask", "[", "inds_of_nonzero_rows", "]", "=", "1", "\n", "sentence_level_mask", "=", "sentence_level_mask", ".", "view", "(", "batch_size", ",", "max_num_sents", ")", "\n", "\n", "embedded_words", "=", "self", ".", "_text_field_embedder", "(", "tokens", ")", "\n", "batch_size", ",", "max_sents", ",", "_", ",", "_", "=", "embedded_words", ".", "size", "(", ")", "\n", "embedded_words", "=", "embedded_words", ".", "view", "(", "batch_size", "*", "max_num_sents", ",", "embedded_words", ".", "size", "(", "2", ")", ",", "-", "1", ")", "\n", "tokens_", "=", "tokens_", ".", "view", "(", "batch_size", "*", "max_num_sents", ",", "-", "1", ")", "\n", "\n", "# we encode each sentence with a seq2seq encoder on its words, then seq2vec encoder incorporating attention", "\n", "mask", "=", "get_text_field_mask", "(", "{", "\"tokens\"", ":", "tokens_", "}", ")", ".", "float", "(", ")", "\n", "embedded_words", "=", "self", ".", "_pre_sentence_encoder_dropout", "(", "embedded_words", ")", "\n", "encoded_words", "=", "self", ".", "_sentence_encoder", "(", "embedded_words", ",", "mask", ")", "\n", "sentence_repr", "=", "self", ".", "_word_attention", "(", "encoded_words", ",", "mask", ")", "\n", "sentence_repr", "=", "torch", ".", "sum", "(", "sentence_repr", ",", "1", ")", "\n", "sentence_repr", "=", "sentence_repr", ".", "view", "(", "batch_size", ",", "max_num_sents", ",", "-", "1", ")", "\n", "\n", "# we encode each document with a seq2seq encoder on its sentences, then seq2vec encoder incorporating attention", "\n", "sentence_repr", "=", "self", ".", "_pre_document_encoder_dropout", "(", "sentence_repr", ")", "\n", "encoded_sents", "=", "self", ".", "_document_encoder", "(", "sentence_repr", ",", "sentence_level_mask", ")", "\n", "document_repr", "=", "self", ".", "_sentence_attention", "(", "encoded_sents", ",", "sentence_level_mask", ")", "\n", "document_repr", "=", "torch", ".", "sum", "(", "document_repr", ",", "1", ")", "\n", "\n", "label_logits", "=", "self", ".", "_output_logit", "(", "document_repr", ".", "view", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "label_probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "label_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output_dict", "=", "{", "\"label_logits\"", ":", "label_logits", ",", "\"label_probs\"", ":", "label_probs", "}", "\n", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "_loss", "(", "label_logits", ",", "label", ".", "long", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "self", ".", "_accuracy", "(", "label_logits", ",", "label", ")", "\n", "if", "self", ".", "calculate_f1", ":", "\n", "                ", "self", ".", "_f1", "(", "label_logits", ",", "label", ")", "\n", "", "output_dict", "[", "\"loss\"", "]", "=", "loss", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HierarchicalAttentionNetwork.reconstruct_attn_weights_for_testing": [[161, 187], ["encoded_sentences.new_zeros().cpu", "range", "print", "exit", "encoded_sentences.size", "sentence_repr.size", "encoded_sentences.size", "range", "str", "encoded_sentences.new_zeros", "encoded_sentences.size", "range", "torch.sum", "torch.sum", "encoded_sentences.size", "encoded_sentences.size", "encoded_sentences.size", "math.isclose", "float", "str", "float", "float", "str"], "methods", ["None"], ["", "def", "reconstruct_attn_weights_for_testing", "(", "self", ",", "encoded_sentences", ",", "sentence_repr", ")", ":", "\n", "        ", "assert", "encoded_sentences", ".", "size", "(", "2", ")", "==", "sentence_repr", ".", "size", "(", "2", ")", ",", "\"reconstruct_attn_weights_for_testing doesn't work if there's a projection\"", "\n", "weights", "=", "encoded_sentences", ".", "new_zeros", "(", "(", "encoded_sentences", ".", "size", "(", "0", ")", ",", "encoded_sentences", ".", "size", "(", "1", ")", ")", ")", ".", "cpu", "(", ")", "\n", "for", "sent_ind", "in", "range", "(", "encoded_sentences", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "for", "word_ind", "in", "range", "(", "encoded_sentences", ".", "size", "(", "1", ")", ")", ":", "\n", "                ", "maybe_multiplier", "=", "None", "\n", "for", "other_dim", "in", "range", "(", "encoded_sentences", ".", "size", "(", "2", ")", ")", ":", "\n", "                    ", "if", "maybe_multiplier", "is", "not", "None", ":", "\n", "                        ", "assert", "isclose", "(", "float", "(", "(", "sentence_repr", "[", "sent_ind", ",", "word_ind", ",", "other_dim", "]", "/", "\n", "encoded_sentences", "[", "sent_ind", ",", "word_ind", ",", "other_dim", "]", ")", ".", "data", ")", ",", "maybe_multiplier", ",", "\n", "abs_tol", "=", ".0001", ")", ",", "(", "\"Hypothesized multiplier is \"", "+", "str", "(", "maybe_multiplier", ")", "+", "\" but just found a multiplier of \"", "+", "\n", "str", "(", "float", "(", "(", "sentence_repr", "[", "sent_ind", ",", "word_ind", ",", "other_dim", "]", "/", "\n", "encoded_sentences", "[", "sent_ind", ",", "word_ind", ",", "other_dim", "]", ")", ".", "data", ")", ")", ")", "\n", "", "elif", "encoded_sentences", "[", "sent_ind", ",", "word_ind", ",", "other_dim", "]", ".", "data", "!=", "0", ":", "\n", "                        ", "maybe_multiplier", "=", "float", "(", "(", "sentence_repr", "[", "sent_ind", ",", "word_ind", ",", "other_dim", "]", "/", "\n", "encoded_sentences", "[", "sent_ind", ",", "word_ind", ",", "other_dim", "]", ")", ".", "data", ")", "\n", "", "", "if", "maybe_multiplier", "is", "None", ":", "\n", "# assume it's zero", "\n", "                    ", "maybe_multiplier", "=", "0", "\n", "", "weights", "[", "sent_ind", ",", "word_ind", "]", "=", "maybe_multiplier", "\n", "\n", "", "assert", ".99", "<", "torch", ".", "sum", "(", "weights", "[", "sent_ind", ",", ":", "]", ")", "<", "1.01", ",", "str", "(", "torch", ".", "sum", "(", "weights", "[", "sent_ind", ",", ":", "]", ")", ")", "\n", "", "print", "(", "weights", "[", "0", "]", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HierarchicalAttentionNetwork.get_metrics": [[188, 195], ["hierarchical_attention_network.HierarchicalAttentionNetwork._f1.get_metric", "hierarchical_attention_network.HierarchicalAttentionNetwork._accuracy.get_metric", "hierarchical_attention_network.HierarchicalAttentionNetwork._accuracy.get_metric"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "if", "self", ".", "calculate_f1", ":", "\n", "            ", "f1_pieces", "=", "self", ".", "_f1", ".", "get_metric", "(", "reset", ")", "\n", "return", "{", "'accuracy'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", ",", "'f1'", ":", "f1_pieces", "[", "2", "]", ",", "\n", "'precision'", ":", "f1_pieces", "[", "0", "]", ",", "'recall'", ":", "f1_pieces", "[", "1", "]", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "'accuracy'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.__init__": [[199, 206], ["allennlp.modules.Seq2VecEncoder.__init__", "torch.nn.Linear", "torch.nn.Linear", "hierarchical_attention_network.HanAttention._mlp.weight.size"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_dim", ":", "int", "=", "None", ",", "\n", "context_vector_dim", ":", "int", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "HanAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_mlp", "=", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "context_vector_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "_context_dot_product", "=", "torch", ".", "nn", ".", "Linear", "(", "context_vector_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "vec_dim", "=", "self", ".", "_mlp", ".", "weight", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.get_input_dim": [[207, 209], ["None"], "methods", ["None"], ["", "def", "get_input_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "vec_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.get_output_dim": [[210, 212], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "vec_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.hierarchical_attention_network.HanAttention.forward": [[213, 225], ["tokens.size", "tokens.view", "torch.tanh", "hierarchical_attention_network.HanAttention._context_dot_product", "attn_weights.unsqueeze().expand.unsqueeze().expand.view", "allennlp.nn.util.masked_softmax", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.sum", "hierarchical_attention_network.HanAttention._mlp", "attn_weights.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "assert", "mask", "is", "not", "None", "\n", "batch_size", ",", "sequence_length", ",", "embedding_dim", "=", "tokens", ".", "size", "(", ")", "\n", "\n", "attn_weights", "=", "tokens", ".", "view", "(", "batch_size", "*", "sequence_length", ",", "embedding_dim", ")", "\n", "attn_weights", "=", "torch", ".", "tanh", "(", "self", ".", "_mlp", "(", "attn_weights", ")", ")", "\n", "attn_weights", "=", "self", ".", "_context_dot_product", "(", "attn_weights", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "batch_size", ",", "-", "1", ")", "# batch_size x seq_len", "\n", "attn_weights", "=", "masked_softmax", "(", "attn_weights", ",", "mask", ")", "\n", "attn_weights", "=", "attn_weights", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "batch_size", ",", "sequence_length", ",", "embedding_dim", ")", "\n", "\n", "return", "torch", ".", "sum", "(", "tokens", "*", "attn_weights", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.__init__": [[36, 38], ["sentence_splitter.SpacySentenceSplitter"], "methods", ["None"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_sentence_splitter", "=", "SpacySentenceSplitter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.tokenize": [[39, 49], ["sentence_tokenizer.SentenceTokenizer._sentence_splitter.split_sentences"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_splitter.SpacySentenceSplitter.split_sentences"], ["", "@", "overrides", "\n", "def", "tokenize", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "\"\"\"\n        Does whatever processing is required to convert a string of text into a sequence of tokens.\n\n        At a minimum, this uses a ``WordSplitter`` to split words into text.  It may also do\n        stemming or stopword removal, depending on the parameters given to the constructor.\n        \"\"\"", "\n", "sents", "=", "self", ".", "_sentence_splitter", ".", "split_sentences", "(", "text", ")", "\n", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.batch_tokenize": [[50, 54], ["sentence_tokenizer.SentenceTokenizer._sentence_splitter.batch_split_sentences"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_splitter.SpacySentenceSplitter.batch_split_sentences"], ["", "@", "overrides", "\n", "def", "batch_tokenize", "(", "self", ",", "texts", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "Token", "]", "]", ":", "\n", "        ", "batched_sents", "=", "self", ".", "_sentence_splitter", ".", "batch_split_sentences", "(", "texts", ")", "\n", "return", "batched_sents", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader.TextCatReader.__init__": [[50, 64], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "allennlp.data.tokenizers.WordTokenizer", "len", "sentence_tokenizer.SentenceTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.tokenizers.word_filter.PassThroughWordFilter"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["def", "__init__", "(", "self", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "word_tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "segment_sentences", ":", "bool", "=", "False", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "column_titles_to_index", ":", "List", "[", "str", "]", "=", "(", "\"tokens\"", ",", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "lazy", ")", "\n", "self", ".", "_word_tokenizer", "=", "word_tokenizer", "or", "WordTokenizer", "(", "word_filter", "=", "PassThroughWordFilter", "(", ")", ")", "\n", "self", ".", "_segment_sentences", "=", "segment_sentences", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "'tokens'", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "self", ".", "_column_titles_to_index", "=", "column_titles_to_index", "\n", "assert", "len", "(", "self", ".", "_column_titles_to_index", ")", ">", "0", "\n", "if", "self", ".", "_segment_sentences", ":", "\n", "            ", "self", ".", "_sentence_segmenter", "=", "SentenceTokenizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader.TextCatReader._read": [[66, 89], ["open", "logger.info", "data_file.readline().strip().split", "data_file.readlines", "allennlp.common.file_utils.cached_path", "data_file.readline().strip().split.index", "line.strip().split", "textcat_reader.TextCatReader.text_to_instance", "data_file.readline().strip", "range", "len", "len", "line.strip", "data_file.readline().strip().split.index", "tokens.strip", "data_file.readline().strip().split.index", "data_file.readline"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader.text_to_instance"], ["", "", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "cached_path", "(", "file_path", ")", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"Reading instances from lines in file at: %s\"", ",", "file_path", ")", "\n", "columns", "=", "data_file", ".", "readline", "(", ")", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "token_col_inds", "=", "[", "columns", ".", "index", "(", "self", ".", "_column_titles_to_index", "[", "field_ind", "]", ")", "\n", "for", "field_ind", "in", "range", "(", "len", "(", "self", ".", "_column_titles_to_index", ")", ")", "]", "\n", "for", "line", "in", "data_file", ".", "readlines", "(", ")", ":", "\n", "                ", "if", "not", "line", ":", "\n", "                    ", "continue", "\n", "", "items", "=", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "tokens", "=", "''", "\n", "for", "col_ind", "in", "token_col_inds", ":", "\n", "                    ", "tokens", "+=", "items", "[", "col_ind", "]", "+", "' '", "\n", "", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "tokens", "=", "items", "[", "columns", ".", "index", "(", "\"tokens\"", ")", "]", "\n", "if", "len", "(", "tokens", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "category", "=", "items", "[", "columns", ".", "index", "(", "\"category\"", ")", "]", "\n", "instance", "=", "self", ".", "text_to_instance", "(", "tokens", "=", "tokens", ",", "\n", "category", "=", "category", ")", "\n", "if", "instance", "is", "not", "None", ":", "\n", "                    ", "yield", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader.TextCatReader.text_to_instance": [[91, 134], ["allennlp.data.fields.LabelField", "allennlp.data.instance.Instance", "textcat_reader.TextCatReader._sentence_segmenter.tokenize", "len", "range", "allennlp.data.fields.ListField", "allennlp.data.fields.TextField", "textcat_reader.TextCatReader._word_tokenizer.tokenize", "text_fields.append", "len", "textcat_reader.TextCatReader._word_tokenizer.tokenize", "len", "allennlp.data.fields.TextField"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.tokenize", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.tokenize", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.tokenize"], ["", "", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "tokens", ":", "List", "[", "str", "]", ",", "category", ":", "str", "=", "None", ")", "->", "Instance", ":", "# type: ignore", "\n", "        ", "\"\"\"\n        We take `pre-tokenized` input here, because we don't have a tokenizer in this class.\n\n        Parameters\n        ----------\n        tokens : ``List[str]``, required.\n            The tokens in a given sentence.\n        category ``str``, optional, (default = None).\n            The category for this sentence.\n\n        Returns\n        -------\n        An ``Instance`` containing the following fields:\n            tokens : ``TextField``\n                The tokens in the sentence or phrase.\n            label : ``LabelField``\n                The category label of the sentence or phrase.\n        \"\"\"", "\n", "# pylint: disable=arguments-differ", "\n", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "text_fields", "=", "[", "]", "\n", "if", "self", ".", "_segment_sentences", ":", "\n", "            ", "sentence_tokens", "=", "self", ".", "_sentence_segmenter", ".", "tokenize", "(", "tokens", ")", "\n", "original_len_sentence_tokens", "=", "len", "(", "sentence_tokens", ")", "\n", "corresponding_sentence_ind", "=", "0", "\n", "for", "i", "in", "range", "(", "original_len_sentence_tokens", ")", ":", "\n", "                ", "sentence", "=", "sentence_tokens", "[", "corresponding_sentence_ind", "]", "\n", "word_tokens", "=", "self", ".", "_word_tokenizer", ".", "tokenize", "(", "sentence", ")", "\n", "if", "len", "(", "word_tokens", ")", "==", "0", ":", "\n", "                    ", "del", "sentence_tokens", "[", "corresponding_sentence_ind", "]", "\n", "continue", "\n", "", "text_fields", ".", "append", "(", "TextField", "(", "word_tokens", ",", "self", ".", "_token_indexers", ")", ")", "\n", "corresponding_sentence_ind", "+=", "1", "\n", "", "if", "len", "(", "text_fields", ")", "==", "0", ":", "\n", "                ", "return", "None", "\n", "", "fields", "[", "'tokens'", "]", "=", "ListField", "(", "text_fields", ")", "\n", "", "else", ":", "\n", "            ", "fields", "[", "'tokens'", "]", "=", "TextField", "(", "self", ".", "_word_tokenizer", ".", "tokenize", "(", "tokens", ")", ",", "\n", "self", ".", "_token_indexers", ")", "\n", "", "fields", "[", "'label'", "]", "=", "LabelField", "(", "category", ")", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_splitter.SentenceSplitter.split_sentences": [[13, 18], ["None"], "methods", ["None"], ["def", "split_sentences", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Splits ``texts`` into a list of :class:`Token` objects.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_splitter.SentenceSplitter.batch_split_sentences": [[19, 25], ["sentence_splitter.SentenceSplitter.split_sentences"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_splitter.SpacySentenceSplitter.split_sentences"], ["", "def", "batch_split_sentences", "(", "self", ",", "texts", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"\n        This method lets you take advantage of spacy's batch processing.\n        Default implementation is to just iterate over the texts and call ``split_sentences``.\n        \"\"\"", "\n", "return", "[", "self", ".", "split_sentences", "(", "text", ")", "for", "text", "in", "texts", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_splitter.SpacySentenceSplitter.__init__": [[37, 47], ["allennlp.common.util.get_spacy_model", "sentence_splitter.SpacySentenceSplitter.spacy.has_pipe", "sentence_splitter.SpacySentenceSplitter.spacy.create_pipe", "sentence_splitter.SpacySentenceSplitter.spacy.add_pipe"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "language", ":", "str", "=", "'en_core_web_sm'", ",", "\n", "rule_based", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "# we need spacy's dependency parser if we're not using rule-based sentence boundary detection.", "\n", "        ", "self", ".", "spacy", "=", "get_spacy_model", "(", "language", ",", "parse", "=", "not", "rule_based", ",", "ner", "=", "False", ",", "pos_tags", "=", "False", ")", "\n", "if", "rule_based", ":", "\n", "# we use `sbd`, a built-in spacy module for rule-based sentence boundary detection.", "\n", "            ", "if", "not", "self", ".", "spacy", ".", "has_pipe", "(", "'sbd'", ")", ":", "\n", "                ", "sbd", "=", "self", ".", "spacy", ".", "create_pipe", "(", "'sbd'", ")", "\n", "self", ".", "spacy", ".", "add_pipe", "(", "sbd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_splitter.SpacySentenceSplitter.split_sentences": [[48, 51], ["sent.string.strip", "sentence_splitter.SpacySentenceSplitter.spacy"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "split_sentences", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "sent", ".", "string", ".", "strip", "(", ")", "for", "sent", "in", "self", ".", "spacy", "(", "text", ")", ".", "sents", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_splitter.SpacySentenceSplitter.batch_split_sentences": [[52, 55], ["sentence.string.strip", "sentence_splitter.SpacySentenceSplitter.spacy.pipe"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "batch_split_sentences", "(", "self", ",", "texts", ":", "List", "[", "str", "]", ")", "->", "List", "[", "List", "[", "str", "]", "]", ":", "\n", "        ", "return", "[", "[", "sentence", ".", "string", ".", "strip", "(", ")", "for", "sentence", "in", "doc", ".", "sents", "]", "for", "doc", "in", "self", ".", "spacy", ".", "pipe", "(", "texts", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader.__init__": [[51, 71], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "model_folder_name.endswith", "allennlp.data.tokenizers.WordTokenizer", "len", "sentence_tokenizer.SentenceTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.tokenizers.word_filter.PassThroughWordFilter", "model_folder_name.rfind"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model_folder_name", ":", "str", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "word_tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "segment_sentences", ":", "bool", "=", "False", ",", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "column_titles_to_index", ":", "List", "[", "str", "]", "=", "(", "\"tokens\"", ",", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "lazy", ")", "\n", "if", "model_folder_name", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "model_folder_name", "=", "model_folder_name", "[", ":", "-", "1", "]", "\n", "", "if", "'/'", "in", "model_folder_name", ":", "\n", "            ", "model_folder_name", "=", "model_folder_name", "[", "model_folder_name", ".", "rfind", "(", "'/'", ")", "+", "1", ":", "]", "\n", "", "self", ".", "model_folder_name", "=", "model_folder_name", "\n", "self", ".", "_word_tokenizer", "=", "word_tokenizer", "or", "WordTokenizer", "(", "word_filter", "=", "PassThroughWordFilter", "(", ")", ")", "\n", "self", ".", "_segment_sentences", "=", "segment_sentences", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "'tokens'", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "self", ".", "_column_titles_to_index", "=", "column_titles_to_index", "\n", "assert", "len", "(", "self", ".", "_column_titles_to_index", ")", ">", "0", "\n", "if", "self", ".", "_segment_sentences", ":", "\n", "            ", "self", ".", "_sentence_segmenter", "=", "SentenceTokenizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader._read": [[72, 107], ["open", "open.close", "open", "logger.info", "data_file.readline().strip().split", "data_file.readlines", "open.readline", "allennlp.common.file_utils.cached_path", "data_file.readline().strip().split.index", "line.strip().split", "textcat_reader_attnlabel.TextCatAttnReader.text_to_instance", "isinstance", "data_file.readline().strip", "range", "len", "open.readline().strip", "allennlp.data.fields.LabelField", "len", "next_label[].isdigit", "len", "line.strip", "data_file.readline().strip().split.index", "tokens.strip", "open.readline.strip", "file_path.rfind", "data_file.readline", "open.readline"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader.text_to_instance"], ["", "", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "label_file_path", "=", "file_path", "[", ":", "file_path", ".", "rfind", "(", "'.'", ")", "]", "+", "\"_attnperformancelabels_\"", "+", "self", ".", "model_folder_name", "+", "\".txt\"", "\n", "label_file", "=", "open", "(", "label_file_path", ",", "'r'", ")", "\n", "with", "open", "(", "cached_path", "(", "file_path", ")", ",", "\"r\"", ")", "as", "data_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"Reading instances from lines in file at: %s\"", ",", "file_path", ")", "\n", "columns", "=", "data_file", ".", "readline", "(", ")", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "token_col_inds", "=", "[", "columns", ".", "index", "(", "self", ".", "_column_titles_to_index", "[", "field_ind", "]", ")", "\n", "for", "field_ind", "in", "range", "(", "len", "(", "self", ".", "_column_titles_to_index", ")", ")", "]", "\n", "for", "line", "in", "data_file", ".", "readlines", "(", ")", ":", "\n", "                ", "if", "not", "line", ":", "\n", "                    ", "continue", "\n", "", "items", "=", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "tokens", "=", "''", "\n", "for", "col_ind", "in", "token_col_inds", ":", "\n", "                    ", "tokens", "+=", "items", "[", "col_ind", "]", "+", "' '", "\n", "", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "tokens", "=", "items", "[", "columns", ".", "index", "(", "\"tokens\"", ")", "]", "\n", "if", "len", "(", "tokens", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "instance", "=", "self", ".", "text_to_instance", "(", "tokens", "=", "tokens", ")", "\n", "if", "instance", "is", "not", "None", ":", "\n", "                    ", "str_category", "=", "label_file", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "assert", "str_category", "!=", "''", "\n", "instance", ".", "fields", "[", "'label'", "]", "=", "LabelField", "(", "str_category", ")", "\n", "yield", "instance", "\n", "\n", "", "", "", "try", ":", "\n", "            ", "next_label", "=", "label_file", ".", "readline", "(", ")", "\n", "if", "isinstance", "(", "next_label", ",", "str", ")", "and", "len", "(", "next_label", ".", "strip", "(", ")", ")", ">=", "1", ":", "\n", "                ", "assert", "not", "next_label", "[", "0", "]", ".", "isdigit", "(", ")", ",", "\"We had too many labels corresponding to the given data file \"", "+", "file_path", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "", "label_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader.text_to_instance": [[108, 153], ["allennlp.data.instance.Instance", "textcat_reader_attnlabel.TextCatAttnReader._sentence_segmenter.tokenize", "len", "range", "allennlp.data.fields.ListField", "textcat_reader_attnlabel.TextCatAttnReader._word_tokenizer.tokenize", "allennlp.data.fields.TextField", "textcat_reader_attnlabel.TextCatAttnReader._word_tokenizer.tokenize", "text_fields.append", "len", "len", "len", "allennlp.data.fields.TextField"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.tokenize", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.tokenize", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.sentence_tokenizer.SentenceTokenizer.tokenize"], ["", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "tokens", ":", "List", "[", "str", "]", ")", "->", "Instance", ":", "# type: ignore", "\n", "        ", "\"\"\"\n        We take `pre-tokenized` input here, because we don't have a tokenizer in this class.\n\n        Parameters\n        ----------\n        tokens : ``List[str]``, required.\n            The tokens in a given sentence.\n        category ``str``, optional, (default = None).\n            The category for this sentence.\n\n        Returns\n        -------\n        An ``Instance`` containing the following fields:\n            tokens : ``TextField``\n                The tokens in the sentence or phrase.\n            label : ``LabelField``\n                The category label of the sentence or phrase.\n        \"\"\"", "\n", "# pylint: disable=arguments-differ", "\n", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "text_fields", "=", "[", "]", "\n", "if", "self", ".", "_segment_sentences", ":", "\n", "            ", "sentence_tokens", "=", "self", ".", "_sentence_segmenter", ".", "tokenize", "(", "tokens", ")", "\n", "original_len_sentence_tokens", "=", "len", "(", "sentence_tokens", ")", "\n", "corresponding_sentence_ind", "=", "0", "\n", "for", "i", "in", "range", "(", "original_len_sentence_tokens", ")", ":", "\n", "                ", "sentence", "=", "sentence_tokens", "[", "corresponding_sentence_ind", "]", "\n", "word_tokens", "=", "self", ".", "_word_tokenizer", ".", "tokenize", "(", "sentence", ")", "\n", "if", "len", "(", "word_tokens", ")", "==", "0", ":", "\n", "                    ", "del", "sentence_tokens", "[", "corresponding_sentence_ind", "]", "\n", "continue", "\n", "", "text_fields", ".", "append", "(", "TextField", "(", "word_tokens", ",", "self", ".", "_token_indexers", ")", ")", "\n", "corresponding_sentence_ind", "+=", "1", "\n", "", "if", "len", "(", "text_fields", ")", "==", "0", ":", "\n", "                ", "return", "None", "\n", "", "fields", "[", "'tokens'", "]", "=", "ListField", "(", "text_fields", ")", "\n", "", "else", ":", "\n", "            ", "list_of_word_tokens", "=", "self", ".", "_word_tokenizer", ".", "tokenize", "(", "tokens", ")", "\n", "if", "len", "(", "list_of_word_tokens", ")", "==", "0", ":", "\n", "                ", "return", "None", "\n", "", "fields", "[", "'tokens'", "]", "=", "TextField", "(", "list_of_word_tokens", ",", "\n", "self", ".", "_token_indexers", ")", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.calculate_word_stats.InstanceLenGenerator.__init__": [[22, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "allennlp_formatted_reader", ",", "filepaths", ")", ":", "\n", "        ", "self", ".", "allennlp_formatted_reader", "=", "allennlp_formatted_reader", "\n", "self", ".", "filepaths", "=", "filepaths", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.calculate_word_stats.InstanceLenGenerator.__iter__": [[26, 31], ["tqdm.tqdm.tqdm", "calculate_word_stats.InstanceLenGenerator.allennlp_formatted_reader._read", "len"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader._read"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "filepath", "in", "self", ".", "filepaths", ":", "\n", "            ", "for", "instance", "in", "tqdm", "(", "self", ".", "allennlp_formatted_reader", ".", "_read", "(", "file_path", "=", "filepath", ")", ")", ":", "\n", "                ", "instance_as_text_field", "=", "instance", ".", "fields", "[", "'tokens'", "]", "\n", "yield", "len", "(", "instance_as_text_field", ".", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.calculate_sentence_stats.get_nth_field_in_line": [[21, 32], ["line.rfind", "line.index", "line.index"], "function", ["None"], ["def", "get_nth_field_in_line", "(", "line", ",", "ind", ")", ":", "\n", "    ", "counter", "=", "0", "\n", "while", "counter", "<", "ind", ":", "\n", "        ", "line", "=", "line", "[", "line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "counter", "+=", "1", "\n", "", "if", "line", ".", "rfind", "(", "'\\t'", ")", "==", "-", "1", ":", "\n", "# this is the last field, so just remove the trailing newline", "\n", "        ", "return", "line", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "# return the remaining line up to the next tab", "\n", "        ", "return", "line", "[", ":", "line", ".", "index", "(", "'\\t'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.calculate_sentence_stats.get_info_about_data_len_distribution": [[33, 62], ["open", "int", "int", "numsents_maxnumtokens.append", "line.strip", "calculate_sentence_stats.get_nth_field_in_line", "calculate_sentence_stats.get_nth_field_in_line", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.index", "temp_line.index"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line"], ["", "", "def", "get_info_about_data_len_distribution", "(", "filepaths", ")", ":", "\n", "    ", "numsents_maxnumtokens", "=", "[", "]", "\n", "for", "filepath", "in", "filepaths", ":", "\n", "        ", "first_line", "=", "True", "\n", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "first_line", ":", "\n", "# find which fields are num_sentences and max_num_tokens_in_sentence", "\n", "                    ", "temp_line", "=", "line", "\n", "num_sents_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'num_sentences\\t'", ")", "or", "temp_line", ".", "startswith", "(", "'num_sentences\\n'", ")", ")", ":", "\n", "                        ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "num_sents_field_ind", "+=", "1", "\n", "", "temp_line", "=", "line", "\n", "max_num_tokens_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\t'", ")", "or", "\n", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\n'", ")", ")", ":", "\n", "                        ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "max_num_tokens_field_ind", "+=", "1", "\n", "", "first_line", "=", "False", "\n", "", "else", ":", "\n", "                    ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                        ", "continue", "\n", "", "num_sents", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "num_sents_field_ind", ")", ")", "\n", "max_num_tokens", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "max_num_tokens_field_ind", ")", ")", "\n", "numsents_maxnumtokens", ".", "append", "(", "(", "num_sents", ",", "max_num_tokens", ")", ")", "\n", "\n", "", "", "", "", "num_sentences", "=", "[", "tup", "[", "0", "]", "for", "tup", "in", "numsents_maxnumtokens", "]", "\n", "return", "num_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.GensimSentenceIterator.__init__": [[46, 51], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "allennlp_formatted_reader", ",", "filepaths", ",", "valid_vocab_words", ":", "dict", "=", "None", ",", "total_num_sentences", "=", "None", ")", ":", "\n", "        ", "self", ".", "allennlp_formatted_reader", "=", "allennlp_formatted_reader", "\n", "self", ".", "filepaths", "=", "filepaths", "\n", "self", ".", "valid_vocab_words", "=", "valid_vocab_words", "\n", "self", ".", "total_num_sentences", "=", "total_num_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.GensimSentenceIterator.__iter__": [[52, 99], ["tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.GensimSentenceIterator.allennlp_formatted_reader._read", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.GensimSentenceIterator.allennlp_formatted_reader._read", "token.text.lower", "token.text.lower", "token.text.lower", "token.text.lower", "token.text.lower", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader._read", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader._read"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "filepath", "in", "self", ".", "filepaths", ":", "\n", "            ", "if", "self", ".", "total_num_sentences", "is", "None", ":", "\n", "                ", "for", "instance", "in", "tqdm", "(", "self", ".", "allennlp_formatted_reader", ".", "_read", "(", "file_path", "=", "filepath", ")", ")", ":", "\n", "                    ", "list_of_sentences", "=", "instance", ".", "fields", "[", "'tokens'", "]", ".", "field_list", "\n", "for", "sentence_as_text_field", "in", "list_of_sentences", ":", "\n", "                        ", "list_of_tokens", "=", "sentence_as_text_field", ".", "tokens", "\n", "if", "lowercase_all_tokens", ":", "\n", "                            ", "if", "self", ".", "valid_vocab_words", "is", "None", ":", "\n", "                                ", "list_of_str_tokens", "=", "[", "token", ".", "text", ".", "lower", "(", ")", "for", "token", "in", "list_of_tokens", "]", "\n", "", "else", ":", "\n", "# we know which words shouldn't be unked, so unk the rest", "\n", "                                ", "list_of_str_tokens", "=", "[", "token", ".", "text", ".", "lower", "(", ")", "if", "(", "token", ".", "text", ".", "lower", "(", ")", "in", "\n", "self", ".", "valid_vocab_words", ")", "\n", "else", "unk_token", "for", "token", "in", "list_of_tokens", "]", "\n", "", "", "else", ":", "\n", "                            ", "if", "self", ".", "valid_vocab_words", "is", "None", ":", "\n", "                                ", "list_of_str_tokens", "=", "[", "token", ".", "text", "for", "token", "in", "list_of_tokens", "]", "\n", "", "else", ":", "\n", "# we know which words shouldn't be unked, so unk the rest", "\n", "                                ", "list_of_str_tokens", "=", "[", "token", ".", "text", "if", "(", "token", ".", "text", "in", "self", ".", "valid_vocab_words", ")", "else", "\n", "unk_token", "\n", "for", "token", "in", "list_of_tokens", "]", "\n", "", "", "yield", "list_of_str_tokens", "\n", "", "", "", "else", ":", "\n", "                ", "for", "instance", "in", "tqdm", "(", "self", ".", "allennlp_formatted_reader", ".", "_read", "(", "file_path", "=", "filepath", ")", ",", "\n", "total", "=", "self", ".", "total_num_sentences", ")", ":", "\n", "                    ", "list_of_sentences", "=", "instance", ".", "fields", "[", "'tokens'", "]", ".", "field_list", "\n", "for", "sentence_as_text_field", "in", "list_of_sentences", ":", "\n", "                        ", "list_of_tokens", "=", "sentence_as_text_field", ".", "tokens", "\n", "if", "lowercase_all_tokens", ":", "\n", "                            ", "if", "self", ".", "valid_vocab_words", "is", "None", ":", "\n", "                                ", "list_of_str_tokens", "=", "[", "token", ".", "text", ".", "lower", "(", ")", "for", "token", "in", "list_of_tokens", "]", "\n", "", "else", ":", "\n", "# we know which words shouldn't be unked, so unk the rest", "\n", "                                ", "list_of_str_tokens", "=", "[", "token", ".", "text", ".", "lower", "(", ")", "if", "(", "token", ".", "text", ".", "lower", "(", ")", "in", "\n", "self", ".", "valid_vocab_words", ")", "\n", "else", "unk_token", "for", "token", "in", "list_of_tokens", "]", "\n", "", "", "else", ":", "\n", "                            ", "if", "self", ".", "valid_vocab_words", "is", "None", ":", "\n", "                                ", "list_of_str_tokens", "=", "[", "token", ".", "text", "for", "token", "in", "list_of_tokens", "]", "\n", "", "else", ":", "\n", "# we know which words shouldn't be unked, so unk the rest", "\n", "                                ", "list_of_str_tokens", "=", "[", "token", ".", "text", "if", "(", "token", ".", "text", "in", "self", ".", "valid_vocab_words", ")", "else", "\n", "unk_token", "\n", "for", "token", "in", "list_of_tokens", "]", "\n", "", "", "yield", "list_of_str_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.SimpleIterator.__init__": [[102, 105], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filepaths", ",", "total_num_sentences", "=", "None", ")", ":", "\n", "        ", "self", ".", "filepaths", "=", "filepaths", "\n", "self", ".", "total_num_sentences", "=", "total_num_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.SimpleIterator.__iter__": [[106, 119], ["open", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "line.strip", "line[].split", "line.strip", "line[].split"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "filepath", "in", "self", ".", "filepaths", ":", "\n", "            ", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "if", "self", ".", "total_num_sentences", "is", "not", "None", ":", "\n", "                    ", "for", "line", "in", "tqdm", "(", "f", ",", "total", "=", "self", ".", "total_num_sentences", ")", ":", "\n", "                        ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                            ", "continue", "\n", "", "yield", "line", "[", ":", "-", "1", "]", ".", "split", "(", "' '", ")", "# get rid of the newline at the end", "\n", "", "", "else", ":", "\n", "                    ", "for", "line", "in", "tqdm", "(", "f", ")", ":", "\n", "                        ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                            ", "continue", "\n", "", "yield", "line", "[", ":", "-", "1", "]", ".", "split", "(", "' '", ")", "# get rid of the newline at the end", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__init__": [[122, 125], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "allennlp_formatted_reader", ",", "filepaths", ")", ":", "\n", "        ", "self", ".", "allennlp_formatted_reader", "=", "allennlp_formatted_reader", "\n", "self", ".", "filepaths", "=", "filepaths", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.__iter__": [[126, 130], ["get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator.allennlp_formatted_reader.read"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "filepath", "in", "self", ".", "filepaths", ":", "\n", "            ", "for", "instance", "in", "self", ".", "allennlp_formatted_reader", ".", "read", "(", "file_path", "=", "filepath", ")", ":", "\n", "                ", "yield", "instance", ".", "fields", "[", "'label'", "]", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_ind_to_word_mapping_file": [[132, 149], ["print", "open", "open.close", "open", "wordcounts.keys", "f.write", "open.write", "str", "datetime.datetime.now", "f.write", "open.write", "str", "str"], "function", ["None"], ["", "", "", "", "def", "make_ind_to_word_mapping_file", "(", "wordcounts", ",", "threshold_for_inclusion_in_vocab", ",", "filename", ",", "filename_wo_nums", ")", ":", "\n", "    ", "print", "(", "\"Starting to construct vocabulary from wordcounts at \"", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "num_actual_words_in_vocab", "=", "0", "\n", "words_to_inds", "=", "{", "}", "\n", "f_nonums", "=", "open", "(", "filename_wo_nums", ",", "\"w\"", ")", "\n", "with", "open", "(", "filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "word", "in", "wordcounts", ".", "keys", "(", ")", ":", "\n", "            ", "if", "wordcounts", "[", "word", "]", ">=", "threshold_for_inclusion_in_vocab", ":", "\n", "                ", "num_actual_words_in_vocab", "+=", "1", "\n", "f", ".", "write", "(", "str", "(", "num_actual_words_in_vocab", ")", "+", "\":\"", "+", "word", "+", "\"\\n\"", ")", "\n", "f_nonums", ".", "write", "(", "word", "+", "\"\\n\"", ")", "\n", "words_to_inds", "[", "word", "]", "=", "num_actual_words_in_vocab", "\n", "", "", "unk_index", "=", "num_actual_words_in_vocab", "+", "1", "\n", "f", ".", "write", "(", "str", "(", "unk_index", ")", "+", "\":\"", "+", "unk_token", "+", "\"\\n\"", ")", "\n", "f_nonums", ".", "write", "(", "unk_token", "+", "\"\\n\"", ")", "\n", "", "f_nonums", ".", "close", "(", ")", "\n", "return", "words_to_inds", ",", "unk_index", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_label_ind_files": [[151, 189], ["iter", "cur_label_dict.keys", "open", "open.close", "cur_label_dict.keys", "open", "range", "float", "numerical_labels_so_far.append", "len", "f.write", "open.write", "sorted", "first_data_filepath.rfind", "first_data_filepath.rfind", "str"], "function", ["None"], ["", "def", "make_label_ind_files", "(", "label_iterator", ")", ":", "\n", "    ", "next_unassigned_label", "=", "0", "\n", "cur_label_dict", "=", "{", "}", "\n", "for", "label", "in", "iter", "(", "label_iterator", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "cur_label_dict", "[", "label", "]", "\n", "", "except", ":", "\n", "            ", "cur_label_dict", "[", "label", "]", "=", "next_unassigned_label", "\n", "next_unassigned_label", "+=", "1", "\n", "", "", "all_labels_are_numbers", "=", "True", "\n", "numerical_labels_so_far", "=", "[", "]", "\n", "for", "label", "in", "cur_label_dict", ".", "keys", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "float_version", "=", "float", "(", "label", ")", "\n", "numerical_labels_so_far", ".", "append", "(", "(", "float_version", ",", "label", ")", ")", "\n", "", "except", ":", "\n", "            ", "all_labels_are_numbers", "=", "False", "\n", "break", "\n", "", "", "if", "all_labels_are_numbers", ":", "\n", "# then use one of the indexings that would arise from sorting the labels in numerical order", "\n", "        ", "all_labels_in_order", "=", "[", "tup", "[", "1", "]", "for", "tup", "in", "sorted", "(", "numerical_labels_so_far", ",", "key", "=", "(", "lambda", "x", ":", "x", "[", "0", "]", ")", ",", "reverse", "=", "False", ")", "]", "\n", "", "else", ":", "\n", "# then just use the ordering from cur_label_dict", "\n", "        ", "all_labels_in_order", "=", "[", "None", "]", "*", "next_unassigned_label", "\n", "for", "label", "in", "cur_label_dict", ".", "keys", "(", ")", ":", "\n", "            ", "all_labels_in_order", "[", "cur_label_dict", "[", "label", "]", "]", "=", "label", "\n", "", "assert", "None", "not", "in", "all_labels_in_order", "\n", "\n", "", "first_data_filepath", "=", "filepaths_of_data_to_train_on", "[", "0", "]", "\n", "filename", "=", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "label_ind_file_ending", "\n", "filename_wo_nums", "=", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "label_ind_not_numbered_file_ending", "\n", "f_nonums", "=", "open", "(", "filename_wo_nums", ",", "\"w\"", ")", "\n", "with", "open", "(", "filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "label_ind", "in", "range", "(", "len", "(", "all_labels_in_order", ")", ")", ":", "\n", "            ", "str_label", "=", "all_labels_in_order", "[", "label_ind", "]", "\n", "f", ".", "write", "(", "str", "(", "label_ind", ")", "+", "\":\"", "+", "str_label", "+", "\"\\n\"", ")", "\n", "f_nonums", ".", "write", "(", "str_label", "+", "\"\\n\"", ")", "\n", "", "", "f_nonums", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_vocab_and_collect_num_sentences": [[191, 210], ["iter", "print", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_ind_to_word_mapping_file", "print", "first_data_filepath.rfind", "first_data_filepath.rfind"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_ind_to_word_mapping_file"], ["", "def", "get_vocab_and_collect_num_sentences", "(", "sentence_iterator", ",", "first_data_filepath", ")", ":", "\n", "    ", "wordcounts", "=", "{", "}", "\n", "total_num_sentences", "=", "0", "\n", "for", "sentence", "in", "iter", "(", "sentence_iterator", ")", ":", "\n", "        ", "total_num_sentences", "+=", "1", "\n", "for", "word", "in", "sentence", ":", "\n", "            ", "try", ":", "\n", "                ", "wordcounts", "[", "word", "]", "+=", "1", "\n", "", "except", ":", "\n", "                ", "wordcounts", "[", "word", "]", "=", "1", "\n", "", "", "", "print", "(", "\"Collected wordcounts, now starting on vocab creation.\"", ")", "\n", "filename_wo_nums", "=", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "vocabword_ind_not_numbered_file_ending", "\n", "words_to_inds", ",", "num_words_in_vocab_including_unk", "=", "make_ind_to_word_mapping_file", "(", "wordcounts", ",", "min_word_count_to_avoid_unking", ",", "\n", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "\n", "vocabword_ind_file_ending", ",", "\n", "filename_wo_nums", ")", "\n", "print", "(", "\"Finished creating vocabulary.\"", ")", "\n", "return", "words_to_inds", ",", "num_words_in_vocab_including_unk", ",", "total_num_sentences", ",", "filename_wo_nums", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_temp_file_and_iterate_over_that_instead": [[212, 222], ["print", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.SimpleIterator", "print", "open", "iter", "f.write"], "function", ["None"], ["", "def", "make_temp_file_and_iterate_over_that_instead", "(", "sentence_iterator", ")", ":", "\n", "    ", "print", "(", "\"Starting to make temp file containing tokenized sentences...\"", ")", "\n", "temp_filename", "=", "filepaths_of_data_to_train_on", "[", "0", "]", "\n", "temp_filename", "=", "temp_filename", "+", "\".temp\"", "\n", "with", "open", "(", "temp_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "sentence", "in", "iter", "(", "sentence_iterator", ")", ":", "\n", "            ", "f", ".", "write", "(", "\" \"", ".", "join", "(", "sentence", ")", "+", "\"\\n\"", ")", "\n", "", "", "new_sentence_iterator", "=", "SimpleIterator", "(", "[", "temp_filename", "]", ")", "\n", "print", "(", "\"Done making that file.\"", ")", "\n", "return", "new_sentence_iterator", ",", "temp_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_3": [[224, 298], ["print", "print", "gensim.models.Word2Vec", "gensim.models.Word2Vec.build_vocab", "gensim.models.Word2Vec.train", "gensim.models.Word2Vec.save", "print", "numpy.zeros", "numpy.linalg.norm", "numpy.save", "print", "print", "os.path.isfile", "glob.glob", "open", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.SimpleIterator", "textcat.TextCatReader", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.GensimSentenceIterator", "iter", "open", "h5py.File", "f.create_dataset", "os.remove", "os.remove", "os.path.isfile", "str", "open", "str", "str", "str", "os.remove", "first_data_filepath.rfind", "line.strip", "allennlp.data.tokenizers.WordTokenizer", "first_data_filepath.rfind", "datetime.datetime.now", "line.strip", "datetime.datetime.now", "datetime.datetime.now", "line.strip", "first_data_filepath.rfind", "first_data_filepath.rfind", "allennlp.data.tokenizers.word_filter.PassThroughWordFilter"], "function", ["None"], ["", "def", "get_word2vec_and_vocab_part_3", "(", ")", ":", "\n", "    ", "first_data_filepath", "=", "filepaths_of_data_to_train_on", "[", "0", "]", "\n", "vocab_filename_nonums", "=", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "vocabword_ind_not_numbered_file_ending", "\n", "num_words_in_vocab_including_unk", "=", "0", "\n", "with", "open", "(", "vocab_filename_nonums", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                ", "continue", "\n", "", "num_words_in_vocab_including_unk", "+=", "1", "\n", "", "", "print", "(", "str", "(", "num_words_in_vocab_including_unk", ")", "+", "\" words in vocab, including unk token.\"", ")", "\n", "if", "write_temp_file_of_all_provided_data_with_set_vocab", ":", "\n", "        ", "temp_data_filename", "=", "first_data_filepath", "+", "\".temp\"", "\n", "sentence_iterator", "=", "SimpleIterator", "(", "[", "temp_data_filename", "]", ")", "\n", "total_num_sentences", "=", "-", "1", "\n", "with", "open", "(", "temp_data_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "total_num_sentences", "+=", "1", "\n", "", "", "", "else", ":", "\n", "        ", "allennlp_reader", "=", "TextCatReader", "(", "word_tokenizer", "=", "WordTokenizer", "(", "word_filter", "=", "PassThroughWordFilter", "(", ")", ")", ",", "\n", "segment_sentences", "=", "True", ")", "\n", "sentence_iterator", "=", "GensimSentenceIterator", "(", "allennlp_reader", ",", "filepaths_of_data_to_train_on", ")", "\n", "total_num_sentences", "=", "0", "\n", "for", "sentence", "in", "iter", "(", "sentence_iterator", ")", ":", "\n", "            ", "total_num_sentences", "+=", "1", "\n", "", "", "sentence_iterator", ".", "total_num_sentences", "=", "total_num_sentences", "\n", "\n", "print", "(", "\"Starting to train model.\"", ")", "\n", "\n", "trained_model", "=", "Word2Vec", "(", "None", ",", "iter", "=", "iterations_for_training_word_embeddings", ",", "\n", "min_count", "=", "0", ",", "size", "=", "word_embedding_dimension", ",", "workers", "=", "4", ")", "\n", "trained_model", ".", "build_vocab", "(", "sentence_iterator", ")", "\n", "trained_model", ".", "train", "(", "sentence_iterator", ",", "total_examples", "=", "total_num_sentences", ",", "\n", "epochs", "=", "iterations_for_training_word_embeddings", ")", "\n", "temp_filename", "=", "(", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "\"_tempgensim\"", ")", "\n", "trained_model", ".", "save", "(", "temp_filename", ")", "\n", "\n", "print", "(", "\"Starting to move trained embeddings into numpy matrix at \"", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "np_embedding_filename", "=", "(", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "embedding_file_tag", "+", "\".npy\"", ")", "\n", "num_vocab_words", "=", "num_words_in_vocab_including_unk", "-", "1", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "num_vocab_words", "+", "2", ",", "word_embedding_dimension", ")", ")", "\n", "ind_counter", "=", "1", "\n", "with", "open", "(", "vocab_filename_nonums", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                ", "continue", "\n", "", "line", "=", "line", "[", ":", "-", "1", "]", "# get rid of newline", "\n", "embedding_matrix", "[", "ind_counter", "]", "=", "trained_model", "[", "line", "]", "\n", "ind_counter", "+=", "1", "\n", "", "", "embedding_matrix", "[", "num_words_in_vocab_including_unk", "]", "=", "trained_model", "[", "unk_token", "]", "\n", "norm_of_embeddings", "=", "np", ".", "linalg", ".", "norm", "(", "embedding_matrix", ",", "axis", "=", "1", ")", "\n", "norm_of_embeddings", "[", "norm_of_embeddings", "==", "0", "]", "=", "1e-13", "\n", "embedding_matrix", "=", "embedding_matrix", "/", "norm_of_embeddings", "[", ":", ",", "None", "]", "\n", "np", ".", "save", "(", "np_embedding_filename", ",", "embedding_matrix", ")", "\n", "\n", "print", "(", "\"Starting to save numpy matrix as hdf5 file containing torch tensor at \"", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "hdf5_filename", "=", "(", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "embedding_file_tag", "+", "\".h5\"", ")", "\n", "with", "h5py", ".", "File", "(", "hdf5_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "dset", "=", "f", ".", "create_dataset", "(", "\"embedding\"", ",", "(", "num_words_in_vocab_including_unk", "+", "1", ",", "word_embedding_dimension", ")", ",", "\n", "dtype", "=", "'f'", ")", "\n", "dset", "[", "...", "]", "=", "embedding_matrix", "\n", "\n", "", "print", "(", "\"Removing temporary gensim model files at \"", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "# remove temp gensim model files, now that embedding matrix has been saved", "\n", "if", "os", ".", "path", ".", "isfile", "(", "temp_filename", ")", ":", "\n", "        ", "os", ".", "remove", "(", "temp_filename", ")", "\n", "", "other_files_to_rm", "=", "glob", "(", "temp_filename", "+", "\".*\"", ")", "\n", "for", "fname", "in", "other_files_to_rm", ":", "\n", "        ", "os", ".", "remove", "(", "fname", ")", "\n", "", "if", "write_temp_file_of_all_provided_data_with_set_vocab", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "temp_data_filename", ")", ":", "\n", "            ", "os", ".", "remove", "(", "temp_data_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_1": [[300, 314], ["textcat.TextCatReader", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.GensimSentenceIterator", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_vocab_and_collect_num_sentences", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_label_ind_files", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_temp_file_and_iterate_over_that_instead", "allennlp.data.tokenizers.WordTokenizer", "allennlp.data.tokenizers.word_filter.PassThroughWordFilter"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_vocab_and_collect_num_sentences", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_label_ind_files", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_temp_file_and_iterate_over_that_instead"], ["", "", "", "def", "get_word2vec_and_vocab_part_1", "(", ")", ":", "\n", "    ", "first_data_filepath", "=", "filepaths_of_data_to_train_on", "[", "0", "]", "\n", "allennlp_reader", "=", "TextCatReader", "(", "word_tokenizer", "=", "WordTokenizer", "(", "word_filter", "=", "PassThroughWordFilter", "(", ")", ")", ",", "\n", "segment_sentences", "=", "True", ")", "\n", "sentence_iterator", "=", "GensimSentenceIterator", "(", "allennlp_reader", ",", "filepaths_of_data_to_train_on", ")", "\n", "words_to_inds", ",", "num_words_in_vocab_including_unk", ",", "total_num_sentences", ",", "vocab_filename_nonums", "=", "get_vocab_and_collect_num_sentences", "(", "sentence_iterator", ",", "first_data_filepath", ")", "\n", "sentence_iterator", ".", "valid_vocab_words", "=", "words_to_inds", "\n", "if", "write_temp_file_of_all_provided_data_with_set_vocab", ":", "\n", "        ", "sentence_iterator", ",", "temp_data_filename", "=", "make_temp_file_and_iterate_over_that_instead", "(", "sentence_iterator", ")", "\n", "words_to_inds", "=", "None", "\n", "\n", "", "label_iterator", "=", "LabelIterator", "(", "allennlp_reader", ",", "filepaths_of_data_to_train_on", ")", "\n", "make_label_ind_files", "(", "label_iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_2": [[316, 321], ["textcat.TextCatReader", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.LabelIterator", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_label_ind_files", "allennlp.data.tokenizers.WordTokenizer", "allennlp.data.tokenizers.word_filter.PassThroughWordFilter"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.make_label_ind_files"], ["", "def", "get_word2vec_and_vocab_part_2", "(", ")", ":", "\n", "    ", "allennlp_reader", "=", "TextCatReader", "(", "word_tokenizer", "=", "WordTokenizer", "(", "word_filter", "=", "PassThroughWordFilter", "(", ")", ")", ",", "\n", "segment_sentences", "=", "True", ")", "\n", "label_iterator", "=", "LabelIterator", "(", "allennlp_reader", ",", "filepaths_of_data_to_train_on", ")", "\n", "make_label_ind_files", "(", "label_iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.save_vocab_in_allennlp_format": [[323, 332], ["allennlp.data.Vocabulary", "allennlp.data.Vocabulary.set_from_file", "allennlp.data.Vocabulary.set_from_file", "allennlp.data.Vocabulary.save_to_files", "first_data_filepath.rfind", "first_data_filepath.rfind"], "function", ["None"], ["", "def", "save_vocab_in_allennlp_format", "(", ")", ":", "\n", "    ", "first_data_filepath", "=", "filepaths_of_data_to_train_on", "[", "0", "]", "\n", "numless_vocab_file", "=", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "vocabword_ind_not_numbered_file_ending", "\n", "numless_label_file", "=", "first_data_filepath", "[", ":", "first_data_filepath", ".", "rfind", "(", "'.'", ")", "]", "+", "label_ind_not_numbered_file_ending", "\n", "\n", "vocab", "=", "Vocabulary", "(", ")", "\n", "vocab", ".", "set_from_file", "(", "numless_vocab_file", ",", "is_padded", "=", "True", ",", "oov_token", "=", "unk_token", ",", "namespace", "=", "'tokens'", ")", "\n", "vocab", ".", "set_from_file", "(", "numless_label_file", ",", "is_padded", "=", "False", ",", "namespace", "=", "'labels'", ")", "\n", "vocab", ".", "save_to_files", "(", "dir_to_save_vocab_in", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource": [[334, 338], ["resource.getrlimit", "resource.RLIMIT_CORE", "resource.RLIMIT_CPU", "resource.RLIMIT_DATA", "resource.RLIMIT_FSIZE", "resource.RLIMIT_MEMLOCK", "resource.RLIMIT_RSS"], "function", ["None"], ["", "def", "get_new_limits_for_resource", "(", "res", ")", ":", "\n", "    ", "original_limits", "=", "resource", ".", "getrlimit", "(", "res", ")", "\n", "new_limits", "=", "(", "original_limits", "[", "1", "]", ",", "original_limits", "[", "1", "]", ")", "\n", "return", "new_limits", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.main": [[340, 363], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "resource.setrlimit", "resource.setrlimit", "resource.setrlimit", "resource.setrlimit", "resource.setrlimit", "resource.setrlimit", "print", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_1", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_2", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_3", "get_vocab_and_initialize_word2vec_embeddings_from_dataset.save_vocab_in_allennlp_format"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_1", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_new_limits_for_resource", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_2", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.get_word2vec_and_vocab_part_3", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.get_vocab_and_initialize_word2vec_embeddings_from_dataset.save_vocab_in_allennlp_format"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"--run-part\"", ",", "type", "=", "int", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Run part 1, 2, or 3 of word2vec-vocab preprocessing\"", ",", "\n", "choices", "=", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "allocate_extra_memory", ":", "\n", "        ", "resource", ".", "setrlimit", "(", "resource", ".", "RLIMIT_CORE", ",", "get_new_limits_for_resource", "(", "resource", ".", "RLIMIT_CORE", ")", ")", "\n", "resource", ".", "setrlimit", "(", "resource", ".", "RLIMIT_CPU", ",", "get_new_limits_for_resource", "(", "resource", ".", "RLIMIT_CPU", ")", ")", "\n", "resource", ".", "setrlimit", "(", "resource", ".", "RLIMIT_DATA", ",", "get_new_limits_for_resource", "(", "resource", ".", "RLIMIT_DATA", ")", ")", "\n", "resource", ".", "setrlimit", "(", "resource", ".", "RLIMIT_FSIZE", ",", "get_new_limits_for_resource", "(", "resource", ".", "RLIMIT_FSIZE", ")", ")", "\n", "resource", ".", "setrlimit", "(", "resource", ".", "RLIMIT_MEMLOCK", ",", "get_new_limits_for_resource", "(", "resource", ".", "RLIMIT_MEMLOCK", ")", ")", "\n", "resource", ".", "setrlimit", "(", "resource", ".", "RLIMIT_RSS", ",", "get_new_limits_for_resource", "(", "resource", ".", "RLIMIT_RSS", ")", ")", "\n", "print", "(", "\"Successfully increased script resources.\"", ")", "\n", "# we split these up because otherwise we use too much memory", "\n", "", "if", "args", ".", "run_part", "==", "1", ":", "\n", "        ", "get_word2vec_and_vocab_part_1", "(", ")", "\n", "", "elif", "args", ".", "run_part", "==", "2", ":", "\n", "        ", "get_word2vec_and_vocab_part_2", "(", ")", "\n", "", "else", ":", "\n", "        ", "get_word2vec_and_vocab_part_3", "(", ")", "\n", "save_vocab_in_allennlp_format", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_writeable_text": [[20, 22], ["text.replace().replace", "text.replace"], "function", ["None"], ["def", "get_writeable_text", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "replace", "(", "'\\n'", ",", "' '", ")", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_nonzero_len_instance_inds_by_class": [[24, 67], ["print", "open", "len", "make_datasets.get_nth_field_in_line", "int", "int", "str", "line.strip", "make_datasets.get_nth_field_in_line", "make_datasets.get_nth_field_in_line", "list_to_append_to.append", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.index", "temp_line.index", "temp_line.index"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line"], ["", "def", "get_nonzero_len_instance_inds_by_class", "(", "data_filename", ")", ":", "\n", "    ", "class_inds_dict", "=", "{", "}", "\n", "instance_ind", "=", "0", "\n", "with", "open", "(", "data_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "first_line", "=", "True", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "first_line", ":", "\n", "                ", "temp_line", "=", "line", "\n", "category_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'category\\t'", ")", "or", "temp_line", ".", "startswith", "(", "'category\\n'", ")", ")", ":", "\n", "                    ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "category_ind", "+=", "1", "\n", "\n", "", "temp_line", "=", "line", "\n", "num_sents_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'num_sentences\\t'", ")", "or", "temp_line", ".", "startswith", "(", "'num_sentences\\n'", ")", ")", ":", "\n", "                    ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "num_sents_field_ind", "+=", "1", "\n", "\n", "", "temp_line", "=", "line", "\n", "max_num_tokens_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\t'", ")", "or", "\n", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\n'", ")", ")", ":", "\n", "                    ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "max_num_tokens_field_ind", "+=", "1", "\n", "", "first_line", "=", "False", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "category", "=", "get_nth_field_in_line", "(", "line", ",", "category_ind", ")", "\n", "num_sents", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "num_sents_field_ind", ")", ")", "\n", "max_num_tokens", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "max_num_tokens_field_ind", ")", ")", "\n", "try", ":", "\n", "                    ", "list_to_append_to", "=", "class_inds_dict", "[", "category", "]", "\n", "", "except", "KeyError", ":", "\n", "                    ", "class_inds_dict", "[", "category", "]", "=", "[", "]", "\n", "list_to_append_to", "=", "class_inds_dict", "[", "category", "]", "\n", "", "if", "num_sents", ">", "0", "and", "max_num_tokens", ">", "0", ":", "\n", "                    ", "list_to_append_to", ".", "append", "(", "[", "instance_ind", ",", "num_sents", ",", "max_num_tokens", "]", ")", "\n", "", "instance_ind", "+=", "1", "\n", "", "", "", "assert", "len", "(", "class_inds_dict", ")", "==", "10", "\n", "print", "(", "\"Iterated over \"", "+", "str", "(", "instance_ind", ")", "+", "\" instances.\"", ")", "\n", "return", "class_inds_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.random_draw_and_remove_from_list": [[69, 79], ["len", "numpy.array", "numpy.random.choice", "numpy.zeros", "list", "list", "len", "len", "range", "numpy.logical_not"], "function", ["None"], ["", "def", "random_draw_and_remove_from_list", "(", "original_list", ",", "draw_x", ")", ":", "\n", "    ", "total_num_instances", "=", "len", "(", "original_list", ")", "\n", "original_list", "=", "np", ".", "array", "(", "original_list", ")", "\n", "subset_inds", "=", "choice", "(", "[", "i", "for", "i", "in", "range", "(", "total_num_instances", ")", "]", ",", "size", "=", "draw_x", ",", "replace", "=", "False", ")", "\n", "binary_mask", "=", "np", ".", "zeros", "(", "total_num_instances", ",", "dtype", "=", "bool", ")", "\n", "binary_mask", "[", "subset_inds", "]", "=", "1", "\n", "chosen", "=", "list", "(", "original_list", "[", "binary_mask", "]", ")", "\n", "not_chosen", "=", "list", "(", "original_list", "[", "np", ".", "logical_not", "(", "binary_mask", ")", "]", ")", "\n", "assert", "len", "(", "chosen", ")", "+", "len", "(", "not_chosen", ")", "==", "total_num_instances", "\n", "return", "chosen", ",", "not_chosen", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.write_list_of_instances_to_file": [[81, 91], ["print", "open", "f.write", "first_line.endswith", "f.write", "instance.endswith"], "function", ["None"], ["", "def", "write_list_of_instances_to_file", "(", "fname", ",", "instances", ",", "first_line", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "if", "not", "first_line", ".", "endswith", "(", "'\\n'", ")", ":", "\n", "            ", "first_line", "=", "first_line", "+", "'\\n'", "\n", "", "f", ".", "write", "(", "first_line", ")", "\n", "for", "instance", "in", "instances", ":", "\n", "            ", "if", "not", "instance", ".", "endswith", "(", "'\\n'", ")", ":", "\n", "                ", "instance", "=", "instance", "+", "'\\n'", "\n", "", "f", ".", "write", "(", "instance", ")", "\n", "", "", "print", "(", "\"Done writing instances to \"", "+", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.make_class_balanced_train_dev_test_sets": [[93, 170], ["subset_data.get_nonzero_len_instance_inds_by_class", "sorted", "subset_data.random_draw_and_remove_from_list", "sorted", "sorted", "random.shuffle", "random.shuffle", "random.shuffle", "print", "print", "print", "subset_data.write_list_of_instances_to_file", "subset_data.write_list_of_instances_to_file", "subset_data.write_list_of_instances_to_file", "ind_lists.append", "subset_data.random_draw_and_remove_from_list", "remaining_choices.append", "range", "subset_data.random_draw_and_remove_from_list", "int", "open", "len", "len", "len", "len", "len", "str", "str", "str", "line.strip", "training_instances.append", "len", "len", "len", "len", "dev_instances.append", "len", "test_instances.append", "len", "make_datasets.yahoo_output_full_data_filename", "make_datasets.yahoo_output_train_filename", "make_datasets.yahoo_output_dev_filename", "make_datasets.yahoo_output_test_filename"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_nonzero_len_instance_inds_by_class", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.random_draw_and_remove_from_list", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.write_list_of_instances_to_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.write_list_of_instances_to_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.write_list_of_instances_to_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.random_draw_and_remove_from_list", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.random_draw_and_remove_from_list"], ["", "def", "make_class_balanced_train_dev_test_sets", "(", "full_data_filename", ",", "max_num_sents_for_traindev", ",", "\n", "max_max_num_tokens_for_traindev", ",", "num_test_instances_per_class", ",", "\n", "num_traindev_per_class", ",", "frac_traindev_that_are_dev", ",", "\n", "training_fname", ",", "dev_fname", ",", "test_fname", ")", ":", "\n", "    ", "classes_to_inds", "=", "get_nonzero_len_instance_inds_by_class", "(", "full_data_filename", ")", "\n", "ind_lists", "=", "[", "]", "\n", "for", "class_name", "in", "classes_to_inds", ":", "\n", "        ", "ind_lists", ".", "append", "(", "classes_to_inds", "[", "class_name", "]", ")", "\n", "\n", "# first, choose test inds", "\n", "", "test_inds", "=", "[", "]", "\n", "remaining_choices", "=", "[", "]", "\n", "for", "class_inds", "in", "ind_lists", ":", "\n", "        ", "chosen", ",", "not_chosen", "=", "random_draw_and_remove_from_list", "(", "class_inds", ",", "num_test_instances_per_class", ")", "\n", "test_inds", "+=", "chosen", "\n", "remaining_choices", ".", "append", "(", "not_chosen", ")", "\n", "", "test_inds", "=", "sorted", "(", "[", "i", "[", "0", "]", "for", "i", "in", "test_inds", "]", ")", "\n", "\n", "# now remove any instances from consideration for training or dev that are outside of the given windows", "\n", "for", "remaining_choice_list", "in", "remaining_choices", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "remaining_choice_list", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "cur_val", "=", "remaining_choice_list", "[", "i", "]", "\n", "if", "cur_val", "[", "1", "]", ">", "max_num_sents_for_traindev", "or", "cur_val", "[", "2", "]", ">", "max_max_num_tokens_for_traindev", ":", "\n", "                ", "del", "remaining_choice_list", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "remaining_choice_list", "[", "i", "]", "=", "cur_val", "[", "0", "]", "\n", "\n", "", "", "", "traindev_inds", "=", "[", "]", "\n", "ind_lists", "=", "remaining_choices", "\n", "for", "class_inds", "in", "ind_lists", ":", "\n", "        ", "chosen", ",", "not_chosen", "=", "random_draw_and_remove_from_list", "(", "class_inds", ",", "num_traindev_per_class", ")", "\n", "traindev_inds", "+=", "chosen", "\n", "\n", "# now randomly separate traindev into training and dev", "\n", "", "dev_inds", ",", "training_inds", "=", "random_draw_and_remove_from_list", "(", "traindev_inds", ",", "\n", "int", "(", "frac_traindev_that_are_dev", "*", "len", "(", "traindev_inds", ")", ")", ")", "\n", "dev_inds", "=", "sorted", "(", "dev_inds", ")", "\n", "training_inds", "=", "sorted", "(", "training_inds", ")", "\n", "\n", "training_instances", "=", "[", "]", "\n", "dev_instances", "=", "[", "]", "\n", "test_instances", "=", "[", "]", "\n", "first_line", "=", "None", "\n", "instance_counter", "=", "0", "\n", "with", "open", "(", "full_data_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "first_line", "is", "None", ":", "\n", "                ", "first_line", "=", "line", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "if", "len", "(", "training_inds", ")", ">", "0", "and", "instance_counter", "==", "training_inds", "[", "0", "]", ":", "\n", "                    ", "training_instances", ".", "append", "(", "line", ")", "\n", "del", "training_inds", "[", "0", "]", "\n", "", "elif", "len", "(", "dev_inds", ")", ">", "0", "and", "instance_counter", "==", "dev_inds", "[", "0", "]", ":", "\n", "                    ", "dev_instances", ".", "append", "(", "line", ")", "\n", "del", "dev_inds", "[", "0", "]", "\n", "", "elif", "len", "(", "test_inds", ")", ">", "0", "and", "instance_counter", "==", "test_inds", "[", "0", "]", ":", "\n", "                    ", "test_instances", ".", "append", "(", "line", ")", "\n", "del", "test_inds", "[", "0", "]", "\n", "", "instance_counter", "+=", "1", "\n", "\n", "", "", "", "assert", "len", "(", "training_inds", ")", "==", "0", "\n", "assert", "len", "(", "dev_inds", ")", "==", "0", "\n", "assert", "len", "(", "test_inds", ")", "==", "0", "\n", "\n", "shuffle", "(", "training_instances", ")", "\n", "shuffle", "(", "dev_instances", ")", "\n", "shuffle", "(", "test_instances", ")", "\n", "\n", "print", "(", "\"Collected \"", "+", "str", "(", "len", "(", "training_instances", ")", ")", "+", "\" training instances.\"", ")", "\n", "print", "(", "\"Collected \"", "+", "str", "(", "len", "(", "dev_instances", ")", ")", "+", "\" dev instances.\"", ")", "\n", "print", "(", "\"Collected \"", "+", "str", "(", "len", "(", "test_instances", ")", ")", "+", "\" test instances.\"", ")", "\n", "\n", "write_list_of_instances_to_file", "(", "training_fname", ",", "training_instances", ",", "first_line", ")", "\n", "write_list_of_instances_to_file", "(", "dev_fname", ",", "dev_instances", ",", "first_line", ")", "\n", "write_list_of_instances_to_file", "(", "test_fname", ",", "test_instances", ",", "first_line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.make_train_dev_test_sets": [[172, 233], ["range", "random.shuffle", "random.shuffle", "random.shuffle", "print", "print", "print", "subset_data.write_list_of_instances_to_file", "subset_data.write_list_of_instances_to_file", "subset_data.write_list_of_instances_to_file", "open", "print", "random.random", "open", "len", "len", "len", "training_inds.append", "line.strip", "dev_inds.append", "test_inds.append", "str", "str", "str", "str", "line.strip", "training_instances.append", "len", "len", "len", "len", "dev_instances.append", "len", "test_instances.append", "len", "make_datasets.imdb_output_full_data_filename", "make_datasets.imdb_output_train_filename", "make_datasets.imdb_output_dev_filename", "make_datasets.imdb_output_test_filename"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.write_list_of_instances_to_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.write_list_of_instances_to_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.write_list_of_instances_to_file"], ["", "def", "make_train_dev_test_sets", "(", "full_data_filename", ",", "pct_train_instances", ",", "pct_dev_instances", ",", "\n", "training_fname", ",", "dev_fname", ",", "test_fname", ")", ":", "\n", "    ", "with", "open", "(", "full_data_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "num_instances", "=", "-", "1", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                ", "continue", "\n", "", "num_instances", "+=", "1", "\n", "", "print", "(", "\"Found \"", "+", "str", "(", "num_instances", ")", "+", "\" instances in total.\"", ")", "\n", "\n", "", "training_inds", "=", "[", "]", "\n", "dev_inds", "=", "[", "]", "\n", "test_inds", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "        ", "decider", "=", "random", "(", ")", "\n", "if", "decider", "<", "pct_train_instances", ":", "\n", "            ", "training_inds", ".", "append", "(", "i", ")", "\n", "", "elif", "decider", "<", "pct_train_instances", "+", "pct_dev_instances", ":", "\n", "            ", "dev_inds", ".", "append", "(", "i", ")", "\n", "", "else", ":", "\n", "            ", "test_inds", ".", "append", "(", "i", ")", "\n", "\n", "", "", "training_instances", "=", "[", "]", "\n", "dev_instances", "=", "[", "]", "\n", "test_instances", "=", "[", "]", "\n", "first_line", "=", "None", "\n", "instance_counter", "=", "0", "\n", "with", "open", "(", "full_data_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "first_line", "is", "None", ":", "\n", "                ", "first_line", "=", "line", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "if", "len", "(", "training_inds", ")", ">", "0", "and", "instance_counter", "==", "training_inds", "[", "0", "]", ":", "\n", "                    ", "training_instances", ".", "append", "(", "line", ")", "\n", "del", "training_inds", "[", "0", "]", "\n", "", "elif", "len", "(", "dev_inds", ")", ">", "0", "and", "instance_counter", "==", "dev_inds", "[", "0", "]", ":", "\n", "                    ", "dev_instances", ".", "append", "(", "line", ")", "\n", "del", "dev_inds", "[", "0", "]", "\n", "", "elif", "len", "(", "test_inds", ")", ">", "0", "and", "instance_counter", "==", "test_inds", "[", "0", "]", ":", "\n", "                    ", "test_instances", ".", "append", "(", "line", ")", "\n", "del", "test_inds", "[", "0", "]", "\n", "", "instance_counter", "+=", "1", "\n", "\n", "", "", "", "assert", "len", "(", "training_inds", ")", "==", "0", "\n", "assert", "len", "(", "dev_inds", ")", "==", "0", "\n", "assert", "len", "(", "test_inds", ")", "==", "0", "\n", "\n", "shuffle", "(", "training_instances", ")", "\n", "shuffle", "(", "dev_instances", ")", "\n", "shuffle", "(", "test_instances", ")", "\n", "\n", "print", "(", "\"Collected \"", "+", "str", "(", "len", "(", "training_instances", ")", ")", "+", "\" training instances.\"", ")", "\n", "print", "(", "\"Collected \"", "+", "str", "(", "len", "(", "dev_instances", ")", ")", "+", "\" dev instances.\"", ")", "\n", "print", "(", "\"Collected \"", "+", "str", "(", "len", "(", "test_instances", ")", ")", "+", "\" test instances.\"", ")", "\n", "\n", "write_list_of_instances_to_file", "(", "training_fname", ",", "training_instances", ",", "first_line", ")", "\n", "write_list_of_instances_to_file", "(", "dev_fname", ",", "dev_instances", ",", "first_line", ")", "\n", "write_list_of_instances_to_file", "(", "test_fname", ",", "test_instances", ",", "first_line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_info_about_data_len_distribution": [[235, 301], ["matplotlib.figure", "matplotlib.scatter", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.close", "matplotlib.figure", "sorted", "matplotlib.hist", "matplotlib.title", "matplotlib.savefig", "matplotlib.close", "matplotlib.figure", "sorted", "matplotlib.hist", "matplotlib.title", "matplotlib.savefig", "matplotlib.close", "int", "bisect.bisect_right", "input().startswith", "int", "bisect.bisect_right", "input().startswith", "open", "range", "input", "print", "range", "input", "print", "min", "input", "min", "input", "int", "int", "numsents_maxnumtokens.append", "max", "len", "max", "len", "line.strip", "make_datasets.get_nth_field_in_line", "make_datasets.get_nth_field_in_line", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "len", "len", "temp_line.index", "temp_line.index"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line"], ["", "def", "get_info_about_data_len_distribution", "(", "filepaths", ",", "base_output_image_dir", ")", ":", "\n", "    ", "numsents_maxnumtokens", "=", "[", "]", "\n", "\n", "for", "filepath", "in", "filepaths", ":", "\n", "        ", "first_line", "=", "True", "\n", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "first_line", ":", "\n", "# find which fields are num_sentences and max_num_tokens_in_sentence", "\n", "                    ", "temp_line", "=", "line", "\n", "num_sents_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'num_sentences\\t'", ")", "or", "temp_line", ".", "startswith", "(", "'num_sentences\\n'", ")", ")", ":", "\n", "                        ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "num_sents_field_ind", "+=", "1", "\n", "", "temp_line", "=", "line", "\n", "max_num_tokens_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\t'", ")", "or", "\n", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\n'", ")", ")", ":", "\n", "                        ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "max_num_tokens_field_ind", "+=", "1", "\n", "", "first_line", "=", "False", "\n", "", "else", ":", "\n", "                    ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                        ", "continue", "\n", "", "num_sents", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "num_sents_field_ind", ")", ")", "\n", "max_num_tokens", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "max_num_tokens_field_ind", ")", ")", "\n", "numsents_maxnumtokens", ".", "append", "(", "(", "num_sents", ",", "max_num_tokens", ")", ")", "\n", "\n", "", "", "", "", "num_sentences", "=", "[", "tup", "[", "0", "]", "for", "tup", "in", "numsents_maxnumtokens", "]", "\n", "max_num_tokens", "=", "[", "tup", "[", "1", "]", "for", "tup", "in", "numsents_maxnumtokens", "]", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "scatter", "(", "num_sentences", ",", "max_num_tokens", ",", "s", "=", "2", ")", "\n", "plt", ".", "xlabel", "(", "\"# of sentences in instance\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Max # tokens in instance\"", ")", "\n", "plt", ".", "savefig", "(", "base_output_image_dir", "+", "\"sents_by_maxnumtokens.png\"", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "num_sentences", "=", "sorted", "(", "num_sentences", ")", "\n", "plt", ".", "hist", "(", "num_sentences", ",", "log", "=", "True", ",", "bins", "=", "range", "(", "min", "(", "num_sentences", ")", ",", "max", "(", "num_sentences", ")", "+", "1", ",", "1", ")", ")", "\n", "plt", ".", "title", "(", "\"# of sentences in instance\"", ")", "\n", "plt", ".", "savefig", "(", "base_output_image_dir", "+", "\"sents_histogram.png\"", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n", "decided", "=", "False", "\n", "while", "not", "decided", ":", "\n", "        ", "greater_than", "=", "int", "(", "input", "(", "\"Find % of instances with # of sentences greater than: \"", ")", ")", "\n", "i", "=", "bisect_right", "(", "num_sentences", ",", "greater_than", ")", "\n", "if", "i", ":", "\n", "            ", "print", "(", "(", "(", "len", "(", "num_sentences", ")", "-", "1", ")", "-", "i", ")", "/", "len", "(", "num_sentences", ")", ")", "\n", "", "decided", "=", "(", "input", "(", "\"Done? (y/n): \"", ")", ".", "startswith", "(", "'y'", ")", ")", "\n", "\n", "", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "max_num_tokens", "=", "sorted", "(", "max_num_tokens", ")", "\n", "plt", ".", "hist", "(", "max_num_tokens", ",", "log", "=", "True", ",", "bins", "=", "range", "(", "min", "(", "max_num_tokens", ")", ",", "max", "(", "max_num_tokens", ")", "+", "1", ",", "1", ")", ")", "\n", "plt", ".", "title", "(", "\"Max # tokens in instance\"", ")", "\n", "plt", ".", "savefig", "(", "base_output_image_dir", "+", "\"maxnumtokens_histogram.png\"", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n", "decided", "=", "False", "\n", "while", "not", "decided", ":", "\n", "        ", "greater_than", "=", "int", "(", "input", "(", "\"Find % of instances with max # of tokens greater than: \"", ")", ")", "\n", "i", "=", "bisect_right", "(", "max_num_tokens", ",", "greater_than", ")", "\n", "if", "i", ":", "\n", "            ", "print", "(", "(", "(", "len", "(", "max_num_tokens", ")", "-", "1", ")", "-", "i", ")", "/", "len", "(", "max_num_tokens", ")", ")", "\n", "", "decided", "=", "(", "input", "(", "\"Done? (y/n): \"", ")", ".", "startswith", "(", "'y'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.split_file_into_training_and_dev": [[303, 332], ["filename.endswith", "open", "open", "open.close", "open.close", "print", "print", "open", "filename.rfind", "filename.rfind", "open.write", "open.write", "random.random", "str", "str", "line.strip", "open.write", "open.write"], "function", ["None"], ["", "", "def", "split_file_into_training_and_dev", "(", "filename", ",", "frac_that_should_be_dev", ")", ":", "\n", "    ", "assert", "filename", ".", "endswith", "(", "\"traindev.tsv\"", ")", "\n", "new_training_name", "=", "filename", "[", ":", "filename", ".", "rfind", "(", "\"traindev.tsv\"", ")", "]", "+", "\"train.tsv\"", "\n", "new_dev_name", "=", "filename", "[", ":", "filename", ".", "rfind", "(", "\"traindev.tsv\"", ")", "]", "+", "\"dev.tsv\"", "\n", "train_f", "=", "open", "(", "new_training_name", ",", "'w'", ")", "\n", "dev_f", "=", "open", "(", "new_dev_name", ",", "'w'", ")", "\n", "num_training", "=", "0", "\n", "num_dev", "=", "0", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "first_line", "=", "True", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "first_line", ":", "\n", "                ", "train_f", ".", "write", "(", "line", ")", "\n", "dev_f", ".", "write", "(", "line", ")", "\n", "first_line", "=", "False", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "decider", "=", "random", "(", ")", "\n", "if", "decider", "<", "frac_that_should_be_dev", ":", "\n", "                    ", "dev_f", ".", "write", "(", "line", ")", "\n", "num_dev", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "train_f", ".", "write", "(", "line", ")", "\n", "num_training", "+=", "1", "\n", "", "", "", "", "train_f", ".", "close", "(", ")", "\n", "dev_f", ".", "close", "(", ")", "\n", "print", "(", "\"Selected \"", "+", "str", "(", "num_training", ")", "+", "\" training instances.\"", ")", "\n", "print", "(", "\"Selected \"", "+", "str", "(", "num_dev", ")", "+", "\" dev instances.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_version_without_outliers": [[334, 367], ["open", "print", "open.close", "open", "filepath.rfind", "open.write", "int", "int", "str", "line.strip", "make_datasets.get_nth_field_in_line", "make_datasets.get_nth_field_in_line", "open.write", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.index", "temp_line.index"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line"], ["", "def", "get_version_without_outliers", "(", "filepaths", ",", "max_num_sents", ",", "max_num_tokens_in_sent", ")", ":", "\n", "    ", "for", "filepath", "in", "filepaths", ":", "\n", "        ", "new_filepath", "=", "filepath", "[", ":", "filepath", ".", "rfind", "(", "'.tsv'", ")", "]", "+", "\"_remoutliers.tsv\"", "\n", "new_f", "=", "open", "(", "new_filepath", ",", "'w'", ")", "\n", "first_line", "=", "True", "\n", "counter", "=", "0", "\n", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "first_line", ":", "\n", "                    ", "new_f", ".", "write", "(", "line", ")", "\n", "# find which fields are num_sentences and max_num_tokens_in_sentence", "\n", "temp_line", "=", "line", "\n", "num_sents_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'num_sentences\\t'", ")", "or", "temp_line", ".", "startswith", "(", "'num_sentences\\n'", ")", ")", ":", "\n", "                        ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "num_sents_field_ind", "+=", "1", "\n", "", "temp_line", "=", "line", "\n", "max_num_tokens_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\t'", ")", "or", "\n", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\n'", ")", ")", ":", "\n", "                        ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "max_num_tokens_field_ind", "+=", "1", "\n", "", "first_line", "=", "False", "\n", "", "else", ":", "\n", "                    ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                        ", "continue", "\n", "", "num_sents", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "num_sents_field_ind", ")", ")", "\n", "max_num_tokens", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "max_num_tokens_field_ind", ")", ")", "\n", "if", "num_sents", "<=", "max_num_sents", "and", "max_num_tokens", "<=", "max_num_tokens_in_sent", ":", "\n", "                        ", "new_f", ".", "write", "(", "line", ")", "\n", "counter", "+=", "1", "\n", "", "", "", "", "print", "(", "\"Wrote \"", "+", "str", "(", "counter", ")", "+", "\" instances to file.\"", ")", "\n", "new_f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.remove_zero_length_instances_from_file": [[369, 401], ["open", "print", "open.close", "open", "filepath.rfind", "open.write", "int", "int", "str", "line.strip", "make_datasets.get_nth_field_in_line", "make_datasets.get_nth_field_in_line", "open.write", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.startswith", "temp_line.index", "temp_line.index"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line"], ["", "", "def", "remove_zero_length_instances_from_file", "(", "filepath", ")", ":", "\n", "    ", "new_filepath", "=", "filepath", "[", ":", "filepath", ".", "rfind", "(", "'.tsv'", ")", "]", "+", "\"_nozerolens.tsv\"", "\n", "new_f", "=", "open", "(", "new_filepath", ",", "'w'", ")", "\n", "first_line", "=", "True", "\n", "counter", "=", "0", "\n", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "first_line", ":", "\n", "                ", "new_f", ".", "write", "(", "line", ")", "\n", "# find which fields are num_sentences and max_num_tokens_in_sentence", "\n", "temp_line", "=", "line", "\n", "num_sents_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'num_sentences\\t'", ")", "or", "temp_line", ".", "startswith", "(", "'num_sentences\\n'", ")", ")", ":", "\n", "                    ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "num_sents_field_ind", "+=", "1", "\n", "", "temp_line", "=", "line", "\n", "max_num_tokens_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\t'", ")", "or", "\n", "temp_line", ".", "startswith", "(", "'max_num_tokens_in_sentence\\n'", ")", ")", ":", "\n", "                    ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "max_num_tokens_field_ind", "+=", "1", "\n", "", "first_line", "=", "False", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "num_sents", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "num_sents_field_ind", ")", ")", "\n", "max_num_tokens", "=", "int", "(", "get_nth_field_in_line", "(", "line", ",", "max_num_tokens_field_ind", ")", ")", "\n", "if", "num_sents", ">", "0", "or", "max_num_tokens", ">", "0", ":", "\n", "                    ", "new_f", ".", "write", "(", "line", ")", "\n", "counter", "+=", "1", "\n", "", "", "", "", "print", "(", "\"Wrote \"", "+", "str", "(", "counter", ")", "+", "\" instances to file.\"", ")", "\n", "new_f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.main": [[403, 419], ["subset_data.get_info_about_data_len_distribution", "subset_data.make_class_balanced_train_dev_test_sets", "subset_data.split_file_into_training_and_dev", "subset_data.split_file_into_training_and_dev", "subset_data.make_train_dev_test_sets", "subset_data.get_info_about_data_len_distribution", "subset_data.get_version_without_outliers", "subset_data.get_info_about_data_len_distribution", "subset_data.get_version_without_outliers", "subset_data.get_info_about_data_len_distribution", "subset_data.get_version_without_outliers", "subset_data.remove_zero_length_instances_from_file"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_info_about_data_len_distribution", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.make_class_balanced_train_dev_test_sets", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.split_file_into_training_and_dev", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.split_file_into_training_and_dev", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.make_train_dev_test_sets", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_info_about_data_len_distribution", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_version_without_outliers", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_info_about_data_len_distribution", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_version_without_outliers", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_info_about_data_len_distribution", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.get_version_without_outliers", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.subset_data.remove_zero_length_instances_from_file"], ["", "def", "main", "(", ")", ":", "\n", "    ", "get_info_about_data_len_distribution", "(", "[", "yahoo_output_full_data_filename", "]", ",", "'/Users/sofias6/Downloads/'", ")", "\n", "make_class_balanced_train_dev_test_sets", "(", "yahoo_output_full_data_filename", ",", "50", ",", "350", ",", "5000", ",", "140000", ",", ".1", ",", "\n", "yahoo_output_train_filename", ",", "yahoo_output_dev_filename", ",", "\n", "yahoo_output_test_filename", ")", "\n", "split_file_into_training_and_dev", "(", "\"/Users/sofias6/Downloads/amazon_traindev.tsv\"", ",", ".1", ")", "\n", "split_file_into_training_and_dev", "(", "\"/Users/sofias6/Downloads/yelp_traindev.tsv\"", ",", ".1", ")", "\n", "make_train_dev_test_sets", "(", "imdb_output_full_data_filename", ",", ".8", ",", ".1", ",", "imdb_output_train_filename", ",", "\n", "imdb_output_dev_filename", ",", "imdb_output_test_filename", ")", "\n", "get_info_about_data_len_distribution", "(", "[", "'/homes/gws/sofias6/data/amazon_train.tsv'", "]", ",", "'/homes/gws/sofias6/'", ")", "\n", "get_version_without_outliers", "(", "[", "'/homes/gws/sofias6/data/amazon_train.tsv'", "]", ",", "15", ",", "130", ")", "\n", "get_info_about_data_len_distribution", "(", "[", "'/homes/gws/sofias6/data/yelp_train.tsv'", "]", ",", "'/homes/gws/sofias6/'", ")", "\n", "get_version_without_outliers", "(", "[", "'/homes/gws/sofias6/data/yelp_train.tsv'", "]", ",", "43", ",", "200", ")", "\n", "get_info_about_data_len_distribution", "(", "[", "'/homes/gws/sofias6/data/yahoo10cat_train.tsv'", "]", ",", "'/homes/gws/sofias6/'", ")", "\n", "get_version_without_outliers", "(", "[", "'/homes/gws/sofias6/data/yahoo10cat_train.tsv'", "]", ",", "25", ",", "175", ")", "\n", "remove_zero_length_instances_from_file", "(", "'/homes/gws/sofias6/data/amazon_test.tsv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.make_pickled_list_of_instances_from_xml": [[40, 88], ["print", "xml.parse().getroot", "tqdm.tqdm", "print", "ElementTree.parse().getroot.findall", "open", "pickle.dump", "str", "xml.parse", "list_of_instances.append", "list_of_instances.append", "str", "datetime.datetime.now", "attribute.text.strip", "int", "print"], "function", ["None"], ["def", "make_pickled_list_of_instances_from_xml", "(", "filename", ",", "label_field_name", ",", "text_field_names", ",", "labels_to_care_about", ",", "\n", "instance_signifier", ",", "pkl_file_to_write_to", ",", "instance_id_field_name", "=", "None", ")", ":", "\n", "    ", "print", "(", "\"Starting to read in data from xml file into python list of instances at \"", "+", "\n", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "\n", "root", "=", "ElementTree", ".", "parse", "(", "filename", ")", ".", "getroot", "(", ")", "# this takes quite a while for both yahoo files", "\n", "list_of_instances", "=", "[", "]", "\n", "if", "instance_id_field_name", "is", "None", ":", "\n", "        ", "counter", "=", "0", "\n", "", "for", "instance", "in", "tqdm", "(", "root", ".", "findall", "(", "'.//'", "+", "instance_signifier", ")", ",", "desc", "=", "\"Loading in data from xml file\"", ")", ":", "\n", "        ", "skip_instance", "=", "False", "\n", "str_label", "=", "None", "\n", "text", "=", "None", "\n", "if", "instance_id_field_name", "is", "not", "None", ":", "\n", "            ", "instance_id", "=", "None", "\n", "", "for", "attribute", "in", "instance", ":", "\n", "            ", "if", "attribute", ".", "tag", "==", "label_field_name", ":", "\n", "                ", "str_label", "=", "attribute", ".", "text", ".", "strip", "(", ")", "\n", "", "elif", "instance_id_field_name", "is", "not", "None", "and", "attribute", ".", "tag", "==", "instance_id_field_name", ":", "\n", "                ", "instance_id", "=", "int", "(", "attribute", ".", "text", ")", "\n", "", "elif", "attribute", ".", "tag", "in", "text_field_names", ":", "\n", "                ", "if", "text", "is", "None", ":", "\n", "                    ", "text", "=", "attribute", ".", "text", "\n", "", "else", ":", "\n", "                    ", "text", "+=", "' '", "+", "attribute", ".", "text", "\n", "", "", "", "if", "skip_instance", ":", "\n", "            ", "continue", "\n", "", "if", "str_label", "is", "None", "or", "text", "is", "None", ":", "\n", "            ", "if", "instance_id_field_name", "is", "None", ":", "\n", "# so that we don't throw our labeling of the data instance off by 1", "\n", "                ", "counter", "+=", "1", "\n", "", "continue", "\n", "", "if", "str_label", "not", "in", "labels_to_care_about", ":", "\n", "            ", "for", "accepted_label", "in", "labels_to_care_about", ":", "\n", "                ", "if", "str_label", "in", "accepted_label", "or", "accepted_label", "in", "str_label", ":", "\n", "                    ", "print", "(", "\"Careful: maybe mistakenly rejecting label \"", "+", "str_label", ")", "\n", "", "", "continue", "\n", "", "if", "instance_id_field_name", "is", "not", "None", ":", "\n", "            ", "if", "instance_id", "is", "None", ":", "\n", "                ", "continue", "\n", "", "", "if", "instance_id_field_name", "is", "None", ":", "\n", "            ", "list_of_instances", ".", "append", "(", "(", "counter", ",", "str_label", ",", "text", ")", ")", "\n", "counter", "+=", "1", "\n", "", "else", ":", "\n", "            ", "list_of_instances", ".", "append", "(", "(", "instance_id", ",", "str_label", ",", "text", ")", ")", "\n", "", "", "with", "open", "(", "pkl_file_to_write_to", ",", "'wb'", ")", "as", "pickle_f", ":", "\n", "        ", "pickle", ".", "dump", "(", "list_of_instances", ",", "pickle_f", ")", "\n", "", "print", "(", "\"Successfully wrote pickle file \"", "+", "str", "(", "pkl_file_to_write_to", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_writeable_text": [[90, 92], ["text.replace().replace", "text.replace"], "function", ["None"], ["", "def", "get_writeable_text", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "replace", "(", "'\\n'", ",", "' '", ")", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_pickled_instance_list": [[94, 98], ["open", "pickle.load"], "function", ["None"], ["", "def", "get_pickled_instance_list", "(", "pkl_filename", ")", ":", "\n", "    ", "with", "open", "(", "pkl_filename", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "ret", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_printed_lines": [[100, 105], ["None"], "function", ["None"], ["", "def", "get_printed_lines", "(", "list_of_lines", ")", ":", "\n", "    ", "str_in_progress", "=", "''", "\n", "for", "line", "in", "list_of_lines", ":", "\n", "        ", "str_in_progress", "+=", "line", "\n", "", "return", "str_in_progress", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.test_opening_file": [[107, 125], ["open", "line.strip().split.strip", "line.strip().split.strip().split", "len", "int", "line.strip().split.strip", "print", "exit"], "function", ["None"], ["", "def", "test_opening_file", "(", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "first_line", "=", "True", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "first_line", ":", "\n", "                ", "first_line", "=", "False", "\n", "continue", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "assert", "len", "(", "line", ")", "==", "3", "\n", "try", ":", "\n", "                        ", "int", "(", "line", "[", "0", "]", ")", "\n", "", "except", ":", "\n", "                        ", "print", "(", "\"Error: first item in line wasn't an int.\"", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.reformat_file_to_remove_newlines_not_caught_by_replace": [[127, 158], ["print", "open", "open", "f.write", "str", "f.write", "line.strip().split", "len", "line.strip", "len", "int", "list_of_instances.append", "line.strip", "inds_needing_fixing.append", "len", "len", "len"], "function", ["None"], ["", "", "", "", "", "", "def", "reformat_file_to_remove_newlines_not_caught_by_replace", "(", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "first_line", "=", "None", "\n", "list_of_instances", "=", "[", "]", "\n", "inds_needing_fixing", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "first_line", "is", "None", ":", "\n", "                ", "first_line", "=", "line", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "line_split", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "line_is_ok", "=", "(", "len", "(", "line_split", ")", "==", "3", ")", "\n", "try", ":", "\n", "                    ", "int", "(", "line_split", "[", "0", "]", ")", "\n", "", "except", ":", "\n", "                    ", "line_is_ok", "=", "False", "\n", "", "if", "line_is_ok", ":", "\n", "                    ", "list_of_instances", ".", "append", "(", "(", "line_split", "[", "0", "]", ",", "line_split", "[", "1", "]", ",", "line_split", "[", "2", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "condensed_line", "=", "\" \"", ".", "join", "(", "line_split", ")", "\n", "list_of_instances", "[", "-", "1", "]", "=", "(", "list_of_instances", "[", "-", "1", "]", "[", "0", "]", ",", "list_of_instances", "[", "-", "1", "]", "[", "1", "]", ",", "\n", "list_of_instances", "[", "-", "1", "]", "[", "2", "]", "+", "' '", "+", "condensed_line", ")", "\n", "if", "len", "(", "inds_needing_fixing", ")", "==", "0", "or", "inds_needing_fixing", "[", "-", "1", "]", "!=", "len", "(", "list_of_instances", ")", "-", "1", ":", "\n", "                        ", "inds_needing_fixing", ".", "append", "(", "len", "(", "list_of_instances", ")", "-", "1", ")", "\n", "\n", "", "", "", "", "", "print", "(", "\"Num lines that still had newlines not caught by replace: \"", "+", "str", "(", "len", "(", "inds_needing_fixing", ")", ")", ")", "\n", "with", "open", "(", "fname", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "first_line", ")", "\n", "for", "instance", "in", "list_of_instances", ":", "\n", "            ", "f", ".", "write", "(", "instance", "[", "0", "]", "+", "'\\t'", "+", "instance", "[", "1", "]", "+", "'\\t'", "+", "instance", "[", "2", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line": [[160, 171], ["line.rfind", "line.index", "line.index"], "function", ["None"], ["", "", "", "def", "get_nth_field_in_line", "(", "line", ",", "ind", ")", ":", "\n", "    ", "counter", "=", "0", "\n", "while", "counter", "<", "ind", ":", "\n", "        ", "line", "=", "line", "[", "line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "counter", "+=", "1", "\n", "", "if", "line", ".", "rfind", "(", "'\\t'", ")", "==", "-", "1", ":", "\n", "# this is the last field, so just remove the trailing newline", "\n", "        ", "return", "line", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "# return the remaining line up to the next tab", "\n", "        ", "return", "line", "[", ":", "line", ".", "index", "(", "'\\t'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.add_info_about_num_sents_and_max_num_tokens_to_data_file": [[173, 283], ["print", "textcat.TextCatReader", "allennlp.data.tokenizers.word_filter.PassThroughWordFilter", "allennlp.data.tokenizers.word_filter.StopwordFilter", "open", "open.close", "os.path.isfile", "os.rename", "open", "tqdm.tqdm", "len", "len", "open", "os.remove", "allennlp.data.tokenizers.WordTokenizer", "make_datasets.get_nth_field_in_line", "textcat.TextCatReader.text_to_instance", "len", "numsents_maxnumtokens.append", "textcat.TextCatReader.text_to_instance", "len", "numsents_maxnumtokens_if_not_considering_stop_words.append", "data_filename.rfind", "f.write", "str", "str", "str", "str", "f.write", "allennlp.data.tokenizers.word_filter.PassThroughWordFilter", "line.strip", "len", "numsents_maxnumtokens.append", "numsents_maxnumtokens_if_not_considering_stop_words.append", "numsents_maxnumtokens.append", "numsents_maxnumtokens_if_not_considering_stop_words.append", "numsents_maxnumtokens_if_not_considering_stop_words.append", "line.strip", "temp_line.startswith", "temp_line.startswith", "len", "len", "len", "len", "line.rfind", "line.rfind", "temp_line.index"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_nth_field_in_line", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader.text_to_instance", "home.repos.pwc.inspect_result.serrano-s_attn-tests.textcat.textcat_reader_attnlabel.TextCatAttnReader.text_to_instance"], ["", "", "def", "add_info_about_num_sents_and_max_num_tokens_to_data_file", "(", "data_filename", ")", ":", "\n", "    ", "print", "(", "\"Starting to calculate information about number of sentences and max number of tokens for each \"", "+", "\n", "\"instance to add to \"", "+", "data_filename", ")", "\n", "numsents_maxnumtokens", "=", "[", "]", "\n", "numsents_maxnumtokens_if_not_considering_stop_words", "=", "[", "]", "\n", "allennlp_formatted_reader", "=", "TextCatReader", "(", "word_tokenizer", "=", "WordTokenizer", "(", "word_filter", "=", "PassThroughWordFilter", "(", ")", ")", ",", "\n", "segment_sentences", "=", "True", ")", "\n", "pass_through_word_filter", "=", "PassThroughWordFilter", "(", ")", "\n", "stop_word_filter", "=", "StopwordFilter", "(", ")", "\n", "\n", "first_line", "=", "True", "\n", "num_instances_passed", "=", "0", "\n", "with", "open", "(", "data_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "f", ")", ":", "\n", "            ", "if", "first_line", ":", "\n", "# find which field is tokens", "\n", "                ", "temp_line", "=", "line", "\n", "tokens_field_ind", "=", "0", "\n", "while", "not", "(", "temp_line", ".", "startswith", "(", "'tokens\\t'", ")", "or", "temp_line", ".", "startswith", "(", "'tokens\\n'", ")", ")", ":", "\n", "                    ", "temp_line", "=", "temp_line", "[", "temp_line", ".", "index", "(", "'\\t'", ")", "+", "1", ":", "]", "\n", "tokens_field_ind", "+=", "1", "\n", "", "first_line", "=", "False", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "text_field", "=", "get_nth_field_in_line", "(", "line", ",", "tokens_field_ind", ")", "\n", "\n", "num_instances_passed", "+=", "1", "\n", "if", "len", "(", "text_field", ")", "==", "0", ":", "\n", "# reader will skip this, so its tuple is (0, 0)", "\n", "                    ", "numsents_maxnumtokens", ".", "append", "(", "(", "0", ",", "0", ")", ")", "\n", "numsents_maxnumtokens_if_not_considering_stop_words", ".", "append", "(", "(", "0", ",", "0", ")", ")", "\n", "continue", "\n", "\n", "", "allennlp_formatted_reader", ".", "_word_tokenizer", ".", "_word_filter", "=", "pass_through_word_filter", "\n", "instance", "=", "allennlp_formatted_reader", ".", "text_to_instance", "(", "tokens", "=", "text_field", ",", "category", "=", "'placeholder'", ")", "\n", "if", "instance", "is", "None", ":", "\n", "# reader will skip this, so its tuple is (0, 0)", "\n", "# and since the stop word version is even MORE restrictive, it would be skipped there too", "\n", "                    ", "numsents_maxnumtokens", ".", "append", "(", "(", "0", ",", "0", ")", ")", "\n", "numsents_maxnumtokens_if_not_considering_stop_words", ".", "append", "(", "(", "0", ",", "0", ")", ")", "\n", "continue", "\n", "", "list_of_sentences", "=", "instance", ".", "fields", "[", "'tokens'", "]", ".", "field_list", "\n", "num_sents", "=", "len", "(", "list_of_sentences", ")", "\n", "max_num_tokens", "=", "0", "\n", "for", "sentence_as_text_field", "in", "list_of_sentences", ":", "\n", "                    ", "list_of_tokens", "=", "sentence_as_text_field", ".", "tokens", "\n", "if", "len", "(", "list_of_tokens", ")", ">", "max_num_tokens", ":", "\n", "                        ", "max_num_tokens", "=", "len", "(", "list_of_tokens", ")", "\n", "", "", "numsents_maxnumtokens", ".", "append", "(", "(", "num_sents", ",", "max_num_tokens", ")", ")", "\n", "\n", "allennlp_formatted_reader", ".", "_word_tokenizer", ".", "_word_filter", "=", "stop_word_filter", "\n", "instance", "=", "allennlp_formatted_reader", ".", "text_to_instance", "(", "tokens", "=", "text_field", ",", "\n", "category", "=", "'placeholder'", ")", "\n", "if", "instance", "is", "None", ":", "\n", "# reader will skip this, so its tuple is (0, 0)", "\n", "                    ", "numsents_maxnumtokens_if_not_considering_stop_words", ".", "append", "(", "(", "0", ",", "0", ")", ")", "\n", "continue", "\n", "", "list_of_sentences", "=", "instance", ".", "fields", "[", "'tokens'", "]", ".", "field_list", "\n", "num_sents", "=", "len", "(", "list_of_sentences", ")", "\n", "max_num_tokens", "=", "0", "\n", "for", "sentence_as_text_field", "in", "list_of_sentences", ":", "\n", "                    ", "list_of_tokens", "=", "sentence_as_text_field", ".", "tokens", "\n", "if", "len", "(", "list_of_tokens", ")", ">", "max_num_tokens", ":", "\n", "                        ", "max_num_tokens", "=", "len", "(", "list_of_tokens", ")", "\n", "", "", "numsents_maxnumtokens_if_not_considering_stop_words", ".", "append", "(", "(", "num_sents", ",", "max_num_tokens", ")", ")", "\n", "\n", "", "", "", "assert", "len", "(", "numsents_maxnumtokens", ")", "==", "num_instances_passed", "\n", "assert", "len", "(", "numsents_maxnumtokens_if_not_considering_stop_words", ")", "==", "num_instances_passed", "\n", "\n", "temp_full_filename", "=", "data_filename", "[", ":", "data_filename", ".", "rfind", "(", "'.'", ")", "]", "+", "\"_temp.tsv\"", "\n", "old_f", "=", "open", "(", "data_filename", ",", "'r'", ")", "\n", "first_line", "=", "True", "\n", "instance_counter", "=", "0", "\n", "with", "open", "(", "temp_full_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "old_f", ":", "\n", "            ", "if", "first_line", ":", "\n", "                ", "old_line", "=", "line", "[", ":", "line", ".", "rfind", "(", "'\\n'", ")", "]", "\n", "\n", "new_line", "=", "(", "old_line", "+", "'\\t'", "+", "\n", "'num_sentences_post_stopword_removal'", "+", "'\\t'", "+", "\n", "'max_num_tokens_in_sentence_post_stopword_removal'", "+", "'\\t'", "+", "\n", "'num_sentences'", "+", "'\\t'", "+", "\n", "'max_num_tokens_in_sentence'", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "new_line", ")", "\n", "first_line", "=", "False", "\n", "", "else", ":", "\n", "                ", "if", "line", ".", "strip", "(", ")", "==", "''", ":", "\n", "                    ", "continue", "\n", "", "str_num_sents_no_stopwords", "=", "str", "(", "\n", "numsents_maxnumtokens_if_not_considering_stop_words", "[", "instance_counter", "]", "[", "0", "]", ")", "\n", "str_max_num_tokens_no_stopwords", "=", "str", "(", "\n", "numsents_maxnumtokens_if_not_considering_stop_words", "[", "instance_counter", "]", "[", "1", "]", ")", "\n", "str_num_sents", "=", "str", "(", "numsents_maxnumtokens", "[", "instance_counter", "]", "[", "0", "]", ")", "\n", "str_max_num_tokens", "=", "str", "(", "numsents_maxnumtokens", "[", "instance_counter", "]", "[", "1", "]", ")", "\n", "old_line", "=", "line", "[", ":", "line", ".", "rfind", "(", "'\\n'", ")", "]", "\n", "\n", "new_line", "=", "(", "old_line", "+", "'\\t'", "+", "\n", "str_num_sents_no_stopwords", "+", "'\\t'", "+", "\n", "str_max_num_tokens_no_stopwords", "+", "'\\t'", "+", "\n", "str_num_sents", "+", "'\\t'", "+", "\n", "str_max_num_tokens", "+", "'\\n'", ")", "\n", "\n", "f", ".", "write", "(", "new_line", ")", "\n", "instance_counter", "+=", "1", "\n", "", "", "", "old_f", ".", "close", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "data_filename", ")", ":", "\n", "        ", "os", ".", "remove", "(", "data_filename", ")", "\n", "", "os", ".", "rename", "(", "temp_full_filename", ",", "data_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.make_yahoo_full_data_file": [[285, 332], ["make_datasets.make_pickled_list_of_instances_from_xml", "make_datasets.make_pickled_list_of_instances_from_xml", "make_datasets.get_pickled_instance_list", "make_datasets.get_pickled_instance_list", "random.shuffle", "random.shuffle", "open", "open.write", "open.close", "print", "os.remove", "os.remove", "make_datasets.reformat_file_to_remove_newlines_not_caught_by_replace", "make_datasets.add_info_about_num_sents_and_max_num_tokens_to_data_file", "open", "str", "str", "make_datasets.get_writeable_text", "open.write", "str", "str", "make_datasets.get_writeable_text", "open.write", "str", "line.strip", "labels_to_care_about.append", "line.strip"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.make_pickled_list_of_instances_from_xml", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.make_pickled_list_of_instances_from_xml", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_pickled_instance_list", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_pickled_instance_list", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.reformat_file_to_remove_newlines_not_caught_by_replace", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.add_info_about_num_sents_and_max_num_tokens_to_data_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_writeable_text", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.get_writeable_text"], ["", "def", "make_yahoo_full_data_file", "(", ")", ":", "\n", "    ", "labels_to_care_about", "=", "[", "]", "\n", "with", "open", "(", "yahoo_accepted_label_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "strip", "(", ")", "!=", "''", ":", "\n", "                ", "labels_to_care_about", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "", "pickle_filename_1", "=", "yahoo_fixed_filename_1", "+", "\"_instances.pkl\"", "\n", "pickle_filename_2", "=", "yahoo_fixed_filename_2", "+", "\"_instances.pkl\"", "\n", "# see note at beginning of file about characters added to ends of yahoo files", "\n", "make_pickled_list_of_instances_from_xml", "(", "yahoo_fixed_filename_1", ",", "'maincat'", ",", "[", "'subject'", ",", "'content'", ",", "'bestanswer'", "]", ",", "\n", "labels_to_care_about", ",", "'document'", ",", "pickle_filename_1", ",", "\n", "instance_id_field_name", "=", "'uri'", ")", "\n", "make_pickled_list_of_instances_from_xml", "(", "yahoo_fixed_filename_1", ",", "'maincat'", ",", "[", "'subject'", ",", "'content'", ",", "'bestanswer'", "]", ",", "\n", "labels_to_care_about", ",", "'document'", ",", "pickle_filename_2", ",", "\n", "instance_id_field_name", "=", "'uri'", ")", "\n", "# we reload the pickle files after finishing with both xml files because otherwise this python process", "\n", "# uses too much memory at once", "\n", "first_set_of_instances", "=", "get_pickled_instance_list", "(", "pickle_filename_1", ")", "\n", "second_set_of_instances", "=", "get_pickled_instance_list", "(", "pickle_filename_2", ")", "\n", "shuffle", "(", "first_set_of_instances", ")", "\n", "shuffle", "(", "second_set_of_instances", ")", "\n", "all_data_f", "=", "open", "(", "yahoo_output_full_data_filename", ",", "'w'", ")", "\n", "all_data_f", ".", "write", "(", "'id'", "+", "'\\t'", "+", "'category'", "+", "'\\t'", "+", "'tokens'", "+", "'\\n'", ")", "\n", "instances_written_so_far", "=", "0", "\n", "\n", "for", "instance", "in", "first_set_of_instances", ":", "\n", "        ", "str_id", "=", "str", "(", "instance", "[", "0", "]", ")", "\n", "str_label", "=", "str", "(", "instance", "[", "1", "]", ")", "\n", "str_text", "=", "get_writeable_text", "(", "instance", "[", "2", "]", ")", "\n", "\n", "all_data_f", ".", "write", "(", "str_id", "+", "'\\t'", "+", "str_label", "+", "'\\t'", "+", "str_text", "+", "'\\n'", ")", "\n", "instances_written_so_far", "+=", "1", "\n", "", "for", "instance", "in", "second_set_of_instances", ":", "\n", "        ", "str_id", "=", "str", "(", "instance", "[", "0", "]", ")", "\n", "str_label", "=", "str", "(", "instance", "[", "1", "]", ")", "\n", "str_text", "=", "get_writeable_text", "(", "instance", "[", "2", "]", ")", "\n", "\n", "all_data_f", ".", "write", "(", "str_id", "+", "'\\t'", "+", "str_label", "+", "'\\t'", "+", "str_text", "+", "'\\n'", ")", "\n", "instances_written_so_far", "+=", "1", "\n", "", "all_data_f", ".", "close", "(", ")", "\n", "\n", "print", "(", "\"Total number of instances: \"", "+", "str", "(", "instances_written_so_far", ")", ")", "\n", "os", ".", "remove", "(", "pickle_filename_1", ")", "\n", "os", ".", "remove", "(", "pickle_filename_2", ")", "\n", "reformat_file_to_remove_newlines_not_caught_by_replace", "(", "yahoo_output_full_data_filename", ")", "\n", "\n", "add_info_about_num_sents_and_max_num_tokens_to_data_file", "(", "yahoo_output_full_data_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.make_imdb_full_data_file": [[334, 348], ["make_datasets.reformat_file_to_remove_newlines_not_caught_by_replace", "print", "open", "json.load", "open", "f.write", "str().replace().replace", "str().replace().replace", "str", "f.write", "str", "str().replace", "str().replace", "str", "str"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.reformat_file_to_remove_newlines_not_caught_by_replace"], ["", "def", "make_imdb_full_data_file", "(", ")", ":", "\n", "    ", "with", "open", "(", "imdb_data_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "imdb_output_full_data_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'id'", "+", "'\\t'", "+", "'category'", "+", "'\\t'", "+", "'tokens'", "+", "'\\n'", ")", "\n", "counter", "=", "1", "\n", "for", "instance", "in", "data", ":", "\n", "            ", "category", "=", "str", "(", "instance", "[", "\"rating\"", "]", ")", ".", "replace", "(", "'\\t'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "tokens", "=", "str", "(", "instance", "[", "\"review\"", "]", ")", ".", "replace", "(", "'\\t'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "' '", ")", "# title is not used", "\n", "id", "=", "str", "(", "counter", ")", "\n", "f", ".", "write", "(", "id", "+", "'\\t'", "+", "category", "+", "'\\t'", "+", "tokens", "+", "'\\n'", ")", "\n", "counter", "+=", "1", "\n", "", "", "reformat_file_to_remove_newlines_not_caught_by_replace", "(", "imdb_output_full_data_filename", ")", "\n", "print", "(", "\"Wrote \"", "+", "str", "(", "counter", "-", "1", ")", "+", "\" instances to file.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.main": [[350, 353], ["make_datasets.make_yahoo_full_data_file", "make_datasets.make_imdb_full_data_file"], "function", ["home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.make_yahoo_full_data_file", "home.repos.pwc.inspect_result.serrano-s_attn-tests.before_model_training.make_datasets.make_imdb_full_data_file"], ["", "def", "main", "(", ")", ":", "\n", "    ", "make_yahoo_full_data_file", "(", ")", "\n", "make_imdb_full_data_file", "(", ")", "\n", "\n"]]}