{"home.repos.pwc.inspect_result.edouardelasalles_dar.None.train.train_step": [[17, 45], ["model.train", "optimizer.zero_grad", "batch.text.to", "batch.author.to", "batch.timestep.to", "target_text.ne().sum().item", "model", "loss.backward", "optimizer.step", "utils.perplexity", "utils.neg_log_prob().sum", "target_text.ne().sum", "utils.neg_log_prob", "ha.pow().sum", "nll.item", "target_text.ne", "ha.pow"], "function", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.perplexity", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.neg_log_prob"], ["def", "train_step", "(", "model", ",", "optimizer", ",", "batch", ",", "device", ",", "opt", ")", ":", "\n", "# perform a single stochastic gradient step", "\n", "    ", "model", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "# extract data from batch and send them to GPU", "\n", "text", "=", "batch", ".", "text", ".", "to", "(", "device", ")", "\n", "input_text", "=", "text", "[", ":", "-", "1", "]", "\n", "target_text", "=", "text", "[", "1", ":", "]", "\n", "authors", "=", "batch", ".", "author", ".", "to", "(", "device", ")", "\n", "timesteps", "=", "batch", ".", "timestep", ".", "to", "(", "device", ")", "\n", "n", "=", "text", ".", "shape", "[", "1", "]", "\n", "ntkn", "=", "target_text", ".", "ne", "(", "Corpus", ".", "pad_id", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "# forward", "\n", "pred", ",", "_", "=", "model", "(", "input_text", ",", "authors", ",", "timesteps", ")", "\n", "# loss", "\n", "loss", "=", "0", "\n", "# -- word level nll", "\n", "nll", "=", "neg_log_prob", "(", "pred", ",", "target_text", ")", ".", "sum", "(", ")", "/", "n", "\n", "loss", "+=", "nll", "\n", "# -- L2 regularization of static word embeddings", "\n", "if", "opt", ".", "l2_a", ">", "0", ":", "\n", "        ", "ha", "=", "model", ".", "author_embedding", ".", "weight", "\n", "loss", "+=", "opt", ".", "l2_a", "*", "0.5", "*", "ha", ".", "pow", "(", "2", ")", ".", "sum", "(", ")", "/", "opt", ".", "n_ex", "\n", "# backward", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# step", "\n", "optimizer", ".", "step", "(", ")", "\n", "return", "perplexity", "(", "nll", ".", "item", "(", ")", "*", "n", "/", "ntkn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.train.evaluate": [[47, 64], ["model.eval", "utils.perplexity", "batch.text.to", "batch.author.to", "batch.timestep.to", "target_text.ne().sum().item", "model", "utils.neg_log_prob().sum().item", "target_text.ne().sum", "utils.neg_log_prob().sum", "target_text.ne", "utils.neg_log_prob"], "function", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.perplexity", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.neg_log_prob"], ["", "def", "evaluate", "(", "model", ",", "testloader", ",", "device", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "ntkn", "=", "0", "\n", "nll", "=", "0", "\n", "for", "batch", "in", "testloader", ":", "\n", "# data", "\n", "        ", "text", "=", "batch", ".", "text", ".", "to", "(", "device", ")", "\n", "input_text", "=", "text", "[", ":", "-", "1", "]", "\n", "target_text", "=", "text", "[", "1", ":", "]", "\n", "authors", "=", "batch", ".", "author", ".", "to", "(", "device", ")", "\n", "timesteps", "=", "batch", ".", "timestep", ".", "to", "(", "device", ")", "\n", "ntkn", "+=", "target_text", ".", "ne", "(", "Corpus", ".", "pad_id", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "# forward", "\n", "pred", ",", "_", "=", "model", "(", "input_text", ",", "authors", ",", "timesteps", ")", "\n", "# perplexity", "\n", "nll", "+=", "neg_log_prob", "(", "pred", ",", "target_text", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "return", "perplexity", "(", "nll", "/", "ntkn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.train.main": [[66, 183], ["print", "random.seed", "torch.manual_seed", "torch.manual_seed", "os.path.isdir", "os.makedirs", "print", "print", "utils.load_corpus", "utils.load_fold", "torch.utils.data.DataLoader", "utils.load_fold", "torch.utils.data.DataLoader", "len", "print", "model.DynamicAuthorLanguageModel().to", "str", "sum", "print", "list", "torch.optim.Adam", "torch.optim.Adam", "str", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "print", "tqdm.tqdm", "tqdm.tqdm.close", "print", "print", "torch.save", "torch.save", "print", "os.uname", "opt.device.lstrip().isdigit", "torch.device", "torch.device", "str", "torch.device", "torch.device", "random.randint", "DynamicAuthorLanguageModel().to.named_parameters", "torch.no_grad", "torch.no_grad", "train.evaluate", "os.path.join", "int", "input", "shutil.rmtree", "print", "exit", "model.DynamicAuthorLanguageModel", "p.nelement", "train.train_step", "tqdm.tqdm.set_postfix", "tqdm.tqdm.update", "torch.save", "torch.save", "DynamicAuthorLanguageModel().to.state_dict", "torch.optim.Adam.state_dict", "opt.device.lstrip", "DynamicAuthorLanguageModel().to.parameters", "max", "torch.optim.lr_scheduler.LambdaLR.step", "torch.no_grad", "torch.no_grad", "train.evaluate", "os.path.join", "any", "DynamicAuthorLanguageModel().to.state_dict", "torch.optim.Adam.state_dict", "any"], "function", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.load_corpus", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.load_fold", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.load_fold", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.train.evaluate", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.train.train_step", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.train.evaluate"], ["", "def", "main", "(", "opt", ")", ":", "\n", "    ", "opt", ".", "hostname", "=", "os", ".", "uname", "(", ")", "[", "1", "]", "\n", "# cudnn", "\n", "if", "opt", ".", "device", ".", "lstrip", "(", "'-'", ")", ".", "isdigit", "(", ")", "and", "int", "(", "opt", ".", "device", ")", "<=", "-", "1", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "else", ":", "\n", "        ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "str", "(", "opt", ".", "device", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "# seed", "\n", "", "if", "opt", ".", "manual_seed", "is", "None", ":", "\n", "        ", "opt", ".", "manual_seed", "=", "random", ".", "randint", "(", "1", ",", "10000", ")", "\n", "", "print", "(", "f\"seed: {opt.manual_seed}\"", ")", "\n", "random", ".", "seed", "(", "opt", ".", "manual_seed", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "manual_seed", ")", "\n", "# xp dir", "\n", "if", "os", ".", "path", ".", "isdir", "(", "opt", ".", "xp_dir", ")", ":", "\n", "        ", "if", "input", "(", "f'Experiment folder already exists at {opt.xp_dir}. Erase it? (y|n)'", ")", "in", "(", "'yes'", ",", "'y'", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "opt", ".", "xp_dir", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Terminating experiment...'", ")", "\n", "exit", "(", "0", ")", "\n", "", "", "os", ".", "makedirs", "(", "opt", ".", "xp_dir", ")", "\n", "print", "(", "f'Experiment directory created at {opt.xp_dir}'", ")", "\n", "\n", "##################################################################################################################", "\n", "# Data", "\n", "##################################################################################################################", "\n", "print", "(", "'Loading data...'", ")", "\n", "# load corpus", "\n", "corpus", "=", "load_corpus", "(", "opt", ")", "\n", "# trainset", "\n", "trainset", "=", "load_fold", "(", "corpus", ",", "'train'", ",", "opt", ".", "data_dir", ")", "\n", "trainloader", "=", "DataLoader", "(", "trainset", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "collate_fn", "=", "text_collate", ",", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ",", "drop_last", "=", "True", ")", "\n", "# testset", "\n", "testset", "=", "load_fold", "(", "corpus", ",", "'test'", ",", "opt", ".", "data_dir", ")", "\n", "testloader", "=", "DataLoader", "(", "testset", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "collate_fn", "=", "text_collate", ",", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "True", ")", "\n", "# attributes", "\n", "opt", ".", "n_ex", "=", "len", "(", "trainset", ")", "\n", "opt", ".", "naut", "=", "trainset", ".", "na", "\n", "opt", ".", "ntoken", "=", "corpus", ".", "vocab_size", "\n", "opt", ".", "padding_idx", "=", "Corpus", ".", "pad_id", "\n", "\n", "##################################################################################################################", "\n", "# Model", "\n", "##################################################################################################################", "\n", "print", "(", "'Building model...'", ")", "\n", "model", "=", "DynamicAuthorLanguageModel", "(", "opt", ".", "ntoken", ",", "opt", ".", "nwe", ",", "opt", ".", "naut", ",", "opt", ".", "nha", ",", "opt", ".", "nhat", ",", "opt", ".", "nhid_dyn", ",", "opt", ".", "nlayers_dyn", ",", "\n", "opt", ".", "cond_fusion", ",", "opt", ".", "nhid_lm", ",", "opt", ".", "nlayers_lm", ",", "opt", ".", "dropouti", ",", "opt", ".", "dropoutl", ",", "\n", "opt", ".", "dropoutw", ",", "opt", ".", "dropouto", ",", "opt", ".", "tie_weights", ",", "opt", ".", "padding_idx", ")", ".", "to", "(", "device", ")", "\n", "opt", ".", "model", "=", "str", "(", "model", ")", "\n", "opt", ".", "nparameters", "=", "sum", "(", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", "\n", "print", "(", "f'{opt.nparameters} parameters'", ")", "\n", "\n", "##################################################################################################################", "\n", "# Optimizer", "\n", "##################################################################################################################", "\n", "model_params", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "no_wd", "=", "[", "'entity_embedding'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model_params", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_wd", ")", "]", ",", "'weight_decay'", ":", "opt", ".", "wd", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model_params", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_wd", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "]", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "opt", ".", "lr", ")", "\n", "opt", ".", "optimizer", "=", "str", "(", "optimizer", ")", "\n", "# learning rate scheduling", "\n", "niter", "=", "opt", ".", "lr_scheduling_burnin", "+", "opt", ".", "lr_scheduling_niter", "\n", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "\n", "optimizer", ",", "\n", "lr_lambda", "=", "lambda", "i", ":", "max", "(", "0", ",", "(", "opt", ".", "lr_scheduling_niter", "-", "i", ")", "/", "opt", ".", "lr_scheduling_niter", ")", ")", "\n", "\n", "##################################################################################################################", "\n", "# Training", "\n", "##################################################################################################################", "\n", "print", "(", "'Training...'", ")", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "assert", "niter", ">", "0", "\n", "pb", "=", "tqdm", "(", "total", "=", "niter", ",", "ncols", "=", "0", ",", "desc", "=", "'iter'", ")", "\n", "itr", "=", "-", "1", "\n", "finished", "=", "False", "\n", "ppl_test", "=", "None", "\n", "while", "not", "finished", ":", "\n", "# train", "\n", "        ", "for", "batch", "in", "trainloader", ":", "\n", "            ", "itr", "+=", "1", "\n", "# gradient step", "\n", "ppl_train", "=", "train_step", "(", "model", ",", "optimizer", ",", "batch", ",", "device", ",", "opt", ")", "\n", "# lr scheduling", "\n", "if", "itr", ">=", "opt", ".", "lr_scheduling_burnin", ":", "\n", "                ", "lr_scheduler", ".", "step", "(", ")", "\n", "# progress bar", "\n", "", "pb", ".", "set_postfix", "(", "ppl_train", "=", "ppl_train", ",", "ppl_test", "=", "ppl_test", ",", "lr", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "pb", ".", "update", "(", ")", "\n", "# break ?", "\n", "if", "itr", ">", "0", "and", "itr", "%", "opt", ".", "chkpt_interval", "==", "0", ":", "\n", "                ", "break", "\n", "", "if", "itr", ">=", "niter", ":", "\n", "                ", "finished", "=", "True", "\n", "break", "\n", "# eval", "\n", "", "", "if", "itr", "%", "opt", ".", "chkpt_interval", "==", "0", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "ppl_test", "=", "evaluate", "(", "model", ",", "testloader", ",", "device", ")", "\n", "", "torch", ".", "save", "(", "\n", "{", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "'opt'", ":", "opt", "}", ",", "\n", "os", ".", "path", ".", "join", "(", "opt", ".", "xp_dir", ",", "'model.pth'", ")", "\n", ")", "\n", "", "", "pb", ".", "close", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "ppl_test", "=", "evaluate", "(", "model", ",", "testloader", ",", "device", ")", "\n", "", "print", "(", "f'Final test ppl: {ppl_test}'", ")", "\n", "print", "(", "'Saving model...'", ")", "\n", "torch", ".", "save", "(", "\n", "{", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "'opt'", ":", "opt", "}", ",", "\n", "os", ".", "path", ".", "join", "(", "opt", ".", "xp_dir", ",", "'model.pth'", ")", "\n", ")", "\n", "print", "(", "'Done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus.__init__": [[25, 35], ["sum", "len", "len", "corpus.Corpus._init_specials", "set", "len"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.BertCorpus._init_specials"], ["def", "__init__", "(", "self", ",", "examples", ",", "ids", ",", "vocab", ",", "authors", ")", ":", "\n", "        ", "self", ".", "examples", "=", "examples", "\n", "self", ".", "ids", "=", "ids", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "vocab_size", "=", "vocab", ".", "size", "\n", "self", ".", "nwords", "=", "sum", "(", "len", "(", "ex", ".", "text", ")", "for", "ex", "in", "self", ".", "examples", ")", "\n", "self", ".", "authors", "=", "authors", "\n", "self", ".", "na", "=", "len", "(", "authors", ".", "i2s", ")", "\n", "self", ".", "nt", "=", "len", "(", "set", "(", "[", "ex", ".", "timestep", "for", "ex", "in", "examples", "]", ")", ")", "\n", "self", ".", "_init_specials", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus.__len__": [[36, 38], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus.__getitem__": [[39, 43], ["torch.LongTensor", "Element", "corpus.Corpus.vocab.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Vocab.convert_tokens_to_ids"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "x", "=", "self", ".", "examples", "[", "index", "]", "\n", "text", "=", "torch", ".", "LongTensor", "(", "self", ".", "vocab", ".", "convert_tokens_to_ids", "(", "x", ".", "text", ")", ")", "\n", "return", "Element", "(", "x", ".", "id", ",", "text", ",", "self", ".", "authors", ".", "s2i", "[", "x", ".", "author", "]", ",", "x", ".", "timestep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus.post_process": [[44, 46], ["None"], "methods", ["None"], ["", "def", "post_process", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus.filter_ids": [[47, 50], ["list", "corpus.Corpus.__class__", "filter"], "methods", ["None"], ["", "def", "filter_ids", "(", "self", ",", "ids", ")", ":", "\n", "        ", "examples", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "id", "in", "ids", ",", "self", ".", "examples", ")", ")", "\n", "return", "self", ".", "__class__", "(", "examples", ",", "self", ".", "ids", ",", "self", ".", "vocab", ",", "self", ".", "authors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus._init_specials": [[51, 55], ["corpus.Corpus.vocab.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Vocab.convert_tokens_to_ids"], ["", "def", "_init_specials", "(", "self", ")", ":", "\n", "        ", "specials", "=", "[", "Corpus", ".", "pad_token", ",", "Corpus", ".", "unk_token", ",", "Corpus", ".", "bos_token", ",", "Corpus", ".", "eos_token", "]", "\n", "Corpus", ".", "pad_id", ",", "Corpus", ".", "unk_id", ",", "Corpus", ".", "bos_id", ",", "Corpus", ".", "eos_id", "=", "self", ".", "vocab", ".", "convert_tokens_to_ids", "(", "specials", ")", "\n", "assert", "Corpus", ".", "unk_token", "in", "self", ".", "vocab", ".", "i2s", "and", "Corpus", ".", "unk_id", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus.load_corpus": [[56, 87], ["os.path.join", "os.path.isfile", "os.path.join", "print", "list", "corpus.Vocab", "cls._build_vocab", "corpus.Vocab", "print", "cls._preprocess", "cls", "print", "open", "f.read().splitlines", "open", "set", "filter", "list", "open", "pickle.dump", "open", "cls", "json.loads", "os.path.join", "f.read().splitlines", "data.values", "data.keys", "f.read", "pickle.load", "f.read"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.BertCorpus._build_vocab", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus._preprocess"], ["", "@", "classmethod", "\n", "def", "load_corpus", "(", "cls", ",", "data_dir", ",", "**", "kwargs", ")", ":", "\n", "        ", "pckl_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'corpus.pkl'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "pckl_path", ")", ":", "\n", "            ", "print", "(", "f'Loading corpus at {pckl_path}...'", ")", "\n", "with", "open", "(", "pckl_path", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "return", "cls", "(", "*", "pickle", ".", "load", "(", "f", ")", ")", "\n", "# corpus", "\n", "", "", "fpath", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'corpus.json'", ")", "\n", "print", "(", "f'Loading corpus at {fpath}...'", ")", "\n", "data", "=", "{", "}", "\n", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "                ", "ex", "=", "json", ".", "loads", "(", "l", ")", "\n", "data", "[", "ex", "[", "'id'", "]", "]", "=", "ex", "\n", "# fields", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "train_ids", "=", "set", "(", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", ")", "\n", "", "trainset", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "[", "'id'", "]", "in", "train_ids", ",", "data", ".", "values", "(", ")", ")", ")", "\n", "# -- ids", "\n", "ids", "=", "Vocab", "(", "list", "(", "data", ".", "keys", "(", ")", ")", ")", "\n", "# -- texts", "\n", "vocab", "=", "cls", ".", "_build_vocab", "(", "trainset", ",", "**", "kwargs", ")", "\n", "# -- authors", "\n", "authors", "=", "Vocab", "(", "[", "e", "for", "ex", "in", "trainset", "for", "e", "in", "ex", "[", "'authors'", "]", "]", ",", "specials", "=", "[", "'<pad>'", "]", ",", "unk_token", "=", "False", ")", "\n", "# preprocess", "\n", "print", "(", "'preprocessing...'", ")", "\n", "examples", "=", "cls", ".", "_preprocess", "(", "data", ",", "ids", ".", "i2s", ",", "vocab", ",", "authors", ")", "\n", "with", "open", "(", "pckl_path", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "(", "examples", ",", "ids", ",", "vocab", ",", "authors", ")", ",", "f", ")", "\n", "", "return", "cls", "(", "examples", ",", "ids", ",", "vocab", ",", "authors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus._build_vocab": [[88, 97], ["corpus.Vocab", "cls._tokenize", "text.strip().lower", "text.strip"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus._tokenize"], ["", "@", "classmethod", "\n", "def", "_build_vocab", "(", "cls", ",", "data", ")", ":", "\n", "        ", "all_tokens", "=", "[", "]", "\n", "for", "ex", "in", "data", ":", "\n", "            ", "text", "=", "' '", ".", "join", "(", "text", ".", "strip", "(", ")", ".", "lower", "(", ")", "for", "text", "in", "ex", "[", "'texts'", "]", ")", "\n", "all_tokens", "+=", "cls", ".", "_tokenize", "(", "text", ")", "\n", "", "specials", "=", "[", "cls", ".", "pad_token", ",", "cls", ".", "unk_token", ",", "cls", ".", "bos_token", ",", "cls", ".", "eos_token", "]", "\n", "vocab", "=", "Vocab", "(", "all_tokens", ",", "min_freq", "=", "5", ",", "specials", "=", "specials", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus._preprocess": [[98, 112], ["tqdm.tqdm.tqdm", "cls._preprocess_texts", "len", "examples.append", "Element"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.BertCorpus._preprocess_texts"], ["", "@", "classmethod", "\n", "def", "_preprocess", "(", "cls", ",", "data", ",", "ids", ",", "text_vocab", ",", "authors_vocab", ")", ":", "\n", "# tokenize", "\n", "        ", "examples", "=", "[", "]", "\n", "for", "i", "in", "tqdm", "(", "ids", ")", ":", "\n", "            ", "ex", "=", "data", "[", "i", "]", "\n", "t", "=", "ex", "[", "'timestep'", "]", "\n", "authors", "=", "ex", "[", "'authors'", "]", "\n", "tokens", "=", "cls", ".", "_preprocess_texts", "(", "ex", "[", "'texts'", "]", ",", "text_vocab", ")", "\n", "if", "len", "(", "tokens", ")", ">", "512", ":", "\n", "                ", "continue", "\n", "", "for", "a", "in", "authors", ":", "\n", "                ", "examples", ".", "append", "(", "Element", "(", "i", ",", "tokens", ",", "a", ",", "t", ")", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus._tokenize": [[113, 116], ["re.search", "nltk.tokenize.word_tokenize"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "[", "'N'", "if", "re", ".", "search", "(", "r'[0-9]'", ",", "w", ")", "else", "w", "for", "w", "in", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus._preprocess_texts": [[117, 122], ["text.strip().lower", "cls._tokenize", "text.strip"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus._tokenize"], ["", "@", "classmethod", "\n", "def", "_preprocess_texts", "(", "cls", ",", "texts", ",", "vocab", ")", ":", "\n", "        ", "text", "=", "' '", ".", "join", "(", "[", "text", ".", "strip", "(", ")", ".", "lower", "(", ")", "for", "text", "in", "texts", "]", ")", "\n", "tokens", "=", "[", "cls", ".", "bos_token", "]", "+", "cls", ".", "_tokenize", "(", "text", ")", "+", "[", "cls", ".", "eos_token", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.BertCorpus._init_wp": [[130, 132], ["torch.tensor", "wp.startswith", "vocab.vocab.keys"], "methods", ["None"], ["def", "_init_wp", "(", "self", ",", "vocab", ")", ":", "\n", "        ", "self", ".", "is_full_word", "=", "torch", ".", "tensor", "(", "[", "not", "wp", ".", "startswith", "(", "'##'", ")", "for", "wp", "in", "vocab", ".", "vocab", ".", "keys", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.BertCorpus._init_specials": [[133, 137], ["corpus.BertCorpus.vocab.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Vocab.convert_tokens_to_ids"], ["", "def", "_init_specials", "(", "self", ")", ":", "\n", "        ", "specials", "=", "[", "BertCorpus", ".", "bos_token", ",", "BertCorpus", ".", "eos_token", ",", "BertCorpus", ".", "pad_token", ",", "BertCorpus", ".", "unk_token", "]", "\n", "Corpus", ".", "bos_token", ",", "Corpus", ".", "eos_token", ",", "Corpus", ".", "pad_token", ",", "Corpus", ".", "unk_token", "=", "specials", "\n", "Corpus", ".", "bos_id", ",", "Corpus", ".", "eos_id", ",", "Corpus", ".", "pad_id", ",", "Corpus", ".", "unk_id", "=", "self", ".", "vocab", ".", "convert_tokens_to_ids", "(", "specials", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.BertCorpus.post_process": [[138, 146], ["None"], "methods", ["None"], ["", "def", "post_process", "(", "self", ",", "text", ")", ":", "\n", "        ", "out", "=", "''", "\n", "for", "word", "in", "text", ":", "\n", "            ", "if", "word", "[", ":", "2", "]", "==", "'##'", ":", "\n", "                ", "out", "+=", "word", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "                ", "out", "+=", "word", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.BertCorpus._build_vocab": [[147, 153], ["print", "pytorch_pretrained_bert.BertTokenizer.from_pretrained", "len"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_build_vocab", "(", "cls", ",", "data", ",", "bert_cache_dir", ")", ":", "\n", "        ", "print", "(", "f'(Down)Loading BERT tokenizer at {bert_cache_dir}'", ")", "\n", "vocab", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ",", "cache_dir", "=", "bert_cache_dir", ")", "\n", "vocab", ".", "size", "=", "len", "(", "vocab", ".", "vocab", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.BertCorpus._preprocess_texts": [[154, 159], ["vocab.tokenize"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_preprocess_texts", "(", "cls", ",", "texts", ",", "vocab", ")", ":", "\n", "        ", "text", "=", "cls", ".", "bos_token", "+", "' '", "+", "' '", ".", "join", "(", "texts", ")", "+", "' '", "+", "cls", ".", "eos_token", "\n", "tokens", "=", "vocab", ".", "tokenize", "(", "text", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Vocab.__init__": [[164, 181], ["collections.Counter", "sorted", "corpus.Vocab.frequencies.sort", "corpus.Vocab.s2i.update", "len", "collections.Counter.items", "corpus.Vocab.i2s.append", "collections.defaultdict", "enumerate"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "min_freq", "=", "0", ",", "specials", "=", "None", ",", "unk_token", "=", "True", ")", ":", "\n", "        ", "self", ".", "min_freq", "=", "min_freq", "\n", "counter", "=", "Counter", "(", "data", ")", "\n", "self", ".", "frequencies", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "tup", ":", "tup", "[", "0", "]", ")", "\n", "self", ".", "frequencies", ".", "sort", "(", "key", "=", "lambda", "tup", ":", "tup", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "self", ".", "specials", "=", "specials", "\n", "self", ".", "i2s", "=", "[", "w", "for", "w", "in", "self", ".", "specials", "]", "if", "self", ".", "specials", "is", "not", "None", "else", "[", "]", "\n", "for", "word", ",", "freq", "in", "self", ".", "frequencies", ":", "\n", "            ", "if", "freq", "<", "self", ".", "min_freq", ":", "\n", "                ", "break", "\n", "", "self", ".", "i2s", ".", "append", "(", "word", ")", "\n", "", "if", "unk_token", ":", "\n", "            ", "self", ".", "s2i", "=", "defaultdict", "(", "_default_id", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "s2i", "=", "{", "}", "\n", "", "self", ".", "s2i", ".", "update", "(", "{", "tok", ":", "i", "for", "i", ",", "tok", "in", "enumerate", "(", "self", ".", "i2s", ")", "}", ")", "\n", "self", ".", "size", "=", "len", "(", "self", ".", "i2s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Vocab.convert_tokens_to_ids": [[182, 184], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "[", "self", ".", "s2i", "[", "token", "]", "for", "token", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Vocab.convert_ids_to_tokens": [[185, 187], ["None"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "return", "[", "self", ".", "i2s", "[", "i", "]", "for", "i", "in", "ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Vocab.__len__": [[188, 190], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "i2s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.text_collate": [[192, 198], ["Element", "torch.nn.utils.rnn.pad_sequence", "torch.tensor", "torch.tensor", "Element", "zip"], "function", ["None"], ["", "", "def", "text_collate", "(", "batch", ")", ":", "\n", "    ", "elements", "=", "Element", "(", "*", "zip", "(", "*", "batch", ")", ")", "\n", "texts", "=", "pad_sequence", "(", "elements", ".", "text", ",", "batch_first", "=", "False", ",", "padding_value", "=", "Corpus", ".", "pad_id", ")", "\n", "authors", "=", "torch", ".", "tensor", "(", "elements", ".", "author", ")", "\n", "timesteps", "=", "torch", ".", "tensor", "(", "elements", ".", "timestep", ")", "\n", "return", "Element", "(", "elements", ".", "id", ",", "texts", ",", "authors", ",", "timesteps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus._default_id": [[200, 202], ["None"], "function", ["None"], ["", "def", "_default_id", "(", ")", ":", "\n", "    ", "return", "1", "\n", "", ""]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.__init__": [[12, 44], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "module.rnn_lm.RNNLanguageModel", "module.mlp.MLP", "module.mlp.MLP", "model.DynamicAuthorLanguageModel._init"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.__init__", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel._init"], ["    ", "def", "__init__", "(", "self", ",", "\n", "ntoken", ",", "nwe", ",", "# text", "\n", "naut", ",", "nha", ",", "nhat", ",", "nhid_dyn", ",", "nlayers_dyn", ",", "cond_fusion", ",", "# authors", "\n", "nhid_lm", ",", "nlayers_lm", ",", "dropouti", ",", "dropoutl", ",", "dropoutw", ",", "dropouto", ",", "tie_weights", ",", "padding_idx", ",", "# language model", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# attributes", "\n", "self", ".", "ntoken", "=", "ntoken", "# size of vocabulary", "\n", "self", ".", "nwe", "=", "nwe", "# size of word embeddings", "\n", "self", ".", "naut", "=", "naut", "# number of authors", "\n", "self", ".", "nha", "=", "nha", "# size of static author embeddings", "\n", "self", ".", "nhat", "=", "nhat", "# size of dynamic latent states", "\n", "self", ".", "tie_weights", "=", "tie_weights", "# tie weights between word embeddings and linear decoder?", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "cond_fusion", "=", "cond_fusion", "# how to incorporate the context vectors into the language mode? (w0|h0|cat)", "\n", "nout", "=", "nwe", "if", "tie_weights", "else", "nhid_lm", "\n", "# modules", "\n", "# -- word embeddings", "\n", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", "(", "ntoken", ",", "nwe", ",", "padding_idx", "=", "padding_idx", ")", "\n", "# -- static author embeddings", "\n", "self", ".", "author_embedding", "=", "nn", ".", "Embedding", "(", "naut", ",", "nha", ",", "padding_idx", "=", "padding_idx", ")", "\n", "# -- LSTM language model", "\n", "self", ".", "rnn_lm", "=", "RNNLanguageModel", "(", "ntoken", ",", "nwe", ",", "nha", "+", "nhat", ",", "self", ".", "cond_fusion", ",", "nhid_lm", ",", "nout", ",", "nlayers_lm", ",", "'LSTM'", ",", "\n", "dropouti", ",", "dropoutl", ",", "dropoutw", ",", "dropouto", ")", "\n", "# dynamic modules", "\n", "nhid_init", "=", "0", "if", "nlayers_dyn", "==", "1", "else", "nhid_dyn", "\n", "# -- mlp that that produce h_{a,t=0} from static author embeddings", "\n", "self", ".", "init_dyn", "=", "MLP", "(", "nha", ",", "nhid_init", ",", "nhat", ",", "nlayers_dyn", ")", "\n", "# -- mlp for the dynamic residual latent function", "\n", "self", ".", "dynamic", "=", "MLP", "(", "nha", "+", "nhat", ",", "nhid_dyn", ",", "nhat", ",", "nlayers_dyn", ")", "\n", "# init", "\n", "self", ".", "_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel._init": [[45, 57], ["model.DynamicAuthorLanguageModel.word_embedding.weight.data.uniform_", "model.DynamicAuthorLanguageModel.author_embedding.weight.data.uniform_", "functools.partial", "model.DynamicAuthorLanguageModel.dynamic.apply", "model.DynamicAuthorLanguageModel.rnn_lm.tie_weights"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel.tie_weights"], ["", "def", "_init", "(", "self", ")", ":", "\n", "        ", "self", ".", "word_embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "self", ".", "word_embedding", ".", "weight", ".", "data", "[", "self", ".", "padding_idx", "]", "=", "0", "\n", "self", ".", "author_embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "self", ".", "author_embedding", ".", "weight", ".", "data", "[", "self", ".", "padding_idx", "]", "=", "0", "\n", "# weight tying", "\n", "if", "self", ".", "tie_weights", ":", "\n", "            ", "self", ".", "rnn_lm", ".", "tie_weights", "(", "self", ".", "word_embedding", ".", "weight", ")", "\n", "# we initialise the residual MLP orthogonally to increase the numerical stability of latent", "\n", "# states through time", "\n", "", "init_weight_fn", "=", "partial", "(", "init_weight", ",", "init_type", "=", "'orthogonal'", ",", "init_gain", "=", "0.02", ")", "\n", "self", ".", "dynamic", ".", "apply", "(", "init_weight_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.init_state": [[58, 62], ["model.DynamicAuthorLanguageModel.init_dyn"], "methods", ["None"], ["", "def", "init_state", "(", "self", ",", "ha", ")", ":", "\n", "# compute the initial state h_{a,t=0}", "\n", "        ", "ha0", "=", "self", ".", "init_dyn", "(", "ha", ")", "\n", "return", "ha0", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.next_state": [[63, 69], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.DynamicAuthorLanguageModel.dynamic"], "methods", ["None"], ["", "def", "next_state", "(", "self", ",", "state", ",", "ha", ")", ":", "\n", "# compute the next state given the previous one and the static embedding", "\n", "        ", "res_inp", "=", "torch", ".", "cat", "(", "[", "state", ",", "ha", "]", ",", "1", ")", "\n", "res", "=", "self", ".", "dynamic", "(", "res_inp", ")", "\n", "next_state", "=", "state", "+", "res", "\n", "return", "next_state", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.get_cond": [[70, 92], ["model.DynamicAuthorLanguageModel.author_embedding", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "isinstance", "isinstance", "model.DynamicAuthorLanguageModel.init_state", "model.DynamicAuthorLanguageModel.next_state", "hat.append", "res.append", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "timesteps.max().item", "len", "timesteps.max"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.init_state", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.next_state"], ["", "def", "get_cond", "(", "self", ",", "authors", ",", "timesteps", ")", ":", "\n", "# compute the context vectors for a batch of (author, timestep) pairs", "\n", "# authors: LongTensor with shape [batch_size] containing author ids", "\n", "# timesteps: LongTensor with shape [batch_size] containing timesteps or a scalar timestep", "\n", "        ", "nt", "=", "timesteps", "+", "1", "if", "isinstance", "(", "timesteps", ",", "int", ")", "else", "timesteps", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", "\n", "# -- get the static author embeddings and the initial state", "\n", "ha", "=", "self", ".", "author_embedding", "(", "authors", ")", "\n", "hat", "=", "[", "self", ".", "init_state", "(", "ha", ")", "]", "\n", "res", "=", "[", "]", "\n", "# -- loop through time to compute all context vectors", "\n", "for", "t", "in", "range", "(", "1", ",", "nt", ")", ":", "\n", "            ", "hat_next", ",", "res_t", "=", "self", ".", "next_state", "(", "hat", "[", "-", "1", "]", ",", "ha", ")", "\n", "hat", ".", "append", "(", "hat_next", ")", "\n", "res", ".", "append", "(", "res_t", ")", "\n", "", "hat_all_t", "=", "torch", ".", "stack", "(", "hat", ")", "\n", "# -- retrive the context vectors corresponding to the (author, timestep) pairs given in input", "\n", "if", "isinstance", "(", "timesteps", ",", "int", ")", ":", "\n", "            ", "hat", "=", "hat_all_t", "[", "timesteps", "]", "\n", "", "else", ":", "\n", "            ", "i_range", "=", "torch", ".", "arange", "(", "len", "(", "timesteps", ")", ",", "device", "=", "timesteps", ".", "device", ")", "\n", "hat", "=", "hat_all_t", "[", "timesteps", ",", "i_range", "]", "\n", "", "return", "ha", ",", "hat", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.decode": [[93, 98], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.DynamicAuthorLanguageModel.rnn_lm"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "emb", ",", "ha", ",", "hat", ",", "hidden", "=", "None", ")", ":", "\n", "# the final context vector if formed by concatenating a static embeddings ha and a dynamic state hat", "\n", "        ", "cond", "=", "torch", ".", "cat", "(", "[", "ha", ",", "hat", "]", ",", "1", ")", "\n", "# the final context vector is fed to the LSTM language model", "\n", "return", "self", ".", "rnn_lm", "(", "cond", ",", "emb", ",", "hidden", "=", "hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.forward": [[99, 107], ["model.DynamicAuthorLanguageModel.get_cond", "model.DynamicAuthorLanguageModel.word_embedding", "model.DynamicAuthorLanguageModel.decode"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.model.DynamicAuthorLanguageModel.get_cond", "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel.decode"], ["", "def", "forward", "(", "self", ",", "text", ",", "authors", ",", "timesteps", ")", ":", "\n", "# text: LongTensor of token indices with shape [seq_len, batch_size]", "\n", "# authors: LongTensor of author ods with shape [batch_size]", "\n", "# timesteps: LongTensor of timesteps with shape [batch_size] or a scalar timestep", "\n", "        ", "ha", ",", "hat", "=", "self", ".", "get_cond", "(", "authors", ",", "timesteps", ")", "\n", "emb", "=", "self", ".", "word_embedding", "(", "text", ")", "\n", "output", ",", "hidden", "=", "self", ".", "decode", "(", "emb", ",", "ha", ",", "hat", ")", "\n", "return", "output", ",", "hidden", "\n", "", "", ""]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.neg_log_prob": [[9, 12], ["torch.cross_entropy", "F.cross_entropy.view_as", "proba.view", "data.view"], "function", ["None"], ["def", "neg_log_prob", "(", "proba", ",", "data", ")", ":", "\n", "    ", "nll", "=", "F", ".", "cross_entropy", "(", "proba", ".", "view", "(", "-", "1", ",", "proba", ".", "shape", "[", "-", "1", "]", ")", ",", "data", ".", "view", "(", "-", "1", ")", ",", "ignore_index", "=", "Corpus", ".", "pad_id", ",", "reduction", "=", "'none'", ")", "\n", "return", "nll", ".", "view_as", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.perplexity": [[14, 19], ["math.exp", "float"], "function", ["None"], ["", "def", "perplexity", "(", "nll", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "math", ".", "exp", "(", "nll", ")", "\n", "", "except", "OverflowError", ":", "\n", "        ", "return", "float", "(", "'inf'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.load_corpus": [[21, 27], ["os.path.join", "corpus.BertCorpus.load_corpus", "corpus.Corpus.load_corpus"], "function", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.load_corpus", "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.load_corpus"], ["", "", "def", "load_corpus", "(", "opt", ")", ":", "\n", "    ", "opt", ".", "data_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "corpus", ",", "opt", ".", "task", ")", "\n", "if", "opt", ".", "corpus", "==", "'s2'", ":", "\n", "        ", "return", "BertCorpus", ".", "load_corpus", "(", "opt", ".", "data_dir", ",", "bert_cache_dir", "=", "opt", ".", "bert_cache_dir", ")", "\n", "", "if", "opt", ".", "corpus", "==", "'nyt'", ":", "\n", "        ", "return", "Corpus", ".", "load_corpus", "(", "opt", ".", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.None.utils.load_fold": [[29, 35], ["corpus.filter_ids.filter_ids", "print", "open", "set", "os.path.join", "f.read().splitlines", "len", "f.read"], "function", ["home.repos.pwc.inspect_result.edouardelasalles_dar.None.corpus.Corpus.filter_ids"], ["", "", "def", "load_fold", "(", "corpus", ",", "fold", ",", "data_dir", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f'{fold}.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "ids", "=", "set", "(", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", ")", "\n", "", "corpus", "=", "corpus", ".", "filter_ids", "(", "ids", ")", "\n", "print", "(", "f'{fold} set: {len(corpus)} examples ({corpus.nwords} words), {corpus.na} authors, {corpus.nt} timesteps'", ")", "\n", "return", "corpus", "\n", "", ""]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel.__init__": [[8, 37], ["torch.Module.__init__", "rnn_lm.RNN", "torch.Linear", "torch.Linear", "rnn_lm.RNNLanguageModel.decoder.weight.data.uniform_", "rnn_lm.RNNLanguageModel.decoder.bias.data.zero_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.linear", "torch.linear"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ntoken", ",", "nwe", ",", "nz", ",", "cond_fusion", ",", "nhid", ",", "nout", ",", "nlayers", ",", "cell", ",", "dropouti", ",", "dropoutl", ",", "dropoutw", ",", "dropouto", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "cond_fusion", "in", "(", "'cat'", ",", "'h0'", ",", "'w0'", ")", "\n", "assert", "dropoutl", "==", "0", "or", "nlayers", ">", "1", "\n", "# attributes", "\n", "self", ".", "do_downproj", "=", "nlayers", "==", "1", "and", "nout", "!=", "nhid", "\n", "self", ".", "nhid", "=", "nhid", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "cond_fusion", "=", "cond_fusion", "\n", "self", ".", "cell", "=", "cell", "\n", "self", ".", "nwe", "=", "nwe", "\n", "self", ".", "nz", "=", "nz", "\n", "# modules", "\n", "# -- rnn", "\n", "ninp", "=", "nwe", "+", "nz", "if", "cond_fusion", "==", "'cat'", "else", "nwe", "\n", "nout", "=", "nhid", "if", "self", ".", "do_downproj", "else", "nout", "\n", "self", ".", "rnn", "=", "RNN", "(", "cell", ",", "ninp", ",", "nhid", ",", "nout", ",", "nlayers", ",", "dropouti", ",", "dropoutl", ",", "dropoutw", ",", "dropouto", ")", "\n", "# -- condition fusion", "\n", "if", "cond_fusion", "==", "'h0'", ":", "\n", "            ", "self", ".", "up_proj", "=", "nn", ".", "Linear", "(", "nz", ",", "nhid", "*", "nlayers", ")", "\n", "", "if", "cond_fusion", "==", "'w0'", ":", "\n", "            ", "self", ".", "up_proj", "=", "nn", ".", "Linear", "(", "nz", ",", "nwe", ")", "\n", "# -- down projection", "\n", "", "if", "self", ".", "do_downproj", ":", "\n", "            ", "self", ".", "downproj", "=", "nn", ".", "linear", "(", "nhid", ",", "nout", ")", "\n", "# -- decoder", "\n", "", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "nout", ",", "ntoken", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "self", ".", "decoder", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel.tie_weights": [[38, 40], ["None"], "methods", ["None"], ["", "def", "tie_weights", "(", "self", ",", "weight", ")", ":", "\n", "        ", "self", ".", "decoder", ".", "weight", "=", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel.forward": [[41, 46], ["rnn_lm.RNNLanguageModel._get_inputs", "rnn_lm.RNNLanguageModel.rnn", "rnn_lm.RNNLanguageModel.decode"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel._get_inputs", "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel.decode"], ["", "def", "forward", "(", "self", ",", "z", ",", "emb", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "inputs", ",", "hidden", "=", "self", ".", "_get_inputs", "(", "z", ",", "emb", ",", "hidden", ")", "\n", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "inputs", ",", "hidden", ")", "\n", "output", "=", "self", ".", "decode", "(", "output", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel.decode": [[47, 51], ["rnn_lm.RNNLanguageModel.decoder", "rnn_lm.RNNLanguageModel.downproj"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "output", ")", ":", "\n", "        ", "if", "self", ".", "do_downproj", ":", "\n", "            ", "output", "=", "self", ".", "downproj", "(", "output", ")", "\n", "", "return", "self", ".", "decoder", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNNLanguageModel._get_inputs": [[52, 71], ["z.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_lm.RNNLanguageModel.up_proj", "rnn_lm.RNNLanguageModel.view().transpose().contiguous", "rnn_lm.RNNLanguageModel.up_proj", "z.unsqueeze", "h.unsqueeze", "rnn_lm.RNNLanguageModel.view().transpose", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "rnn_lm.RNNLanguageModel.view"], "methods", ["None"], ["", "def", "_get_inputs", "(", "self", ",", "z", ",", "emb", ",", "hidden", ")", ":", "\n", "        ", "if", "self", ".", "cond_fusion", "==", "'cat'", ":", "\n", "            ", "z_ex", "=", "z", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "emb", ".", "shape", "[", "0", "]", ",", "*", "z", ".", "shape", ")", "\n", "inputs", "=", "torch", ".", "cat", "(", "[", "emb", ",", "z_ex", "]", ",", "2", ")", "\n", "return", "inputs", ",", "hidden", "\n", "", "if", "hidden", "is", "None", ":", "\n", "            ", "if", "self", ".", "cond_fusion", "==", "'h0'", ":", "\n", "                ", "z_proj", "=", "self", ".", "up_proj", "(", "z", ")", "\n", "h0", "=", "z_proj", ".", "view", "(", "-", "1", ",", "self", ".", "nlayers", ",", "self", ".", "nhid", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "hidden", "=", "[", "h", ".", "unsqueeze", "(", "0", ")", "for", "h", "in", "h0", "]", "\n", "if", "self", ".", "cell", "==", "'LSTM'", ":", "\n", "                    ", "c0", "=", "[", "torch", ".", "zeros_like", "(", "h", ")", "for", "h", "in", "hidden", "]", "\n", "hidden", "=", "(", "hidden", ",", "c0", ")", "\n", "", "return", "emb", ",", "hidden", "\n", "", "if", "self", ".", "cond_fusion", "==", "'w0'", ":", "\n", "                ", "emb", "[", "0", "]", "=", "self", ".", "up_proj", "(", "z", ")", "\n", "return", "emb", ",", "None", "\n", "# if hidden is not None, then we are not at first token", "\n", "", "", "return", "emb", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNN.__init__": [[80, 99], ["torch.Module.__init__", "module.dropout.LockedDropout", "module.dropout.LockedDropout", "module.dropout.LockedDropout", "torch.ModuleList", "torch.ModuleList", "getattr", "range", "module.dropout.WeightDropout"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.__init__"], ["def", "__init__", "(", "self", ",", "cell", ",", "ninp", ",", "nhid", ",", "nout", ",", "nlayers", ",", "dropouti", ",", "dropoutl", ",", "dropoutw", ",", "dropouto", ")", ":", "\n", "        ", "super", "(", "RNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "nlayers", ">", "1", "or", "dropoutl", "==", "0.0", ",", "'Layer dropout only in multi layers lstm'", "\n", "assert", "nlayers", ">", "1", "or", "nout", "==", "nhid", ",", "'if one layer, nhid = nwe'", "\n", "# attributes", "\n", "self", ".", "cell", "=", "cell", "\n", "self", ".", "ninp", "=", "ninp", "\n", "self", ".", "nhid", "=", "nhid", "\n", "self", ".", "nout", "=", "nout", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "idrop", "=", "LockedDropout", "(", "dropouti", ")", "\n", "self", ".", "ldrop", "=", "LockedDropout", "(", "dropoutl", ")", "\n", "self", ".", "odrop", "=", "LockedDropout", "(", "dropouto", ")", "\n", "# LSTM", "\n", "self", ".", "rnns", "=", "[", "getattr", "(", "nn", ",", "self", ".", "cell", ")", "(", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "nout", ",", "1", ")", "\n", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "if", "dropoutw", ">", "0", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "WeightDropout", "(", "rnn", ",", "dropoutw", ")", "for", "rnn", "in", "self", ".", "rnns", "]", "\n", "", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.rnn_lm.RNN.forward": [[100, 133], ["enumerate", "rnn_lm.RNN.odrop", "outputs.append", "rnn", "raw_outputs.append", "new_hidden.append", "rnn_lm.RNN.idrop", "rnn_lm.RNN.ldrop", "outputs.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "output", "=", "input", "\n", "new_hidden", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "raw_outputs", "=", "[", "]", "\n", "# forward through layers", "\n", "for", "l", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnns", ")", ":", "\n", "            ", "input_l", "=", "output", "\n", "if", "hidden", "is", "None", ":", "\n", "                ", "h_n", "=", "None", "\n", "", "elif", "self", ".", "cell", "==", "'LSTM'", ":", "\n", "                ", "h_n", "=", "(", "hidden", "[", "0", "]", "[", "l", "]", ",", "hidden", "[", "1", "]", "[", "l", "]", ")", "\n", "", "else", ":", "\n", "                ", "h_n", "=", "hidden", "[", "l", "]", "\n", "# dropout", "\n", "", "input_l_droped", "=", "self", ".", "idrop", "(", "input_l", ")", "if", "l", "==", "0", "else", "self", ".", "ldrop", "(", "input_l", ")", "\n", "if", "l", ">", "0", ":", "\n", "                ", "outputs", ".", "append", "(", "input_l_droped", ")", "\n", "# forward", "\n", "", "raw_output", ",", "new_h", "=", "rnn", "(", "input_l_droped", ",", "h_n", ")", "\n", "raw_outputs", ".", "append", "(", "raw_output", ")", "\n", "new_hidden", ".", "append", "(", "new_h", ")", "\n", "output", "=", "raw_output", "\n", "", "raw_output", "=", "output", "\n", "output", "=", "self", ".", "odrop", "(", "output", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "if", "self", ".", "cell", "==", "'LSTM'", ":", "\n", "            ", "h_n", "=", "[", "h_n_l", "for", "h_n_l", ",", "_", "in", "new_hidden", "]", "\n", "c_n", "=", "[", "c_n_l", "for", "_", ",", "c_n_l", "in", "new_hidden", "]", "\n", "hidden", "=", "(", "h_n", ",", "c_n", ")", "\n", "", "else", ":", "\n", "            ", "hidden", "=", "new_hidden", "\n", "", "return", "output", ",", "hidden", "\n", "", "", ""]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.mlp.MLP.__init__": [[15, 33], ["torch.Module.__init__", "torch.Sequential", "mlp.make_lin_block", "range"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.__init__", "home.repos.pwc.inspect_result.edouardelasalles_dar.module.mlp.make_lin_block"], ["    ", "def", "__init__", "(", "self", ",", "ninp", ",", "nhid", ",", "nout", ",", "nlayers", ",", "bias", "=", "True", ",", "dropout", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "nhid", "==", "0", "or", "nlayers", ">", "1", "\n", "assert", "dropout", "==", "0", "or", "nlayers", ">", "1", "\n", "# attributes", "\n", "self", ".", "ninp", "=", "ninp", "\n", "self", ".", "nout", "=", "nout", "\n", "# modules", "\n", "modules", "=", "[", "\n", "make_lin_block", "(", "\n", "ninp", "=", "ninp", "if", "il", "==", "0", "else", "nhid", ",", "\n", "nout", "=", "nout", "if", "il", "==", "nlayers", "-", "1", "else", "nhid", ",", "\n", "bias", "=", "bias", ",", "\n", "relu", "=", "il", ">", "0", ",", "\n", "dropout", "=", "dropout", "if", "il", ">", "0", "else", "0.", ",", "\n", ")", "for", "il", "in", "range", "(", "nlayers", ")", "\n", "]", "\n", "self", ".", "module", "=", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.mlp.MLP.forward": [[34, 36], ["mlp.MLP.module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "module", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.mlp.make_lin_block": [[4, 12], ["modules.append", "torch.Sequential", "modules.append", "modules.append", "torch.Linear", "torch.Dropout", "torch.ReLU"], "function", ["None"], ["def", "make_lin_block", "(", "ninp", ",", "nout", ",", "bias", ",", "relu", ",", "dropout", ")", ":", "\n", "    ", "modules", "=", "[", "]", "\n", "if", "dropout", ">", "0", ":", "\n", "        ", "modules", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "", "if", "relu", ":", "\n", "        ", "modules", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "ninp", ",", "nout", ",", "bias", "=", "bias", ")", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.LockedDropout.__init__": [[12, 15], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.__init__"], ["def", "__init__", "(", "self", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.LockedDropout.forward": [[16, 23], ["x.new().bernoulli_", "mask.expand_as.expand_as.expand_as", "x.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", "or", "self", ".", "dropout", "<=", "0", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "new", "(", "1", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "self", ".", "dropout", ")", "\n", "mask", "=", "m", "/", "(", "1", "-", "self", ".", "dropout", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.__init__": [[32, 40], ["torch.Module.__init__", "getattr", "dropout.WeightDropout.register_parameter", "torch.dropout", "torch.dropout", "torch.Parameter", "torch.Parameter"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.__init__"], ["def", "__init__", "(", "self", ",", "module", ",", "weight_p", ",", "layer_names", "=", "[", "'weight_hh_l0'", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", ",", "self", ".", "weight_p", ",", "self", ".", "layer_names", "=", "module", ",", "weight_p", ",", "layer_names", "\n", "for", "layer", "in", "self", ".", "layer_names", ":", "\n", "# Makes a copy of the weights of the selected layers.", "\n", "            ", "w", "=", "getattr", "(", "self", ".", "module", ",", "layer", ")", "\n", "self", ".", "register_parameter", "(", "f'{layer}_raw'", ",", "nn", ".", "Parameter", "(", "w", ".", "data", ")", ")", "\n", "self", ".", "module", ".", "_parameters", "[", "layer", "]", "=", "F", ".", "dropout", "(", "w", ",", "p", "=", "self", ".", "weight_p", ",", "training", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout._setweights": [[41, 46], ["getattr", "torch.dropout", "torch.dropout"], "methods", ["None"], ["", "", "def", "_setweights", "(", "self", ")", ":", "\n", "        ", "\"Apply dropout to the raw weights.\"", "\n", "for", "layer", "in", "self", ".", "layer_names", ":", "\n", "            ", "raw_w", "=", "getattr", "(", "self", ",", "f'{layer}_raw'", ")", "\n", "self", ".", "module", ".", "_parameters", "[", "layer", "]", "=", "F", ".", "dropout", "(", "raw_w", ",", "p", "=", "self", ".", "weight_p", ",", "training", "=", "self", ".", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.forward": [[47, 53], ["dropout.WeightDropout._setweights", "warnings.catch_warnings", "warnings.simplefilter", "dropout.WeightDropout.module.forward"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout._setweights", "home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.forward"], ["", "", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_setweights", "(", ")", "\n", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "\n", "# To avoid the warning that comes because the weights aren't flattened.", "\n", "            ", "warnings", ".", "simplefilter", "(", "\"ignore\"", ")", "\n", "return", "self", ".", "module", ".", "forward", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.reset": [[54, 60], ["hasattr", "getattr", "torch.dropout", "torch.dropout", "dropout.WeightDropout.module.reset"], "methods", ["home.repos.pwc.inspect_result.edouardelasalles_dar.module.dropout.WeightDropout.reset"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layer_names", ":", "\n", "            ", "raw_w", "=", "getattr", "(", "self", ",", "f'{layer}_raw'", ")", "\n", "self", ".", "module", ".", "_parameters", "[", "layer", "]", "=", "F", ".", "dropout", "(", "raw_w", ",", "p", "=", "self", ".", "weight_p", ",", "training", "=", "False", ")", "\n", "", "if", "hasattr", "(", "self", ".", "module", ",", "'reset'", ")", ":", "\n", "            ", "self", ".", "module", ".", "reset", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.edouardelasalles_dar.module.utils.init_weight": [[4, 24], ["torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["None"], ["import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "\n", "from", "corpus", "import", "BertCorpus", ",", "Corpus", "\n", "\n", "\n", "def", "neg_log_prob", "(", "proba", ",", "data", ")", ":", "\n", "    ", "nll", "=", "F", ".", "cross_entropy", "(", "proba", ".", "view", "(", "-", "1", ",", "proba", ".", "shape", "[", "-", "1", "]", ")", ",", "data", ".", "view", "(", "-", "1", ")", ",", "ignore_index", "=", "Corpus", ".", "pad_id", ",", "reduction", "=", "'none'", ")", "\n", "return", "nll", ".", "view_as", "(", "data", ")", "\n", "\n", "\n", "", "def", "perplexity", "(", "nll", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "math", ".", "exp", "(", "nll", ")", "\n", "", "except", "OverflowError", ":", "\n", "        ", "return", "float", "(", "'inf'", ")", "\n", "\n", "\n", "", "", "def", "load_corpus", "(", "opt", ")", ":", "\n", "    ", "opt", ".", "data_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "corpus", ",", "opt", ".", "task", ")", "\n", "if", "opt", ".", "corpus", "==", "'s2'", ":", "\n", "        ", "return", "BertCorpus", ".", "load_corpus", "(", "opt", ".", "data_dir", ",", "bert_cache_dir", "=", "opt", ".", "bert_cache_dir", ")", "\n"]]}