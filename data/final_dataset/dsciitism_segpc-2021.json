{"home.repos.pwc.inspect_result.dsciitism_segpc-2021.utils.ensemble.work": [[28, 48], ["glob.glob", "glob.glob", "glob.glob", "print", "shutil.copyfile", "shutil.copyfile", "shutil.copyfile", "str", "str", "str"], "function", ["None"], ["def", "work", "(", "it", ")", ":", "\n", "  ", "img", "=", "imgs", "[", "it", "]", "\n", "imgs1", "=", "glob", ".", "glob", "(", "path1", "+", "img", "+", "\"_*.bmp\"", ")", "\n", "imgs2", "=", "glob", ".", "glob", "(", "path2", "+", "img", "+", "\"_*.bmp\"", ")", "\n", "imgs3", "=", "glob", ".", "glob", "(", "path3", "+", "img", "+", "\"_*.bmp\"", ")", "\n", "\n", "count", "=", "1", "\n", "for", "im", "in", "imgs1", ":", "\n", "    ", "shutil", ".", "copyfile", "(", "im", ",", "new_path", "+", "img", "+", "\"_\"", "+", "str", "(", "count", ")", "+", "\".bmp\"", ")", "\n", "count", "=", "count", "+", "1", "\n", "\n", "", "for", "im", "in", "imgs2", ":", "\n", "    ", "shutil", ".", "copyfile", "(", "im", ",", "new_path", "+", "img", "+", "\"_\"", "+", "str", "(", "count", ")", "+", "\".bmp\"", ")", "\n", "count", "=", "count", "+", "1", "\n", "\n", "", "for", "im", "in", "imgs3", ":", "\n", "    ", "shutil", ".", "copyfile", "(", "im", ",", "new_path", "+", "img", "+", "\"_\"", "+", "str", "(", "count", ")", "+", "\".bmp\"", ")", "\n", "count", "=", "count", "+", "1", "\n", "\n", "", "print", "(", "it", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Transformer_Encoder.__init__": [[50, 80], ["timm.models.vision_transformer.VisionTransformer.__init__", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "DetectoRS_train.Transformer_Encoder.load_weights"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__", "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.load_weights"], ["    ", "def", "__init__", "(", "self", ",", "pretrained", "=", "False", ",", "pretrained_model", "=", "None", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "hybrid_backbone", "=", "None", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "\n", "        ", "super", "(", "Transformer_Encoder", ",", "self", ")", ".", "__init__", "(", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "num_classes", "=", "1000", ",", "embed_dim", "=", "embed_dim", ",", "depth", "=", "depth", ",", "\n", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "drop_rate", "=", "drop_rate", ",", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "hybrid_backbone", "=", "hybrid_backbone", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n", "self", ".", "num_classes", "=", "1", "\n", "self", ".", "dispatcher", "=", "{", "\n", "'vit_small_patch16_224'", ":", "vit_small_patch16_224", ",", "\n", "'vit_base_patch16_224'", ":", "vit_base_patch16_224", ",", "\n", "'vit_large_patch16_224'", ":", "vit_large_patch16_224", ",", "\n", "'vit_base_patch16_384'", ":", "vit_base_patch16_384", ",", "\n", "'vit_base_patch32_384'", ":", "vit_base_patch32_384", ",", "\n", "'vit_large_patch16_384'", ":", "vit_large_patch16_384", ",", "\n", "'vit_large_patch32_384'", ":", "vit_large_patch32_384", ",", "\n", "'vit_large_patch16_224'", ":", "vit_large_patch16_224", ",", "\n", "'vit_large_patch32_384'", ":", "vit_large_patch32_384", ",", "\n", "'vit_small_resnet26d_224'", ":", "vit_small_resnet26d_224", ",", "\n", "'vit_small_resnet50d_s3_224'", ":", "vit_small_resnet50d_s3_224", ",", "\n", "'vit_base_resnet26d_224'", ":", "vit_base_resnet26d_224", ",", "\n", "'vit_base_resnet50d_224'", ":", "vit_base_resnet50d_224", ",", "\n", "}", "\n", "self", ".", "pretrained_model", "=", "pretrained_model", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "if", "pretrained", ":", "\n", "            ", "self", ".", "load_weights", "(", ")", "\n", "", "self", ".", "head", "=", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "encoder_out", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Transformer_Encoder.forward_features": [[83, 103], ["DetectoRS_train.Transformer_Encoder.patch_embed", "DetectoRS_train.Transformer_Encoder.cls_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "DetectoRS_train.Transformer_Encoder.pos_drop", "enumerate", "range", "blk", "len", "DetectoRS_train.Transformer_Encoder.norm", "features.append"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "features", "=", "[", "]", "\n", "\n", "for", "i", ",", "blk", "in", "enumerate", "(", "self", ".", "blocks", ",", "1", ")", ":", "\n", "            ", "x", "=", "blk", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "encoder_out", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "            ", "features", "[", "i", "]", "=", "self", ".", "norm", "(", "features", "[", "i", "]", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Transformer_Encoder.forward": [[104, 108], ["DetectoRS_train.Transformer_Encoder.forward_features"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "features", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Transformer_Encoder.load_weights": [[109, 120], ["DetectoRS_train.Transformer_Encoder.load_state_dict", "print", "model.state_dict", "print"], "methods", ["None"], ["", "def", "load_weights", "(", "self", ")", ":", "\n", "        ", "model", "=", "None", "\n", "try", ":", "\n", "            ", "model", "=", "self", ".", "dispatcher", "[", "self", ".", "pretrained_model", "]", "(", "pretrained", "=", "True", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'could not not load model'", ")", "\n", "", "if", "model", "==", "None", ":", "\n", "            ", "return", "\n", "# try:", "\n", "", "self", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "print", "(", "\"successfully loaded weights!!!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Custom_Backbone.__init__": [[126, 161], ["torch.Module.__init__", "segmentation_models_pytorch.encoders.get_encoder", "DetectoRS_train.Transformer_Encoder", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torchvision.transforms.Resize", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "str", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "range", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "1", "\n", "self", ".", "emb_dim", "=", "768", "\n", "self", ".", "pretrained", "=", "True", "\n", "self", ".", "pretrained_trans_model", "=", "'vit_base_patch16_384'", "\n", "self", ".", "patch_size", "=", "16", "\n", "\n", "self", ".", "encoder_name", "=", "'timm-efficientnet-b5'", "\n", "self", ".", "in_channels", "=", "3", "\n", "self", ".", "encoder_depth", "=", "5", "\n", "self", ".", "encoder_weights", "=", "'noisy-student'", "\n", "\n", "self", ".", "conv_encoder", "=", "get_encoder", "(", "self", ".", "encoder_name", ",", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "depth", "=", "self", ".", "encoder_depth", ",", "\n", "weights", "=", "self", ".", "encoder_weights", ")", "\n", "self", ".", "conv_encoder", ".", "num_classes", "=", "1", "\n", "\n", "self", ".", "conv_channels", "=", "self", ".", "conv_encoder", ".", "out_channels", "\n", "\n", "if", "\"Transformer\"", "in", "args", ".", "backbone", ":", "\n", "          ", "self", ".", "transformer", "=", "Transformer_Encoder", "(", "pretrained", "=", "True", ",", "img_size", "=", "384", ",", "pretrained_model", "=", "self", ".", "pretrained_trans_model", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "qkv_bias", "=", "True", ")", "\n", "self", ".", "conv_final", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Conv2d", "(", "self", ".", "conv_channels", "[", "i", "]", ",", "self", ".", "emb_dim", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "conv_channels", ")", ")", "]", "\n", ")", "\n", "self", ".", "names", "=", "[", "\"p\"", "+", "str", "(", "i", "+", "2", ")", "for", "i", "in", "range", "(", "5", ")", "]", "\n", "self", ".", "resize", "=", "Resize", "(", "(", "384", ",", "384", ")", ")", "\n", "self", ".", "Wq", "=", "nn", ".", "Linear", "(", "self", ".", "emb_dim", ",", "self", ".", "emb_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "Wk", "=", "nn", ".", "Linear", "(", "self", ".", "emb_dim", ",", "self", ".", "emb_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "output_conv", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "self", ".", "emb_dim", ",", "2", "**", "(", "8", "+", "i", ")", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "for", "i", "in", "range", "(", "4", ")", "]", ")", "\n", "\n", "", "else", ":", "\n", "          ", "self", ".", "output_conv", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "self", ".", "conv_channels", "[", "i", "+", "2", "]", ",", "2", "**", "(", "8", "+", "i", ")", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "for", "i", "in", "range", "(", "4", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Custom_Backbone.forward": [[163, 186], ["list", "DetectoRS_train.Custom_Backbone.conv_encoder", "range", "DetectoRS_train.Custom_Backbone.transformer", "DetectoRS_train.Custom_Backbone.project", "DetectoRS_train.Custom_Backbone.emb2img", "DetectoRS_train.Custom_Backbone.insert", "DetectoRS_train.Custom_Backbone.insert", "len", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.project", "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.emb2img"], ["", "", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "\n", "      ", "conv_features", "=", "list", "(", "self", ".", "conv_encoder", "(", "image", ")", ")", "\n", "\n", "if", "\"Transformer\"", "in", "args", ".", "backbone", ":", "\n", "        ", "conv_features", "=", "conv_features", "[", "1", ":", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "conv_final", ")", ")", ":", "\n", "            ", "conv_features", "[", "i", "]", "=", "self", ".", "conv_final", "[", "i", "]", "(", "conv_features", "[", "i", "]", ")", "\n", "", "exp_shape", "=", "[", "i", ".", "shape", "for", "i", "in", "conv_features", "]", "\n", "transformer_features", "=", "self", ".", "transformer", "(", "F", ".", "interpolate", "(", "image", ",", "(", "384", ",", "384", ")", ")", ")", "\n", "features", "=", "self", ".", "project", "(", "conv_features", ",", "transformer_features", ")", "\n", "features", "=", "self", ".", "emb2img", "(", "features", ",", "exp_shape", ")", "\n", "features", "=", "features", "[", ":", "-", "1", "]", "\n", "features", "=", "[", "self", ".", "output_conv", "[", "i", "]", "(", "features", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", "]", "\n", "features", ".", "insert", "(", "0", ",", "image", ")", "\n", "\n", "", "else", ":", "\n", "        ", "conv_features", "=", "conv_features", "[", "2", ":", "]", "\n", "features", "=", "conv_features", "\n", "features", "=", "[", "self", ".", "output_conv", "[", "i", "]", "(", "features", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", "]", "\n", "features", ".", "insert", "(", "0", ",", "image", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Custom_Backbone.project": [[187, 203], ["range", "len", "einops.rearrange", "DetectoRS_train.Custom_Backbone.Wq", "DetectoRS_train.Custom_Backbone.Wk", "einops.rearrange", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "features.append", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["None"], ["", "def", "project", "(", "self", ",", "conv_features", ",", "transformer_features", ")", ":", "\n", "\n", "        ", "features", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "conv_features", ")", ")", ":", "\n", "\n", "            ", "t", "=", "transformer_features", "[", "i", "]", "\n", "x", "=", "rearrange", "(", "conv_features", "[", "i", "]", ",", "'b c h w -> b (h w) c'", ")", "\n", "xwq", "=", "self", ".", "Wq", "(", "x", ")", "\n", "twk", "=", "self", ".", "Wk", "(", "t", ")", "\n", "twk_T", "=", "rearrange", "(", "twk", ",", "'b l c -> b c l'", ")", "\n", "A", "=", "torch", ".", "einsum", "(", "'bij,bjk->bik'", ",", "xwq", ",", "twk_T", ")", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "x", "+=", "torch", ".", "einsum", "(", "'bij,bjk->bik'", ",", "A", ",", "t", ")", "\n", "features", ".", "append", "(", "x", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Custom_Backbone.emb2img": [[204, 212], ["enumerate", "x.transpose().reshape.transpose().reshape.transpose().reshape", "x.transpose().reshape.transpose().reshape.transpose"], "methods", ["None"], ["", "def", "emb2img", "(", "self", ",", "features", ",", "exp_shape", ")", ":", "\n", "\n", "        ", "for", "i", ",", "x", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "B", ",", "P", ",", "E", "=", "x", ".", "shape", "#(batch_size, latent_dim, emb_dim)", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "E", ",", "exp_shape", "[", "i", "]", "[", "2", "]", ",", "exp_shape", "[", "i", "]", "[", "3", "]", ")", "\n", "features", "[", "i", "]", "=", "x", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_train.Custom_Backbone.init_weights": [[213, 215], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "      ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Transformer_Encoder.__init__": [[42, 72], ["timm.models.vision_transformer.VisionTransformer.__init__", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "DetectoRS_inference.Transformer_Encoder.load_weights"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__", "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.load_weights"], ["    ", "def", "__init__", "(", "self", ",", "pretrained", "=", "False", ",", "pretrained_model", "=", "None", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "hybrid_backbone", "=", "None", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "\n", "        ", "super", "(", "Transformer_Encoder", ",", "self", ")", ".", "__init__", "(", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "num_classes", "=", "1000", ",", "embed_dim", "=", "embed_dim", ",", "depth", "=", "depth", ",", "\n", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "drop_rate", "=", "drop_rate", ",", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "hybrid_backbone", "=", "hybrid_backbone", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n", "self", ".", "num_classes", "=", "1", "\n", "self", ".", "dispatcher", "=", "{", "\n", "'vit_small_patch16_224'", ":", "vit_small_patch16_224", ",", "\n", "'vit_base_patch16_224'", ":", "vit_base_patch16_224", ",", "\n", "'vit_large_patch16_224'", ":", "vit_large_patch16_224", ",", "\n", "'vit_base_patch16_384'", ":", "vit_base_patch16_384", ",", "\n", "'vit_base_patch32_384'", ":", "vit_base_patch32_384", ",", "\n", "'vit_large_patch16_384'", ":", "vit_large_patch16_384", ",", "\n", "'vit_large_patch32_384'", ":", "vit_large_patch32_384", ",", "\n", "'vit_large_patch16_224'", ":", "vit_large_patch16_224", ",", "\n", "'vit_large_patch32_384'", ":", "vit_large_patch32_384", ",", "\n", "'vit_small_resnet26d_224'", ":", "vit_small_resnet26d_224", ",", "\n", "'vit_small_resnet50d_s3_224'", ":", "vit_small_resnet50d_s3_224", ",", "\n", "'vit_base_resnet26d_224'", ":", "vit_base_resnet26d_224", ",", "\n", "'vit_base_resnet50d_224'", ":", "vit_base_resnet50d_224", ",", "\n", "}", "\n", "self", ".", "pretrained_model", "=", "pretrained_model", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "if", "pretrained", ":", "\n", "            ", "self", ".", "load_weights", "(", ")", "\n", "", "self", ".", "head", "=", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "encoder_out", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Transformer_Encoder.forward_features": [[75, 95], ["DetectoRS_inference.Transformer_Encoder.patch_embed", "DetectoRS_inference.Transformer_Encoder.cls_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "DetectoRS_inference.Transformer_Encoder.pos_drop", "enumerate", "range", "blk", "len", "DetectoRS_inference.Transformer_Encoder.norm", "features.append"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "features", "=", "[", "]", "\n", "\n", "for", "i", ",", "blk", "in", "enumerate", "(", "self", ".", "blocks", ",", "1", ")", ":", "\n", "            ", "x", "=", "blk", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "encoder_out", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "            ", "features", "[", "i", "]", "=", "self", ".", "norm", "(", "features", "[", "i", "]", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Transformer_Encoder.forward": [[96, 100], ["DetectoRS_inference.Transformer_Encoder.forward_features"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "features", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Transformer_Encoder.load_weights": [[101, 112], ["DetectoRS_inference.Transformer_Encoder.load_state_dict", "print", "model.state_dict", "print"], "methods", ["None"], ["", "def", "load_weights", "(", "self", ")", ":", "\n", "        ", "model", "=", "None", "\n", "try", ":", "\n", "            ", "model", "=", "self", ".", "dispatcher", "[", "self", ".", "pretrained_model", "]", "(", "pretrained", "=", "True", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'could not not load model'", ")", "\n", "", "if", "model", "==", "None", ":", "\n", "            ", "return", "\n", "# try:", "\n", "", "self", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "print", "(", "\"successfully loaded weights!!!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Custom_Backbone.__init__": [[118, 153], ["torch.Module.__init__", "segmentation_models_pytorch.encoders.get_encoder", "DetectoRS_inference.Transformer_Encoder", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torchvision.transforms.Resize", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "str", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "range", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "1", "\n", "self", ".", "emb_dim", "=", "768", "\n", "self", ".", "pretrained", "=", "True", "\n", "self", ".", "pretrained_trans_model", "=", "'vit_base_patch16_384'", "\n", "self", ".", "patch_size", "=", "16", "\n", "\n", "self", ".", "encoder_name", "=", "'timm-efficientnet-b5'", "\n", "self", ".", "in_channels", "=", "3", "\n", "self", ".", "encoder_depth", "=", "5", "\n", "self", ".", "encoder_weights", "=", "'noisy-student'", "\n", "\n", "self", ".", "conv_encoder", "=", "get_encoder", "(", "self", ".", "encoder_name", ",", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "depth", "=", "self", ".", "encoder_depth", ",", "\n", "weights", "=", "self", ".", "encoder_weights", ")", "\n", "self", ".", "conv_encoder", ".", "num_classes", "=", "1", "\n", "\n", "self", ".", "conv_channels", "=", "self", ".", "conv_encoder", ".", "out_channels", "\n", "\n", "if", "\"Transformer\"", "in", "args", ".", "backbone", ":", "\n", "          ", "self", ".", "transformer", "=", "Transformer_Encoder", "(", "pretrained", "=", "True", ",", "img_size", "=", "384", ",", "pretrained_model", "=", "self", ".", "pretrained_trans_model", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "qkv_bias", "=", "True", ")", "\n", "self", ".", "conv_final", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Conv2d", "(", "self", ".", "conv_channels", "[", "i", "]", ",", "self", ".", "emb_dim", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "conv_channels", ")", ")", "]", "\n", ")", "\n", "self", ".", "names", "=", "[", "\"p\"", "+", "str", "(", "i", "+", "2", ")", "for", "i", "in", "range", "(", "5", ")", "]", "\n", "self", ".", "resize", "=", "Resize", "(", "(", "384", ",", "384", ")", ")", "\n", "self", ".", "Wq", "=", "nn", ".", "Linear", "(", "self", ".", "emb_dim", ",", "self", ".", "emb_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "Wk", "=", "nn", ".", "Linear", "(", "self", ".", "emb_dim", ",", "self", ".", "emb_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "output_conv", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "self", ".", "emb_dim", ",", "2", "**", "(", "8", "+", "i", ")", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "for", "i", "in", "range", "(", "4", ")", "]", ")", "\n", "\n", "", "else", ":", "\n", "          ", "self", ".", "output_conv", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "self", ".", "conv_channels", "[", "i", "+", "2", "]", ",", "2", "**", "(", "8", "+", "i", ")", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "for", "i", "in", "range", "(", "4", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Custom_Backbone.forward": [[155, 178], ["list", "DetectoRS_inference.Custom_Backbone.conv_encoder", "range", "DetectoRS_inference.Custom_Backbone.transformer", "DetectoRS_inference.Custom_Backbone.project", "DetectoRS_inference.Custom_Backbone.emb2img", "DetectoRS_inference.Custom_Backbone.insert", "DetectoRS_inference.Custom_Backbone.insert", "len", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.project", "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.emb2img"], ["", "", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "\n", "      ", "conv_features", "=", "list", "(", "self", ".", "conv_encoder", "(", "image", ")", ")", "\n", "\n", "if", "\"Transformer\"", "in", "args", ".", "backbone", ":", "\n", "        ", "conv_features", "=", "conv_features", "[", "1", ":", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "conv_final", ")", ")", ":", "\n", "            ", "conv_features", "[", "i", "]", "=", "self", ".", "conv_final", "[", "i", "]", "(", "conv_features", "[", "i", "]", ")", "\n", "", "exp_shape", "=", "[", "i", ".", "shape", "for", "i", "in", "conv_features", "]", "\n", "transformer_features", "=", "self", ".", "transformer", "(", "F", ".", "interpolate", "(", "image", ",", "(", "384", ",", "384", ")", ")", ")", "\n", "features", "=", "self", ".", "project", "(", "conv_features", ",", "transformer_features", ")", "\n", "features", "=", "self", ".", "emb2img", "(", "features", ",", "exp_shape", ")", "\n", "features", "=", "features", "[", ":", "-", "1", "]", "\n", "features", "=", "[", "self", ".", "output_conv", "[", "i", "]", "(", "features", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", "]", "\n", "features", ".", "insert", "(", "0", ",", "image", ")", "\n", "\n", "", "else", ":", "\n", "        ", "conv_features", "=", "conv_features", "[", "2", ":", "]", "\n", "features", "=", "conv_features", "\n", "features", "=", "[", "self", ".", "output_conv", "[", "i", "]", "(", "features", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", "]", "\n", "features", ".", "insert", "(", "0", ",", "image", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Custom_Backbone.project": [[179, 195], ["range", "len", "einops.rearrange", "DetectoRS_inference.Custom_Backbone.Wq", "DetectoRS_inference.Custom_Backbone.Wk", "einops.rearrange", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "features.append", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["None"], ["", "def", "project", "(", "self", ",", "conv_features", ",", "transformer_features", ")", ":", "\n", "\n", "        ", "features", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "conv_features", ")", ")", ":", "\n", "\n", "            ", "t", "=", "transformer_features", "[", "i", "]", "\n", "x", "=", "rearrange", "(", "conv_features", "[", "i", "]", ",", "'b c h w -> b (h w) c'", ")", "\n", "xwq", "=", "self", ".", "Wq", "(", "x", ")", "\n", "twk", "=", "self", ".", "Wk", "(", "t", ")", "\n", "twk_T", "=", "rearrange", "(", "twk", ",", "'b l c -> b c l'", ")", "\n", "A", "=", "torch", ".", "einsum", "(", "'bij,bjk->bik'", ",", "xwq", ",", "twk_T", ")", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "x", "+=", "torch", ".", "einsum", "(", "'bij,bjk->bik'", ",", "A", ",", "t", ")", "\n", "features", ".", "append", "(", "x", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Custom_Backbone.emb2img": [[196, 204], ["enumerate", "x.transpose().reshape.transpose().reshape.transpose().reshape", "x.transpose().reshape.transpose().reshape.transpose"], "methods", ["None"], ["", "def", "emb2img", "(", "self", ",", "features", ",", "exp_shape", ")", ":", "\n", "\n", "        ", "for", "i", ",", "x", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "B", ",", "P", ",", "E", "=", "x", ".", "shape", "#(batch_size, latent_dim, emb_dim)", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "E", ",", "exp_shape", "[", "i", "]", "[", "2", "]", ",", "exp_shape", "[", "i", "]", "[", "3", "]", ")", "\n", "features", "[", "i", "]", "=", "x", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.DetectoRS.DetectoRS_inference.Custom_Backbone.init_weights": [[205, 207], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "      ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Encoder.__init__": [[43, 73], ["timm.models.vision_transformer.VisionTransformer.__init__", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "CMRCNN_X152_inference.Transformer_Encoder.load_weights"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__", "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.load_weights"], ["    ", "def", "__init__", "(", "self", ",", "pretrained", "=", "False", ",", "pretrained_model", "=", "None", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "hybrid_backbone", "=", "None", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "\n", "        ", "super", "(", "Transformer_Encoder", ",", "self", ")", ".", "__init__", "(", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "num_classes", "=", "1000", ",", "embed_dim", "=", "embed_dim", ",", "depth", "=", "depth", ",", "\n", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "drop_rate", "=", "drop_rate", ",", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "hybrid_backbone", "=", "hybrid_backbone", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n", "self", ".", "num_classes", "=", "1", "\n", "self", ".", "dispatcher", "=", "{", "\n", "'vit_small_patch16_224'", ":", "vit_small_patch16_224", ",", "\n", "'vit_base_patch16_224'", ":", "vit_base_patch16_224", ",", "\n", "'vit_large_patch16_224'", ":", "vit_large_patch16_224", ",", "\n", "'vit_base_patch16_384'", ":", "vit_base_patch16_384", ",", "\n", "'vit_base_patch32_384'", ":", "vit_base_patch32_384", ",", "\n", "'vit_large_patch16_384'", ":", "vit_large_patch16_384", ",", "\n", "'vit_large_patch32_384'", ":", "vit_large_patch32_384", ",", "\n", "'vit_large_patch16_224'", ":", "vit_large_patch16_224", ",", "\n", "'vit_large_patch32_384'", ":", "vit_large_patch32_384", ",", "\n", "'vit_small_resnet26d_224'", ":", "vit_small_resnet26d_224", ",", "\n", "'vit_small_resnet50d_s3_224'", ":", "vit_small_resnet50d_s3_224", ",", "\n", "'vit_base_resnet26d_224'", ":", "vit_base_resnet26d_224", ",", "\n", "'vit_base_resnet50d_224'", ":", "vit_base_resnet50d_224", ",", "\n", "}", "\n", "self", ".", "pretrained_model", "=", "pretrained_model", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "if", "pretrained", ":", "\n", "            ", "self", ".", "load_weights", "(", ")", "\n", "", "self", ".", "head", "=", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "encoder_out", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Encoder.forward_features": [[76, 96], ["CMRCNN_X152_inference.Transformer_Encoder.patch_embed", "CMRCNN_X152_inference.Transformer_Encoder.cls_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "CMRCNN_X152_inference.Transformer_Encoder.pos_drop", "enumerate", "range", "blk", "len", "CMRCNN_X152_inference.Transformer_Encoder.norm", "features.append"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "features", "=", "[", "]", "\n", "\n", "for", "i", ",", "blk", "in", "enumerate", "(", "self", ".", "blocks", ",", "1", ")", ":", "\n", "            ", "x", "=", "blk", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "encoder_out", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "            ", "features", "[", "i", "]", "=", "self", ".", "norm", "(", "features", "[", "i", "]", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Encoder.forward": [[97, 101], ["CMRCNN_X152_inference.Transformer_Encoder.forward_features"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "features", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Encoder.load_weights": [[102, 113], ["CMRCNN_X152_inference.Transformer_Encoder.load_state_dict", "print", "model.state_dict", "print"], "methods", ["None"], ["", "def", "load_weights", "(", "self", ")", ":", "\n", "        ", "model", "=", "None", "\n", "try", ":", "\n", "            ", "model", "=", "self", ".", "dispatcher", "[", "self", ".", "pretrained_model", "]", "(", "pretrained", "=", "True", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'could not not load model'", ")", "\n", "", "if", "model", "==", "None", ":", "\n", "            ", "return", "\n", "# try:", "\n", "", "self", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "print", "(", "\"successfully loaded weights!!!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Effb5.__init__": [[124, 141], ["detectron2.modeling.Backbone.__init__", "segmentation_models_pytorch.encoders.get_encoder", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "str", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__"], ["  ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "encoder_name", "=", "'timm-efficientnet-b5'", "\n", "in_channels", "=", "3", "\n", "encoder_depth", "=", "5", "\n", "encoder_weights", "=", "'noisy-student'", "\n", "self", ".", "encoder", "=", "get_encoder", "(", "encoder_name", ",", "\n", "in_channels", "=", "in_channels", ",", "\n", "depth", "=", "encoder_depth", ",", "\n", "weights", "=", "encoder_weights", ")", "\n", "self", ".", "channels", "=", "self", ".", "encoder", ".", "out_channels", "\n", "self", ".", "conv", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Conv2d", "(", "self", ".", "channels", "[", "i", "]", ",", "256", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "channels", ")", ")", "]", "\n", ")", "\n", "\n", "self", ".", "names", "=", "[", "\"p\"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "6", ")", "]", "\n", "", "def", "forward", "(", "self", ",", "image", ")", ":", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Effb5.forward": [[141, 147], ["CMRCNN_X152_inference.Effb5.encoder", "range", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "\n", "    ", "features", "=", "self", ".", "encoder", "(", "image", ")", "\n", "out", "=", "{", "self", ".", "names", "[", "i", "]", ":", "self", ".", "conv", "[", "i", "]", "(", "features", "[", "i", "]", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "features", ")", ")", "}", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Effb5.output_shape": [[148, 152], ["detectron2.modeling.ShapeSpec", "range", "len"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "    ", "out_shape", "=", "{", "self", ".", "names", "[", "i", "]", ":", "ShapeSpec", "(", "channels", "=", "256", ",", "stride", "=", "2", "**", "(", "i", "+", "1", ")", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "names", ")", ")", "}", "\n", "\n", "return", "out_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Effb5.__init__": [[159, 186], ["detectron2.modeling.Backbone.__init__", "CMRCNN_X152_inference.Transformer_Encoder", "segmentation_models_pytorch.encoders.get_encoder", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torchvision.transforms.Resize", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "str", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_dim", "=", "768", "\n", "self", ".", "pretrained", "=", "True", "\n", "self", ".", "pretrained_trans_model", "=", "'vit_base_patch16_384'", "\n", "self", ".", "patch_size", "=", "16", "\n", "\n", "self", ".", "transformer", "=", "Transformer_Encoder", "(", "pretrained", "=", "True", ",", "img_size", "=", "384", ",", "pretrained_model", "=", "self", ".", "pretrained_trans_model", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "qkv_bias", "=", "True", ")", "\n", "self", ".", "encoder_name", "=", "'timm-efficientnet-b5'", "\n", "self", ".", "in_channels", "=", "3", "\n", "self", ".", "encoder_depth", "=", "5", "\n", "self", ".", "encoder_weights", "=", "'noisy-student'", "\n", "\n", "self", ".", "conv_encoder", "=", "get_encoder", "(", "self", ".", "encoder_name", ",", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "depth", "=", "self", ".", "encoder_depth", ",", "\n", "weights", "=", "self", ".", "encoder_weights", ")", "\n", "\n", "self", ".", "conv_channels", "=", "self", ".", "conv_encoder", ".", "out_channels", "\n", "self", ".", "conv_final", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Conv2d", "(", "self", ".", "conv_channels", "[", "i", "]", ",", "self", ".", "emb_dim", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "conv_channels", ")", ")", "]", "\n", ")", "\n", "self", ".", "names", "=", "[", "\"p\"", "+", "str", "(", "i", "+", "2", ")", "for", "i", "in", "range", "(", "5", ")", "]", "\n", "self", ".", "resize", "=", "Resize", "(", "(", "384", ",", "384", ")", ")", "\n", "self", ".", "Wq", "=", "nn", ".", "Linear", "(", "self", ".", "emb_dim", ",", "self", ".", "emb_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "Wk", "=", "nn", ".", "Linear", "(", "self", ".", "emb_dim", ",", "self", ".", "emb_dim", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Effb5.forward": [[190, 221], ["CMRCNN_X152_inference.Transformer_Effb5.conv_encoder", "range", "CMRCNN_X152_inference.Transformer_Effb5.transformer", "CMRCNN_X152_inference.Transformer_Effb5.project", "CMRCNN_X152_inference.Transformer_Effb5.emb2img", "len", "CMRCNN_X152_inference.Transformer_Effb5.resize", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.project", "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.emb2img"], ["", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "\n", "      ", "conv_features", "=", "self", ".", "conv_encoder", "(", "image", ")", "\n", "# print(\"initial shape of conv features:\")", "\n", "# print([i.shape for i in conv_features])", "\n", "conv_features", "=", "conv_features", "[", "1", ":", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "conv_final", ")", ")", ":", "\n", "          ", "conv_features", "[", "i", "]", "=", "self", ".", "conv_final", "[", "i", "]", "(", "conv_features", "[", "i", "]", ")", "\n", "\n", "\n", "# print(\"final shape of conv features:\")", "\n", "", "exp_shape", "=", "[", "i", ".", "shape", "for", "i", "in", "conv_features", "]", "\n", "# print(exp_shape)", "\n", "\n", "\n", "\n", "transformer_features", "=", "self", ".", "transformer", "(", "self", ".", "resize", "(", "image", ")", ")", "\n", "# print(\"shape of transformer features:\")", "\n", "# print([i.shape for i in transformer_features])", "\n", "\n", "# _ , l, e = transformer_features[0].shape", "\n", "# _ , e, h, w = conv_features[0].shape", "\n", "\n", "features", "=", "self", ".", "project", "(", "conv_features", ",", "transformer_features", ")", "\n", "features", "=", "self", ".", "emb2img", "(", "features", ",", "exp_shape", ")", "\n", "\n", "# print(\"shape of final features:\")", "\n", "# print([i.shape for i in features])", "\n", "out", "=", "{", "self", ".", "names", "[", "i", "]", ":", "features", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", "}", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Effb5.project": [[222, 238], ["range", "len", "einops.rearrange", "CMRCNN_X152_inference.Transformer_Effb5.Wq", "CMRCNN_X152_inference.Transformer_Effb5.Wk", "einops.rearrange", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "features.append", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["None"], ["", "def", "project", "(", "self", ",", "conv_features", ",", "transformer_features", ")", ":", "\n", "\n", "        ", "features", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "conv_features", ")", ")", ":", "\n", "\n", "            ", "t", "=", "transformer_features", "[", "i", "]", "\n", "x", "=", "rearrange", "(", "conv_features", "[", "i", "]", ",", "'b c h w -> b (h w) c'", ")", "\n", "xwq", "=", "self", ".", "Wq", "(", "x", ")", "\n", "twk", "=", "self", ".", "Wk", "(", "t", ")", "\n", "twk_T", "=", "rearrange", "(", "twk", ",", "'b l c -> b c l'", ")", "\n", "A", "=", "torch", ".", "einsum", "(", "'bij,bjk->bik'", ",", "xwq", ",", "twk_T", ")", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "x", "+=", "torch", ".", "einsum", "(", "'bij,bjk->bik'", ",", "A", ",", "t", ")", "\n", "features", ".", "append", "(", "x", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Effb5.emb2img": [[239, 247], ["enumerate", "x.transpose().reshape.transpose().reshape.transpose().reshape", "x.transpose().reshape.transpose().reshape.transpose"], "methods", ["None"], ["", "def", "emb2img", "(", "self", ",", "features", ",", "exp_shape", ")", ":", "\n", "\n", "        ", "for", "i", ",", "x", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "B", ",", "P", ",", "E", "=", "x", ".", "shape", "#(batch_size, latent_dim, emb_dim)", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "E", ",", "exp_shape", "[", "i", "]", "[", "2", "]", ",", "exp_shape", "[", "i", "]", "[", "3", "]", ")", "\n", "features", "[", "i", "]", "=", "x", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_inference.Transformer_Effb5.output_shape": [[248, 252], ["detectron2.modeling.ShapeSpec", "range", "len"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "      ", "out_shape", "=", "{", "self", ".", "names", "[", "i", "]", ":", "ShapeSpec", "(", "channels", "=", "768", ",", "stride", "=", "2", "**", "(", "i", "+", "2", ")", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "names", ")", ")", "}", "\n", "\n", "return", "out_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.__init__": [[60, 90], ["timm.models.vision_transformer.VisionTransformer.__init__", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "CMRCNN_X152_train.Transformer_Encoder.load_weights"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__", "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.load_weights"], ["    ", "def", "__init__", "(", "self", ",", "pretrained", "=", "False", ",", "pretrained_model", "=", "None", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "1", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "hybrid_backbone", "=", "None", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "\n", "        ", "super", "(", "Transformer_Encoder", ",", "self", ")", ".", "__init__", "(", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "num_classes", "=", "1000", ",", "embed_dim", "=", "embed_dim", ",", "depth", "=", "depth", ",", "\n", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "drop_rate", "=", "drop_rate", ",", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "hybrid_backbone", "=", "hybrid_backbone", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n", "self", ".", "num_classes", "=", "1", "\n", "self", ".", "dispatcher", "=", "{", "\n", "'vit_small_patch16_224'", ":", "vit_small_patch16_224", ",", "\n", "'vit_base_patch16_224'", ":", "vit_base_patch16_224", ",", "\n", "'vit_large_patch16_224'", ":", "vit_large_patch16_224", ",", "\n", "'vit_base_patch16_384'", ":", "vit_base_patch16_384", ",", "\n", "'vit_base_patch32_384'", ":", "vit_base_patch32_384", ",", "\n", "'vit_large_patch16_384'", ":", "vit_large_patch16_384", ",", "\n", "'vit_large_patch32_384'", ":", "vit_large_patch32_384", ",", "\n", "'vit_large_patch16_224'", ":", "vit_large_patch16_224", ",", "\n", "'vit_large_patch32_384'", ":", "vit_large_patch32_384", ",", "\n", "'vit_small_resnet26d_224'", ":", "vit_small_resnet26d_224", ",", "\n", "'vit_small_resnet50d_s3_224'", ":", "vit_small_resnet50d_s3_224", ",", "\n", "'vit_base_resnet26d_224'", ":", "vit_base_resnet26d_224", ",", "\n", "'vit_base_resnet50d_224'", ":", "vit_base_resnet50d_224", ",", "\n", "}", "\n", "self", ".", "pretrained_model", "=", "pretrained_model", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "if", "pretrained", ":", "\n", "            ", "self", ".", "load_weights", "(", ")", "\n", "", "self", ".", "head", "=", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "encoder_out", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.forward_features": [[93, 113], ["CMRCNN_X152_train.Transformer_Encoder.patch_embed", "CMRCNN_X152_train.Transformer_Encoder.cls_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "CMRCNN_X152_train.Transformer_Encoder.pos_drop", "enumerate", "range", "blk", "len", "CMRCNN_X152_train.Transformer_Encoder.norm", "features.append"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "features", "=", "[", "]", "\n", "\n", "for", "i", ",", "blk", "in", "enumerate", "(", "self", ".", "blocks", ",", "1", ")", ":", "\n", "            ", "x", "=", "blk", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "encoder_out", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "            ", "features", "[", "i", "]", "=", "self", ".", "norm", "(", "features", "[", "i", "]", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.forward": [[114, 118], ["CMRCNN_X152_train.Transformer_Encoder.forward_features"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "features", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Encoder.load_weights": [[119, 130], ["CMRCNN_X152_train.Transformer_Encoder.load_state_dict", "print", "model.state_dict", "print"], "methods", ["None"], ["", "def", "load_weights", "(", "self", ")", ":", "\n", "        ", "model", "=", "None", "\n", "try", ":", "\n", "            ", "model", "=", "self", ".", "dispatcher", "[", "self", ".", "pretrained_model", "]", "(", "pretrained", "=", "True", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'could not not load model'", ")", "\n", "", "if", "model", "==", "None", ":", "\n", "            ", "return", "\n", "# try:", "\n", "", "self", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "print", "(", "\"successfully loaded weights!!!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Effb5.__init__": [[141, 158], ["detectron2.modeling.Backbone.__init__", "segmentation_models_pytorch.encoders.get_encoder", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "str", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__"], ["  ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "encoder_name", "=", "'timm-efficientnet-b5'", "\n", "in_channels", "=", "3", "\n", "encoder_depth", "=", "5", "\n", "encoder_weights", "=", "'noisy-student'", "\n", "self", ".", "encoder", "=", "get_encoder", "(", "encoder_name", ",", "\n", "in_channels", "=", "in_channels", ",", "\n", "depth", "=", "encoder_depth", ",", "\n", "weights", "=", "encoder_weights", ")", "\n", "self", ".", "channels", "=", "self", ".", "encoder", ".", "out_channels", "\n", "self", ".", "conv", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Conv2d", "(", "self", ".", "channels", "[", "i", "]", ",", "256", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "channels", ")", ")", "]", "\n", ")", "\n", "\n", "self", ".", "names", "=", "[", "\"p\"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "6", ")", "]", "\n", "", "def", "forward", "(", "self", ",", "image", ")", ":", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Effb5.forward": [[158, 164], ["CMRCNN_X152_train.Effb5.encoder", "range", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "\n", "    ", "features", "=", "self", ".", "encoder", "(", "image", ")", "\n", "out", "=", "{", "self", ".", "names", "[", "i", "]", ":", "self", ".", "conv", "[", "i", "]", "(", "features", "[", "i", "]", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "features", ")", ")", "}", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Effb5.output_shape": [[165, 169], ["detectron2.modeling.ShapeSpec", "range", "len"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "    ", "out_shape", "=", "{", "self", ".", "names", "[", "i", "]", ":", "ShapeSpec", "(", "channels", "=", "256", ",", "stride", "=", "2", "**", "(", "i", "+", "1", ")", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "names", ")", ")", "}", "\n", "\n", "return", "out_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__": [[176, 203], ["detectron2.modeling.Backbone.__init__", "CMRCNN_X152_train.Transformer_Encoder", "segmentation_models_pytorch.encoders.get_encoder", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torchvision.transforms.Resize", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "str", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_dim", "=", "768", "\n", "self", ".", "pretrained", "=", "True", "\n", "self", ".", "pretrained_trans_model", "=", "'vit_base_patch16_384'", "\n", "self", ".", "patch_size", "=", "16", "\n", "\n", "self", ".", "transformer", "=", "Transformer_Encoder", "(", "pretrained", "=", "True", ",", "img_size", "=", "384", ",", "pretrained_model", "=", "self", ".", "pretrained_trans_model", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "qkv_bias", "=", "True", ")", "\n", "self", ".", "encoder_name", "=", "'timm-efficientnet-b5'", "\n", "self", ".", "in_channels", "=", "3", "\n", "self", ".", "encoder_depth", "=", "5", "\n", "self", ".", "encoder_weights", "=", "'noisy-student'", "\n", "\n", "self", ".", "conv_encoder", "=", "get_encoder", "(", "self", ".", "encoder_name", ",", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "depth", "=", "self", ".", "encoder_depth", ",", "\n", "weights", "=", "self", ".", "encoder_weights", ")", "\n", "\n", "self", ".", "conv_channels", "=", "self", ".", "conv_encoder", ".", "out_channels", "\n", "self", ".", "conv_final", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Conv2d", "(", "self", ".", "conv_channels", "[", "i", "]", ",", "self", ".", "emb_dim", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "conv_channels", ")", ")", "]", "\n", ")", "\n", "self", ".", "names", "=", "[", "\"p\"", "+", "str", "(", "i", "+", "2", ")", "for", "i", "in", "range", "(", "5", ")", "]", "\n", "self", ".", "resize", "=", "Resize", "(", "(", "384", ",", "384", ")", ")", "\n", "self", ".", "Wq", "=", "nn", ".", "Linear", "(", "self", ".", "emb_dim", ",", "self", ".", "emb_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "Wk", "=", "nn", ".", "Linear", "(", "self", ".", "emb_dim", ",", "self", ".", "emb_dim", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.forward": [[207, 238], ["CMRCNN_X152_train.Transformer_Effb5.conv_encoder", "range", "CMRCNN_X152_train.Transformer_Effb5.transformer", "CMRCNN_X152_train.Transformer_Effb5.project", "CMRCNN_X152_train.Transformer_Effb5.emb2img", "len", "CMRCNN_X152_train.Transformer_Effb5.resize", "range", "len"], "methods", ["home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.project", "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.emb2img"], ["", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "\n", "      ", "conv_features", "=", "self", ".", "conv_encoder", "(", "image", ")", "\n", "# print(\"initial shape of conv features:\")", "\n", "# print([i.shape for i in conv_features])", "\n", "conv_features", "=", "conv_features", "[", "1", ":", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "conv_final", ")", ")", ":", "\n", "          ", "conv_features", "[", "i", "]", "=", "self", ".", "conv_final", "[", "i", "]", "(", "conv_features", "[", "i", "]", ")", "\n", "\n", "\n", "# print(\"final shape of conv features:\")", "\n", "", "exp_shape", "=", "[", "i", ".", "shape", "for", "i", "in", "conv_features", "]", "\n", "# print(exp_shape)", "\n", "\n", "\n", "\n", "transformer_features", "=", "self", ".", "transformer", "(", "self", ".", "resize", "(", "image", ")", ")", "\n", "# print(\"shape of transformer features:\")", "\n", "# print([i.shape for i in transformer_features])", "\n", "\n", "# _ , l, e = transformer_features[0].shape", "\n", "# _ , e, h, w = conv_features[0].shape", "\n", "\n", "features", "=", "self", ".", "project", "(", "conv_features", ",", "transformer_features", ")", "\n", "features", "=", "self", ".", "emb2img", "(", "features", ",", "exp_shape", ")", "\n", "\n", "# print(\"shape of final features:\")", "\n", "# print([i.shape for i in features])", "\n", "out", "=", "{", "self", ".", "names", "[", "i", "]", ":", "features", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", "}", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.project": [[239, 255], ["range", "len", "einops.rearrange", "CMRCNN_X152_train.Transformer_Effb5.Wq", "CMRCNN_X152_train.Transformer_Effb5.Wk", "einops.rearrange", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum().softmax", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "features.append", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["None"], ["", "def", "project", "(", "self", ",", "conv_features", ",", "transformer_features", ")", ":", "\n", "\n", "        ", "features", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "conv_features", ")", ")", ":", "\n", "\n", "            ", "t", "=", "transformer_features", "[", "i", "]", "\n", "x", "=", "rearrange", "(", "conv_features", "[", "i", "]", ",", "'b c h w -> b (h w) c'", ")", "\n", "xwq", "=", "self", ".", "Wq", "(", "x", ")", "\n", "twk", "=", "self", ".", "Wk", "(", "t", ")", "\n", "twk_T", "=", "rearrange", "(", "twk", ",", "'b l c -> b c l'", ")", "\n", "A", "=", "torch", ".", "einsum", "(", "'bij,bjk->bik'", ",", "xwq", ",", "twk_T", ")", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "x", "+=", "torch", ".", "einsum", "(", "'bij,bjk->bik'", ",", "A", ",", "t", ")", "\n", "features", ".", "append", "(", "x", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.emb2img": [[256, 264], ["enumerate", "x.transpose().reshape.transpose().reshape.transpose().reshape", "x.transpose().reshape.transpose().reshape.transpose"], "methods", ["None"], ["", "def", "emb2img", "(", "self", ",", "features", ",", "exp_shape", ")", ":", "\n", "\n", "        ", "for", "i", ",", "x", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "B", ",", "P", ",", "E", "=", "x", ".", "shape", "#(batch_size, latent_dim, emb_dim)", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "E", ",", "exp_shape", "[", "i", "]", "[", "2", "]", ",", "exp_shape", "[", "i", "]", "[", "3", "]", ")", "\n", "features", "[", "i", "]", "=", "x", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.Transformer_Effb5.output_shape": [[265, 269], ["detectron2.modeling.ShapeSpec", "range", "len"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "      ", "out_shape", "=", "{", "self", ".", "names", "[", "i", "]", ":", "ShapeSpec", "(", "channels", "=", "768", ",", "stride", "=", "2", "**", "(", "i", "+", "2", ")", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "names", ")", ")", "}", "\n", "\n", "return", "out_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.dsciitism_segpc-2021.Cascade_Mask_RCNN_X152.CMRCNN_X152_train.CocoTrainer.build_evaluator": [[306, 314], ["detectron2.evaluation.COCOEvaluator", "os.makedirs"], "methods", ["None"], ["  ", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "\n", "    ", "if", "output_folder", "is", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "\"coco_eval\"", ",", "exist_ok", "=", "True", ")", "\n", "output_folder", "=", "\"coco_eval\"", "\n", "\n", "", "return", "COCOEvaluator", "(", "dataset_name", ",", "cfg", ",", "False", ",", "output_folder", ")", "\n", "\n"]]}