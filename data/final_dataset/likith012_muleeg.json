{"home.repos.pwc.inspect_result.likith012_muleeg.None.config.Config.__init__": [[13, 45], ["os.path.join", "os.getcwd", "torch.cuda.is_available"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "wandb", "=", "None", ")", "->", "None", ":", "\n", "\n", "# path", "\n", "        ", "self", ".", "src_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"data\"", ")", "\n", "self", ".", "wandb", "=", "wandb", "\n", "\n", "# augmentation", "\n", "self", ".", "degree", "=", "0.05", "\n", "self", ".", "mask_max_points", "=", "200", "\n", "self", ".", "mask_min_points", "=", "50", "\n", "\n", "# time domain", "\n", "self", ".", "tc_hidden_dim", "=", "128", "\n", "self", ".", "input_channels", "=", "1", "\n", "\n", "# loss", "\n", "self", ".", "temperature", "=", "1", "\n", "self", ".", "intra_temperature", "=", "10", "\n", "self", ".", "use_cosine_similarity", "=", "True", "\n", "\n", "# optimizer", "\n", "self", ".", "optimizer", "=", "\"adam\"", "\n", "self", ".", "beta1", "=", "0.9", "\n", "self", ".", "beta2", "=", "0.99", "\n", "self", ".", "lr", "=", "0.0003", "\n", "\n", "# training and evaluation", "\n", "self", ".", "num_epoch", "=", "200", "\n", "self", ".", "batch_size", "=", "256", "\n", "self", ".", "num_ft_epoch", "=", "100", "\n", "self", ".", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "self", ".", "drop_last", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.__init__": [[15, 43], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "models.model.contrast_loss", "helper_train.sleep_pretrain.model.to", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "helper_train.sleep_pretrain.model.parameters", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "name", ",", "dataloader", ",", "wandb_logger", ")", ":", "\n", "        ", "super", "(", "sleep_pretrain", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "model", "=", "contrast_loss", "(", "config", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "weight_decay", "=", "3e-5", "\n", "self", ".", "batch_size", "=", "config", ".", "batch_size", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "dataloader", "=", "dataloader", "\n", "self", ".", "loggr", "=", "wandb_logger", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "self", ".", "config", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "config", ".", "beta1", ",", "self", ".", "config", ".", "beta2", ")", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ",", "\n", ")", "\n", "self", ".", "scheduler", "=", "ReduceLROnPlateau", "(", "\n", "self", ".", "optimizer", ",", "mode", "=", "\"min\"", ",", "patience", "=", "5", ",", "factor", "=", "0.2", "\n", ")", "\n", "self", ".", "epochs", "=", "config", ".", "num_epoch", "\n", "self", ".", "ft_epochs", "=", "config", ".", "num_ft_epoch", "\n", "\n", "self", ".", "max_f1", "=", "0", "\n", "self", ".", "max_mean_f1", "=", "0", "\n", "self", ".", "max_kappa", "=", "0", "\n", "self", ".", "max_bal_acc", "=", "0", "\n", "self", ".", "max_acc", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.training_step": [[44, 49], ["helper_train.sleep_pretrain.model", "weak.to", "strong.to"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "weak", ",", "strong", "=", "batch", "\n", "weak", ",", "strong", "=", "weak", ".", "to", "(", "self", ".", "device", ")", ",", "strong", ".", "to", "(", "self", ".", "device", ")", "\n", "loss", "=", "self", ".", "model", "(", "weak", ",", "strong", ",", "self", ".", "current_epoch", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.training_epoch_end": [[50, 75], ["torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "helper_train.sleep_pretrain.loggr.log", "helper_train.sleep_pretrain.scheduler.step", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "training_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "epoch_loss", "=", "torch", ".", "hstack", "(", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "outputs", "[", "\"loss\"", "]", "]", ")", ".", "mean", "(", ")", "\n", "time_loss", "=", "torch", ".", "hstack", "(", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "outputs", "[", "\"time_loss\"", "]", "]", ")", ".", "mean", "(", ")", "\n", "fusion_loss", "=", "torch", ".", "hstack", "(", "\n", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "outputs", "[", "\"fusion_loss\"", "]", "]", "\n", ")", ".", "mean", "(", ")", "\n", "spect_loss", "=", "torch", ".", "hstack", "(", "\n", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "outputs", "[", "\"spect_loss\"", "]", "]", "\n", ")", ".", "mean", "(", ")", "\n", "intra_loss", "=", "torch", ".", "hstack", "(", "\n", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "outputs", "[", "\"intra_loss\"", "]", "]", "\n", ")", ".", "mean", "(", ")", "\n", "self", ".", "loggr", ".", "log", "(", "\n", "{", "\n", "\"Epoch Loss\"", ":", "epoch_loss", ",", "\n", "\"Fusion Loss\"", ":", "fusion_loss", ",", "\n", "\"Time Loss\"", ":", "time_loss", ",", "\n", "\"Spect Loss\"", ":", "spect_loss", ",", "\n", "\"Intra Loss\"", ":", "intra_loss", ",", "\n", "\"LR\"", ":", "self", ".", "scheduler", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "\n", "\"Epoch\"", ":", "self", ".", "current_epoch", ",", "\n", "}", "\n", ")", "\n", "self", ".", "scheduler", ".", "step", "(", "epoch_loss", ")", "\n", "return", "epoch_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.on_epoch_end": [[76, 88], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "helper_train.sleep_pretrain.model.model.eeg_encoder.state_dict", "os.path.join", "helper_train.sleep_pretrain.model.state_dict", "os.path.join"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ")", ":", "\n", "        ", "chkpoint", "=", "{", "\"eeg_model_state_dict\"", ":", "self", ".", "model", ".", "model", ".", "eeg_encoder", ".", "state_dict", "(", ")", "}", "\n", "torch", ".", "save", "(", "chkpoint", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config", ".", "exp_path", ",", "self", ".", "name", "+", "\".pt\"", ")", ")", "\n", "full_chkpoint", "=", "{", "\n", "\"model_state_dict\"", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "\"epoch\"", ":", "self", ".", "current_epoch", ",", "\n", "}", "\n", "torch", ".", "save", "(", "\n", "full_chkpoint", ",", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "config", ".", "exp_path", ",", "self", ".", "name", "+", "\"_full\"", "+", "\".pt\"", ")", ",", "\n", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.ft_fun": [[89, 105], ["utils.dataloader.cross_data_generator", "helper_train.sleep_ft", "helper_train.sleep_ft.fit"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.utils.dataloader.cross_data_generator", "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.fit"], ["", "def", "ft_fun", "(", "self", ",", "file_name", ",", "epoch", ",", "train_idx", ",", "val_idx", ",", "split", ")", ":", "\n", "        ", "src_path", "=", "self", ".", "config", ".", "src_path", "\n", "train_dl", ",", "valid_dl", "=", "cross_data_generator", "(", "\n", "src_path", ",", "train_idx", ",", "val_idx", ",", "self", ".", "config", "\n", ")", "\n", "sleep_eval", "=", "sleep_ft", "(", "\n", "self", ".", "config", ".", "exp_path", "+", "\"/\"", "+", "self", ".", "name", "+", "\".pt\"", ",", "\n", "self", ".", "config", ",", "\n", "train_dl", ",", "\n", "valid_dl", ",", "\n", "epoch", ",", "\n", "self", ".", "loggr", ",", "\n", ")", "\n", "f1", ",", "mean_f1", ",", "kappa", ",", "bal_acc", ",", "acc", "=", "sleep_eval", ".", "fit", "(", ")", "\n", "\n", "return", "f1", ",", "mean_f1", ",", "kappa", ",", "bal_acc", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.do_kfold": [[106, 123], ["utils.dataloader.cross_data_generator", "sklearn.model_selection.KFold", "numpy.arange", "enumerate", "sklearn.model_selection.KFold.split", "print", "helper_train.sleep_pretrain.ft_fun"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.utils.dataloader.cross_data_generator", "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.ft_fun"], ["", "def", "do_kfold", "(", "self", ")", ":", "\n", "        ", "n", "=", "cross_data_generator", "(", "self", ".", "config", ".", "src_path", ",", "[", "]", ",", "[", "]", ",", "self", ".", "config", ")", "\n", "kfold", "=", "KFold", "(", "n_splits", "=", "5", ",", "shuffle", "=", "False", ")", "\n", "idxs", "=", "np", ".", "arange", "(", "0", ",", "n", ",", "1", ")", "\n", "k_f1", ",", "k_mean_f1", ",", "k_kappa", ",", "k_bal_acc", ",", "k_acc", "=", "0", ",", "0", ",", "0", ",", "0", ",", "0", "\n", "for", "split", ",", "(", "train_idx", ",", "val_idx", ")", "in", "enumerate", "(", "kfold", ".", "split", "(", "idxs", ")", ")", ":", "\n", "            ", "print", "(", "f\"Split {split}\"", ")", "\n", "f1", ",", "mean_f1", ",", "kappa", ",", "bal_acc", ",", "acc", "=", "self", ".", "ft_fun", "(", "\n", "self", ".", "name", ",", "0", ",", "train_idx", ",", "val_idx", ",", "split", "\n", ")", "\n", "k_f1", "+=", "f1", "\n", "k_mean_f1", "+=", "mean_f1", "\n", "k_kappa", "+=", "kappa", "\n", "k_bal_acc", "+=", "bal_acc", "\n", "k_acc", "+=", "acc", "\n", "\n", "", "return", "k_f1", "/", "5", ",", "k_mean_f1", "/", "5", ",", "k_kappa", "/", "5", ",", "k_bal_acc", "/", "5", ",", "k_acc", "/", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.fit": [[124, 199], ["range", "helper_train.sleep_pretrain.model.train", "enumerate", "print", "helper_train.sleep_pretrain.training_epoch_end", "helper_train.sleep_pretrain.on_epoch_end", "helper_train.sleep_pretrain.training_step", "outputs[].append", "outputs[].append", "outputs[].append", "outputs[].append", "outputs[].append", "helper_train.sleep_pretrain.optimizer.zero_grad", "loss.backward", "helper_train.sleep_pretrain.optimizer.step", "helper_train.sleep_pretrain.do_kfold", "helper_train.sleep_pretrain.loggr.log", "loss.item", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "loss.item", "helper_train.sleep_pretrain.model.model.eeg_encoder.state_dict", "os.path.join", "helper_train.sleep_pretrain.model.model.eeg_encoder.state_dict", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.training_epoch_end", "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.on_epoch_end", "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.training_step", "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_pretrain.do_kfold"], ["", "def", "fit", "(", "self", ")", ":", "\n", "\n", "        ", "epoch_loss", "=", "0", "\n", "for", "epoch", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "\n", "            ", "self", ".", "current_epoch", "=", "epoch", "\n", "outputs", "=", "{", "\n", "\"loss\"", ":", "[", "]", ",", "\n", "\"time_loss\"", ":", "[", "]", ",", "\n", "\"fusion_loss\"", ":", "[", "]", ",", "\n", "\"spect_loss\"", ":", "[", "]", ",", "\n", "\"intra_loss\"", ":", "[", "]", ",", "\n", "}", "\n", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "batch_idx", ",", "batch", "in", "enumerate", "(", "self", ".", "dataloader", ")", ":", "\n", "                ", "(", "\n", "loss", ",", "\n", "time_loss", ",", "\n", "fusion_loss", ",", "\n", "spect_loss", ",", "\n", "intra_loss", ",", "\n", ")", "=", "self", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "outputs", "[", "\"loss\"", "]", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "outputs", "[", "\"fusion_loss\"", "]", ".", "append", "(", "fusion_loss", ")", "\n", "outputs", "[", "\"time_loss\"", "]", ".", "append", "(", "time_loss", ")", "\n", "outputs", "[", "\"spect_loss\"", "]", ".", "append", "(", "spect_loss", ")", "\n", "outputs", "[", "\"intra_loss\"", "]", ".", "append", "(", "intra_loss", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "print", "(", "\n", "f\"Pretrain Epoch {epoch}: Prev.Epoch Loss {epoch_loss:.6g} Pretrain Batch Loss:{loss.item():.6g}\"", "\n", ")", "\n", "epoch_loss", "=", "self", ".", "training_epoch_end", "(", "outputs", ")", "\n", "self", ".", "on_epoch_end", "(", ")", "\n", "\n", "# evaluation step", "\n", "if", "(", "epoch", "%", "4", "==", "0", ")", "and", "(", "epoch", ">=", "80", ")", ":", "\n", "                ", "f1", ",", "mean_f1", ",", "kappa", ",", "bal_acc", ",", "acc", "=", "self", ".", "do_kfold", "(", ")", "\n", "\n", "if", "self", ".", "max_f1", "<", "f1", ":", "\n", "                    ", "chkpoint", "=", "{", "\n", "\"eeg_model_state_dict\"", ":", "self", ".", "model", ".", "model", ".", "eeg_encoder", ".", "state_dict", "(", ")", ",", "\n", "\"best_pretrain_epoch\"", ":", "epoch", ",", "\n", "}", "\n", "torch", ".", "save", "(", "\n", "chkpoint", ",", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "config", ".", "exp_path", ",", "self", ".", "name", "+", "\"_best.pt\"", ")", ",", "\n", ")", "\n", "self", ".", "max_f1", ",", "self", ".", "max_kappa", ",", "self", ".", "max_bal_acc", ",", "self", ".", "max_acc", "=", "(", "\n", "f1", ",", "\n", "kappa", ",", "\n", "bal_acc", ",", "\n", "acc", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "max_mean_f1", "<", "mean_f1", ":", "\n", "                    ", "chkpoint", "=", "{", "\n", "\"eeg_model_state_dict\"", ":", "self", ".", "model", ".", "model", ".", "eeg_encoder", ".", "state_dict", "(", ")", ",", "\n", "\"best_pretrain_epoch\"", ":", "epoch", ",", "\n", "}", "\n", "torch", ".", "save", "(", "\n", "chkpoint", ",", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "config", ".", "exp_path", ",", "self", ".", "name", "+", "\"_mean_best.pt\"", ")", ",", "\n", ")", "\n", "self", ".", "max_mean_f1", "=", "mean_f1", "\n", "", "self", ".", "loggr", ".", "log", "(", "\n", "{", "\n", "\"F1\"", ":", "f1", ",", "\n", "\"Mean-F1\"", ":", "mean_f1", ",", "\n", "\"Kappa\"", ":", "kappa", ",", "\n", "\"Bal Acc\"", ":", "bal_acc", ",", "\n", "\"Acc\"", ":", "acc", ",", "\n", "\"Epoch\"", ":", "epoch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.__init__": [[204, 234], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "models.model.ft_loss().to", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "helper_train.sleep_ft.model.parameters", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "models.model.ft_loss"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "chkpoint_pth", ",", "config", ",", "train_dl", ",", "valid_dl", ",", "pret_epoch", ",", "wandb_logger", "\n", ")", ":", "\n", "        ", "super", "(", "sleep_ft", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "model", "=", "ft_loss", "(", "chkpoint_pth", ",", "config", ",", "self", ".", "device", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "beta1", "=", "config", ".", "beta1", "\n", "self", ".", "beta2", "=", "config", ".", "beta2", "\n", "self", ".", "weight_decay", "=", "3e-5", "\n", "self", ".", "batch_size", "=", "config", ".", "batch_size", "\n", "self", ".", "loggr", "=", "wandb_logger", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "train_ft_dl", "=", "train_dl", "\n", "self", ".", "valid_ft_dl", "=", "valid_dl", "\n", "self", ".", "pret_epoch", "=", "pret_epoch", "\n", "self", ".", "max_f1", "=", "torch", ".", "tensor", "(", "0", ")", "\n", "\n", "self", ".", "mean_f1", "=", "[", "]", "\n", "\n", "self", ".", "max_acc", "=", "torch", ".", "tensor", "(", "0", ")", "\n", "self", ".", "max_bal_acc", "=", "torch", ".", "tensor", "(", "0", ")", "\n", "self", ".", "max_kappa", "=", "torch", ".", "tensor", "(", "0", ")", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "self", ".", "config", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "config", ".", "beta1", ",", "self", ".", "config", ".", "beta2", ")", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ",", "\n", ")", "\n", "self", ".", "ft_epoch", "=", "config", ".", "num_ft_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.train_dataloader": [[235, 237], ["None"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "train_dl", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.val_dataloader": [[238, 240], ["None"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "valid_dl", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.training_step": [[241, 247], ["helper_train.sleep_ft.model", "helper_train.sleep_ft.criterion", "data.to", "y.to"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "data", ",", "y", "=", "batch", "\n", "data", ",", "y", "=", "data", ".", "to", "(", "self", ".", "device", ")", ",", "y", ".", "to", "(", "self", ".", "device", ")", "\n", "outs", "=", "self", ".", "model", "(", "data", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "outs", ",", "y", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.validation_step": [[248, 255], ["helper_train.sleep_ft.model", "helper_train.sleep_ft.criterion", "torchmetrics.functional.accuracy", "data.to", "y.to", "helper_train.sleep_ft.detach", "y.detach"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "data", ",", "y", "=", "batch", "\n", "data", ",", "y", "=", "data", ".", "to", "(", "self", ".", "device", ")", ",", "y", ".", "to", "(", "self", ".", "device", ")", "\n", "outs", "=", "self", ".", "model", "(", "data", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "outs", ",", "y", ")", "\n", "acc", "=", "accuracy", "(", "outs", ",", "y", ")", "\n", "return", "{", "\"loss\"", ":", "loss", ",", "\"acc\"", ":", "acc", ",", "\"preds\"", ":", "outs", ".", "detach", "(", ")", ",", "\"target\"", ":", "y", ".", "detach", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.validation_epoch_end": [[256, 284], ["torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.hstack().mean", "torch.vstack.cpu().detach().argmax", "torch.vstack.cpu().detach().argmax", "torchmetrics.functional.f1", "torchmetrics.functional.cohen_kappa", "sklearn.metrics.balanced_accuracy_score", "helper_train.sleep_ft.mean_f1.append", "torch.hstack.cpu().numpy", "torch.hstack.cpu().numpy", "torch.vstack.cpu().detach().argmax.cpu().numpy", "sklearn.metrics.ConfusionMatrixDisplay.from_predictions", "helper_train.sleep_ft.loggr.log", "plt.close", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.vstack.cpu().detach", "torch.vstack.cpu().detach", "torch.hstack.cpu", "torch.hstack.cpu", "torch.vstack.cpu().detach().argmax.cpu", "torch.hstack.cpu", "torch.hstack.cpu", "torch.vstack.cpu().detach().argmax.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.vstack.cpu", "torch.vstack.cpu"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "\n", "        ", "epoch_preds", "=", "torch", ".", "vstack", "(", "[", "x", "for", "x", "in", "outputs", "[", "\"preds\"", "]", "]", ")", "\n", "epoch_targets", "=", "torch", ".", "hstack", "(", "[", "x", "for", "x", "in", "outputs", "[", "\"target\"", "]", "]", ")", "\n", "# epoch_loss = torch.hstack([x['loss'] for x in outputs]).mean()", "\n", "epoch_acc", "=", "torch", ".", "hstack", "(", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "outputs", "[", "\"acc\"", "]", "]", ")", ".", "mean", "(", ")", "\n", "class_preds", "=", "epoch_preds", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "f1_sc", "=", "f1", "(", "epoch_preds", ",", "epoch_targets", ",", "average", "=", "\"macro\"", ",", "num_classes", "=", "5", ")", "\n", "kappa", "=", "cohen_kappa", "(", "epoch_preds", ",", "epoch_targets", ",", "num_classes", "=", "5", ")", "\n", "bal_acc", "=", "balanced_accuracy_score", "(", "\n", "epoch_targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "class_preds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "\n", "self", ".", "mean_f1", ".", "append", "(", "f1_sc", ")", "\n", "\n", "if", "f1_sc", ">", "self", ".", "max_f1", ":", "\n", "            ", "ConfusionMatrixDisplay", ".", "from_predictions", "(", "\n", "epoch_targets", ".", "cpu", "(", ")", ",", "class_preds", ".", "cpu", "(", ")", "\n", ")", "\n", "# self.loggr.log({'Pretrain Epoch' : self.loggr.plot.confusion_matrix(probs=None,title=f'Pretrain Epoch :{self.pret_epoch+1}',", "\n", "#            y_true= epoch_targets.cpu().numpy(), preds= class_preds.numpy(),", "\n", "#            class_names= ['Wake', 'N1', 'N2', 'N3', 'REM'])})", "\n", "self", ".", "max_f1", "=", "f1_sc", "\n", "self", ".", "max_kappa", "=", "kappa", "\n", "self", ".", "max_bal_acc", "=", "bal_acc", "\n", "self", ".", "max_acc", "=", "epoch_acc", "\n", "self", ".", "loggr", ".", "log", "(", "{", "f\"Pretrain Epoch: Valid Confusion Matrix\"", ":", "plt", "}", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.on_train_end": [[287, 290], ["sum", "len"], "methods", ["None"], ["", "", "def", "on_train_end", "(", "self", ")", ":", "\n", "        ", "self", ".", "mean_f1", "=", "sum", "(", "self", ".", "mean_f1", ")", "/", "len", "(", "self", ".", "mean_f1", ")", "\n", "return", "self", ".", "max_f1", ",", "self", ".", "mean_f1", ",", "self", ".", "max_kappa", ",", "self", ".", "max_bal_acc", ",", "self", ".", "max_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.fit": [[291, 331], ["range", "helper_train.sleep_ft.on_train_end", "helper_train.sleep_ft.model.train", "enumerate", "helper_train.sleep_ft.model.eval", "helper_train.sleep_ft.training_step", "helper_train.sleep_ft.optimizer.zero_grad", "helper_train.sleep_ft.backward", "helper_train.sleep_ft.optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "helper_train.sleep_ft.validation_epoch_end", "print", "helper_train.sleep_ft.validation_step", "ft_outputs[].append", "ft_outputs[].append", "ft_outputs[].append", "ft_outputs[].append", "helper_train.sleep_ft.item", "acc.item", "helper_train.sleep_ft.max_f1.item", "helper_train.sleep_ft.max_kappa.item", "helper_train.sleep_ft.max_bal_acc.item", "helper_train.sleep_ft.max_acc.item"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.on_train_end", "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.training_step", "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.validation_epoch_end", "home.repos.pwc.inspect_result.likith012_muleeg.None.helper_train.sleep_ft.validation_step"], ["", "def", "fit", "(", "self", ")", ":", "\n", "\n", "        ", "for", "ft_epoch", "in", "range", "(", "self", ".", "ft_epoch", ")", ":", "\n", "\n", "# Training Loop", "\n", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "ft_outputs", "=", "{", "\"loss\"", ":", "[", "]", ",", "\"acc\"", ":", "[", "]", ",", "\"preds\"", ":", "[", "]", ",", "\"target\"", ":", "[", "]", "}", "\n", "for", "ft_batch_idx", ",", "ft_batch", "in", "enumerate", "(", "self", ".", "train_ft_dl", ")", ":", "\n", "\n", "                ", "loss", "=", "self", ".", "training_step", "(", "ft_batch", ",", "ft_batch_idx", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Validation Loop", "\n", "\n", "", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "ft_batch_idx", ",", "ft_batch", "in", "enumerate", "(", "self", ".", "valid_ft_dl", ")", ":", "\n", "                    ", "dct", "=", "self", ".", "validation_step", "(", "ft_batch", ",", "ft_batch_idx", ")", "\n", "loss", ",", "acc", ",", "preds", ",", "target", "=", "(", "\n", "dct", "[", "\"loss\"", "]", ",", "\n", "dct", "[", "\"acc\"", "]", ",", "\n", "dct", "[", "\"preds\"", "]", ",", "\n", "dct", "[", "\"target\"", "]", ",", "\n", ")", "\n", "ft_outputs", "[", "\"loss\"", "]", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "ft_outputs", "[", "\"acc\"", "]", ".", "append", "(", "acc", ".", "item", "(", ")", ")", "\n", "ft_outputs", "[", "\"preds\"", "]", ".", "append", "(", "preds", ")", "\n", "ft_outputs", "[", "\"target\"", "]", ".", "append", "(", "target", ")", "\n", "\n", "", "self", ".", "validation_epoch_end", "(", "ft_outputs", ")", "\n", "print", "(", "\n", "f\"FT Epoch: {ft_epoch} F1: {self.max_f1.item():.4g} Kappa: {self.max_kappa.item():.4g} B.Acc: {self.max_bal_acc.item():.4g} Acc: {self.max_acc.item():.4g}\"", "\n", ")", "\n", "# self.loggr.log({'FT Epoch':ft_epoch,'Epoch':self.pret_epoch})", "\n", "\n", "", "", "return", "self", ".", "on_train_end", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.preprocess_sleepedf.combine_to_subjects": [[62, 103], ["os.listdir", "os.makedirs", "os.path.join", "numpy.savez", "print", "i.split", "files_dict[].append", "len", "numpy.concatenate", "[].tolist", "[].tolist", "np.array.extend", "numpy.array", "os.path.join", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "str", "numpy.load", "numpy.load"], "function", ["None"], ["def", "combine_to_subjects", "(", "root_dir", ",", "output_dir", ")", ":", "\n", "    ", "sampling_rate", "=", "100.", "\n", "files", "=", "os", ".", "listdir", "(", "root_dir", ")", "\n", "files", "=", "[", "os", ".", "path", ".", "join", "(", "root_dir", ",", "i", ")", "for", "i", "in", "files", "]", "\n", "\n", "files_dict", "=", "{", "}", "\n", "\n", "for", "i", "in", "files", ":", "\n", "        ", "file_name", "=", "i", ".", "split", "(", "os", ".", "sep", ")", "[", "-", "1", "]", "\n", "file_num", "=", "file_name", "[", "3", ":", "5", "]", "\n", "if", "file_num", "not", "in", "files_dict", ":", "\n", "            ", "files_dict", "[", "file_num", "]", "=", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "files_dict", "[", "file_num", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "for", "i", "in", "files_dict", ":", "\n", "        ", "if", "len", "(", "files_dict", "[", "i", "]", ")", "==", "2", ":", "\n", "            ", "x1", "=", "np", ".", "load", "(", "files_dict", "[", "i", "]", "[", "0", "]", ")", "[", "\"x\"", "]", "\n", "x2", "=", "np", ".", "load", "(", "files_dict", "[", "i", "]", "[", "1", "]", ")", "[", "\"x\"", "]", "\n", "new_x", "=", "np", ".", "concatenate", "(", "(", "x1", ",", "x2", ")", ",", "axis", "=", "0", ")", "\n", "\n", "y1", "=", "np", ".", "load", "(", "files_dict", "[", "i", "]", "[", "0", "]", ")", "[", "\"y\"", "]", ".", "tolist", "(", ")", "\n", "y2", "=", "np", ".", "load", "(", "files_dict", "[", "i", "]", "[", "1", "]", ")", "[", "\"y\"", "]", ".", "tolist", "(", ")", "\n", "y1", ".", "extend", "(", "y2", ")", "\n", "y1", "=", "np", ".", "array", "(", "y1", ")", "\n", "", "else", ":", "\n", "            ", "new_x", "=", "np", ".", "load", "(", "files_dict", "[", "i", "]", "[", "0", "]", ")", "[", "\"x\"", "]", "\n", "y1", "=", "np", ".", "load", "(", "files_dict", "[", "i", "]", "[", "0", "]", ")", "[", "\"y\"", "]", "\n", "\n", "# Saving as numpy files", "\n", "# print(file, x_values.shape[0], y_values.shape[0])", "\n", "", "filename", "=", "\"subject_\"", "+", "str", "(", "i", ")", "+", "\".npz\"", "\n", "\n", "save_dict", "=", "{", "\n", "\"x\"", ":", "new_x", ",", "\n", "\"y\"", ":", "y1", ",", "\n", "\"fs\"", ":", "sampling_rate", "\n", "}", "\n", "np", ".", "savez", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "filename", ")", ",", "**", "save_dict", ")", "\n", "print", "(", "\" ---------- Combining files to subjects is done ---------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.preprocess_sleepedf.main": [[106, 290], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "glob.glob", "glob.glob", "np.asarray.sort", "np.asarray.sort", "print", "print", "numpy.asarray", "numpy.asarray", "range", "preprocess_sleepedf.combine_to_subjects", "os.listdir", "numpy.array", "np.array.sort", "generate_sleepedf.gen_sleepedf", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "len", "len", "len", "print", "mne.io.read_raw_edf", "raw_ch_df.set_index", "open", "dhedfreader.BaseEDFReader", "dhedfreader.BaseEDFReader.read_header", "open.close", "datetime.datetime.strptime", "open", "dhedfreader.BaseEDFReader", "dhedfreader.BaseEDFReader.read_header", "zip", "open.close", "datetime.datetime.strptime", "numpy.hstack", "numpy.hstack", "numpy.intersect1d", "numpy.asarray().astype", "np.hstack.astype", "numpy.arange", "print", "print", "ntpath.basename().replace", "numpy.savez", "print", "mne.io.read_raw_edf.to_data_frame", "numpy.arange", "len", "numpy.hstack", "numpy.setdiff1d", "numpy.arange", "len", "len", "numpy.setdiff1d", "numpy.all", "Exception", "len", "len", "len", "numpy.where", "len", "os.path.join", "os.path.join", "len", "dhedfreader.BaseEDFReader.records", "int", "np.hstack.append", "np.hstack.append", "np.hstack.append", "numpy.arange", "len", "int", "len", "numpy.asarray", "len", "ntpath.basename", "Exception", "numpy.ones", "int", "numpy.arange", "int", "numpy.arange", "len", "math.ceil", "numpy.split", "len"], "function", ["home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.preprocess_sleepedf.combine_to_subjects", "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.generate_sleepedf.gen_sleepedf", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_header", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_header", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.records"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./SLEEP_data\"", ",", "\n", "help", "=", "\"File path to the PSG and annotation files.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--save_path\"", ",", "type", "=", "str", ",", "default", "=", "\"./SLEEP_data\"", ",", "\n", "help", "=", "\"Path to save preprocess files\"", ")", "\n", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "channels", "=", "1", "\n", "\n", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"/physionet-sleep-data/\"", ")", "\n", "subjects_output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"/numpy_subjects/\"", ")", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"/numpy_saves/\"", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"/data/\"", ")", "\n", "\n", "print", "(", "data_dir", ")", "\n", "\n", "# Output dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "subjects_output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "subjects_output_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "\n", "# Select channel", "\n", "", "all_picks", "=", "[", "'EEG Fpz-Cz'", ",", "\n", "'EEG Pz-Oz'", ",", "\n", "'EOG horizontal'", ",", "\n", "'Resp oro-nasal'", ",", "\n", "'EMG submental'", ",", "\n", "'Temp rectal'", ",", "\n", "'Event marker'", "]", "\n", "select_ch", "=", "all_picks", "[", ":", "channels", "]", "\n", "\n", "# Read raw and annotation EDF files", "\n", "psg_fnames", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"*PSG.edf\"", ")", ")", "\n", "ann_fnames", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"*Hypnogram.edf\"", ")", ")", "\n", "\n", "psg_fnames", ".", "sort", "(", ")", "\n", "ann_fnames", ".", "sort", "(", ")", "\n", "\n", "print", "(", "\"Number of PSG files: \"", ",", "len", "(", "psg_fnames", ")", ")", "\n", "print", "(", "\"Number of annotation files: \"", ",", "len", "(", "ann_fnames", ")", ")", "\n", "\n", "psg_fnames", "=", "np", ".", "asarray", "(", "psg_fnames", ")", "\n", "ann_fnames", "=", "np", ".", "asarray", "(", "ann_fnames", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "psg_fnames", ")", ")", ":", "\n", "\n", "        ", "print", "(", "i", ")", "\n", "\n", "raw", "=", "read_raw_edf", "(", "psg_fnames", "[", "i", "]", ",", "preload", "=", "True", ",", "stim_channel", "=", "None", ")", "\n", "sampling_rate", "=", "raw", ".", "info", "[", "'sfreq'", "]", "\n", "raw_ch_df", "=", "raw", ".", "to_data_frame", "(", ")", "[", "select_ch", "]", "\n", "\n", "raw_ch_df", ".", "set_index", "(", "np", ".", "arange", "(", "len", "(", "raw_ch_df", ")", ")", ")", "\n", "\n", "# Get raw header", "\n", "f", "=", "open", "(", "psg_fnames", "[", "i", "]", ",", "'r'", ",", "errors", "=", "'ignore'", ")", "\n", "reader_raw", "=", "dhedfreader", ".", "BaseEDFReader", "(", "f", ")", "\n", "reader_raw", ".", "read_header", "(", ")", "\n", "h_raw", "=", "reader_raw", ".", "header", "\n", "f", ".", "close", "(", ")", "\n", "raw_start_dt", "=", "datetime", ".", "strptime", "(", "h_raw", "[", "'date_time'", "]", ",", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "\n", "# Read annotation and its header", "\n", "f", "=", "open", "(", "ann_fnames", "[", "i", "]", ",", "'r'", ",", "errors", "=", "'ignore'", ")", "\n", "reader_ann", "=", "dhedfreader", ".", "BaseEDFReader", "(", "f", ")", "\n", "reader_ann", ".", "read_header", "(", ")", "\n", "h_ann", "=", "reader_ann", ".", "header", "\n", "_", ",", "_", ",", "ann", "=", "zip", "(", "*", "reader_ann", ".", "records", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "ann_start_dt", "=", "datetime", ".", "strptime", "(", "h_ann", "[", "'date_time'", "]", ",", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "\n", "# Assert that raw and annotation files start at the same time", "\n", "assert", "raw_start_dt", "==", "ann_start_dt", "\n", "\n", "# Generate label and remove indices", "\n", "remove_idx", "=", "[", "]", "# indicies of the data that will be removed", "\n", "labels", "=", "[", "]", "# indicies of the data that have labels", "\n", "label_idx", "=", "[", "]", "\n", "\n", "for", "a", "in", "ann", "[", "0", "]", ":", "\n", "            ", "onset_sec", ",", "duration_sec", ",", "ann_char", "=", "a", "\n", "ann_str", "=", "\"\"", ".", "join", "(", "ann_char", ")", "\n", "label", "=", "ann2label", "[", "ann_str", "[", "2", ":", "-", "1", "]", "]", "\n", "if", "label", "!=", "UNKNOWN", ":", "\n", "                ", "if", "duration_sec", "%", "EPOCH_SEC_SIZE", "!=", "0", ":", "\n", "                    ", "raise", "Exception", "(", "\"Something wrong\"", ")", "\n", "", "duration_epoch", "=", "int", "(", "duration_sec", "/", "EPOCH_SEC_SIZE", ")", "\n", "label_epoch", "=", "np", ".", "ones", "(", "duration_epoch", ",", "dtype", "=", "np", ".", "int", ")", "*", "label", "\n", "labels", ".", "append", "(", "label_epoch", ")", "\n", "idx", "=", "int", "(", "onset_sec", "*", "sampling_rate", ")", "+", "np", ".", "arange", "(", "duration_sec", "*", "sampling_rate", ",", "dtype", "=", "np", ".", "int", ")", "\n", "label_idx", ".", "append", "(", "idx", ")", "\n", "\n", "", "else", ":", "\n", "                ", "idx", "=", "int", "(", "onset_sec", "*", "sampling_rate", ")", "+", "np", ".", "arange", "(", "duration_sec", "*", "sampling_rate", ",", "dtype", "=", "np", ".", "int", ")", "\n", "remove_idx", ".", "append", "(", "idx", ")", "\n", "\n", "", "", "labels", "=", "np", ".", "hstack", "(", "labels", ")", "\n", "\n", "if", "len", "(", "remove_idx", ")", ">", "0", ":", "\n", "            ", "remove_idx", "=", "np", ".", "hstack", "(", "remove_idx", ")", "\n", "select_idx", "=", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "len", "(", "raw_ch_df", ")", ")", ",", "remove_idx", ")", "\n", "", "else", ":", "\n", "            ", "select_idx", "=", "np", ".", "arange", "(", "len", "(", "raw_ch_df", ")", ")", "\n", "\n", "# Select only the data with labels", "\n", "", "label_idx", "=", "np", ".", "hstack", "(", "label_idx", ")", "\n", "select_idx", "=", "np", ".", "intersect1d", "(", "select_idx", ",", "label_idx", ")", "\n", "\n", "# Remove extra index", "\n", "if", "len", "(", "label_idx", ")", ">", "len", "(", "select_idx", ")", ":", "\n", "            ", "extra_idx", "=", "np", ".", "setdiff1d", "(", "label_idx", ",", "select_idx", ")", "\n", "# Trim the tail", "\n", "if", "np", ".", "all", "(", "extra_idx", ">", "select_idx", "[", "-", "1", "]", ")", ":", "\n", "\n", "                ", "n_label_trims", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "extra_idx", ")", "/", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", ")", ")", "\n", "if", "n_label_trims", "!=", "0", ":", "\n", "\n", "                    ", "labels", "=", "labels", "[", ":", "-", "n_label_trims", "]", "\n", "\n", "# Remove movement and unknown stages if any", "\n", "", "", "", "raw_ch", "=", "raw_ch_df", ".", "values", "[", "select_idx", "]", "\n", "\n", "# Verify that we can split into 30-s epochs", "\n", "if", "len", "(", "raw_ch", ")", "%", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Something wrong\"", ")", "\n", "", "n_epochs", "=", "len", "(", "raw_ch", ")", "/", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", "\n", "\n", "# Get epochs and their corresponding labels", "\n", "x", "=", "np", ".", "asarray", "(", "np", ".", "split", "(", "raw_ch", ",", "n_epochs", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "y", "=", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "assert", "len", "(", "x", ")", "==", "len", "(", "y", ")", "\n", "\n", "# Select on sleep periods", "\n", "w_edge_mins", "=", "30", "\n", "\n", "nw_idx", "=", "np", ".", "where", "(", "y", "!=", "stage_dict", "[", "\"W\"", "]", ")", "[", "0", "]", "\n", "start_idx", "=", "nw_idx", "[", "0", "]", "-", "(", "w_edge_mins", "*", "2", ")", "\n", "end_idx", "=", "nw_idx", "[", "-", "1", "]", "+", "(", "w_edge_mins", "*", "2", ")", "\n", "\n", "if", "start_idx", "<", "0", ":", "start_idx", "=", "0", "\n", "if", "end_idx", ">=", "len", "(", "y", ")", ":", "end_idx", "=", "len", "(", "y", ")", "-", "1", "\n", "\n", "select_idx", "=", "np", ".", "arange", "(", "start_idx", ",", "end_idx", "+", "1", ")", "\n", "print", "(", "\"Data before selection: {}, {}\"", ".", "format", "(", "x", ".", "shape", ",", "y", ".", "shape", ")", ")", "\n", "x", "=", "x", "[", "select_idx", "]", "\n", "y", "=", "y", "[", "select_idx", "]", "\n", "print", "(", "\"Data after selection: {}, {}\"", ".", "format", "(", "x", ".", "shape", ",", "y", ".", "shape", ")", ")", "\n", "\n", "# Save", "\n", "filename", "=", "ntpath", ".", "basename", "(", "psg_fnames", "[", "i", "]", ")", ".", "replace", "(", "\"-PSG.edf\"", ",", "\".npz\"", ")", "\n", "\n", "\n", "save_dict", "=", "{", "\n", "\"x\"", ":", "x", ",", "\n", "\"y\"", ":", "y", ",", "\n", "\"fs\"", ":", "sampling_rate", ",", "\n", "\"ch_label\"", ":", "select_ch", ",", "\n", "\"header_raw\"", ":", "h_raw", ",", "\n", "\"header_annotation\"", ":", "h_ann", ",", "\n", "}", "\n", "np", ".", "savez", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "filename", ")", ",", "**", "save_dict", ")", "\n", "\n", "print", "(", "\"\\n====================================================================================\\n\"", ")", "\n", "\n", "", "combine_to_subjects", "(", "output_dir", ",", "subjects_output_dir", ")", "\n", "\n", "files", "=", "os", ".", "listdir", "(", "subjects_output_dir", ")", "\n", "files", "=", "np", ".", "array", "(", "[", "os", ".", "path", ".", "join", "(", "subjects_output_dir", ",", "i", ")", "for", "i", "in", "files", "]", ")", "\n", "files", ".", "sort", "(", ")", "\n", "\n", "# generates the final preprocessed data", "\n", "gen_sleepedf", "(", "files", ",", "subjects_output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.generate_sleepedf.gen_sleepedf": [[19, 90], ["list", "print", "enumerate", "dict", "torch.from_numpy", "torch.from_numpy", "torch.save", "list", "print", "print", "dict", "torch.from_numpy", "torch.from_numpy", "torch.save", "sorted", "print", "print", "dict", "torch.from_numpy", "torch.from_numpy", "torch.save", "numpy.random.choice", "len", "numpy.load", "numpy.load", "print", "numpy.vstack", "numpy.append", "np.vstack.transpose", "os.path.join", "numpy.random.choice", "len", "numpy.load", "numpy.load", "print", "numpy.vstack", "numpy.append", "np.vstack.transpose", "os.path.join", "list", "len", "numpy.load", "numpy.load", "print", "numpy.vstack", "numpy.append", "np.vstack.transpose", "os.path.join", "os.path.basename", "sorted", "os.path.basename", "os.path.basename", "numpy.load", "list", "numpy.load", "set", "numpy.load", "numpy.load", "numpy.load", "set", "set", "numpy.load", "set", "set"], "function", ["None"], ["def", "gen_sleepedf", "(", "files", ":", "np", ".", "ndarray", ",", "save_path", ":", "str", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Generates the pretext, train and test splits on sleep-edf dataset for self-supervised pre-training.\n\n    Attributes:\n        files: list\n            List of files to be used for generating the splits.\n        save_path: str\n            Path to save the splits.\n    \"\"\"", "\n", "\n", "######## Pretext files########", "\n", "pretext_files", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "files", ",", "58", ",", "replace", "=", "False", ")", ")", "\n", "print", "(", "\"pretext files: \"", ",", "len", "(", "pretext_files", ")", ")", "\n", "\n", "# load files", "\n", "X", "=", "np", ".", "load", "(", "pretext_files", "[", "0", "]", ")", "[", "\"x\"", "]", "\n", "y", "=", "np", ".", "load", "(", "pretext_files", "[", "0", "]", ")", "[", "\"y\"", "]", "\n", "\n", "for", "i", ",", "file", "in", "enumerate", "(", "pretext_files", "[", "1", ":", "]", ")", ":", "\n", "        ", "print", "(", "os", ".", "path", ".", "basename", "(", "file", ")", ")", "\n", "X", "=", "np", ".", "vstack", "(", "(", "X", ",", "np", ".", "load", "(", "file", ")", "[", "\"x\"", "]", ")", ")", "\n", "y", "=", "np", ".", "append", "(", "y", ",", "np", ".", "load", "(", "file", ")", "[", "\"y\"", "]", ")", "\n", "\n", "", "data_save", "=", "dict", "(", ")", "\n", "data_save", "[", "\"samples\"", "]", "=", "torch", ".", "from_numpy", "(", "X", ".", "transpose", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "data_save", "[", "\"labels\"", "]", "=", "torch", ".", "from_numpy", "(", "y", ")", "\n", "\n", "torch", ".", "save", "(", "data_save", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"pretext.pt\"", ")", ")", "\n", "\n", "######## Training files ##########", "\n", "training_files", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "sorted", "(", "list", "(", "set", "(", "files", ")", "-", "set", "(", "pretext_files", ")", ")", ")", ",", "10", ",", "replace", "=", "False", ")", ")", "\n", "\n", "print", "(", "\"\\n ============================================== \\n\"", ")", "\n", "print", "(", "\"training files: \"", ",", "len", "(", "training_files", ")", ")", "\n", "\n", "# load files", "\n", "X", "=", "np", ".", "load", "(", "training_files", "[", "0", "]", ")", "[", "\"x\"", "]", "\n", "y", "=", "np", ".", "load", "(", "training_files", "[", "0", "]", ")", "[", "\"y\"", "]", "\n", "\n", "for", "file", "in", "training_files", "[", "1", ":", "]", ":", "\n", "        ", "print", "(", "os", ".", "path", ".", "basename", "(", "file", ")", ")", "\n", "X", "=", "np", ".", "vstack", "(", "(", "X", ",", "np", ".", "load", "(", "file", ")", "[", "\"x\"", "]", ")", ")", "\n", "y", "=", "np", ".", "append", "(", "y", ",", "np", ".", "load", "(", "file", ")", "[", "\"y\"", "]", ")", "\n", "\n", "", "data_save", "=", "dict", "(", ")", "\n", "data_save", "[", "\"samples\"", "]", "=", "torch", ".", "from_numpy", "(", "X", ".", "transpose", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "data_save", "[", "\"labels\"", "]", "=", "torch", ".", "from_numpy", "(", "y", ")", "\n", "torch", ".", "save", "(", "data_save", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"train.pt\"", ")", ")", "\n", "\n", "######## Test files ##########", "\n", "test_files", "=", "sorted", "(", "list", "(", "set", "(", "files", ")", "-", "set", "(", "pretext_files", ")", "-", "set", "(", "training_files", ")", ")", ")", "\n", "\n", "print", "(", "\"\\n =========================================== \\n\"", ")", "\n", "print", "(", "\"test files: \"", ",", "len", "(", "test_files", ")", ")", "\n", "\n", "# load files", "\n", "X", "=", "np", ".", "load", "(", "test_files", "[", "0", "]", ")", "[", "\"x\"", "]", "\n", "y", "=", "np", ".", "load", "(", "test_files", "[", "0", "]", ")", "[", "\"y\"", "]", "\n", "\n", "for", "file", "in", "test_files", "[", "1", ":", "]", ":", "\n", "        ", "print", "(", "os", ".", "path", ".", "basename", "(", "file", ")", ")", "\n", "X", "=", "np", ".", "vstack", "(", "(", "X", ",", "np", ".", "load", "(", "file", ")", "[", "\"x\"", "]", ")", ")", "\n", "y", "=", "np", ".", "append", "(", "y", ",", "np", ".", "load", "(", "file", ")", "[", "\"y\"", "]", ")", "\n", "\n", "", "data_save", "=", "dict", "(", ")", "\n", "data_save", "[", "\"samples\"", "]", "=", "torch", ".", "from_numpy", "(", "X", ".", "transpose", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "data_save", "[", "\"labels\"", "]", "=", "torch", ".", "from_numpy", "(", "y", ")", "\n", "\n", "torch", ".", "save", "(", "data_save", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"test.pt\"", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.BaseEDFReader.__init__": [[77, 79], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "file", ")", ":", "\n", "    ", "self", ".", "file", "=", "file", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.BaseEDFReader.read_header": [[81, 92], ["dhedfreader.edf_header"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.edf_header"], ["", "def", "read_header", "(", "self", ")", ":", "\n", "    ", "self", ".", "header", "=", "h", "=", "edf_header", "(", "self", ".", "file", ")", "\n", "\n", "# calculate ranges for rescaling", "\n", "self", ".", "dig_min", "=", "h", "[", "'digital_min'", "]", "\n", "self", ".", "phys_min", "=", "h", "[", "'physical_min'", "]", "\n", "phys_range", "=", "h", "[", "'physical_max'", "]", "-", "h", "[", "'physical_min'", "]", "\n", "dig_range", "=", "h", "[", "'digital_max'", "]", "-", "h", "[", "'digital_min'", "]", "\n", "#assert np.all(phys_range > 0)", "\n", "#assert np.all(dig_range > 0)", "\n", "self", ".", "gain", "=", "phys_range", "/", "dig_range", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.BaseEDFReader.read_raw_record": [[94, 105], ["dhedfreader.BaseEDFReader.file.read", "result.append", "len"], "methods", ["None"], ["", "def", "read_raw_record", "(", "self", ")", ":", "\n", "    ", "'''Read a record with data_2013 and return a list containing arrays with raw\n    bytes.\n    '''", "\n", "result", "=", "[", "]", "\n", "for", "nsamp", "in", "self", ".", "header", "[", "'n_samples_per_record'", "]", ":", "\n", "      ", "samples", "=", "self", ".", "file", ".", "read", "(", "nsamp", "*", "2", ")", "\n", "if", "len", "(", "samples", ")", "!=", "nsamp", "*", "2", ":", "\n", "        ", "raise", "EDFEndOfData", "\n", "", "result", ".", "append", "(", "samples", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.BaseEDFReader.convert_record": [[107, 130], ["float", "enumerate", "dhedfreader.tal", "events.extend", "numpy.fromstring().astype", "signals.append", "numpy.fromstring"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.tal"], ["", "def", "convert_record", "(", "self", ",", "raw_record", ")", ":", "\n", "    ", "'''Convert a raw record to a (time, signals, events) tuple based on\n    information in the header.\n    '''", "\n", "h", "=", "self", ".", "header", "\n", "dig_min", ",", "phys_min", ",", "gain", "=", "self", ".", "dig_min", ",", "self", ".", "phys_min", ",", "self", ".", "gain", "\n", "time", "=", "float", "(", "'nan'", ")", "\n", "signals", "=", "[", "]", "\n", "events", "=", "[", "]", "\n", "for", "(", "i", ",", "samples", ")", "in", "enumerate", "(", "raw_record", ")", ":", "\n", "      ", "if", "h", "[", "'label'", "]", "[", "i", "]", "==", "EVENT_CHANNEL", ":", "\n", "        ", "ann", "=", "tal", "(", "samples", ")", "\n", "time", "=", "ann", "[", "0", "]", "[", "0", "]", "\n", "events", ".", "extend", "(", "ann", "[", "1", ":", "]", ")", "\n", "# print(i, samples)", "\n", "# exit()", "\n", "", "else", ":", "\n", "# 2-byte little-endian integers", "\n", "        ", "dig", "=", "np", ".", "fromstring", "(", "samples", ",", "'<i2'", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "phys", "=", "(", "dig", "-", "dig_min", "[", "i", "]", ")", "*", "gain", "[", "i", "]", "+", "phys_min", "[", "i", "]", "\n", "signals", ".", "append", "(", "phys", ")", "\n", "\n", "", "", "return", "time", ",", "signals", ",", "events", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.BaseEDFReader.read_record": [[132, 134], ["dhedfreader.BaseEDFReader.convert_record", "dhedfreader.BaseEDFReader.read_raw_record"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.convert_record", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_raw_record"], ["", "def", "read_record", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "convert_record", "(", "self", ".", "read_raw_record", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.BaseEDFReader.records": [[136, 145], ["dhedfreader.BaseEDFReader.read_record"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_record"], ["", "def", "records", "(", "self", ")", ":", "\n", "    ", "'''\n    Record generator.\n    '''", "\n", "try", ":", "\n", "      ", "while", "True", ":", "\n", "        ", "yield", "self", ".", "read_record", "(", ")", "\n", "", "", "except", "EDFEndOfData", ":", "\n", "      ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.tal": [[14, 33], ["dhedfreader.tal.parse"], "function", ["None"], ["def", "tal", "(", "tal_str", ")", ":", "\n", "  ", "'''Return a list with (onset, duration, annotation) tuples for an EDF+ TAL\n  stream.\n  '''", "\n", "exp", "=", "'(?P<onset>[+\\-]\\d+(?:\\.\\d*)?)'", "+", "'(?:\\x15(?P<duration>\\d+(?:\\.\\d*)?))?'", "+", "'(\\x14(?P<annotation>[^\\x00]*))?'", "+", "'(?:\\x14\\x00)'", "\n", "\n", "def", "annotation_to_list", "(", "annotation", ")", ":", "\n", "    ", "return", "str", "(", "annotation", ".", "encode", "(", "'utf-8'", ")", ")", ".", "split", "(", "'\\x14'", ")", "if", "annotation", "else", "[", "]", "\n", "\n", "", "def", "parse", "(", "dic", ")", ":", "\n", "    ", "return", "(", "\n", "float", "(", "dic", "[", "'onset'", "]", ")", ",", "\n", "float", "(", "dic", "[", "'duration'", "]", ")", "if", "dic", "[", "'duration'", "]", "else", "0.", ",", "\n", "annotation_to_list", "(", "dic", "[", "'annotation'", "]", ")", ")", "\n", "\n", "", "return", "[", "parse", "(", "m", ".", "groupdict", "(", ")", ")", "for", "m", "in", "re", ".", "finditer", "(", "exp", ",", "tal_str", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.edf_header": [[35, 74], ["f.read().strip", "f.read().strip", "str", "int", "int", "float", "int", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "f.read", "f.tell", "f.read", "int", "int", "datetime.datetime", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read().strip", "f.read().strip", "f.read().strip", "f.read().strip", "int", "f.read", "f.read", "re.findall", "re.findall", "float", "float", "float", "float", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read"], "function", ["None"], ["", "def", "edf_header", "(", "f", ")", ":", "\n", "  ", "h", "=", "{", "}", "\n", "assert", "f", ".", "tell", "(", ")", "==", "0", "# check file position", "\n", "assert", "f", ".", "read", "(", "8", ")", "==", "'0       '", "\n", "\n", "# recording info)", "\n", "h", "[", "'local_subject_id'", "]", "=", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "\n", "h", "[", "'local_recording_id'", "]", "=", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "\n", "\n", "# parse timestamp", "\n", "(", "day", ",", "month", ",", "year", ")", "=", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "findall", "(", "'(\\d+)'", ",", "f", ".", "read", "(", "8", ")", ")", "]", "\n", "(", "hour", ",", "minute", ",", "sec", ")", "=", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "findall", "(", "'(\\d+)'", ",", "f", ".", "read", "(", "8", ")", ")", "]", "\n", "h", "[", "'date_time'", "]", "=", "str", "(", "datetime", ".", "datetime", "(", "year", "+", "2000", ",", "month", ",", "day", ",", "\n", "hour", ",", "minute", ",", "sec", ")", ")", "\n", "\n", "# misc", "\n", "header_nbytes", "=", "int", "(", "f", ".", "read", "(", "8", ")", ")", "\n", "subtype", "=", "f", ".", "read", "(", "44", ")", "[", ":", "5", "]", "\n", "h", "[", "'EDF+'", "]", "=", "subtype", "in", "[", "'EDF+C'", ",", "'EDF+D'", "]", "\n", "h", "[", "'contiguous'", "]", "=", "subtype", "!=", "'EDF+D'", "\n", "h", "[", "'n_records'", "]", "=", "int", "(", "f", ".", "read", "(", "8", ")", ")", "\n", "h", "[", "'record_length'", "]", "=", "float", "(", "f", ".", "read", "(", "8", ")", ")", "# in seconds", "\n", "nchannels", "=", "h", "[", "'n_channels'", "]", "=", "int", "(", "f", ".", "read", "(", "4", ")", ")", "\n", "\n", "# read channel info", "\n", "channels", "=", "range", "(", "h", "[", "'n_channels'", "]", ")", "\n", "h", "[", "'label'", "]", "=", "[", "f", ".", "read", "(", "16", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'transducer_type'", "]", "=", "[", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'units'", "]", "=", "[", "f", ".", "read", "(", "8", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'physical_min'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'physical_max'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'digital_min'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'digital_max'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'prefiltering'", "]", "=", "[", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'n_samples_per_record'", "]", "=", "[", "int", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", "\n", "f", ".", "read", "(", "32", "*", "nchannels", ")", "# reserved", "\n", "\n", "#assert f.tell() == header_nbytes", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.sleepedf.dhedfreader.load_edf": [[147, 209], ["isinstance", "dhedfreader.BaseEDFReader", "dhedfreader.BaseEDFReader.read_header", "log.debug", "numpy.unique", "zip", "numpy.hstack", "reduce", "collections.namedtuple", "collections.namedtuple.", "float", "numpy.linspace", "numpy.hstack", "open", "dhedfreader.load_edf", "dhedfreader.BaseEDFReader.records", "numpy.arange", "zip"], "function", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_header", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.load_edf", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.records"], ["", "", "", "def", "load_edf", "(", "edffile", ")", ":", "\n", "  ", "'''Load an EDF+ file.\n  Very basic reader for EDF and EDF+ files. While BaseEDFReader does support\n  exotic features like non-homogeneous sample rates and loading only parts of\n  the stream, load_edf expects a single fixed sample rate for all channels and\n  tries to load the whole file.\n  Parameters\n  ----------\n  edffile : file-like object or string\n  Returns\n  -------\n  Named tuple with the fields:\n    X : NumPy array with shape p by n.\n      Raw recording of n samples in p dimensions.\n    sample_rate : float\n      The sample rate of the recording. Note that mixed sample-rates are not\n      supported.\n    sens_lab : list of length p with strings\n      The labels of the sensors used to record X.\n    time : NumPy array with length n\n      The time offset in the recording for each sample.\n    annotations : a list with tuples\n      EDF+ annotations are stored in (start, duration, description) tuples.\n      start : float\n        Indicates the start of the event in seconds.\n      duration : float\n        Indicates the duration of the event in seconds.\n      description : list with strings\n        Contains (multiple?) descriptions of the annotation event.\n  '''", "\n", "if", "isinstance", "(", "edffile", ",", "basestring", ")", ":", "\n", "    ", "with", "open", "(", "edffile", ",", "'rb'", ")", "as", "f", ":", "\n", "      ", "return", "load_edf", "(", "f", ")", "# convert filename to file", "\n", "\n", "", "", "reader", "=", "BaseEDFReader", "(", "edffile", ")", "\n", "reader", ".", "read_header", "(", ")", "\n", "\n", "h", "=", "reader", ".", "header", "\n", "log", ".", "debug", "(", "'EDF header: %s'", "%", "h", ")", "\n", "\n", "# get sample rate info", "\n", "nsamp", "=", "np", ".", "unique", "(", "\n", "[", "n", "for", "(", "l", ",", "n", ")", "in", "zip", "(", "h", "[", "'label'", "]", ",", "h", "[", "'n_samples_per_record'", "]", ")", "\n", "if", "l", "!=", "EVENT_CHANNEL", "]", ")", "\n", "assert", "nsamp", ".", "size", "==", "1", ",", "'Multiple sample rates not supported!'", "\n", "sample_rate", "=", "float", "(", "nsamp", "[", "0", "]", ")", "/", "h", "[", "'record_length'", "]", "\n", "\n", "rectime", ",", "X", ",", "annotations", "=", "zip", "(", "*", "reader", ".", "records", "(", ")", ")", "\n", "X", "=", "np", ".", "hstack", "(", "X", ")", "\n", "annotations", "=", "reduce", "(", "operator", ".", "add", ",", "annotations", ")", "\n", "chan_lab", "=", "[", "lab", "for", "lab", "in", "reader", ".", "header", "[", "'label'", "]", "if", "lab", "!=", "EVENT_CHANNEL", "]", "\n", "\n", "# create timestamps", "\n", "if", "reader", ".", "header", "[", "'contiguous'", "]", ":", "\n", "    ", "time", "=", "np", ".", "arange", "(", "X", ".", "shape", "[", "1", "]", ")", "/", "sample_rate", "\n", "", "else", ":", "\n", "    ", "reclen", "=", "reader", ".", "header", "[", "'record_length'", "]", "\n", "within_rec_time", "=", "np", ".", "linspace", "(", "0", ",", "reclen", ",", "nsamp", ",", "endpoint", "=", "False", ")", "\n", "time", "=", "np", ".", "hstack", "(", "[", "t", "+", "within_rec_time", "for", "t", "in", "rectime", "]", ")", "\n", "\n", "", "tup", "=", "namedtuple", "(", "'EDF'", ",", "'X sample_rate chan_lab time annotations'", ")", "\n", "return", "tup", "(", "X", ",", "sample_rate", ",", "chan_lab", ",", "time", ",", "annotations", ")", "", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.generate_shhs.gen_shhs": [[17, 105], ["list", "print", "dict", "torch.from_numpy", "torch.from_numpy", "torch.save", "list", "print", "print", "dict", "torch.from_numpy", "torch.from_numpy", "torch.save", "sorted", "print", "print", "dict", "torch.from_numpy", "torch.from_numpy", "torch.save", "numpy.random.choice", "len", "numpy.load", "numpy.load", "print", "np.vstack.transpose", "os.path.join", "numpy.random.choice", "len", "numpy.load", "numpy.load", "print", "np.vstack.transpose", "os.path.join", "list", "len", "numpy.load", "numpy.load", "print", "np.vstack.transpose", "os.path.join", "os.path.basename", "numpy.load", "numpy.vstack", "numpy.append", "print", "sorted", "numpy.load", "os.path.basename", "numpy.vstack", "numpy.append", "print", "os.path.basename", "numpy.load", "numpy.vstack", "numpy.append", "print", "list", "set", "numpy.load", "numpy.load", "set", "set", "numpy.load", "set", "set"], "function", ["None"], ["def", "gen_shhs", "(", "files", ":", "np", ".", "ndarray", ",", "save_path", ":", "str", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Generates the pretext, train and test splits on shhs dataset for self-supervised pre-training.\n\n    Attributes:\n        files: list\n            List of files to be used for generating the splits.\n        save_path: str\n            Path to save the splits. \n    \n    \"\"\"", "\n", "\n", "######## pretext files##########", "\n", "pretext_files", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "files", ",", "264", ",", "replace", "=", "False", ")", ")", "#change", "\n", "\n", "print", "(", "\"pretext files: \"", ",", "len", "(", "pretext_files", ")", ")", "\n", "\n", "### Below code is for making pretext.pt train.pt val.pt", "\n", "\n", "X_train", "=", "np", ".", "load", "(", "pretext_files", "[", "0", "]", ")", "[", "\"x\"", "]", "\n", "y_train", "=", "np", ".", "load", "(", "pretext_files", "[", "0", "]", ")", "[", "\"y\"", "]", "\n", "c", "=", "0", "\n", "for", "np_file", "in", "pretext_files", "[", "1", ":", "]", ":", "\n", "       ", "print", "(", "os", ".", "path", ".", "basename", "(", "np_file", ")", ")", "\n", "x_dat", "=", "np", ".", "load", "(", "np_file", ")", "[", "\"x\"", "]", "\n", "if", "x_dat", ".", "shape", "[", "-", "1", "]", "==", "2", ":", "\n", "           ", "X_train", "=", "np", ".", "vstack", "(", "(", "X_train", ",", "x_dat", ")", ")", "\n", "y_train", "=", "np", ".", "append", "(", "y_train", ",", "np", ".", "load", "(", "np_file", ")", "[", "\"y\"", "]", ")", "\n", "", "else", ":", "\n", "           ", "print", "(", "'Deleted'", ")", "\n", "\n", "\n", "", "", "data_save", "=", "dict", "(", ")", "\n", "data_save", "[", "\"samples\"", "]", "=", "torch", ".", "from_numpy", "(", "X_train", ".", "transpose", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "data_save", "[", "\"labels\"", "]", "=", "torch", ".", "from_numpy", "(", "y_train", ")", "\n", "\n", "torch", ".", "save", "(", "data_save", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"pretext.pt\"", ")", ")", "\n", "\n", "######## training files ##########", "\n", "training_files", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "sorted", "(", "list", "(", "set", "(", "files", ")", "-", "set", "(", "pretext_files", ")", ")", ")", ",", "31", ",", "replace", "=", "False", ")", ")", "#change", "\n", "\n", "print", "(", "\"\\n =========================================== \\n\"", ")", "\n", "print", "(", "\"training files: \"", ",", "len", "(", "training_files", ")", ")", "\n", "\n", "# load files", "\n", "X_train", "=", "np", ".", "load", "(", "training_files", "[", "0", "]", ")", "[", "\"x\"", "]", "\n", "y_train", "=", "np", ".", "load", "(", "training_files", "[", "0", "]", ")", "[", "\"y\"", "]", "\n", "\n", "for", "np_file", "in", "training_files", "[", "1", ":", "]", ":", "\n", "       ", "x_dat", "=", "np", ".", "load", "(", "np_file", ")", "[", "\"x\"", "]", "\n", "print", "(", "os", ".", "path", ".", "basename", "(", "np_file", ")", ",", "x_dat", ".", "shape", ")", "\n", "if", "x_dat", ".", "shape", "[", "-", "1", "]", "==", "2", ":", "\n", "           ", "X_train", "=", "np", ".", "vstack", "(", "(", "X_train", ",", "x_dat", ")", ")", "\n", "y_train", "=", "np", ".", "append", "(", "y_train", ",", "np", ".", "load", "(", "np_file", ")", "[", "\"y\"", "]", ")", "\n", "", "else", ":", "\n", "           ", "print", "(", "'Deleted'", ")", "\n", "\n", "", "", "data_save", "=", "dict", "(", ")", "\n", "data_save", "[", "\"samples\"", "]", "=", "torch", ".", "from_numpy", "(", "X_train", ".", "transpose", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "data_save", "[", "\"labels\"", "]", "=", "torch", ".", "from_numpy", "(", "y_train", ")", "\n", "torch", ".", "save", "(", "data_save", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"train.pt\"", ")", ")", "\n", "\n", "######## validation files ##########", "\n", "validation_files", "=", "sorted", "(", "list", "(", "set", "(", "files", ")", "-", "set", "(", "pretext_files", ")", "-", "set", "(", "training_files", ")", ")", ")", "#list(np.random.choice(sorted(list(set(files)-set(pretext_files)-set(training_files))),32,replace=False))    # left =32", "\n", "\n", "print", "(", "\"\\n =========================================== \\n\"", ")", "\n", "print", "(", "\"validation files: \"", ",", "len", "(", "validation_files", ")", ")", "\n", "\n", "# load files", "\n", "X_train", "=", "np", ".", "load", "(", "validation_files", "[", "0", "]", ")", "[", "\"x\"", "]", "\n", "y_train", "=", "np", ".", "load", "(", "validation_files", "[", "0", "]", ")", "[", "\"y\"", "]", "\n", "\n", "for", "np_file", "in", "validation_files", "[", "1", ":", "]", ":", "\n", "       ", "print", "(", "os", ".", "path", ".", "basename", "(", "np_file", ")", ")", "\n", "x_dat", "=", "np", ".", "load", "(", "np_file", ")", "[", "\"x\"", "]", "\n", "if", "x_dat", ".", "shape", "[", "-", "1", "]", "==", "2", ":", "\n", "           ", "X_train", "=", "np", ".", "vstack", "(", "(", "X_train", ",", "x_dat", ")", ")", "\n", "y_train", "=", "np", ".", "append", "(", "y_train", ",", "np", ".", "load", "(", "np_file", ")", "[", "\"y\"", "]", ")", "\n", "", "else", ":", "\n", "           ", "print", "(", "'Deleted'", ")", "\n", "\n", "\n", "", "", "data_save", "=", "dict", "(", ")", "\n", "data_save", "[", "\"samples\"", "]", "=", "torch", ".", "from_numpy", "(", "X_train", ".", "transpose", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "data_save", "[", "\"labels\"", "]", "=", "torch", ".", "from_numpy", "(", "y_train", ")", "\n", "\n", "torch", ".", "save", "(", "data_save", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"val.pt\"", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.__init__": [[76, 78], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "file", ")", ":", "\n", "        ", "self", ".", "file", "=", "file", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_header": [[80, 91], ["shhs_edfreader.edf_header", "numpy.all", "numpy.all"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.edf_header"], ["", "def", "read_header", "(", "self", ")", ":", "\n", "        ", "self", ".", "header", "=", "h", "=", "edf_header", "(", "self", ".", "file", ")", "\n", "\n", "# calculate ranges for rescaling", "\n", "self", ".", "dig_min", "=", "h", "[", "'digital_min'", "]", "\n", "self", ".", "phys_min", "=", "h", "[", "'physical_min'", "]", "\n", "phys_range", "=", "h", "[", "'physical_max'", "]", "-", "h", "[", "'physical_min'", "]", "\n", "dig_range", "=", "h", "[", "'digital_max'", "]", "-", "h", "[", "'digital_min'", "]", "\n", "assert", "np", ".", "all", "(", "phys_range", ">", "0", ")", "\n", "assert", "np", ".", "all", "(", "dig_range", ">", "0", ")", "\n", "self", ".", "gain", "=", "phys_range", "/", "dig_range", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_raw_record": [[93, 104], ["shhs_edfreader.BaseEDFReader.file.read", "result.append", "len"], "methods", ["None"], ["", "def", "read_raw_record", "(", "self", ")", ":", "\n", "        ", "'''Read a record with data_2013 and return a list containing arrays with raw\n        bytes.\n        '''", "\n", "result", "=", "[", "]", "\n", "for", "nsamp", "in", "self", ".", "header", "[", "'n_samples_per_record'", "]", ":", "\n", "            ", "samples", "=", "self", ".", "file", ".", "read", "(", "nsamp", "*", "2", ")", "\n", "if", "len", "(", "samples", ")", "!=", "nsamp", "*", "2", ":", "\n", "                ", "raise", "EDFEndOfData", "\n", "", "result", ".", "append", "(", "samples", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.convert_record": [[106, 129], ["float", "enumerate", "shhs_edfreader.tal", "events.extend", "numpy.fromstring().astype", "signals.append", "numpy.fromstring"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.tal"], ["", "def", "convert_record", "(", "self", ",", "raw_record", ")", ":", "\n", "        ", "'''Convert a raw record to a (time, signals, events) tuple based on\n        information in the header.\n        '''", "\n", "h", "=", "self", ".", "header", "\n", "dig_min", ",", "phys_min", ",", "gain", "=", "self", ".", "dig_min", ",", "self", ".", "phys_min", ",", "self", ".", "gain", "\n", "time", "=", "float", "(", "'nan'", ")", "\n", "signals", "=", "[", "]", "\n", "events", "=", "[", "]", "\n", "for", "(", "i", ",", "samples", ")", "in", "enumerate", "(", "raw_record", ")", ":", "\n", "            ", "if", "h", "[", "'label'", "]", "[", "i", "]", "==", "EVENT_CHANNEL", ":", "\n", "                ", "ann", "=", "tal", "(", "samples", ")", "\n", "time", "=", "ann", "[", "0", "]", "[", "0", "]", "\n", "events", ".", "extend", "(", "ann", "[", "1", ":", "]", ")", "\n", "# print(i, samples)", "\n", "# exit()", "\n", "", "else", ":", "\n", "# 2-byte little-endian integers", "\n", "                ", "dig", "=", "np", ".", "fromstring", "(", "samples", ",", "'<i2'", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "phys", "=", "(", "dig", "-", "dig_min", "[", "i", "]", ")", "*", "gain", "[", "i", "]", "+", "phys_min", "[", "i", "]", "\n", "signals", ".", "append", "(", "phys", ")", "\n", "\n", "", "", "return", "time", ",", "signals", ",", "events", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_record": [[131, 133], ["shhs_edfreader.BaseEDFReader.convert_record", "shhs_edfreader.BaseEDFReader.read_raw_record"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.convert_record", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_raw_record"], ["", "def", "read_record", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "convert_record", "(", "self", ".", "read_raw_record", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.records": [[135, 144], ["shhs_edfreader.BaseEDFReader.read_record"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_record"], ["", "def", "records", "(", "self", ")", ":", "\n", "        ", "'''\n        Record generator.\n        '''", "\n", "try", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "yield", "self", ".", "read_record", "(", ")", "\n", "", "", "except", "EDFEndOfData", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.tal": [[18, 34], ["shhs_edfreader.tal.parse"], "function", ["None"], ["def", "tal", "(", "tal_str", ")", ":", "\n", "    ", "'''Return a list with (onset, duration, annotation) tuples for an EDF+ TAL\n  stream.\n  '''", "\n", "exp", "=", "'(?P<onset>[+\\-]\\d+(?:\\.\\d*)?)'", "+", "'(?:\\x15(?P<duration>\\d+(?:\\.\\d*)?))?'", "+", "'(\\x14(?P<annotation>[^\\x00]*))?'", "+", "'(?:\\x14\\x00)'", "\n", "\n", "def", "annotation_to_list", "(", "annotation", ")", ":", "\n", "        ", "return", "str", "(", "annotation", ".", "encode", "(", "'utf-8'", ")", ")", ".", "split", "(", "'\\x14'", ")", "if", "annotation", "else", "[", "]", "\n", "\n", "", "def", "parse", "(", "dic", ")", ":", "\n", "        ", "return", "(", "\n", "float", "(", "dic", "[", "'onset'", "]", ")", ",", "\n", "float", "(", "dic", "[", "'duration'", "]", ")", "if", "dic", "[", "'duration'", "]", "else", "0.", ",", "\n", "annotation_to_list", "(", "dic", "[", "'annotation'", "]", ")", ")", "\n", "\n", "", "return", "[", "parse", "(", "m", ".", "groupdict", "(", ")", ")", "for", "m", "in", "re", ".", "finditer", "(", "exp", ",", "tal_str", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.edf_header": [[36, 73], ["f.read().strip", "f.read().strip", "str", "int", "float", "int", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "f.read", "f.tell", "f.read", "int", "int", "datetime.datetime", "datetime.datetime.datetime", "f.read", "f.read", "f.read", "f.read", "f.read().strip", "f.read().strip", "f.read().strip", "f.read().strip", "int", "f.read", "f.read", "re.findall", "re.findall", "float", "float", "float", "float", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read"], "function", ["None"], ["", "def", "edf_header", "(", "f", ")", ":", "\n", "    ", "h", "=", "{", "}", "\n", "assert", "f", ".", "tell", "(", ")", "==", "0", "# check file position", "\n", "assert", "f", ".", "read", "(", "8", ")", "==", "'0       '", "\n", "\n", "# recording info)", "\n", "h", "[", "'local_subject_id'", "]", "=", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "\n", "h", "[", "'local_recording_id'", "]", "=", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "\n", "\n", "# parse timestamp", "\n", "(", "day", ",", "month", ",", "year", ")", "=", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "findall", "(", "'(\\d+)'", ",", "f", ".", "read", "(", "8", ")", ")", "]", "\n", "(", "hour", ",", "minute", ",", "sec", ")", "=", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "findall", "(", "'(\\d+)'", ",", "f", ".", "read", "(", "8", ")", ")", "]", "\n", "h", "[", "'date_time'", "]", "=", "str", "(", "datetime", ".", "datetime", "(", "year", "+", "2000", ",", "month", ",", "day", ",", "\n", "hour", ",", "minute", ",", "sec", ")", ")", "\n", "\n", "# misc", "\n", "subtype", "=", "f", ".", "read", "(", "44", ")", "[", ":", "5", "]", "\n", "h", "[", "'EDF+'", "]", "=", "subtype", "in", "[", "'EDF+C'", ",", "'EDF+D'", "]", "\n", "h", "[", "'contiguous'", "]", "=", "subtype", "!=", "'EDF+D'", "\n", "h", "[", "'n_records'", "]", "=", "int", "(", "f", ".", "read", "(", "8", ")", ")", "\n", "h", "[", "'record_length'", "]", "=", "float", "(", "f", ".", "read", "(", "8", ")", ")", "# in seconds", "\n", "nchannels", "=", "h", "[", "'n_channels'", "]", "=", "int", "(", "f", ".", "read", "(", "4", ")", ")", "\n", "\n", "# read channel info", "\n", "channels", "=", "range", "(", "h", "[", "'n_channels'", "]", ")", "\n", "h", "[", "'label'", "]", "=", "[", "f", ".", "read", "(", "16", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'transducer_type'", "]", "=", "[", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'units'", "]", "=", "[", "f", ".", "read", "(", "8", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'physical_min'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'physical_max'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'digital_min'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'digital_max'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'prefiltering'", "]", "=", "[", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'n_samples_per_record'", "]", "=", "[", "int", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", "\n", "f", ".", "read", "(", "32", "*", "nchannels", ")", "# reserved", "\n", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.load_edf": [[146, 208], ["isinstance", "shhs_edfreader.BaseEDFReader", "shhs_edfreader.BaseEDFReader.read_header", "log.debug", "numpy.unique", "zip", "numpy.hstack", "reduce", "collections.namedtuple", "collections.namedtuple.", "float", "numpy.linspace", "numpy.hstack", "open", "shhs_edfreader.load_edf", "shhs_edfreader.BaseEDFReader.records", "numpy.arange", "zip"], "function", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.read_header", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.load_edf", "home.repos.pwc.inspect_result.likith012_muleeg.shhs.shhs_edfreader.BaseEDFReader.records"], ["", "", "", "def", "load_edf", "(", "edffile", ")", ":", "\n", "    ", "'''Load an EDF+ file.\n  Very basic reader for EDF and EDF+ files. While BaseEDFReader does support\n  exotic features like non-homogeneous sample rates and loading only parts of\n  the stream, load_edf expects a single fixed sample rate for all channels and\n  tries to load the whole file.\n  Parameters\n  ----------\n  edffile : file-like object or string\n  Returns\n  -------\n  Named tuple with the fields:\n    X : NumPy array with shape p by n.\n      Raw recording of n samples in p dimensions.\n    sample_rate : float\n      The sample rate of the recording. Note that mixed sample-rates are not\n      supported.\n    sens_lab : list of length p with strings\n      The labels of the sensors used to record X.\n    time : NumPy array with length n\n      The time offset in the recording for each sample.\n    annotations : a list with tuples\n      EDF+ annotations are stored in (start, duration, description) tuples.\n      start : float\n        Indicates the start of the event in seconds.\n      duration : float\n        Indicates the duration of the event in seconds.\n      description : list with strings\n        Contains (multiple?) descriptions of the annotation event.\n  '''", "\n", "if", "isinstance", "(", "edffile", ",", "basestring", ")", ":", "\n", "        ", "with", "open", "(", "edffile", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "return", "load_edf", "(", "f", ")", "# convert filename to file", "\n", "\n", "", "", "reader", "=", "BaseEDFReader", "(", "edffile", ")", "\n", "reader", ".", "read_header", "(", ")", "\n", "\n", "h", "=", "reader", ".", "header", "\n", "log", ".", "debug", "(", "'EDF header: %s'", "%", "h", ")", "\n", "\n", "# get sample rate info", "\n", "nsamp", "=", "np", ".", "unique", "(", "\n", "[", "n", "for", "(", "l", ",", "n", ")", "in", "zip", "(", "h", "[", "'label'", "]", ",", "h", "[", "'n_samples_per_record'", "]", ")", "\n", "if", "l", "!=", "EVENT_CHANNEL", "]", ")", "\n", "assert", "nsamp", ".", "size", "==", "1", ",", "'Multiple sample rates not supported!'", "\n", "sample_rate", "=", "float", "(", "nsamp", "[", "0", "]", ")", "/", "h", "[", "'record_length'", "]", "\n", "\n", "rectime", ",", "X", ",", "annotations", "=", "zip", "(", "*", "reader", ".", "records", "(", ")", ")", "\n", "X", "=", "np", ".", "hstack", "(", "X", ")", "\n", "annotations", "=", "reduce", "(", "operator", ".", "add", ",", "annotations", ")", "\n", "chan_lab", "=", "[", "lab", "for", "lab", "in", "reader", ".", "header", "[", "'label'", "]", "if", "lab", "!=", "EVENT_CHANNEL", "]", "\n", "\n", "# create timestamps", "\n", "if", "reader", ".", "header", "[", "'contiguous'", "]", ":", "\n", "        ", "time", "=", "np", ".", "arange", "(", "X", ".", "shape", "[", "1", "]", ")", "/", "sample_rate", "\n", "", "else", ":", "\n", "        ", "reclen", "=", "reader", ".", "header", "[", "'record_length'", "]", "\n", "within_rec_time", "=", "np", ".", "linspace", "(", "0", ",", "reclen", ",", "nsamp", ",", "endpoint", "=", "False", ")", "\n", "time", "=", "np", ".", "hstack", "(", "[", "t", "+", "within_rec_time", "for", "t", "in", "rectime", "]", ")", "\n", "\n", "", "tup", "=", "namedtuple", "(", "'EDF'", ",", "'X sample_rate chan_lab time annotations'", ")", "\n", "return", "tup", "(", "X", ",", "sample_rate", ",", "chan_lab", ",", "time", ",", "annotations", ")", "", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.shhs.preprocess_shhs.main": [[13, 126], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv", "ids[].values.tolist", "np.asarray.sort", "np.asarray.sort", "numpy.asarray", "numpy.asarray", "range", "os.listdir", "numpy.array", "np.array.sort", "generate_shhs.gen_shhs", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.join", "os.path.join", "len", "os.path.exists", "print", "mne.io.read_raw_edf", "sorted", "print", "print", "raw_ch_df.set_index", "xml.parse", "ET.parse.getroot", "range", "numpy.asarray", "print", "numpy.asarray().astype", "np.asarray.astype", "print", "print", "numpy.arange", "print", "print", "os.path.basename().replace", "numpy.savez", "print", "sorted.split", "mne.io.read_raw_edf.to_data_frame", "numpy.arange", "len", "int", "print", "Exception", "len", "len", "len", "numpy.where", "len", "os.path.join", "os.path.join", "len", "np.asarray.append", "len", "numpy.asarray", "len", "os.path.basename", "os.path.join", "np.asarray.append", "np.asarray.append", "numpy.split", "edf_fnames[].split"], "function", ["home.repos.pwc.inspect_result.likith012_muleeg.shhs.generate_shhs.gen_shhs"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./shhs\"", ",", "help", "=", "\"Path to the data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_path\"", ",", "type", "=", "str", ",", "default", "=", "\"./shhs\"", ",", "help", "=", "\"Path to save preprocessed data\"", ")", "\n", "\n", "EPOCH_SEC_SIZE", "=", "30", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"/edfs/\"", ")", "\n", "ann_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"/annots/\"", ")", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"/mid_level_data/\"", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "\"/data/\"", ")", "\n", "\n", "csv_path", "=", "r\"./selected_shhs1_files.txt\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "output_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "\n", "", "ids", "=", "pd", ".", "read_csv", "(", "csv_path", ",", "header", "=", "None", ")", "\n", "ids", "=", "ids", "[", "0", "]", ".", "values", ".", "tolist", "(", ")", "\n", "\n", "edf_fnames", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "i", "+", "\".edf\"", ")", "for", "i", "in", "ids", "]", "\n", "ann_fnames", "=", "[", "os", ".", "path", ".", "join", "(", "ann_dir", ",", "i", "+", "\"-profusion.xml\"", ")", "for", "i", "in", "ids", "]", "\n", "\n", "edf_fnames", ".", "sort", "(", ")", "\n", "ann_fnames", ".", "sort", "(", ")", "\n", "\n", "edf_fnames", "=", "np", ".", "asarray", "(", "edf_fnames", ")", "\n", "ann_fnames", "=", "np", ".", "asarray", "(", "ann_fnames", ")", "\n", "\n", "for", "file_id", "in", "range", "(", "len", "(", "edf_fnames", ")", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "edf_fnames", "[", "file_id", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "[", ":", "-", "4", "]", "+", "\".npz\"", ")", ":", "\n", "            ", "continue", "\n", "", "print", "(", "edf_fnames", "[", "file_id", "]", ")", "\n", "select_ch", "=", "'EEG C4-A1'", "\n", "raw", "=", "read_raw_edf", "(", "edf_fnames", "[", "file_id", "]", ",", "preload", "=", "True", ",", "stim_channel", "=", "None", ",", "verbose", "=", "None", ")", "\n", "sampling_rate", "=", "raw", ".", "info", "[", "'sfreq'", "]", "\n", "ch_type", "=", "select_ch", ".", "split", "(", "\" \"", ")", "[", "0", "]", "# selecting EEG out of 'EEG C4-A1'", "\n", "select_ch", "=", "sorted", "(", "[", "s", "for", "s", "in", "raw", ".", "info", "[", "\"ch_names\"", "]", "if", "ch_type", "in", "s", "]", ")", "# this has 2 vals [EEG,EEG(sec)] and selecting 0th index", "\n", "print", "(", "select_ch", ")", "\n", "raw_ch_df", "=", "raw", ".", "to_data_frame", "(", "scalings", "=", "sampling_rate", ")", "[", "select_ch", "]", "\n", "print", "(", "raw_ch_df", ".", "shape", ")", "\n", "raw_ch_df", ".", "set_index", "(", "np", ".", "arange", "(", "len", "(", "raw_ch_df", ")", ")", ")", "\n", "\n", "labels", "=", "[", "]", "\n", "t", "=", "ET", ".", "parse", "(", "ann_fnames", "[", "file_id", "]", ")", "\n", "r", "=", "t", ".", "getroot", "(", ")", "\n", "faulty_File", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "r", "[", "4", "]", ")", ")", ":", "\n", "            ", "lbl", "=", "int", "(", "r", "[", "4", "]", "[", "i", "]", ".", "text", ")", "\n", "if", "lbl", "==", "4", ":", "# make stages N3, N4 same as N3", "\n", "                ", "labels", ".", "append", "(", "3", ")", "\n", "", "elif", "lbl", "==", "5", ":", "# Assign label 4 for REM stage", "\n", "                ", "labels", ".", "append", "(", "4", ")", "\n", "", "else", ":", "\n", "                ", "labels", ".", "append", "(", "lbl", ")", "\n", "", "if", "lbl", ">", "5", ":", "# some files may contain labels > 5 BUT not the selected ones.", "\n", "                ", "faulty_File", "=", "1", "\n", "\n", "", "", "if", "faulty_File", "==", "1", ":", "\n", "            ", "print", "(", "\"============================== Faulty file ==================\"", ")", "\n", "continue", "\n", "\n", "", "labels", "=", "np", ".", "asarray", "(", "labels", ")", "\n", "\n", "# Remove movement and unknown stages if any", "\n", "raw_ch", "=", "raw_ch_df", ".", "values", "\n", "print", "(", "raw_ch", ".", "shape", ")", "\n", "\n", "# Verify that we can split into 30-s epochs", "\n", "if", "len", "(", "raw_ch", ")", "%", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Something wrong\"", ")", "\n", "", "n_epochs", "=", "len", "(", "raw_ch", ")", "/", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", "\n", "\n", "# Get epochs and their corresponding labels", "\n", "x", "=", "np", ".", "asarray", "(", "np", ".", "split", "(", "raw_ch", ",", "n_epochs", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "y", "=", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "print", "(", "x", ".", "shape", ")", "\n", "print", "(", "y", ".", "shape", ")", "\n", "assert", "len", "(", "x", ")", "==", "len", "(", "y", ")", "\n", "\n", "# Select on sleep periods", "\n", "w_edge_mins", "=", "30", "\n", "nw_idx", "=", "np", ".", "where", "(", "y", "!=", "0", ")", "[", "0", "]", "\n", "start_idx", "=", "nw_idx", "[", "0", "]", "-", "(", "w_edge_mins", "*", "2", ")", "\n", "end_idx", "=", "nw_idx", "[", "-", "1", "]", "+", "(", "w_edge_mins", "*", "2", ")", "\n", "if", "start_idx", "<", "0", ":", "start_idx", "=", "0", "\n", "if", "end_idx", ">=", "len", "(", "y", ")", ":", "end_idx", "=", "len", "(", "y", ")", "-", "1", "\n", "select_idx", "=", "np", ".", "arange", "(", "start_idx", ",", "end_idx", "+", "1", ")", "\n", "print", "(", "\"Data before selection: {}, {}\"", ".", "format", "(", "x", ".", "shape", ",", "y", ".", "shape", ")", ")", "\n", "x", "=", "x", "[", "select_idx", "]", "\n", "y", "=", "y", "[", "select_idx", "]", "\n", "print", "(", "\"Data after selection: {}, {}\"", ".", "format", "(", "x", ".", "shape", ",", "y", ".", "shape", ")", ")", "\n", "\n", "# Saving as numpy files", "\n", "filename", "=", "os", ".", "path", ".", "basename", "(", "edf_fnames", "[", "file_id", "]", ")", ".", "replace", "(", "\".edf\"", ",", "\".npz\"", ")", "\n", "save_dict", "=", "{", "\n", "\"x\"", ":", "x", ",", "\n", "\"y\"", ":", "y", ",", "\n", "\"fs\"", ":", "sampling_rate", "\n", "}", "\n", "np", ".", "savez", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "filename", ")", ",", "**", "save_dict", ")", "\n", "print", "(", "\" ---------- Done this file ---------\"", ")", "\n", "\n", "", "files", "=", "os", ".", "listdir", "(", "output_dir", ")", "\n", "files", "=", "np", ".", "array", "(", "[", "os", ".", "path", ".", "join", "(", "output_dir", ",", "i", ")", "for", "i", "in", "files", "]", ")", "\n", "files", ".", "sort", "(", ")", "\n", "\n", "gen_shhs", "(", "files", ",", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.add_noise": [[30, 57], ["len", "numpy.linspace", "numpy.linspace", "scipy.interpolate.interp1d", "scipy.interpolate.interp1d.", "numpy.ptp", "numpy.random.rand", "numpy.random.rand"], "function", ["None"], ["def", "add_noise", "(", "x", ":", "torch", ".", "Tensor", ",", "degree", ":", "float", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Adds low-frequency and high-frequency noise to the EEG signal.\n\n    Parameters\n    ----------\n    x: torch.Tensor\n        Input EEG signals.\n    degree: float\n        Degree of low and high frequency noise to be added.     \n\n    Returns\n    -------\n    torch.Tensor\n        Augmented EEG signals.\n    \"\"\"", "\n", "\n", "len_x", "=", "len", "(", "x", ")", "\n", "num_range", "=", "np", ".", "ptp", "(", "x", ")", "+", "1e-4", "# add a small number for flat signal", "\n", "\n", "noise_high_frequency", "=", "degree", "*", "num_range", "*", "(", "2.0", "*", "np", ".", "random", ".", "rand", "(", "len_x", ")", "-", "1", ")", "\n", "noise_low_frequency", "=", "degree", "*", "num_range", "*", "(", "2.0", "*", "np", ".", "random", ".", "rand", "(", "len_x", "//", "100", ")", "-", "1", ")", "\n", "x_old", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "num", "=", "len_x", "//", "100", ",", "endpoint", "=", "True", ")", "\n", "x_new", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "num", "=", "len_x", ",", "endpoint", "=", "True", ")", "\n", "interpolation", "=", "interp1d", "(", "x_old", ",", "noise_low_frequency", ",", "kind", "=", "\"linear\"", ")", "\n", "noise2", "=", "interpolation", "(", "x_new", ")", "\n", "out_x", "=", "x", "+", "noise_low_frequency", "+", "noise_high_frequency", "\n", "return", "out_x", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.jitter": [[59, 83], ["range", "numpy.vstack", "torch.from_numpy", "torch.from_numpy.append", "augmentations.add_noise"], "function", ["home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.add_noise"], ["", "def", "jitter", "(", "x", ":", "torch", ".", "Tensor", ",", "config", ",", "degree", ":", "float", "=", "1.0", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Applies random uniform noise to the EEG signal.\n\n    Parameters\n    ----------\n    x: torch.Tensor\n        Input EEG signals.\n    config\n        Configuration object.\n    degree: float, optional\n        Degree of uniform noise to be added.\n\n    Returns\n    -------\n    torch.Tensor\n        Augmented EEG signals.\n    \"\"\"", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "ch", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "ret", ".", "append", "(", "add_noise", "(", "x", "[", "ch", "]", ",", "config", ".", "degree", "*", "degree", ")", ")", "\n", "", "ret", "=", "np", ".", "vstack", "(", "ret", ")", "\n", "ret", "=", "torch", ".", "from_numpy", "(", "ret", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.scaling": [[85, 111], ["numpy.zeros_like", "range", "torch.from_numpy", "numpy.random.rand", "numpy.random.normal", "numpy.random.rand"], "function", ["None"], ["", "def", "scaling", "(", "x", ":", "torch", ".", "Tensor", ",", "config", ",", "degree", ":", "float", "=", "2.0", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Applies Gaussian noise to the EEG signal.\n\n    Parameters\n    ----------\n     x: torch.Tensor\n        Input EEG signals.\n    config\n        Configuration object.\n    degree: float, optional\n        Degree of Gaussian noise to be added.\n\n    Returns\n    -------\n    torch.Tensor\n        Augmented EEG signals.\n    \"\"\"", "\n", "\n", "ret", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "degree", "=", "config", ".", "degree", "*", "(", "degree", "+", "np", ".", "random", ".", "rand", "(", ")", ")", "\n", "factor", "=", "2.0", "*", "np", ".", "random", ".", "normal", "(", "size", "=", "x", ".", "shape", "[", "1", "]", ")", "-", "1", "\n", "factor", "=", "1.5", "+", "(", "2.0", "*", "np", ".", "random", ".", "rand", "(", ")", ")", "+", "degree", "*", "factor", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "ret", "[", "i", "]", "=", "x", "[", "i", "]", "*", "factor", "\n", "", "ret", "=", "torch", ".", "from_numpy", "(", "ret", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.masking": [[113, 138], ["numpy.random.randint", "x.detach().clone", "enumerate", "int", "x.detach", "numpy.random.rand"], "function", ["None"], ["", "def", "masking", "(", "x", ":", "torch", ".", "Tensor", ",", "config", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Masks a single segment of the EEG signal randomly.\n\n    Parameters\n    ----------\n    x: torch.Tensor\n        Input EEG signals.\n    config\n        Configuration object.\n\n    Returns\n    -------\n    torch.Tensor\n        Augmented EEG signals.\n    \"\"\"", "\n", "\n", "segments", "=", "config", ".", "mask_min_points", "+", "int", "(", "\n", "np", ".", "random", ".", "rand", "(", ")", "*", "(", "config", ".", "mask_max_points", "-", "config", ".", "mask_min_points", ")", "\n", ")", "\n", "points", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "3000", "-", "segments", ")", "\n", "ret", "=", "x", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "x", ")", ":", "\n", "        ", "ret", "[", "i", ",", "points", ":", "points", "+", "segments", "]", "=", "0", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.multi_masking": [[140, 178], ["range", "numpy.random.randint", "x.clone", "enumerate", "int", "fin_masks.append", "range", "numpy.random.rand", "int", "numpy.random.rand"], "function", ["None"], ["", "def", "multi_masking", "(", "\n", "x", ":", "np", ".", "ndarray", ",", "\n", "mask_min", ":", "int", "=", "40", ",", "\n", "mask_max", ":", "int", "=", "10", ",", "\n", "min_seg", ":", "int", "=", "8", ",", "\n", "max_seg", ":", "int", "=", "14", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Masks multiple segments of the EEG signal randomly.\n\n    Parameters\n    ----------\n    x: torch.Tensor\n        Input EEG signals.\n    mask_min: int, optional\n        Minimum number of points to be masked in a segment.\n    mask_max: int, optional\n        Maximum number of points to be masked in a segment.\n    min_seg: int, optional\n        Minimum number of points segments.\n    max_seg: int, optional\n        Maximum number of points segments.\n\n    Returns\n    -------\n    torch.Tensor\n        Augmented EEG signals.\n    \"\"\"", "\n", "\n", "fin_masks", "=", "[", "]", "\n", "segments", "=", "min_seg", "+", "int", "(", "np", ".", "random", ".", "rand", "(", ")", "*", "(", "max_seg", "-", "min_seg", ")", ")", "\n", "for", "seg", "in", "range", "(", "segments", ")", ":", "\n", "        ", "fin_masks", ".", "append", "(", "mask_min", "+", "int", "(", "np", ".", "random", ".", "rand", "(", ")", "*", "(", "mask_max", "-", "mask_min", ")", ")", ")", "\n", "", "points", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "3000", "-", "segments", ",", "size", "=", "segments", ")", "\n", "ret", "=", "x", ".", "clone", "(", ")", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "x", ")", ":", "\n", "        ", "for", "seg", "in", "range", "(", "segments", ")", ":", "\n", "            ", "ret", "[", "i", ",", "points", "[", "seg", "]", ":", "points", "[", "seg", "]", "+", "fin_masks", "[", "seg", "]", "]", "=", "0", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.flip": [[180, 199], ["numpy.random.rand", "torch.tensor", "numpy.flip().copy", "numpy.flip", "x.numpy"], "function", ["home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.flip"], ["", "def", "flip", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Flips the input EEG Signal.\n\n    Parameters\n    ----------\n    inputs: torch.Tensor\n        Input EEG signal.\n\n    Returns\n    -------\n    torch.Tensor\n        Flipped EEG signal.\n\n    \"\"\"", "\n", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "0.5", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "np", ".", "flip", "(", "x", ".", "numpy", "(", ")", ",", "1", ")", ".", "copy", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.augment": [[201, 230], ["augmentations.scaling", "augmentations.masking", "augmentations.multi_masking", "augmentations.flip", "augmentations.jitter", "augmentations.jitter"], "function", ["home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.scaling", "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.masking", "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.multi_masking", "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.flip", "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.jitter", "home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.jitter"], ["", "", "def", "augment", "(", "\n", "x", ":", "torch", ".", "Tensor", ",", "config", ",", "masking_type", ":", "Optional", "[", "str", "]", "=", "None", ",", "degree", ":", "float", "=", "3.0", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Applies strong and weak kind of augmentations on the EEG Signal.\n\n    Parameters\n    ----------\n    inputs: torch.tensor\n        Input EEG signal.\n    config\n        Configuration object.\n    masking_type: str, optional\n        Type of masking to be applied.\n    degree: float, optional\n        Degree of noise to be added.\n\n    Returns\n    -------\n    Tuple[torch.Tensor, torch.Tensor]\n       Two different augmented views of the input EEG Signal.\n\n    \"\"\"", "\n", "\n", "if", "masking_type", "is", "None", ":", "\n", "        ", "weak_augment", "=", "masking", "(", "jitter", "(", "x", ",", "config", ")", ",", "config", ")", "\n", "", "else", ":", "\n", "        ", "weak_augment", "=", "multi_masking", "(", "jitter", "(", "x", ",", "config", ")", ",", "config", ")", "\n", "", "strong_augment", "=", "scaling", "(", "flip", "(", "x", ",", "config", ")", ",", "config", ",", "degree", "=", "degree", ")", "\n", "return", "weak_augment", ",", "strong_augment", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.dataloader.Load_Dataset.__init__": [[50, 83], ["torch.utils.data.Dataset.__init__", "[].unsqueeze", "isinstance", "isinstance", "len", "X_train.permute.permute.unsqueeze", "X_train.permute.permute.shape.index", "X_train.permute.permute.permute", "torch.from_numpy", "torch.from_numpy().long", "min", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "config", ":", "Type", "[", "Config", "]", ",", "\n", "training_mode", ":", "str", "=", "\"self_supervised\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "Load_Dataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "X_train", "=", "dataset", "[", "\"samples\"", "]", "[", ":", ",", "0", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "y_train", "=", "dataset", "[", "\"labels\"", "]", "\n", "\n", "# checking the shape of the data", "\n", "if", "len", "(", "X_train", ".", "shape", ")", "<", "3", ":", "\n", "            ", "X_train", "=", "X_train", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# make sure the channels are in second dim", "\n", "", "if", "X_train", ".", "shape", ".", "index", "(", "min", "(", "X_train", ".", "shape", ")", ")", "!=", "1", ":", "\n", "            ", "X_train", "=", "X_train", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "# checking for the instance of the dataset", "\n", "", "if", "isinstance", "(", "X_train", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "self", ".", "x_data", "=", "torch", ".", "from_numpy", "(", "X_train", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "x_data", "=", "X_train", "\n", "\n", "", "if", "isinstance", "(", "y_train", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "self", ".", "y_data", "=", "torch", ".", "from_numpy", "(", "y_train", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "y_data", "=", "y_train", "\n", "\n", "", "self", ".", "len", "=", "X_train", ".", "shape", "[", "0", "]", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "training_mode", "=", "training_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.dataloader.Load_Dataset.__getitem__": [[84, 100], ["utils.augmentations.augment", "isinstance", "isinstance", "torch.from_numpy", "torch.from_numpy", "dataloader.Load_Dataset.x_data[].float"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.utils.augmentations.augment"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\" Returns indexed data and labels depending on the training mode.\"\"\"", "\n", "\n", "if", "self", ".", "training_mode", "==", "\"self_supervised\"", ":", "\n", "# get the augmented data for the pretraining", "\n", "            ", "weak_data", ",", "strong_data", "=", "augment", "(", "self", ".", "x_data", "[", "index", "]", ",", "self", ".", "config", ")", "\n", "\n", "if", "isinstance", "(", "weak_data", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "weak_data", "=", "torch", ".", "from_numpy", "(", "weak_data", ")", "\n", "", "if", "isinstance", "(", "strong_data", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "strong_data", "=", "torch", ".", "from_numpy", "(", "strong_data", ")", "\n", "\n", "", "return", "weak_data", ",", "strong_data", "\n", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "x_data", "[", "index", "]", ".", "float", "(", ")", ",", "self", ".", "y_data", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.dataloader.Load_Dataset.__len__": [[101, 105], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\" Returns the length of the dataset.\"\"\"", "\n", "\n", "return", "self", ".", "len", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.dataloader.data_generator": [[107, 138], ["torch.load", "dataloader.Load_Dataset", "torch.utils.data.DataLoader", "os.path.join"], "function", ["None"], ["", "", "def", "data_generator", "(", "data_path", ":", "str", ",", "config", ":", "Type", "[", "Config", "]", ")", "->", "Type", "[", "DataLoader", "]", ":", "\n", "\n", "    ", "\"\"\" Generates a dataloader for the dataset.\n\n    Parameters\n    ----------\n    data_path: str\n        A string indicating the path to the dataset.\n    config: Config Object\n        Configuration object specifying the model hyperparameters.\n\n    Returns\n    -------\n    Type[DataLoader]\n        DataLoader object for the given dataset.\n    \"\"\"", "\n", "\n", "train_dataset", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"pretext.pt\"", ")", ")", "\n", "\n", "train_dataset", "=", "Load_Dataset", "(", "train_dataset", ",", "config", ")", "\n", "train_loader", "=", "DataLoader", "(", "\n", "dataset", "=", "train_dataset", ",", "\n", "batch_size", "=", "config", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "drop_last", "=", "config", ".", "drop_last", ",", "\n", "num_workers", "=", "10", ",", "\n", "pin_memory", "=", "True", ",", "\n", "persistent_workers", "=", "True", ",", "\n", ")", "\n", "\n", "return", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.utils.dataloader.cross_data_generator": [[140, 259], ["torch.load", "[].unsqueeze", "torch.load", "[].unsqueeze", "os.path.join", "os.path.join", "torch.from_numpy", "torch.from_numpy", "torch.split", "torch.split", "print", "torch.cat", "torch.cat", "dataloader.Load_Dataset", "torch.cat", "torch.cat", "dataloader.Load_Dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "len", "numpy.vstack", "numpy.hstack", "len"], "function", ["None"], ["", "def", "cross_data_generator", "(", "\n", "data_path", ":", "str", ",", "train_idxs", ":", "list", ",", "val_idxs", ":", "list", ",", "config", ":", "Type", "[", "Config", "]", "\n", ")", "->", "Union", "[", "Tuple", "[", "Type", "[", "DataLoader", "]", ",", "...", "]", ",", "int", "]", ":", "\n", "    ", "\"\"\" Generates a k-fold dataloader for the given dataset. \n\n    Here the splits are made depending on the subject id, to make sure that there is no data leakage.\n\n    Parameters\n    ----------\n    data_path: str\n        Data path to the dataset.\n    train_idxs: list\n       Contains the indices of the training data.\n    val_idxs: list\n        Contains the indices of the validation data.\n    config: Type[Config]\n        An object containing the hyperparameters.\n\n    Returns\n    -------\n    Union[Tuple[Type[DataLoader], ...], int]\n        DataLoader object for the training and validation data.\n\n    \"\"\"", "\n", "\n", "train_ds", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"train.pt\"", ")", ")", "\n", "train_ds", "[", "\"samples\"", "]", "=", "train_ds", "[", "\"samples\"", "]", "[", ":", ",", "0", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "valid_ds", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"val.pt\"", ")", ")", "\n", "valid_ds", "[", "\"samples\"", "]", "=", "valid_ds", "[", "\"samples\"", "]", "[", ":", ",", "0", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "\"\"\"\n    train_subs : list of subjects for training; this list depends on the seed set during the preprocessing\n        with the default seed that we are using these are the subjects present in the training split\n\n    train_segs : list of number of epochs of EEG data present in each subject of the train_subs list  \n    \"\"\"", "\n", "\n", "train_subs", "=", "[", "48", ",", "72", ",", "24", ",", "30", ",", "34", ",", "50", ",", "38", ",", "15", ",", "60", ",", "12", "]", "\n", "train_segs", "=", "[", "3937", ",", "2161", ",", "3448", ",", "1783", ",", "3083", ",", "2429", ",", "3647", ",", "2714", ",", "3392", ",", "2029", "]", "\n", "\n", "\"\"\"\n    val_subs : list of subjects for validation; this list depends on the seed set during the preprocessing\n\n    val_segs : list of number of epochs of EEG data present in each subject of the val_subs list\n    \"\"\"", "\n", "\n", "val_subs", "=", "[", "23", ",", "26", ",", "37", ",", "44", ",", "49", ",", "51", ",", "54", ",", "59", ",", "73", ",", "82", "]", "\n", "val_segs", "=", "[", "2633", ",", "2577", ",", "2427", ",", "2287", ",", "2141", ",", "2041", ",", "2864", ",", "3071", ",", "4985", ",", "3070", "]", "\n", "\n", "segs", "=", "train_segs", "+", "val_segs", "\n", "\n", "if", "train_idxs", "!=", "[", "]", ":", "\n", "\n", "        ", "dataset", "=", "{", "}", "\n", "train_dataset", "=", "{", "}", "\n", "valid_dataset", "=", "{", "}", "\n", "\n", "# combine both training and validation data", "\n", "dataset", "[", "\"samples\"", "]", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "vstack", "(", "(", "train_ds", "[", "\"samples\"", "]", ",", "valid_ds", "[", "\"samples\"", "]", ")", ")", "\n", ")", "\n", "dataset", "[", "\"labels\"", "]", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "hstack", "(", "(", "train_ds", "[", "\"labels\"", "]", ",", "valid_ds", "[", "\"labels\"", "]", ")", ")", "\n", ")", "\n", "\n", "# split the data depending on the subject id", "\n", "dataset", "[", "\"samples\"", "]", "=", "torch", ".", "split", "(", "dataset", "[", "\"samples\"", "]", ",", "segs", ")", "\n", "dataset", "[", "\"labels\"", "]", "=", "torch", ".", "split", "(", "dataset", "[", "\"labels\"", "]", ",", "segs", ")", "\n", "print", "(", "\"Split Shape\"", ",", "len", "(", "dataset", "[", "\"samples\"", "]", ")", ")", "\n", "\n", "# create split for training", "\n", "train_dataset", "[", "\"samples\"", "]", "=", "[", "dataset", "[", "\"samples\"", "]", "[", "i", "]", "for", "i", "in", "train_idxs", "]", "\n", "train_dataset", "[", "\"labels\"", "]", "=", "[", "dataset", "[", "\"labels\"", "]", "[", "i", "]", "for", "i", "in", "train_idxs", "]", "\n", "\n", "train_dataset", "[", "\"samples\"", "]", "=", "torch", ".", "cat", "(", "train_dataset", "[", "\"samples\"", "]", ")", "\n", "train_dataset", "[", "\"labels\"", "]", "=", "torch", ".", "cat", "(", "train_dataset", "[", "\"labels\"", "]", ")", "\n", "train_dataset", "=", "Load_Dataset", "(", "train_dataset", ",", "config", ",", "training_mode", "=", "\"ft\"", ")", "\n", "\n", "# create split for validation", "\n", "valid_dataset", "[", "\"samples\"", "]", "=", "[", "dataset", "[", "\"samples\"", "]", "[", "i", "]", "for", "i", "in", "val_idxs", "]", "\n", "valid_dataset", "[", "\"labels\"", "]", "=", "[", "dataset", "[", "\"labels\"", "]", "[", "i", "]", "for", "i", "in", "val_idxs", "]", "\n", "\n", "valid_dataset", "[", "\"samples\"", "]", "=", "torch", ".", "cat", "(", "valid_dataset", "[", "\"samples\"", "]", ")", "\n", "valid_dataset", "[", "\"labels\"", "]", "=", "torch", ".", "cat", "(", "valid_dataset", "[", "\"labels\"", "]", ")", "\n", "valid_dataset", "=", "Load_Dataset", "(", "valid_dataset", ",", "config", ",", "training_mode", "=", "\"ft\"", ")", "\n", "\n", "# create training dataloader", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "train_dataset", ",", "\n", "batch_size", "=", "config", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "drop_last", "=", "config", ".", "drop_last", ",", "\n", "num_workers", "=", "10", ",", "\n", "pin_memory", "=", "True", ",", "\n", "persistent_workers", "=", "True", ",", "\n", ")", "\n", "\n", "# create validation dataloader", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "valid_dataset", ",", "\n", "batch_size", "=", "config", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "drop_last", "=", "config", ".", "drop_last", ",", "\n", "num_workers", "=", "10", ",", "\n", "pin_memory", "=", "True", ",", "\n", "persistent_workers", "=", "True", ",", "\n", ")", "\n", "\n", "del", "dataset", "\n", "del", "train_dataset", "\n", "del", "valid_dataset", "\n", "\n", "return", "train_loader", ",", "valid_loader", "\n", "\n", "", "ret", "=", "len", "(", "val_subs", ")", "+", "len", "(", "train_subs", ")", "\n", "del", "train_ds", "\n", "del", "valid_ds", "\n", "\n", "return", "ret", "\n", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.models.spectrogram_model.ResBlock.__init__": [[41, 68], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "stride", ":", "int", "=", "1", ",", "\n", "downsample", ":", "bool", "=", "False", ",", "\n", "pooling", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "ResBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", "\n", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "out_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", "\n", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", ")", "\n", "self", ".", "downsampleOrNot", "=", "downsample", "\n", "self", ".", "pooling", "=", "pooling", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.spectrogram_model.ResBlock.forward": [[69, 87], ["spectrogram_model.ResBlock.conv1", "spectrogram_model.ResBlock.bn1", "spectrogram_model.ResBlock.relu", "spectrogram_model.ResBlock.conv2", "spectrogram_model.ResBlock.bn2", "spectrogram_model.ResBlock.dropout", "spectrogram_model.ResBlock.downsample", "spectrogram_model.ResBlock.maxpool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" Forward pass of the block.\"\"\"", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsampleOrNot", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "out", "+=", "residual", "\n", "\n", "if", "self", ".", "pooling", ":", "\n", "            ", "out", "=", "self", ".", "maxpool", "(", "out", ")", "\n", "", "out", "=", "self", ".", "dropout", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.spectrogram_model.CNNEncoder2D_SLEEP.__init__": [[110, 127], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "spectrogram_model.ResBlock", "spectrogram_model.ResBlock", "spectrogram_model.ResBlock", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ELU", "torch.ELU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "n_dim", ":", "int", ")", "->", "None", ":", "\n", "        ", "super", "(", "CNNEncoder2D_SLEEP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "2", ",", "6", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "6", ")", ",", "\n", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "self", ".", "conv2", "=", "ResBlock", "(", "6", ",", "8", ",", "2", ",", "True", ",", "False", ")", "\n", "self", ".", "conv3", "=", "ResBlock", "(", "8", ",", "16", ",", "2", ",", "True", ",", "True", ")", "\n", "self", ".", "conv4", "=", "ResBlock", "(", "16", ",", "32", ",", "2", ",", "True", ",", "True", ")", "\n", "self", ".", "n_dim", "=", "n_dim", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "128", ",", "self", ".", "n_dim", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "n_dim", ",", "self", ".", "n_dim", ",", "bias", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.spectrogram_model.CNNEncoder2D_SLEEP.torch_stft": [[129, 154], ["range", "[].permute", "[].permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "signal.append", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "torch_stft", "(", "self", ",", "X_train", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" Compute the STFT of the input.\"\"\"", "\n", "\n", "signal", "=", "[", "]", "\n", "\n", "for", "s", "in", "range", "(", "X_train", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "spectral", "=", "torch", ".", "stft", "(", "\n", "X_train", "[", ":", ",", "s", ",", ":", "]", ",", "\n", "n_fft", "=", "256", ",", "\n", "hop_length", "=", "256", "*", "1", "//", "4", ",", "\n", "center", "=", "False", ",", "\n", "onesided", "=", "True", ",", "\n", "return_complex", "=", "False", ",", "\n", ")", "\n", "signal", ".", "append", "(", "spectral", ")", "\n", "\n", "", "signal1", "=", "torch", ".", "stack", "(", "signal", ")", "[", ":", ",", ":", ",", ":", ",", ":", ",", "0", "]", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "signal2", "=", "torch", ".", "stack", "(", "signal", ")", "[", ":", ",", ":", ",", ":", ",", ":", ",", "1", "]", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "\n", "[", "\n", "torch", ".", "log", "(", "torch", ".", "abs", "(", "signal1", ")", "+", "1e-8", ")", ",", "\n", "torch", ".", "log", "(", "torch", ".", "abs", "(", "signal2", ")", "+", "1e-8", ")", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.spectrogram_model.CNNEncoder2D_SLEEP.forward": [[156, 169], ["spectrogram_model.CNNEncoder2D_SLEEP.torch_stft", "spectrogram_model.CNNEncoder2D_SLEEP.conv1", "spectrogram_model.CNNEncoder2D_SLEEP.conv2", "spectrogram_model.CNNEncoder2D_SLEEP.conv3", "spectrogram_model.CNNEncoder2D_SLEEP.conv4", "spectrogram_model.CNNEncoder2D_SLEEP.reshape", "spectrogram_model.CNNEncoder2D_SLEEP.fc"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.spectrogram_model.CNNEncoder2D_SLEEP.torch_stft"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" Forward pass of the block.\"\"\"", "\n", "\n", "x", "=", "self", ".", "torch_stft", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.encoder.__init__": [[27, 33], ["torch.Module.__init__", "resnet1d.BaseNet", "model.attention", "spectrogram_model.CNNEncoder2D_SLEEP"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "Type", "[", "Config", "]", ")", ":", "\n", "        ", "super", "(", "encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "time_model", "=", "BaseNet", "(", ")", "\n", "self", ".", "attention", "=", "attention", "(", "config", ")", "\n", "\n", "self", ".", "spect_model", "=", "CNNEncoder2D_SLEEP", "(", "256", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.encoder.forward": [[34, 43], ["model.encoder.time_model", "model.encoder.attention", "model.encoder.spect_model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "time", "=", "self", ".", "time_model", "(", "x", ")", "\n", "\n", "time_feats", "=", "self", ".", "attention", "(", "time", ")", "\n", "\n", "spect_feats", "=", "self", ".", "spect_model", "(", "x", ")", "\n", "\n", "return", "time_feats", ",", "spect_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.attention.__init__": [[57, 63], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "att_dim", "=", "256", "\n", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "256", ",", "self", ".", "att_dim", ")", ")", "\n", "self", ".", "V", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "att_dim", ",", "1", ")", ")", "\n", "self", ".", "scale", "=", "self", ".", "att_dim", "**", "-", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.attention.forward": [[64, 74], ["torch.sum.permute", "torch.sum.permute", "torch.sum.permute", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "e", "=", "torch", ".", "matmul", "(", "x", ",", "self", ".", "W", ")", "\n", "e", "=", "torch", ".", "matmul", "(", "torch", ".", "tanh", "(", "e", ")", ",", "self", ".", "V", ")", "\n", "e", "=", "e", "*", "self", ".", "scale", "\n", "n1", "=", "torch", ".", "exp", "(", "e", ")", "\n", "n2", "=", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "e", ")", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "alpha", "=", "torch", ".", "div", "(", "n1", ",", "n2", ")", "\n", "x", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "alpha", ",", "x", ")", ",", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.projection_head.__init__": [[96, 104], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "Type", "[", "Config", "]", ",", "input_dim", ":", "int", "=", "256", ")", ":", "\n", "        ", "super", "(", "projection_head", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "projection_head", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "config", ".", "tc_hidden_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "config", ".", "tc_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "tc_hidden_dim", ",", "config", ".", "tc_hidden_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.projection_head.forward": [[105, 109], ["model.projection_head.reshape", "model.projection_head.projection_head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "projection_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.sleep_model.__init__": [[127, 139], ["torch.Module.__init__", "model.encoder", "model.projection_head", "model.projection_head", "model.projection_head", "model.projection_head", "model.projection_head", "model.projection_head"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "Type", "[", "Config", "]", ")", ":", "\n", "        ", "super", "(", "sleep_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eeg_encoder", "=", "encoder", "(", "config", ")", "\n", "self", ".", "weak_pj1", "=", "projection_head", "(", "config", ")", "\n", "self", ".", "weak_pj2", "=", "projection_head", "(", "config", ",", "256", "*", "2", ")", "\n", "self", ".", "weak_pj3", "=", "projection_head", "(", "config", ")", "\n", "\n", "self", ".", "strong_pj1", "=", "projection_head", "(", "config", ")", "\n", "self", ".", "strong_pj2", "=", "projection_head", "(", "config", ",", "256", "*", "2", ")", "\n", "self", ".", "strong_pj3", "=", "projection_head", "(", "config", ")", "\n", "\n", "self", ".", "wandb", "=", "config", ".", "wandb", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.sleep_model.forward": [[140, 159], ["weak_dat.float", "strong_dat.float", "model.sleep_model.eeg_encoder", "model.sleep_model.eeg_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.sleep_model.weak_pj2", "model.sleep_model.weak_pj1", "model.sleep_model.weak_pj3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.sleep_model.strong_pj2", "model.sleep_model.strong_pj1", "model.sleep_model.strong_pj3", "model.sleep_model.unsqueeze", "model.sleep_model.unsqueeze", "model.sleep_model.unsqueeze", "model.sleep_model.unsqueeze", "model.sleep_model.unsqueeze", "model.sleep_model.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "weak_dat", ":", "torch", ".", "Tensor", ",", "strong_dat", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "weak_eeg_dat", "=", "weak_dat", ".", "float", "(", ")", "\n", "strong_eeg_dat", "=", "strong_dat", ".", "float", "(", ")", "\n", "\n", "weak_time_feats", ",", "weak_spect_feats", "=", "self", ".", "eeg_encoder", "(", "weak_eeg_dat", ")", "\n", "strong_time_feats", ",", "strong_spect_feats", "=", "self", ".", "eeg_encoder", "(", "strong_eeg_dat", ")", "\n", "\n", "weak_fusion_feats", "=", "torch", ".", "cat", "(", "(", "weak_time_feats", ",", "weak_spect_feats", ")", ",", "dim", "=", "-", "1", ")", "\n", "weak_fusion_feats", "=", "self", ".", "weak_pj2", "(", "weak_fusion_feats", ".", "unsqueeze", "(", "1", ")", ")", "\n", "weak_time_feats", "=", "self", ".", "weak_pj1", "(", "weak_time_feats", ".", "unsqueeze", "(", "1", ")", ")", "\n", "weak_spect_feats", "=", "self", ".", "weak_pj3", "(", "weak_spect_feats", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "strong_fusion_feats", "=", "torch", ".", "cat", "(", "(", "strong_time_feats", ",", "strong_spect_feats", ")", ",", "dim", "=", "-", "1", ")", "\n", "strong_fusion_feats", "=", "self", ".", "strong_pj2", "(", "strong_fusion_feats", ".", "unsqueeze", "(", "1", ")", ")", "\n", "strong_time_feats", "=", "self", ".", "strong_pj1", "(", "strong_time_feats", ".", "unsqueeze", "(", "1", ")", ")", "\n", "strong_spect_feats", "=", "self", ".", "strong_pj3", "(", "strong_spect_feats", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "return", "weak_time_feats", ",", "weak_fusion_feats", ",", "weak_spect_feats", ",", "strong_time_feats", ",", "strong_fusion_feats", ",", "strong_spect_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.contrast_loss.__init__": [[176, 188], ["torch.Module.__init__", "model.sleep_model", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "Type", "[", "Config", "]", ")", ":", "\n", "\n", "        ", "super", "(", "contrast_loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "sleep_model", "(", "config", ")", "\n", "self", ".", "T", "=", "config", ".", "temperature", "\n", "self", ".", "intra_T", "=", "config", ".", "intra_temperature", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "config", ".", "tc_hidden_dim", "//", "2", ",", "affine", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm1d", "(", "config", ".", "tc_hidden_dim", "//", "2", ",", "affine", "=", "False", ")", "\n", "self", ".", "bs", "=", "config", ".", "batch_size", "\n", "self", ".", "lambd", "=", "0.05", "\n", "self", ".", "mse", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'mean'", ")", "\n", "self", ".", "wandb", "=", "config", ".", "wandb", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.contrast_loss.loss": [[189, 212], ["torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp.masked_select().view().sum", "torch.exp.masked_select().view().sum", "torch.exp.masked_select().view().sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.t().contiguous", "torch.cat.t().contiguous", "torch.cat.t().contiguous", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.log().mean", "torch.log().mean", "torch.log().mean", "torch.log().mean", "torch.log().mean", "torch.log().mean", "torch.log().mean", "torch.log().mean", "torch.log().mean", "torch.exp.masked_select().view", "torch.exp.masked_select().view", "torch.exp.masked_select().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat.t", "torch.cat.t", "torch.cat.t", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp.masked_select", "torch.exp.masked_select", "torch.exp.masked_select"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "out_1", ":", "torch", ".", "Tensor", ",", "out_2", ":", "torch", ".", "Tensor", ")", ":", "\n", "# L2 normalize", "\n", "        ", "out_1", "=", "F", ".", "normalize", "(", "out_1", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "out_2", "=", "F", ".", "normalize", "(", "out_2", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "[", "out_1", ",", "out_2", "]", ",", "dim", "=", "0", ")", "# 2B, 128", "\n", "N", "=", "out", ".", "shape", "[", "0", "]", "\n", "\n", "# Full similarity matrix", "\n", "cov", "=", "torch", ".", "mm", "(", "out", ",", "out", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "# 2B, 2B", "\n", "sim", "=", "torch", ".", "exp", "(", "cov", "/", "self", ".", "T", ")", "# 2B, 2B", "\n", "\n", "# Negative similarity matrix", "\n", "mask", "=", "~", "torch", ".", "eye", "(", "N", ",", "device", "=", "sim", ".", "device", ")", ".", "bool", "(", ")", "\n", "neg", "=", "sim", ".", "masked_select", "(", "mask", ")", ".", "view", "(", "N", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n", "# Positive similarity matrix", "\n", "pos", "=", "torch", ".", "exp", "(", "torch", ".", "sum", "(", "out_1", "*", "out_2", ",", "dim", "=", "-", "1", ")", "/", "self", ".", "T", ")", "\n", "pos", "=", "torch", ".", "cat", "(", "[", "pos", ",", "pos", "]", ",", "dim", "=", "0", ")", "# 2B", "\n", "loss", "=", "-", "torch", ".", "log", "(", "pos", "/", "neg", ")", ".", "mean", "(", ")", "\n", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.contrast_loss.intra_loss": [[213, 240], ["torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "sim[].view().sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "loss.mean.mean.mean", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.normalize.unsqueeze", "torch.normalize.unsqueeze", "torch.normalize.unsqueeze", "torch.normalize.unsqueeze", "sim[].view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["None"], ["", "def", "intra_loss", "(", "self", ",", "weak_time", ":", "torch", ".", "Tensor", ",", "weak_spect", ":", "torch", ".", "Tensor", ",", "strong_time", ":", "torch", ".", "Tensor", ",", "strong_spect", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "weak_time", "=", "F", ".", "normalize", "(", "weak_time", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "strong_time", "=", "F", ".", "normalize", "(", "strong_time", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "strong_spect", "=", "F", ".", "normalize", "(", "strong_spect", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "weak_spect", "=", "F", ".", "normalize", "(", "weak_spect", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "\n", "out1", "=", "torch", ".", "vstack", "(", "(", "weak_time", ".", "unsqueeze", "(", "0", ")", ",", "weak_spect", ".", "unsqueeze", "(", "0", ")", ")", ")", "\n", "out2", "=", "torch", ".", "vstack", "(", "(", "strong_time", ".", "unsqueeze", "(", "0", ")", ",", "strong_spect", ".", "unsqueeze", "(", "0", ")", ")", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "[", "out1", ",", "out2", "]", ",", "dim", "=", "0", ")", "# 4*B*Feat", "\n", "N", "=", "out", ".", "shape", "[", "0", "]", "\n", "\n", "# similarity matrix", "\n", "cov", "=", "torch", ".", "einsum", "(", "'abf,dbf->adb'", ",", "out", ",", "out", ")", "#/weak_time.shape[-1] # 4*4*B", "\n", "sim", "=", "torch", ".", "exp", "(", "cov", "/", "self", ".", "intra_T", ")", "\n", "\n", "\n", "# negtive similarity matrix", "\n", "mask", "=", "~", "torch", ".", "eye", "(", "N", ",", "device", "=", "sim", ".", "device", ")", ".", "bool", "(", ")", "\n", "neg", "=", "sim", "[", "mask", "]", ".", "view", "(", "N", ",", "N", "-", "1", ",", "weak_time", ".", "shape", "[", "0", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "# positive similarity matrix", "\n", "pos", "=", "torch", ".", "exp", "(", "torch", ".", "sum", "(", "out1", "*", "out2", ",", "dim", "=", "-", "1", ")", "/", "self", ".", "intra_T", ")", "\n", "pos", "=", "torch", ".", "cat", "(", "[", "pos", ",", "pos", "]", ",", "dim", "=", "0", ")", "\n", "loss", "=", "-", "torch", ".", "log", "(", "pos", "/", "neg", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.contrast_loss.forward": [[241, 253], ["model.contrast_loss.model", "model.contrast_loss.loss", "model.contrast_loss.loss", "model.contrast_loss.loss", "model.contrast_loss.intra_loss", "model.contrast_loss.item", "model.contrast_loss.item", "model.contrast_loss.item", "model.contrast_loss.item"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.model.contrast_loss.loss", "home.repos.pwc.inspect_result.likith012_muleeg.models.model.contrast_loss.loss", "home.repos.pwc.inspect_result.likith012_muleeg.models.model.contrast_loss.loss", "home.repos.pwc.inspect_result.likith012_muleeg.models.model.contrast_loss.intra_loss"], ["", "def", "forward", "(", "self", ",", "weak", ":", "torch", ".", "Tensor", ",", "strong", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "float", ",", "float", ",", "float", ",", "float", "]", ":", "\n", "\n", "        ", "weak_time_feats", ",", "weak_fusion_feats", ",", "weak_spect_feats", ",", "strong_time_feats", ",", "strong_fusion_feats", ",", "strong_spect_feats", "=", "self", ".", "model", "(", "weak", ",", "strong", ")", "\n", "\n", "l1", "=", "self", ".", "loss", "(", "weak_time_feats", ",", "strong_time_feats", ")", "\n", "l2", "=", "self", ".", "loss", "(", "weak_fusion_feats", ",", "strong_fusion_feats", ")", "\n", "l3", "=", "self", ".", "loss", "(", "weak_spect_feats", ",", "strong_spect_feats", ")", "\n", "intra_loss", "=", "self", ".", "intra_loss", "(", "weak_time_feats", ",", "weak_spect_feats", ",", "strong_time_feats", ",", "strong_spect_feats", ")", "\n", "\n", "tot_loss", "=", "l1", "+", "l2", "+", "l3", "+", "intra_loss", "\n", "\n", "return", "tot_loss", ",", "l1", ".", "item", "(", ")", ",", "l2", ".", "item", "(", ")", ",", "l3", ".", "item", "(", ")", ",", "intra_loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.ft_loss.__init__": [[276, 289], ["torch.Module.__init__", "model.encoder", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "model.ft_loss.eeg_encoder.load_state_dict", "model.ft_loss.eeg_encoder.parameters", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "chkpoint_pth", ":", "str", ",", "config", ":", "Type", "[", "Config", "]", ",", "device", ":", "str", ")", ":", "\n", "\n", "        ", "super", "(", "ft_loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eeg_encoder", "=", "encoder", "(", "config", ")", "\n", "chkpoint", "=", "torch", ".", "load", "(", "chkpoint_pth", ",", "map_location", "=", "device", ")", "\n", "eeg_dict", "=", "chkpoint", "[", "'eeg_model_state_dict'", "]", "\n", "self", ".", "eeg_encoder", ".", "load_state_dict", "(", "eeg_dict", ")", "\n", "\n", "for", "p", "in", "self", ".", "eeg_encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "lin", "=", "nn", ".", "Linear", "(", "256", ",", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.model.ft_loss.forward": [[290, 296], ["model.ft_loss.eeg_encoder", "model.ft_loss.lin"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "time_dat", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "time_feats", ",", "_", "=", "self", ".", "eeg_encoder", "(", "time_dat", ")", "\n", "x", "=", "self", ".", "lin", "(", "time_feats", ")", "\n", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BasicBlock_Bottle.__init__": [[17, 33], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "inplanes3", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock_Bottle", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "inplanes3", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "25", ",", "stride", "=", "stride", ",", "padding", "=", "12", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm1d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv1d", "(", "\n", "planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", "\n", ")", "#", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm1d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BasicBlock_Bottle.forward": [[34, 55], ["resnet1d.BasicBlock_Bottle.conv1", "resnet1d.BasicBlock_Bottle.bn1", "resnet1d.BasicBlock_Bottle.relu", "resnet1d.BasicBlock_Bottle.drop", "resnet1d.BasicBlock_Bottle.conv2", "resnet1d.BasicBlock_Bottle.bn2", "resnet1d.BasicBlock_Bottle.relu", "resnet1d.BasicBlock_Bottle.conv3", "resnet1d.BasicBlock_Bottle.bn3", "resnet1d.BasicBlock_Bottle.relu", "resnet1d.BasicBlock_Bottle.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "drop", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__": [[59, 75], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.MaxPool1d", "torch.MaxPool1d", "resnet1d.BaseNet._make_layer3", "resnet1d.BaseNet._make_layer3", "resnet1d.BaseNet._make_layer3", "resnet1d.BaseNet._make_layer3"], "methods", ["home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.__init__", "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet._make_layer3", "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet._make_layer3", "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet._make_layer3", "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet._make_layer3"], ["    ", "def", "__init__", "(", "self", ",", "input_channels", "=", "1", ",", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", ":", "\n", "        ", "self", ".", "inplanes3", "=", "16", "\n", "\n", "super", "(", "BaseNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "\n", "input_channels", ",", "16", ",", "kernel_size", "=", "71", ",", "stride", "=", "2", ",", "padding", "=", "35", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "16", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool1d", "(", "kernel_size", "=", "71", ",", "stride", "=", "2", ",", "padding", "=", "35", ")", "\n", "\n", "self", ".", "layer3x3_1", "=", "self", ".", "_make_layer3", "(", "BasicBlock_Bottle", ",", "8", ",", "layers", "[", "0", "]", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer3x3_2", "=", "self", ".", "_make_layer3", "(", "BasicBlock_Bottle", ",", "16", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3x3_3", "=", "self", ".", "_make_layer3", "(", "BasicBlock_Bottle", ",", "32", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3x3_4", "=", "self", ".", "_make_layer3", "(", "BasicBlock_Bottle", ",", "64", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet._make_layer3": [[76, 97], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "block"], "methods", ["None"], ["", "def", "_make_layer3", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "2", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes3", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "\n", "self", ".", "inplanes3", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes3", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes3", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes3", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.BaseNet.forward": [[98, 109], ["resnet1d.BaseNet.conv1", "resnet1d.BaseNet.bn1", "resnet1d.BaseNet.relu", "resnet1d.BaseNet.maxpool", "resnet1d.BaseNet.layer3x3_1", "resnet1d.BaseNet.layer3x3_2", "resnet1d.BaseNet.layer3x3_3", "resnet1d.BaseNet.layer3x3_4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x0", ")", ":", "\n", "        ", "x0", "=", "self", ".", "conv1", "(", "x0", ")", "\n", "x0", "=", "self", ".", "bn1", "(", "x0", ")", "\n", "x0", "=", "self", ".", "relu", "(", "x0", ")", "\n", "x0", "=", "self", ".", "maxpool", "(", "x0", ")", "\n", "\n", "x", "=", "self", ".", "layer3x3_1", "(", "x0", ")", "\n", "x", "=", "self", ".", "layer3x3_2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3x3_3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3x3_4", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.likith012_muleeg.models.resnet1d.conv3x3": [[6, 10], ["torch.Conv1d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv1d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "7", ",", "stride", "=", "stride", ",", "padding", "=", "3", ",", "bias", "=", "False", "\n", ")", "\n"]]}