{"home.repos.pwc.inspect_result.yuboxie_meed.None.validate.read_data": [[48, 64], ["validate.read_data.load_np_files"], "function", ["None"], ["def", "read_data", "(", "data_path", ")", ":", "\n", "    ", "def", "load_np_files", "(", "path", ")", ":", "\n", "        ", "my_set", "=", "{", "}", "\n", "my_set", "[", "'enc_input'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input.npy'", ")", ")", "\n", "my_set", "[", "'enc_input_e'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input_e.npy'", ")", ")", "\n", "my_set", "[", "'dec_input'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'dec_input.npy'", ")", ")", "\n", "my_set", "[", "'target'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'target.npy'", ")", ")", "\n", "my_set", "[", "'enc_input_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input_len.npy'", ")", ")", "\n", "my_set", "[", "'dec_input_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'dec_input_len.npy'", ")", ")", "\n", "my_set", "[", "'hist_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'hist_len.npy'", ")", ")", "\n", "return", "my_set", "\n", "", "train_set", "=", "load_np_files", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'train'", ")", ")", "\n", "valid_set", "=", "load_np_files", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'validation'", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../token2id.pickle'", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "token2id", "=", "pickle", ".", "load", "(", "file", ")", "\n", "", "return", "train_set", ",", "valid_set", ",", "token2id", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.predict.read_data": [[56, 75], ["predict.read_data.load_np_files"], "function", ["None"], ["def", "read_data", "(", "data_path", ")", ":", "\n", "    ", "def", "load_np_files", "(", "path", ")", ":", "\n", "        ", "my_set", "=", "{", "}", "\n", "my_set", "[", "'enc_input'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input.npy'", ")", ")", "\n", "my_set", "[", "'enc_input_e'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input_e.npy'", ")", ")", "\n", "my_set", "[", "'dec_input'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'dec_input.npy'", ")", ")", "\n", "my_set", "[", "'target'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'target.npy'", ")", ")", "\n", "my_set", "[", "'enc_input_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input_len.npy'", ")", ")", "\n", "my_set", "[", "'dec_input_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'dec_input_len.npy'", ")", ")", "\n", "my_set", "[", "'hist_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'hist_len.npy'", ")", ")", "\n", "return", "my_set", "\n", "", "test_set", "=", "load_np_files", "(", "data_path", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../token2id.pickle'", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "token2id", "=", "pickle", ".", "load", "(", "file", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../id2token.pickle'", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "id2token", "=", "pickle", ".", "load", "(", "file", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../id2evec.pickle'", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "id2evec", "=", "pickle", ".", "load", "(", "file", ")", "\n", "", "return", "test_set", ",", "token2id", ",", "id2token", ",", "id2evec", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.predict.ids_to_sentence": [[76, 88], ["range", "tokens.append", "tokens.append", "len"], "function", ["None"], ["", "def", "ids_to_sentence", "(", "ids", ",", "uttr_len", ",", "id2token", ")", ":", "\n", "    ", "tokens", "=", "[", "]", "\n", "if", "uttr_len", "is", "not", "None", ":", "\n", "        ", "for", "i", "in", "range", "(", "uttr_len", ")", ":", "\n", "            ", "if", "id2token", "[", "ids", "[", "i", "]", "]", "!=", "'<eos>'", "and", "id2token", "[", "ids", "[", "i", "]", "]", "!=", "'<go>'", ":", "\n", "                ", "tokens", ".", "append", "(", "id2token", "[", "ids", "[", "i", "]", "]", ")", "\n", "", "", "", "else", ":", "\n", "        ", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "ids", ")", "and", "id2token", "[", "ids", "[", "i", "]", "]", "!=", "'<eos>'", ":", "\n", "            ", "tokens", ".", "append", "(", "id2token", "[", "ids", "[", "i", "]", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "return", "' '", ".", "join", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.predict.get_emotion_score": [[89, 102], ["nlp", "numpy.linalg.norm", "numpy.array"], "function", ["None"], ["", "def", "get_emotion_score", "(", "text", ",", "token2vad", ")", ":", "\n", "    ", "n", "=", "0", "\n", "score", "=", "0.0", "\n", "doc", "=", "nlp", "(", "text", ")", "\n", "for", "t", "in", "doc", ":", "\n", "        ", "if", "not", "t", ".", "is_space", ":", "\n", "            ", "if", "t", ".", "lemma_", "in", "token2vad", ":", "\n", "                ", "vad_diff", "=", "token2vad", "[", "t", ".", "lemma_", "]", "-", "np", ".", "array", "(", "[", "5.0", ",", "1.0", ",", "5.0", "]", ")", "\n", "score", "+=", "np", ".", "linalg", ".", "norm", "(", "vad_diff", ")", "\n", "n", "+=", "1", "\n", "", "", "", "if", "n", ">", "0", ":", "\n", "        ", "score", "=", "score", "/", "n", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.predict.build_emot_vec": [[103, 117], ["numpy.zeros", "range", "numpy.sum", "numpy.zeros", "range"], "function", ["None"], ["", "def", "build_emot_vec", "(", "pred_id", ",", "pred_len", ",", "id2evec", ")", ":", "\n", "    ", "beam_width", "=", "pred_id", ".", "shape", "[", "0", "]", "\n", "n_emot", "=", "id2evec", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "enc_input_e", "=", "np", ".", "zeros", "(", "(", "beam_width", ",", "n_emot", ")", ",", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "beam_width", ")", ":", "\n", "        ", "emot_vec", "=", "np", ".", "zeros", "(", "(", "n_emot", ")", ",", "np", ".", "float32", ")", "\n", "for", "j", "in", "range", "(", "pred_len", "[", "i", "]", "-", "1", ")", ":", "\n", "            ", "emot_vec", "+=", "id2evec", "[", "pred_id", "[", "i", ",", "j", "]", "]", "\n", "", "enc_input_e", "[", "i", ",", ":", "]", "=", "emot_vec", "\n", "", "enc_input_e", "[", "enc_input_e", ">", "0", "]", "=", "1.0", "\n", "enc_input_e_part_sum", "=", "np", ".", "sum", "(", "enc_input_e", "[", ":", ",", ":", "n_emot", "-", "1", "]", ",", "axis", "=", "1", ")", "\n", "enc_input_e_part_sum", "[", "enc_input_e_part_sum", ">", "0", "]", "=", "1.0", "\n", "enc_input_e", "[", ":", ",", "-", "1", "]", "=", "1.0", "-", "enc_input_e_part_sum", "\n", "return", "enc_input_e", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.predict.build_reversed_data_set": [[118, 163], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.tile", "predict.build_emot_vec", "range", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.array", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.ones", "numpy.ones", "numpy.array"], "function", ["home.repos.pwc.inspect_result.yuboxie_meed.None.predict.build_emot_vec"], ["", "def", "build_reversed_data_set", "(", "n", ",", "enc_input", ",", "enc_input_e", ",", "enc_input_len", ",", "hist_len", ",", "pred_id", ",", "pred_len", ",", "id2evec", ",", "token2id", ")", ":", "\n", "    ", "\"\"\"\n        n: how many utterances to take from enc_input, 0 <= n <= hist_len - 1\n        enc_input: [max_hist_len, 1, max_uttr_len]\n        enc_input_e: [1, max_hist_len, n_emot]\n        enc_input_len: [max_hist_len, 1]\n        hist_len: int scalar\n        pred_id: [beam_width, max_time], max_time <= max_uttr_len + 1\n        pred_len: [beam_width]\n    \"\"\"", "\n", "max_hist_len", "=", "enc_input", ".", "shape", "[", "0", "]", "\n", "max_uttr_len", "=", "enc_input", ".", "shape", "[", "2", "]", "\n", "n_emot", "=", "enc_input_e", ".", "shape", "[", "2", "]", "\n", "batch_size", "=", "pred_id", ".", "shape", "[", "0", "]", "# batch_size == beam_width", "\n", "max_time", "=", "pred_id", ".", "shape", "[", "1", "]", "\n", "\n", "my_set", "=", "{", "}", "\n", "my_set", "[", "'enc_input'", "]", "=", "np", ".", "zeros", "(", "(", "max_hist_len", ",", "batch_size", ",", "max_uttr_len", ")", ",", "np", ".", "int32", ")", "\n", "my_set", "[", "'enc_input_e'", "]", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "max_hist_len", ",", "n_emot", ")", ",", "np", ".", "float32", ")", "\n", "my_set", "[", "'dec_input'", "]", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "max_uttr_len", "+", "1", ")", ",", "np", ".", "int32", ")", "\n", "my_set", "[", "'target'", "]", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "max_uttr_len", "+", "1", ")", ",", "np", ".", "int32", ")", "\n", "my_set", "[", "'enc_input_len'", "]", "=", "np", ".", "zeros", "(", "(", "max_hist_len", ",", "batch_size", ")", ",", "np", ".", "int32", ")", "\n", "\n", "my_set", "[", "'hist_len'", "]", "=", "np", ".", "tile", "(", "np", ".", "array", "(", "[", "n", "+", "1", "]", ",", "np", ".", "int32", ")", ",", "batch_size", ")", "\n", "\n", "# Set prediction as the first utterance in the history", "\n", "my_set", "[", "'enc_input'", "]", "[", "max_hist_len", "-", "n", "-", "1", ",", ":", ",", ":", "max_time", "-", "1", "]", "=", "pred_id", "[", ":", ",", ":", "-", "1", "]", "\n", "my_set", "[", "'enc_input_len'", "]", "[", "max_hist_len", "-", "n", "-", "1", ",", ":", "]", "=", "pred_len", "-", "1", "# exclude the <eos> token", "\n", "my_set", "[", "'enc_input_e'", "]", "[", ":", ",", "0", ",", ":", "]", "=", "build_emot_vec", "(", "pred_id", ",", "pred_len", ",", "id2evec", ")", "\n", "\n", "# Take the last n utterances from original enc_input", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "my_set", "[", "'enc_input'", "]", "[", "max_hist_len", "-", "n", "+", "i", ",", ":", ",", ":", "]", "=", "np", ".", "tile", "(", "enc_input", "[", "-", "(", "i", "+", "1", ")", ",", ":", ",", ":", "]", ",", "(", "batch_size", ",", "1", ")", ")", "\n", "my_set", "[", "'enc_input_len'", "]", "[", "max_hist_len", "-", "n", "+", "i", ",", ":", "]", "=", "np", ".", "tile", "(", "enc_input_len", "[", "-", "(", "i", "+", "1", ")", ",", ":", "]", ",", "batch_size", ")", "\n", "my_set", "[", "'enc_input_e'", "]", "[", ":", ",", "i", "+", "1", ",", ":", "]", "=", "np", ".", "tile", "(", "enc_input_e", "[", ":", ",", "hist_len", "-", "(", "i", "+", "1", ")", ",", ":", "]", ",", "(", "batch_size", ",", "1", ")", ")", "\n", "\n", "# Use the next utterance in history as response", "\n", "", "uttr_len", "=", "enc_input_len", "[", "-", "(", "n", "+", "1", ")", ",", "0", "]", "\n", "my_set", "[", "'dec_input'", "]", "[", ":", ",", "0", "]", "=", "np", ".", "ones", "(", "batch_size", ",", "np", ".", "int32", ")", "*", "token2id", "[", "'<go>'", "]", "\n", "my_set", "[", "'dec_input'", "]", "[", ":", ",", "1", ":", "]", "=", "np", ".", "tile", "(", "enc_input", "[", "-", "(", "n", "+", "1", ")", ",", ":", ",", ":", "]", ",", "(", "batch_size", ",", "1", ")", ")", "\n", "my_set", "[", "'target'", "]", "[", ":", ",", ":", "uttr_len", "]", "=", "np", ".", "tile", "(", "enc_input", "[", "-", "(", "n", "+", "1", ")", ",", ":", ",", ":", "uttr_len", "]", ",", "(", "batch_size", ",", "1", ")", ")", "\n", "my_set", "[", "'target'", "]", "[", ":", ",", "uttr_len", "]", "=", "np", ".", "ones", "(", "batch_size", ",", "np", ".", "int32", ")", "*", "token2id", "[", "'<eos>'", "]", "\n", "my_set", "[", "'dec_input_len'", "]", "=", "np", ".", "tile", "(", "np", ".", "array", "(", "[", "uttr_len", "+", "1", "]", ",", "np", ".", "int32", ")", ",", "batch_size", ")", "\n", "\n", "return", "my_set", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.train.read_data": [[48, 64], ["train.read_data.load_np_files"], "function", ["None"], ["def", "read_data", "(", "data_path", ")", ":", "\n", "    ", "def", "load_np_files", "(", "path", ")", ":", "\n", "        ", "my_set", "=", "{", "}", "\n", "my_set", "[", "'enc_input'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input.npy'", ")", ")", "\n", "my_set", "[", "'enc_input_e'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input_e.npy'", ")", ")", "\n", "my_set", "[", "'dec_input'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'dec_input.npy'", ")", ")", "\n", "my_set", "[", "'target'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'target.npy'", ")", ")", "\n", "my_set", "[", "'enc_input_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'enc_input_len.npy'", ")", ")", "\n", "my_set", "[", "'dec_input_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'dec_input_len.npy'", ")", ")", "\n", "my_set", "[", "'hist_len'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'hist_len.npy'", ")", ")", "\n", "return", "my_set", "\n", "", "train_set", "=", "load_np_files", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'train'", ")", ")", "\n", "valid_set", "=", "load_np_files", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'validation'", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../token2id.pickle'", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "token2id", "=", "pickle", ".", "load", "(", "file", ")", "\n", "", "return", "train_set", ",", "valid_set", ",", "token2id", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.WordLevelAttentionMechanism.__init__": [[24, 92], ["TypeError", "callable", "TypeError", "tensorflow.dtypes.as_dtype().as_numpy_dtype", "attention._maybe_mask_score_softmax", "tensorflow.name_scope", "tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory", "isinstance", "probability_fn", "tensorflow.contrib.framework.nest.flatten", "attention.WordLevelAttentionMechanism.memory_layer", "tensorflow.dtypes.as_dtype", "attention._maybe_mask_score_no_check", "tensorflow.shape", "tensorflow.shape", "type", "type"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.attention._maybe_mask_score_softmax", "home.repos.pwc.inspect_result.yuboxie_meed.None.attention._maybe_mask_score_no_check"], ["def", "__init__", "(", "self", ",", "\n", "attention_v", ",", "\n", "dec_query_layer", ",", "\n", "enc_query_layer", ",", "\n", "memory_layer", ",", "\n", "memory", ",", "\n", "memory_sequence_length", "=", "None", ",", "\n", "probability_fn", "=", "None", ",", "\n", "score_mask_value", "=", "None", ",", "\n", "check_inner_dims_defined", "=", "True", ")", ":", "\n", "        ", "\"\"\"Construct the word level attention mechanism.\n        Args:\n            attention_v: The attention v variable.\n            dec_query_layer: Mapping layer for decoder's query.\n            enc_query_layer: Mapping layer for utterance-level encoder's query.\n            memory_layer: Mapping layer for memory.\n            memory: The memory to query; the output of a bidirectional RNN.  This\n                tensor should be shaped `[batch_size, max_uttr_len, 2*n_hidden_units]`.\n            memory_sequence_length (optional): Sequence lengths for the batch entries\n                in memory.  If provided, the memory tensor rows are masked with zeros\n                for values past the respective sequence lengths.\n            probability_fn: (optional) A `callable`.  Converts the score to\n                probabilities.  The default is `tf.nn.softmax`. Other options include\n                `tf.contrib.seq2seq.hardmax` and `tf.contrib.sparsemax.sparsemax`.\n                Its signature should be: `probabilities = probability_fn(score)`.\n            score_mask_value: (optional): The mask value for score before passing into\n                `probability_fn`. The default is -inf. Only used if\n                `memory_sequence_length` is not None.\n            check_inner_dims_defined: Python boolean.  If `True`, the `memory`\n                argument's shape is checked to ensure all but the two outermost\n                dimensions are fully defined.\n        \"\"\"", "\n", "# super(WordLevelAttentionMechanism, self).__init__(", "\n", "#     query_layer = None,", "\n", "#     memory_layer = memory_layer,", "\n", "#     memory = memory,", "\n", "#     probability_fn = wrapped_probability_fn,", "\n", "#     memory_sequence_length = memory_sequence_length)", "\n", "\n", "# Use custom initialization due to the probable zero values in memory_sequence_length", "\n", "if", "probability_fn", "is", "None", ":", "\n", "            ", "probability_fn", "=", "tf", ".", "nn", ".", "softmax", "\n", "", "if", "(", "memory_layer", "is", "not", "None", "and", "not", "isinstance", "(", "memory_layer", ",", "tf", ".", "layers", ".", "Layer", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"memory_layer is not a Layer: %s\"", "%", "type", "(", "memory_layer", ")", ".", "__name__", ")", "\n", "", "self", ".", "_query_layer", "=", "None", "\n", "self", ".", "_memory_layer", "=", "memory_layer", "\n", "self", ".", "dtype", "=", "memory_layer", ".", "dtype", "\n", "if", "not", "callable", "(", "probability_fn", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"probability_fn must be callable, saw type: %s\"", "%", "type", "(", "probability_fn", ")", ".", "__name__", ")", "\n", "", "if", "score_mask_value", "is", "None", ":", "\n", "            ", "score_mask_value", "=", "tf", ".", "dtypes", ".", "as_dtype", "(", "self", ".", "_memory_layer", ".", "dtype", ")", ".", "as_numpy_dtype", "(", "-", "np", ".", "inf", ")", "\n", "", "self", ".", "_probability_fn", "=", "lambda", "score", ":", "_maybe_mask_score_softmax", "(", "\n", "probability_fn", "(", "_maybe_mask_score_no_check", "(", "score", ",", "memory_sequence_length", ",", "score_mask_value", ")", ")", ",", "\n", "memory_sequence_length", ")", "\n", "with", "tf", ".", "name_scope", "(", "None", ",", "\"BaseAttentionMechanismInit\"", ",", "tf", ".", "contrib", ".", "framework", ".", "nest", ".", "flatten", "(", "memory", ")", ")", ":", "\n", "            ", "self", ".", "_values", "=", "_prepare_memory", "(", "\n", "memory", ",", "memory_sequence_length", ",", "\n", "check_inner_dims_defined", "=", "check_inner_dims_defined", ")", "\n", "self", ".", "_keys", "=", "(", "\n", "self", ".", "memory_layer", "(", "self", ".", "_values", ")", "if", "self", ".", "memory_layer", "\n", "else", "self", ".", "_values", ")", "\n", "self", ".", "_batch_size", "=", "(", "self", ".", "_keys", ".", "shape", "[", "0", "]", ".", "value", "or", "tf", ".", "shape", "(", "self", ".", "_keys", ")", "[", "0", "]", ")", "\n", "self", ".", "_alignments_size", "=", "(", "self", ".", "_keys", ".", "shape", "[", "1", "]", ".", "value", "or", "tf", ".", "shape", "(", "self", ".", "_keys", ")", "[", "1", "]", ")", "\n", "\n", "# Extra initialization", "\n", "", "self", ".", "_dec_query_layer", "=", "dec_query_layer", "\n", "self", ".", "_enc_query_layer", "=", "enc_query_layer", "\n", "self", ".", "_attention_v", "=", "attention_v", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.WordLevelAttentionMechanism.__call__": [[93, 114], ["tensorflow.variable_scope", "attention.WordLevelAttentionMechanism._dec_query_layer", "attention.WordLevelAttentionMechanism._enc_query_layer", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_sum", "attention.WordLevelAttentionMechanism._probability_fn", "tensorflow.tanh"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "dec_query", ",", "enc_query", ")", ":", "\n", "        ", "\"\"\"Score the query based on the keys and values.\n        Args:\n            dec_query: Tensor of dtype matching `self.values` and shape\n                `[batch_size, query_depth]`.\n            enc_query: Tensor of dtype matching `self.values` and shape\n                `[batch_size, query_depth]`.\n        Returns:\n            alignments: Tensor of dtype matching `self.values` and shape\n                `[batch_size, alignments_size]` (`alignments_size` is memory's\n                `max_time`).\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'word_level_attention'", ")", ":", "\n", "            ", "processed_dec_query", "=", "self", ".", "_dec_query_layer", "(", "dec_query", ")", "\n", "processed_enc_query", "=", "self", ".", "_enc_query_layer", "(", "enc_query", ")", "\n", "processed_dec_query", "=", "tf", ".", "expand_dims", "(", "processed_dec_query", ",", "1", ")", "\n", "processed_enc_query", "=", "tf", ".", "expand_dims", "(", "processed_enc_query", ",", "1", ")", "\n", "# v = tf.get_variable('attention_v', [self._num_units], dtype = tf.float32)", "\n", "score", "=", "tf", ".", "reduce_sum", "(", "self", ".", "_attention_v", "*", "tf", ".", "tanh", "(", "self", ".", "_keys", "+", "processed_dec_query", "+", "processed_enc_query", ")", ",", "[", "2", "]", ")", "\n", "alignments", "=", "self", ".", "_probability_fn", "(", "score", ")", "\n", "", "return", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.__init__": [[117, 186], ["tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.nn.rnn_cell.GRUCell", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.Variable", "tensorflow.Variable", "range", "tensorflow.as_dtype().as_numpy_dtype", "tensorflow.zeros", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "attention.UttrLevelAttentionMechanism._word_level_attns.append", "tensorflow.nn.softmax", "attention.WordLevelAttentionMechanism", "tensorflow.as_dtype", "tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "word_level_num_units", ",", "\n", "uttr_level_num_units", ",", "\n", "n_hidden_units", ",", "\n", "memory", ",", "\n", "memory_sequence_length", ",", "\n", "hist_length", ")", ":", "\n", "        ", "\"\"\"Construct the utterance level attention mechanism.\n        Args:\n            word_level_num_units: Word level attention depth.\n            uttr_level_num_units: Utterance level attention depth.\n            n_hidden_units: Number of hidden units for utterance-level encoder.\n            memory: The memory to query; the output of the bidirectional RNNs.  This\n                tensor should be shaped `[max_hist_len, batch_size, max_uttr_len, 2*n_hidden_units]`.\n            memory_sequence_length: Sequence lengths for the batch entries in memory.\n                Shaped `[max_hist_len, batch_size]`.\n            hist_length: Lengths for the utterances in history. Shaped `[batch_size]`.\n        \"\"\"", "\n", "self", ".", "_query_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "uttr_level_num_units", ",", "\n", "name", "=", "'uttr_level_query_layer'", ",", "\n", "use_bias", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_memory_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "uttr_level_num_units", ",", "\n", "name", "=", "'uttr_level_memory_layer'", ",", "\n", "use_bias", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_uttr_enc_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "n_hidden_units", ")", "\n", "self", ".", "_uttr_level_num_units", "=", "uttr_level_num_units", "\n", "\n", "word_level_dec_query_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "word_level_num_units", ",", "\n", "name", "=", "'word_level_dec_query_layer'", ",", "\n", "use_bias", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "word_level_enc_query_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "word_level_num_units", ",", "\n", "name", "=", "'word_level_enc_query_layer'", ",", "\n", "use_bias", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "word_level_memory_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "word_level_num_units", ",", "\n", "name", "=", "'word_level_memory_layer'", ",", "\n", "use_bias", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "self", ".", "_attention_v_ul", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "uttr_level_num_units", "]", ",", "stddev", "=", "0.1", ")", ",", "name", "=", "'attention_v_ul'", ")", "\n", "self", ".", "_attention_v_wl", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "word_level_num_units", "]", ",", "stddev", "=", "0.1", ")", ",", "name", "=", "'attention_v_wl'", ")", "\n", "\n", "self", ".", "_word_level_attns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "memory", ".", "shape", "[", "0", "]", ".", "value", ")", ":", "\n", "            ", "self", ".", "_word_level_attns", ".", "append", "(", "WordLevelAttentionMechanism", "(", "\n", "attention_v", "=", "self", ".", "_attention_v_wl", ",", "\n", "dec_query_layer", "=", "word_level_dec_query_layer", ",", "\n", "enc_query_layer", "=", "word_level_enc_query_layer", ",", "\n", "memory_layer", "=", "word_level_memory_layer", ",", "\n", "memory", "=", "memory", "[", "i", ",", ":", ",", ":", ",", ":", "]", ",", "\n", "memory_sequence_length", "=", "memory_sequence_length", "[", "i", ",", ":", "]", ")", ")", "\n", "\n", "", "self", ".", "dtype", "=", "tf", ".", "float32", "\n", "\n", "self", ".", "_memory", "=", "memory", "\n", "self", ".", "_hist_length", "=", "hist_length", "\n", "self", ".", "_batch_size", "=", "memory", ".", "shape", "[", "1", "]", ".", "value", "\n", "self", ".", "_alignments_size", "=", "memory", ".", "shape", "[", "0", "]", ".", "value", "\n", "\n", "self", ".", "_alignments_w_size", "=", "self", ".", "_alignments_size", "*", "self", ".", "_word_level_attns", "[", "0", "]", ".", "alignments_size", "\n", "\n", "score_mask_value", "=", "tf", ".", "as_dtype", "(", "self", ".", "dtype", ")", ".", "as_numpy_dtype", "(", "-", "np", ".", "inf", ")", "\n", "self", ".", "_probability_fn", "=", "lambda", "score", ":", "tf", ".", "nn", ".", "softmax", "(", "_maybe_mask_score", "(", "score", ",", "self", ".", "_hist_length", ",", "score_mask_value", ")", ")", "\n", "\n", "# self._values changes each time self.__call__() is called", "\n", "self", ".", "_values", "=", "tf", ".", "zeros", "(", "[", "self", ".", "_batch_size", ",", "self", ".", "_alignments_size", ",", "n_hidden_units", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.__call__": [[187, 231], ["tensorflow.variable_scope", "attention.UttrLevelAttentionMechanism._uttr_enc_cell.zero_state", "reversed", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.sequence_mask", "tensorflow.expand_dims", "attention.UttrLevelAttentionMechanism._query_layer", "tensorflow.expand_dims", "attention.UttrLevelAttentionMechanism._memory_layer", "tensorflow.reduce_sum", "attention.UttrLevelAttentionMechanism._probability_fn", "range", "tensorflow.reshape.append", "tensorflow.expand_dims", "tensorflow.matmul", "tensorflow.squeeze", "attention.UttrLevelAttentionMechanism._uttr_enc_cell", "tensorflow.transpose.append", "tensorflow.stack", "tensorflow.stack", "tensorflow.tanh"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.zero_state"], ["", "def", "__call__", "(", "self", ",", "query", ",", "state", ")", ":", "\n", "        ", "\"\"\"Score the query based on the keys and values.\n        Args:\n            query: Tensor of dtype matching `self.values` and shape\n                `[batch_size, query_depth]`.\n            state: Tensor of dtype matching `self.values` and shape\n                `[batch_size, alignments_size]`\n                (`alignments_size` is memory's `max_time`).\n        Returns:\n            alignments: Tensor of dtype matching `self.values` and shape\n                `[batch_size, alignments_size]` (`alignments_size` is memory's\n                `max_time`).\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'uttr_level_encoding'", ")", ":", "\n", "            ", "uttr_enc_outputs", "=", "[", "]", "\n", "uttr_enc_state", "=", "self", ".", "_uttr_enc_cell", ".", "zero_state", "(", "self", ".", "_batch_size", ",", "self", ".", "dtype", ")", "\n", "alignments_w", "=", "[", "]", "\n", "for", "i", "in", "reversed", "(", "range", "(", "self", ".", "_alignments_size", ")", ")", ":", "\n", "                ", "word_alignments", "=", "self", ".", "_word_level_attns", "[", "i", "]", "(", "dec_query", "=", "query", ",", "enc_query", "=", "uttr_enc_state", ")", "\n", "alignments_w", ".", "append", "(", "word_alignments", ")", "\n", "word_alignments", "=", "tf", ".", "expand_dims", "(", "word_alignments", ",", "1", ")", "\n", "uttr_enc_input", "=", "tf", ".", "matmul", "(", "word_alignments", ",", "self", ".", "_word_level_attns", "[", "i", "]", ".", "values", ")", "\n", "uttr_enc_input", "=", "tf", ".", "squeeze", "(", "uttr_enc_input", ",", "[", "1", "]", ")", "\n", "_", ",", "uttr_enc_state", "=", "self", ".", "_uttr_enc_cell", "(", "uttr_enc_input", ",", "uttr_enc_state", ")", "\n", "uttr_enc_outputs", ".", "append", "(", "uttr_enc_state", ")", "\n", "", "uttr_enc_outputs", "=", "tf", ".", "transpose", "(", "tf", ".", "stack", "(", "uttr_enc_outputs", ")", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "# [batch_size, max_hist_len, n_hidden_units]", "\n", "\n", "alignments_w", "=", "tf", ".", "transpose", "(", "tf", ".", "stack", "(", "alignments_w", ")", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "# [batch_size, max_hist_len, max_uttr_len]", "\n", "alignments_w", "=", "tf", ".", "reshape", "(", "alignments_w", ",", "[", "self", ".", "_batch_size", ",", "self", ".", "_alignments_w_size", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'uttr_level_attention'", ")", ":", "\n", "            ", "mask", "=", "tf", ".", "sequence_mask", "(", "self", ".", "_hist_length", ",", "maxlen", "=", "self", ".", "_alignments_size", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "2", ")", "\n", "self", ".", "_values", "=", "uttr_enc_outputs", "*", "mask", "\n", "\n", "processed_query", "=", "self", ".", "_query_layer", "(", "query", ")", "\n", "processed_query", "=", "tf", ".", "expand_dims", "(", "processed_query", ",", "1", ")", "\n", "keys", "=", "self", ".", "_memory_layer", "(", "self", ".", "_values", ")", "\n", "# v = tf.get_variable('attention_v', [self._uttr_level_num_units], dtype = self.dtype)", "\n", "score", "=", "tf", ".", "reduce_sum", "(", "self", ".", "_attention_v_ul", "*", "tf", ".", "tanh", "(", "keys", "+", "processed_query", ")", ",", "[", "2", "]", ")", "\n", "alignments", "=", "self", ".", "_probability_fn", "(", "score", ")", "\n", "next_state", "=", "alignments", "\n", "\n", "", "return", "alignments", ",", "next_state", ",", "alignments_w", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.values": [[232, 235], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "values", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_values", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.batch_size": [[236, 239], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.alignments_size": [[240, 243], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "alignments_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_alignments_size", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.alignments_w_size": [[244, 247], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "alignments_w_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_alignments_w_size", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.state_size": [[248, 251], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_alignments_size", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.initial_alignments": [[252, 255], ["_zero_state_tensors"], "methods", ["None"], ["", "def", "initial_alignments", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "        ", "max_time", "=", "self", ".", "_alignments_size", "\n", "return", "_zero_state_tensors", "(", "max_time", ",", "batch_size", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.initial_alignments_w": [[256, 259], ["_zero_state_tensors"], "methods", ["None"], ["", "def", "initial_alignments_w", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "        ", "max_time", "=", "self", ".", "_alignments_w_size", "\n", "return", "_zero_state_tensors", "(", "max_time", ",", "batch_size", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.initial_state": [[260, 262], ["attention.UttrLevelAttentionMechanism.initial_alignments"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.initial_alignments"], ["", "def", "initial_state", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "        ", "return", "self", ".", "initial_alignments", "(", "batch_size", ",", "dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention._maybe_mask_score_no_check": [[8, 14], ["tensorflow.sequence_mask", "tensorflow.where", "tensorflow.ones_like", "tensorflow.shape"], "function", ["None"], ["def", "_maybe_mask_score_no_check", "(", "score", ",", "memory_sequence_length", ",", "score_mask_value", ")", ":", "\n", "    ", "if", "memory_sequence_length", "is", "None", ":", "\n", "        ", "return", "score", "\n", "", "score_mask", "=", "tf", ".", "sequence_mask", "(", "memory_sequence_length", ",", "maxlen", "=", "tf", ".", "shape", "(", "score", ")", "[", "1", "]", ")", "\n", "score_mask_values", "=", "score_mask_value", "*", "tf", ".", "ones_like", "(", "score", ")", "\n", "return", "tf", ".", "where", "(", "score_mask", ",", "score", ",", "score_mask_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attention._maybe_mask_score_softmax": [[15, 21], ["tensorflow.sequence_mask", "tensorflow.where", "tensorflow.ones_like", "tensorflow.shape"], "function", ["None"], ["", "def", "_maybe_mask_score_softmax", "(", "score", ",", "memory_sequence_length", ")", ":", "\n", "    ", "if", "memory_sequence_length", "is", "None", ":", "\n", "        ", "return", "score", "\n", "", "score_mask", "=", "tf", ".", "sequence_mask", "(", "memory_sequence_length", ",", "maxlen", "=", "tf", ".", "shape", "(", "score", ")", "[", "1", "]", ")", "\n", "score_mask_values", "=", "0.0", "*", "tf", ".", "ones_like", "(", "score", ")", "\n", "return", "tf", ".", "where", "(", "score_mask", ",", "score", ",", "score_mask_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapperState.clone": [[12, 21], ["tensorflow.contrib.framework.nest.map_structure", "super()._replace", "isinstance", "isinstance", "tensorflow.contrib.framework.with_same_shape"], "methods", ["None"], ["    ", "def", "clone", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "def", "with_same_shape", "(", "old", ",", "new", ")", ":", "\n", "            ", "if", "isinstance", "(", "old", ",", "tf", ".", "Tensor", ")", "and", "isinstance", "(", "new", ",", "tf", ".", "Tensor", ")", ":", "\n", "                ", "return", "tf", ".", "contrib", ".", "framework", ".", "with_same_shape", "(", "old", ",", "new", ")", "\n", "", "return", "new", "\n", "", "return", "tf", ".", "contrib", ".", "framework", ".", "nest", ".", "map_structure", "(", "\n", "with_same_shape", ",", "\n", "self", ",", "\n", "super", "(", "MyAttentionWrapperState", ",", "self", ")", ".", "_replace", "(", "**", "kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.__init__": [[40, 60], ["tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.__init__"], ["def", "__init__", "(", "self", ",", "\n", "cell", ",", "\n", "attention_mechanism", ",", "\n", "emotion_vector", ",", "\n", "attention_layer_size", "=", "None", ",", "\n", "alignment_history", "=", "True", ",", "\n", "cell_input_fn", "=", "None", ",", "\n", "output_attention", "=", "False", ",", "\n", "initial_cell_state", "=", "None", ",", "\n", "name", "=", "None", ",", "\n", "attention_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cell", ",", "attention_mechanism", ",", "\n", "attention_layer_size", "=", "attention_layer_size", ",", "\n", "alignment_history", "=", "alignment_history", ",", "\n", "cell_input_fn", "=", "cell_input_fn", ",", "\n", "output_attention", "=", "output_attention", ",", "\n", "initial_cell_state", "=", "initial_cell_state", ",", "\n", "name", "=", "name", ",", "\n", "attention_layer", "=", "attention_layer", ")", "\n", "self", ".", "_emotion_vector", "=", "emotion_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.output_size": [[61, 64], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_cell", ".", "output_size", "+", "self", ".", "_emotion_vector", ".", "shape", "[", "1", "]", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.state_size": [[65, 85], ["attn_wrapper.MyAttentionWrapperState", "tensorflow.TensorShape", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"The `state_size` property of `MyAttentionWrapper`.\n        Returns:\n          A `MyAttentionWrapperState` tuple containing shapes used by this object.\n        \"\"\"", "\n", "return", "MyAttentionWrapperState", "(", "\n", "cell_state", "=", "self", ".", "_cell", ".", "state_size", ",", "\n", "time", "=", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "attention", "=", "self", ".", "_attention_layer_size", ",", "\n", "alignments", "=", "self", ".", "_item_or_tuple", "(", "\n", "a", ".", "alignments_size", "for", "a", "in", "self", ".", "_attention_mechanisms", ")", ",", "\n", "attention_state", "=", "self", ".", "_item_or_tuple", "(", "\n", "a", ".", "state_size", "for", "a", "in", "self", ".", "_attention_mechanisms", ")", ",", "\n", "alignment_history_ul", "=", "self", ".", "_item_or_tuple", "(", "\n", "a", ".", "alignments_size", "if", "self", ".", "_alignment_history", "else", "(", ")", "\n", "for", "a", "in", "self", ".", "_attention_mechanisms", ")", ",", "\n", "alignment_history_wl", "=", "self", ".", "_item_or_tuple", "(", "\n", "a", ".", "alignments_w_size", "if", "self", ".", "_alignment_history", "else", "(", ")", "\n", "for", "a", "in", "self", ".", "_attention_mechanisms", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.zero_state": [[86, 159], ["tensorflow.name_scope", "enumerate", "tensorflow.concat", "attn_wrapper.MyAttentionWrapperState", "attn_wrapper.MyAttentionWrapper._cell.zero_state", "tensorflow.control_dependencies", "tensorflow.contrib.framework.nest.map_structure", "attn_wrapper._compute_attention", "initial_alignments.append", "initial_alignments_w.append", "all_attentions.append", "attn_wrapper.MyAttentionWrapper._batch_size_checks", "tensorflow.TensorArray", "tensorflow.TensorArray", "initial_alignment_history_ul[].write", "initial_alignment_history_wl[].write", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "type", "tensorflow.identity", "tensorflow.zeros", "attention_mechanism.initial_state", "a.initial_alignments", "a.initial_alignments_w"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.zero_state", "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper._compute_attention", "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.initial_state", "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.initial_alignments", "home.repos.pwc.inspect_result.yuboxie_meed.None.attention.UttrLevelAttentionMechanism.initial_alignments_w"], ["", "def", "zero_state", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"Return an initial (zero) state tuple for this `MyAttentionWrapper`.\n        **NOTE** Please see the initializer documentation for details of how\n        to call `zero_state` if using a `MyAttentionWrapper` with a\n        `BeamSearchDecoder`.\n        Args:\n          batch_size: `0D` integer tensor: the batch size.\n          dtype: The internal state data type.\n        Returns:\n          An `MyAttentionWrapperState` tuple containing zeroed out tensors and,\n          possibly, empty `TensorArray` objects.\n        Raises:\n          ValueError: (or, possibly at runtime, InvalidArgument), if\n            `batch_size` does not match the output size of the encoder passed\n            to the wrapper object at initialization time.\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "type", "(", "self", ")", ".", "__name__", "+", "\"ZeroState\"", ",", "values", "=", "[", "batch_size", "]", ")", ":", "\n", "            ", "if", "self", ".", "_initial_cell_state", "is", "not", "None", ":", "\n", "                ", "cell_state", "=", "self", ".", "_initial_cell_state", "\n", "", "else", ":", "\n", "                ", "cell_state", "=", "self", ".", "_cell", ".", "zero_state", "(", "batch_size", ",", "dtype", ")", "\n", "", "error_message", "=", "(", "\n", "\"When calling zero_state of MyAttentionWrapper %s: \"", "%", "self", ".", "_base_name", "+", "\n", "\"Non-matching batch sizes between the memory \"", "\n", "\"(encoder output) and the requested batch size.  Are you using \"", "\n", "\"the BeamSearchDecoder?  If so, make sure your encoder output has \"", "\n", "\"been tiled to beam_width via tf.contrib.seq2seq.tile_batch, and \"", "\n", "\"the batch_size= argument passed to zero_state is \"", "\n", "\"batch_size * beam_width.\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "self", ".", "_batch_size_checks", "(", "batch_size", ",", "error_message", ")", ")", ":", "\n", "                ", "cell_state", "=", "tf", ".", "contrib", ".", "framework", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "s", ":", "tf", ".", "identity", "(", "s", ",", "name", "=", "\"checked_cell_state\"", ")", ",", "\n", "cell_state", ")", "\n", "", "initial_alignments", "=", "[", "]", "\n", "initial_alignments_w", "=", "[", "]", "\n", "all_attentions", "=", "[", "]", "\n", "initial_alignment_history_ul", "=", "[", "\n", "tf", ".", "TensorArray", "(", "\n", "dtype", ",", "\n", "size", "=", "0", ",", "\n", "dynamic_size", "=", "True", ",", "\n", "element_shape", "=", "a", ".", "initial_alignments", "(", "batch_size", ",", "dtype", ")", ".", "shape", ")", "\n", "if", "self", ".", "_alignment_history", "else", "(", ")", "\n", "for", "a", "in", "self", ".", "_attention_mechanisms", "]", "\n", "initial_alignment_history_wl", "=", "[", "\n", "tf", ".", "TensorArray", "(", "\n", "dtype", ",", "\n", "size", "=", "0", ",", "\n", "dynamic_size", "=", "True", ",", "\n", "element_shape", "=", "a", ".", "initial_alignments_w", "(", "batch_size", ",", "dtype", ")", ".", "shape", ")", "\n", "if", "self", ".", "_alignment_history", "else", "(", ")", "\n", "for", "a", "in", "self", ".", "_attention_mechanisms", "]", "\n", "for", "i", ",", "attention_mechanism", "in", "enumerate", "(", "self", ".", "_attention_mechanisms", ")", ":", "\n", "                ", "attention", ",", "alignments", ",", "_", ",", "alignments_w", "=", "_compute_attention", "(", "\n", "attention_mechanism", ",", "cell_state", ",", "None", ",", "None", ")", "\n", "initial_alignment_history_ul", "[", "i", "]", "=", "initial_alignment_history_ul", "[", "i", "]", ".", "write", "(", "\n", "0", ",", "alignments", ")", "if", "self", ".", "_alignment_history", "else", "(", ")", "\n", "initial_alignment_history_wl", "[", "i", "]", "=", "initial_alignment_history_wl", "[", "i", "]", ".", "write", "(", "\n", "0", ",", "alignments_w", ")", "if", "self", ".", "_alignment_history", "else", "(", ")", "\n", "initial_alignments", ".", "append", "(", "alignments", ")", "\n", "initial_alignments_w", ".", "append", "(", "alignments_w", ")", "\n", "all_attentions", ".", "append", "(", "attention", ")", "\n", "", "attention", "=", "tf", ".", "concat", "(", "all_attentions", ",", "1", ")", "\n", "return", "MyAttentionWrapperState", "(", "\n", "cell_state", "=", "cell_state", ",", "\n", "time", "=", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "+", "1", ",", "\n", "attention", "=", "attention", ",", "\n", "alignments", "=", "self", ".", "_item_or_tuple", "(", "initial_alignments", ")", ",", "\n", "attention_state", "=", "self", ".", "_item_or_tuple", "(", "\n", "attention_mechanism", ".", "initial_state", "(", "batch_size", ",", "dtype", ")", "\n", "for", "attention_mechanism", "in", "self", ".", "_attention_mechanisms", ")", ",", "\n", "alignment_history_ul", "=", "self", ".", "_item_or_tuple", "(", "initial_alignment_history_ul", ")", ",", "\n", "alignment_history_wl", "=", "self", ".", "_item_or_tuple", "(", "initial_alignment_history_wl", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.call": [[160, 225], ["attn_wrapper.MyAttentionWrapper._cell_input_fn", "attn_wrapper.MyAttentionWrapper._cell", "enumerate", "tensorflow.concat", "attn_wrapper.MyAttentionWrapperState", "isinstance", "TypeError", "tensorflow.control_dependencies", "tensorflow.identity", "attn_wrapper._compute_attention", "all_attention_states.append", "all_alignments.append", "all_attentions.append", "maybe_all_histories_ul.append", "maybe_all_histories_wl.append", "tensorflow.shape", "attn_wrapper.MyAttentionWrapper._batch_size_checks", "previous_alignment_history_ul[].write", "previous_alignment_history_wl[].write", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "attn_wrapper.MyAttentionWrapper._item_or_tuple", "tensorflow.concat", "type"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper._compute_attention"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "state", ",", "MyAttentionWrapperState", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Expected state to be instance of MyAttentionWrapperState. \"", "\n", "\"Received type %s instead.\"", "%", "type", "(", "state", ")", ")", "\n", "\n", "", "cell_inputs", "=", "self", ".", "_cell_input_fn", "(", "inputs", ",", "state", ".", "attention", ")", "\n", "cell_state", "=", "state", ".", "cell_state", "\n", "cell_output", ",", "next_cell_state", "=", "self", ".", "_cell", "(", "cell_inputs", ",", "cell_state", ")", "\n", "\n", "cell_batch_size", "=", "(", "\n", "cell_output", ".", "shape", "[", "0", "]", ".", "value", "or", "tf", ".", "shape", "(", "cell_output", ")", "[", "0", "]", ")", "\n", "error_message", "=", "(", "\n", "\"When applying MyAttentionWrapper %s: \"", "%", "self", ".", "name", "+", "\n", "\"Non-matching batch sizes between the memory \"", "\n", "\"(encoder output) and the query (decoder output).  Are you using \"", "\n", "\"the BeamSearchDecoder?  You may need to tile your memory input via \"", "\n", "\"the tf.contrib.seq2seq.tile_batch function with argument \"", "\n", "\"multiple=beam_width.\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "self", ".", "_batch_size_checks", "(", "cell_batch_size", ",", "error_message", ")", ")", ":", "\n", "            ", "cell_output", "=", "tf", ".", "identity", "(", "\n", "cell_output", ",", "name", "=", "\"checked_cell_output\"", ")", "\n", "\n", "", "if", "self", ".", "_is_multi", ":", "\n", "            ", "previous_attention_state", "=", "state", ".", "attention_state", "\n", "previous_alignment_history_ul", "=", "state", ".", "alignment_history_ul", "\n", "previous_alignment_history_wl", "=", "state", ".", "alignment_history_wl", "\n", "", "else", ":", "\n", "            ", "previous_attention_state", "=", "[", "state", ".", "attention_state", "]", "\n", "previous_alignment_history_ul", "=", "[", "state", ".", "alignment_history_ul", "]", "\n", "previous_alignment_history_wl", "=", "[", "state", ".", "alignment_history_wl", "]", "\n", "\n", "", "all_alignments", "=", "[", "]", "\n", "all_attentions", "=", "[", "]", "\n", "all_attention_states", "=", "[", "]", "\n", "maybe_all_histories_ul", "=", "[", "]", "\n", "maybe_all_histories_wl", "=", "[", "]", "\n", "for", "i", ",", "attention_mechanism", "in", "enumerate", "(", "self", ".", "_attention_mechanisms", ")", ":", "\n", "            ", "attention", ",", "alignments", ",", "next_attention_state", ",", "alignments_w", "=", "_compute_attention", "(", "\n", "attention_mechanism", ",", "cell_output", ",", "previous_attention_state", "[", "i", "]", ",", "\n", "self", ".", "_attention_layers", "[", "i", "]", "if", "self", ".", "_attention_layers", "else", "None", ")", "\n", "alignment_history_ul", "=", "previous_alignment_history_ul", "[", "i", "]", ".", "write", "(", "\n", "state", ".", "time", ",", "alignments", ")", "if", "self", ".", "_alignment_history", "else", "(", ")", "\n", "alignment_history_wl", "=", "previous_alignment_history_wl", "[", "i", "]", ".", "write", "(", "\n", "state", ".", "time", ",", "alignments_w", ")", "if", "self", ".", "_alignment_history", "else", "(", ")", "\n", "\n", "all_attention_states", ".", "append", "(", "next_attention_state", ")", "\n", "all_alignments", ".", "append", "(", "alignments", ")", "\n", "all_attentions", ".", "append", "(", "attention", ")", "\n", "maybe_all_histories_ul", ".", "append", "(", "alignment_history_ul", ")", "\n", "maybe_all_histories_wl", ".", "append", "(", "alignment_history_wl", ")", "\n", "\n", "", "attention", "=", "tf", ".", "concat", "(", "all_attentions", ",", "1", ")", "\n", "next_state", "=", "MyAttentionWrapperState", "(", "\n", "time", "=", "state", ".", "time", "+", "1", ",", "\n", "cell_state", "=", "next_cell_state", ",", "\n", "attention", "=", "attention", ",", "\n", "attention_state", "=", "self", ".", "_item_or_tuple", "(", "all_attention_states", ")", ",", "\n", "alignments", "=", "self", ".", "_item_or_tuple", "(", "all_alignments", ")", ",", "\n", "alignment_history_ul", "=", "self", ".", "_item_or_tuple", "(", "maybe_all_histories_ul", ")", ",", "\n", "alignment_history_wl", "=", "self", ".", "_item_or_tuple", "(", "maybe_all_histories_wl", ")", ")", "\n", "\n", "if", "self", ".", "_output_attention", ":", "\n", "            ", "return", "attention", ",", "next_state", "\n", "", "else", ":", "\n", "            ", "return", "tf", ".", "concat", "(", "[", "cell_output", ",", "self", ".", "_emotion_vector", "]", ",", "1", ")", ",", "next_state", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper._compute_attention": [[22, 37], ["attention_mechanism", "tensorflow.expand_dims", "tensorflow.matmul", "tensorflow.squeeze", "attention_layer", "tensorflow.concat"], "function", ["None"], ["", "", "def", "_compute_attention", "(", "attention_mechanism", ",", "cell_output", ",", "attention_state", ",", "\n", "attention_layer", ")", ":", "\n", "    ", "alignments", ",", "next_attention_state", ",", "alignments_w", "=", "attention_mechanism", "(", "\n", "cell_output", ",", "state", "=", "attention_state", ")", "\n", "\n", "expanded_alignments", "=", "tf", ".", "expand_dims", "(", "alignments", ",", "1", ")", "\n", "context", "=", "tf", ".", "matmul", "(", "expanded_alignments", ",", "attention_mechanism", ".", "values", ")", "\n", "context", "=", "tf", ".", "squeeze", "(", "context", ",", "[", "1", "]", ")", "\n", "\n", "if", "attention_layer", "is", "not", "None", ":", "\n", "        ", "attention", "=", "attention_layer", "(", "tf", ".", "concat", "(", "[", "cell_output", ",", "context", "]", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "        ", "attention", "=", "context", "\n", "\n", "", "return", "attention", ",", "alignments", ",", "next_attention_state", ",", "alignments_w", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.Options.__init__": [[10, 42], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.__init__"], ["def", "__init__", "(", "self", ",", "mode", ",", "num_epochs", ",", "batch_size", ",", "learning_rate", ",", "beam_width", ",", "\n", "vocab_size", ",", "max_hist_len", ",", "max_uttr_len", ",", "go_index", ",", "eos_index", ",", "\n", "word_embed_size", ",", "emot_input_layer_size", ",", "n_hidden_units_enc_s", ",", "\n", "n_hidden_units_enc_e", ",", "n_hidden_units_dec", ",", "n_emot", ",", "\n", "word_level_attn_depth", ",", "uttr_level_attn_depth", ",", "\n", "beta", ",", "word_embeddings", ")", ":", "\n", "        ", "super", "(", "Options", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "num_epochs", "=", "num_epochs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "beam_width", "=", "beam_width", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "max_hist_len", "=", "max_hist_len", "\n", "self", ".", "max_uttr_len", "=", "max_uttr_len", "\n", "self", ".", "go_index", "=", "go_index", "\n", "self", ".", "eos_index", "=", "eos_index", "\n", "\n", "self", ".", "word_embed_size", "=", "word_embed_size", "\n", "self", ".", "emot_input_layer_size", "=", "emot_input_layer_size", "\n", "self", ".", "n_hidden_units_enc_s", "=", "n_hidden_units_enc_s", "\n", "self", ".", "n_hidden_units_enc_e", "=", "n_hidden_units_enc_e", "\n", "self", ".", "n_hidden_units_dec", "=", "n_hidden_units_dec", "\n", "self", ".", "n_emot", "=", "n_emot", "\n", "\n", "self", ".", "word_level_attn_depth", "=", "word_level_attn_depth", "\n", "self", ".", "uttr_level_attn_depth", "=", "uttr_level_attn_depth", "\n", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "word_embeddings", "=", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.__init__": [[45, 50], ["object.__init__", "model.MEED.build_graph", "tensorflow.Session"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.__init__", "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.build_graph"], ["def", "__init__", "(", "self", ",", "options", ")", ":", "\n", "        ", "super", "(", "MEED", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "options", "=", "options", "\n", "self", ".", "build_graph", "(", ")", "\n", "self", ".", "session", "=", "tf", ".", "Session", "(", "graph", "=", "self", ".", "graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.__del__": [[51, 54], ["model.MEED.session.close", "print"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "session", ".", "close", "(", ")", "\n", "print", "(", "'TensorFlow session is closed.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.build_graph": [[55, 164], ["print", "tensorflow.Graph", "model.MEED.graph.as_default", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.variable_scope", "tensorflow.Variable", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "tensorflow.nn.rnn_cell.GRUCell", "tensorflow.nn.rnn_cell.GRUCell", "range", "tensorflow.stack", "tensorflow.variable_scope", "tensorflow.layers.Dense", "tensorflow.layers.Dense.", "tensorflow.nn.rnn_cell.GRUCell", "tensorflow.nn.dynamic_rnn", "tensorflow.transpose", "tensorflow.contrib.seq2seq.tile_batch", "tensorflow.transpose", "tensorflow.contrib.seq2seq.tile_batch", "tensorflow.transpose", "tensorflow.contrib.seq2seq.tile_batch", "tensorflow.contrib.seq2seq.tile_batch", "tensorflow.variable_scope", "attention.UttrLevelAttentionMechanism", "tensorflow.nn.rnn_cell.GRUCell", "attn_wrapper.MyAttentionWrapper", "tensorflow.layers.Dense", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.transpose.append", "tensorflow.transpose", "tensorflow.nn.dynamic_rnn", "tensorflow.layers.Dense.apply", "tensorflow.sequence_mask", "tensorflow.contrib.seq2seq.sequence_loss", "tensorflow.contrib.seq2seq.sequence_loss", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.global_variables_initializer", "tensorflow.constant", "tensorflow.contrib.seq2seq.BeamSearchDecoder", "tensorflow.contrib.seq2seq.dynamic_decode", "final_state[].alignment_history_ul.stack", "final_state[].alignment_history_wl.stack", "tensorflow.concat", "tensorflow.truncated_normal_initializer", "tensorflow.truncated_normal_initializer", "attn_wrapper.MyAttentionWrapper.zero_state", "tensorflow.train.AdamOptimizer", "attn_wrapper.MyAttentionWrapper.zero_state"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.zero_state", "home.repos.pwc.inspect_result.yuboxie_meed.None.attn_wrapper.MyAttentionWrapper.zero_state"], ["", "def", "build_graph", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Building the TensorFlow graph...'", ")", "\n", "opts", "=", "self", ".", "options", "\n", "\n", "self", ".", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "enc_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "opts", ".", "max_hist_len", ",", "opts", ".", "batch_size", ",", "opts", ".", "max_uttr_len", "]", ")", "\n", "self", ".", "enc_input_e", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "opts", ".", "batch_size", ",", "opts", ".", "max_hist_len", ",", "opts", ".", "n_emot", "]", ")", "\n", "self", ".", "dec_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "opts", ".", "batch_size", ",", "opts", ".", "max_uttr_len", "+", "1", "]", ")", "\n", "self", ".", "target", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "opts", ".", "batch_size", ",", "opts", ".", "max_uttr_len", "+", "1", "]", ")", "\n", "\n", "self", ".", "enc_input_len", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "opts", ".", "max_hist_len", ",", "opts", ".", "batch_size", "]", ")", "\n", "self", ".", "dec_input_len", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "opts", ".", "batch_size", "]", ")", "\n", "self", ".", "hist_len", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "opts", ".", "batch_size", "]", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'embedding'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "# word_embeddings = tf.Variable(tf.random_uniform([opts.vocab_size, opts.word_embed_size], -1.0, 1.0),", "\n", "#     name = 'word_embeddings')", "\n", "                ", "word_embeddings", "=", "tf", ".", "Variable", "(", "opts", ".", "word_embeddings", ",", "name", "=", "'word_embeddings'", ")", "\n", "enc_input_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "word_embeddings", ",", "self", ".", "enc_input", ")", "\n", "dec_input_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "word_embeddings", ",", "self", ".", "dec_input", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'word_level_encoding'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "outputs_enc", "=", "[", "]", "\n", "cell_fw", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "opts", ".", "n_hidden_units_enc_s", ")", "\n", "cell_bw", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "opts", ".", "n_hidden_units_enc_s", ")", "\n", "for", "i", "in", "range", "(", "opts", ".", "max_hist_len", ")", ":", "\n", "                    ", "outputs", ",", "_", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "cell_fw", ",", "cell_bw", ",", "\n", "inputs", "=", "enc_input_embed", "[", "i", ",", ":", ",", ":", ",", ":", "]", ",", "\n", "sequence_length", "=", "self", ".", "enc_input_len", "[", "i", ",", ":", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "outputs_enc", ".", "append", "(", "tf", ".", "concat", "(", "outputs", ",", "2", ")", ")", "\n", "", "outputs_enc", "=", "tf", ".", "stack", "(", "outputs_enc", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'emotion_encoding'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "emot_input_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "opts", ".", "emot_input_layer_size", ",", "activation", "=", "tf", ".", "sigmoid", ",", "\n", "kernel_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "name", "=", "'emot_input_layer'", ")", "\n", "enc_input_e", "=", "emot_input_layer", "(", "self", ".", "enc_input_e", ")", "\n", "\n", "cell_emot", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "opts", ".", "n_hidden_units_enc_e", ")", "\n", "_", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell_emot", ",", "\n", "inputs", "=", "enc_input_e", ",", "\n", "sequence_length", "=", "self", ".", "hist_len", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "emot_vector", "=", "final_state", "*", "opts", ".", "beta", "\n", "\n", "", "if", "opts", ".", "mode", "==", "'PREDICT'", ":", "\n", "                ", "outputs_enc", "=", "tf", ".", "transpose", "(", "outputs_enc", ",", "perm", "=", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", "\n", "outputs_enc", "=", "tile_batch", "(", "outputs_enc", ",", "multiplier", "=", "opts", ".", "beam_width", ")", "\n", "outputs_enc", "=", "tf", ".", "transpose", "(", "outputs_enc", ",", "perm", "=", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", "\n", "tiled_enc_input_len", "=", "tile_batch", "(", "tf", ".", "transpose", "(", "self", ".", "enc_input_len", ")", ",", "multiplier", "=", "opts", ".", "beam_width", ")", "\n", "tiled_enc_input_len", "=", "tf", ".", "transpose", "(", "tiled_enc_input_len", ")", "\n", "tiled_hist_len", "=", "tile_batch", "(", "self", ".", "hist_len", ",", "multiplier", "=", "opts", ".", "beam_width", ")", "\n", "tiled_emot_vector", "=", "tile_batch", "(", "emot_vector", ",", "multiplier", "=", "opts", ".", "beam_width", ")", "\n", "", "else", ":", "\n", "                ", "tiled_enc_input_len", "=", "self", ".", "enc_input_len", "\n", "tiled_hist_len", "=", "self", ".", "hist_len", "\n", "tiled_emot_vector", "=", "emot_vector", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'decoding'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "vs", ":", "\n", "                ", "attn_mechanism", "=", "UttrLevelAttentionMechanism", "(", "word_level_num_units", "=", "opts", ".", "word_level_attn_depth", ",", "\n", "uttr_level_num_units", "=", "opts", ".", "uttr_level_attn_depth", ",", "\n", "n_hidden_units", "=", "opts", ".", "n_hidden_units_enc_s", ",", "\n", "memory", "=", "outputs_enc", ",", "\n", "memory_sequence_length", "=", "tiled_enc_input_len", ",", "\n", "hist_length", "=", "tiled_hist_len", ")", "\n", "cell_dec", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "opts", ".", "n_hidden_units_dec", ")", "\n", "cell_dec", "=", "MyAttentionWrapper", "(", "cell_dec", ",", "attn_mechanism", ",", "tiled_emot_vector", ")", "\n", "output_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "opts", ".", "vocab_size", "-", "1", ",", "\n", "kernel_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "name", "=", "'output_layer'", ")", "\n", "\n", "# Train", "\n", "if", "opts", ".", "mode", "==", "'TRAIN'", ":", "\n", "                    ", "outputs_dec", ",", "_", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell", "=", "cell_dec", ",", "\n", "inputs", "=", "dec_input_embed", ",", "\n", "sequence_length", "=", "self", ".", "dec_input_len", ",", "\n", "initial_state", "=", "cell_dec", ".", "zero_state", "(", "opts", ".", "batch_size", ",", "tf", ".", "float32", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "scope", "=", "vs", ")", "\n", "logits", "=", "output_layer", ".", "apply", "(", "outputs_dec", ")", "\n", "weights", "=", "tf", ".", "sequence_mask", "(", "self", ".", "dec_input_len", ",", "\n", "maxlen", "=", "opts", ".", "max_uttr_len", "+", "1", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "loss", "=", "sequence_loss", "(", "logits", ",", "self", ".", "target", ",", "weights", ")", "\n", "self", ".", "loss_batch", "=", "sequence_loss", "(", "logits", ",", "self", ".", "target", ",", "weights", ",", "average_across_batch", "=", "False", ")", "\n", "self", ".", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "opts", ".", "learning_rate", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "self", ".", "init", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "# Predict", "\n", "", "if", "opts", ".", "mode", "==", "'PREDICT'", ":", "\n", "                    ", "start_tokens", "=", "tf", ".", "constant", "(", "opts", ".", "go_index", ",", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "opts", ".", "batch_size", "]", ")", "\n", "bs_decoder", "=", "BeamSearchDecoder", "(", "cell", "=", "cell_dec", ",", "embedding", "=", "word_embeddings", ",", "\n", "start_tokens", "=", "start_tokens", ",", "\n", "end_token", "=", "opts", ".", "eos_index", ",", "\n", "initial_state", "=", "cell_dec", ".", "zero_state", "(", "opts", ".", "batch_size", "*", "opts", ".", "beam_width", ",", "tf", ".", "float32", ")", ",", "\n", "beam_width", "=", "opts", ".", "beam_width", ",", "\n", "output_layer", "=", "output_layer", ")", "\n", "final_outputs", ",", "final_state", ",", "_", "=", "dynamic_decode", "(", "bs_decoder", ",", "\n", "impute_finished", "=", "False", ",", "\n", "maximum_iterations", "=", "opts", ".", "max_uttr_len", "+", "1", ",", "\n", "scope", "=", "vs", ")", "\n", "self", ".", "predicted_ids", "=", "final_outputs", ".", "predicted_ids", "\n", "self", ".", "scores", "=", "final_outputs", ".", "beam_search_decoder_output", ".", "scores", "\n", "self", ".", "uttr_level_alignments", "=", "final_state", "[", "0", "]", ".", "alignment_history_ul", ".", "stack", "(", ")", "\n", "self", ".", "word_level_alignments", "=", "final_state", "[", "0", "]", ".", "alignment_history_wl", ".", "stack", "(", ")", "\n", "self", ".", "final_sequence_lengths", "=", "final_state", "[", "3", "]", "\n", "\n", "", "", "self", ".", "tvars", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.init_tf_vars": [[165, 169], ["model.MEED.session.run", "print"], "methods", ["None"], ["", "", "def", "init_tf_vars", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "options", ".", "mode", "==", "'TRAIN'", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "init", ")", "\n", "print", "(", "'TensorFlow variables initialized.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.validate": [[170, 204], ["range", "numpy.exp", "model.MEED.session.run"], "methods", ["None"], ["", "", "def", "validate", "(", "self", ",", "valid_set", ")", ":", "\n", "        ", "\"\"\"Validate the model on the validation set.\n        Args:\n            valid_set: Dictionary containing:\n                enc_input: Input to the word-level encoders (syntax).\n                    Shaped `[max_hist_len, N, max_uttr_len]`.\n                enc_input_e: Input to the word-level encoders (emotion).\n                    Shaped `[N, max_hist_len, n_emot]`.\n                dec_input: Input to the decoder. Shaped `[N, max_uttr_len]`.\n                target: Targets, expected output of the decoder. Shaped `[N, max_uttr_len]`.\n                enc_input_len: Lengths of the input to the word-level encoders. Shaped `[max_hist_len, N]`.\n                dec_input_len: Lengths of the input to the decoder. Shaped `[N]`.\n                hist_len: Lengths of the conversation history. Shaped `[N]`.\n                (N should be a multiple of batch_size)\n        Returns:\n            perplexity: Perplexity on the validation set.\n        \"\"\"", "\n", "opts", "=", "self", ".", "options", "\n", "num_examples", "=", "valid_set", "[", "'enc_input'", "]", ".", "shape", "[", "1", "]", "\n", "num_batches", "=", "num_examples", "//", "opts", ".", "batch_size", "\n", "loss", "=", "0.0", "\n", "for", "batch", "in", "range", "(", "num_batches", ")", ":", "\n", "            ", "s", "=", "batch", "*", "opts", ".", "batch_size", "\n", "t", "=", "s", "+", "opts", ".", "batch_size", "\n", "feed_dict", "=", "{", "self", ".", "enc_input", ":", "valid_set", "[", "'enc_input'", "]", "[", ":", ",", "s", ":", "t", ",", ":", "]", ",", "\n", "self", ".", "enc_input_e", ":", "valid_set", "[", "'enc_input_e'", "]", "[", "s", ":", "t", ",", ":", ",", ":", "]", ",", "\n", "self", ".", "dec_input", ":", "valid_set", "[", "'dec_input'", "]", "[", "s", ":", "t", ",", ":", "]", ",", "\n", "self", ".", "target", ":", "valid_set", "[", "'target'", "]", "[", "s", ":", "t", ",", ":", "]", ",", "\n", "self", ".", "enc_input_len", ":", "valid_set", "[", "'enc_input_len'", "]", "[", ":", ",", "s", ":", "t", "]", ",", "\n", "self", ".", "dec_input_len", ":", "valid_set", "[", "'dec_input_len'", "]", "[", "s", ":", "t", "]", ",", "\n", "self", ".", "hist_len", ":", "valid_set", "[", "'hist_len'", "]", "[", "s", ":", "t", "]", "}", "\n", "loss_val", "=", "self", ".", "session", ".", "run", "(", "self", ".", "loss", ",", "feed_dict", "=", "feed_dict", ")", "\n", "loss", "+=", "loss_val", "\n", "", "return", "np", ".", "exp", "(", "loss", "/", "num_batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.validate_batch": [[205, 215], ["model.MEED.session.run"], "methods", ["None"], ["", "def", "validate_batch", "(", "self", ",", "valid_set", ")", ":", "\n", "        ", "feed_dict", "=", "{", "self", ".", "enc_input", ":", "valid_set", "[", "'enc_input'", "]", ",", "\n", "self", ".", "enc_input_e", ":", "valid_set", "[", "'enc_input_e'", "]", ",", "\n", "self", ".", "dec_input", ":", "valid_set", "[", "'dec_input'", "]", ",", "\n", "self", ".", "target", ":", "valid_set", "[", "'target'", "]", ",", "\n", "self", ".", "enc_input_len", ":", "valid_set", "[", "'enc_input_len'", "]", ",", "\n", "self", ".", "dec_input_len", ":", "valid_set", "[", "'dec_input_len'", "]", ",", "\n", "self", ".", "hist_len", ":", "valid_set", "[", "'hist_len'", "]", "}", "\n", "loss_batch_val", "=", "self", ".", "session", ".", "run", "(", "self", ".", "loss_batch", ",", "feed_dict", "=", "feed_dict", ")", "\n", "return", "loss_batch_val", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.train": [[216, 263], ["print", "range", "numpy.random.permutation", "range", "model.MEED.save", "range", "print", "range", "model.MEED.session.run", "print", "model.MEED.validate", "valid_ppl.append", "os.path.join", "print", "numpy.min"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.save", "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.validate"], ["", "def", "train", "(", "self", ",", "train_set", ",", "save_path", ",", "restore_epoch", ",", "valid_set", "=", "None", ")", ":", "\n", "        ", "\"\"\"Train the model.\n        Args:\n            train_set and valid_set: Dictionaries containing:\n                enc_input: Input to the word-level encoders (syntax).\n                    Shaped `[max_hist_len, N, max_uttr_len]`.\n                enc_input_e: Input to the word-level encoders (emotion).\n                    Shaped `[N, max_hist_len, n_emot]`.\n                dec_input: Input to the decoder. Shaped `[N, max_uttr_len]`.\n                target: Targets, expected output of the decoder. Shaped `[N, max_uttr_len]`.\n                enc_input_len: Lengths of the input to the word-level encoders. Shaped `[max_hist_len, N]`.\n                dec_input_len: Lengths of the input to the decoder. Shaped `[N]`.\n                hist_len: Lengths of the conversation history. Shaped `[N]`.\n        \"\"\"", "\n", "print", "(", "'Start to train the model...'", ")", "\n", "opts", "=", "self", ".", "options", "\n", "\n", "num_examples", "=", "train_set", "[", "'enc_input'", "]", ".", "shape", "[", "1", "]", "\n", "num_batches", "=", "num_examples", "//", "opts", ".", "batch_size", "\n", "valid_ppl", "=", "[", "None", "]", "\n", "\n", "for", "epoch", "in", "range", "(", "opts", ".", "num_epochs", ")", ":", "\n", "            ", "perm_indices", "=", "np", ".", "random", ".", "permutation", "(", "range", "(", "num_examples", ")", ")", "\n", "for", "batch", "in", "range", "(", "num_batches", ")", ":", "\n", "                ", "s", "=", "batch", "*", "opts", ".", "batch_size", "\n", "t", "=", "s", "+", "opts", ".", "batch_size", "\n", "batch_indices", "=", "perm_indices", "[", "s", ":", "t", "]", "\n", "feed_dict", "=", "{", "self", ".", "enc_input", ":", "train_set", "[", "'enc_input'", "]", "[", ":", ",", "batch_indices", ",", ":", "]", ",", "\n", "self", ".", "enc_input_e", ":", "train_set", "[", "'enc_input_e'", "]", "[", "batch_indices", ",", ":", ",", ":", "]", ",", "\n", "self", ".", "dec_input", ":", "train_set", "[", "'dec_input'", "]", "[", "batch_indices", ",", ":", "]", ",", "\n", "self", ".", "target", ":", "train_set", "[", "'target'", "]", "[", "batch_indices", ",", ":", "]", ",", "\n", "self", ".", "enc_input_len", ":", "train_set", "[", "'enc_input_len'", "]", "[", ":", ",", "batch_indices", "]", ",", "\n", "self", ".", "dec_input_len", ":", "train_set", "[", "'dec_input_len'", "]", "[", "batch_indices", "]", ",", "\n", "self", ".", "hist_len", ":", "train_set", "[", "'hist_len'", "]", "[", "batch_indices", "]", "}", "\n", "_", ",", "loss_val", "=", "self", ".", "session", ".", "run", "(", "[", "self", ".", "optimizer", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "print", "(", "'Epoch {:03d}/{:03d}, valid ppl = {}, batch {:04d}/{:04d}, train loss = {}'", ".", "format", "(", "epoch", "+", "1", ",", "\n", "opts", ".", "num_epochs", ",", "valid_ppl", "[", "-", "1", "]", ",", "batch", "+", "1", ",", "num_batches", ",", "loss_val", ")", ",", "flush", "=", "True", ")", "\n", "\n", "", "if", "valid_set", "is", "not", "None", ":", "\n", "                ", "ppl", "=", "self", ".", "validate", "(", "valid_set", ")", "\n", "valid_ppl", ".", "append", "(", "ppl", ")", "\n", "", "self", ".", "save", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'model_epoch_{:03d}.ckpt'", ".", "format", "(", "restore_epoch", "+", "epoch", "+", "1", ")", ")", ")", "\n", "\n", "", "if", "valid_set", "is", "not", "None", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "opts", ".", "num_epochs", ")", ":", "\n", "                ", "print", "(", "'Epoch {:03d}, valid ppl = {}'", ".", "format", "(", "epoch", "+", "1", ",", "valid_ppl", "[", "epoch", "+", "1", "]", ")", ")", "\n", "", "print", "(", "'Beta = {}, lowest ppl = {}'", ".", "format", "(", "opts", ".", "beta", ",", "np", ".", "min", "(", "valid_ppl", "[", "1", ":", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.train_to_tune": [[264, 294], ["print", "range", "numpy.random.permutation", "range", "model.MEED.validate", "valid_ppl.append", "model.MEED.save", "range", "model.MEED.session.run", "print", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.validate", "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.save"], ["", "", "def", "train_to_tune", "(", "self", ",", "train_set", ",", "valid_set", ",", "save_path", ")", ":", "\n", "        ", "print", "(", "'Start to train the model...'", ")", "\n", "opts", "=", "self", ".", "options", "\n", "\n", "num_examples", "=", "train_set", "[", "'enc_input'", "]", ".", "shape", "[", "1", "]", "\n", "num_batches", "=", "num_examples", "//", "opts", ".", "batch_size", "\n", "valid_ppl", "=", "[", "None", "]", "\n", "\n", "for", "epoch", "in", "range", "(", "opts", ".", "num_epochs", ")", ":", "\n", "            ", "perm_indices", "=", "np", ".", "random", ".", "permutation", "(", "range", "(", "num_examples", ")", ")", "\n", "for", "batch", "in", "range", "(", "num_batches", ")", ":", "\n", "                ", "s", "=", "batch", "*", "opts", ".", "batch_size", "\n", "t", "=", "s", "+", "opts", ".", "batch_size", "\n", "batch_indices", "=", "perm_indices", "[", "s", ":", "t", "]", "\n", "feed_dict", "=", "{", "self", ".", "enc_input", ":", "train_set", "[", "'enc_input'", "]", "[", ":", ",", "batch_indices", ",", ":", "]", ",", "\n", "self", ".", "enc_input_e", ":", "train_set", "[", "'enc_input_e'", "]", "[", "batch_indices", ",", ":", ",", ":", "]", ",", "\n", "self", ".", "dec_input", ":", "train_set", "[", "'dec_input'", "]", "[", "batch_indices", ",", ":", "]", ",", "\n", "self", ".", "target", ":", "train_set", "[", "'target'", "]", "[", "batch_indices", ",", ":", "]", ",", "\n", "self", ".", "enc_input_len", ":", "train_set", "[", "'enc_input_len'", "]", "[", ":", ",", "batch_indices", "]", ",", "\n", "self", ".", "dec_input_len", ":", "train_set", "[", "'dec_input_len'", "]", "[", "batch_indices", "]", ",", "\n", "self", ".", "hist_len", ":", "train_set", "[", "'hist_len'", "]", "[", "batch_indices", "]", "}", "\n", "_", ",", "loss_val", "=", "self", ".", "session", ".", "run", "(", "[", "self", ".", "optimizer", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "print", "(", "'Epoch {:03d}/{:03d}, valid ppl = {}, batch {:04d}/{:04d}, train loss = {}'", ".", "format", "(", "epoch", "+", "1", ",", "\n", "opts", ".", "num_epochs", ",", "valid_ppl", "[", "-", "1", "]", ",", "batch", "+", "1", ",", "num_batches", ",", "loss_val", ")", ",", "flush", "=", "True", ")", "\n", "\n", "", "ppl", "=", "self", ".", "validate", "(", "valid_set", ")", "\n", "valid_ppl", ".", "append", "(", "ppl", ")", "\n", "self", ".", "save", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'model_epoch_{:03d}.ckpt'", ".", "format", "(", "epoch", "+", "1", ")", ")", ")", "\n", "\n", "", "return", "valid_ppl", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.predict": [[295, 332], ["range", "model.MEED.session.run", "prediction.append", "scores.append", "uttr_level_alignments.append", "word_level_alignments.append", "final_sequence_lengths.append"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "enc_input", ",", "enc_input_e", ",", "enc_input_len", ",", "hist_len", ")", ":", "\n", "        ", "\"\"\"Predict the response based on the input.\n        Args:\n            enc_input: Input to the word-level encoders (syntax).\n                Shaped `[max_hist_len, N, max_uttr_len]`.\n            enc_input_e: Input to the word-level encoders (emotion).\n                Shaped `[N, max_hist_len, n_emot]`.\n            enc_input_len: Lengths of the input to the word-level encoders. Shaped `[max_hist_len, N]`.\n            hist_len: Lengths of the conversation history. Shaped `[N]`.\n            (N should be a multiple of batch_size)\n        Returns:\n            prediction: Predicted word indices. Shaped `[N, max_uttr_len, beam_width]`.\n        \"\"\"", "\n", "opts", "=", "self", ".", "options", "\n", "num_examples", "=", "enc_input", ".", "shape", "[", "1", "]", "\n", "num_batches", "=", "num_examples", "//", "opts", ".", "batch_size", "\n", "prediction", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "uttr_level_alignments", "=", "[", "]", "\n", "word_level_alignments", "=", "[", "]", "\n", "final_sequence_lengths", "=", "[", "]", "\n", "for", "batch", "in", "range", "(", "num_batches", ")", ":", "\n", "            ", "s", "=", "batch", "*", "opts", ".", "batch_size", "\n", "t", "=", "s", "+", "opts", ".", "batch_size", "\n", "feed_dict", "=", "{", "self", ".", "enc_input", ":", "enc_input", "[", ":", ",", "s", ":", "t", ",", ":", "]", ",", "\n", "self", ".", "enc_input_e", ":", "enc_input_e", "[", "s", ":", "t", ",", ":", ",", ":", "]", ",", "\n", "self", ".", "enc_input_len", ":", "enc_input_len", "[", ":", ",", "s", ":", "t", "]", ",", "\n", "self", ".", "hist_len", ":", "hist_len", "[", "s", ":", "t", "]", "}", "\n", "p", ",", "s", ",", "u", ",", "w", ",", "fsl", "=", "self", ".", "session", ".", "run", "(", "[", "self", ".", "predicted_ids", ",", "self", ".", "scores", ",", "\n", "self", ".", "uttr_level_alignments", ",", "self", ".", "word_level_alignments", ",", "\n", "self", ".", "final_sequence_lengths", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "prediction", ".", "append", "(", "p", ")", "\n", "scores", ".", "append", "(", "s", ")", "\n", "uttr_level_alignments", ".", "append", "(", "u", ")", "\n", "word_level_alignments", ".", "append", "(", "w", ")", "\n", "final_sequence_lengths", ".", "append", "(", "fsl", ")", "\n", "", "return", "prediction", ",", "scores", ",", "uttr_level_alignments", ",", "word_level_alignments", ",", "final_sequence_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.save": [[333, 336], ["print", "model.MEED.saver.save"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.save"], ["", "def", "save", "(", "self", ",", "save_path", ")", ":", "\n", "        ", "print", "(", "'Saving the trained model to {}...'", ".", "format", "(", "save_path", ")", ")", "\n", "self", ".", "saver", ".", "save", "(", "self", ".", "session", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.restore": [[337, 340], ["print", "model.MEED.saver.restore"], "methods", ["home.repos.pwc.inspect_result.yuboxie_meed.None.model.MEED.restore"], ["", "def", "restore", "(", "self", ",", "restore_path", ")", ":", "\n", "        ", "print", "(", "'Restoring a pre-trained model from {}...'", ".", "format", "(", "restore_path", ")", ")", "\n", "self", ".", "saver", ".", "restore", "(", "self", ".", "session", ",", "restore_path", ")", "\n", "", "", ""]]}