{"home.repos.pwc.inspect_result.EdinburghNLP_nematus.utils.visualize_probs.print_probdist": [[48, 75], ["enumerate", "outfile.write", "html_text.format", "entries.append", "line.split", "line.split.append", "list", "zip", "entries.append", "map", "line.split", "int", "int", "int"], "function", ["None"], ["def", "print_probdist", "(", "infile", ",", "outfile", ")", ":", "\n", "\n", "    ", "entries", "=", "[", "]", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "infile", ")", ":", "\n", "        ", "if", "i", "%", "3", "==", "0", ":", "\n", "#words = line.split()", "\n", "            ", "entry", "=", "\"\"", "\n", "#for w in words:", "\n", "#entry += \"<th>\" + w + \"</thr>\\n\"", "\n", "entry", "=", "\"<tr><th colspan=\\\"0\\\">\"", "+", "line", "+", "\"</th></tr>\\n\"", "\n", "entries", ".", "append", "(", "entry", ")", "\n", "\n", "", "if", "i", "%", "3", "==", "1", ":", "\n", "            ", "words", "=", "line", ".", "split", "(", ")", "\n", "words", ".", "append", "(", "'&lt;/s&gt;'", ")", "\n", "", "elif", "i", "%", "3", "==", "2", ":", "\n", "            ", "probs", "=", "list", "(", "map", "(", "float", ",", "line", ".", "split", "(", ")", ")", ")", "\n", "entry", "=", "\"\"", "\n", "for", "w", ",", "p", "in", "zip", "(", "words", ",", "probs", ")", ":", "\n", "                ", "color", "=", "'#%02x%02x%02x'", "%", "(", "int", "(", "(", "1", "-", "p", ")", "*", "255", ")", ",", "int", "(", "(", "1", "-", "p", ")", "*", "255", ")", ",", "int", "(", "(", "1", "-", "p", ")", "*", "255", ")", ")", "\n", "entry", "+=", "\"<td bgcolor=\\\"{0}\\\">{1}</td>\"", ".", "format", "(", "color", ",", "w", ")", "\n", "", "entry", "=", "\"<tr>\"", "+", "entry", "+", "\"</tr>\\n\"", "\n", "entries", ".", "append", "(", "entry", ")", "\n", "\n", "\n", "", "", "outfile", ".", "write", "(", "html_text", ".", "format", "(", "'\\n'", ".", "join", "(", "entries", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.utils.copy_unknown_words.copy_unknown_words": [[22, 52], ["json.loads", "source_sent.split", "target_sent.split", "numpy.argmax", "range", "json.dumps().decode().encode", "print", "len", "updated_target_words.append", "updated_target_words.append", "json.dumps().decode", "json.dumps"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder.encode"], ["def", "copy_unknown_words", "(", "filename", ",", "out_filename", ",", "unk_token", ")", ":", "\n", "\t", "for", "line", "in", "filename", ":", "\n", "\t\t", "sent_pair", "=", "json", ".", "loads", "(", "line", ")", "\n", "# \t\tprint \"Translation:\"", "\n", "# \t\tprint sent_pair", "\n", "source_sent", "=", "sent_pair", "[", "\"source_sent\"", "]", "\n", "target_sent", "=", "sent_pair", "[", "\"target_sent\"", "]", "\n", "# matrix dimension: (len(target_sent) + 1) * (len(source_sent) + 1)", "\n", "# sum of values in a row = 1", "\n", "full_alignment", "=", "sent_pair", "[", "\"matrix\"", "]", "\n", "source_words", "=", "source_sent", ".", "split", "(", ")", "\n", "target_words", "=", "target_sent", ".", "split", "(", ")", "\n", "# get the indices of maximum values in each row ", "\n", "# (best alignment for each target word)", "\n", "hard_alignment", "=", "numpy", ".", "argmax", "(", "full_alignment", ",", "axis", "=", "1", ")", "\n", "# \t\tprint hard_alignment", "\n", "\n", "updated_target_words", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "target_words", ")", ")", ":", "\n", "\t\t\t", "if", "target_words", "[", "j", "]", "==", "unk_token", ":", "\n", "\t\t\t\t", "unk_source", "=", "source_words", "[", "hard_alignment", "[", "j", "]", "]", "\n", "updated_target_words", ".", "append", "(", "unk_source", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "updated_target_words", ".", "append", "(", "target_words", "[", "j", "]", ")", "\n", "\n", "", "", "sent_pair", "[", "\"target_sent\"", "]", "=", "\" \"", ".", "join", "(", "updated_target_words", ")", "\n", "# \t\tprint \"Updated translation:\"", "\n", "# \t\tprint sent_pair", "\n", "sent_pair", "=", "json", ".", "dumps", "(", "sent_pair", ")", ".", "decode", "(", "'unicode-escape'", ")", ".", "encode", "(", "'utf8'", ")", "\n", "print", "(", "sent_pair", ",", "file", "=", "out_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_score.TestScore.setUp": [[21, 26], ["test_utils.load_wmt16_model"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_utils.load_wmt16_model"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Download pre-trained models\n        \"\"\"", "\n", "load_wmt16_model", "(", "'en'", ",", "'de'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_score.TestScore.scoreEqual": [[27, 37], ["open", "open", "zip", "out1.readlines", "out2.readlines", "float", "float", "test_score.TestScore.assertAlmostEqual", "line1.split", "line2.split"], "methods", ["None"], ["", "def", "scoreEqual", "(", "self", ",", "output1", ",", "output2", ")", ":", "\n", "        ", "\"\"\"Given two files with translation scores, check that probabilities\n           are equal within rounding error.\n        \"\"\"", "\n", "with", "open", "(", "output1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "out1", ",", "open", "(", "output2", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "out2", ":", "\n", "            ", "for", "(", "line1", ",", "line2", ")", "in", "zip", "(", "out1", ".", "readlines", "(", ")", ",", "out2", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "score1", "=", "float", "(", "line1", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "score2", "=", "float", "(", "line2", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "self", ".", "assertAlmostEqual", "(", "score1", ",", "score2", ",", "places", "=", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_score.TestScore.test_ende": [[39, 51], ["os.chdir", "os.chdir", "test_score.TestScore.scoreEqual", "open", "open", "open", "settings.ScorerSettings.ScorerSettings", "score.main.main"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_score.TestScore.scoreEqual", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.strip_sgml.main"], ["", "", "", "def", "test_ende", "(", "self", ")", ":", "\n", "        ", "os", ".", "chdir", "(", "'models/en-de/'", ")", "\n", "with", "open", "(", "'../../en-de/in'", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "in_file", ",", "open", "(", "'../../en-de/references'", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "ref_file", ",", "open", "(", "'../../en-de/out_score'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "score_file", ":", "\n", "            ", "settings", "=", "ScorerSettings", "(", ")", "\n", "settings", ".", "models", "=", "[", "'model.npz'", "]", "\n", "settings", ".", "minibatch_size", "=", "80", "\n", "settings", ".", "normalization_alpha", "=", "1.0", "\n", "score", "(", "in_file", ",", "ref_file", ",", "score_file", ",", "settings", ")", "\n", "", "os", ".", "chdir", "(", "'../..'", ")", "\n", "self", ".", "scoreEqual", "(", "'en-de/ref_score'", ",", "'en-de/out_score'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_translate.TestTranslate.setUp": [[21, 26], ["test_utils.load_wmt16_model"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_utils.load_wmt16_model"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Download pre-trained models\n        \"\"\"", "\n", "load_wmt16_model", "(", "'en'", ",", "'de'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_translate.TestTranslate.outputEqual": [[27, 34], ["open", "open", "zip", "out1.readlines", "out2.readlines", "test_translate.TestTranslate.assertEqual", "line1.strip", "line2.strip"], "methods", ["None"], ["", "def", "outputEqual", "(", "self", ",", "output1", ",", "output2", ")", ":", "\n", "        ", "\"\"\"given two translation outputs, check that output string is identical\n        \"\"\"", "\n", "with", "open", "(", "output1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "out1", ",", "open", "(", "output2", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "out2", ":", "\n", "            ", "for", "(", "line1", ",", "line2", ")", "in", "zip", "(", "out1", ".", "readlines", "(", ")", ",", "out2", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "line1", ".", "strip", "(", ")", ",", "line2", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_translate.TestTranslate.test_ende": [[36, 49], ["test_translate.TestTranslate.outputEqual", "open", "open", "os.chdir", "settings.TranslationSettings.TranslationSettings", "translate.main.main", "os.chdir"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_translate_sampling.TestTranslate.outputEqual", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.strip_sgml.main"], ["", "", "", "def", "test_ende", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "'en-de/in'", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "in_file", ",", "open", "(", "'en-de/out'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "out_file", ":", "\n", "            ", "os", ".", "chdir", "(", "'models/en-de/'", ")", "\n", "settings", "=", "TranslationSettings", "(", ")", "\n", "settings", ".", "input", "=", "in_file", "\n", "settings", ".", "output", "=", "out_file", "\n", "settings", ".", "models", "=", "[", "\"model.npz\"", "]", "\n", "settings", ".", "beam_size", "=", "12", "\n", "settings", ".", "normalization_alpha", "=", "1.0", "\n", "translate", "(", "settings", "=", "settings", ")", "\n", "os", ".", "chdir", "(", "'../..'", ")", "\n", "", "self", ".", "outputEqual", "(", "'en-de/ref2'", ",", "'en-de/out'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_utils.load_wmt16_model": [[11, 32], ["os.path.join", "os.makedirs", "os.path.exists", "requests.get", "os.path.join", "os.path.exists", "open", "requests.get.iter_content", "shutil.copyfile", "os.path.join", "os.path.join", "f.write", "os.path.exists", "os.path.join", "os.path.join", "os.rename", "theano_tf_convert.theano_to_tensorflow_model", "os.path.join", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.theano_tf_convert.theano_to_tensorflow_model"], ["def", "load_wmt16_model", "(", "src", ",", "target", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "'models'", ",", "'{0}-{1}'", ".", "format", "(", "src", ",", "target", ")", ")", "\n", "try", ":", "\n", "            ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "pass", "\n", "", "for", "filename", "in", "[", "'model.npz.json'", ",", "'model.npz'", ",", "'vocab.{0}.json'", ".", "format", "(", "src", ")", ",", "'vocab.{0}.json'", ".", "format", "(", "target", ")", "]", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", ")", ":", "\n", "                ", "if", "filename", "==", "'model.npz'", "and", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'model.npz.index'", ")", ")", ":", "\n", "                    ", "continue", "\n", "", "r", "=", "requests", ".", "get", "(", "'http://data.statmt.org/rsennrich/wmt16_systems/{0}-{1}/'", ".", "format", "(", "src", ",", "target", ")", "+", "filename", ",", "stream", "=", "True", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "for", "chunk", "in", "r", ".", "iter_content", "(", "1024", "**", "2", ")", ":", "\n", "                        ", "f", ".", "write", "(", "chunk", ")", "\n", "\n", "# regression test is based on Theano model - convert to TF names", "\n", "", "", "if", "filename", "==", "'model.npz.json'", "and", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'model.npz.index'", ")", ")", ":", "\n", "                    ", "copyfile", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'model.npz.json'", ")", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'model-theano.npz.json'", ")", ")", "\n", "", "elif", "filename", "==", "'model.npz'", "and", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'model.npz.index'", ")", ")", ":", "\n", "                    ", "os", ".", "rename", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'model.npz'", ")", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'model-theano.npz'", ")", ")", "\n", "theano_to_tensorflow_model", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'model-theano.npz'", ")", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'model.npz'", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_translate_sampling.TestTranslate.setUp": [[21, 26], ["test_utils.load_wmt16_model"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_utils.load_wmt16_model"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Download pre-trained models\n        \"\"\"", "\n", "load_wmt16_model", "(", "'en'", ",", "'de'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_translate_sampling.TestTranslate.outputEqual": [[27, 34], ["open", "open", "zip", "out1.readlines", "out2.readlines", "test_translate_sampling.TestTranslate.assertEqual", "line1.strip", "line2.strip"], "methods", ["None"], ["", "def", "outputEqual", "(", "self", ",", "output1", ",", "output2", ")", ":", "\n", "        ", "\"\"\"given two translation outputs, check that output string is identical\n        \"\"\"", "\n", "with", "open", "(", "output1", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "out1", ",", "open", "(", "output2", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "out2", ":", "\n", "            ", "for", "(", "line1", ",", "line2", ")", "in", "zip", "(", "out1", ".", "readlines", "(", ")", ",", "out2", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "line1", ".", "strip", "(", ")", ",", "line2", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_translate_sampling.TestTranslate.test_ende": [[36, 51], ["test_translate_sampling.TestTranslate.outputEqual", "open", "open", "os.chdir", "settings.TranslationSettings.TranslationSettings", "translate.main.main", "os.chdir"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.test.test_translate_sampling.TestTranslate.outputEqual", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.strip_sgml.main"], ["", "", "", "def", "test_ende", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "'en-de/in'", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "in_file", ",", "open", "(", "'en-de/out'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "out_file", ":", "\n", "            ", "os", ".", "chdir", "(", "'models/en-de/'", ")", "\n", "settings", "=", "TranslationSettings", "(", ")", "\n", "settings", ".", "input", "=", "in_file", "\n", "settings", ".", "output", "=", "out_file", "\n", "settings", ".", "models", "=", "[", "\"model.npz\"", "]", "\n", "settings", ".", "beam_size", "=", "12", "\n", "settings", ".", "normalization_alpha", "=", "1.0", "\n", "settings", ".", "translation_strategy", "=", "'sampling'", "\n", "settings", ".", "sampling_temperature", "=", "0.4", "\n", "translate", "(", "settings", "=", "settings", ")", "\n", "os", ".", "chdir", "(", "'../..'", ")", "\n", "", "self", ".", "outputEqual", "(", "'en-de/ref2'", ",", "'en-de/out'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.assert_shapes": [[5, 17], ["tensorflow.debugging.assert_shapes", "tensorflow.control_dependencies"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.assert_shapes"], ["def", "assert_shapes", "(", "shapes", ")", ":", "\n", "    ", "\"\"\"Wrapper for tf.debugging.assert_shapes.\"\"\"", "\n", "\n", "# tf.debugging.assert_shapes is only supported in 1.14 and later, so", "\n", "# the call is wrapped in a try-except to allow Nematus to run on earlier", "\n", "# versions.", "\n", "try", ":", "\n", "        ", "assertion_op", "=", "tf", ".", "debugging", ".", "assert_shapes", "(", "shapes", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion_op", "]", ")", ":", "\n", "            ", "pass", "\n", "", "", "except", "(", "AttributeError", ",", "TypeError", ")", "as", "e", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_available_gpus": [[19, 27], ["device_lib.list_local_devices"], "function", ["None"], ["", "", "def", "get_available_gpus", "(", ")", ":", "\n", "    ", "\"\"\"Returns a list of the identifiers of all visible GPUs.\n\n    Source: https://stackoverflow.com/questions/38559755\n    \"\"\"", "\n", "from", "tensorflow", ".", "python", ".", "client", "import", "device_lib", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "return", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list": [[29, 51], ["tensorflow.convert_to_tensor", "tensorflow.shape", "tf.convert_to_tensor.get_shape().as_list", "tensorflow.shape", "list", "range", "tf.convert_to_tensor.get_shape", "len", "list.append", "tf.convert_to_tensor.get_shape"], "function", ["None"], ["", "def", "get_shape_list", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"Returns a list of input dimensions, statically where possible.\n\n    TODO What is this useful for?\n\n    Adopted from the tensor2tensor library.\n    \"\"\"", "\n", "inputs", "=", "tf", ".", "convert_to_tensor", "(", "value", "=", "inputs", ")", "\n", "# If input's rank is unknown, return dynamic shape.", "\n", "if", "inputs", ".", "get_shape", "(", ")", ".", "dims", "is", "None", ":", "\n", "        ", "dims_list", "=", "tf", ".", "shape", "(", "input", "=", "inputs", ")", "\n", "", "else", ":", "\n", "        ", "static_dims_list", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "dynamic_shape", "=", "tf", ".", "shape", "(", "input", "=", "inputs", ")", "\n", "# Replace the unspecified static dimensions with dynamic ones.", "\n", "dims_list", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "static_dims_list", ")", ")", ":", "\n", "            ", "dim", "=", "static_dims_list", "[", "i", "]", "\n", "if", "dim", "is", "None", ":", "\n", "                ", "dim", "=", "dynamic_shape", "[", "i", "]", "\n", "", "dims_list", ".", "append", "(", "dim", ")", "\n", "", "", "return", "dims_list", "\n", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate.main": [[46, 123], ["tensorflow.Graph", "tf.Graph.as_default", "tensorflow.compat.v1.ConfigProto", "tensorflow.compat.v1.Session", "logging.debug", "enumerate", "enumerate", "translate_utils.translate_file", "load_config_from_json_file", "setattr", "setattr", "configs.append", "ExponentialSmoothing", "tf.compat.v1.Session.run", "BeamSearchSampler", "RandomSampler", "tensorflow.compat.v1.variable_scope", "SamplingUtils", "models.append", "tensorflow.compat.v1.variable_scope", "model_loader.init_or_restore_variables", "logging.warn", "TransformerModel", "rnn_model.RNNModel"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.translate_file", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.load_config_from_json_file", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader.init_or_restore_variables"], ["", "def", "main", "(", "settings", ")", ":", "\n", "    ", "\"\"\"\n    Translates a source language file (or STDIN) into a target language file\n    (or STDOUT).\n    \"\"\"", "\n", "# Create the TensorFlow session.", "\n", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "        ", "tf_config", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", ")", "\n", "tf_config", ".", "allow_soft_placement", "=", "True", "\n", "session", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "config", "=", "tf_config", ")", "\n", "\n", "# Load config file for each model.", "\n", "configs", "=", "[", "]", "\n", "for", "model", "in", "settings", ".", "models", ":", "\n", "            ", "config", "=", "load_config_from_json_file", "(", "model", ")", "\n", "setattr", "(", "config", ",", "'reload'", ",", "model", ")", "\n", "setattr", "(", "config", ",", "'translation_maxlen'", ",", "settings", ".", "translation_maxlen", ")", "\n", "configs", ".", "append", "(", "config", ")", "\n", "\n", "# Create the model graphs.", "\n", "", "logging", ".", "debug", "(", "\"Loading models\\n\"", ")", "\n", "models", "=", "[", "]", "\n", "for", "i", ",", "config", "in", "enumerate", "(", "configs", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"model%d\"", "%", "i", ")", "as", "scope", ":", "\n", "                ", "if", "config", ".", "model_type", "==", "\"transformer\"", ":", "\n", "                    ", "model", "=", "TransformerModel", "(", "config", ")", "\n", "", "else", ":", "\n", "                    ", "model", "=", "rnn_model", ".", "RNNModel", "(", "config", ")", "\n", "", "model", ".", "sampling_utils", "=", "SamplingUtils", "(", "settings", ")", "\n", "models", ".", "append", "(", "model", ")", "\n", "\n", "# Add smoothing variables (if the models were trained with smoothing).", "\n", "#FIXME Assumes either all models were trained with smoothing or none were.", "\n", "", "", "if", "configs", "[", "0", "]", ".", "exponential_smoothing", ">", "0.0", ":", "\n", "            ", "smoothing", "=", "ExponentialSmoothing", "(", "configs", "[", "0", "]", ".", "exponential_smoothing", ")", "\n", "\n", "# Restore the model variables.", "\n", "", "for", "i", ",", "config", "in", "enumerate", "(", "configs", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"model%d\"", "%", "i", ")", "as", "scope", ":", "\n", "                ", "_", "=", "model_loader", ".", "init_or_restore_variables", "(", "config", ",", "session", ",", "\n", "ensemble_scope", "=", "scope", ")", "\n", "\n", "# Swap-in the smoothed versions of the variables.", "\n", "", "", "if", "configs", "[", "0", "]", ".", "exponential_smoothing", ">", "0.0", ":", "\n", "            ", "session", ".", "run", "(", "fetches", "=", "smoothing", ".", "swap_ops", ")", "\n", "\n", "", "max_translation_len", "=", "settings", ".", "translation_maxlen", "\n", "\n", "# Create a BeamSearchSampler / RandomSampler.", "\n", "if", "settings", ".", "translation_strategy", "==", "'beam_search'", ":", "\n", "            ", "sampler", "=", "BeamSearchSampler", "(", "models", ",", "configs", ",", "settings", ".", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "assert", "settings", ".", "translation_strategy", "==", "'sampling'", "\n", "sampler", "=", "RandomSampler", "(", "models", ",", "configs", ",", "settings", ".", "beam_size", ")", "\n", "\n", "# Warn about the change from neg log probs to log probs for the RNN.", "\n", "", "if", "settings", ".", "n_best", ":", "\n", "            ", "model_types", "=", "[", "config", ".", "model_type", "for", "config", "in", "configs", "]", "\n", "if", "'rnn'", "in", "model_types", ":", "\n", "                ", "logging", ".", "warn", "(", "'n-best scores for RNN models have changed from '", "\n", "'positive to negative (as of commit 95793196...). '", "\n", "'If you are using the scores for reranking etc, then '", "\n", "'you may need to update your scripts.'", ")", "\n", "\n", "# Translate the source file.", "\n", "", "", "translate_utils", ".", "translate_file", "(", "\n", "input_file", "=", "settings", ".", "input", ",", "\n", "output_file", "=", "settings", ".", "output", ",", "\n", "session", "=", "session", ",", "\n", "sampler", "=", "sampler", ",", "\n", "config", "=", "configs", "[", "0", "]", ",", "\n", "max_translation_len", "=", "max_translation_len", ",", "\n", "normalization_alpha", "=", "settings", ".", "normalization_alpha", ",", "\n", "nbest", "=", "settings", ".", "n_best", ",", "\n", "minibatch_size", "=", "settings", ".", "minibatch_size", ",", "\n", "maxibatch_size", "=", "settings", ".", "maxibatch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.exponential_smoothing.ExponentialSmoothing.__init__": [[29, 70], ["tensorflow.DeviceSpec", "tensorflow.device", "tensorflow.compat.v1.trainable_variables", "tensorflow.compat.v1.trainable_variables", "tensorflow.compat.v1.trainable_variables", "tensorflow.compat.v1.get_variable", "v.read_value", "tensorflow.compat.v1.get_variable.read_value", "tensorflow.compat.v1.assign", "tensorflow.control_dependencies", "tensorflow.zeros_like", "v.assign", "tensorflow.compat.v1.get_variable.assign"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "smoothing_factor", ",", "\n", "update_frequency", "=", "DEFAULT_UPDATE_FREQUENCY", ")", ":", "\n", "        ", "\"\"\"Creates TF variables and operations.\n\n        Args:\n            smoothing_factor: float controlling weight of past vs new values.\n            update_frequency: integer indicating how often updates will occur.\n        \"\"\"", "\n", "self", ".", "_update_frequency", "=", "update_frequency", "\n", "adjusted_smoothing_factor", "=", "smoothing_factor", "*", "update_frequency", "\n", "# Smoothed variables are stored in CPU memory to avoid eating into", "\n", "# valuable GPU memory.", "\n", "device_spec", "=", "tf", ".", "DeviceSpec", "(", "device_type", "=", "\"CPU\"", ",", "device_index", "=", "0", ")", "\n", "with", "tf", ".", "device", "(", "device_spec", ")", ":", "\n", "# Create variables to hold the smoothed versions of all trainable", "\n", "# variables.", "\n", "            ", "smooth_vars", "=", "{", "}", "\n", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ":", "\n", "                ", "assert", "v", ".", "name", "[", "-", "2", ":", "]", "==", "\":0\"", "\n", "name", "=", "v", ".", "name", "[", ":", "-", "2", "]", "+", "\"_smooth\"", "\n", "s", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "name", ",", "\n", "initializer", "=", "tf", ".", "zeros_like", "(", "v", ")", ",", "\n", "trainable", "=", "False", ",", "\n", "use_resource", "=", "True", ")", "\n", "smooth_vars", "[", "v", ".", "name", "]", "=", "s", "\n", "# Define the ops to update the smoothed variables.", "\n", "", "self", ".", "_update_ops", "=", "[", "]", "\n", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ":", "\n", "                ", "s", "=", "smooth_vars", "[", "v", ".", "name", "]", "\n", "updated_s", "=", "(", "1", "-", "adjusted_smoothing_factor", ")", "*", "s", "+", "adjusted_smoothing_factor", "*", "v", "\n", "self", ".", "_update_ops", "+=", "[", "tf", ".", "compat", ".", "v1", ".", "assign", "(", "s", ",", "updated_s", ")", "]", "\n", "# Define the ops to swap the raw and smoothed variables.", "\n", "", "self", ".", "_swap_ops", "=", "[", "]", "\n", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ":", "\n", "                ", "s", "=", "smooth_vars", "[", "v", ".", "name", "]", "\n", "v_value", "=", "v", ".", "read_value", "(", ")", "\n", "s_value", "=", "s", ".", "read_value", "(", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "v_value", ",", "s_value", "]", ")", ":", "\n", "                    ", "self", ".", "_swap_ops", "+=", "[", "v", ".", "assign", "(", "s_value", ")", "]", "\n", "self", ".", "_swap_ops", "+=", "[", "s", ".", "assign", "(", "v_value", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.exponential_smoothing.ExponentialSmoothing.update_ops": [[71, 74], ["None"], "methods", ["None"], ["", "", "", "", "@", "property", "\n", "def", "update_ops", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_update_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.exponential_smoothing.ExponentialSmoothing.swap_ops": [[75, 78], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "swap_ops", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_swap_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.exponential_smoothing.ExponentialSmoothing.update_frequency": [[79, 82], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "update_frequency", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_update_frequency", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ParameterSpecification.__init__": [[56, 79], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "default", ",", "legacy_names", "=", "[", "]", ",", "visible_arg_names", "=", "[", "]", ",", "\n", "hidden_arg_names", "=", "[", "]", ",", "derivation_func", "=", "None", ",", "**", "argparse_args", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            name: string (must be a valid Python variable name).\n            default: the default parameter value.\n            legacy_names: list of strings.\n            visible_arg_names: list of strings (all must start '-' or '--')\n            hidden_arg_names: list of strings (all must start '-' or '--')\n            derivation_func: function taking config and meta_config arguments.\n            argparse_args: any keyword arguments accepted by argparse.\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "default", "=", "default", "\n", "self", ".", "legacy_names", "=", "legacy_names", "\n", "self", ".", "visible_arg_names", "=", "visible_arg_names", "\n", "self", ".", "hidden_arg_names", "=", "hidden_arg_names", "\n", "self", ".", "derivation_func", "=", "derivation_func", "\n", "self", ".", "argparse_args", "=", "argparse_args", "\n", "if", "len", "(", "argparse_args", ")", "==", "0", ":", "\n", "            ", "assert", "visible_arg_names", "==", "[", "]", "and", "hidden_arg_names", "==", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "argparse_args", "[", "'default'", "]", "=", "self", ".", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.__init__": [[94, 122], ["collections.OrderedDict", "config.ConfigSpecification._define_param_specs", "config.ConfigSpecification._check_self", "config.ConfigSpecification._build_name_to_spec"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification._define_param_specs", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification._check_self", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification._build_name_to_spec"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Builds the collection of ParameterSpecifications.\"\"\"", "\n", "\n", "# Define the parameter groups and their descriptions.", "\n", "description_pairs", "=", "[", "\n", "(", "''", ",", "None", ")", ",", "\n", "(", "'data'", ",", "'data sets; model loading and saving'", ")", ",", "\n", "(", "'network'", ",", "'network parameters (all model types)'", ")", ",", "\n", "(", "'network_rnn'", ",", "'network parameters (rnn-specific)'", ")", ",", "\n", "(", "'network_transformer'", ",", "'network parameters (transformer-'", "\n", "'specific)'", ")", ",", "\n", "(", "'training'", ",", "'training parameters'", ")", ",", "\n", "(", "'validation'", ",", "'validation parameters'", ")", ",", "\n", "(", "'display'", ",", "'display parameters'", ")", ",", "\n", "(", "'translate'", ",", "'translate parameters'", ")", ",", "\n", "(", "'sampling'", ",", "'sampling parameters'", ")", ",", "\n", "(", "'MRT'", ",", "'MRT parameters'", ")", ",", "\n", "]", "\n", "self", ".", "_group_descriptions", "=", "collections", ".", "OrderedDict", "(", "description_pairs", ")", "\n", "\n", "# Add all the ParameterSpecification objects.", "\n", "self", ".", "_param_specs", "=", "self", ".", "_define_param_specs", "(", ")", "\n", "\n", "# Check that there are no duplicated names.", "\n", "self", ".", "_check_self", "(", ")", "\n", "\n", "# Build a dictionary for looking up ParameterSpecifications by name.", "\n", "self", ".", "_name_to_spec", "=", "self", ".", "_build_name_to_spec", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.group_names": [[123, 127], ["config.ConfigSpecification._group_descriptions.keys"], "methods", ["None"], ["", "@", "property", "\n", "def", "group_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the list of parameter group names.\"\"\"", "\n", "return", "self", ".", "_group_descriptions", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.group_description": [[128, 131], ["None"], "methods", ["None"], ["", "def", "group_description", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Returns the description string for the given group name.\"\"\"", "\n", "return", "self", ".", "_group_descriptions", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group": [[132, 135], ["None"], "methods", ["None"], ["", "def", "params_by_group", "(", "self", ",", "group_name", ")", ":", "\n", "        ", "\"\"\"Returns the list of ParameterSpecifications for the given group.\"\"\"", "\n", "return", "self", ".", "_param_specs", "[", "group_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.lookup": [[136, 139], ["config.ConfigSpecification._name_to_spec.get"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get"], ["", "def", "lookup", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Looks up a ParameterSpecification by name. None if not found.\"\"\"", "\n", "return", "self", ".", "_name_to_spec", ".", "get", "(", "name", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification._define_param_specs": [[140, 956], ["group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "group.append", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification", "config.ParameterSpecification"], "methods", ["None"], ["", "def", "_define_param_specs", "(", "self", ")", ":", "\n", "        ", "\"\"\"Adds all ParameterSpecification objects.\"\"\"", "\n", "param_specs", "=", "{", "}", "\n", "\n", "# Add an empty list for each parameter group.", "\n", "for", "group", "in", "self", ".", "group_names", ":", "\n", "            ", "param_specs", "[", "group", "]", "=", "[", "]", "\n", "\n", "# Add non-command-line parameters.", "\n", "\n", "", "group", "=", "param_specs", "[", "''", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'model_version'", ",", "default", "=", "None", ",", "\n", "derivation_func", "=", "_derive_model_version", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'theano_compat'", ",", "default", "=", "None", ",", "\n", "derivation_func", "=", "lambda", "_", ",", "meta_config", ":", "meta_config", ".", "from_theano", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'source_dicts'", ",", "default", "=", "None", ",", "\n", "derivation_func", "=", "lambda", "config", ",", "_", ":", "config", ".", "dictionaries", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'target_dict'", ",", "default", "=", "None", ",", "\n", "derivation_func", "=", "lambda", "config", ",", "_", ":", "config", ".", "dictionaries", "[", "-", "1", "]", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'target_embedding_size'", ",", "default", "=", "None", ",", "\n", "derivation_func", "=", "_derive_target_embedding_size", ")", ")", "\n", "\n", "# All remaining parameters are command-line parameters.", "\n", "\n", "# Add command-line parameters for the 'data' group.", "\n", "\n", "group", "=", "param_specs", "[", "'data'", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'source_dataset'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--source_dataset'", "]", ",", "\n", "derivation_func", "=", "_derive_source_dataset", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'parallel training corpus (source)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'target_dataset'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--target_dataset'", "]", ",", "\n", "derivation_func", "=", "_derive_target_dataset", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'parallel training corpus (target)'", ")", ")", "\n", "\n", "# Hidden option for backward compatibility.", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'datasets'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "]", ",", "hidden_arg_names", "=", "[", "'--datasets'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "nargs", "=", "2", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'dictionaries'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--dictionaries'", "]", ",", "hidden_arg_names", "=", "[", "]", ",", "\n", "type", "=", "str", ",", "required", "=", "True", ",", "metavar", "=", "'PATH'", ",", "nargs", "=", "'+'", ",", "\n", "help", "=", "'network vocabularies (one per source factor, plus target '", "\n", "'vocabulary)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'save_freq'", ",", "default", "=", "30000", ",", "\n", "legacy_names", "=", "[", "'saveFreq'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--save_freq'", "]", ",", "hidden_arg_names", "=", "[", "'--saveFreq'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'save frequency (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'saveto'", ",", "default", "=", "'model'", ",", "\n", "visible_arg_names", "=", "[", "'--model'", "]", ",", "hidden_arg_names", "=", "[", "'--saveto'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'model file name (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'reload'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--reload'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'load existing model from this path. Set to '", "\n", "'\"latest_checkpoint\" to reload the latest checkpoint in the '", "\n", "'same directory of --model'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'reload_training_progress'", ",", "default", "=", "True", ",", "\n", "visible_arg_names", "=", "[", "'--no_reload_training_progress'", "]", ",", "\n", "action", "=", "'store_false'", ",", "\n", "help", "=", "'don\\'t reload training progress (only used if --reload '", "\n", "'is enabled)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'summary_dir'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--summary_dir'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'directory for saving summaries (default: same directory '", "\n", "'as the --model file)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'summary_freq'", ",", "default", "=", "0", ",", "\n", "legacy_names", "=", "[", "'summaryFreq'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--summary_freq'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--summaryFreq'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'Save summaries after INT updates, if 0 do not save '", "\n", "'summaries (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'preprocess_script'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--preprocess_script'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to script for external preprocessing (default: '", "\n", "'%(default)s). The script will be called at the start of training, and before each epoch. '", "\n", "'Useful for dynamic preprocessing, such as BPE dropout. Ideally, this script should write the files '", "\n", "'given in --source_dataset and --target_dataset, which will be reloaded after calling the script.'", ")", ")", "\n", "\n", "# Add command-line parameters for 'network' group.", "\n", "\n", "group", "=", "param_specs", "[", "'network'", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'model_type'", ",", "default", "=", "'rnn'", ",", "\n", "visible_arg_names", "=", "[", "'--model_type'", "]", ",", "\n", "type", "=", "str", ",", "choices", "=", "[", "'rnn'", ",", "'transformer'", "]", ",", "\n", "help", "=", "'model type (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'embedding_size'", ",", "default", "=", "512", ",", "\n", "legacy_names", "=", "[", "'dim_word'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--embedding_size'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dim_word'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'embedding layer size (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'state_size'", ",", "default", "=", "1000", ",", "\n", "legacy_names", "=", "[", "'dim'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--state_size'", "]", ",", "hidden_arg_names", "=", "[", "'--dim'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'hidden state size (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'source_vocab_sizes'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--source_vocab_sizes'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--n_words_src'", "]", ",", "\n", "derivation_func", "=", "_derive_source_vocab_sizes", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "nargs", "=", "'+'", ",", "\n", "help", "=", "'source vocabulary sizes (one per input factor) (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'target_vocab_size'", ",", "default", "=", "-", "1", ",", "\n", "legacy_names", "=", "[", "'n_words'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--target_vocab_size'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--n_words'", "]", ",", "\n", "derivation_func", "=", "_derive_target_vocab_size", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'target vocabulary size (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'factors'", ",", "default", "=", "1", ",", "\n", "visible_arg_names", "=", "[", "'--factors'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of input factors (default: %(default)s) - CURRENTLY '", "\n", "'ONLY WORKS FOR \\'rnn\\' MODEL'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'dim_per_factor'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--dim_per_factor'", "]", ",", "\n", "derivation_func", "=", "_derive_dim_per_factor", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "nargs", "=", "'+'", ",", "\n", "help", "=", "'list of word vector dimensionalities (one per factor): '", "\n", "'\\'--dim_per_factor 250 200 50\\' for total dimensionality '", "\n", "'of 500 (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'tie_encoder_decoder_embeddings'", ",", "default", "=", "False", ",", "\n", "visible_arg_names", "=", "[", "'--tie_encoder_decoder_embeddings'", "]", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'tie the input embeddings of the encoder and the decoder '", "\n", "'(first factor only). Source and target vocabulary size '", "\n", "'must be the same'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'tie_decoder_embeddings'", ",", "default", "=", "False", ",", "\n", "visible_arg_names", "=", "[", "'--tie_decoder_embeddings'", "]", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'tie the input embeddings of the decoder with the softmax '", "\n", "'output embeddings'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'output_hidden_activation'", ",", "default", "=", "'tanh'", ",", "\n", "visible_arg_names", "=", "[", "'--output_hidden_activation'", "]", ",", "\n", "type", "=", "str", ",", "choices", "=", "[", "'tanh'", ",", "'relu'", ",", "'prelu'", ",", "'linear'", "]", ",", "\n", "help", "=", "'activation function in hidden layer of the output '", "\n", "'network (default: %(default)s) - CURRENTLY ONLY WORKS '", "\n", "'FOR \\'rnn\\' MODEL'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'softmax_mixture_size'", ",", "default", "=", "1", ",", "\n", "visible_arg_names", "=", "[", "'--softmax_mixture_size'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of softmax components to use (default: '", "\n", "'%(default)s) - CURRENTLY ONLY WORKS FOR \\'rnn\\' MODEL'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'layer_normalization_type'", ",", "default", "=", "'layernorm'", ",", "\n", "visible_arg_names", "=", "[", "'--layer_normalisation_type'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--layer_normalization_type'", "]", ",", "\n", "type", "=", "str", ",", "choices", "=", "[", "'layernorm'", ",", "'rmsnorm'", "]", ",", "\n", "help", "=", "'layer normalisation variant to apply'", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "# Add command-line parameters for 'network_rnn' group.", "\n", "\n", "group", "=", "param_specs", "[", "'network_rnn'", "]", "\n", "\n", "# NOTE: parameter names in this group must use the rnn_ prefix.", "\n", "#       read_config_from_cmdline() uses this to check that only", "\n", "#       model type specific options are only used with the appropriate", "\n", "#       model type.", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_enc_depth'", ",", "default", "=", "1", ",", "\n", "legacy_names", "=", "[", "'enc_depth'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_enc_depth'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--enc_depth'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of encoder layers (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_enc_transition_depth'", ",", "default", "=", "1", ",", "\n", "legacy_names", "=", "[", "'enc_recurrence_transition_depth'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_enc_transition_depth'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--enc_recurrence_transition_depth'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of GRU transition operations applied in the '", "\n", "'encoder. Minimum is 1. (Only applies to gru). (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_dec_depth'", ",", "default", "=", "1", ",", "\n", "legacy_names", "=", "[", "'dec_depth'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_dec_depth'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dec_depth'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of decoder layers (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_dec_base_transition_depth'", ",", "default", "=", "2", ",", "\n", "legacy_names", "=", "[", "'dec_base_recurrence_transition_depth'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_dec_base_transition_depth'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dec_base_recurrence_transition_depth'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of GRU transition operations applied in the first '", "\n", "'layer of the decoder. Minimum is 2.  (Only applies to '", "\n", "'gru_cond). (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_dec_high_transition_depth'", ",", "default", "=", "1", ",", "\n", "legacy_names", "=", "[", "'dec_high_recurrence_transition_depth'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_dec_high_transition_depth'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dec_high_recurrence_transition_depth'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of GRU transition operations applied in the higher '", "\n", "'layers of the decoder. Minimum is 1. (Only applies to '", "\n", "'gru). (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_dec_deep_context'", ",", "default", "=", "False", ",", "\n", "legacy_names", "=", "[", "'dec_deep_context'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_dec_deep_context'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dec_deep_context'", "]", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'pass context vector (from first layer) to deep decoder '", "\n", "'layers'", ")", ")", "\n", "\n", "# option should no longer be set in command line;", "\n", "# code only remains to ensure backward-compatible loading of JSON files", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_use_dropout'", ",", "default", "=", "False", ",", "\n", "legacy_names", "=", "[", "'use_dropout'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_use_dropout'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--use_dropout'", "]", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'REMOVED: has no effect'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_dropout_embedding'", ",", "default", "=", "0.0", ",", "\n", "legacy_names", "=", "[", "'dropout_embedding'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_dropout_embedding'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dropout_embedding'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout for input embeddings (0: no dropout) (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_dropout_hidden'", ",", "default", "=", "0.0", ",", "\n", "legacy_names", "=", "[", "'dropout_hidden'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_dropout_hidden'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dropout_hidden'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout for hidden layer (0: no dropout) (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_dropout_source'", ",", "default", "=", "0.0", ",", "\n", "legacy_names", "=", "[", "'dropout_source'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_dropout_source'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dropout_source'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout source words (0: no dropout) (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_dropout_target'", ",", "default", "=", "0.0", ",", "\n", "legacy_names", "=", "[", "'dropout_target'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_dropout_target'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--dropout_target'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout target words (0: no dropout) (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_layer_normalization'", ",", "default", "=", "False", ",", "\n", "legacy_names", "=", "[", "'use_layer_norm'", ",", "'layer_normalisation'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_layer_normalisation'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--use_layer_norm'", ",", "'--layer_normalisation'", "]", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Set to use layer normalization in encoder and decoder'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'rnn_lexical_model'", ",", "default", "=", "False", ",", "\n", "legacy_names", "=", "[", "'lexical_model'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--rnn_lexical_model'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--lexical_model'", "]", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Enable feedforward lexical model (Nguyen and Chiang, 2018)'", ")", ")", "\n", "\n", "# Add command-line parameters for 'network_transformer' group.", "\n", "\n", "group", "=", "param_specs", "[", "'network_transformer'", "]", "\n", "\n", "# NOTE: parameter names in this group must use the transformer_ prefix.", "\n", "#       read_config_from_cmdline() uses this to check that only", "\n", "#       model type specific options are only used with the appropriate", "\n", "#       model type.", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_enc_depth'", ",", "default", "=", "6", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_enc_depth'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of encoder layers (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_dec_depth'", ",", "default", "=", "6", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_dec_depth'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of decoder layers (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_ffn_hidden_size'", ",", "default", "=", "2048", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_ffn_hidden_size'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'inner dimensionality of feed-forward sub-layers (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_num_heads'", ",", "default", "=", "8", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_num_heads'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of attention heads used in multi-head attention '", "\n", "'(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_dropout_embeddings'", ",", "default", "=", "0.1", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_dropout_embeddings'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout applied to sums of word embeddings and positional '", "\n", "'encodings (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_dropout_residual'", ",", "default", "=", "0.1", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_dropout_residual'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout applied to residual connections (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_dropout_relu'", ",", "default", "=", "0.1", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_dropout_relu'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout applied to the internal activation of the '", "\n", "'feed-forward sub-layers (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_dropout_attn'", ",", "default", "=", "0.1", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_dropout_attn'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout applied to attention weights (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'transformer_drophead'", ",", "default", "=", "0.0", ",", "\n", "visible_arg_names", "=", "[", "'--transformer_drophead'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'dropout of entire attention heads (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "# Add command-line parameters for 'training' group.", "\n", "\n", "group", "=", "param_specs", "[", "'training'", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'loss_function'", ",", "default", "=", "'cross-entropy'", ",", "\n", "visible_arg_names", "=", "[", "'--loss_function'", "]", ",", "\n", "type", "=", "str", ",", "choices", "=", "[", "'cross-entropy'", ",", "'per-token-cross-entropy'", ",", "'MRT'", "]", ",", "\n", "help", "=", "'loss function (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'decay_c'", ",", "default", "=", "0.0", ",", "\n", "visible_arg_names", "=", "[", "'--decay_c'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'L2 regularization penalty (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'map_decay_c'", ",", "default", "=", "0.0", ",", "\n", "visible_arg_names", "=", "[", "'--map_decay_c'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'MAP-L2 regularization penalty towards original weights '", "\n", "'(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'prior_model'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--prior_model'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'Prior model for MAP-L2 regularization. Unless using '", "\n", "'\\\"--reload\\\", this will also be used for initialization.'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'clip_c'", ",", "default", "=", "1.0", ",", "\n", "visible_arg_names", "=", "[", "'--clip_c'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'gradient clipping threshold (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'label_smoothing'", ",", "default", "=", "0.0", ",", "\n", "visible_arg_names", "=", "[", "'--label_smoothing'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'label smoothing (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'exponential_smoothing'", ",", "default", "=", "0.0", ",", "\n", "visible_arg_names", "=", "[", "'--exponential_smoothing'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'exponential smoothing factor; use 0 to disable (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'optimizer'", ",", "default", "=", "'adam'", ",", "\n", "visible_arg_names", "=", "[", "'--optimizer'", "]", ",", "\n", "type", "=", "str", ",", "choices", "=", "[", "'adam'", "]", ",", "\n", "help", "=", "'optimizer (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'adam_beta1'", ",", "default", "=", "0.9", ",", "\n", "visible_arg_names", "=", "[", "'--adam_beta1'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'exponential decay rate for the first moment estimates '", "\n", "'(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'adam_beta2'", ",", "default", "=", "0.999", ",", "\n", "visible_arg_names", "=", "[", "'--adam_beta2'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'exponential decay rate for the second moment estimates '", "\n", "'(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'adam_epsilon'", ",", "default", "=", "1e-08", ",", "\n", "visible_arg_names", "=", "[", "'--adam_epsilon'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'constant for numerical stability (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'learning_schedule'", ",", "default", "=", "'constant'", ",", "\n", "visible_arg_names", "=", "[", "'--learning_schedule'", "]", ",", "\n", "type", "=", "str", ",", "choices", "=", "[", "'constant'", ",", "'transformer'", ",", "\n", "'warmup-plateau-decay'", "]", ",", "\n", "help", "=", "'learning schedule (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'learning_rate'", ",", "default", "=", "0.0001", ",", "\n", "visible_arg_names", "=", "[", "'--learning_rate'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--lrate'", "]", ",", "\n", "legacy_names", "=", "[", "'lrate'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'learning rate (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'warmup_steps'", ",", "default", "=", "8000", ",", "\n", "visible_arg_names", "=", "[", "'--warmup_steps'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of initial updates during which the learning rate is '", "\n", "'increased linearly during learning rate scheduling '", "\n", "'(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'plateau_steps'", ",", "default", "=", "0", ",", "\n", "visible_arg_names", "=", "[", "'--plateau_steps'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of updates after warm-up before the learning rate '", "\n", "'starts to decay (applies to \\'warmup-plateau-decay\\' '", "\n", "'learning schedule only). (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'maxlen'", ",", "default", "=", "100", ",", "\n", "visible_arg_names", "=", "[", "'--maxlen'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'maximum sequence length for training and validation '", "\n", "'(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'batch_size'", ",", "default", "=", "80", ",", "\n", "visible_arg_names", "=", "[", "'--batch_size'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'minibatch size (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'token_batch_size'", ",", "default", "=", "0", ",", "\n", "visible_arg_names", "=", "[", "'--token_batch_size'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'minibatch size (expressed in number of source or target '", "\n", "'tokens). Sentence-level minibatch size will be dynamic. If '", "\n", "'this is enabled, batch_size only affects sorting by '", "\n", "'length. (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'max_sentences_per_device'", ",", "default", "=", "0", ",", "\n", "visible_arg_names", "=", "[", "'--max_sentences_per_device'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'maximum size of minibatch subset to run on a single device, '", "\n", "'in number of sentences (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'max_tokens_per_device'", ",", "default", "=", "0", ",", "\n", "visible_arg_names", "=", "[", "'--max_tokens_per_device'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'maximum size of minibatch subset to run on a single device, '", "\n", "'in number of tokens (either source or target - whichever is '", "\n", "'highest) (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'gradient_aggregation_steps'", ",", "default", "=", "1", ",", "\n", "visible_arg_names", "=", "[", "'--gradient_aggregation_steps'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of times to accumulate gradients before aggregating '", "\n", "'and applying; the minibatch is split between steps, so '", "\n", "'adding more steps allows larger minibatches to be used '", "\n", "'(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'maxibatch_size'", ",", "default", "=", "20", ",", "\n", "visible_arg_names", "=", "[", "'--maxibatch_size'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'size of maxibatch (number of minibatches that are sorted '", "\n", "'by length) (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'sort_by_length'", ",", "default", "=", "True", ",", "\n", "visible_arg_names", "=", "[", "'--no_sort_by_length'", "]", ",", "\n", "action", "=", "'store_false'", ",", "\n", "help", "=", "'do not sort sentences in maxibatch by length'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'shuffle_each_epoch'", ",", "default", "=", "True", ",", "\n", "visible_arg_names", "=", "[", "'--no_shuffle'", "]", ",", "\n", "action", "=", "'store_false'", ",", "\n", "help", "=", "'disable shuffling of training data (for each epoch)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'keep_train_set_in_memory'", ",", "default", "=", "False", ",", "\n", "visible_arg_names", "=", "[", "'--keep_train_set_in_memory'", "]", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Keep training dataset lines stores in RAM during training'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'max_epochs'", ",", "default", "=", "5000", ",", "\n", "visible_arg_names", "=", "[", "'--max_epochs'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'maximum number of epochs (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'finish_after'", ",", "default", "=", "10000000", ",", "\n", "visible_arg_names", "=", "[", "'--finish_after'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'maximum number of updates (minibatches) (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'print_per_token_pro'", ",", "default", "=", "False", ",", "\n", "visible_arg_names", "=", "[", "'--print_per_token_pro'", "]", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'PATH to store the probability of each target token given source sentences '", "\n", "'over the training dataset (default: %(default)s). Please get rid of the 1.0s at the end '", "\n", "'of each list which is the probability of padding.'", ")", ")", "\n", "\n", "# Add command-line parameters for 'validation' group.", "\n", "\n", "group", "=", "param_specs", "[", "'validation'", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'valid_source_dataset'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--valid_source_dataset'", "]", ",", "\n", "derivation_func", "=", "_derive_valid_source_dataset", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'source validation corpus (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'valid_bleu_source_dataset'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--valid_bleu_source_dataset'", "]", ",", "\n", "derivation_func", "=", "_derive_valid_source_bleu_dataset", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'source validation corpus for external evaluation bleu (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'valid_target_dataset'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--valid_target_dataset'", "]", ",", "\n", "derivation_func", "=", "_derive_valid_target_dataset", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'target validation corpus (default: %(default)s)'", ")", ")", "\n", "\n", "# Hidden option for backward compatibility.", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'valid_datasets'", ",", "default", "=", "None", ",", "\n", "hidden_arg_names", "=", "[", "'--valid_datasets'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "nargs", "=", "2", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'valid_batch_size'", ",", "default", "=", "80", ",", "\n", "visible_arg_names", "=", "[", "'--valid_batch_size'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'validation minibatch size (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'valid_token_batch_size'", ",", "default", "=", "0", ",", "\n", "visible_arg_names", "=", "[", "'--valid_token_batch_size'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'validation minibatch size (expressed in number of source '", "\n", "'or target tokens). Sentence-level minibatch size will be '", "\n", "'dynamic. If this is enabled, valid_batch_size only affects '", "\n", "'sorting by length. (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'valid_freq'", ",", "default", "=", "10000", ",", "\n", "legacy_names", "=", "[", "'validFreq'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--valid_freq'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--validFreq'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'validation frequency (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'valid_script'", ",", "default", "=", "None", ",", "\n", "visible_arg_names", "=", "[", "'--valid_script'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to script for external validation (default: '", "\n", "'%(default)s). The script will be passed an argument '", "\n", "'specifying the path of a file that contains translations '", "\n", "'of the source validation corpus. It must write a single '", "\n", "'score to standard output.'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'patience'", ",", "default", "=", "10", ",", "\n", "visible_arg_names", "=", "[", "'--patience'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'early stopping patience (default: %(default)s)'", ")", ")", "\n", "\n", "# Add command-line parameters for 'display' group.", "\n", "\n", "group", "=", "param_specs", "[", "'display'", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'disp_freq'", ",", "default", "=", "1000", ",", "\n", "legacy_names", "=", "[", "'dispFreq'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--disp_freq'", "]", ",", "hidden_arg_names", "=", "[", "'--dispFreq'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'display loss after INT updates (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'sample_freq'", ",", "default", "=", "10000", ",", "\n", "legacy_names", "=", "[", "'sampleFreq'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--sample_freq'", "]", ",", "\n", "hidden_arg_names", "=", "[", "'--sampleFreq'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'display some samples after INT updates (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'beam_freq'", ",", "default", "=", "10000", ",", "\n", "legacy_names", "=", "[", "'beamFreq'", "]", ",", "\n", "visible_arg_names", "=", "[", "'--beam_freq'", "]", ",", "hidden_arg_names", "=", "[", "'--beamFreq'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'display some beam_search samples after INT updates '", "\n", "'(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'beam_size'", ",", "default", "=", "12", ",", "\n", "visible_arg_names", "=", "[", "'--beam_size'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'size of the beam (default: %(default)s)'", ")", ")", "\n", "\n", "# Add command-line parameters for 'translate' group.", "\n", "\n", "group", "=", "param_specs", "[", "'translate'", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'normalization_alpha'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "nargs", "=", "\"?\"", ",", "\n", "const", "=", "1.0", ",", "metavar", "=", "\"ALPHA\"", ",", "\n", "visible_arg_names", "=", "[", "'--normalization_alpha'", "]", ",", "\n", "help", "=", "'normalize scores by sentence length (with argument, \" \\\n                 \"exponentiate lengths by ALPHA)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'n_best'", ",", "default", "=", "False", ",", "\n", "visible_arg_names", "=", "[", "'--n_best'", "]", ",", "\n", "action", "=", "'store_true'", ",", "dest", "=", "'n_best'", ",", "\n", "help", "=", "'Print full beam'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'translation_maxlen'", ",", "default", "=", "200", ",", "\n", "visible_arg_names", "=", "[", "'--translation_maxlen'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'Maximum length of translation output sentence (default: '", "\n", "'%(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'translation_strategy'", ",", "default", "=", "'beam_search'", ",", "\n", "visible_arg_names", "=", "[", "'--translation_strategy'", "]", ",", "\n", "type", "=", "str", ",", "choices", "=", "[", "'beam_search'", ",", "'sampling'", "]", ",", "\n", "help", "=", "'translation_strategy, either beam_search or sampling (default: %(default)s)'", ")", ")", "\n", "\n", "# Add Add command-line parameters for 'MRT' group.", "\n", "\n", "group", "=", "param_specs", "[", "'MRT'", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'mrt_reference'", ",", "default", "=", "False", ",", "\n", "visible_arg_names", "=", "[", "'--mrt_reference'", "]", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'add reference into MRT candidates sentences'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'mrt_alpha'", ",", "default", "=", "0.005", ",", "\n", "visible_arg_names", "=", "[", "'--mrt_alpha'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'MRT alpha to control sharpness ofthe distribution of '", "\n", "'sampled subspace(default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'samplesN'", ",", "default", "=", "100", ",", "\n", "visible_arg_names", "=", "[", "'--samplesN'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'the number of sampled candidates sentences per source sentence (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'mrt_loss'", ",", "default", "=", "'SENTENCEBLEU n=4'", ",", "\n", "visible_arg_names", "=", "[", "'--mrt_loss'", "]", ",", "\n", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'evaluation matrics used in MRT (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'mrt_ml_mix'", ",", "default", "=", "0", ",", "\n", "visible_arg_names", "=", "[", "'--mrt_ml_mix'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'mix in MLE objective in MRT training with this scaling factor (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'sample_way'", ",", "default", "=", "'beam_search'", ",", "\n", "visible_arg_names", "=", "[", "'--sample_way'", "]", ",", "\n", "type", "=", "str", ",", "choices", "=", "[", "'beam_search'", ",", "'randomly_sample'", "]", ",", "\n", "help", "=", "'the sampling strategy to generate candidates sentences (default: %(default)s)'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'max_len_a'", ",", "default", "=", "1.5", ",", "\n", "visible_arg_names", "=", "[", "'--max_len_a'", "]", ",", "\n", "type", "=", "float", ",", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "'generate candidates sentences with maximum length: ax + b, '", "\n", "'where x is the source length'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'max_len_b'", ",", "default", "=", "5", ",", "\n", "visible_arg_names", "=", "[", "'--max_len_b'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'generate candidates sentences with maximum length ax + b, '", "\n", "'where x is the source length'", ")", ")", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'max_sentences_of_sampling'", ",", "default", "=", "0", ",", "\n", "visible_arg_names", "=", "[", "'--max_sentences_of_sampling'", "]", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'maximum number of source sentences to generate candidates sentences '", "\n", "'at one time (limited by device memory capacity) (default: %(default)s)'", ")", ")", "\n", "\n", "# Add command-line parameters for 'sampling' group.", "\n", "\n", "group", "=", "param_specs", "[", "'sampling'", "]", "\n", "\n", "group", ".", "append", "(", "ParameterSpecification", "(", "\n", "name", "=", "'sampling_temperature'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "metavar", "=", "\"FLOAT\"", ",", "\n", "visible_arg_names", "=", "[", "'--sampling_temperature'", "]", ",", "\n", "help", "=", "'softmax temperature used for sampling (default %(default)s)'", ")", ")", "\n", "\n", "return", "param_specs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification._build_name_to_spec": [[957, 965], ["config.ConfigSpecification.params_by_group"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group"], ["", "def", "_build_name_to_spec", "(", "self", ")", ":", "\n", "        ", "name_to_spec", "=", "{", "}", "\n", "for", "group", "in", "self", ".", "group_names", ":", "\n", "            ", "for", "param", "in", "self", ".", "params_by_group", "(", "group", ")", ":", "\n", "                ", "for", "name", "in", "[", "param", ".", "name", "]", "+", "param", ".", "legacy_names", ":", "\n", "                    ", "assert", "name", "not", "in", "name_to_spec", "\n", "name_to_spec", "[", "name", "]", "=", "param", "\n", "", "", "", "return", "name_to_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification._check_self": [[966, 985], ["set", "set", "config.ConfigSpecification.params_by_group", "config.ConfigSpecification.params_by_group", "set.add", "set.add", "set.add"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group"], ["", "def", "_check_self", "(", "self", ")", ":", "\n", "# Check that there are no duplicated parameter names.", "\n", "        ", "param_names", "=", "set", "(", ")", "\n", "for", "group", "in", "self", ".", "group_names", ":", "\n", "            ", "for", "param", "in", "self", ".", "params_by_group", "(", "group", ")", ":", "\n", "                ", "assert", "param", ".", "name", "not", "in", "param_names", "\n", "param_names", ".", "add", "(", "param", ".", "name", ")", "\n", "for", "name", "in", "param", ".", "legacy_names", ":", "\n", "                    ", "assert", "name", "not", "in", "param_names", "\n", "param_names", ".", "add", "(", "name", ")", "\n", "# Check that there are no duplicated command-line argument names.", "\n", "", "", "", "arg_names", "=", "set", "(", ")", "\n", "for", "group", "in", "self", ".", "group_names", ":", "\n", "            ", "for", "param", "in", "self", ".", "params_by_group", "(", "group", ")", ":", "\n", "                ", "for", "arg_list", "in", "(", "param", ".", "visible_arg_names", ",", "\n", "param", ".", "hidden_arg_names", ")", ":", "\n", "                    ", "for", "name", "in", "arg_list", ":", "\n", "                        ", "assert", "name", "not", "in", "arg_names", "\n", "arg_names", ".", "add", "(", "param", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._construct_argument_parser": [[987, 1035], ["argparse.ArgumentParser", "spec.params_by_group", "spec.group_description", "argparse.ArgumentParser.add_argument_group", "dict", "target.add_mutually_exclusive_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_mutually_exclusive_group", "parser.add_argument_group.add_mutually_exclusive_group", "len", "target.add_mutually_exclusive_group.add_argument"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.group_description"], ["", "", "", "", "", "", "def", "_construct_argument_parser", "(", "spec", ",", "suppress_missing", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs an argparse.ArgumentParser given a ConfigSpecification.\n\n    Setting suppress_missing to True causes the parser to suppress arguments\n    that are not supplied by the user (as opposed to adding them with\n    their default values).\n\n    Args:\n        spec: a ConfigSpecification object.\n        suppress_missing: Boolean\n\n    Returns:\n        An argparse.ArgumentParser.\n    \"\"\"", "\n", "# Construct an ArgumentParser and parse command-line args.", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "for", "group_name", "in", "spec", ".", "group_names", ":", "\n", "        ", "if", "group_name", "==", "\"\"", ":", "\n", "            ", "target", "=", "parser", "\n", "", "else", ":", "\n", "            ", "description", "=", "spec", ".", "group_description", "(", "group_name", ")", "\n", "target", "=", "parser", ".", "add_argument_group", "(", "description", ")", "\n", "\n", "", "for", "param", "in", "spec", ".", "params_by_group", "(", "group_name", ")", ":", "\n", "            ", "if", "param", ".", "visible_arg_names", "==", "[", "]", "and", "param", ".", "hidden_arg_names", "==", "[", "]", ":", "\n", "# Internal parameter - no command-line argument.", "\n", "                ", "continue", "\n", "", "argparse_args", "=", "dict", "(", "param", ".", "argparse_args", ")", "\n", "argparse_args", "[", "'dest'", "]", "=", "param", ".", "name", "\n", "if", "suppress_missing", ":", "\n", "                ", "argparse_args", "[", "'default'", "]", "=", "argparse", ".", "SUPPRESS", "\n", "", "if", "param", ".", "visible_arg_names", "==", "[", "]", ":", "\n", "                ", "argparse_args", "[", "'help'", "]", "=", "argparse", ".", "SUPPRESS", "\n", "target", ".", "add_argument", "(", "*", "param", ".", "hidden_arg_names", ",", "**", "argparse_args", ")", "\n", "continue", "\n", "", "if", "'required'", "in", "argparse_args", "and", "argparse_args", "[", "'required'", "]", ":", "\n", "                ", "mutex_group", "=", "target", ".", "add_mutually_exclusive_group", "(", "required", "=", "True", ")", "\n", "del", "argparse_args", "[", "'required'", "]", "\n", "", "else", ":", "\n", "                ", "mutex_group", "=", "target", ".", "add_mutually_exclusive_group", "(", ")", "\n", "", "mutex_group", ".", "add_argument", "(", "*", "param", ".", "visible_arg_names", ",", "**", "argparse_args", ")", "\n", "# Add any hidden arguments for this param.", "\n", "if", "len", "(", "param", ".", "hidden_arg_names", ")", ">", "0", ":", "\n", "                ", "argparse_args", "[", "'help'", "]", "=", "argparse", ".", "SUPPRESS", "\n", "mutex_group", ".", "add_argument", "(", "*", "param", ".", "hidden_arg_names", ",", "\n", "**", "argparse_args", ")", "\n", "", "", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.read_config_from_cmdline": [[1037, 1084], ["config.ConfigSpecification", "config._construct_argument_parser", "_construct_argument_parser.parse_args", "config._construct_argument_parser", "_construct_argument_parser.parse_args", "set", "config._check_config_consistency", "argparse.Namespace", "vars().keys", "len", "sys.exit", "config.ConfigSpecification.params_by_group", "logging.error", "vars", "setattr", "param.derivation_func"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._construct_argument_parser", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._construct_argument_parser", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._check_config_consistency", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group"], ["", "def", "read_config_from_cmdline", "(", ")", ":", "\n", "    ", "\"\"\"Reads a config from the command-line.\n\n    Logs an error and exits if the parameter values are not mutually\n    consistent.\n\n    Returns:\n        An argparse.Namespace object representing the config.\n    \"\"\"", "\n", "\n", "spec", "=", "ConfigSpecification", "(", ")", "\n", "\n", "# Construct an argparse.ArgumentParser and parse command-line args.", "\n", "parser", "=", "_construct_argument_parser", "(", "spec", ")", "\n", "config", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Construct a second ArgumentParser but using default=argparse.SUPPRESS", "\n", "# in every argparse.add_argument() call. This allows us to determine", "\n", "# which parameters were actually set by the user.", "\n", "# Solution is from https://stackoverflow.com/a/45803037", "\n", "aux_parser", "=", "_construct_argument_parser", "(", "spec", ",", "suppress_missing", "=", "True", ")", "\n", "aux_config", "=", "aux_parser", ".", "parse_args", "(", ")", "\n", "set_by_user", "=", "set", "(", "vars", "(", "aux_config", ")", ".", "keys", "(", ")", ")", "\n", "\n", "# Perform consistency checks.", "\n", "error_messages", "=", "_check_config_consistency", "(", "spec", ",", "config", ",", "set_by_user", ")", "\n", "if", "len", "(", "error_messages", ")", ">", "0", ":", "\n", "        ", "for", "msg", "in", "error_messages", ":", "\n", "            ", "logging", ".", "error", "(", "msg", ")", "\n", "", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "# Set meta parameters.", "\n", "", "meta_config", "=", "argparse", ".", "Namespace", "(", ")", "\n", "meta_config", ".", "from_cmdline", "=", "True", "\n", "meta_config", ".", "from_theano", "=", "False", "\n", "\n", "# Set defaults for removed options", "\n", "config", ".", "rnn_use_dropout", "=", "True", "\n", "\n", "# Run derivation functions.", "\n", "for", "group", "in", "spec", ".", "group_names", ":", "\n", "        ", "for", "param", "in", "spec", ".", "params_by_group", "(", "group", ")", ":", "\n", "            ", "if", "param", ".", "derivation_func", "is", "not", "None", ":", "\n", "                ", "setattr", "(", "config", ",", "param", ".", "name", ",", "\n", "param", ".", "derivation_func", "(", "config", ",", "meta_config", ")", ")", "\n", "\n", "", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.write_config_to_json_file": [[1086, 1097], ["collections.OrderedDict", "json.dump", "sorted", "open", "vars().items", "vars"], "function", ["None"], ["", "def", "write_config_to_json_file", "(", "config", ",", "path", ")", ":", "\n", "    ", "\"\"\"\n    Writes a config object to a JSON file.\n\n    Args:\n        config: a config Namespace object\n        path: full path to the JSON file except \".json\" suffix\n    \"\"\"", "\n", "\n", "config_as_dict", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "vars", "(", "config", ")", ".", "items", "(", ")", ")", ")", "\n", "json", ".", "dump", "(", "config_as_dict", ",", "open", "(", "'%s.json'", "%", "path", ",", "'w'", ",", "encoding", "=", "\"UTF-8\"", ")", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.load_config_from_json_file": [[1099, 1158], ["config.ConfigSpecification", "argparse.Namespace", "argparse.Namespace", "hasattr", "config.ConfigSpecification.params_by_group", "config.ConfigSpecification.params_by_group", "config.ConfigSpecification.params_by_group", "open", "json.load", "hasattr", "hasattr", "setattr", "setattr", "open", "pickle.load", "logging.error", "sys.exit", "getattr", "setattr", "delattr", "param.derivation_func", "hasattr"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group"], ["", "def", "load_config_from_json_file", "(", "basename", ")", ":", "\n", "    ", "\"\"\"Loads and, if necessary, updates a config from a JSON (or Pickle) file.\n\n    Logs an error and exits if the file can't be loaded.\n\n    Args:\n        basename: a string containing the path to the corresponding model file.\n\n    Returns:\n        An argparse.Namespace object representing the config.\n    \"\"\"", "\n", "\n", "spec", "=", "ConfigSpecification", "(", ")", "\n", "\n", "# Load a config from a JSON (or Pickle) config file.", "\n", "try", ":", "\n", "        ", "with", "open", "(", "'%s.json'", "%", "basename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "config_as_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "except", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "'%s.pkl'", "%", "basename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "                ", "config_as_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "except", ":", "\n", "            ", "logging", ".", "error", "(", "'config file {}.json is missing'", ".", "format", "(", "basename", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "", "config", "=", "argparse", ".", "Namespace", "(", "**", "config_as_dict", ")", "\n", "\n", "# Set meta parameters.", "\n", "meta_config", "=", "argparse", ".", "Namespace", "(", ")", "\n", "meta_config", ".", "from_cmdline", "=", "False", "\n", "meta_config", ".", "from_theano", "=", "(", "not", "hasattr", "(", "config", ",", "'embedding_size'", ")", ")", "\n", "\n", "# Update config to use current parameter names.", "\n", "for", "group_name", "in", "spec", ".", "group_names", ":", "\n", "        ", "for", "param", "in", "spec", ".", "params_by_group", "(", "group_name", ")", ":", "\n", "            ", "for", "legacy_name", "in", "param", ".", "legacy_names", ":", "\n", "# TODO It shouldn't happen, but check for multiple names", "\n", "#      (legacy and/or current) for same parameter appearing", "\n", "#      in config.", "\n", "                ", "if", "hasattr", "(", "config", ",", "legacy_name", ")", ":", "\n", "                    ", "val", "=", "getattr", "(", "config", ",", "legacy_name", ")", "\n", "assert", "not", "hasattr", "(", "config", ",", "param", ".", "name", ")", "\n", "setattr", "(", "config", ",", "param", ".", "name", ",", "val", ")", "\n", "delattr", "(", "config", ",", "legacy_name", ")", "\n", "\n", "# Add missing parameters.", "\n", "", "", "", "", "for", "group_name", "in", "spec", ".", "group_names", ":", "\n", "        ", "for", "param", "in", "spec", ".", "params_by_group", "(", "group_name", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "param", ".", "name", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "param", ".", "name", ",", "param", ".", "default", ")", "\n", "\n", "# Run derivation functions.", "\n", "", "", "", "for", "group", "in", "spec", ".", "group_names", ":", "\n", "        ", "for", "param", "in", "spec", ".", "params_by_group", "(", "group", ")", ":", "\n", "            ", "if", "param", ".", "derivation_func", "is", "not", "None", ":", "\n", "                ", "setattr", "(", "config", ",", "param", ".", "name", ",", "\n", "param", ".", "derivation_func", "(", "config", ",", "meta_config", ")", ")", "\n", "\n", "", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._check_config_consistency": [[1160, 1312], ["spec.lookup", "spec.lookup", "spec.lookup", "spec.params_by_group", "error_messages.append", "error_messages.append", "len", "error_messages.append", "error_messages.append", "error_messages.append", "error_messages.append", "error_messages.append", "spec.lookup", "error_messages.append", "error_messages.append", "error_messages.append", "error_messages.append", "error_messages.append", "len", "len", "error_messages.append", "config._check_config_consistency.arg_names_string"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.lookup", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.lookup", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.lookup", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.params_by_group", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.ConfigSpecification.lookup"], ["", "def", "_check_config_consistency", "(", "spec", ",", "config", ",", "set_by_user", ")", ":", "\n", "    ", "\"\"\"Performs consistency checks on a config read from the command-line.\n\n    Args:\n        spec: a ConfigSpecification object.\n        config: an argparse.Namespace object.\n        set_by_user: a set of strings representing parameter names.\n\n    Returns:\n        A list of error messages, one for each check that failed. An empty\n        list indicates that all checks passed.\n    \"\"\"", "\n", "\n", "def", "arg_names_string", "(", "param", ")", ":", "\n", "        ", "arg_names", "=", "param", ".", "visible_arg_names", "+", "param", ".", "hidden_arg_names", "\n", "return", "' / '", ".", "join", "(", "arg_names", ")", "\n", "\n", "", "error_messages", "=", "[", "]", "\n", "\n", "# Check parameters are appropriate for the model type.", "\n", "assert", "config", ".", "model_type", "is", "not", "None", "\n", "for", "group", "in", "spec", ".", "group_names", ":", "\n", "        ", "for", "param", "in", "spec", ".", "params_by_group", "(", "group", ")", ":", "\n", "            ", "if", "param", ".", "name", "not", "in", "set_by_user", ":", "\n", "                ", "continue", "\n", "", "if", "(", "(", "param", ".", "name", ".", "startswith", "(", "'rnn_'", ")", "and", "\n", "config", ".", "model_type", "==", "'transformer'", ")", "or", "\n", "(", "param", ".", "name", ".", "startswith", "(", "'transformer_'", ")", "and", "\n", "config", ".", "model_type", "==", "'rnn'", ")", ")", ":", "\n", "                ", "msg", "=", "'{} cannot be used with \\'{}\\' model type'", ".", "format", "(", "\n", "arg_names_string", "(", "param", ")", ",", "config", ".", "model_type", ")", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "# Check user-supplied learning schedule options are consistent.", "\n", "", "", "", "if", "config", ".", "learning_schedule", "==", "'constant'", ":", "\n", "        ", "for", "key", "in", "[", "'warmup_steps'", ",", "'plateau_steps'", "]", ":", "\n", "            ", "param", "=", "spec", ".", "lookup", "(", "key", ")", "\n", "assert", "param", "is", "not", "None", "\n", "if", "param", ".", "name", "in", "set_by_user", ":", "\n", "                ", "msg", "=", "'{} cannot be used with \\'constant\\' learning '", "'schedule'", ".", "format", "(", "arg_names_string", "(", "param", ")", ",", "\n", "config", ".", "model_type", ")", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "", "", "", "elif", "config", ".", "learning_schedule", "==", "'transformer'", ":", "\n", "        ", "for", "key", "in", "[", "'learning_rate'", ",", "'plateau_steps'", "]", ":", "\n", "            ", "param", "=", "spec", ".", "lookup", "(", "key", ")", "\n", "assert", "param", "is", "not", "None", "\n", "if", "param", ".", "name", "in", "set_by_user", ":", "\n", "                ", "msg", "=", "'{} cannot be used with \\'transformer\\' learning '", "'schedule'", ".", "format", "(", "arg_names_string", "(", "param", ")", ",", "\n", "config", ".", "model_type", ")", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "# TODO Other similar checks? e.g. check user hasn't set adam parameters", "\n", "#       if optimizer != 'adam' (not currently possible but probably will", "\n", "#       be in in the future)...", "\n", "\n", "# Check if user is trying to use the Transformer with features that", "\n", "# aren't supported yet.", "\n", "", "", "", "if", "config", ".", "model_type", "==", "'transformer'", ":", "\n", "        ", "if", "config", ".", "factors", ">", "1", ":", "\n", "            ", "msg", "=", "'factors are not yet supported for the \\'transformer\\' '", "'model type'", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "", "if", "config", ".", "softmax_mixture_size", ">", "1", ":", "\n", "            ", "msg", "=", "'softmax mixtures are not yet supported for the '", "'\\'transformer\\' model type'", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "", "if", "config", ".", "datasets", ":", "\n", "        ", "if", "config", ".", "source_dataset", "or", "config", ".", "target_dataset", ":", "\n", "            ", "msg", "=", "'argument clash: --datasets is mutually exclusive '", "'with --source_dataset and --target_dataset'", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "", "", "elif", "not", "config", ".", "source_dataset", ":", "\n", "        ", "msg", "=", "'--source_dataset is required'", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "", "elif", "not", "config", ".", "target_dataset", ":", "\n", "        ", "msg", "=", "'--target_dataset is required'", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "if", "config", ".", "valid_datasets", ":", "\n", "        ", "if", "config", ".", "valid_source_dataset", "or", "config", ".", "valid_target_dataset", ":", "\n", "            ", "msg", "=", "'argument clash: --valid_datasets is mutually '", "'exclusive with --valid_source_dataset and '", "'--valid_target_dataset'", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "", "if", "(", "config", ".", "source_vocab_sizes", "is", "not", "None", "and", "\n", "len", "(", "config", ".", "source_vocab_sizes", ")", ">", "config", ".", "factors", ")", ":", "\n", "        ", "msg", "=", "'too many values supplied to \\'--source_vocab_sizes\\' option '", "'(expected one per factor = {})'", ".", "format", "(", "config", ".", "factors", ")", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "if", "config", ".", "dim_per_factor", "is", "None", "and", "config", ".", "factors", "!=", "1", ":", "\n", "        ", "msg", "=", "'if using factored input, you must specify \\'dim_per_factor\\''", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "if", "config", ".", "dim_per_factor", "is", "not", "None", ":", "\n", "        ", "if", "len", "(", "config", ".", "dim_per_factor", ")", "!=", "config", ".", "factors", ":", "\n", "            ", "msg", "=", "'mismatch between \\'--factors\\' ({0}) and '", "'\\'--dim_per_factor\\' ({1} entries)'", ".", "format", "(", "\n", "config", ".", "factors", ",", "len", "(", "config", ".", "dim_per_factor", ")", ")", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "", "elif", "sum", "(", "config", ".", "dim_per_factor", ")", "!=", "config", ".", "embedding_size", ":", "\n", "            ", "msg", "=", "'mismatch between \\'--embedding_size\\' ({0}) and '", "'\\'--dim_per_factor\\' (sums to {1})\\''", ".", "format", "(", "\n", "config", ".", "embedding_size", ",", "sum", "(", "config", ".", "dim_per_factor", ")", ")", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "", "if", "len", "(", "config", ".", "dictionaries", ")", "!=", "config", ".", "factors", "+", "1", ":", "\n", "        ", "msg", "=", "'\\'--dictionaries\\' must specify one dictionary per source '", "'factor and one target dictionary'", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "max_sents_param", "=", "spec", ".", "lookup", "(", "'max_sentences_per_device'", ")", "\n", "max_tokens_param", "=", "spec", ".", "lookup", "(", "'max_tokens_per_device'", ")", "\n", "\n", "# TODO Extend ParameterSpecification to support mutually exclusive", "\n", "#      command-line args.", "\n", "if", "(", "max_sents_param", ".", "name", "in", "set_by_user", "\n", "and", "max_tokens_param", ".", "name", "in", "set_by_user", ")", ":", "\n", "        ", "msg", "=", "'{} is mutually exclusive with {}'", ".", "format", "(", "\n", "arg_names_string", "(", "max_sents_param", ")", ",", "\n", "arg_names_string", "(", "max_tokens_param", ")", ")", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "aggregation_param", "=", "spec", ".", "lookup", "(", "'gradient_aggregation_steps'", ")", "\n", "\n", "if", "(", "aggregation_param", ".", "name", "in", "set_by_user", "\n", "and", "(", "max_sents_param", ".", "name", "in", "set_by_user", "\n", "or", "max_tokens_param", ".", "name", "in", "set_by_user", ")", ")", ":", "\n", "        ", "msg", "=", "'{} is mutually exclusive with {} / {}'", ".", "format", "(", "\n", "arg_names_string", "(", "aggregation_param", ")", ",", "\n", "arg_names_string", "(", "max_sents_param", ")", ",", "\n", "arg_names_string", "(", "max_tokens_param", ")", ")", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "# softmax_mixture_size and lexical_model are currently mutually exclusive:", "\n", "", "if", "config", ".", "softmax_mixture_size", ">", "1", "and", "config", ".", "rnn_lexical_model", ":", "\n", "       ", "error_messages", ".", "append", "(", "'behavior of --rnn_lexical_model is undefined if softmax_mixture_size > 1'", ")", "\n", "\n", "", "if", "'rnn_use_dropout'", "in", "set_by_user", ":", "\n", "        ", "msg", "=", "'--rnn_use_dropout is no longer used. Set --rnn_dropout_* instead (0 by default).\\n'", "'old defaults:\\n'", "'--rnn_dropout_embedding: 0.2\\n'", "'--rnn_dropout_hidden: 0.2\\n'", "'--rnn_dropout_source: 0\\n'", "'--rnn_dropout_target: 0'", "\n", "error_messages", ".", "append", "(", "msg", ")", "\n", "\n", "", "return", "error_messages", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_model_version": [[1314, 1325], ["logging.error", "sys.exit"], "function", ["None"], ["", "def", "_derive_model_version", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "meta_config", ".", "from_cmdline", ":", "\n", "# We're creating a new model - set the current version number.", "\n", "        ", "return", "0.2", "\n", "", "if", "config", ".", "model_version", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "model_version", "\n", "", "if", "meta_config", ".", "from_theano", "and", "config", ".", "rnn_use_dropout", ":", "\n", "        ", "logging", ".", "error", "(", "'version 0 dropout is not supported in '", "\n", "'TensorFlow Nematus'", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "return", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_target_embedding_size": [[1327, 1337], ["hasattr", "hasattr"], "function", ["None"], ["", "def", "_derive_target_embedding_size", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "assert", "hasattr", "(", "config", ",", "'embedding_size'", ")", "\n", "if", "not", "config", ".", "tie_encoder_decoder_embeddings", ":", "\n", "        ", "return", "config", ".", "embedding_size", "\n", "", "if", "config", ".", "factors", ">", "1", ":", "\n", "        ", "assert", "hasattr", "(", "config", ",", "'dim_per_factor'", ")", "\n", "assert", "config", ".", "dim_per_factor", "is", "not", "None", "\n", "return", "config", ".", "dim_per_factor", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "config", ".", "embedding_size", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_source_dataset": [[1339, 1344], ["None"], "function", ["None"], ["", "", "def", "_derive_source_dataset", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "config", ".", "source_dataset", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "source_dataset", "\n", "", "assert", "config", ".", "datasets", "is", "not", "None", "\n", "return", "config", ".", "datasets", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_target_dataset": [[1346, 1351], ["None"], "function", ["None"], ["", "def", "_derive_target_dataset", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "config", ".", "target_dataset", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "target_dataset", "\n", "", "assert", "config", ".", "datasets", "is", "not", "None", "\n", "return", "config", ".", "datasets", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_source_vocab_sizes": [[1353, 1397], ["enumerate", "hasattr", "config._determine_vocab_size_from_file", "len", "hasattr", "len", "len", "type"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._determine_vocab_size_from_file"], ["", "def", "_derive_source_vocab_sizes", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "config", ".", "source_vocab_sizes", "is", "not", "None", ":", "\n", "        ", "if", "len", "(", "config", ".", "source_vocab_sizes", ")", "==", "config", ".", "factors", ":", "\n", "# Case 1: we're loading parameters from a recent config or", "\n", "#         we're processing command-line arguments and", "\n", "#         a source_vocab_sizes was fully specified.", "\n", "            ", "return", "config", ".", "source_vocab_sizes", "\n", "", "else", ":", "\n", "# Case 2: source_vocab_sizes was given on the command-line", "\n", "#         but was only partially specified", "\n", "            ", "assert", "meta_config", ".", "from_cmdline", "\n", "assert", "len", "(", "config", ".", "source_vocab_sizes", ")", "<", "config", ".", "factors", "\n", "num_missing", "=", "config", ".", "factors", "-", "len", "(", "config", ".", "source_vocab_sizes", ")", "\n", "vocab_sizes", "=", "config", ".", "source_vocab_sizes", "+", "[", "-", "1", "]", "*", "num_missing", "\n", "", "", "elif", "hasattr", "(", "config", ",", "'n_words_src'", ")", ":", "\n", "# Case 3: we're loading parameters from a Theano config.", "\n", "#         This will always contain a single value for the", "\n", "#         source vocab size regardless of how many factors", "\n", "#         there are.", "\n", "        ", "assert", "not", "meta_config", ".", "from_cmdline", "\n", "assert", "meta_config", ".", "from_theano", "\n", "assert", "type", "(", "config", ".", "n_words_src", ")", "==", "int", "\n", "return", "[", "config", ".", "n_words_src", "]", "*", "config", ".", "factors", "\n", "", "elif", "hasattr", "(", "config", ",", "'source_vocab_size'", ")", ":", "\n", "# Case 4: we're loading parameters from a pre-factors", "\n", "#         TensorFlow config.", "\n", "        ", "assert", "not", "meta_config", ".", "from_cmdline", "\n", "assert", "not", "meta_config", ".", "from_theano", "\n", "assert", "config", ".", "factors", "==", "1", "\n", "return", "[", "config", ".", "source_vocab_size", "]", "\n", "", "else", ":", "\n", "# Case 5: we're reading command-line parameters and", "\n", "#         --source_vocab_size was not given.", "\n", "        ", "assert", "meta_config", ".", "from_cmdline", "\n", "vocab_sizes", "=", "[", "-", "1", "]", "*", "config", ".", "factors", "\n", "# For any unspecified vocabulary sizes, determine sizes from the", "\n", "# vocabulary dictionaries.", "\n", "", "for", "i", ",", "vocab_size", "in", "enumerate", "(", "vocab_sizes", ")", ":", "\n", "        ", "if", "vocab_size", ">=", "0", ":", "\n", "            ", "continue", "\n", "", "path", "=", "config", ".", "dictionaries", "[", "i", "]", "\n", "vocab_sizes", "[", "i", "]", "=", "_determine_vocab_size_from_file", "(", "path", ",", "\n", "config", ".", "model_type", ")", "\n", "", "return", "vocab_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_target_vocab_size": [[1399, 1404], ["config._determine_vocab_size_from_file"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._determine_vocab_size_from_file"], ["", "def", "_derive_target_vocab_size", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "config", ".", "target_vocab_size", "!=", "-", "1", ":", "\n", "        ", "return", "config", ".", "target_vocab_size", "\n", "", "path", "=", "config", ".", "dictionaries", "[", "-", "1", "]", "\n", "return", "_determine_vocab_size_from_file", "(", "path", ",", "config", ".", "model_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_dim_per_factor": [[1406, 1411], ["None"], "function", ["None"], ["", "def", "_derive_dim_per_factor", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "config", ".", "dim_per_factor", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "dim_per_factor", "\n", "", "assert", "config", ".", "factors", "==", "1", "\n", "return", "[", "config", ".", "embedding_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_valid_source_dataset": [[1413, 1419], ["None"], "function", ["None"], ["", "def", "_derive_valid_source_dataset", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "config", ".", "valid_source_dataset", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "valid_source_dataset", "\n", "", "if", "config", ".", "valid_datasets", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "valid_datasets", "[", "0", "]", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_valid_source_bleu_dataset": [[1422, 1427], ["None"], "function", ["None"], ["", "def", "_derive_valid_source_bleu_dataset", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "config", ".", "valid_bleu_source_dataset", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "valid_bleu_source_dataset", "\n", "", "else", ":", "\n", "        ", "return", "config", ".", "valid_source_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._derive_valid_target_dataset": [[1429, 1435], ["None"], "function", ["None"], ["", "", "def", "_derive_valid_target_dataset", "(", "config", ",", "meta_config", ")", ":", "\n", "    ", "if", "config", ".", "valid_target_dataset", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "valid_target_dataset", "\n", "", "if", "config", ".", "valid_datasets", "is", "not", "None", ":", "\n", "        ", "return", "config", ".", "valid_datasets", "[", "1", "]", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config._determine_vocab_size_from_file": [[1437, 1449], ["util.load_dict", "max", "logging.error", "sys.exit", "logging.error", "sys.exit", "util.load_dict.values", "str"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dict"], ["", "def", "_determine_vocab_size_from_file", "(", "path", ",", "model_type", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "d", "=", "util", ".", "load_dict", "(", "path", ",", "model_type", ")", "\n", "", "except", "IOError", "as", "x", ":", "\n", "        ", "logging", ".", "error", "(", "'failed to determine vocabulary size from file: '", "\n", "'{}: {}'", ".", "format", "(", "path", ",", "str", "(", "x", ")", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "except", ":", "\n", "        ", "logging", ".", "error", "(", "'failed to determine vocabulary size from file: '", "\n", "'{}'", ".", "format", "(", "path", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "return", "max", "(", "d", ".", "values", "(", ")", ")", "+", "1", "\n", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler.RandomSampler.__init__": [[51, 92], ["tensorflow.compat.v1.name_scope", "sampler_inputs.SamplerInputs", "enumerate", "random_sampler._random_sample", "zip", "tensorflow.compat.v1.name_scope", "model_adapters.append", "transformer_inference.ModelAdapter", "rnn_inference.ModelAdapter"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler._random_sample"], ["def", "__init__", "(", "self", ",", "models", ",", "configs", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\"Sets some things up then calls _random_sample() to do the real work.\n\n        Args:\n            models: a sequence of RNN or Transformer objects.\n            configs: a sequence of model configs (argparse.Namespace objects).\n            beam_size: integer specifying the beam width.\n        \"\"\"", "\n", "self", ".", "_models", "=", "models", "\n", "self", ".", "_configs", "=", "configs", "\n", "self", ".", "_beam_size", "=", "beam_size", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "'random_sampler'", ")", ":", "\n", "\n", "# Define placeholders.", "\n", "            ", "self", ".", "inputs", "=", "sampler_inputs", ".", "SamplerInputs", "(", ")", "\n", "\n", "# Create an adapter to get a consistent interface to", "\n", "# Transformer and RNN models.", "\n", "model_adapters", "=", "[", "]", "\n", "for", "i", ",", "(", "model", ",", "config", ")", "in", "enumerate", "(", "zip", "(", "models", ",", "configs", ")", ")", ":", "\n", "                ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "'model_adapter_{}'", ".", "format", "(", "i", ")", ")", "as", "scope", ":", "\n", "                    ", "if", "config", ".", "model_type", "==", "'transformer'", ":", "\n", "                        ", "adapter", "=", "transformer_inference", ".", "ModelAdapter", "(", "\n", "model", ",", "config", ",", "scope", ")", "\n", "", "else", ":", "\n", "                        ", "assert", "config", ".", "model_type", "==", "'rnn'", "\n", "adapter", "=", "rnn_inference", ".", "ModelAdapter", "(", "\n", "model", ",", "config", ",", "scope", ")", "\n", "", "model_adapters", ".", "append", "(", "adapter", ")", "\n", "\n", "# Build the graph to do the actual work.", "\n", "", "", "sequences", ",", "scores", "=", "_random_sample", "(", "\n", "model_adapters", "=", "model_adapters", ",", "\n", "beam_size", "=", "beam_size", ",", "\n", "batch_size_x", "=", "self", ".", "inputs", ".", "batch_size_x", ",", "\n", "max_translation_len", "=", "self", ".", "inputs", ".", "max_translation_len", ",", "\n", "normalization_alpha", "=", "self", ".", "inputs", ".", "normalization_alpha", ",", "\n", "eos_id", "=", "0", ")", "\n", "\n", "self", ".", "_outputs", "=", "sequences", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler.RandomSampler.outputs": [[93, 96], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "outputs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler.RandomSampler.models": [[97, 100], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "models", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_models", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler.RandomSampler.configs": [[101, 104], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "configs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_configs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler.RandomSampler.beam_size": [[105, 108], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "beam_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler._random_sample": [[110, 204], ["tensorflow.constant", "tensorflow.ones", "tensorflow.zeros", "tensorflow.fill", "random_sampler._generate_while_loop_cond_func", "random_sampler._generate_while_loop_body_func", "tensorflow.nest.map_structure", "tensorflow.range", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.compat.v1.where", "tensorflow.reduce_min", "tensorflow.cast", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.transpose", "adapter.encode", "adapter.generate_decoding_function", "decoding_functions.append", "ma.generate_initial_memories", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.while_loop", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.equal", "adapter.get_memory_invariants", "zip"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._generate_while_loop_cond_func", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._generate_while_loop_body_func", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder.encode", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.generate_decoding_function", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.generate_initial_memories", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.get_memory_invariants"], ["", "", "def", "_random_sample", "(", "model_adapters", ",", "beam_size", ",", "batch_size_x", ",", "\n", "max_translation_len", ",", "normalization_alpha", ",", "eos_id", ")", ":", "\n", "    ", "\"\"\"See description for RandomSampler above.\n\n    Args:\n        model_adapters: sequence of ModelAdapter objects.\n        beam_size: integer specifying beam width.\n        batch_size_x: tf.int32 scalar specifying number of input sentences.\n        max_translation_len: tf.int32 scalar specifying max translation length.\n        normalization_alpha: tf.float32 scalar specifying alpha parameter for\n            length normalization.\n        eos_id: integer specifying the vocabulary ID of the EOS symbol.\n\n    Returns:\n        A pair of tensors: (sequences, scores). sequences contains vocabulary\n        IDs. It has shape (batch_size, len), where len <= max_translation_len\n        is the length of the longest translation in the batch. scores contains\n        sequnces scores, which are summed probabilities.\n    \"\"\"", "\n", "\n", "# Encode the input and generate a 1-step decoding function for each model.", "\n", "decoding_functions", "=", "[", "]", "\n", "for", "adapter", "in", "model_adapters", ":", "\n", "        ", "encoder_output", "=", "adapter", ".", "encode", "(", ")", "\n", "func", "=", "adapter", ".", "generate_decoding_function", "(", "encoder_output", ")", "\n", "decoding_functions", ".", "append", "(", "func", ")", "\n", "\n", "# Initialize the timestep counter.", "\n", "", "current_time_step", "=", "tf", ".", "constant", "(", "1", ")", "\n", "\n", "# Initialize sequences with <GO>.", "\n", "sequences", "=", "tf", ".", "ones", "(", "[", "batch_size_x", "*", "beam_size", ",", "1", "]", ",", "dtype", "=", "INT_DTYPE", ")", "\n", "\n", "# Initialize sequence scores.", "\n", "scores", "=", "tf", ".", "zeros", "(", "[", "batch_size_x", "*", "beam_size", "]", ",", "dtype", "=", "FLOAT_DTYPE", ")", "\n", "\n", "# Flags indicating which sequences are finished.", "\n", "finished", "=", "tf", ".", "fill", "(", "[", "batch_size_x", "*", "beam_size", "]", ",", "False", ")", "\n", "\n", "# Initialize memories (i.e. states carried over from last timestep.", "\n", "memories", "=", "[", "ma", ".", "generate_initial_memories", "(", "batch_size_x", ",", "beam_size", ")", "\n", "for", "ma", "in", "model_adapters", "]", "\n", "\n", "# Generate the conditional and body functions for the sampling loop.", "\n", "\n", "loop_cond", "=", "_generate_while_loop_cond_func", "(", "max_translation_len", ")", "\n", "\n", "loop_body", "=", "_generate_while_loop_body_func", "(", "model_adapters", ",", "\n", "decoding_functions", ",", "\n", "batch_size_x", ",", "beam_size", ",", "eos_id", ")", "\n", "\n", "loop_vars", "=", "[", "current_time_step", ",", "sequences", ",", "scores", ",", "memories", ",", "finished", "]", "\n", "\n", "shape_invariants", "=", "[", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "# timestep", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", ",", "# sequences", "\n", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "# scores", "\n", "[", "adapter", ".", "get_memory_invariants", "(", "mems", ")", "# memories", "\n", "for", "adapter", ",", "mems", "in", "zip", "(", "model_adapters", ",", "memories", ")", "]", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", "]", "# finished", "\n", "\n", "_", ",", "sequences", ",", "scores", ",", "_", ",", "_", "=", "tf", ".", "nest", ".", "map_structure", "(", "tf", ".", "stop_gradient", ",", "tf", ".", "while_loop", "(", "cond", "=", "loop_cond", ",", "\n", "body", "=", "loop_body", ",", "\n", "loop_vars", "=", "loop_vars", ",", "\n", "shape_invariants", "=", "shape_invariants", ",", "\n", "parallel_iterations", "=", "10", ",", "\n", "swap_memory", "=", "False", ")", ")", "\n", "\n", "# Truncate sequences to remove leading <GO> tokens.", "\n", "sequences", "=", "sequences", "[", ":", ",", "1", ":", "]", "\n", "\n", "# Normalize scores. Note that we include the <EOS> token when calculating", "\n", "# sequence length.", "\n", "seq_len", "=", "tf", ".", "shape", "(", "input", "=", "sequences", ")", "[", "1", "]", "\n", "indices", "=", "tf", ".", "range", "(", "seq_len", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "indices", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "indices", ",", "0", ")", ",", "[", "batch_size_x", "*", "beam_size", ",", "1", "]", ")", "\n", "seq_lens", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "seq_len", ",", "0", ")", ",", "0", ")", "\n", "seq_lens", "=", "tf", ".", "tile", "(", "seq_lens", ",", "[", "batch_size_x", "*", "beam_size", ",", "seq_len", "]", ")", "\n", "eos_indices", "=", "tf", ".", "compat", ".", "v1", ".", "where", "(", "tf", ".", "equal", "(", "sequences", ",", "eos_id", ")", ",", "indices", ",", "seq_lens", ")", "\n", "lengths", "=", "tf", ".", "reduce_min", "(", "input_tensor", "=", "eos_indices", "+", "1", ",", "axis", "=", "1", ")", "\n", "float_lengths", "=", "tf", ".", "cast", "(", "lengths", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "length_penalties", "=", "float_lengths", "**", "normalization_alpha", "\n", "scores", "=", "scores", "/", "length_penalties", "\n", "\n", "# Reshape / transpose to group translations and scores by input sentence.", "\n", "\n", "sequences", "=", "tf", ".", "reshape", "(", "sequences", ",", "[", "beam_size", ",", "batch_size_x", ",", "seq_len", "]", ")", "\n", "sequences", "=", "tf", ".", "transpose", "(", "a", "=", "sequences", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "scores", "=", "tf", ".", "reshape", "(", "scores", ",", "[", "beam_size", ",", "batch_size_x", "]", ")", "\n", "scores", "=", "tf", ".", "transpose", "(", "a", "=", "scores", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "\n", "return", "sequences", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler._generate_while_loop_cond_func": [[206, 214], ["tensorflow.logical_and", "tensorflow.less", "tensorflow.logical_not", "tensorflow.reduce_all"], "function", ["None"], ["", "def", "_generate_while_loop_cond_func", "(", "max_translation_len", ")", ":", "\n", "\n", "    ", "def", "continue_decoding", "(", "current_time_step", ",", "sequences", ",", "scores", ",", "memories", ",", "\n", "finished", ")", ":", "\n", "        ", "return", "tf", ".", "logical_and", "(", "tf", ".", "less", "(", "current_time_step", ",", "max_translation_len", ")", ",", "\n", "tf", ".", "logical_not", "(", "tf", ".", "reduce_all", "(", "input_tensor", "=", "finished", ")", ")", ")", "\n", "\n", "", "return", "continue_decoding", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.random_sampler._generate_while_loop_body_func": [[216, 271], ["range", "tensorflow.squeeze", "tensorflow.range", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.compat.v1.where", "tensorflow.concat", "tensorflow.equal", "len", "model_adapters[].model.sampling_utils.adjust_logits", "tensorflow.nn.log_softmax", "tensorflow.random.categorical", "tensorflow.logical_not", "tensorflow.zeros", "tensorflow.reduce_prod", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sampling_utils.SamplingUtils.adjust_logits"], ["", "def", "_generate_while_loop_body_func", "(", "model_adapters", ",", "decoding_functions", ",", "\n", "batch_size_x", ",", "beam_size", ",", "eos_id", ")", ":", "\n", "\n", "    ", "def", "decoding_step", "(", "current_time_step", ",", "sequences", ",", "scores", ",", "memories", ",", "\n", "finished", ")", ":", "\n", "\n", "# Get the target vocabulary IDs for this time step.", "\n", "        ", "step_ids", "=", "sequences", "[", ":", ",", "-", "1", "]", "\n", "\n", "# Calculate next token probabilities for each model and sum them.", "\n", "sum_log_probs", "=", "None", "\n", "for", "i", "in", "range", "(", "len", "(", "model_adapters", ")", ")", ":", "\n", "# Propagate through decoder.", "\n", "            ", "step_logits", ",", "memories", "[", "i", "]", "=", "decoding_functions", "[", "i", "]", "(", "\n", "step_ids", ",", "current_time_step", ",", "memories", "[", "i", "]", ")", "\n", "\n", "# Adjust sampling temperature.", "\n", "step_logits", "=", "model_adapters", "[", "i", "]", ".", "model", ".", "sampling_utils", ".", "adjust_logits", "(", "\n", "step_logits", ")", "\n", "\n", "# Calculate log probs for all possible tokens at current time-step.", "\n", "model_log_probs", "=", "tf", ".", "nn", ".", "log_softmax", "(", "step_logits", ")", "\n", "\n", "# Add to summed log probs.", "\n", "if", "sum_log_probs", "is", "None", ":", "\n", "                ", "sum_log_probs", "=", "model_log_probs", "\n", "", "else", ":", "\n", "                ", "sum_log_probs", "+=", "model_log_probs", "\n", "\n", "# Determine the next token to be added to each sequence.", "\n", "", "", "next_ids", "=", "tf", ".", "squeeze", "(", "tf", ".", "random", ".", "categorical", "(", "logits", "=", "sum_log_probs", ",", "num_samples", "=", "1", ",", "\n", "dtype", "=", "INT_DTYPE", ")", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "# Collect scores associated with the selected tokens.", "\n", "seq_indices", "=", "tf", ".", "range", "(", "batch_size_x", "*", "beam_size", ",", "dtype", "=", "INT_DTYPE", ")", "\n", "score_coordinates", "=", "tf", ".", "stack", "(", "[", "seq_indices", ",", "next_ids", "]", ",", "axis", "=", "1", ")", "\n", "increments", "=", "tf", ".", "gather_nd", "(", "sum_log_probs", ",", "score_coordinates", ")", "\n", "\n", "# Add scores to cumulative scores, except for sequences that were", "\n", "# already completed before this timestep.", "\n", "scores", "+=", "tf", ".", "compat", ".", "v1", ".", "where", "(", "tf", ".", "logical_not", "(", "finished", ")", ",", "\n", "increments", ",", "\n", "tf", ".", "zeros", "(", "[", "batch_size_x", "*", "beam_size", "]", ")", ")", "\n", "\n", "# Extend each sequence with the next token.", "\n", "sequences", "=", "tf", ".", "concat", "(", "[", "sequences", ",", "tf", ".", "expand_dims", "(", "next_ids", ",", "1", ")", "]", ",", "1", ")", "\n", "\n", "# Check if sequences have been finished (with a <EOS> token).", "\n", "finished", "|=", "tf", ".", "equal", "(", "tf", ".", "reduce_prod", "(", "input_tensor", "=", "sequences", "-", "eos_id", ",", "axis", "=", "1", ")", ",", "\n", "eos_id", ")", "\n", "\n", "return", "current_time_step", "+", "1", ",", "sequences", ",", "scores", ",", "memories", ",", "finished", "\n", "\n", "", "return", "decoding_step", "\n", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.training_progress.TrainingProgress.load_from_json": [[12, 15], ["open", "training_progress.TrainingProgress.__dict__.update", "json.load"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater.update"], ["def", "load_from_json", "(", "self", ",", "file_name", ")", ":", "\n", "        ", "with", "open", "(", "file_name", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fh", ":", "\n", "            ", "self", ".", "__dict__", ".", "update", "(", "json", ".", "load", "(", "fh", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.training_progress.TrainingProgress.save_to_json": [[16, 20], ["open", "json.dump"], "methods", ["None"], ["", "", "def", "save_to_json", "(", "self", ",", "file_name", ")", ":", "\n", "        ", "with", "open", "(", "file_name", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fh", ":", "\n", "# TODO ensure_ascii=False?", "\n", "            ", "json", ".", "dump", "(", "self", ".", "__dict__", ",", "fh", ",", "indent", "=", "2", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_blocks.AttentionBlock.__init__": [[33, 83], ["ProcessingLayer", "MultiHeadAttentionLayer", "ProcessingLayer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "float_dtype", ",", "\n", "self_attention", ",", "\n", "training", ",", "\n", "from_rnn", "=", "False", ",", "\n", "tie_attention", "=", "False", ")", ":", "\n", "# Set attributes", "\n", "        ", "self", ".", "self_attention", "=", "self_attention", "\n", "if", "not", "tie_attention", ":", "\n", "            ", "if", "self_attention", ":", "\n", "                ", "attn_name", "=", "'self_attn'", "\n", "", "else", ":", "\n", "                ", "attn_name", "=", "'cross_attn'", "\n", "", "", "else", ":", "\n", "            ", "attn_name", "=", "'tied_attn'", "\n", "\n", "", "memory_size", "=", "config", ".", "state_size", "\n", "if", "from_rnn", ":", "\n", "            ", "memory_size", "*=", "2", "\n", "\n", "", "if", "config", ".", "layer_normalization_type", "==", "'layernorm'", ":", "\n", "            ", "layernorm", "=", "LayerNormLayer", "\n", "", "elif", "config", ".", "layer_normalization_type", "==", "'rmsnorm'", ":", "\n", "            ", "layernorm", "=", "RMSNormLayer", "\n", "\n", "# Build layers", "\n", "", "self", ".", "pre_attn", "=", "ProcessingLayer", "(", "config", ".", "state_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "training", "=", "training", ",", "\n", "name", "=", "'pre_{:s}_sublayer'", ".", "format", "(", "attn_name", ")", ")", "\n", "\n", "self", ".", "attn", "=", "MultiHeadAttentionLayer", "(", "memory_size", ",", "\n", "config", ".", "state_size", ",", "\n", "config", ".", "state_size", ",", "\n", "config", ".", "state_size", ",", "\n", "config", ".", "state_size", ",", "\n", "config", ".", "transformer_num_heads", ",", "\n", "float_dtype", ",", "\n", "dropout_attn", "=", "config", ".", "transformer_dropout_attn", ",", "\n", "drophead", "=", "config", ".", "transformer_drophead", ",", "\n", "training", "=", "training", ",", "\n", "name", "=", "'{:s}_sublayer'", ".", "format", "(", "attn_name", ")", ")", "\n", "\n", "self", ".", "post_attn", "=", "ProcessingLayer", "(", "config", ".", "state_size", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "dropout_rate", "=", "config", ".", "transformer_dropout_residual", ",", "\n", "training", "=", "training", ",", "\n", "name", "=", "'post_{:s}_sublayer'", ".", "format", "(", "attn_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_blocks.AttentionBlock.forward": [[84, 93], ["transformer_blocks.AttentionBlock.pre_attn.forward", "transformer_blocks.AttentionBlock.attn.forward", "transformer_blocks.AttentionBlock.post_attn.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_context", ",", "attn_mask", ",", "layer_memories", "=", "None", ")", ":", "\n", "        ", "\"\"\" Propagates input data through the block. \"\"\"", "\n", "if", "not", "self", ".", "self_attention", ":", "\n", "            ", "assert", "(", "memory_context", "is", "not", "None", ")", ",", "'Encoder memories have to be provided for encoder-decoder attention computation.'", "\n", "", "attn_inputs", "=", "self", ".", "pre_attn", ".", "forward", "(", "inputs", ")", "\n", "attn_outputs", ",", "layer_memories", "=", "self", ".", "attn", ".", "forward", "(", "attn_inputs", ",", "memory_context", ",", "attn_mask", ",", "layer_memories", ")", "\n", "block_out", "=", "self", ".", "post_attn", ".", "forward", "(", "attn_outputs", ",", "residual_inputs", "=", "inputs", ")", "\n", "return", "block_out", ",", "layer_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_blocks.FFNBlock.__init__": [[99, 138], ["ProcessingLayer", "FeedForwardNetwork", "ProcessingLayer", "ProcessingLayer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "ffn_dims", ",", "\n", "float_dtype", ",", "\n", "is_final", ",", "\n", "training", ")", ":", "\n", "# Set attributes", "\n", "        ", "self", ".", "is_final", "=", "is_final", "\n", "\n", "if", "config", ".", "layer_normalization_type", "==", "'layernorm'", ":", "\n", "            ", "layernorm", "=", "LayerNormLayer", "\n", "", "elif", "config", ".", "layer_normalization_type", "==", "'rmsnorm'", ":", "\n", "            ", "layernorm", "=", "RMSNormLayer", "\n", "\n", "# Build layers", "\n", "", "self", ".", "pre_ffn", "=", "ProcessingLayer", "(", "config", ".", "state_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "training", "=", "training", ",", "\n", "name", "=", "'pre_ffn_sublayer'", ")", "\n", "self", ".", "ffn", "=", "FeedForwardNetwork", "(", "ffn_dims", ",", "\n", "float_dtype", ",", "\n", "use_bias", "=", "True", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "dropout_rate", "=", "config", ".", "transformer_dropout_relu", ",", "\n", "training", "=", "training", ",", "\n", "name", "=", "'ffn_sublayer'", ")", "\n", "self", ".", "post_ffn", "=", "ProcessingLayer", "(", "config", ".", "state_size", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "dropout_rate", "=", "config", ".", "transformer_dropout_residual", ",", "\n", "training", "=", "training", ",", "\n", "name", "=", "'post_ffn_sublayer'", ")", "\n", "if", "is_final", ":", "\n", "            ", "self", ".", "pre_final", "=", "ProcessingLayer", "(", "config", ".", "state_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "training", "=", "training", ",", "\n", "name", "=", "'final_transform'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_blocks.FFNBlock.forward": [[139, 147], ["transformer_blocks.FFNBlock.pre_ffn.forward", "transformer_blocks.FFNBlock.ffn.forward", "transformer_blocks.FFNBlock.post_ffn.forward", "transformer_blocks.FFNBlock.pre_final.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\" Propagates input data through the block. \"\"\"", "\n", "ffn_inputs", "=", "self", ".", "pre_ffn", ".", "forward", "(", "inputs", ")", "\n", "ffn_outputs", "=", "self", ".", "ffn", ".", "forward", "(", "ffn_inputs", ")", "\n", "block_out", "=", "self", ".", "post_ffn", ".", "forward", "(", "ffn_outputs", ",", "residual_inputs", "=", "inputs", ")", "\n", "if", "self", ".", "is_final", ":", "\n", "            ", "block_out", "=", "self", ".", "pre_final", ".", "forward", "(", "block_out", ")", "\n", "", "return", "block_out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch": [[20, 78], ["numpy.tile", "numpy.tile", "zip", "session.run", "range", "len", "len", "len", "zip", "beams.append", "sorted"], "function", ["None"], ["", "def", "translate_batch", "(", "session", ",", "sampler", ",", "x", ",", "x_mask", ",", "max_translation_len", ",", "\n", "normalization_alpha", ")", ":", "\n", "    ", "\"\"\"Translate a batch using a RandomSampler or BeamSearchSampler.\n\n    Args:\n        session: a TensorFlow session.\n        sampler: a BeamSearchSampler or RandomSampler object.\n        x: input Tensor with shape (factors, max_seq_len, batch_size).\n        x_mask: mask Tensor for x with shape (max_seq_len, batch_size).\n        max_translation_len: integer specifying maximum translation length.\n        normalization_alpha: float specifying alpha parameter for length\n            normalization.\n\n    Returns:\n        A list of lists of (translation, score) pairs. The outer list contains\n        one list for each input sentence in the batch. The inner lists contain\n        k elements (where k is the beam size), sorted by score in best-first\n        order.\n    \"\"\"", "\n", "\n", "x_tiled", "=", "numpy", ".", "tile", "(", "x", ",", "reps", "=", "[", "1", ",", "1", ",", "sampler", ".", "beam_size", "]", ")", "\n", "x_mask_tiled", "=", "numpy", ".", "tile", "(", "x_mask", ",", "reps", "=", "[", "1", ",", "sampler", ".", "beam_size", "]", ")", "\n", "\n", "feed_dict", "=", "{", "}", "\n", "\n", "# Feed inputs to the models.", "\n", "for", "model", ",", "config", "in", "zip", "(", "sampler", ".", "models", ",", "sampler", ".", "configs", ")", ":", "\n", "        ", "if", "config", ".", "model_type", "==", "'rnn'", ":", "\n", "            ", "feed_dict", "[", "model", ".", "inputs", ".", "x", "]", "=", "x_tiled", "\n", "feed_dict", "[", "model", ".", "inputs", ".", "x_mask", "]", "=", "x_mask_tiled", "\n", "", "else", ":", "\n", "            ", "assert", "config", ".", "model_type", "==", "'transformer'", "\n", "# Inputs don't need to be tiled in the Transformer because it", "\n", "# checks for different batch sizes in the encoder and decoder and", "\n", "# does its own tiling internally at the connection points.", "\n", "feed_dict", "[", "model", ".", "inputs", ".", "x", "]", "=", "x", "\n", "feed_dict", "[", "model", ".", "inputs", ".", "x_mask", "]", "=", "x_mask", "\n", "", "feed_dict", "[", "model", ".", "inputs", ".", "training", "]", "=", "False", "\n", "\n", "# Feed inputs to the sampler.", "\n", "", "feed_dict", "[", "sampler", ".", "inputs", ".", "batch_size_x", "]", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "feed_dict", "[", "sampler", ".", "inputs", ".", "max_translation_len", "]", "=", "max_translation_len", "\n", "feed_dict", "[", "sampler", ".", "inputs", ".", "normalization_alpha", "]", "=", "normalization_alpha", "\n", "\n", "# Run the sampler.", "\n", "translations", ",", "scores", "=", "session", ".", "run", "(", "sampler", ".", "outputs", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "assert", "len", "(", "translations", ")", "==", "x", ".", "shape", "[", "-", "1", "]", "\n", "assert", "len", "(", "scores", ")", "==", "x", ".", "shape", "[", "-", "1", "]", "\n", "\n", "# Sort the translations by score. The scores are (optionally normalized)", "\n", "# log probs so higher values are better.", "\n", "beams", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "translations", ")", ")", ":", "\n", "        ", "pairs", "=", "zip", "(", "translations", "[", "i", "]", ",", "scores", "[", "i", "]", ")", "\n", "beams", ".", "append", "(", "sorted", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "\n", "", "return", "beams", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_file": [[80, 172], ["util.load_dictionaries", "logging.info", "time.time", "logging.info", "numpy.array", "enumerate", "input_file.readline", "maxibatch.append", "time.time", "util.read_all_lines", "numpy.zeros", "util.prepare_data", "translate_utils.translate_batch", "beams.extend", "logging.info", "len", "translate_utils.translate_file.translate_maxibatch"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dictionaries", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.read_all_lines", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.prepare_data", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch"], ["", "def", "translate_file", "(", "input_file", ",", "output_file", ",", "session", ",", "sampler", ",", "config", ",", "\n", "max_translation_len", ",", "normalization_alpha", ",", "nbest", "=", "False", ",", "\n", "minibatch_size", "=", "80", ",", "maxibatch_size", "=", "20", ")", ":", "\n", "    ", "\"\"\"Translates a source file using a RandomSampler or BeamSearchSampler.\n\n    Args:\n        input_file: file object from which source sentences will be read.\n        output_file: file object to which translations will be written.\n        session: TensorFlow session.\n        sampler: BeamSearchSampler or RandomSampler object.\n        config: model config.\n        max_translation_len: integer specifying maximum translation length.\n        normalization_alpha: float specifying alpha parameter for length\n            normalization.\n        nbest: if True, produce n-best output with scores; otherwise 1-best.\n        minibatch_size: minibatch size in sentences.\n        maxibatch_size: number of minibatches to read and sort, pre-translation.\n    \"\"\"", "\n", "\n", "def", "translate_maxibatch", "(", "maxibatch", ",", "num_to_target", ",", "num_prev_translated", ")", ":", "\n", "        ", "\"\"\"Translates an individual maxibatch.\n\n        Args:\n            maxibatch: a list of sentences.\n            num_to_target: dictionary mapping target vocabulary IDs to strings.\n            num_prev_translated: the number of previously translated sentences.\n        \"\"\"", "\n", "\n", "# Sort the maxibatch by length and split into minibatches.", "\n", "try", ":", "\n", "            ", "minibatches", ",", "idxs", "=", "util", ".", "read_all_lines", "(", "config", ",", "maxibatch", ",", "\n", "minibatch_size", ")", "\n", "", "except", "exception", ".", "Error", "as", "x", ":", "\n", "            ", "logging", ".", "error", "(", "x", ".", "msg", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "# Translate the minibatches and store the resulting beam (i.e.", "\n", "# translations and scores) for each sentence.", "\n", "", "beams", "=", "[", "]", "\n", "for", "x", "in", "minibatches", ":", "\n", "            ", "y_dummy", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "len", "(", "x", ")", ",", "1", ")", ")", "\n", "x", ",", "x_mask", ",", "_", ",", "_", "=", "util", ".", "prepare_data", "(", "x", ",", "y_dummy", ",", "config", ".", "factors", ",", "\n", "maxlen", "=", "None", ")", "\n", "sample", "=", "translate_batch", "(", "session", ",", "sampler", ",", "x", ",", "x_mask", ",", "\n", "max_translation_len", ",", "normalization_alpha", ")", "\n", "beams", ".", "extend", "(", "sample", ")", "\n", "num_translated", "=", "num_prev_translated", "+", "len", "(", "beams", ")", "\n", "logging", ".", "info", "(", "'Translated {} sents'", ".", "format", "(", "num_translated", ")", ")", "\n", "\n", "# Put beams into the same order as the input maxibatch.", "\n", "", "tmp", "=", "numpy", ".", "array", "(", "beams", ",", "dtype", "=", "numpy", ".", "object", ")", "\n", "ordered_beams", "=", "tmp", "[", "idxs", ".", "argsort", "(", ")", "]", "\n", "\n", "# Write the translations to the output file.", "\n", "for", "i", ",", "beam", "in", "enumerate", "(", "ordered_beams", ")", ":", "\n", "            ", "if", "nbest", ":", "\n", "                ", "num", "=", "num_prev_translated", "+", "i", "\n", "for", "sent", ",", "cost", "in", "beam", ":", "\n", "                    ", "translation", "=", "util", ".", "seq2words", "(", "sent", ",", "num_to_target", ")", "\n", "line", "=", "\"{} ||| {} ||| {}\\n\"", ".", "format", "(", "num", ",", "translation", ",", "\n", "str", "(", "cost", ")", ")", "\n", "output_file", ".", "write", "(", "line", ")", "\n", "", "", "else", ":", "\n", "                ", "best_hypo", ",", "cost", "=", "beam", "[", "0", "]", "\n", "line", "=", "util", ".", "seq2words", "(", "best_hypo", ",", "num_to_target", ")", "+", "'\\n'", "\n", "output_file", ".", "write", "(", "line", ")", "\n", "\n", "", "", "", "_", ",", "_", ",", "_", ",", "num_to_target", "=", "util", ".", "load_dictionaries", "(", "config", ")", "\n", "\n", "logging", ".", "info", "(", "\"NOTE: Length of translations is capped to {}\"", ".", "format", "(", "\n", "max_translation_len", ")", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "num_translated", "=", "0", "\n", "maxibatch", "=", "[", "]", "\n", "while", "True", ":", "\n", "        ", "line", "=", "input_file", ".", "readline", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "\n", "            ", "if", "len", "(", "maxibatch", ")", ">", "0", ":", "\n", "                ", "translate_maxibatch", "(", "maxibatch", ",", "num_to_target", ",", "num_translated", ")", "\n", "num_translated", "+=", "len", "(", "maxibatch", ")", "\n", "", "break", "\n", "", "maxibatch", ".", "append", "(", "line", ")", "\n", "if", "len", "(", "maxibatch", ")", "==", "(", "maxibatch_size", "*", "minibatch_size", ")", ":", "\n", "            ", "translate_maxibatch", "(", "maxibatch", ",", "num_to_target", ",", "num_translated", ")", "\n", "num_translated", "+=", "len", "(", "maxibatch", ")", "\n", "maxibatch", "=", "[", "]", "\n", "\n", "", "", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "logging", ".", "info", "(", "'Translated {} sents in {} sec. Speed {} sents/sec'", ".", "format", "(", "\n", "num_translated", ",", "duration", ",", "num_translated", "/", "duration", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.__init__": [[77, 92], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.transpose", "tensorflow.python.ops.init_ops.glorot_uniform_initializer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocabulary_size", ",", "embedding_size", ",", "hidden_size", ",", "float_dtype", ",", "name", ")", ":", "\n", "# Set arguments", "\n", "        ", "self", ".", "vocabulary_size", "=", "vocabulary_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "float_dtype", "=", "float_dtype", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# Create embedding matrix and its transposes", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "self", ".", "embedding_table", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'embedding_table'", ",", "\n", "shape", "=", "[", "vocabulary_size", ",", "embedding_size", "]", ",", "\n", "dtype", "=", "float_dtype", ",", "\n", "initializer", "=", "glorot_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "True", ")", "\n", "self", ".", "projection_matrix", "=", "tf", ".", "transpose", "(", "a", "=", "self", ".", "embedding_table", ",", "name", "=", "'vocab_projection_matrix'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.embed": [[93, 99], ["tensorflow.nn.embedding_lookup", "tensorflow.sqrt", "tensorflow.cast"], "methods", ["None"], ["", "", "def", "embed", "(", "self", ",", "one_hot_inputs", ")", ":", "\n", "        ", "\"\"\" Embeds one-hot-vectors corresponding to input tokens. \"\"\"", "\n", "embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "embedding_table", ",", "ids", "=", "one_hot_inputs", ")", "\n", "# Apply transformer-specific scaling", "\n", "embeddings", "*=", "tf", ".", "sqrt", "(", "tf", ".", "cast", "(", "self", ".", "hidden_size", ",", "self", ".", "float_dtype", ")", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.project": [[100, 104], ["transformer_layers.matmul_nd"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.matmul_nd"], ["", "def", "project", "(", "self", ",", "dec_out", ")", ":", "\n", "        ", "\"\"\" Projects the transformer decoder's output into the vocabulary space. \"\"\"", "\n", "projections", "=", "matmul_nd", "(", "dec_out", ",", "self", ".", "projection_matrix", ")", "\n", "return", "projections", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.get_embedding_table": [[105, 108], ["None"], "methods", ["None"], ["", "def", "get_embedding_table", "(", "self", ")", ":", "\n", "        ", "\"\"\" Recovers the learned embedding table. \"\"\"", "\n", "return", "self", ".", "embedding_table", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.get_projection_matrix": [[109, 112], ["None"], "methods", ["None"], ["", "def", "get_projection_matrix", "(", "self", ")", ":", "\n", "        ", "\"\"\" Recovers the pre-softmax projection matrix which is the inverse of the embedding table. \"\"\"", "\n", "return", "self", ".", "projection_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.get_vocab_size": [[113, 116], ["None"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Recovers the vocabulary size. \"\"\"", "\n", "return", "self", ".", "vocabulary_size", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.LayerNormLayer.__init__": [[122, 138], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.constant", "tensorflow.zeros_initializer", "tensorflow.compat.v1.ones_initializer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dims_out", ",", "name", "=", "None", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "if", "name", "is", "None", ":", "\n", "            ", "name", "=", "'layer_norm'", "\n", "", "else", ":", "\n", "            ", "name", "=", "'{:s}_layer_norm'", ".", "format", "(", "name", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "values", "=", "[", "dims_out", "]", ")", ":", "\n", "            ", "self", ".", "offset", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'offset'", ",", "\n", "shape", "=", "[", "dims_out", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "self", ".", "scale", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'scale'", ",", "\n", "shape", "=", "[", "dims_out", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "ones_initializer", "(", ")", ")", "\n", "self", ".", "eps", "=", "tf", ".", "constant", "(", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.LayerNormLayer.forward": [[139, 147], ["tensorflow.nn.moments", "tensorflow.add", "tensorflow.multiply", "tensorflow.math.divide", "tensorflow.subtract", "tensorflow.sqrt", "tensorflow.add"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "layer_mean", ",", "layer_var", "=", "tf", ".", "nn", ".", "moments", "(", "x", "=", "inputs", ",", "axes", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "normalized", "=", "tf", ".", "add", "(", "\n", "tf", ".", "multiply", "(", "self", ".", "scale", ",", "tf", ".", "math", ".", "divide", "(", "tf", ".", "subtract", "(", "inputs", ",", "layer_mean", ")", ",", "\n", "tf", ".", "sqrt", "(", "tf", ".", "add", "(", "layer_var", ",", "self", ".", "eps", ")", ")", ")", ")", ",", "\n", "self", ".", "offset", ")", "\n", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.RMSNormLayer.__init__": [[153, 165], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.constant", "tensorflow.compat.v1.ones_initializer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dims_out", ",", "name", "=", "None", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "if", "name", "is", "None", ":", "\n", "            ", "name", "=", "'rms_norm'", "\n", "", "else", ":", "\n", "            ", "name", "=", "'{:s}_rms_norm'", ".", "format", "(", "name", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "values", "=", "[", "dims_out", "]", ")", ":", "\n", "            ", "self", ".", "scale", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'scale'", ",", "\n", "shape", "=", "[", "dims_out", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "ones_initializer", "(", ")", ")", "\n", "self", ".", "eps", "=", "tf", ".", "constant", "(", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.RMSNormLayer.forward": [[166, 171], ["tensorflow.reduce_mean", "tensorflow.math.rsqrt"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "meansquare", "=", "tf", ".", "reduce_mean", "(", "inputs", "**", "2", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "normalized", "=", "self", ".", "scale", "*", "inputs", "*", "tf", ".", "math", ".", "rsqrt", "(", "meansquare", "+", "self", ".", "eps", ")", "\n", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.ProcessingLayer.__init__": [[176, 191], ["tensorflow.compat.v1.variable_scope", "use_layer_norm", "tensorflow.keras.layers.Dropout"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "out_size", ",", "use_layer_norm", ",", "dropout_rate", ",", "training", ",", "name", ")", ":", "\n", "# Set attributes", "\n", "        ", "self", ".", "use_layer_norm", "=", "use_layer_norm", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "name", "=", "name", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "# Initialize layer normalization, if specified", "\n", "            ", "if", "use_layer_norm", "is", "not", "False", "and", "use_layer_norm", "is", "not", "None", ":", "\n", "                ", "self", ".", "layer_norm", "=", "use_layer_norm", "(", "out_size", ")", "\n", "\n", "", "if", "dropout_rate", ">", "0", ":", "\n", "                ", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", "=", "dropout_rate", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "dropout", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.ProcessingLayer.forward": [[192, 205], ["tensorflow.compat.v1.variable_scope", "transformer_layers.ProcessingLayer.dropout", "transformer_layers.ProcessingLayer.layer_norm.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "", "def", "forward", "(", "self", ",", "inputs", ",", "residual_inputs", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ",", "values", "=", "[", "inputs", ",", "residual_inputs", "]", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "outputs", "=", "inputs", "\n", "# Apply dropout", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "                ", "outputs", "=", "self", ".", "dropout", "(", "inputs", ",", "training", "=", "self", ".", "training", ")", "\n", "# Apply residual connections", "\n", "", "if", "residual_inputs", "is", "not", "None", ":", "\n", "                ", "outputs", "=", "outputs", "+", "residual_inputs", "\n", "# Apply layer normalization", "\n", "", "if", "self", ".", "use_layer_norm", ":", "\n", "                ", "outputs", "=", "self", ".", "layer_norm", ".", "forward", "(", "outputs", ")", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.FeedForwardLayer.__init__": [[210, 255], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "use_layer_norm", "tensorflow.keras.layers.Dropout", "tensorflow.compat.v1.get_variable", "tensorflow.python.ops.init_ops.glorot_uniform_initializer", "tensorflow.zeros_initializer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "in_size", ",", "\n", "out_size", ",", "\n", "float_dtype", ",", "\n", "dropout_rate", ",", "\n", "activation", ",", "\n", "use_bias", ",", "\n", "use_layer_norm", ",", "\n", "training", ",", "\n", "name", ")", ":", "\n", "# Set attributes", "\n", "        ", "self", ".", "in_size", "=", "in_size", "\n", "self", ".", "out_size", "=", "out_size", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "name", "=", "name", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "# Set up layer normalization", "\n", "            ", "if", "use_layer_norm", "is", "not", "False", "and", "use_layer_norm", "is", "not", "None", ":", "\n", "                ", "self", ".", "layer_norm_layer", "=", "use_layer_norm", "(", "out_size", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "layer_norm_layer", "=", "None", "\n", "\n", "", "if", "dropout_rate", ">", "0", ":", "\n", "                ", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", "=", "dropout_rate", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "dropout", "=", "None", "\n", "\n", "# Define parameters", "\n", "", "weights_shape", "=", "[", "in_size", ",", "out_size", "]", "if", "out_size", "is", "not", "None", "else", "[", "in_size", "]", "\n", "self", ".", "weights", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'dense_layer_weights'", ",", "\n", "shape", "=", "weights_shape", ",", "\n", "dtype", "=", "float_dtype", ",", "\n", "initializer", "=", "glorot_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "True", ")", "\n", "if", "use_bias", ":", "\n", "                ", "biases_shape", "=", "[", "out_size", "]", "if", "out_size", "is", "not", "None", "else", "[", "in_size", "]", "\n", "self", ".", "biases", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'dense_layer_biases'", ",", "\n", "shape", "=", "biases_shape", ",", "\n", "dtype", "=", "float_dtype", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "trainable", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.FeedForwardLayer.forward": [[256, 271], ["tensorflow.compat.v1.variable_scope", "transformer_layers.matmul_nd", "transformer_layers.FeedForwardLayer.dropout", "transformer_layers.FeedForwardLayer.activation", "transformer_layers.FeedForwardLayer.layer_norm_layer"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.matmul_nd"], ["", "", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "# Optionally apply dropout", "\n", "            ", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "                ", "inputs", "=", "self", ".", "dropout", "(", "inputs", ",", "training", "=", "self", ".", "training", ")", "\n", "# Feed through a dense layer", "\n", "", "outputs", "=", "matmul_nd", "(", "inputs", ",", "self", ".", "weights", ")", "\n", "if", "self", ".", "use_bias", ":", "\n", "                ", "outputs", "+=", "self", ".", "biases", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "                ", "outputs", "=", "self", ".", "activation", "(", "outputs", ")", "\n", "# Optionally apply layer normalization", "\n", "", "if", "self", ".", "layer_norm_layer", "is", "not", "None", ":", "\n", "                ", "outputs", "=", "self", ".", "layer_norm_layer", "(", "outputs", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.FeedForwardNetwork.__init__": [[276, 297], ["list", "transformer_layers.FeedForwardNetwork._initialize_layers"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.FeedForwardNetwork._initialize_layers"], ["def", "__init__", "(", "self", ",", "\n", "layer_dims", ",", "\n", "float_dtype", ",", "\n", "use_bias", ",", "\n", "activation", ",", "\n", "use_layer_norm", ",", "\n", "dropout_rate", ",", "\n", "training", ",", "\n", "name", "=", "None", ")", ":", "\n", "# Set attributes", "\n", "        ", "self", ".", "layer_dims", "=", "layer_dims", "\n", "self", ".", "float_dtype", "=", "float_dtype", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "use_layer_norm", "=", "use_layer_norm", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "name", "=", "name", "\n", "# Container for network layers", "\n", "self", ".", "layers", "=", "list", "(", ")", "\n", "self", ".", "_initialize_layers", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.FeedForwardNetwork._initialize_layers": [[298, 323], ["len", "range", "transformer_layers.FeedForwardNetwork.layers.append", "transformer_layers.FeedForwardLayer"], "methods", ["None"], ["", "def", "_initialize_layers", "(", "self", ")", ":", "\n", "        ", "\"\"\" Builds the network from fully-connected layers. \"\"\"", "\n", "num_layers", "=", "len", "(", "self", ".", "layer_dims", ")", "\n", "for", "layer_id", "in", "range", "(", "num_layers", ")", ":", "\n", "# Assure that no non-linearity or dropout is applied at the final layer", "\n", "            ", "if", "layer_id", "==", "num_layers", "-", "1", ":", "\n", "                ", "layer_activation", "=", "None", "\n", "dropout_rate", "=", "0.0", "\n", "", "else", ":", "\n", "                ", "layer_activation", "=", "self", ".", "activation", "\n", "dropout_rate", "=", "self", ".", "dropout_rate", "\n", "# Add layer", "\n", "", "if", "layer_id", "==", "0", ":", "\n", "                ", "input_dims", "=", "self", ".", "layer_dims", "[", "-", "1", "]", "# input and output dimensions of the sub-layer are identical", "\n", "", "else", ":", "\n", "                ", "input_dims", "=", "self", ".", "layer_dims", "[", "layer_id", "-", "1", "]", "\n", "", "self", ".", "layers", ".", "append", "(", "FeedForwardLayer", "(", "input_dims", ",", "\n", "self", ".", "layer_dims", "[", "layer_id", "]", ",", "\n", "self", ".", "float_dtype", ",", "\n", "dropout_rate", "=", "dropout_rate", ",", "\n", "activation", "=", "layer_activation", ",", "\n", "use_bias", "=", "self", ".", "use_bias", ",", "\n", "use_layer_norm", "=", "self", ".", "use_layer_norm", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "name", "=", "'ff_layer_{:d}'", ".", "format", "(", "layer_id", "+", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.FeedForwardNetwork.forward": [[324, 330], ["tensorflow.compat.v1.variable_scope", "layer.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\" Propagates input data through the specified layers. \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "            ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "                ", "inputs", "=", "layer", ".", "forward", "(", "inputs", ")", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.PReLU.__init__": [[335, 341], ["tensorflow.compat.v1.variable_scope", "tensorflow.Variable", "numpy.ones().astype", "numpy.ones"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "in_size", ",", "\n", "initial_slope", "=", "1.0", ",", "\n", "name", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "default_name", "=", "'PReLu'", ")", ":", "\n", "            ", "self", ".", "slope", "=", "tf", ".", "Variable", "(", "initial_slope", "*", "np", ".", "ones", "(", "(", "in_size", ",", ")", ")", ".", "astype", "(", "'float32'", ")", ",", "name", "=", "'slope'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.PReLU.forward": [[342, 347], ["tensorflow.nn.relu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "pos", "=", "tf", ".", "nn", ".", "relu", "(", "inputs", ")", "\n", "neg", "=", "inputs", "-", "pos", "\n", "outputs", "=", "pos", "+", "self", ".", "slope", "*", "neg", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.MaskedCrossEntropy.__init__": [[351, 359], ["int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "label_smoothing_discount", ",", "int_dtype", ",", "float_dtype", ",", "time_major", ",", "name", "=", "None", ")", ":", "\n", "# Set attributes", "\n", "        ", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "label_smoothing_discount", "=", "label_smoothing_discount", "\n", "self", ".", "int_dtype", "=", "int_dtype", "\n", "self", ".", "float_dtype", "=", "float_dtype", "\n", "self", ".", "time_dim", "=", "int", "(", "not", "time_major", ")", "# i.e. 0 is time_major, 1 if batch_major", "\n", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.MaskedCrossEntropy._get_smoothing_parameters": [[360, 372], ["tensorflow.cast", "tensorflow.math.log", "tensorflow.math.log"], "methods", ["None"], ["", "def", "_get_smoothing_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\" Calculates the confidence values used for label smoothing application. \"\"\"", "\n", "# Assign low confidence, i.e. the label smoothing discount value, to all non-true labels", "\n", "one_out_vocab", "=", "tf", ".", "cast", "(", "self", ".", "vocab_size", "-", "1", ",", "self", ".", "float_dtype", ")", "\n", "# For cross-entropy, each row of the labels matrix must be a valid probability distribution", "\n", "low_confidence", "=", "self", ".", "label_smoothing_discount", "/", "one_out_vocab", "\n", "high_confidence", "=", "1.0", "-", "self", ".", "label_smoothing_discount", "\n", "# Normalizing constant for better readability, which is the best cross-entropy value with soft targets", "\n", "# Has no impact on training", "\n", "normalizing_factor", "=", "-", "(", "1.0", "*", "high_confidence", "*", "tf", ".", "math", ".", "log", "(", "high_confidence", ")", "\n", "+", "one_out_vocab", "*", "low_confidence", "*", "tf", ".", "math", ".", "log", "(", "low_confidence", "+", "1e-20", ")", ")", "\n", "return", "high_confidence", ",", "low_confidence", ",", "normalizing_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.MaskedCrossEntropy.forward": [[373, 437], ["tensorflow.compat.v1.name_scope", "tensorflow.cond", "tensorflow.shape", "tensorflow.shape", "tensorflow.cond", "tensorflow.one_hot", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.math.divide", "tensorflow.reduce_mean", "transformer_layers.MaskedCrossEntropy.forward._get_pad_shape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ",", "target_mask", ",", "training", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "name", ",", "values", "=", "[", "logits", ",", "targets", ",", "target_mask", "]", ")", ":", "\n", "# Get smoothing parameters (no smoothing/ normalization at test time)", "\n", "            ", "high_confidence", ",", "low_confidence", ",", "normalizing_factor", "=", "tf", ".", "cond", "(", "pred", "=", "tf", ".", "logical_and", "(", "training", ",", "tf", ".", "greater", "(", "self", ".", "label_smoothing_discount", ",", "0.0", ")", ")", ",", "\n", "true_fn", "=", "self", ".", "_get_smoothing_parameters", ",", "\n", "false_fn", "=", "lambda", ":", "(", "1.0", ",", "0.0", ",", "0.0", ")", ")", "\n", "\n", "# If necessary, pad the label and the label-mask to match the length of decoder output", "\n", "# Not sure if that's a sensible thing to do", "\n", "targets_shape", "=", "tf", ".", "shape", "(", "input", "=", "targets", ")", "\n", "logits_shape", "=", "tf", ".", "shape", "(", "input", "=", "logits", ")", "\n", "targets_length", "=", "targets_shape", "[", "self", ".", "time_dim", "]", "\n", "logits_length", "=", "logits_shape", "[", "self", ".", "time_dim", "]", "\n", "\n", "def", "_get_pad_shape", "(", "shape_to_pad", ",", "shape_to_match", ")", ":", "\n", "                ", "\"\"\" Calculates the shape of the padding to be applied to the logits or targets. \"\"\"", "\n", "time_steps_to_pad", "=", "shape_to_match", "[", "self", ".", "time_dim", "]", "-", "shape_to_pad", "[", "self", ".", "time_dim", "]", "\n", "if", "self", ".", "time_dim", "==", "0", ":", "\n", "                    ", "pad_shape", "=", "[", "time_steps_to_pad", ",", "shape_to_pad", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "                    ", "pad_shape", "=", "[", "shape_to_pad", "[", "0", "]", ",", "time_steps_to_pad", "]", "\n", "", "return", "pad_shape", "\n", "\n", "", "def", "_pad_targets", "(", "targets", ",", "target_mask", ",", "logits", ")", ":", "\n", "                ", "\"\"\" Pads the targets to match the size of the model-generated logits. \"\"\"", "\n", "pad_shape", "=", "_get_pad_shape", "(", "targets_shape", ",", "logits_shape", ")", "\n", "targets", "=", "tf", ".", "concat", "(", "[", "targets", ",", "tf", ".", "zeros", "(", "pad_shape", ",", "dtype", "=", "self", ".", "int_dtype", ")", "]", ",", "axis", "=", "self", ".", "time_dim", ")", "\n", "target_mask", "=", "tf", ".", "concat", "(", "[", "target_mask", ",", "tf", ".", "zeros", "(", "pad_shape", ",", "dtype", "=", "self", ".", "float_dtype", ")", "]", ",", "axis", "=", "self", ".", "time_dim", ")", "\n", "return", "targets", ",", "target_mask", ",", "logits", "\n", "\n", "", "def", "_pad_logits", "(", "targets", ",", "target_mask", ",", "logits", ")", ":", "\n", "                ", "\"\"\" Pads the logits to match the size of the ground-truth targets. \"\"\"", "\n", "pad_shape", "=", "_get_pad_shape", "(", "logits_shape", ",", "targets_shape", ")", "\n", "logits", "=", "tf", ".", "concat", "(", "[", "logits", ",", "tf", ".", "zeros", "(", "pad_shape", "+", "[", "logits_shape", "[", "-", "1", "]", "]", ",", "dtype", "=", "self", ".", "float_dtype", ")", "]", ",", "\n", "axis", "=", "self", ".", "time_dim", ")", "\n", "return", "targets", ",", "target_mask", ",", "logits", "\n", "\n", "# For teacher-forcing with RNN models", "\n", "", "targets", ",", "target_mask", ",", "logits", "=", "tf", ".", "cond", "(", "pred", "=", "tf", ".", "equal", "(", "targets_length", ",", "logits_length", ")", ",", "\n", "true_fn", "=", "lambda", ":", "(", "targets", ",", "target_mask", ",", "logits", ")", ",", "\n", "false_fn", "=", "lambda", ":", "tf", ".", "cond", "(", "pred", "=", "tf", ".", "less", "(", "targets_length", ",", "logits_length", ")", ",", "\n", "true_fn", "=", "lambda", ":", "_pad_targets", "(", "targets", ",", "target_mask", ",", "logits", ")", ",", "\n", "false_fn", "=", "lambda", ":", "_pad_logits", "(", "targets", ",", "target_mask", ",", "logits", ")", ")", ")", "\n", "\n", "# Project and optionally smooth target token ids", "\n", "projected_targets", "=", "tf", ".", "one_hot", "(", "targets", ",", "\n", "depth", "=", "self", ".", "vocab_size", ",", "\n", "on_value", "=", "high_confidence", ",", "\n", "off_value", "=", "low_confidence", ",", "\n", "dtype", "=", "self", ".", "float_dtype", ")", "\n", "\n", "# Compute token-level loss", "\n", "flat_logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", ",", "self", ".", "vocab_size", "]", ")", "\n", "flat_targets", "=", "tf", ".", "reshape", "(", "projected_targets", ",", "[", "-", "1", ",", "self", ".", "vocab_size", "]", ")", "\n", "flat_loss", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "logits", "=", "flat_logits", ",", "labels", "=", "tf", ".", "stop_gradient", "(", "flat_targets", ")", ")", "\n", "flat_normalized_loss", "=", "flat_loss", "-", "normalizing_factor", "\n", "# Compute sentence- and batch-level losses (i.e. mean token-loss per sentence/ batch)", "\n", "normalized_loss", "=", "tf", ".", "reshape", "(", "flat_normalized_loss", ",", "tf", ".", "shape", "(", "input", "=", "targets", ")", ")", "\n", "masked_loss", "=", "normalized_loss", "*", "target_mask", "\n", "sentence_lengths", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "target_mask", ",", "axis", "=", "self", ".", "time_dim", ",", "keepdims", "=", "False", ")", "\n", "sentence_loss", "=", "tf", ".", "math", ".", "divide", "(", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "masked_loss", ",", "axis", "=", "self", ".", "time_dim", ",", "keepdims", "=", "False", ")", ",", "sentence_lengths", ")", "\n", "batch_loss", "=", "tf", ".", "reduce_mean", "(", "input_tensor", "=", "sentence_loss", ",", "keepdims", "=", "False", ")", "\n", "", "return", "masked_loss", ",", "sentence_loss", ",", "batch_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.matmul_nd": [[21, 33], ["tf_utils.get_shape_list", "tf_utils.get_shape_list", "tensorflow.reduce_prod", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "def", "matmul_nd", "(", "nd_tensor", ",", "matrix", ")", ":", "\n", "    ", "\"\"\" Performs matrix multiplication for n-dimensional inputs. \"\"\"", "\n", "tensor_shape", "=", "tf_utils", ".", "get_shape_list", "(", "nd_tensor", ")", "\n", "matrix_shape", "=", "tf_utils", ".", "get_shape_list", "(", "matrix", ")", "\n", "\n", "initial_tensor_dims", "=", "tensor_shape", "[", ":", "-", "1", "]", "\n", "flat_first_dim", "=", "tf", ".", "reduce_prod", "(", "input_tensor", "=", "initial_tensor_dims", ")", "\n", "\n", "tensor_2d", "=", "tf", ".", "reshape", "(", "nd_tensor", ",", "[", "flat_first_dim", ",", "tensor_shape", "[", "-", "1", "]", "]", ")", "\n", "result_2d", "=", "tf", ".", "matmul", "(", "tensor_2d", ",", "matrix", ")", "\n", "result_3d", "=", "tf", ".", "reshape", "(", "result_2d", ",", "initial_tensor_dims", "+", "[", "matrix_shape", "[", "-", "1", "]", "]", ")", "\n", "return", "result_3d", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.get_right_context_mask": [[35, 45], ["tensorflow.linalg.band_part", "tensorflow.expand_dims", "tensorflow.ones", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "get_right_context_mask", "(", "time_steps", ")", ":", "\n", "    ", "\"\"\" Generates the mask preventing the decoder from attending to unseen positions. \"\"\"", "\n", "# Generate mask that limits decoder self-attention up to and including the current position", "\n", "attn_mask", "=", "tf", ".", "linalg", ".", "band_part", "(", "tf", ".", "ones", "(", "[", "time_steps", ",", "time_steps", "]", ")", ",", "-", "1", ",", "0", ")", "\n", "# Expand mask to 4d. so as to be compatible with attention weights", "\n", "attn_mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "attn_mask", ",", "0", ")", ",", "0", ")", "\n", "# Illegal connections will be set to -inf when fed into the softmax function", "\n", "# Padding for non-masked positions is applied to prevent NaNs", "\n", "attn_mask", "=", "-", "1e9", "*", "(", "1.0", "-", "attn_mask", ")", "\n", "return", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.get_positional_signal": [[47, 71], ["tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.concat", "tensorflow.reshape", "tensorflow.math.log", "tensorflow.exp", "tensorflow.range", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.pad", "tensorflow.cast", "tensorflow.sin", "tensorflow.cos", "tensorflow.range"], "function", ["None"], ["", "def", "get_positional_signal", "(", "time_steps", ",", "depth", ",", "float_dtype", ",", "min_timescale", "=", "1", ",", "max_timescale", "=", "10000", ")", ":", "\n", "    ", "\"\"\" Generates a series of sinusoid functions capable of expressing the relative and absolute position\n    of a token within a longer sequence. \"\"\"", "\n", "# Convert to floats", "\n", "min_timescale", "=", "tf", ".", "cast", "(", "min_timescale", ",", "float_dtype", ")", "\n", "max_timescale", "=", "tf", ".", "cast", "(", "max_timescale", ",", "float_dtype", ")", "\n", "# Obtain timing signal via sinusoids", "\n", "num_timescales", "=", "tf", ".", "cast", "(", "depth", "//", "2", ",", "float_dtype", ")", "\n", "log_timescale_increment", "=", "tf", ".", "math", ".", "log", "(", "max_timescale", "/", "min_timescale", ")", "/", "(", "num_timescales", "-", "tf", ".", "cast", "(", "1.0", ",", "float_dtype", ")", ")", "\n", "# Introduce an offset between individual timescales to obtain different frequencies", "\n", "incremented_timescales", "=", "min_timescale", "*", "tf", ".", "exp", "(", "tf", ".", "range", "(", "num_timescales", ",", "dtype", "=", "float_dtype", ")", "*", "-", "log_timescale_increment", ")", "\n", "# Assign the designated number of time-scales per token position", "\n", "positions", "=", "tf", ".", "cast", "(", "tf", ".", "range", "(", "time_steps", ")", ",", "float_dtype", ")", "\n", "scaled_time", "=", "tf", ".", "expand_dims", "(", "positions", ",", "1", ")", "*", "tf", ".", "expand_dims", "(", "incremented_timescales", ",", "0", ")", "\n", "positional_signal", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "scaled_time", ")", ",", "tf", ".", "cos", "(", "scaled_time", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# Pad the signal tensor, if needed", "\n", "pad_size", "=", "depth", "%", "2", "\n", "if", "pad_size", "!=", "0", ":", "\n", "        ", "tf", ".", "pad", "(", "tensor", "=", "positional_signal", ",", "paddings", "=", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "pad_size", "]", "]", ")", "\n", "# Reshape the signal to make it compatible with the target tensor", "\n", "", "positional_signal", "=", "tf", ".", "reshape", "(", "positional_signal", ",", "[", "1", ",", "time_steps", ",", "depth", "]", ")", "\n", "return", "positional_signal", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translation.__init__": [[29, 35], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "source_words", ",", "target_words", ",", "sentence_id", "=", "None", ",", "score", "=", "0", ",", "hypothesis_id", "=", "None", ")", ":", "\n", "        ", "self", ".", "source_words", "=", "source_words", "\n", "self", ".", "target_words", "=", "target_words", "\n", "self", ".", "sentence_id", "=", "sentence_id", "\n", "self", ".", "score", "=", "score", "\n", "self", ".", "hypothesis_id", "=", "hypothesis_id", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.QueueItem.__init__": [[41, 43], ["server_translator.QueueItem.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater.update"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.__init__": [[46, 62], ["collections.defaultdict", "server_translator.Translator._load_model_options", "server_translator.Translator._init_queues", "server_translator.Translator._init_processes"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._load_model_options", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._init_queues", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._init_processes"], ["    ", "def", "__init__", "(", "self", ",", "settings", ")", ":", "\n", "        ", "\"\"\"\n        Loads translation models.\n        \"\"\"", "\n", "self", ".", "_models", "=", "settings", ".", "models", "\n", "self", ".", "_num_processes", "=", "settings", ".", "num_processes", "\n", "self", ".", "_verbose", "=", "settings", ".", "verbose", "\n", "self", ".", "_retrieved_translations", "=", "defaultdict", "(", "dict", ")", "\n", "self", ".", "_batch_size", "=", "settings", ".", "minibatch_size", "\n", "\n", "# load model options", "\n", "self", ".", "_load_model_options", "(", ")", "\n", "# set up queues", "\n", "self", ".", "_init_queues", "(", ")", "\n", "# init worker processes", "\n", "self", ".", "_init_processes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._load_model_options": [[63, 75], ["util.load_dictionaries", "config.load_config_from_json_file.load_config_from_json_file", "setattr", "server_translator.Translator._options.append"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dictionaries", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.load_config_from_json_file"], ["", "def", "_load_model_options", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Loads config options for each model.\n        \"\"\"", "\n", "\n", "self", ".", "_options", "=", "[", "]", "\n", "for", "model", "in", "self", ".", "_models", ":", "\n", "            ", "config", "=", "load_config_from_json_file", "(", "model", ")", "\n", "setattr", "(", "config", ",", "'reload'", ",", "model", ")", "\n", "self", ".", "_options", ".", "append", "(", "config", ")", "\n", "\n", "", "_", ",", "_", ",", "_", ",", "self", ".", "_num_to_target", "=", "util", ".", "load_dictionaries", "(", "self", ".", "_options", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._init_queues": [[76, 82], ["multiprocessing.Queue", "multiprocessing.Queue"], "methods", ["None"], ["", "def", "_init_queues", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Sets up shared queues for inter-process communication.\n        \"\"\"", "\n", "self", ".", "_input_queue", "=", "Queue", "(", ")", "\n", "self", ".", "_output_queue", "=", "Queue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.shutdown": [[83, 90], ["server_translator.Translator._input_queue.put"], "methods", ["None"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Executed from parent process to terminate workers,\n        method: \"poison pill\".\n        \"\"\"", "\n", "for", "process", "in", "self", ".", "_processes", ":", "\n", "            ", "self", ".", "_input_queue", ".", "put", "(", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._init_processes": [[91, 104], ["range", "multiprocessing.Process", "processes[].start"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer.start"], ["", "", "def", "_init_processes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Starts child (worker) processes.\n        \"\"\"", "\n", "processes", "=", "[", "None", "]", "*", "self", ".", "_num_processes", "\n", "for", "process_id", "in", "range", "(", "self", ".", "_num_processes", ")", ":", "\n", "            ", "processes", "[", "process_id", "]", "=", "Process", "(", "\n", "target", "=", "self", ".", "_start_worker", ",", "\n", "args", "=", "(", "process_id", ",", ")", "\n", ")", "\n", "processes", "[", "process_id", "]", ".", "start", "(", ")", "\n", "\n", "", "self", ".", "_processes", "=", "processes", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._load_models": [[110, 130], ["logging.debug", "enumerate", "logging.info", "tf.compat.v1.variable_scope", "model_loader.init_or_restore_variables", "models.append", "transformer.Transformer", "rnn_model.RNNModel"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader.init_or_restore_variables"], ["", "def", "_load_models", "(", "self", ",", "process_id", ",", "sess", ")", ":", "\n", "        ", "\"\"\"\n        Loads models and returns them\n        \"\"\"", "\n", "logging", ".", "debug", "(", "\"Process '%s' - Loading models\\n\"", "%", "(", "process_id", ")", ")", "\n", "\n", "import", "tensorflow", "as", "tf", "\n", "models", "=", "[", "]", "\n", "for", "i", ",", "options", "in", "enumerate", "(", "self", ".", "_options", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"model%d\"", "%", "i", ")", "as", "scope", ":", "\n", "                ", "if", "options", ".", "model_type", "==", "\"transformer\"", ":", "\n", "                    ", "model", "=", "TransformerModel", "(", "options", ")", "\n", "", "else", ":", "\n", "                    ", "model", "=", "rnn_model", ".", "RNNModel", "(", "options", ")", "\n", "", "saver", "=", "model_loader", ".", "init_or_restore_variables", "(", "\n", "options", ",", "sess", ",", "ensemble_scope", "=", "scope", ")", "\n", "models", ".", "append", "(", "model", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"NOTE: Length of translations is capped to {}\"", ".", "format", "(", "self", ".", "_options", "[", "0", "]", ".", "translation_maxlen", ")", ")", "\n", "return", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._start_worker": [[131, 170], ["tf.compat.v1.ConfigProto", "tf.compat.v1.Session", "server_translator.Translator._load_models", "server_translator.Translator._input_queue.get", "server_translator.Translator._translate", "server_translator.Translator._output_queue.put", "beam_search_sampler.BeamSearchSampler"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._load_models", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._translate"], ["", "def", "_start_worker", "(", "self", ",", "process_id", ")", ":", "\n", "        ", "\"\"\"\n        Function executed by each worker once started. Do not execute in\n        the parent process.\n        \"\"\"", "\n", "\n", "# load TF functionality", "\n", "import", "tensorflow", "as", "tf", "\n", "tf_config", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", ")", "\n", "tf_config", ".", "allow_soft_placement", "=", "True", "\n", "sess", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "config", "=", "tf_config", ")", "\n", "models", "=", "self", ".", "_load_models", "(", "process_id", ",", "sess", ")", "\n", "\n", "samplers", "=", "{", "}", "\n", "\n", "def", "get_sampler", "(", "beam_size", ")", ":", "\n", "# FIXME In practice, the beam size is probably the same for all", "\n", "# input items, but if it gets changed a lot, then constructing a", "\n", "# new beam search graph for each combination isn't great. Can it", "\n", "# be turned into a placeholder?", "\n", "            ", "if", "beam_size", "not", "in", "samplers", ":", "\n", "                ", "samplers", "[", "beam_size", "]", "=", "BeamSearchSampler", "(", "models", ",", "self", ".", "_options", ",", "\n", "beam_size", ")", "\n", "", "return", "samplers", "[", "beam_size", "]", "\n", "\n", "# listen to queue in while loop, translate items", "\n", "", "while", "True", ":", "\n", "            ", "input_item", "=", "self", ".", "_input_queue", ".", "get", "(", ")", "\n", "\n", "if", "input_item", "is", "None", ":", "\n", "                ", "break", "\n", "", "idx", "=", "input_item", ".", "idx", "\n", "request_id", "=", "input_item", ".", "request_id", "\n", "\n", "output_item", "=", "self", ".", "_translate", "(", "process_id", ",", "input_item", ",", "get_sampler", ",", "\n", "sess", ")", "\n", "self", ".", "_output_queue", ".", "put", "(", "(", "request_id", ",", "idx", ",", "output_item", ")", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._translate": [[171, 196], ["numpy.zeros", "util.prepare_data", "translate_utils.translate_batch", "server_translator.Translator._start_worker.get_sampler", "len"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.prepare_data", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch"], ["", "def", "_translate", "(", "self", ",", "process_id", ",", "input_item", ",", "get_sampler", ",", "sess", ")", ":", "\n", "        ", "\"\"\"\n        Actual translation (model sampling).\n        \"\"\"", "\n", "\n", "# unpack input item attributes", "\n", "k", "=", "input_item", ".", "k", "\n", "x", "=", "input_item", ".", "batch", "\n", "alpha", "=", "input_item", ".", "normalization_alpha", "\n", "#max_ratio = input_item.max_ratio", "\n", "\n", "y_dummy", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "len", "(", "x", ")", ",", "1", ")", ")", "\n", "x", ",", "x_mask", ",", "_", ",", "_", "=", "util", ".", "prepare_data", "(", "x", ",", "y_dummy", ",", "\n", "self", ".", "_options", "[", "0", "]", ".", "factors", ",", "\n", "maxlen", "=", "None", ")", "\n", "\n", "sample", "=", "translate_utils", ".", "translate_batch", "(", "\n", "session", "=", "sess", ",", "\n", "sampler", "=", "get_sampler", "(", "k", ")", ",", "\n", "x", "=", "x", ",", "\n", "x_mask", "=", "x_mask", ",", "\n", "max_translation_len", "=", "self", ".", "_options", "[", "0", "]", ".", "translation_maxlen", ",", "\n", "normalization_alpha", "=", "alpha", ")", "\n", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._send_jobs": [[200, 227], ["enumerate", "util.read_all_lines", "server_translator.QueueItem", "server_translator.Translator._input_queue.put", "source_batches.append", "logging.error", "sys.exit", "process.terminate"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.read_all_lines"], ["", "def", "_send_jobs", "(", "self", ",", "input_", ",", "translation_settings", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "source_batches", "=", "[", "]", "\n", "\n", "try", ":", "\n", "            ", "batches", ",", "idxs", "=", "util", ".", "read_all_lines", "(", "self", ".", "_options", "[", "0", "]", ",", "input_", ",", "\n", "self", ".", "_batch_size", ")", "\n", "", "except", "exception", ".", "Error", "as", "x", ":", "\n", "            ", "logging", ".", "error", "(", "x", ".", "msg", ")", "\n", "for", "process", "in", "self", ".", "_processes", ":", "\n", "                ", "process", ".", "terminate", "(", ")", "\n", "", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "for", "idx", ",", "batch", "in", "enumerate", "(", "batches", ")", ":", "\n", "\n", "            ", "input_item", "=", "QueueItem", "(", "verbose", "=", "self", ".", "_verbose", ",", "\n", "k", "=", "translation_settings", ".", "beam_size", ",", "\n", "normalization_alpha", "=", "translation_settings", ".", "normalization_alpha", ",", "\n", "nbest", "=", "translation_settings", ".", "n_best", ",", "\n", "batch", "=", "batch", ",", "\n", "idx", "=", "idx", ",", "\n", "request_id", "=", "translation_settings", ".", "request_id", ")", "\n", "\n", "self", ".", "_input_queue", ".", "put", "(", "input_item", ")", "\n", "source_batches", ".", "append", "(", "batch", ")", "\n", "", "return", "idx", "+", "1", ",", "source_batches", ",", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._retrieve_jobs": [[228, 256], ["range", "len", "server_translator.Translator._output_queue.get", "range", "server_translator.Translator._input_queue.cancel_join_thread", "server_translator.Translator._output_queue.cancel_join_thread", "range", "logging.error", "sys.exit", "server_translator.Translator._processes[].is_alive", "server_translator.Translator._processes[].terminate"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get"], ["", "def", "_retrieve_jobs", "(", "self", ",", "num_samples", ",", "request_id", ",", "timeout", "=", "5", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "while", "len", "(", "self", ".", "_retrieved_translations", "[", "request_id", "]", ")", "<", "num_samples", ":", "\n", "            ", "resp", "=", "None", "\n", "while", "resp", "is", "None", ":", "\n", "                ", "try", ":", "\n", "                    ", "resp", "=", "self", ".", "_output_queue", ".", "get", "(", "True", ",", "timeout", ")", "\n", "# if queue is empty after 5s, check if processes are still alive", "\n", "", "except", "Empty", ":", "\n", "                    ", "for", "midx", "in", "range", "(", "self", ".", "_num_processes", ")", ":", "\n", "                        ", "if", "not", "self", ".", "_processes", "[", "midx", "]", ".", "is_alive", "(", ")", "and", "self", ".", "_processes", "[", "midx", "]", ".", "exitcode", "!=", "0", ":", "\n", "# kill all other processes and raise exception if one dies", "\n", "                            ", "self", ".", "_input_queue", ".", "cancel_join_thread", "(", ")", "\n", "self", ".", "_output_queue", ".", "cancel_join_thread", "(", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "_num_processes", ")", ":", "\n", "                                ", "self", ".", "_processes", "[", "idx", "]", ".", "terminate", "(", ")", "\n", "", "logging", ".", "error", "(", "\"Translate worker process {0} crashed with exitcode {1}\"", ".", "format", "(", "self", ".", "_processes", "[", "midx", "]", ".", "pid", ",", "self", ".", "_processes", "[", "midx", "]", ".", "exitcode", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "", "", "", "request_id", ",", "idx", ",", "output_item", "=", "resp", "\n", "self", ".", "_retrieved_translations", "[", "request_id", "]", "[", "idx", "]", "=", "output_item", "\n", "#print self._retrieved_translations", "\n", "\n", "", "for", "idx", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "yield", "self", ".", "_retrieved_translations", "[", "request_id", "]", "[", "idx", "]", "\n", "\n", "# then remove all entries with this request ID from the dictionary", "\n", "", "del", "self", ".", "_retrieved_translations", "[", "request_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.translate": [[259, 307], ["logging.info", "time.time", "server_translator.Translator._send_jobs", "enumerate", "numpy.array", "enumerate", "logging.info", "server_translator.Translator._retrieve_jobs", "list", "len", "logging.info", "time.time", "len", "idxs.argsort", "enumerate", "translations.append", "util.seq2words", "server_translator.Translation", "translations.append", "util.seq2words", "server_translator.Translation", "n_best_list.append"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._send_jobs", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator._retrieve_jobs", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words"], ["", "def", "translate", "(", "self", ",", "source_segments", ",", "translation_settings", ")", ":", "\n", "        ", "\"\"\"\n        Returns the translation of @param source_segments.\n        \"\"\"", "\n", "\n", "logging", ".", "info", "(", "'Translating {0} segments...\\n'", ".", "format", "(", "len", "(", "source_segments", ")", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "n_batches", ",", "source_batches", ",", "idxs", "=", "self", ".", "_send_jobs", "(", "source_segments", ",", "translation_settings", ")", "\n", "\n", "n_sent", "=", "0", "\n", "outputs", "=", "[", "None", "]", "*", "n_batches", "\n", "for", "i", ",", "samples", "in", "enumerate", "(", "self", ".", "_retrieve_jobs", "(", "n_batches", ",", "translation_settings", ".", "request_id", ")", ")", ":", "\n", "            ", "outputs", "[", "i", "]", "=", "list", "(", "samples", ")", "\n", "n_sent", "+=", "len", "(", "samples", ")", "\n", "logging", ".", "info", "(", "'Translated {} sents'", ".", "format", "(", "n_sent", ")", ")", "\n", "\n", "", "outputs", "=", "[", "beam", "for", "batch", "in", "outputs", "for", "beam", "in", "batch", "]", "\n", "outputs", "=", "numpy", ".", "array", "(", "outputs", ",", "dtype", "=", "numpy", ".", "object", ")", "\n", "outputs", "=", "outputs", "[", "idxs", ".", "argsort", "(", ")", "]", "\n", "\n", "translations", "=", "[", "]", "\n", "for", "i", ",", "beam", "in", "enumerate", "(", "outputs", ")", ":", "\n", "            ", "if", "translation_settings", ".", "n_best", "is", "True", ":", "\n", "                ", "n_best_list", "=", "[", "]", "\n", "for", "j", ",", "(", "sent", ",", "cost", ")", "in", "enumerate", "(", "beam", ")", ":", "\n", "                    ", "target_words", "=", "util", ".", "seq2words", "(", "sent", ",", "self", ".", "_num_to_target", ",", "\n", "join", "=", "False", ")", "\n", "translation", "=", "Translation", "(", "sentence_id", "=", "i", ",", "\n", "source_words", "=", "source_segments", "[", "i", "]", ",", "\n", "target_words", "=", "target_words", ",", "\n", "score", "=", "cost", ",", "\n", "hypothesis_id", "=", "j", ")", "\n", "n_best_list", ".", "append", "(", "translation", ")", "\n", "", "translations", ".", "append", "(", "n_best_list", ")", "\n", "", "else", ":", "\n", "                ", "best_hypo", ",", "cost", "=", "beam", "[", "0", "]", "\n", "target_words", "=", "util", ".", "seq2words", "(", "best_hypo", ",", "self", ".", "_num_to_target", ",", "\n", "join", "=", "False", ")", "\n", "translation", "=", "Translation", "(", "sentence_id", "=", "i", ",", "\n", "source_words", "=", "source_segments", "[", "i", "]", ",", "\n", "target_words", "=", "target_words", ",", "\n", "score", "=", "cost", ")", "\n", "translations", ".", "append", "(", "translation", ")", "\n", "\n", "", "", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "logging", ".", "info", "(", "'Translated {} sents in {} sec. Speed {} sents/sec'", ".", "format", "(", "n_sent", ",", "duration", ",", "n_sent", "/", "duration", ")", ")", "\n", "\n", "return", "translations", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.translate_file": [[308, 313], ["input_object.readlines", "server_translator.Translator.translate"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.translate"], ["", "def", "translate_file", "(", "self", ",", "input_object", ",", "translation_settings", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "source_segments", "=", "input_object", ".", "readlines", "(", ")", "\n", "return", "self", ".", "translate", "(", "source_segments", ",", "translation_settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.translate_string": [[315, 323], ["server_translator.Translator.translate", "segment.endswith"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.translate"], ["", "def", "translate_string", "(", "self", ",", "segment", ",", "translation_settings", ")", ":", "\n", "        ", "\"\"\"\n        Translates a single segment\n        \"\"\"", "\n", "if", "not", "segment", ".", "endswith", "(", "'\\n'", ")", ":", "\n", "            ", "segment", "+=", "'\\n'", "\n", "", "source_segments", "=", "[", "segment", "]", "\n", "return", "self", ".", "translate", "(", "source_segments", ",", "translation_settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.translate_list": [[324, 330], ["server_translator.Translator.translate", "s.endswith"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.translate"], ["", "def", "translate_list", "(", "self", ",", "segments", ",", "translation_settings", ")", ":", "\n", "        ", "\"\"\"\n        Translates a list of segments\n        \"\"\"", "\n", "source_segments", "=", "[", "s", "+", "'\\n'", "if", "not", "s", ".", "endswith", "(", "'\\n'", ")", "else", "s", "for", "s", "in", "segments", "]", "\n", "return", "self", ".", "translate", "(", "source_segments", ",", "translation_settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.write_translation": [[333, 353], ["output_items.append", "output_items.append", "output_items.append", "output_file.write", "output_file.write", "str", "str"], "methods", ["None"], ["", "def", "write_translation", "(", "self", ",", "output_file", ",", "translation", ",", "translation_settings", ")", ":", "\n", "        ", "\"\"\"\n        Writes a single translation to a file or STDOUT.\n        \"\"\"", "\n", "output_items", "=", "[", "]", "\n", "# sentence ID only for nbest", "\n", "if", "translation_settings", ".", "n_best", "is", "True", ":", "\n", "            ", "output_items", ".", "append", "(", "str", "(", "translation", ".", "sentence_id", ")", ")", "\n", "\n", "# translations themselves", "\n", "", "output_items", ".", "append", "(", "\" \"", ".", "join", "(", "translation", ".", "target_words", ")", ")", "\n", "\n", "# write scores for nbest?", "\n", "if", "translation_settings", ".", "n_best", "is", "True", ":", "\n", "            ", "output_items", ".", "append", "(", "str", "(", "translation", ".", "score", ")", ")", "\n", "\n", "", "if", "translation_settings", ".", "n_best", "is", "True", ":", "\n", "            ", "output_file", ".", "write", "(", "\" ||| \"", ".", "join", "(", "output_items", ")", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "            ", "output_file", ".", "write", "(", "\"\\n\"", ".", "join", "(", "output_items", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.write_translations": [[355, 366], ["server_translator.Translator.write_translation", "server_translator.Translator.write_translation"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.write_translation", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.write_translation"], ["", "", "def", "write_translations", "(", "self", ",", "output_file", ",", "translations", ",", "translation_settings", ")", ":", "\n", "        ", "\"\"\"\n        Writes translations to a file or STDOUT.\n        \"\"\"", "\n", "if", "translation_settings", ".", "n_best", "is", "True", ":", "\n", "            ", "for", "nbest_list", "in", "translations", ":", "\n", "                ", "for", "translation", "in", "nbest_list", ":", "\n", "                    ", "self", ".", "write_translation", "(", "output_file", ",", "translation", ",", "translation_settings", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "translation", "in", "translations", ":", "\n", "                ", "self", ".", "write_translation", "(", "output_file", ",", "translation", ",", "translation_settings", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler.BeamSearchSampler.__init__": [[51, 100], ["tensorflow.compat.v1.name_scope", "sampler_inputs.SamplerInputs", "enumerate", "beam_search_sampler._beam_search", "zip", "len", "exception.Error", "tensorflow.compat.v1.name_scope", "model_adapters.append", "set", "transformer_inference.ModelAdapter", "rnn_inference.ModelAdapter"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._beam_search"], ["def", "__init__", "(", "self", ",", "models", ",", "configs", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\"Sets some things up then calls _beam_search() to do the real work.\n\n        Args:\n            models: a sequence of RNN or Transformer objects.\n            configs: a sequence of model configs (argparse.Namespace objects).\n            beam_size: an integer specifying the beam width.\n        \"\"\"", "\n", "self", ".", "_models", "=", "models", "\n", "self", ".", "_configs", "=", "configs", "\n", "self", ".", "_beam_size", "=", "beam_size", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "'beam_search'", ")", ":", "\n", "\n", "# Define placeholders.", "\n", "            ", "self", ".", "inputs", "=", "sampler_inputs", ".", "SamplerInputs", "(", ")", "\n", "\n", "# Create model adapters to get a consistent interface to", "\n", "# Transformer and RNN models.", "\n", "model_adapters", "=", "[", "]", "\n", "for", "i", ",", "(", "model", ",", "config", ")", "in", "enumerate", "(", "zip", "(", "models", ",", "configs", ")", ")", ":", "\n", "                ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "'model_adapter_{}'", ".", "format", "(", "i", ")", ")", "as", "scope", ":", "\n", "                    ", "if", "config", ".", "model_type", "==", "'transformer'", ":", "\n", "                        ", "adapter", "=", "transformer_inference", ".", "ModelAdapter", "(", "\n", "model", ",", "config", ",", "scope", ")", "\n", "", "else", ":", "\n", "                        ", "assert", "config", ".", "model_type", "==", "'rnn'", "\n", "adapter", "=", "rnn_inference", ".", "ModelAdapter", "(", "\n", "model", ",", "config", ",", "scope", ")", "\n", "", "model_adapters", ".", "append", "(", "adapter", ")", "\n", "\n", "# Check that individual models are compatible with each other.", "\n", "", "", "vocab_sizes", "=", "[", "a", ".", "target_vocab_size", "for", "a", "in", "model_adapters", "]", "\n", "if", "len", "(", "set", "(", "vocab_sizes", ")", ")", ">", "1", ":", "\n", "                ", "raise", "exception", ".", "Error", "(", "'Cannot ensemble models with different '", "\n", "'target vocabulary sizes'", ")", "\n", "", "target_vocab_size", "=", "vocab_sizes", "[", "0", "]", "\n", "\n", "# Build the graph to do the actual work.", "\n", "sequences", ",", "scores", "=", "_beam_search", "(", "\n", "model_adapters", "=", "model_adapters", ",", "\n", "beam_size", "=", "beam_size", ",", "\n", "batch_size_x", "=", "self", ".", "inputs", ".", "batch_size_x", ",", "\n", "max_translation_len", "=", "self", ".", "inputs", ".", "max_translation_len", ",", "\n", "normalization_alpha", "=", "self", ".", "inputs", ".", "normalization_alpha", ",", "\n", "vocab_size", "=", "target_vocab_size", ",", "\n", "eos_id", "=", "0", ")", "\n", "\n", "self", ".", "_outputs", "=", "sequences", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler.BeamSearchSampler.outputs": [[101, 104], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "outputs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler.BeamSearchSampler.models": [[105, 108], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "models", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_models", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler.BeamSearchSampler.configs": [[109, 112], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "configs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_configs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler.BeamSearchSampler.beam_size": [[113, 116], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "beam_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._beam_search": [[118, 237], ["tensorflow.constant", "tensorflow.ones", "tensorflow.ones", "tensorflow.zeros", "tensorflow.fill", "tensorflow.fill", "beam_search_sampler._generate_while_loop_cond_func", "beam_search_sampler._generate_while_loop_body_func", "tensorflow.nest.map_structure", "tf.ones.set_shape", "tf.compat.v1.where.set_shape", "tensorflow.compat.v1.where", "tensorflow.compat.v1.where", "tensorflow.range", "tensorflow.reshape", "tensorflow.tile", "tensorflow.reshape", "tensorflow.tile", "tensorflow.compat.v1.where", "tensorflow.reduce_min", "tensorflow.cast", "adapter.encode", "adapter.generate_decoding_function", "decoding_functions.append", "ma.generate_initial_memories", "tensorflow.TensorShape", "tensorflow.TensorShape", "tf.zeros.get_shape", "tensorflow.TensorShape", "tf.compat.v1.where.get_shape", "tf.fill.get_shape", "tensorflow.while_loop", "tensorflow.reduce_any", "tensorflow.reduce_any", "tensorflow.shape", "tensorflow.equal", "adapter.get_memory_invariants", "zip"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._generate_while_loop_cond_func", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._generate_while_loop_body_func", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder.encode", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.generate_decoding_function", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.generate_initial_memories", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.get_memory_invariants"], ["", "", "def", "_beam_search", "(", "model_adapters", ",", "beam_size", ",", "batch_size_x", ",", "max_translation_len", ",", "\n", "normalization_alpha", ",", "vocab_size", ",", "eos_id", ")", ":", "\n", "    ", "\"\"\"See description of BeamSearchSampler above.\n\n    Args:\n        model_adapters: sequence of ModelAdapter objects.\n        beam_size: integer specifying beam width.\n        batch_size_x: tf.int32 scalar specifying number of input sentences.\n        max_translation_len: tf.int32 scalar specifying max translation length.\n        normalization_alpha: tf.float32 scalar specifying alpha parameter for\n            length normalization.\n        vocab_size: float specifying the target vocabulary size.\n        eos_id: integer specifying the vocabulary ID of the EOS symbol.\n\n    Returns:\n        A pair of tensors: (sequences, scores). sequences contains vocabulary\n        IDs. It has shape (batch_size, len), where len <= max_translation_len\n        is the length of the longest translation in the batch. scores contains\n        sequnces scores, which are summed probabilities.\n    \"\"\"", "\n", "\n", "# Encode the input and generate a 1-step decoding function for each model.", "\n", "decoding_functions", "=", "[", "]", "\n", "for", "adapter", "in", "model_adapters", ":", "\n", "        ", "encoder_output", "=", "adapter", ".", "encode", "(", ")", "\n", "func", "=", "adapter", ".", "generate_decoding_function", "(", "encoder_output", ")", "\n", "decoding_functions", ".", "append", "(", "func", ")", "\n", "\n", "# Initialize the timestep counter.", "\n", "", "current_time_step", "=", "tf", ".", "constant", "(", "1", ")", "\n", "\n", "# Initialize sequences with <GO>.", "\n", "alive_sequences", "=", "tf", ".", "ones", "(", "[", "batch_size_x", ",", "beam_size", ",", "1", "]", ",", "dtype", "=", "INT_DTYPE", ")", "\n", "finished_sequences", "=", "tf", ".", "ones", "(", "[", "batch_size_x", ",", "beam_size", ",", "1", "]", ",", "dtype", "=", "INT_DTYPE", ")", "\n", "\n", "# Initialize alive sequence scores.", "\n", "alive_scores", "=", "tf", ".", "zeros", "(", "[", "batch_size_x", ",", "beam_size", "]", ")", "\n", "\n", "# Initialize finished sequence scores to a low value.", "\n", "finished_scores", "=", "tf", ".", "fill", "(", "[", "batch_size_x", ",", "beam_size", "]", ",", "-", "1.", "*", "1e7", ")", "\n", "\n", "# Initialize flags indicating which finished_sequences are really finished.", "\n", "finished_eos_flags", "=", "tf", ".", "fill", "(", "[", "batch_size_x", ",", "beam_size", "]", ",", "False", ")", "\n", "\n", "# Initialize memories (i.e. states carried over from the last timestep).", "\n", "alive_memories", "=", "[", "ma", ".", "generate_initial_memories", "(", "batch_size_x", ",", "beam_size", ")", "\n", "for", "ma", "in", "model_adapters", "]", "\n", "\n", "# Generate the conditional and body functions for the beam search loop.", "\n", "\n", "loop_cond", "=", "_generate_while_loop_cond_func", "(", "max_translation_len", ")", "\n", "\n", "loop_body", "=", "_generate_while_loop_body_func", "(", "model_adapters", ",", "\n", "decoding_functions", ",", "\n", "max_translation_len", ",", "\n", "batch_size_x", ",", "beam_size", ",", "\n", "vocab_size", ",", "eos_id", ",", "\n", "normalization_alpha", ")", "\n", "\n", "loop_vars", "=", "[", "current_time_step", ",", "\n", "alive_sequences", ",", "\n", "alive_scores", ",", "\n", "finished_sequences", ",", "\n", "finished_scores", ",", "\n", "finished_eos_flags", ",", "\n", "alive_memories", "]", "\n", "\n", "shape_invariants", "=", "[", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "# timestep", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "# alive sequences", "\n", "alive_scores", ".", "get_shape", "(", ")", ",", "# alive scores", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "# finished sequence", "\n", "finished_scores", ".", "get_shape", "(", ")", ",", "# finished scores", "\n", "finished_eos_flags", ".", "get_shape", "(", ")", ",", "# finished EOS flags", "\n", "[", "adapter", ".", "get_memory_invariants", "(", "memories", ")", "# alive memories", "\n", "for", "adapter", ",", "memories", "in", "zip", "(", "model_adapters", ",", "alive_memories", ")", "]", "]", "\n", "\n", "# Execute the auto-regressive decoding step via while loop.", "\n", "_", ",", "alive_sequences", ",", "alive_scores", ",", "finished_sequences", ",", "finished_scores", ",", "finished_eos_flags", ",", "_", "=", "tf", ".", "nest", ".", "map_structure", "(", "tf", ".", "stop_gradient", ",", "tf", ".", "while_loop", "(", "\n", "cond", "=", "loop_cond", ",", "\n", "body", "=", "loop_body", ",", "\n", "loop_vars", "=", "loop_vars", ",", "\n", "shape_invariants", "=", "shape_invariants", ",", "\n", "parallel_iterations", "=", "10", ",", "\n", "swap_memory", "=", "False", ")", ")", "\n", "\n", "alive_sequences", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "finished_sequences", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "\n", "# Account for the case in which no translations terminate in <EOS> for a", "\n", "# particular input sentence. In that case, copy the contents of the alive", "\n", "# beam for that sentence into the finished beam (sequence + score).", "\n", "finished_sequences", "=", "tf", ".", "compat", ".", "v1", ".", "where", "(", "tf", ".", "reduce_any", "(", "input_tensor", "=", "finished_eos_flags", ",", "axis", "=", "1", ")", ",", "\n", "finished_sequences", ",", "alive_sequences", ")", "\n", "# Attention: alive_scores are not length normalized!", "\n", "finished_scores", "=", "tf", ".", "compat", ".", "v1", ".", "where", "(", "tf", ".", "reduce_any", "(", "input_tensor", "=", "finished_eos_flags", ",", "axis", "=", "1", ")", ",", "\n", "finished_scores", ",", "alive_scores", ")", "\n", "\n", "# Truncate finished sequences to remove initial <GO>.", "\n", "finished_sequences", "=", "finished_sequences", "[", ":", ",", ":", ",", "1", ":", "]", "\n", "\n", "# Normalize scores. Note that we include the <EOS> token when calculating", "\n", "# sequence length.", "\n", "seq_len", "=", "tf", ".", "shape", "(", "input", "=", "finished_sequences", ")", "[", "2", "]", "\n", "indices", "=", "tf", ".", "range", "(", "seq_len", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "indices", "=", "tf", ".", "reshape", "(", "indices", ",", "[", "1", ",", "1", ",", "seq_len", "]", ")", "\n", "indices", "=", "tf", ".", "tile", "(", "indices", ",", "[", "batch_size_x", ",", "beam_size", ",", "1", "]", ")", "\n", "seq_lens", "=", "tf", ".", "reshape", "(", "seq_len", ",", "[", "1", ",", "1", ",", "1", "]", ")", "\n", "seq_lens", "=", "tf", ".", "tile", "(", "seq_lens", ",", "[", "batch_size_x", ",", "beam_size", ",", "seq_len", "]", ")", "\n", "eos_indices", "=", "tf", ".", "compat", ".", "v1", ".", "where", "(", "tf", ".", "equal", "(", "finished_sequences", ",", "eos_id", ")", ",", "\n", "indices", ",", "seq_lens", ")", "\n", "lengths", "=", "tf", ".", "reduce_min", "(", "input_tensor", "=", "eos_indices", "+", "1", ",", "axis", "=", "2", ")", "\n", "float_lengths", "=", "tf", ".", "cast", "(", "lengths", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "length_penalties", "=", "float_lengths", "**", "normalization_alpha", "\n", "finished_scores", "=", "finished_scores", "/", "length_penalties", "\n", "\n", "return", "finished_sequences", ",", "finished_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._compute_batch_indices": [[239, 248], ["tensorflow.reshape", "tensorflow.range"], "function", ["None"], ["", "def", "_compute_batch_indices", "(", "batch_size_x", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Generates a matrix of batch indices for the 'merged' beam tensor.\n\n    Each index denotes the batch from which the sequence occupying the same\n    relative position as the index within the 'merged' tensor belongs.\n    \"\"\"", "\n", "batch_range", "=", "tf", ".", "range", "(", "batch_size_x", "*", "beam_size", ")", "//", "beam_size", "\n", "batch_index_matrix", "=", "tf", ".", "reshape", "(", "batch_range", ",", "[", "batch_size_x", ",", "beam_size", "]", ")", "\n", "return", "batch_index_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._gather_top_sequences": [[250, 281], ["tensorflow.nn.top_k", "beam_search_sampler._compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.gather_nd", "adapter.gather_memories", "zip"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._compute_batch_indices", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.gather_memories"], ["", "def", "_gather_top_sequences", "(", "model_adapters", ",", "all_sequences", ",", "all_scores", ",", "\n", "all_scores_to_gather", ",", "all_eos_flags", ",", "all_memories", ",", "\n", "beam_size", ",", "batch_size_x", ",", "prefix", ")", ":", "\n", "    ", "\"\"\"Selects the top-k sequences from a sequence set.\"\"\"", "\n", "\n", "# Obtain indices of the top-k scores within the scores tensor.", "\n", "_", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "all_scores", ",", "k", "=", "beam_size", ")", "\n", "\n", "# Create a lookup-indices tensor for gathering the sequences associated", "\n", "# with the top scores.", "\n", "batch_index_matrix", "=", "_compute_batch_indices", "(", "batch_size_x", ",", "beam_size", ")", "\n", "gather_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_index_matrix", ",", "top_indices", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Collect top outputs.", "\n", "gathered_sequences", "=", "tf", ".", "gather_nd", "(", "all_sequences", ",", "gather_coordinates", ",", "\n", "name", "=", "'{:s}_sequences'", ".", "format", "(", "prefix", ")", ")", "\n", "\n", "gathered_scores", "=", "tf", ".", "gather_nd", "(", "all_scores_to_gather", ",", "gather_coordinates", ",", "\n", "name", "=", "'{:s}_scores'", ".", "format", "(", "prefix", ")", ")", "\n", "\n", "gathered_eos_flags", "=", "tf", ".", "gather_nd", "(", "all_eos_flags", ",", "gather_coordinates", ",", "\n", "name", "=", "'{:s}_eos_flags'", ".", "format", "(", "prefix", ")", ")", "\n", "\n", "gathered_memories", "=", "None", "\n", "if", "all_memories", "is", "not", "None", ":", "\n", "        ", "gathered_memories", "=", "[", "\n", "adapter", ".", "gather_memories", "(", "memories", ",", "gather_coordinates", ")", "\n", "for", "adapter", ",", "memories", "in", "zip", "(", "model_adapters", ",", "all_memories", ")", "]", "\n", "\n", "", "return", "gathered_sequences", ",", "gathered_scores", ",", "gathered_eos_flags", ",", "gathered_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._generate_while_loop_cond_func": [[283, 323], ["tensorflow.less", "tensorflow.reduce_min", "tensorflow.reduce_any", "tensorflow.logical_not", "tensorflow.logical_and", "tensorflow.reduce_all", "tensorflow.cast", "tensorflow.cast", "tensorflow.greater"], "function", ["None"], ["", "def", "_generate_while_loop_cond_func", "(", "max_translation_len", ")", ":", "\n", "\n", "    ", "def", "continue_decoding", "(", "curr_time_step", ",", "alive_sequences", ",", "alive_scores", ",", "\n", "finished_sequences", ",", "finished_scores", ",", "\n", "finished_eos_flags", ",", "alive_memories", ")", ":", "\n", "        ", "\"\"\"Determines whether decoding should continue or terminate.\"\"\"", "\n", "\n", "# Check maximum prediction length has not been reached.", "\n", "length_criterion", "=", "tf", ".", "less", "(", "curr_time_step", ",", "max_translation_len", ")", "\n", "\n", "# Otherwise, check if the most likely alive hypothesis is less likely", "\n", "# than the least probable completed sequence.", "\n", "\n", "# Calculate the best possible score of the most probable sequence", "\n", "# currently alive.", "\n", "highest_alive_score", "=", "alive_scores", "[", ":", ",", "0", "]", "\n", "\n", "# Calculate the score of the least likely sequence currently finished.", "\n", "lowest_finished_score", "=", "tf", ".", "reduce_min", "(", "\n", "input_tensor", "=", "finished_scores", "*", "tf", ".", "cast", "(", "finished_eos_flags", ",", "FLOAT_DTYPE", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# Account for the case in which none of the sequences in 'finished'", "\n", "# have terminated so far; In that case, each of the unfinished", "\n", "# sequences is assigned a high negative probability, so that the", "\n", "# termination condition is not met.", "\n", "tmp", "=", "tf", ".", "reduce_any", "(", "input_tensor", "=", "finished_eos_flags", ",", "axis", "=", "1", ")", "\n", "mask_unfinished", "=", "(", "1.", "-", "tf", ".", "cast", "(", "tmp", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "*", "(", "-", "1.", "*", "1e7", ")", "\n", "lowest_finished_score", "+=", "mask_unfinished", "\n", "\n", "# Check is the current highest alive score is lower than the current", "\n", "# lowest finished score.", "\n", "likelihood_criterion", "=", "tf", ".", "logical_not", "(", "\n", "tf", ".", "reduce_all", "(", "\n", "input_tensor", "=", "tf", ".", "greater", "(", "lowest_finished_score", ",", "highest_alive_score", ")", ")", ")", "\n", "\n", "# Decide whether to continue the decoding process.", "\n", "return", "tf", ".", "logical_and", "(", "length_criterion", ",", "likelihood_criterion", ")", "\n", "\n", "", "return", "continue_decoding", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._generate_while_loop_body_func": [[325, 519], ["tensorflow.constant", "tensorflow.tile", "tensorflow.transpose", "tensorflow.reshape", "range", "tensorflow.compat.v1.where", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.cond", "tensorflow.nn.top_k", "beam_search_sampler._compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.concat", "tensorflow.equal", "beam_search_sampler._gather_top_sequences", "tensorflow.zeros", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "beam_search_sampler._gather_top_sequences", "beam_search_sampler._generate_while_loop_body_func.extend_hypotheses"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._compute_batch_indices", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._gather_top_sequences", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.beam_search_sampler._gather_top_sequences"], ["", "def", "_generate_while_loop_body_func", "(", "model_adapters", ",", "decoding_functions", ",", "\n", "max_translation_len", ",", "batch_size_x", ",", "beam_size", ",", "\n", "vocab_size", ",", "eos_id", ",", "normalization_alpha", ")", ":", "\n", "\n", "# Construct an alternate set of 'log probabilities' to use when extending", "\n", "# sequences beyond EOS. The value is set very low to ensure that these", "\n", "# overgrown sequences are never chosen over incomplete or just-finished", "\n", "# sequences.", "\n", "    ", "tmp", "=", "tf", ".", "constant", "(", "tf", ".", "float32", ".", "min", ",", "shape", "=", "[", "1", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "eos_log_probs", "=", "tf", ".", "tile", "(", "tmp", ",", "\n", "multiples", "=", "[", "batch_size_x", "*", "beam_size", ",", "vocab_size", "]", ")", "\n", "\n", "def", "extend_hypotheses", "(", "current_time_step", ",", "alive_sequences", ",", "alive_scores", ",", "\n", "alive_memories", ")", ":", "\n", "        ", "\"\"\"Generates top-k extensions of the alive beam candidates.\"\"\"", "\n", "\n", "# Get the vocab IDs for this timestep in the order of the model inputs.", "\n", "next_ids", "=", "alive_sequences", "[", ":", ",", ":", ",", "-", "1", "]", "# [batch_size_x, beam_size]", "\n", "next_ids", "=", "tf", ".", "transpose", "(", "a", "=", "next_ids", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "# [beam_size, batch_size_x]", "\n", "next_ids", "=", "tf", ".", "reshape", "(", "next_ids", ",", "[", "-", "1", "]", ")", "# [beam_size * batch_size_x]", "\n", "\n", "# Run the vocab IDs through the decoders and get the log probs for all", "\n", "# possible extensions.", "\n", "sum_log_probs", "=", "None", "\n", "for", "i", "in", "range", "(", "len", "(", "decoding_functions", ")", ")", ":", "\n", "\n", "# Get logits.", "\n", "            ", "step_logits", ",", "alive_memories", "[", "i", "]", "=", "decoding_functions", "[", "i", "]", "(", "\n", "next_ids", ",", "current_time_step", ",", "alive_memories", "[", "i", "]", ")", "\n", "\n", "# Calculate the scores for all possible extensions of alive", "\n", "# hypotheses.", "\n", "log_probs", "=", "tf", ".", "nn", ".", "log_softmax", "(", "step_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Add to the log probs from other models.", "\n", "if", "sum_log_probs", "is", "None", ":", "\n", "                ", "sum_log_probs", "=", "log_probs", "\n", "", "else", ":", "\n", "                ", "sum_log_probs", "+=", "log_probs", "\n", "\n", "# In certain situations, the alive set can legitimately contain", "\n", "# sequences that are actually finished. When extending these, we don't", "\n", "# care what gets added beyond the EOS, only that the resulting sequence", "\n", "# gets a very low score. We give every possible extension the lowest", "\n", "# possible probability.", "\n", "", "", "sum_log_probs", "=", "tf", ".", "compat", ".", "v1", ".", "where", "(", "tf", ".", "equal", "(", "next_ids", ",", "eos_id", ")", ",", "\n", "eos_log_probs", ",", "\n", "sum_log_probs", ")", "\n", "\n", "# Reshape / transpose to match alive_sequences, alive_scores, etc.", "\n", "sum_log_probs", "=", "tf", ".", "reshape", "(", "sum_log_probs", ",", "\n", "[", "beam_size", ",", "batch_size_x", ",", "vocab_size", "]", ")", "\n", "sum_log_probs", "=", "tf", ".", "transpose", "(", "a", "=", "sum_log_probs", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "# Add log probs for this timestep to the full sequence log probs.", "\n", "curr_scores", "=", "sum_log_probs", "+", "tf", ".", "expand_dims", "(", "alive_scores", ",", "axis", "=", "2", ")", "\n", "\n", "# At first time step, all beams are identical - pick first.", "\n", "# At other time steps, flatten all beams.", "\n", "flat_curr_scores", "=", "tf", ".", "cond", "(", "pred", "=", "tf", ".", "equal", "(", "current_time_step", ",", "1", ")", ",", "\n", "true_fn", "=", "lambda", ":", "curr_scores", "[", ":", ",", "0", "]", ",", "\n", "false_fn", "=", "lambda", ":", "tf", ".", "reshape", "(", "curr_scores", ",", "[", "batch_size_x", ",", "-", "1", "]", ")", ")", "\n", "\n", "# Select top-k highest scores.", "\n", "top_scores", ",", "top_ids", "=", "tf", ".", "nn", ".", "top_k", "(", "flat_curr_scores", ",", "k", "=", "beam_size", ")", "\n", "\n", "# Determine the beam from which the top-scoring items originate and", "\n", "# their identity (i.e. token-ID).", "\n", "top_beam_indices", "=", "top_ids", "//", "vocab_size", "\n", "top_ids", "%=", "vocab_size", "\n", "\n", "# Determine the location of top candidates.", "\n", "# [batch_size_x, beam_size]", "\n", "batch_index_matrix", "=", "_compute_batch_indices", "(", "batch_size_x", ",", "beam_size", ")", "\n", "top_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_index_matrix", ",", "top_beam_indices", "]", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "# Extract top decoded sequences.", "\n", "# [batch_size_x, beam_size, sent_len]", "\n", "top_sequences", "=", "tf", ".", "gather_nd", "(", "alive_sequences", ",", "top_coordinates", ")", "\n", "top_sequences", "=", "tf", ".", "concat", "(", "[", "top_sequences", ",", "\n", "tf", ".", "expand_dims", "(", "top_ids", ",", "axis", "=", "2", ")", "]", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "# Extract top memories for each model.", "\n", "top_memories", "=", "[", "adapter", ".", "gather_memories", "(", "memories", ",", "top_coordinates", ")", "\n", "for", "adapter", ",", "memories", "in", "zip", "(", "model_adapters", ",", "\n", "alive_memories", ")", "]", "\n", "\n", "# Check how many of the top sequences have terminated.", "\n", "top_eos_flags", "=", "tf", ".", "equal", "(", "top_ids", ",", "eos_id", ")", "# [batch_size_x, beam_size]", "\n", "\n", "return", "(", "top_sequences", ",", "top_scores", ",", "top_eos_flags", ",", "top_memories", ")", "\n", "\n", "# Define a function to update alive set (part of tf.while_loop body)", "\n", "", "def", "update_alive", "(", "top_sequences", ",", "top_scores", ",", "top_eos_flags", ",", "top_memories", ")", ":", "\n", "        ", "\"\"\"Assembles an updated set of unfinished beam candidates.\"\"\"", "\n", "\n", "# Exclude completed sequences from the alive beam by setting their", "\n", "# scores to a large negative value.", "\n", "selection_scores", "=", "top_scores", "+", "tf", ".", "cast", "(", "top_eos_flags", ",", "dtype", "=", "tf", ".", "float32", ")", "*", "(", "-", "1.", "*", "1e7", ")", "\n", "\n", "# Update the alive beam.", "\n", "updated_alive_sequences", ",", "updated_alive_scores", ",", "updated_alive_eos_flags", ",", "updated_alive_memories", "=", "_gather_top_sequences", "(", "model_adapters", ",", "\n", "top_sequences", ",", "\n", "selection_scores", ",", "\n", "top_scores", ",", "\n", "top_eos_flags", ",", "\n", "top_memories", ",", "\n", "beam_size", ",", "\n", "batch_size_x", ",", "\n", "'alive'", ")", "\n", "\n", "return", "updated_alive_sequences", ",", "updated_alive_scores", ",", "updated_alive_eos_flags", ",", "updated_alive_memories", "\n", "\n", "# Define a function to update finished set (part of tf.while_loop body)", "\n", "", "def", "update_finished", "(", "finished_sequences", ",", "finished_scores", ",", "\n", "finished_eos_flags", ",", "top_sequences", ",", "top_scores", ",", "\n", "top_eos_flags", ")", ":", "\n", "        ", "\"\"\"Updates the list of completed translation hypotheses.\"\"\"", "\n", "\n", "# Match the length of the 'finished sequences' tensor with the length", "\n", "# of the 'finished scores' tensor", "\n", "zero_padding", "=", "tf", ".", "zeros", "(", "[", "batch_size_x", ",", "beam_size", ",", "1", "]", ",", "dtype", "=", "INT_DTYPE", ")", "\n", "finished_sequences", "=", "tf", ".", "concat", "(", "[", "finished_sequences", ",", "zero_padding", "]", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "# Exclude incomplete sequences from the finished beam by setting their", "\n", "# scores to a large negative value", "\n", "selection_scores", "=", "top_scores", "+", "(", "1.", "-", "tf", ".", "cast", "(", "top_eos_flags", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "*", "(", "-", "1.", "*", "1e7", ")", "\n", "\n", "# Combine sequences finished at previous time steps with the top", "\n", "# sequences from current time step, as well as their scores and", "\n", "# eos-flags, for the selection of a new, most likely, set of finished", "\n", "# sequences", "\n", "top_finished_sequences", "=", "tf", ".", "concat", "(", "[", "finished_sequences", ",", "top_sequences", "]", ",", "\n", "axis", "=", "1", ")", "\n", "top_finished_scores", "=", "tf", ".", "concat", "(", "[", "finished_scores", ",", "selection_scores", "]", ",", "\n", "axis", "=", "1", ")", "\n", "top_finished_eos_flags", "=", "tf", ".", "concat", "(", "[", "finished_eos_flags", ",", "top_eos_flags", "]", ",", "\n", "axis", "=", "1", ")", "\n", "# Update the finished beam", "\n", "updated_finished_sequences", ",", "updated_finished_scores", ",", "updated_finished_eos_flags", ",", "_", "=", "_gather_top_sequences", "(", "model_adapters", ",", "\n", "top_finished_sequences", ",", "\n", "top_finished_scores", ",", "\n", "top_finished_scores", ",", "\n", "top_finished_eos_flags", ",", "\n", "None", ",", "\n", "beam_size", ",", "\n", "batch_size_x", ",", "\n", "'finished'", ")", "\n", "\n", "return", "updated_finished_sequences", ",", "updated_finished_scores", ",", "updated_finished_eos_flags", "\n", "\n", "", "def", "decoding_step", "(", "current_time_step", ",", "alive_sequences", ",", "alive_scores", ",", "\n", "finished_sequences", ",", "finished_scores", ",", "finished_eos_flags", ",", "\n", "alive_memories", ")", ":", "\n", "        ", "\"\"\"Defines a single step of the while loop.\"\"\"", "\n", "\n", "# 1. Get the top sequences/ scores/ flags for the current time step", "\n", "top_sequences", ",", "top_scores", ",", "top_eos_flags", ",", "top_memories", "=", "extend_hypotheses", "(", "current_time_step", ",", "\n", "alive_sequences", ",", "\n", "alive_scores", ",", "\n", "alive_memories", ")", "\n", "\n", "# 2. Update the alive beam", "\n", "alive_sequences", ",", "alive_scores", ",", "alive_eos_flags", ",", "alive_memories", "=", "update_alive", "(", "top_sequences", ",", "\n", "top_scores", ",", "\n", "top_eos_flags", ",", "\n", "top_memories", ")", "\n", "\n", "# 3. Update the finished beam", "\n", "finished_sequences", ",", "finished_scores", ",", "finished_eos_flags", "=", "update_finished", "(", "finished_sequences", ",", "\n", "finished_scores", ",", "\n", "finished_eos_flags", ",", "\n", "top_sequences", ",", "\n", "top_scores", ",", "\n", "top_eos_flags", ")", "\n", "\n", "return", "current_time_step", "+", "1", ",", "alive_sequences", ",", "alive_scores", ",", "finished_sequences", ",", "finished_scores", ",", "finished_eos_flags", ",", "alive_memories", "\n", "\n", "", "return", "decoding_step", "\n", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer.__init__": [[22, 105], ["ValueError", "ValueError", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.compat.v1.variable_scope", "FeedForwardLayer", "FeedForwardLayer", "FeedForwardLayer", "FeedForwardLayer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "reference_dims", ",", "\n", "hypothesis_dims", ",", "\n", "total_key_dims", ",", "\n", "total_value_dims", ",", "\n", "output_dims", ",", "\n", "num_heads", ",", "\n", "float_dtype", ",", "\n", "dropout_attn", ",", "\n", "drophead", ",", "\n", "training", ",", "\n", "name", "=", "None", ")", ":", "\n", "\n", "# Set attributes", "\n", "        ", "self", ".", "reference_dims", "=", "reference_dims", "\n", "self", ".", "hypothesis_dims", "=", "hypothesis_dims", "\n", "self", ".", "total_key_dims", "=", "total_key_dims", "\n", "self", ".", "total_value_dims", "=", "total_value_dims", "\n", "self", ".", "output_dims", "=", "output_dims", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "float_dtype", "=", "float_dtype", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# Check if the specified hyper-parameters are consistent", "\n", "if", "total_key_dims", "%", "num_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'Specified total attention key dimensions {:d} must be divisible by the number of '", "\n", "'attention heads {:d}'", ".", "format", "(", "total_key_dims", ",", "num_heads", ")", ")", "\n", "", "if", "total_value_dims", "%", "num_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'Specified total attention value dimensions {:d} must be divisible by the number of '", "\n", "'attention heads {:d}'", ".", "format", "(", "total_value_dims", ",", "num_heads", ")", ")", "\n", "\n", "", "if", "dropout_attn", ">", "0", ":", "\n", "            ", "self", ".", "dropout_attn", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", "=", "dropout_attn", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout_attn", "=", "None", "\n", "\n", "", "if", "drophead", ">", "0", ":", "\n", "            ", "self", ".", "drophead", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", "=", "drophead", ",", "noise_shape", "=", "[", "None", ",", "None", ",", "1", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "drophead", "=", "None", "\n", "\n", "# Instantiate parameters", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "self", ".", "queries_projection", "=", "FeedForwardLayer", "(", "self", ".", "hypothesis_dims", ",", "\n", "self", ".", "total_key_dims", ",", "\n", "float_dtype", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "activation", "=", "None", ",", "\n", "use_bias", "=", "False", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "name", "=", "'queries_projection'", ")", "\n", "\n", "self", ".", "keys_projection", "=", "FeedForwardLayer", "(", "self", ".", "reference_dims", ",", "\n", "self", ".", "total_key_dims", ",", "\n", "float_dtype", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "activation", "=", "None", ",", "\n", "use_bias", "=", "False", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "name", "=", "'keys_projection'", ")", "\n", "\n", "self", ".", "values_projection", "=", "FeedForwardLayer", "(", "self", ".", "reference_dims", ",", "\n", "self", ".", "total_value_dims", ",", "\n", "float_dtype", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "activation", "=", "None", ",", "\n", "use_bias", "=", "False", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "name", "=", "'values_projection'", ")", "\n", "\n", "self", ".", "context_projection", "=", "FeedForwardLayer", "(", "self", ".", "total_value_dims", ",", "\n", "self", ".", "output_dims", ",", "\n", "float_dtype", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "activation", "=", "None", ",", "\n", "use_bias", "=", "False", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "name", "=", "'context_projection'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._compute_attn_inputs": [[106, 113], ["transformer_attention_modules.MultiHeadAttentionLayer.queries_projection.forward", "transformer_attention_modules.MultiHeadAttentionLayer.keys_projection.forward", "transformer_attention_modules.MultiHeadAttentionLayer.values_projection.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "_compute_attn_inputs", "(", "self", ",", "query_context", ",", "memory_context", ")", ":", "\n", "        ", "\"\"\" Computes query, key, and value tensors used by the attention function for the calculation of the\n        time-dependent context representation. \"\"\"", "\n", "queries", "=", "self", ".", "queries_projection", ".", "forward", "(", "query_context", ")", "\n", "keys", "=", "self", ".", "keys_projection", ".", "forward", "(", "memory_context", ")", "\n", "values", "=", "self", ".", "values_projection", ".", "forward", "(", "memory_context", ")", "\n", "return", "queries", ",", "keys", ",", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._split_among_heads": [[114, 127], ["get_shape_list", "tensorflow.reshape", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "def", "_split_among_heads", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\" Splits the attention inputs among multiple heads. \"\"\"", "\n", "# Retrieve the depth of the input tensor to be split (input is 3d)", "\n", "inputs_dims", "=", "get_shape_list", "(", "inputs", ")", "\n", "inputs_depth", "=", "inputs_dims", "[", "-", "1", "]", "\n", "\n", "# Assert the depth is compatible with the specified number of attention heads", "\n", "if", "isinstance", "(", "inputs_depth", ",", "int", ")", "and", "isinstance", "(", "self", ".", "num_heads", ",", "int", ")", ":", "\n", "            ", "assert", "inputs_depth", "%", "self", ".", "num_heads", "==", "0", ",", "(", "'Attention inputs depth {:d} is not evenly divisible by the specified number of attention heads {:d}'", "\n", ".", "format", "(", "inputs_depth", ",", "self", ".", "num_heads", ")", ")", "\n", "", "split_inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "inputs_dims", "[", ":", "-", "1", "]", "+", "[", "self", ".", "num_heads", ",", "inputs_depth", "//", "self", ".", "num_heads", "]", ")", "\n", "return", "split_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._merge_from_heads": [[128, 138], ["tensorflow.transpose", "get_shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "def", "_merge_from_heads", "(", "self", ",", "split_inputs", ")", ":", "\n", "        ", "\"\"\" Inverts the _split_among_heads operation. \"\"\"", "\n", "# Transpose split_inputs to perform the merge along the last two dimensions of the split input", "\n", "split_inputs", "=", "tf", ".", "transpose", "(", "a", "=", "split_inputs", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "# Retrieve the depth of the tensor to be merged", "\n", "split_inputs_dims", "=", "get_shape_list", "(", "split_inputs", ")", "\n", "split_inputs_depth", "=", "split_inputs_dims", "[", "-", "1", "]", "\n", "# Merge the depth and num_heads dimensions of split_inputs", "\n", "merged_inputs", "=", "tf", ".", "reshape", "(", "split_inputs", ",", "split_inputs_dims", "[", ":", "-", "2", "]", "+", "[", "self", ".", "num_heads", "*", "split_inputs_depth", "]", ")", "\n", "return", "merged_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._dot_product_attn": [[139, 178], ["tensorflow.cond", "tensorflow.cond", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.sqrt", "tensorflow.cond", "transformer_attention_modules.MultiHeadAttentionLayer.dropout_attn", "transformer_attention_modules.MultiHeadAttentionLayer.drophead", "get_shape_list", "get_shape_list", "tensorflow.greater", "tensorflow.greater", "get_shape_list", "tensorflow.cast", "tensorflow.tile", "tensorflow.tile", "tensorflow.greater", "tensorflow.tile"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "def", "_dot_product_attn", "(", "self", ",", "queries", ",", "keys", ",", "values", ",", "attn_mask", ",", "scaling_on", ")", ":", "\n", "        ", "\"\"\" Defines the dot-product attention function; see Vasvani et al.(2017), Eq.(1). \"\"\"", "\n", "# query/ key/ value have shape = [batch_size, time_steps, num_heads, num_features]", "\n", "# Tile keys and values tensors to match the number of decoding beams; ignored if already done by fusion module", "\n", "num_beams", "=", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "keys", ")", "[", "0", "]", "\n", "keys", "=", "tf", ".", "cond", "(", "pred", "=", "tf", ".", "greater", "(", "num_beams", ",", "1", ")", ",", "true_fn", "=", "lambda", ":", "tf", ".", "tile", "(", "keys", ",", "[", "num_beams", ",", "1", ",", "1", ",", "1", "]", ")", ",", "false_fn", "=", "lambda", ":", "keys", ")", "\n", "values", "=", "tf", ".", "cond", "(", "pred", "=", "tf", ".", "greater", "(", "num_beams", ",", "1", ")", ",", "true_fn", "=", "lambda", ":", "tf", ".", "tile", "(", "values", ",", "[", "num_beams", ",", "1", ",", "1", ",", "1", "]", ")", ",", "false_fn", "=", "lambda", ":", "values", ")", "\n", "\n", "# Transpose split inputs", "\n", "queries", "=", "tf", ".", "transpose", "(", "a", "=", "queries", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "values", "=", "tf", ".", "transpose", "(", "a", "=", "values", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "attn_logits", "=", "tf", ".", "matmul", "(", "queries", ",", "tf", ".", "transpose", "(", "a", "=", "keys", ",", "perm", "=", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", ")", "\n", "\n", "# Scale attention_logits by key dimensions to prevent softmax saturation, if specified", "\n", "if", "scaling_on", ":", "\n", "            ", "key_dims", "=", "get_shape_list", "(", "keys", ")", "[", "-", "1", "]", "\n", "normalizer", "=", "tf", ".", "sqrt", "(", "tf", ".", "cast", "(", "key_dims", ",", "self", ".", "float_dtype", ")", ")", "\n", "attn_logits", "/=", "normalizer", "\n", "\n", "# Optionally mask out positions which should not be attended to", "\n", "# attention mask should have shape=[batch, num_heads, query_length, key_length]", "\n", "# attn_logits has shape=[batch, num_heads, query_length, key_length]", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "tf", ".", "cond", "(", "pred", "=", "tf", ".", "greater", "(", "num_beams", ",", "1", ")", ",", "\n", "true_fn", "=", "lambda", ":", "tf", ".", "tile", "(", "attn_mask", ",", "[", "num_beams", ",", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "false_fn", "=", "lambda", ":", "attn_mask", ")", "\n", "attn_logits", "+=", "attn_mask", "\n", "\n", "# Calculate attention weights", "\n", "", "attn_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_logits", ")", "\n", "# Optionally apply dropout:", "\n", "if", "self", ".", "dropout_attn", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "self", ".", "dropout_attn", "(", "attn_weights", ",", "training", "=", "self", ".", "training", ")", "\n", "# Optionally apply DropHead:", "\n", "", "if", "self", ".", "drophead", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "self", ".", "drophead", "(", "attn_weights", ",", "training", "=", "self", ".", "training", ")", "\n", "# Weigh attention values", "\n", "", "weighted_memories", "=", "tf", ".", "matmul", "(", "attn_weights", ",", "values", ")", "\n", "return", "weighted_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer.forward": [[179, 207], ["transformer_attention_modules.MultiHeadAttentionLayer._compute_attn_inputs", "transformer_attention_modules.MultiHeadAttentionLayer._split_among_heads", "transformer_attention_modules.MultiHeadAttentionLayer._split_among_heads", "transformer_attention_modules.MultiHeadAttentionLayer._split_among_heads", "transformer_attention_modules.MultiHeadAttentionLayer._dot_product_attn", "transformer_attention_modules.MultiHeadAttentionLayer._merge_from_heads", "transformer_attention_modules.MultiHeadAttentionLayer.context_projection.forward", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.SingleHeadAttentionLayer._compute_attn_inputs", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._split_among_heads", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._split_among_heads", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._split_among_heads", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._dot_product_attn", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.MultiHeadAttentionLayer._merge_from_heads", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "def", "forward", "(", "self", ",", "query_context", ",", "memory_context", ",", "attn_mask", ",", "layer_memories", ")", ":", "\n", "        ", "\"\"\" Propagates the input information through the attention layer. \"\"\"", "\n", "# The context for the query and the referenced memory is identical in case of self-attention", "\n", "if", "memory_context", "is", "None", ":", "\n", "            ", "memory_context", "=", "query_context", "\n", "\n", "# Get attention inputs", "\n", "", "queries", ",", "keys", ",", "values", "=", "self", ".", "_compute_attn_inputs", "(", "query_context", ",", "memory_context", ")", "\n", "\n", "# Recall and update memories (analogous to the RNN state) - decoder only", "\n", "if", "layer_memories", "is", "not", "None", ":", "\n", "            ", "keys", "=", "tf", ".", "concat", "(", "[", "layer_memories", "[", "'keys'", "]", ",", "keys", "]", ",", "axis", "=", "1", ")", "\n", "values", "=", "tf", ".", "concat", "(", "[", "layer_memories", "[", "'values'", "]", ",", "values", "]", ",", "axis", "=", "1", ")", "\n", "layer_memories", "[", "'keys'", "]", "=", "keys", "\n", "layer_memories", "[", "'values'", "]", "=", "values", "\n", "\n", "# Split attention inputs among attention heads", "\n", "", "split_queries", "=", "self", ".", "_split_among_heads", "(", "queries", ")", "\n", "split_keys", "=", "self", ".", "_split_among_heads", "(", "keys", ")", "\n", "split_values", "=", "self", ".", "_split_among_heads", "(", "values", ")", "\n", "# Apply attention function", "\n", "split_weighted_memories", "=", "self", ".", "_dot_product_attn", "(", "split_queries", ",", "split_keys", ",", "split_values", ",", "attn_mask", ",", "\n", "scaling_on", "=", "True", ")", "\n", "# Merge head output", "\n", "weighted_memories", "=", "self", ".", "_merge_from_heads", "(", "split_weighted_memories", ")", "\n", "# Feed through a dense layer", "\n", "projected_memories", "=", "self", ".", "context_projection", ".", "forward", "(", "weighted_memories", ")", "\n", "return", "projected_memories", ",", "layer_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.SingleHeadAttentionLayer.__init__": [[212, 268], ["tensorflow.keras.layers.Dropout", "tensorflow.compat.v1.variable_scope", "FeedForwardLayer", "FeedForwardLayer", "tensorflow.compat.v1.get_variable", "tensorflow.python.ops.init_ops.glorot_uniform_initializer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "reference_dims", ",", "\n", "hypothesis_dims", ",", "\n", "hidden_dims", ",", "\n", "float_dtype", ",", "\n", "dropout_attn", ",", "\n", "training", ",", "\n", "name", ",", "\n", "attn_type", "=", "'multiplicative'", ")", ":", "\n", "\n", "# Declare attributes", "\n", "        ", "self", ".", "reference_dims", "=", "reference_dims", "\n", "self", ".", "hypothesis_dims", "=", "hypothesis_dims", "\n", "self", ".", "hidden_dims", "=", "hidden_dims", "\n", "self", ".", "float_dtype", "=", "float_dtype", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "name", "=", "name", "\n", "\n", "assert", "attn_type", "in", "[", "'additive'", ",", "'multiplicative'", "]", ",", "'Attention type {:s} is not supported.'", ".", "format", "(", "attn_type", ")", "\n", "\n", "if", "dropout_attn", ">", "0", ":", "\n", "            ", "self", ".", "dropout_attn", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", "=", "dropout_attn", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout_attn", "=", "None", "\n", "\n", "# Instantiate parameters", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "self", ".", "queries_projection", "=", "None", "\n", "self", ".", "attn_weight", "=", "None", "\n", "if", "attn_type", "==", "'additive'", ":", "\n", "                ", "self", ".", "queries_projection", "=", "FeedForwardLayer", "(", "self", ".", "hypothesis_dims", ",", "\n", "self", ".", "hidden_dims", ",", "\n", "float_dtype", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "activation", "=", "None", ",", "\n", "use_bias", "=", "False", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "name", "=", "'queries_projection'", ")", "\n", "\n", "self", ".", "attn_weight", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'attention_weight'", ",", "\n", "shape", "=", "self", ".", "hidden_dims", ",", "\n", "dtype", "=", "float_dtype", ",", "\n", "initializer", "=", "glorot_uniform_initializer", "(", ")", ",", "\n", "trainable", "=", "True", ")", "\n", "\n", "", "self", ".", "keys_projection", "=", "FeedForwardLayer", "(", "self", ".", "reference_dims", ",", "\n", "self", ".", "hidden_dims", ",", "\n", "float_dtype", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "activation", "=", "None", ",", "\n", "use_bias", "=", "False", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "name", "=", "'keys_projection'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.SingleHeadAttentionLayer._compute_attn_inputs": [[269, 278], ["transformer_attention_modules.SingleHeadAttentionLayer.keys_projection.forward", "transformer_attention_modules.SingleHeadAttentionLayer.queries_projection.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "_compute_attn_inputs", "(", "self", ",", "query_context", ",", "memory_context", ")", ":", "\n", "        ", "\"\"\" Computes query, key, and value tensors used by the attention function for the calculation of the\n        time-dependent context representation. \"\"\"", "\n", "queries", "=", "query_context", "\n", "if", "self", ".", "attn_type", "==", "'additive'", ":", "\n", "            ", "queries", "=", "self", ".", "queries_projection", ".", "forward", "(", "query_context", ")", "\n", "", "keys", "=", "self", ".", "keys_projection", ".", "forward", "(", "memory_context", ")", "\n", "values", "=", "memory_context", "\n", "return", "queries", ",", "keys", ",", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.SingleHeadAttentionLayer._additive_attn": [[279, 309], ["tensorflow.tile", "tensorflow.tile", "tensorflow.transpose", "tensorflow.map_fn", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.tile", "transformer_attention_modules.SingleHeadAttentionLayer.dropout_attn", "get_shape_list", "get_shape_list", "tensorflow.squeeze", "tensorflow.nn.tanh", "get_shape_list", "get_shape_list"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "def", "_additive_attn", "(", "self", ",", "queries", ",", "keys", ",", "values", ",", "attn_mask", ")", ":", "\n", "        ", "\"\"\" Uses additive attention to compute contextually enriched source-side representations. \"\"\"", "\n", "# Account for beam-search", "\n", "num_beams", "=", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "keys", ")", "[", "0", "]", "\n", "keys", "=", "tf", ".", "tile", "(", "keys", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "values", "=", "tf", ".", "tile", "(", "values", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "\n", "def", "_logits_fn", "(", "query", ")", ":", "\n", "            ", "\"\"\" Computes time-step-wise attention scores. \"\"\"", "\n", "query", "=", "tf", ".", "expand_dims", "(", "query", ",", "1", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "self", ".", "attn_weight", "*", "tf", ".", "nn", ".", "tanh", "(", "keys", "+", "query", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Obtain attention scores", "\n", "", "transposed_queries", "=", "tf", ".", "transpose", "(", "a", "=", "queries", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "# time-major", "\n", "attn_logits", "=", "tf", ".", "map_fn", "(", "_logits_fn", ",", "transposed_queries", ")", "\n", "attn_logits", "=", "tf", ".", "transpose", "(", "a", "=", "attn_logits", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# Transpose and tile the mask", "\n", "            ", "attn_logits", "+=", "tf", ".", "tile", "(", "tf", ".", "squeeze", "(", "attn_mask", ",", "1", ")", ",", "\n", "[", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "attn_mask", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "\n", "# Compute the attention weights", "\n", "", "attn_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_logits", ",", "axis", "=", "-", "1", ",", "name", "=", "'attn_weights'", ")", "\n", "# Optionally apply dropout", "\n", "if", "self", ".", "dropout_attn", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "self", ".", "dropout_attn", "(", "attn_weights", ",", "training", "=", "self", ".", "training", ")", "\n", "# Obtain context vectors", "\n", "", "weighted_memories", "=", "tf", ".", "matmul", "(", "attn_weights", ",", "values", ")", "\n", "return", "weighted_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.SingleHeadAttentionLayer._multiplicative_attn": [[310, 333], ["tensorflow.tile", "tensorflow.tile", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.tile", "transformer_attention_modules.SingleHeadAttentionLayer.dropout_attn", "get_shape_list", "get_shape_list", "tensorflow.squeeze", "get_shape_list", "get_shape_list"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "def", "_multiplicative_attn", "(", "self", ",", "queries", ",", "keys", ",", "values", ",", "attn_mask", ")", ":", "\n", "        ", "\"\"\" Uses multiplicative attention to compute contextually enriched source-side representations. \"\"\"", "\n", "# Account for beam-search", "\n", "num_beams", "=", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "keys", ")", "[", "0", "]", "\n", "keys", "=", "tf", ".", "tile", "(", "keys", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "values", "=", "tf", ".", "tile", "(", "values", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "\n", "# Use multiplicative attention", "\n", "transposed_keys", "=", "tf", ".", "transpose", "(", "a", "=", "keys", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "attn_logits", "=", "tf", ".", "matmul", "(", "queries", ",", "transposed_keys", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# Transpose and tile the mask", "\n", "            ", "attn_logits", "+=", "tf", ".", "tile", "(", "tf", ".", "squeeze", "(", "attn_mask", ",", "1", ")", ",", "\n", "[", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "attn_mask", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "\n", "# Compute the attention weights", "\n", "", "attn_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_logits", ",", "axis", "=", "-", "1", ",", "name", "=", "'attn_weights'", ")", "\n", "# Optionally apply dropout", "\n", "if", "self", ".", "dropout_attn", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "self", ".", "dropout_attn", "(", "attn_weights", ",", "training", "=", "self", ".", "training", ")", "\n", "# Obtain context vectors", "\n", "", "weighted_memories", "=", "tf", ".", "matmul", "(", "attn_weights", ",", "values", ")", "\n", "return", "weighted_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.SingleHeadAttentionLayer.forward": [[334, 355], ["transformer_attention_modules.SingleHeadAttentionLayer._compute_attn_inputs", "tensorflow.concat", "tensorflow.concat", "transformer_attention_modules.SingleHeadAttentionLayer._additive_attn", "transformer_attention_modules.SingleHeadAttentionLayer._multiplicative_attn"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.SingleHeadAttentionLayer._compute_attn_inputs", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.FineGrainedAttentionLayer._additive_attn", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.FineGrainedAttentionLayer._multiplicative_attn"], ["", "def", "forward", "(", "self", ",", "query_context", ",", "memory_context", ",", "attn_mask", ",", "layer_memories", ")", ":", "\n", "        ", "\"\"\" Propagates the input information through the attention layer. \"\"\"", "\n", "# The context for the query and the referenced memory is identical in case of self-attention", "\n", "if", "memory_context", "is", "None", ":", "\n", "            ", "memory_context", "=", "query_context", "\n", "\n", "# Get attention inputs", "\n", "", "queries", ",", "keys", ",", "values", "=", "self", ".", "_compute_attn_inputs", "(", "query_context", ",", "memory_context", ")", "\n", "# Recall and update memories (analogous to the RNN state) - decoder only", "\n", "if", "layer_memories", "is", "not", "None", ":", "\n", "            ", "keys", "=", "tf", ".", "concat", "(", "[", "layer_memories", "[", "'keys'", "]", ",", "keys", "]", ",", "axis", "=", "1", ")", "\n", "values", "=", "tf", ".", "concat", "(", "[", "layer_memories", "[", "'values'", "]", ",", "values", "]", ",", "axis", "=", "1", ")", "\n", "layer_memories", "[", "'keys'", "]", "=", "keys", "\n", "layer_memories", "[", "'values'", "]", "=", "values", "\n", "\n", "# Obtain weighted layer hidden representations", "\n", "", "if", "self", ".", "attn_type", "==", "'additive'", ":", "\n", "            ", "weighted_memories", "=", "self", ".", "_additive_attn", "(", "queries", ",", "keys", ",", "values", ",", "attn_mask", ")", "\n", "", "else", ":", "\n", "            ", "weighted_memories", "=", "self", ".", "_multiplicative_attn", "(", "queries", ",", "keys", ",", "values", ",", "attn_mask", ")", "\n", "", "return", "weighted_memories", ",", "layer_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.FineGrainedAttentionLayer.__init__": [[361, 372], ["transformer_attention_modules.SingleHeadAttentionLayer.__init__"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__"], ["def", "__init__", "(", "self", ",", "\n", "reference_dims", ",", "\n", "hypothesis_dims", ",", "\n", "hidden_dims", ",", "\n", "float_dtype", ",", "\n", "dropout_attn", ",", "\n", "training", ",", "\n", "name", ",", "\n", "attn_type", "=", "'multiplicative'", ")", ":", "\n", "        ", "super", "(", "FineGrainedAttentionLayer", ",", "self", ")", ".", "__init__", "(", "reference_dims", ",", "hypothesis_dims", ",", "hidden_dims", ",", "float_dtype", ",", "\n", "dropout_attn", ",", "training", ",", "name", ",", "attn_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.FineGrainedAttentionLayer._additive_attn": [[373, 407], ["tensorflow.tile", "tensorflow.tile", "tensorflow.transpose", "tensorflow.map_fn", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.transpose", "transformer_attention_modules.FineGrainedAttentionLayer.dropout_attn", "get_shape_list", "get_shape_list", "tensorflow.nn.tanh", "tensorflow.multiply", "tensorflow.tile", "tensorflow.transpose", "get_shape_list", "get_shape_list"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "def", "_additive_attn", "(", "self", ",", "queries", ",", "keys", ",", "values", ",", "attn_mask", ")", ":", "\n", "        ", "\"\"\" Uses additive attention to compute contextually enriched source-side representations. \"\"\"", "\n", "# Account for beam-search", "\n", "num_beams", "=", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "keys", ")", "[", "0", "]", "\n", "keys", "=", "tf", ".", "tile", "(", "keys", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "values", "=", "tf", ".", "tile", "(", "values", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "\n", "def", "_logits_fn", "(", "query", ")", ":", "\n", "            ", "\"\"\" Computes time-step-wise attention scores. \"\"\"", "\n", "query", "=", "tf", ".", "expand_dims", "(", "query", ",", "1", ")", "\n", "return", "self", ".", "attn_weight", "*", "tf", ".", "nn", ".", "tanh", "(", "keys", "+", "query", ")", "\n", "\n", "# Obtain attention scores", "\n", "", "transposed_queries", "=", "tf", ".", "transpose", "(", "a", "=", "queries", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "# time-major", "\n", "# attn_logits has shape=[time_steps_q, batch_size, time_steps_k, num_features]", "\n", "attn_logits", "=", "tf", ".", "map_fn", "(", "_logits_fn", ",", "transposed_queries", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "transposed_mask", "=", "tf", ".", "transpose", "(", "a", "=", "tf", ".", "tile", "(", "attn_mask", ",", "[", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "attn_mask", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "perm", "=", "[", "2", ",", "0", ",", "3", ",", "1", "]", ")", "\n", "attn_logits", "+=", "transposed_mask", "\n", "\n", "# Compute the attention weights", "\n", "", "attn_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_logits", ",", "axis", "=", "-", "2", ",", "name", "=", "'attn_weights'", ")", "\n", "# Optionally apply dropout", "\n", "if", "self", ".", "dropout_attn", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "self", ".", "dropout_attn", "(", "attn_weights", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# Obtain context vectors", "\n", "", "expanded_values", "=", "tf", ".", "expand_dims", "(", "values", ",", "axis", "=", "1", ")", "\n", "weighted_memories", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tf", ".", "multiply", "(", "tf", ".", "transpose", "(", "a", "=", "attn_weights", ",", "perm", "=", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", ",", "expanded_values", ")", ",", "axis", "=", "2", ")", "\n", "return", "weighted_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.FineGrainedAttentionLayer._multiplicative_attn": [[408, 442], ["tensorflow.tile", "tensorflow.tile", "tensorflow.transpose", "tensorflow.map_fn", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.transpose", "transformer_attention_modules.FineGrainedAttentionLayer.dropout_attn", "get_shape_list", "get_shape_list", "tensorflow.multiply", "tensorflow.tile", "tensorflow.transpose", "get_shape_list", "get_shape_list"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "def", "_multiplicative_attn", "(", "self", ",", "queries", ",", "keys", ",", "values", ",", "attn_mask", ")", ":", "\n", "        ", "\"\"\" Uses multiplicative attention to compute contextually enriched source-side representations. \"\"\"", "\n", "# Account for beam-search", "\n", "num_beams", "=", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "keys", ")", "[", "0", "]", "\n", "keys", "=", "tf", ".", "tile", "(", "keys", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "values", "=", "tf", ".", "tile", "(", "values", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "\n", "def", "_logits_fn", "(", "query", ")", ":", "\n", "            ", "\"\"\" Computes time-step-wise attention scores. \"\"\"", "\n", "query", "=", "tf", ".", "expand_dims", "(", "query", ",", "1", ")", "\n", "return", "tf", ".", "multiply", "(", "keys", ",", "query", ")", "\n", "\n", "# Obtain attention scores", "\n", "", "transposed_queries", "=", "tf", ".", "transpose", "(", "a", "=", "queries", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "# time-major", "\n", "# attn_logits has shape=[time_steps_q, batch_size, time_steps_k, num_features]", "\n", "attn_logits", "=", "tf", ".", "map_fn", "(", "_logits_fn", ",", "transposed_queries", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "transposed_mask", "=", "tf", ".", "transpose", "(", "a", "=", "tf", ".", "tile", "(", "attn_mask", ",", "[", "get_shape_list", "(", "queries", ")", "[", "0", "]", "//", "get_shape_list", "(", "attn_mask", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "perm", "=", "[", "2", ",", "0", ",", "3", ",", "1", "]", ")", "\n", "attn_logits", "+=", "transposed_mask", "\n", "\n", "# Compute the attention weights", "\n", "", "attn_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_logits", ",", "axis", "=", "-", "2", ",", "name", "=", "'attn_weights'", ")", "\n", "# Optionally apply dropout", "\n", "if", "self", ".", "dropout_attn", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "self", ".", "dropout_attn", "(", "attn_weights", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# Obtain context vectors", "\n", "", "expanded_values", "=", "tf", ".", "expand_dims", "(", "values", ",", "axis", "=", "1", ")", "\n", "weighted_memories", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tf", ".", "multiply", "(", "tf", ".", "transpose", "(", "a", "=", "attn_weights", ",", "perm", "=", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", ",", "expanded_values", ")", ",", "axis", "=", "2", ")", "\n", "return", "weighted_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_attention_modules.FineGrainedAttentionLayer._attn": [[443, 483], ["tensorflow.tile", "tensorflow.tile", "tensorflow.transpose", "tensorflow.map_fn", "tensorflow.nn.softmax", "tensorflow.map_fn", "tensorflow.transpose", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.transpose", "transformer_attention_modules.FineGrainedAttentionLayer.dropout_attn", "tensorflow.shape", "tensorflow.shape", "tensorflow.nn.tanh", "tensorflow.multiply", "tensorflow.tile", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "queries", ",", "keys", ",", "values", ",", "attn_mask", ")", ":", "\n", "        ", "\"\"\" For each encoder layer, weighs and combines time-step-wise hidden representation into a single layer\n        context state.  -- DEPRECATED, SINCE IT'S SLOW AND PROBABLY NOT ENTIRELY CORRECT \"\"\"", "\n", "# Account for beam-search", "\n", "num_beams", "=", "tf", ".", "shape", "(", "input", "=", "queries", ")", "[", "0", "]", "//", "tf", ".", "shape", "(", "input", "=", "keys", ")", "[", "0", "]", "\n", "keys", "=", "tf", ".", "tile", "(", "keys", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "values", "=", "tf", ".", "tile", "(", "values", ",", "[", "num_beams", ",", "1", ",", "1", "]", ")", "\n", "\n", "def", "_logits_fn", "(", "query", ")", ":", "\n", "            ", "\"\"\" Computes position-wise attention scores. \"\"\"", "\n", "query", "=", "tf", ".", "expand_dims", "(", "query", ",", "1", ")", "\n", "# return tf.squeeze(self.attn_weight * (tf.nn.tanh(keys + query + norm_bias)), axis=2)", "\n", "return", "self", ".", "attn_weight", "*", "tf", ".", "nn", ".", "tanh", "(", "keys", "+", "query", ")", "# 4D output", "\n", "\n", "", "def", "_weighting_fn", "(", "step_weights", ")", ":", "\n", "            ", "\"\"\" Computes position-wise context vectors. \"\"\"", "\n", "# step_weights = tf.expand_dims(step_weights, 2)", "\n", "return", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tf", ".", "multiply", "(", "step_weights", ",", "values", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# Obtain attention scores", "\n", "", "transposed_queries", "=", "tf", ".", "transpose", "(", "a", "=", "queries", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "attn_logits", "=", "tf", ".", "map_fn", "(", "_logits_fn", ",", "transposed_queries", ")", "# multiple queries per step are possible", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# attn_logits has shape=[batch, query_lengh, key_length, attn_features]", "\n", "            ", "transposed_mask", "=", "tf", ".", "transpose", "(", "a", "=", "tf", ".", "tile", "(", "attn_mask", ",", "[", "tf", ".", "shape", "(", "input", "=", "queries", ")", "[", "0", "]", "//", "tf", ".", "shape", "(", "input", "=", "attn_mask", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "perm", "=", "[", "2", ",", "0", ",", "3", ",", "1", "]", ")", "\n", "attn_logits", "+=", "transposed_mask", "\n", "\n", "# Compute the attention weights", "\n", "", "attn_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_logits", ",", "axis", "=", "-", "2", ",", "name", "=", "'attn_weights'", ")", "\n", "\n", "# Optionally apply dropout", "\n", "if", "self", ".", "dropout_attn", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "self", ".", "dropout_attn", "(", "attn_weights", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# Obtain context vectors", "\n", "", "weighted_memories", "=", "tf", ".", "map_fn", "(", "_weighting_fn", ",", "attn_weights", ")", "\n", "weighted_memories", "=", "tf", ".", "transpose", "(", "a", "=", "weighted_memories", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "return", "weighted_memories", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rescore.rescore": [[32, 54], ["source_file.readlines", "nbest_file.readlines", "enumerate", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile", "tmp_in.seek", "tmp_out.seek", "calc_scores", "output_file.write", "line.split", "int", "tmp_in.write", "tmp_out.write", "str", "line.strip"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.seek", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.seek", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.score.calc_scores"], ["", "def", "rescore", "(", "source_file", ",", "nbest_file", ",", "output_file", ",", "rescorer_settings", ",", "options", ")", ":", "\n", "\n", "    ", "lines", "=", "source_file", ".", "readlines", "(", ")", "\n", "nbest_lines", "=", "nbest_file", ".", "readlines", "(", ")", "\n", "\n", "# create plain text file for scoring", "\n", "with", "NamedTemporaryFile", "(", "mode", "=", "'w+'", ",", "prefix", "=", "'rescore-tmpin'", ")", "as", "tmp_in", ",", "NamedTemporaryFile", "(", "mode", "=", "'w+'", ",", "prefix", "=", "'rescore-tmpout'", ")", "as", "tmp_out", ":", "\n", "        ", "for", "line", "in", "nbest_lines", ":", "\n", "            ", "linesplit", "=", "line", ".", "split", "(", "' ||| '", ")", "\n", "# Get the source file index (zero-based).", "\n", "idx", "=", "int", "(", "linesplit", "[", "0", "]", ")", "\n", "tmp_in", ".", "write", "(", "lines", "[", "idx", "]", ")", "\n", "tmp_out", ".", "write", "(", "linesplit", "[", "1", "]", "+", "'\\n'", ")", "\n", "\n", "", "tmp_in", ".", "seek", "(", "0", ")", "\n", "tmp_out", ".", "seek", "(", "0", ")", "\n", "scores", "=", "calc_scores", "(", "tmp_in", ",", "tmp_out", ",", "rescorer_settings", ",", "options", ")", "\n", "\n", "", "for", "i", ",", "line", "in", "enumerate", "(", "nbest_lines", ")", ":", "\n", "        ", "score_str", "=", "' '", ".", "join", "(", "[", "str", "(", "s", "[", "i", "]", ")", "for", "s", "in", "scores", "]", ")", "\n", "output_file", ".", "write", "(", "'{0} {1}\\n'", ".", "format", "(", "line", ".", "strip", "(", ")", ",", "score_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rescore.main": [[56, 65], ["rescore.rescore", "load_config_from_json_file", "setattr", "options.append"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rescore.rescore", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.load_config_from_json_file"], ["", "", "def", "main", "(", "source_file", ",", "nbest_file", ",", "output_file", ",", "rescorer_settings", ")", ":", "\n", "# load model model_options", "\n", "    ", "options", "=", "[", "]", "\n", "for", "model", "in", "rescorer_settings", ".", "models", ":", "\n", "        ", "config", "=", "load_config_from_json_file", "(", "model", ")", "\n", "setattr", "(", "config", ",", "'reload'", ",", "model", ")", "\n", "options", ".", "append", "(", "config", ")", "\n", "\n", "", "rescore", "(", "source_file", ",", "nbest_file", ",", "output_file", ",", "rescorer_settings", ",", "options", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.load_data": [[58, 100], ["logging.info", "TextIterator", "logging.info", "TextIterator", "logging.info"], "function", ["None"], ["", "def", "load_data", "(", "config", ")", ":", "\n", "    ", "logging", ".", "info", "(", "'Reading data...'", ")", "\n", "text_iterator", "=", "TextIterator", "(", "\n", "source", "=", "config", ".", "source_dataset", ",", "\n", "target", "=", "config", ".", "target_dataset", ",", "\n", "source_dicts", "=", "config", ".", "source_dicts", ",", "\n", "target_dict", "=", "config", ".", "target_dict", ",", "\n", "model_type", "=", "config", ".", "model_type", ",", "\n", "batch_size", "=", "config", ".", "batch_size", ",", "\n", "maxlen", "=", "config", ".", "maxlen", ",", "\n", "source_vocab_sizes", "=", "config", ".", "source_vocab_sizes", ",", "\n", "target_vocab_size", "=", "config", ".", "target_vocab_size", ",", "\n", "skip_empty", "=", "True", ",", "\n", "shuffle_each_epoch", "=", "config", ".", "shuffle_each_epoch", ",", "\n", "sort_by_length", "=", "config", ".", "sort_by_length", ",", "\n", "use_factor", "=", "(", "config", ".", "factors", ">", "1", ")", ",", "\n", "maxibatch_size", "=", "config", ".", "maxibatch_size", ",", "\n", "token_batch_size", "=", "config", ".", "token_batch_size", ",", "\n", "keep_data_in_memory", "=", "config", ".", "keep_train_set_in_memory", ",", "\n", "preprocess_script", "=", "config", ".", "preprocess_script", ")", "\n", "\n", "if", "config", ".", "valid_freq", "and", "config", ".", "valid_source_dataset", "and", "config", ".", "valid_target_dataset", ":", "\n", "        ", "valid_text_iterator", "=", "TextIterator", "(", "\n", "source", "=", "config", ".", "valid_source_dataset", ",", "\n", "target", "=", "config", ".", "valid_target_dataset", ",", "\n", "source_dicts", "=", "config", ".", "source_dicts", ",", "\n", "target_dict", "=", "config", ".", "target_dict", ",", "\n", "model_type", "=", "config", ".", "model_type", ",", "\n", "batch_size", "=", "config", ".", "valid_batch_size", ",", "\n", "maxlen", "=", "config", ".", "maxlen", ",", "\n", "source_vocab_sizes", "=", "config", ".", "source_vocab_sizes", ",", "\n", "target_vocab_size", "=", "config", ".", "target_vocab_size", ",", "\n", "shuffle_each_epoch", "=", "False", ",", "\n", "sort_by_length", "=", "True", ",", "\n", "use_factor", "=", "(", "config", ".", "factors", ">", "1", ")", ",", "\n", "maxibatch_size", "=", "config", ".", "maxibatch_size", ",", "\n", "token_batch_size", "=", "config", ".", "valid_token_batch_size", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "'no validation set loaded'", ")", "\n", "valid_text_iterator", "=", "None", "\n", "", "logging", ".", "info", "(", "'Done'", ")", "\n", "return", "text_iterator", ",", "valid_text_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.train": [[102, 356], ["len", "max", "logging.info", "range", "tensorflow.zeros_initializer", "tensorflow.compat.v1.get_variable", "ModelUpdater", "model_loader.init_or_restore_variables", "tf.compat.v1.get_variable.assign", "write_config_to_json_file", "train.load_data", "util.load_dictionaries", "time.time", "logging.info", "range", "tf_utils.get_available_gpus", "tensorflow.DeviceSpec", "learning_schedule.ConstantSchedule", "tensorflow.compat.v1.train.AdamOptimizer", "logging.error", "sys.exit", "tensorflow.compat.v1.summary.FileWriter", "ExponentialSmoothing", "RandomSampler", "BeamSearchSampler", "logging.info", "tensorflow.compat.v1.train.checkpoint_exists", "tensorflow.device", "learning_schedule.TransformerSchedule", "os.path.abspath", "util.prepare_data", "ModelUpdater.update", "int", "os.path.abspath", "tensorflow.compat.v1.variable_scope", "replicas.append", "learning_schedule.WarmupPlateauDecaySchedule", "logging.error", "sys.exit", "os.path.dirname", "len", "logging.error", "sys.exit", "logging.info", "open", "open.close", "numpy.sum", "sess.run", "datetime.datetime.now().strftime", "logging.info", "time.time", "translate_utils.translate_batch", "zip", "translate_utils.translate_batch", "zip", "saver.save", "write_config_to_json_file", "progress.save_to_json", "logging.info", "saver.save", "write_config_to_json_file", "progress.save_to_json", "tensorflow.compat.v1.get_variable_scope", "TransformerModel", "rnn_model.RNNModel", "open.write", "time.time", "len", "len", "len", "len", "util.factoredseq2words", "util.seq2words", "util.seq2words", "logging.info", "logging.info", "logging.info", "len", "len", "len", "len", "util.factoredseq2words", "util.seq2words", "logging.info", "logging.info", "enumerate", "sess.run", "train.validate", "sess.run", "train.validate", "progress.history_errs.append", "train.save_non_checkpoint", "progress.save_to_json", "progress.history_errs.append", "progress.valid_script_scores.append", "len", "str", "datetime.datetime.now", "util.seq2words", "logging.info", "len", "min", "logging.info", "sess.run", "train.validate_with_script", "sess.run", "train.validate_with_script", "train.save_non_checkpoint", "write_config_to_json_file", "progress.save_to_json", "len", "len", "len", "max"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader.init_or_restore_variables", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.write_config_to_json_file", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.load_data", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dictionaries", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_available_gpus", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.prepare_data", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater.update", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.write_config_to_json_file", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.training_progress.TrainingProgress.save_to_json", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.write_config_to_json_file", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.training_progress.TrainingProgress.save_to_json", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.factoredseq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.factoredseq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.validate", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.validate", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.save_non_checkpoint", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.training_progress.TrainingProgress.save_to_json", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.validate_with_script", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.validate_with_script", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.save_non_checkpoint", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.write_config_to_json_file", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.training_progress.TrainingProgress.save_to_json"], ["", "def", "train", "(", "config", ",", "sess", ")", ":", "\n", "    ", "assert", "(", "config", ".", "prior_model", "!=", "None", "and", "(", "tf", ".", "compat", ".", "v1", ".", "train", ".", "checkpoint_exists", "(", "os", ".", "path", ".", "abspath", "(", "config", ".", "prior_model", ")", ")", ")", "or", "(", "config", ".", "map_decay_c", "==", "0.0", ")", ")", ",", "\"MAP training requires a prior model file: Use command-line option --prior_model\"", "\n", "\n", "# Construct the graph, with one model replica per GPU", "\n", "\n", "num_gpus", "=", "len", "(", "tf_utils", ".", "get_available_gpus", "(", ")", ")", "\n", "num_replicas", "=", "max", "(", "1", ",", "num_gpus", ")", "\n", "\n", "if", "config", ".", "loss_function", "==", "'MRT'", ":", "\n", "        ", "assert", "config", ".", "gradient_aggregation_steps", "==", "1", "\n", "assert", "config", ".", "max_sentences_per_device", "==", "0", ",", "\"MRT mode does not support sentence-based split\"", "\n", "if", "config", ".", "max_tokens_per_device", "!=", "0", ":", "\n", "            ", "assert", "(", "config", ".", "samplesN", "*", "config", ".", "maxlen", "<=", "config", ".", "max_tokens_per_device", ")", ",", "\"need to make sure candidates of a sentence could be \"", "\"feed into the model\"", "\n", "", "else", ":", "\n", "            ", "assert", "num_replicas", "==", "1", ",", "\"MRT mode does not support sentence-based split\"", "\n", "assert", "(", "config", ".", "samplesN", "*", "config", ".", "maxlen", "<=", "config", ".", "token_batch_size", ")", ",", "\"need to make sure candidates of a sentence could be \"", "\"feed into the model\"", "\n", "\n", "\n", "\n", "", "", "logging", ".", "info", "(", "'Building model...'", ")", "\n", "replicas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_replicas", ")", ":", "\n", "        ", "device_type", "=", "\"GPU\"", "if", "num_gpus", ">", "0", "else", "\"CPU\"", "\n", "device_spec", "=", "tf", ".", "DeviceSpec", "(", "device_type", "=", "device_type", ",", "device_index", "=", "i", ")", "\n", "with", "tf", ".", "device", "(", "device_spec", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "tf", ".", "compat", ".", "v1", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "(", "i", ">", "0", ")", ")", ":", "\n", "                ", "if", "config", ".", "model_type", "==", "\"transformer\"", ":", "\n", "                    ", "model", "=", "TransformerModel", "(", "config", ")", "\n", "", "else", ":", "\n", "                    ", "model", "=", "rnn_model", ".", "RNNModel", "(", "config", ")", "\n", "", "replicas", ".", "append", "(", "model", ")", "\n", "\n", "", "", "", "init", "=", "tf", ".", "zeros_initializer", "(", ")", "\n", "global_step", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'time'", ",", "[", "]", ",", "initializer", "=", "init", ",", "trainable", "=", "False", ")", "\n", "\n", "if", "config", ".", "learning_schedule", "==", "\"constant\"", ":", "\n", "        ", "schedule", "=", "learning_schedule", ".", "ConstantSchedule", "(", "config", ".", "learning_rate", ")", "\n", "", "elif", "config", ".", "learning_schedule", "==", "\"transformer\"", ":", "\n", "        ", "schedule", "=", "learning_schedule", ".", "TransformerSchedule", "(", "\n", "global_step", "=", "global_step", ",", "\n", "dim", "=", "config", ".", "state_size", ",", "\n", "warmup_steps", "=", "config", ".", "warmup_steps", ")", "\n", "", "elif", "config", ".", "learning_schedule", "==", "\"warmup-plateau-decay\"", ":", "\n", "        ", "schedule", "=", "learning_schedule", ".", "WarmupPlateauDecaySchedule", "(", "\n", "global_step", "=", "global_step", ",", "\n", "peak_learning_rate", "=", "config", ".", "learning_rate", ",", "\n", "warmup_steps", "=", "config", ".", "warmup_steps", ",", "\n", "plateau_steps", "=", "config", ".", "plateau_steps", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "error", "(", "'Learning schedule type is not valid: {}'", ".", "format", "(", "\n", "config", ".", "learning_schedule", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "if", "config", ".", "optimizer", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "schedule", ".", "learning_rate", ",", "\n", "beta1", "=", "config", ".", "adam_beta1", ",", "\n", "beta2", "=", "config", ".", "adam_beta2", ",", "\n", "epsilon", "=", "config", ".", "adam_epsilon", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "error", "(", "'No valid optimizer defined: {}'", ".", "format", "(", "config", ".", "optimizer", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "if", "config", ".", "summary_freq", ":", "\n", "        ", "summary_dir", "=", "(", "config", ".", "summary_dir", "if", "config", ".", "summary_dir", "is", "not", "None", "\n", "else", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "dirname", "(", "config", ".", "saveto", ")", ")", ")", "\n", "writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriter", "(", "summary_dir", ",", "sess", ".", "graph", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "None", "\n", "\n", "", "updater", "=", "ModelUpdater", "(", "config", ",", "num_gpus", ",", "replicas", ",", "optimizer", ",", "global_step", ",", "\n", "writer", ")", "\n", "\n", "if", "config", ".", "exponential_smoothing", ">", "0.0", ":", "\n", "        ", "smoothing", "=", "ExponentialSmoothing", "(", "config", ".", "exponential_smoothing", ")", "\n", "\n", "", "saver", ",", "progress", "=", "model_loader", ".", "init_or_restore_variables", "(", "\n", "config", ",", "sess", ",", "train", "=", "True", ")", "\n", "\n", "global_step", ".", "assign", "(", "progress", ".", "uidx", ",", "sess", ")", "\n", "\n", "if", "config", ".", "sample_freq", ":", "\n", "        ", "random_sampler", "=", "RandomSampler", "(", "\n", "models", "=", "[", "replicas", "[", "0", "]", "]", ",", "\n", "configs", "=", "[", "config", "]", ",", "\n", "beam_size", "=", "1", ")", "\n", "\n", "", "if", "config", ".", "beam_freq", "or", "config", ".", "valid_script", "is", "not", "None", ":", "\n", "        ", "beam_search_sampler", "=", "BeamSearchSampler", "(", "\n", "models", "=", "[", "replicas", "[", "0", "]", "]", ",", "\n", "configs", "=", "[", "config", "]", ",", "\n", "beam_size", "=", "config", ".", "beam_size", ")", "\n", "\n", "#save model options", "\n", "", "write_config_to_json_file", "(", "config", ",", "config", ".", "saveto", ")", "\n", "\n", "text_iterator", ",", "valid_text_iterator", "=", "load_data", "(", "config", ")", "\n", "_", ",", "_", ",", "num_to_source", ",", "num_to_target", "=", "util", ".", "load_dictionaries", "(", "config", ")", "\n", "total_loss", "=", "0.", "\n", "n_sents", ",", "n_words", "=", "0", ",", "0", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "\"Initial uidx={}\"", ".", "format", "(", "progress", ".", "uidx", ")", ")", "\n", "# set epoch = 1 if print per-token-probability", "\n", "if", "config", ".", "print_per_token_pro", ":", "\n", "        ", "config", ".", "max_epochs", "=", "progress", ".", "eidx", "+", "1", "\n", "", "for", "progress", ".", "eidx", "in", "range", "(", "progress", ".", "eidx", ",", "config", ".", "max_epochs", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Starting epoch {0}'", ".", "format", "(", "progress", ".", "eidx", ")", ")", "\n", "for", "source_sents", ",", "target_sents", "in", "text_iterator", ":", "\n", "            ", "if", "len", "(", "source_sents", "[", "0", "]", "[", "0", "]", ")", "!=", "config", ".", "factors", ":", "\n", "                ", "logging", ".", "error", "(", "'Mismatch between number of factors in settings ({0}), and number in training corpus ({1})\\n'", ".", "format", "(", "config", ".", "factors", ",", "len", "(", "source_sents", "[", "0", "]", "[", "0", "]", ")", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "x_in", ",", "x_mask_in", ",", "y_in", ",", "y_mask_in", "=", "util", ".", "prepare_data", "(", "\n", "source_sents", ",", "target_sents", ",", "config", ".", "factors", ",", "maxlen", "=", "None", ")", "\n", "if", "x_in", "is", "None", ":", "\n", "                ", "logging", ".", "info", "(", "'Minibatch with zero sample under length {0}'", ".", "format", "(", "config", ".", "maxlen", ")", ")", "\n", "continue", "\n", "", "write_summary_for_this_batch", "=", "config", ".", "summary_freq", "and", "(", "(", "progress", ".", "uidx", "%", "config", ".", "summary_freq", "==", "0", ")", "or", "(", "config", ".", "finish_after", "and", "progress", ".", "uidx", "%", "config", ".", "finish_after", "==", "0", ")", ")", "\n", "(", "factors", ",", "seqLen", ",", "batch_size", ")", "=", "x_in", ".", "shape", "\n", "\n", "output", "=", "updater", ".", "update", "(", "\n", "sess", ",", "x_in", ",", "x_mask_in", ",", "y_in", ",", "y_mask_in", ",", "num_to_target", ",", "\n", "write_summary_for_this_batch", ")", "\n", "\n", "if", "config", ".", "print_per_token_pro", "==", "False", ":", "\n", "                ", "total_loss", "+=", "output", "\n", "", "else", ":", "\n", "# write per-token probability into the file", "\n", "                ", "f", "=", "open", "(", "config", ".", "print_per_token_pro", ",", "'a'", ")", "\n", "for", "pro", "in", "output", ":", "\n", "                    ", "pro", "=", "str", "(", "pro", ")", "+", "'\\n'", "\n", "f", ".", "write", "(", "pro", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n", "", "n_sents", "+=", "batch_size", "\n", "n_words", "+=", "int", "(", "numpy", ".", "sum", "(", "y_mask_in", ")", ")", "\n", "progress", ".", "uidx", "+=", "1", "\n", "\n", "# Update the smoothed version of the model variables.", "\n", "# To reduce the performance overhead, we only do this once every", "\n", "# N steps (the smoothing factor is adjusted accordingly).", "\n", "if", "config", ".", "exponential_smoothing", ">", "0.0", "and", "progress", ".", "uidx", "%", "smoothing", ".", "update_frequency", "==", "0", ":", "\n", "                ", "sess", ".", "run", "(", "fetches", "=", "smoothing", ".", "update_ops", ")", "\n", "\n", "", "if", "config", ".", "disp_freq", "and", "progress", ".", "uidx", "%", "config", ".", "disp_freq", "==", "0", ":", "\n", "                ", "duration", "=", "time", ".", "time", "(", ")", "-", "last_time", "\n", "disp_time", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'[%Y-%m-%d %H:%M:%S]'", ")", "\n", "logging", ".", "info", "(", "'{0} Epoch: {1} Update: {2} Loss/word: {3} Words/sec: {4} Sents/sec: {5}'", ".", "format", "(", "disp_time", ",", "progress", ".", "eidx", ",", "progress", ".", "uidx", ",", "total_loss", "/", "n_words", ",", "n_words", "/", "duration", ",", "n_sents", "/", "duration", ")", ")", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "total_loss", "=", "0.", "\n", "n_sents", "=", "0", "\n", "n_words", "=", "0", "\n", "\n", "", "if", "config", ".", "sample_freq", "and", "progress", ".", "uidx", "%", "config", ".", "sample_freq", "==", "0", ":", "\n", "                ", "x_small", "=", "x_in", "[", ":", ",", ":", ",", ":", "10", "]", "\n", "x_mask_small", "=", "x_mask_in", "[", ":", ",", ":", "10", "]", "\n", "y_small", "=", "y_in", "[", ":", ",", ":", "10", "]", "\n", "samples", "=", "translate_utils", ".", "translate_batch", "(", "\n", "sess", ",", "random_sampler", ",", "x_small", ",", "x_mask_small", ",", "\n", "config", ".", "translation_maxlen", ",", "0.0", ")", "\n", "assert", "len", "(", "samples", ")", "==", "len", "(", "x_small", ".", "T", ")", "==", "len", "(", "y_small", ".", "T", ")", ",", "(", "len", "(", "samples", ")", ",", "x_small", ".", "shape", ",", "y_small", ".", "shape", ")", "\n", "for", "xx", ",", "yy", ",", "ss", "in", "zip", "(", "x_small", ".", "T", ",", "y_small", ".", "T", ",", "samples", ")", ":", "\n", "                    ", "source", "=", "util", ".", "factoredseq2words", "(", "xx", ",", "num_to_source", ")", "\n", "target", "=", "util", ".", "seq2words", "(", "yy", ",", "num_to_target", ")", "\n", "sample", "=", "util", ".", "seq2words", "(", "ss", "[", "0", "]", "[", "0", "]", ",", "num_to_target", ")", "\n", "logging", ".", "info", "(", "'SOURCE: {}'", ".", "format", "(", "source", ")", ")", "\n", "logging", ".", "info", "(", "'TARGET: {}'", ".", "format", "(", "target", ")", ")", "\n", "logging", ".", "info", "(", "'SAMPLE: {}'", ".", "format", "(", "sample", ")", ")", "\n", "\n", "", "", "if", "config", ".", "beam_freq", "and", "progress", ".", "uidx", "%", "config", ".", "beam_freq", "==", "0", ":", "\n", "                ", "x_small", "=", "x_in", "[", ":", ",", ":", ",", ":", "10", "]", "\n", "x_mask_small", "=", "x_mask_in", "[", ":", ",", ":", "10", "]", "\n", "y_small", "=", "y_in", "[", ":", ",", ":", "10", "]", "\n", "samples", "=", "translate_utils", ".", "translate_batch", "(", "\n", "sess", ",", "beam_search_sampler", ",", "x_small", ",", "x_mask_small", ",", "\n", "config", ".", "translation_maxlen", ",", "config", ".", "normalization_alpha", ")", "\n", "assert", "len", "(", "samples", ")", "==", "len", "(", "x_small", ".", "T", ")", "==", "len", "(", "y_small", ".", "T", ")", ",", "(", "len", "(", "samples", ")", ",", "x_small", ".", "shape", ",", "y_small", ".", "shape", ")", "\n", "for", "xx", ",", "yy", ",", "ss", "in", "zip", "(", "x_small", ".", "T", ",", "y_small", ".", "T", ",", "samples", ")", ":", "\n", "                    ", "source", "=", "util", ".", "factoredseq2words", "(", "xx", ",", "num_to_source", ")", "\n", "target", "=", "util", ".", "seq2words", "(", "yy", ",", "num_to_target", ")", "\n", "logging", ".", "info", "(", "'SOURCE: {}'", ".", "format", "(", "source", ")", ")", "\n", "logging", ".", "info", "(", "'TARGET: {}'", ".", "format", "(", "target", ")", ")", "\n", "for", "i", ",", "(", "sample_seq", ",", "cost", ")", "in", "enumerate", "(", "ss", ")", ":", "\n", "                        ", "sample", "=", "util", ".", "seq2words", "(", "sample_seq", ",", "num_to_target", ")", "\n", "msg", "=", "'SAMPLE {}: {} Cost/Len/Avg {}/{}/{}'", ".", "format", "(", "\n", "i", ",", "sample", ",", "cost", ",", "len", "(", "sample", ")", ",", "cost", "/", "len", "(", "sample", ")", ")", "\n", "logging", ".", "info", "(", "msg", ")", "\n", "\n", "", "", "", "if", "config", ".", "valid_freq", "and", "progress", ".", "uidx", "%", "config", ".", "valid_freq", "==", "0", ":", "\n", "                ", "if", "config", ".", "exponential_smoothing", ">", "0.0", ":", "\n", "                    ", "sess", ".", "run", "(", "fetches", "=", "smoothing", ".", "swap_ops", ")", "\n", "valid_ce", "=", "validate", "(", "sess", ",", "replicas", "[", "0", "]", ",", "config", ",", "\n", "valid_text_iterator", ")", "\n", "sess", ".", "run", "(", "fetches", "=", "smoothing", ".", "swap_ops", ")", "\n", "", "else", ":", "\n", "                    ", "valid_ce", "=", "validate", "(", "sess", ",", "replicas", "[", "0", "]", ",", "config", ",", "\n", "valid_text_iterator", ")", "\n", "", "if", "(", "len", "(", "progress", ".", "history_errs", ")", "==", "0", "or", "\n", "valid_ce", "<", "min", "(", "progress", ".", "history_errs", ")", ")", ":", "\n", "                    ", "progress", ".", "history_errs", ".", "append", "(", "valid_ce", ")", "\n", "progress", ".", "bad_counter", "=", "0", "\n", "save_non_checkpoint", "(", "sess", ",", "saver", ",", "config", ".", "saveto", ")", "\n", "progress_path", "=", "'{0}.progress.json'", ".", "format", "(", "config", ".", "saveto", ")", "\n", "progress", ".", "save_to_json", "(", "progress_path", ")", "\n", "", "else", ":", "\n", "                    ", "progress", ".", "history_errs", ".", "append", "(", "valid_ce", ")", "\n", "progress", ".", "bad_counter", "+=", "1", "\n", "if", "progress", ".", "bad_counter", ">", "config", ".", "patience", ":", "\n", "                        ", "logging", ".", "info", "(", "'Early Stop!'", ")", "\n", "progress", ".", "estop", "=", "True", "\n", "break", "\n", "", "", "if", "config", ".", "valid_script", "is", "not", "None", ":", "\n", "                    ", "if", "config", ".", "exponential_smoothing", ">", "0.0", ":", "\n", "                        ", "sess", ".", "run", "(", "fetches", "=", "smoothing", ".", "swap_ops", ")", "\n", "score", "=", "validate_with_script", "(", "sess", ",", "beam_search_sampler", ")", "\n", "sess", ".", "run", "(", "fetches", "=", "smoothing", ".", "swap_ops", ")", "\n", "", "else", ":", "\n", "                        ", "score", "=", "validate_with_script", "(", "sess", ",", "beam_search_sampler", ")", "\n", "", "need_to_save", "=", "(", "score", "is", "not", "None", "and", "\n", "(", "len", "(", "progress", ".", "valid_script_scores", ")", "==", "0", "or", "\n", "score", ">", "max", "(", "progress", ".", "valid_script_scores", ")", ")", ")", "\n", "if", "score", "is", "None", ":", "\n", "                        ", "score", "=", "0.0", "# ensure a valid value is written", "\n", "", "progress", ".", "valid_script_scores", ".", "append", "(", "score", ")", "\n", "if", "need_to_save", ":", "\n", "                        ", "progress", ".", "bad_counter", "=", "0", "\n", "save_path", "=", "config", ".", "saveto", "+", "\".best-valid-script\"", "\n", "save_non_checkpoint", "(", "sess", ",", "saver", ",", "save_path", ")", "\n", "write_config_to_json_file", "(", "config", ",", "save_path", ")", "\n", "\n", "progress_path", "=", "'{}.progress.json'", ".", "format", "(", "save_path", ")", "\n", "progress", ".", "save_to_json", "(", "progress_path", ")", "\n", "\n", "", "", "", "if", "config", ".", "save_freq", "and", "progress", ".", "uidx", "%", "config", ".", "save_freq", "==", "0", ":", "\n", "                ", "saver", ".", "save", "(", "sess", ",", "save_path", "=", "config", ".", "saveto", ",", "global_step", "=", "progress", ".", "uidx", ")", "\n", "write_config_to_json_file", "(", "config", ",", "\"%s-%s\"", "%", "(", "config", ".", "saveto", ",", "progress", ".", "uidx", ")", ")", "\n", "\n", "progress_path", "=", "'{0}-{1}.progress.json'", ".", "format", "(", "config", ".", "saveto", ",", "progress", ".", "uidx", ")", "\n", "progress", ".", "save_to_json", "(", "progress_path", ")", "\n", "\n", "", "if", "config", ".", "finish_after", "and", "progress", ".", "uidx", "%", "config", ".", "finish_after", "==", "0", ":", "\n", "                ", "logging", ".", "info", "(", "\"Maximum number of updates reached\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "save_path", "=", "config", ".", "saveto", ",", "global_step", "=", "progress", ".", "uidx", ")", "\n", "write_config_to_json_file", "(", "config", ",", "\"%s-%s\"", "%", "(", "config", ".", "saveto", ",", "progress", ".", "uidx", ")", ")", "\n", "\n", "progress", ".", "estop", "=", "True", "\n", "progress_path", "=", "'{0}-{1}.progress.json'", ".", "format", "(", "config", ".", "saveto", ",", "progress", ".", "uidx", ")", "\n", "progress", ".", "save_to_json", "(", "progress_path", ")", "\n", "break", "\n", "", "", "if", "progress", ".", "estop", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.save_non_checkpoint": [[358, 393], ["os.path.split", "tempfile.TemporaryDirectory", "os.path.join", "saver.save", "os.listdir", "os.path.join", "os.path.join", "os.replace"], "function", ["None"], ["", "", "", "def", "save_non_checkpoint", "(", "session", ",", "saver", ",", "save_path", ")", ":", "\n", "    ", "\"\"\"Saves the model to a temporary directory then moves it to save_path.\n\n    Rationale: we use TensorFlow's standard tf.train.Saver mechanism for saving\n    training checkpoints and also for saving the current best model according\n    to validation metrics. Since these are all stored in the same directory,\n    their paths would normally all get written to the same 'checkpoint' file,\n    with the file containing whichever one was last saved. That creates a\n    problem if training is interrupted after a best-so-far model is saved but\n    before a regular checkpoint is saved, since Nematus will try to load the\n    best-so-far model instead of the last checkpoint when it is restarted. To\n    avoid this, we save the best-so-far models to a temporary directory, then\n    move them to their desired location. The 'checkpoint' file that is written\n    to the temporary directory can safely be deleted along with the directory.\n\n    Args:\n        session: a TensorFlow session.\n        saver: a tf.train.Saver\n        save_path: string containing the path to save the model to.\n\n    Returns:\n        None.\n    \"\"\"", "\n", "head", ",", "tail", "=", "os", ".", "path", ".", "split", "(", "save_path", ")", "\n", "assert", "tail", "!=", "\"\"", "\n", "base_dir", "=", "\".\"", "if", "head", "==", "\"\"", "else", "head", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", "dir", "=", "base_dir", ")", "as", "tmp_dir", ":", "\n", "        ", "tmp_save_path", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "tail", ")", "\n", "saver", ".", "save", "(", "session", ",", "save_path", "=", "tmp_save_path", ")", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "tmp_dir", ")", ":", "\n", "            ", "if", "filename", "==", "'checkpoint'", ":", "\n", "                ", "continue", "\n", "", "new", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "filename", ")", "\n", "old", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "filename", ")", "\n", "os", ".", "replace", "(", "src", "=", "new", ",", "dst", "=", "old", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.validate": [[395, 405], ["train.calc_cross_entropy_per_sentence", "len", "sum", "sum", "logging.info"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.calc_cross_entropy_per_sentence"], ["", "", "", "def", "validate", "(", "session", ",", "model", ",", "config", ",", "text_iterator", ")", ":", "\n", "    ", "ce_vals", ",", "token_counts", "=", "calc_cross_entropy_per_sentence", "(", "\n", "session", ",", "model", ",", "config", ",", "text_iterator", ",", "normalization_alpha", "=", "0.0", ")", "\n", "num_sents", "=", "len", "(", "ce_vals", ")", "\n", "num_tokens", "=", "sum", "(", "token_counts", ")", "\n", "sum_ce", "=", "sum", "(", "ce_vals", ")", "\n", "avg_ce", "=", "sum_ce", "/", "num_sents", "\n", "logging", ".", "info", "(", "'Validation cross entropy (AVG/SUM/N_SENTS/N_TOKENS): {0} '", "'{1} {2} {3}'", ".", "format", "(", "avg_ce", ",", "sum_ce", ",", "num_sents", ",", "num_tokens", ")", ")", "\n", "return", "avg_ce", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.validate_with_script": [[407, 446], ["logging.info", "tempfile.NamedTemporaryFile", "translate_utils.translate_file", "tempfile.NamedTemporaryFile.flush", "subprocess.Popen", "subprocess.Popen.communicate", "locale.getpreferredencoding", "stdout_bytes.decode", "stderr_bytes.decode", "logging.info", "len", "logging.info", "logging.warning", "float", "open", "logging.warning", "stdout_bytes.decode.split"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.translate_file"], ["", "def", "validate_with_script", "(", "session", ",", "beam_search_sampler", ")", ":", "\n", "    ", "config", "=", "beam_search_sampler", ".", "configs", "[", "0", "]", "\n", "if", "config", ".", "valid_script", "==", "None", ":", "\n", "        ", "return", "None", "\n", "", "logging", ".", "info", "(", "'Starting external validation.'", ")", "\n", "out", "=", "tempfile", ".", "NamedTemporaryFile", "(", "mode", "=", "'w'", ")", "\n", "translate_utils", ".", "translate_file", "(", "\n", "input_file", "=", "open", "(", "config", ".", "valid_bleu_source_dataset", ",", "encoding", "=", "\"UTF-8\"", ")", ",", "\n", "output_file", "=", "out", ",", "\n", "session", "=", "session", ",", "\n", "sampler", "=", "beam_search_sampler", ",", "\n", "config", "=", "config", ",", "\n", "max_translation_len", "=", "config", ".", "translation_maxlen", ",", "\n", "normalization_alpha", "=", "config", ".", "normalization_alpha", ",", "\n", "nbest", "=", "False", ",", "\n", "minibatch_size", "=", "config", ".", "valid_batch_size", ")", "\n", "out", ".", "flush", "(", ")", "\n", "args", "=", "[", "config", ".", "valid_script", ",", "out", ".", "name", "]", "\n", "proc", "=", "subprocess", ".", "Popen", "(", "args", ",", "stdin", "=", "None", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "\n", "stderr", "=", "subprocess", ".", "PIPE", ")", "\n", "stdout_bytes", ",", "stderr_bytes", "=", "proc", ".", "communicate", "(", ")", "\n", "encoding", "=", "locale", ".", "getpreferredencoding", "(", ")", "\n", "stdout", "=", "stdout_bytes", ".", "decode", "(", "encoding", "=", "encoding", ")", "\n", "stderr", "=", "stderr_bytes", ".", "decode", "(", "encoding", "=", "encoding", ")", "\n", "if", "len", "(", "stderr", ")", ">", "0", ":", "\n", "        ", "logging", ".", "info", "(", "\"Validation script wrote the following to standard \"", "\n", "\"error:\\n\"", "+", "stderr", ")", "\n", "", "if", "proc", ".", "returncode", "!=", "0", ":", "\n", "        ", "logging", ".", "warning", "(", "\"Validation script failed (returned exit status of \"", "\n", "\"{}).\"", ".", "format", "(", "proc", ".", "returncode", ")", ")", "\n", "return", "None", "\n", "", "try", ":", "\n", "        ", "score", "=", "float", "(", "stdout", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "", "except", ":", "\n", "        ", "logging", ".", "warning", "(", "\"Validation script output does not look like a score: \"", "\n", "\"{}\"", ".", "format", "(", "stdout", ")", ")", "\n", "return", "None", "\n", "", "logging", ".", "info", "(", "\"Validation script score: {}\"", ".", "format", "(", "score", ")", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.calc_cross_entropy_per_sentence": [[448, 506], ["util.prepare_data", "session.run", "list", "logging.info", "len", "len", "len", "logging.error", "sys.exit", "numpy.count_nonzero", "numpy.array", "len", "len"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.prepare_data"], ["", "def", "calc_cross_entropy_per_sentence", "(", "session", ",", "model", ",", "config", ",", "text_iterator", ",", "\n", "normalization_alpha", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Calculates cross entropy values for a parallel corpus.\n\n    By default (when normalization_alpha is 0.0), the sentence-level cross\n    entropy is calculated. If normalization_alpha is 1.0 then the per-token\n    cross entropy is calculated. Other values of normalization_alpha may be\n    useful if the cross entropy value will be used as a score for selecting\n    between translation candidates (e.g. in reranking an n-nbest list). Using\n    a different (empirically determined) alpha value can help correct a model\n    bias toward too-short / too-long sentences.\n\n    TODO Support for multiple GPUs\n\n    Args:\n        session: TensorFlow session.\n        model: a RNNModel object.\n        config: model config.\n        text_iterator: TextIterator.\n        normalization_alpha: length normalization hyperparameter.\n\n    Returns:\n        A pair of lists. The first contains the (possibly normalized) cross\n        entropy value for each sentence pair. The second contains the\n        target-side token count for each pair (including the terminating\n        <EOS> symbol).\n    \"\"\"", "\n", "ce_vals", ",", "token_counts", "=", "[", "]", ",", "[", "]", "\n", "for", "xx", ",", "yy", "in", "text_iterator", ":", "\n", "        ", "if", "len", "(", "xx", "[", "0", "]", "[", "0", "]", ")", "!=", "config", ".", "factors", ":", "\n", "            ", "logging", ".", "error", "(", "'Mismatch between number of factors in settings '", "'({0}) and number present in data ({1})'", ".", "format", "(", "\n", "config", ".", "factors", ",", "len", "(", "xx", "[", "0", "]", "[", "0", "]", ")", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "x", ",", "x_mask", ",", "y", ",", "y_mask", "=", "util", ".", "prepare_data", "(", "xx", ",", "yy", ",", "config", ".", "factors", ",", "\n", "maxlen", "=", "None", ")", "\n", "\n", "# Run the minibatch through the model to get the sentence-level cross", "\n", "# entropy values.", "\n", "feeds", "=", "{", "model", ".", "inputs", ".", "x", ":", "x", ",", "\n", "model", ".", "inputs", ".", "x_mask", ":", "x_mask", ",", "\n", "model", ".", "inputs", ".", "y", ":", "y", ",", "\n", "model", ".", "inputs", ".", "y_mask", ":", "y_mask", ",", "\n", "model", ".", "inputs", ".", "training", ":", "False", "}", "\n", "batch_ce_vals", "=", "session", ".", "run", "(", "model", ".", "loss_per_sentence", ",", "feed_dict", "=", "feeds", ")", "\n", "\n", "# Optionally, do length normalization.", "\n", "batch_token_counts", "=", "[", "numpy", ".", "count_nonzero", "(", "s", ")", "for", "s", "in", "y_mask", ".", "T", "]", "\n", "if", "normalization_alpha", ":", "\n", "            ", "adjusted_lens", "=", "[", "n", "**", "normalization_alpha", "for", "n", "in", "batch_token_counts", "]", "\n", "batch_ce_vals", "/=", "numpy", ".", "array", "(", "adjusted_lens", ")", "\n", "\n", "", "ce_vals", "+=", "list", "(", "batch_ce_vals", ")", "\n", "token_counts", "+=", "batch_token_counts", "\n", "logging", ".", "info", "(", "\"Seen {}\"", ".", "format", "(", "len", "(", "ce_vals", ")", ")", ")", "\n", "\n", "", "assert", "len", "(", "ce_vals", ")", "==", "len", "(", "token_counts", ")", "\n", "return", "ce_vals", ",", "token_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.BaseSettings.__init__": [[17, 23], ["argparse.ArgumentParser", "settings.BaseSettings._add_console_arguments", "settings.BaseSettings._set_console_arguments", "settings.BaseSettings._set_additional_vars"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.RescorerSettings._add_console_arguments", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.BaseSettings._set_console_arguments", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.TranslationSettings._set_additional_vars"], ["def", "__init__", "(", "self", ",", "from_console_arguments", "=", "False", ")", ":", "\n", "        ", "self", ".", "_from_console_arguments", "=", "from_console_arguments", "\n", "self", ".", "_parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "self", ".", "_add_console_arguments", "(", ")", "\n", "self", ".", "_set_console_arguments", "(", ")", "\n", "self", ".", "_set_additional_vars", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.BaseSettings._add_console_arguments": [[24, 41], ["settings.BaseSettings._parser.add_argument", "settings.BaseSettings._parser.add_argument", "settings.BaseSettings._parser.add_argument"], "methods", ["None"], ["", "def", "_add_console_arguments", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Console arguments used in all modes\n        \"\"\"", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-v'", ",", "'--verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"verbose mode\"", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-m'", ",", "'--models'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "required", "=", "True", ",", "\n", "metavar", "=", "\"PATH\"", ",", "\n", "help", "=", "\"model to use; provide multiple models (with same \"", "\"vocabulary) for ensemble decoding\"", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-b'", ",", "'--minibatch_size'", ",", "type", "=", "int", ",", "default", "=", "80", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "\"minibatch size (default: %(default)s)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.BaseSettings._set_console_arguments": [[42, 57], ["list", "vars", "vars.items", "setattr", "settings.BaseSettings._parser.parse_args", "settings.BaseSettings._parser.get_default"], "methods", ["None"], ["", "def", "_set_console_arguments", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Parses console arguments and loads them into the namespace of this\n        object.\n\n        If there are no console arguments, the argument parser's default values\n        (see `self._parse_shared_console_arguments` and\n        `self._parse_individual_console_arguments`) are used.\n        \"\"\"", "\n", "if", "self", ".", "_from_console_arguments", ":", "\n", "            ", "args", "=", "vars", "(", "self", ".", "_parser", ".", "parse_args", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "args", "=", "{", "a", ".", "dest", ":", "self", ".", "_parser", ".", "get_default", "(", "a", ".", "dest", ")", "for", "a", "in", "self", ".", "_parser", ".", "_actions", "}", "\n", "", "for", "key", ",", "value", "in", "list", "(", "args", ".", "items", "(", ")", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.BaseSettings._set_additional_vars": [[58, 64], ["None"], "methods", ["None"], ["", "", "def", "_set_additional_vars", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Adds additional variables/constants to this object. They can be derived\n        or independent from parsed console arguments.\n        \"\"\"", "\n", "pass", "# override in subclass", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.TranslationSettings._add_console_arguments": [[71, 125], ["settings.BaseSettings._add_console_arguments", "settings.TranslationSettings._parser.add_argument", "settings.TranslationSettings._parser.add_argument", "settings.TranslationSettings._parser.add_mutually_exclusive_group", "settings.TranslationSettings.add_argument", "settings.TranslationSettings.add_argument", "settings.TranslationSettings._parser.add_argument", "settings.TranslationSettings._parser.add_argument", "settings.TranslationSettings._parser.add_argument", "settings.TranslationSettings._parser.add_argument", "settings.TranslationSettings._parser.add_argument", "settings.TranslationSettings._parser.add_argument", "argparse.FileType", "argparse.FileType"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.RescorerSettings._add_console_arguments"], ["def", "_add_console_arguments", "(", "self", ")", ":", "\n", "        ", "super", "(", "TranslationSettings", ",", "self", ")", ".", "_add_console_arguments", "(", ")", "\n", "\n", "if", "self", ".", "_from_console_arguments", ":", "\n", "# don't open files if no console arguments are parsed", "\n", "            ", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-i'", ",", "'--input'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "\n", "default", "=", "sys", ".", "stdin", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"input file (default: standard input)\"", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-o'", ",", "'--output'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "\n", "default", "=", "sys", ".", "stdout", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"output file (default: standard output)\"", ")", "\n", "\n", "", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-k'", ",", "'--beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "\"beam size (default: %(default)s)\"", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-n'", ",", "'--normalization_alpha'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "nargs", "=", "\"?\"", ",", "\n", "const", "=", "1.0", ",", "metavar", "=", "\"ALPHA\"", ",", "\n", "help", "=", "\"normalize scores by sentence length (with argument, \"", "\"exponentiate lengths by ALPHA)\"", ")", "\n", "\n", "# Support --n-best and --n_best (the dash version was added first, but", "\n", "# is inconsistent with the prevailing underscore style).", "\n", "group", "=", "self", ".", "_parser", ".", "add_mutually_exclusive_group", "(", ")", "\n", "group", ".", "add_argument", "(", "\n", "'--n_best'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"write n-best list (of size k)\"", ")", "\n", "group", ".", "add_argument", "(", "\n", "'--n-best'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "argparse", ".", "SUPPRESS", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'--maxibatch_size'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "\"size of maxibatch (number of minibatches that are sorted \"", "\"by length) (default: %(default)s)\"", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'--sampling_temperature'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "nargs", "=", "\"?\"", ",", "\n", "const", "=", "1.0", ",", "metavar", "=", "\"FLOAT\"", ",", "\n", "help", "=", "\"softmax temperature used for sampling (default %(default)s)\"", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'--translation_maxlen'", ",", "default", "=", "200", ",", "\n", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'Maximum length of translation output sentence (default: '", "\n", "'%(default)s)'", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'--translation_strategy'", ",", "type", "=", "str", ",", "choices", "=", "[", "'beam_search'", ",", "'sampling'", "]", ",", "default", "=", "\"beam_search\"", ",", "\n", "help", "=", "\"translation_strategy, either beam_search or sampling (default: %(default)s)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.TranslationSettings._set_additional_vars": [[126, 129], ["uuid.uuid4"], "methods", ["None"], ["", "def", "_set_additional_vars", "(", "self", ")", ":", "\n", "        ", "self", ".", "request_id", "=", "uuid", ".", "uuid4", "(", ")", "\n", "self", ".", "num_processes", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.ServerSettings._add_console_arguments": [[138, 160], ["settings.BaseSettings._add_console_arguments", "settings.ServerSettings._parser.add_argument", "settings.ServerSettings._parser.add_argument", "settings.ServerSettings._parser.add_argument", "settings.ServerSettings._parser.add_argument", "settings.ServerSettings._parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.RescorerSettings._add_console_arguments"], ["def", "_add_console_arguments", "(", "self", ")", ":", "\n", "        ", "super", "(", "ServerSettings", ",", "self", ")", ".", "_add_console_arguments", "(", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'--style'", ",", "default", "=", "'Nematus'", ",", "\n", "help", "=", "'API style; see `README.md` (default: Nematus)'", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'--host'", ",", "default", "=", "'0.0.0.0'", ",", "\n", "help", "=", "'host address (default: %(default)s)'", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'--port'", ",", "type", "=", "int", ",", "default", "=", "8080", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'host port (default: %(default)s)'", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'--threads'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "'number of threads (default: %(default)s)'", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-p'", ",", "'--num_processes'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "metavar", "=", "'INT'", ",", "\n", "help", "=", "\"number of processes (default: %(default)s)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.ScorerBaseSettings._add_console_arguments": [[167, 187], ["settings.BaseSettings._add_console_arguments", "settings.ScorerBaseSettings._parser.add_argument", "settings.ScorerBaseSettings._parser.add_argument", "settings.ScorerBaseSettings._parser.add_argument", "argparse.FileType", "argparse.FileType"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.RescorerSettings._add_console_arguments"], ["def", "_add_console_arguments", "(", "self", ")", ":", "\n", "        ", "super", "(", "ScorerBaseSettings", ",", "self", ")", ".", "_add_console_arguments", "(", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-n'", ",", "'--normalization_alpha'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "nargs", "=", "\"?\"", ",", "\n", "const", "=", "1.0", ",", "metavar", "=", "\"ALPHA\"", ",", "\n", "help", "=", "\"normalize scores by sentence length (with argument, \"", "\"exponentiate lengths by ALPHA)\"", ")", "\n", "\n", "if", "self", ".", "_from_console_arguments", ":", "\n", "# don't open files if no console arguments are parsed", "\n", "            ", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-o'", ",", "'--output'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "\n", "default", "=", "sys", ".", "stdout", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"output file (default: standard output)\"", ")", "\n", "\n", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-s'", ",", "'--source'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "\n", "required", "=", "True", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"source text file\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.ScorerSettings._add_console_arguments": [[193, 200], ["settings.ScorerBaseSettings._add_console_arguments", "settings.ScorerSettings._parser.add_argument", "argparse.FileType"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.RescorerSettings._add_console_arguments"], ["def", "_add_console_arguments", "(", "self", ")", ":", "\n", "        ", "super", "(", "ScorerSettings", ",", "self", ")", ".", "_add_console_arguments", "(", ")", "\n", "if", "self", ".", "_from_console_arguments", ":", "\n", "            ", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-t'", ",", "'--target'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "required", "=", "True", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"target text file\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.RescorerSettings._add_console_arguments": [[206, 213], ["settings.ScorerBaseSettings._add_console_arguments", "settings.RescorerSettings._parser.add_argument", "argparse.FileType"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.settings.RescorerSettings._add_console_arguments"], ["def", "_add_console_arguments", "(", "self", ")", ":", "\n", "        ", "super", "(", "RescorerSettings", ",", "self", ")", ".", "_add_console_arguments", "(", ")", "\n", "if", "self", ".", "_from_console_arguments", ":", "\n", "            ", "self", ".", "_parser", ".", "add_argument", "(", "\n", "'-i'", ",", "'--input'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "\n", "default", "=", "sys", ".", "stdin", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"input n-best list file (default: standard input)\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.FeedForwardLayer.__init__": [[62, 86], ["tensorflow.compat.v1.get_variable", "initializers.norm_weight", "tensorflow.compat.v1.get_variable", "layers.FeedForwardLayer.use_layer_norm", "tensorflow.ones", "dropout_input"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight"], ["    ", "def", "__init__", "(", "self", ",", "\n", "in_size", ",", "\n", "out_size", ",", "\n", "batch_size", ",", "\n", "non_linearity", "=", "tf", ".", "nn", ".", "tanh", ",", "\n", "W", "=", "None", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "dropout_input", "=", "None", ")", ":", "\n", "        ", "if", "W", "is", "None", ":", "\n", "            ", "init", "=", "initializers", ".", "norm_weight", "(", "in_size", ",", "out_size", ")", "\n", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'W'", ",", "initializer", "=", "init", ")", "\n", "", "self", ".", "W", "=", "W", "\n", "self", ".", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'b'", ",", "[", "out_size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", ")", "\n", "self", ".", "non_linearity", "=", "non_linearity", "\n", "self", ".", "use_layer_norm", "=", "use_layer_norm", "\n", "if", "use_layer_norm", ":", "\n", "            ", "self", ".", "layer_norm", "=", "self", ".", "use_layer_norm", "(", "layer_size", "=", "out_size", ")", "\n", "# Create a dropout mask for input values (reused at every timestep).", "\n", "", "if", "dropout_input", "==", "None", ":", "\n", "            ", "self", ".", "dropout_mask", "=", "None", "\n", "", "else", ":", "\n", "            ", "ones", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "in_size", "]", ")", "\n", "self", ".", "dropout_mask", "=", "dropout_input", "(", "ones", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.FeedForwardLayer.forward": [[88, 98], ["layers.apply_dropout_mask", "layers.FeedForwardLayer.non_linearity", "layers.FeedForwardLayer.layer_norm.forward", "layers.matmul3d", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.matmul3d"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "input_is_3d", "=", "False", ")", ":", "\n", "        ", "x", "=", "apply_dropout_mask", "(", "x", ",", "self", ".", "dropout_mask", ",", "input_is_3d", ")", "\n", "if", "input_is_3d", ":", "\n", "            ", "y", "=", "matmul3d", "(", "x", ",", "self", ".", "W", ")", "+", "self", ".", "b", "\n", "", "else", ":", "\n", "            ", "y", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "W", ")", "+", "self", ".", "b", "\n", "", "if", "self", ".", "use_layer_norm", ":", "\n", "            ", "y", "=", "self", ".", "layer_norm", ".", "forward", "(", "y", ")", "\n", "", "y", "=", "self", ".", "non_linearity", "(", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.EmbeddingLayer.__init__": [[101, 111], ["range", "len", "len", "len", "initializers.norm_weight", "tensorflow.compat.v1.get_variable", "layers.EmbeddingLayer.embedding_matrices.append", "str"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight"], ["    ", "def", "__init__", "(", "self", ",", "vocabulary_sizes", ",", "dim_per_factor", ")", ":", "\n", "        ", "assert", "len", "(", "vocabulary_sizes", ")", "==", "len", "(", "dim_per_factor", ")", "\n", "self", ".", "_dim_per_factor", "=", "dim_per_factor", "\n", "self", ".", "embedding_matrices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "vocabulary_sizes", ")", ")", ":", "\n", "            ", "vocab_size", ",", "dim", "=", "vocabulary_sizes", "[", "i", "]", ",", "dim_per_factor", "[", "i", "]", "\n", "var_name", "=", "'embeddings'", "if", "i", "==", "0", "else", "'embeddings_'", "+", "str", "(", "i", ")", "\n", "init", "=", "initializers", ".", "norm_weight", "(", "vocab_size", ",", "dim", ")", "\n", "matrix", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "var_name", ",", "initializer", "=", "init", ")", "\n", "self", ".", "embedding_matrices", ".", "append", "(", "matrix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.EmbeddingLayer.forward": [[112, 121], ["tensorflow.concat", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "enumerate"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "factor", "=", "None", ")", ":", "\n", "        ", "if", "factor", "==", "None", ":", "\n", "# Assumes that x has shape: factors, ...", "\n", "            ", "embs", "=", "[", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "matrix", ",", "ids", "=", "x", "[", "i", "]", ")", "\n", "for", "i", ",", "matrix", "in", "enumerate", "(", "self", ".", "embedding_matrices", ")", "]", "\n", "return", "tf", ".", "concat", "(", "embs", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "matrix", "=", "self", ".", "embedding_matrices", "[", "factor", "]", "\n", "return", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "matrix", ",", "ids", "=", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.EmbeddingLayer.zero": [[122, 134], ["tensorflow.zeros", "sum", "tensorflow.concat", "tensorflow.concat", "tensorflow.constant", "tensorflow.shape", "tensorflow.constant", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "zero", "(", "self", ",", "x", ",", "factor", "=", "None", ")", ":", "\n", "        ", "if", "factor", "==", "None", ":", "\n", "            ", "emb_size", "=", "sum", "(", "self", ".", "_dim_per_factor", ")", "\n", "out_shape", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "shape", "(", "input", "=", "x", ")", "[", "1", ":", "]", ",", "tf", ".", "constant", "(", "[", "emb_size", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "emb_size", "=", "self", ".", "_dim_per_factor", "[", "factor", "]", "\n", "out_shape", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "shape", "(", "input", "=", "x", ")", ",", "tf", ".", "constant", "(", "[", "emb_size", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "", "return", "tf", ".", "zeros", "(", "out_shape", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.EmbeddingLayer.get_embeddings": [[135, 140], ["None"], "methods", ["None"], ["", "def", "get_embeddings", "(", "self", ",", "factor", "=", "None", ")", ":", "\n", "        ", "if", "factor", "==", "None", ":", "\n", "            ", "return", "self", ".", "embedding_matrices", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "embedding_matrices", "[", "factor", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.RecurrentLayer.__init__": [[143, 148], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "initial_state", ",", "\n", "step_fn", ")", ":", "\n", "        ", "self", ".", "initial_state", "=", "initial_state", "\n", "self", ".", "step_fn", "=", "step_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.RecurrentLayer.forward": [[149, 155], ["tensorflow.scan"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# Assumes that x has shape: time, batch, ...", "\n", "        ", "states", "=", "tf", ".", "scan", "(", "fn", "=", "self", ".", "step_fn", ",", "\n", "elems", "=", "x", ",", "\n", "initializer", "=", "self", ".", "initial_state", ")", "\n", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.LayerNormLayer.__init__": [[157, 166], ["tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.constant_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "layer_size", ",", "\n", "eps", "=", "1e-5", ")", ":", "\n", "#TODO: If nematus_compat is true, then eps must be 1e-5!", "\n", "        ", "self", ".", "new_mean", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'new_mean'", ",", "[", "layer_size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", ")", "\n", "self", ".", "new_std", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'new_std'", ",", "[", "layer_size", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "constant_initializer", "(", "1", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.LayerNormLayer.forward": [[167, 173], ["tensorflow.nn.moments", "tensorflow.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "m", ",", "v", "=", "tf", ".", "nn", ".", "moments", "(", "x", "=", "x", ",", "axes", "=", "[", "-", "1", "]", ",", "keepdims", "=", "True", ")", "\n", "std", "=", "tf", ".", "sqrt", "(", "v", "+", "self", ".", "eps", ")", "\n", "norm_x", "=", "(", "x", "-", "m", ")", "/", "std", "\n", "new_x", "=", "norm_x", "*", "self", ".", "new_std", "+", "self", ".", "new_mean", "\n", "return", "new_x", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.RMSNormLayer.__init__": [[175, 181], ["tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.constant_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "layer_size", ",", "\n", "eps", "=", "1e-5", ")", ":", "\n", "        ", "self", ".", "scale", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'scale'", ",", "[", "layer_size", "]", ",", "\n", "initializer", "=", "tf", ".", "compat", ".", "v1", ".", "constant_initializer", "(", "1", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.RMSNormLayer.forward": [[182, 185], ["tensorflow.reduce_mean", "tensorflow.math.rsqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "ms", "=", "tf", ".", "reduce_mean", "(", "x", "**", "2", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "return", "x", "*", "tf", ".", "math", ".", "rsqrt", "(", "ms", "+", "self", ".", "eps", ")", "*", "self", ".", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep.__init__": [[187, 262], ["tensorflow.concat", "tensorflow.compat.v1.get_variable", "initializers.ortho_weight", "tensorflow.compat.v1.get_variable", "tensorflow.concat", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "initializers.norm_weight", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.ones", "dropout_input", "dropout_input", "tensorflow.ones", "dropout_state", "dropout_state", "initializers.ortho_weight", "initializers.ortho_weight", "tensorflow.compat.v1.variable_scope", "layers.GRUStep.use_layer_norm", "tensorflow.compat.v1.variable_scope", "layers.GRUStep.use_layer_norm", "initializers.norm_weight", "initializers.norm_weight", "tensorflow.compat.v1.variable_scope", "layers.GRUStep.use_layer_norm", "tensorflow.compat.v1.variable_scope", "layers.GRUStep.use_layer_norm"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.ortho_weight", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.ortho_weight", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.ortho_weight", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_size", ",", "\n", "state_size", ",", "\n", "batch_size", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "legacy_bias_type", "=", "LegacyBiasType", ".", "NEMATUS_COMPAT_FALSE", ",", "\n", "dropout_input", "=", "None", ",", "\n", "dropout_state", "=", "None", ")", ":", "\n", "        ", "init", "=", "tf", ".", "concat", "(", "[", "initializers", ".", "ortho_weight", "(", "state_size", ")", ",", "\n", "initializers", ".", "ortho_weight", "(", "state_size", ")", "]", ",", "\n", "axis", "=", "1", ")", "\n", "self", ".", "state_to_gates", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'state_to_gates'", ",", "\n", "initializer", "=", "init", ")", "\n", "if", "input_size", ">", "0", ":", "\n", "            ", "init", "=", "tf", ".", "concat", "(", "[", "initializers", ".", "norm_weight", "(", "input_size", ",", "state_size", ")", ",", "\n", "initializers", ".", "norm_weight", "(", "input_size", ",", "state_size", ")", "]", ",", "\n", "axis", "=", "1", ")", "\n", "self", ".", "input_to_gates", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'input_to_gates'", ",", "\n", "initializer", "=", "init", ")", "\n", "\n", "", "if", "input_size", "==", "0", "and", "legacy_bias_type", "==", "LegacyBiasType", ".", "NEMATUS_COMPAT_FALSE", ":", "\n", "            ", "self", ".", "gates_bias", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "gates_bias", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'gates_bias'", ",", "[", "2", "*", "state_size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", ")", "\n", "\n", "", "init", "=", "initializers", ".", "ortho_weight", "(", "state_size", ")", "\n", "self", ".", "state_to_proposal", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'state_to_proposal'", ",", "\n", "initializer", "=", "init", ")", "\n", "if", "input_size", ">", "0", ":", "\n", "            ", "init", "=", "initializers", ".", "norm_weight", "(", "input_size", ",", "state_size", ")", "\n", "self", ".", "input_to_proposal", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'input_to_proposal'", ",", "\n", "initializer", "=", "init", ")", "\n", "\n", "", "if", "input_size", "==", "0", "and", "legacy_bias_type", "==", "LegacyBiasType", ".", "NEMATUS_COMPAT_FALSE", ":", "\n", "            ", "self", ".", "proposal_bias", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "proposal_bias", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'proposal_bias'", ",", "[", "state_size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", ")", "\n", "\n", "", "self", ".", "legacy_bias_type", "=", "legacy_bias_type", "\n", "self", ".", "use_layer_norm", "=", "use_layer_norm", "\n", "\n", "self", ".", "gates_state_norm", "=", "None", "\n", "self", ".", "proposal_state_norm", "=", "None", "\n", "self", ".", "gates_x_norm", "=", "None", "\n", "self", ".", "proposal_x_norm", "=", "None", "\n", "if", "self", ".", "use_layer_norm", "is", "not", "None", "and", "self", ".", "use_layer_norm", "is", "not", "False", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'gates_state_norm'", ")", ":", "\n", "                ", "self", ".", "gates_state_norm", "=", "self", ".", "use_layer_norm", "(", "2", "*", "state_size", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'proposal_state_norm'", ")", ":", "\n", "                ", "self", ".", "proposal_state_norm", "=", "self", ".", "use_layer_norm", "(", "state_size", ")", "\n", "", "if", "input_size", ">", "0", ":", "\n", "                ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'gates_x_norm'", ")", ":", "\n", "                    ", "self", ".", "gates_x_norm", "=", "self", ".", "use_layer_norm", "(", "2", "*", "state_size", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'proposal_x_norm'", ")", ":", "\n", "                    ", "self", ".", "proposal_x_norm", "=", "self", ".", "use_layer_norm", "(", "state_size", ")", "\n", "\n", "# Create dropout masks for input values (reused at every timestep).", "\n", "", "", "", "if", "dropout_input", "==", "None", ":", "\n", "            ", "self", ".", "dropout_mask_input_to_gates", "=", "None", "\n", "self", ".", "dropout_mask_input_to_proposal", "=", "None", "\n", "", "else", ":", "\n", "            ", "ones", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "input_size", "]", ")", "\n", "self", ".", "dropout_mask_input_to_gates", "=", "dropout_input", "(", "ones", ")", "\n", "self", ".", "dropout_mask_input_to_proposal", "=", "dropout_input", "(", "ones", ")", "\n", "\n", "# Create dropout masks for state values (reused at every timestep).", "\n", "", "if", "dropout_state", "==", "None", ":", "\n", "            ", "self", ".", "dropout_mask_state_to_gates", "=", "None", "\n", "self", ".", "dropout_mask_state_to_proposal", "=", "None", "\n", "", "else", ":", "\n", "            ", "ones", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "state_size", "]", ")", "\n", "self", ".", "dropout_mask_state_to_gates", "=", "dropout_state", "(", "ones", ")", "\n", "self", ".", "dropout_mask_state_to_proposal", "=", "dropout_state", "(", "ones", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_gates_x": [[263, 273], ["layers.apply_dropout_mask", "layers.GRUStep._layer_norm_and_bias", "layers.matmul3d", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._layer_norm_and_bias", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.matmul3d"], ["", "", "def", "_get_gates_x", "(", "self", ",", "x", ",", "input_is_3d", "=", "False", ")", ":", "\n", "        ", "x", "=", "apply_dropout_mask", "(", "x", ",", "self", ".", "dropout_mask_input_to_gates", ",", "input_is_3d", ")", "\n", "if", "input_is_3d", ":", "\n", "            ", "gates_x", "=", "matmul3d", "(", "x", ",", "self", ".", "input_to_gates", ")", "\n", "", "else", ":", "\n", "            ", "gates_x", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "input_to_gates", ")", "\n", "", "return", "self", ".", "_layer_norm_and_bias", "(", "x", "=", "gates_x", ",", "\n", "b", "=", "self", ".", "gates_bias", ",", "\n", "layer_norm", "=", "self", ".", "gates_x_norm", ",", "\n", "x_is_input", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_gates_state": [[274, 282], ["layers.apply_dropout_mask", "tensorflow.matmul", "layers.GRUStep._layer_norm_and_bias"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._layer_norm_and_bias"], ["", "def", "_get_gates_state", "(", "self", ",", "prev_state", ")", ":", "\n", "        ", "prev_state", "=", "apply_dropout_mask", "(", "prev_state", ",", "\n", "self", ".", "dropout_mask_state_to_gates", ")", "\n", "gates_state", "=", "tf", ".", "matmul", "(", "prev_state", ",", "self", ".", "state_to_gates", ")", "\n", "return", "self", ".", "_layer_norm_and_bias", "(", "x", "=", "gates_state", ",", "\n", "b", "=", "self", ".", "gates_bias", ",", "\n", "layer_norm", "=", "self", ".", "gates_state_norm", ",", "\n", "x_is_input", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_proposal_x": [[283, 294], ["layers.apply_dropout_mask", "layers.GRUStep._layer_norm_and_bias", "layers.matmul3d", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._layer_norm_and_bias", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.matmul3d"], ["", "def", "_get_proposal_x", "(", "self", ",", "x", ",", "input_is_3d", "=", "False", ")", ":", "\n", "        ", "x", "=", "apply_dropout_mask", "(", "x", ",", "self", ".", "dropout_mask_input_to_proposal", ",", "\n", "input_is_3d", ")", "\n", "if", "input_is_3d", ":", "\n", "            ", "proposal_x", "=", "matmul3d", "(", "x", ",", "self", ".", "input_to_proposal", ")", "\n", "", "else", ":", "\n", "            ", "proposal_x", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "input_to_proposal", ")", "\n", "", "return", "self", ".", "_layer_norm_and_bias", "(", "x", "=", "proposal_x", ",", "\n", "b", "=", "self", ".", "proposal_bias", ",", "\n", "layer_norm", "=", "self", ".", "proposal_x_norm", ",", "\n", "x_is_input", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_proposal_state": [[295, 303], ["layers.apply_dropout_mask", "tensorflow.matmul", "layers.GRUStep._layer_norm_and_bias"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._layer_norm_and_bias"], ["", "def", "_get_proposal_state", "(", "self", ",", "prev_state", ")", ":", "\n", "        ", "prev_state", "=", "apply_dropout_mask", "(", "prev_state", ",", "\n", "self", ".", "dropout_mask_state_to_proposal", ")", "\n", "proposal_state", "=", "tf", ".", "matmul", "(", "prev_state", ",", "self", ".", "state_to_proposal", ")", "\n", "return", "self", ".", "_layer_norm_and_bias", "(", "x", "=", "proposal_state", ",", "\n", "b", "=", "self", ".", "proposal_bias", ",", "\n", "layer_norm", "=", "self", ".", "proposal_state_norm", ",", "\n", "x_is_input", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._layer_norm_and_bias": [[304, 319], ["layer_norm.forward", "layer_norm.forward", "layer_norm.forward", "layer_norm.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "def", "_layer_norm_and_bias", "(", "self", ",", "x", ",", "b", ",", "layer_norm", ",", "x_is_input", ")", ":", "\n", "        ", "if", "(", "self", ".", "legacy_bias_type", "==", "LegacyBiasType", ".", "THEANO_A", "\n", "or", "self", ".", "legacy_bias_type", "==", "LegacyBiasType", ".", "NEMATUS_COMPAT_FALSE", ")", ":", "\n", "            ", "if", "x_is_input", ":", "\n", "                ", "return", "layer_norm", ".", "forward", "(", "x", "+", "b", ")", "if", "self", ".", "use_layer_norm", "else", "x", "+", "b", "\n", "", "else", ":", "\n", "                ", "return", "layer_norm", ".", "forward", "(", "x", ")", "if", "self", ".", "use_layer_norm", "else", "x", "\n", "", "", "elif", "(", "self", ".", "legacy_bias_type", "==", "LegacyBiasType", ".", "THEANO_B", "\n", "or", "self", ".", "legacy_bias_type", "==", "LegacyBiasType", ".", "NEMATUS_COMPAT_TRUE", ")", ":", "\n", "            ", "if", "x_is_input", ":", "\n", "                ", "return", "layer_norm", ".", "forward", "(", "x", ")", "if", "self", ".", "use_layer_norm", "else", "x", "\n", "", "else", ":", "\n", "                ", "return", "layer_norm", ".", "forward", "(", "x", "+", "b", ")", "if", "self", ".", "use_layer_norm", "else", "x", "+", "b", "\n", "", "", "else", ":", "\n", "            ", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep.precompute_from_x": [[320, 328], ["layers.GRUStep._get_gates_x", "layers.GRUStep._get_proposal_x"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_gates_x", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_proposal_x"], ["", "", "def", "precompute_from_x", "(", "self", ",", "x", ")", ":", "\n", "# compute gates_x and proposal_x in one big matrix multiply", "\n", "# if x is fully known upfront ", "\n", "# this method exists only for efficiency reasons", "\n", "\n", "        ", "gates_x", "=", "self", ".", "_get_gates_x", "(", "x", ",", "input_is_3d", "=", "True", ")", "\n", "proposal_x", "=", "self", ".", "_get_proposal_x", "(", "x", ",", "input_is_3d", "=", "True", ")", "\n", "return", "gates_x", ",", "proposal_x", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep.forward": [[329, 370], ["tensorflow.nn.sigmoid", "tensorflow.split", "tensorflow.tanh", "layers.GRUStep._get_gates_x", "layers.GRUStep._get_proposal_x", "layers.GRUStep._get_gates_state", "layers.GRUStep._get_proposal_state"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_gates_x", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_proposal_x", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_gates_state", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStep._get_proposal_state"], ["", "def", "forward", "(", "self", ",", "\n", "prev_state", ",", "\n", "x", "=", "None", ",", "\n", "gates_x", "=", "None", ",", "\n", "gates_state", "=", "None", ",", "\n", "proposal_x", "=", "None", ",", "\n", "proposal_state", "=", "None", ")", ":", "\n", "        ", "if", "gates_x", "is", "None", "and", "x", "!=", "None", ":", "\n", "            ", "gates_x", "=", "self", ".", "_get_gates_x", "(", "x", ")", "\n", "", "if", "proposal_x", "is", "None", "and", "x", "!=", "None", ":", "\n", "            ", "proposal_x", "=", "self", ".", "_get_proposal_x", "(", "x", ")", "\n", "", "if", "gates_state", "is", "None", ":", "\n", "            ", "gates_state", "=", "self", ".", "_get_gates_state", "(", "prev_state", ")", "\n", "", "if", "proposal_state", "is", "None", ":", "\n", "            ", "proposal_state", "=", "self", ".", "_get_proposal_state", "(", "prev_state", ")", "\n", "\n", "", "if", "gates_x", "!=", "None", ":", "\n", "# level l = 0 in deep transition GRU", "\n", "            ", "gates", "=", "gates_x", "+", "gates_state", "\n", "", "else", ":", "\n", "# level l > 0 in deep transition GRU", "\n", "            ", "gates", "=", "gates_state", "\n", "if", "self", ".", "legacy_bias_type", "==", "LegacyBiasType", ".", "THEANO_A", ":", "\n", "                ", "gates", "+=", "self", ".", "gates_bias", "\n", "", "", "gates", "=", "tf", ".", "nn", ".", "sigmoid", "(", "gates", ")", "\n", "read_gate", ",", "update_gate", "=", "tf", ".", "split", "(", "gates", ",", "\n", "num_or_size_splits", "=", "2", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "proposal", "=", "proposal_state", "*", "read_gate", "\n", "if", "proposal_x", "!=", "None", ":", "\n", "# level l = 0 in deep transition GRU", "\n", "            ", "proposal", "+=", "proposal_x", "\n", "", "else", ":", "\n", "# level l > 0 in deep transition GRU", "\n", "            ", "if", "self", ".", "legacy_bias_type", "==", "LegacyBiasType", ".", "THEANO_A", ":", "\n", "                ", "proposal", "+=", "self", ".", "proposal_bias", "\n", "", "", "proposal", "=", "tf", ".", "tanh", "(", "proposal", ")", "\n", "new_state", "=", "update_gate", "*", "prev_state", "+", "(", "1", "-", "update_gate", ")", "*", "proposal", "\n", "\n", "return", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.DeepTransitionGRUStep.__init__": [[372, 393], ["range", "layers.DeepTransitionGRUStep.gru_steps.append", "tensorflow.compat.v1.variable_scope", "layers.GRUStep", "var_scope_fn"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_size", ",", "\n", "state_size", ",", "\n", "batch_size", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "legacy_bias_type", "=", "LegacyBiasType", ".", "NEMATUS_COMPAT_FALSE", ",", "\n", "dropout_input", "=", "None", ",", "\n", "dropout_state", "=", "None", ",", "\n", "transition_depth", "=", "1", ",", "\n", "var_scope_fn", "=", "lambda", "i", ":", "\"gru{0}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "        ", "self", ".", "gru_steps", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "transition_depth", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "var_scope_fn", "(", "i", ")", ")", ":", "\n", "                ", "gru", "=", "GRUStep", "(", "input_size", "=", "(", "input_size", "if", "i", "==", "0", "else", "0", ")", ",", "\n", "state_size", "=", "state_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "use_layer_norm", ",", "\n", "legacy_bias_type", "=", "legacy_bias_type", ",", "\n", "dropout_input", "=", "(", "dropout_input", "if", "i", "==", "0", "else", "None", ")", ",", "\n", "dropout_state", "=", "dropout_state", ")", "\n", "", "self", ".", "gru_steps", ".", "append", "(", "gru", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.DeepTransitionGRUStep.precompute_from_x": [[394, 396], ["layers.DeepTransitionGRUStep.gru_steps[].precompute_from_x"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.DeepTransitionGRUStep.precompute_from_x"], ["", "", "def", "precompute_from_x", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "gru_steps", "[", "0", "]", ".", "precompute_from_x", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.DeepTransitionGRUStep.forward": [[397, 413], ["layers.DeepTransitionGRUStep.gru_steps[].forward", "gru_step.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "def", "forward", "(", "self", ",", "\n", "prev_state", ",", "\n", "x", "=", "None", ",", "\n", "gates_x", "=", "None", ",", "\n", "gates_state", "=", "None", ",", "\n", "proposal_x", "=", "None", ",", "\n", "proposal_state", "=", "None", ")", ":", "\n", "        ", "new_state", "=", "self", ".", "gru_steps", "[", "0", "]", ".", "forward", "(", "prev_state", "=", "prev_state", ",", "\n", "x", "=", "x", ",", "\n", "gates_x", "=", "gates_x", ",", "\n", "gates_state", "=", "gates_state", ",", "\n", "proposal_x", "=", "proposal_x", ",", "\n", "proposal_state", "=", "proposal_state", ")", "\n", "for", "gru_step", "in", "self", ".", "gru_steps", "[", "1", ":", "]", ":", "\n", "            ", "new_state", "=", "gru_step", ".", "forward", "(", "prev_state", "=", "new_state", ")", "\n", "", "return", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStack.__init__": [[416, 451], ["range", "tensorflow.compat.v1.variable_scope", "layers.GRUStack.grus.append", "layers.DeepTransitionGRUStep"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_size", ",", "\n", "state_size", ",", "\n", "batch_size", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "legacy_bias_type", "=", "LegacyBiasType", ".", "NEMATUS_COMPAT_FALSE", ",", "\n", "dropout_input", "=", "None", ",", "\n", "dropout_state", "=", "None", ",", "\n", "stack_depth", "=", "1", ",", "\n", "transition_depth", "=", "1", ",", "\n", "alternating", "=", "False", ",", "\n", "reverse_alternation", "=", "False", ",", "\n", "context_state_size", "=", "0", ",", "\n", "residual_connections", "=", "False", ",", "\n", "first_residual_output", "=", "0", ")", ":", "\n", "        ", "self", ".", "state_size", "=", "state_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "alternating", "=", "alternating", "\n", "self", ".", "reverse_alternation", "=", "reverse_alternation", "\n", "self", ".", "context_state_size", "=", "context_state_size", "\n", "self", ".", "residual_connections", "=", "residual_connections", "\n", "self", ".", "first_residual_output", "=", "first_residual_output", "\n", "self", ".", "grus", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "stack_depth", ")", ":", "\n", "            ", "in_size", "=", "(", "input_size", "if", "i", "==", "0", "else", "state_size", ")", "+", "context_state_size", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"level{0}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "                ", "self", ".", "grus", ".", "append", "(", "DeepTransitionGRUStep", "(", "\n", "input_size", "=", "in_size", ",", "\n", "state_size", "=", "state_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "use_layer_norm", ",", "\n", "legacy_bias_type", "=", "legacy_bias_type", ",", "\n", "dropout_input", "=", "(", "dropout_input", "if", "i", "==", "0", "else", "dropout_state", ")", ",", "\n", "dropout_state", "=", "dropout_state", ",", "\n", "transition_depth", "=", "transition_depth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStack.forward_single": [[453, 467], ["len", "range", "layers.GRUStack.grus[].forward", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "", "def", "forward_single", "(", "self", ",", "prev_states", ",", "x", ",", "context", "=", "None", ")", ":", "\n", "        ", "stack_depth", "=", "len", "(", "self", ".", "grus", ")", "\n", "states", "=", "[", "None", "]", "*", "stack_depth", "\n", "for", "i", "in", "range", "(", "stack_depth", ")", ":", "\n", "            ", "if", "context", "==", "None", ":", "\n", "                ", "x2", "=", "x", "\n", "", "else", ":", "\n", "                ", "x2", "=", "tf", ".", "concat", "(", "[", "x", ",", "context", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "states", "[", "i", "]", "=", "self", ".", "grus", "[", "i", "]", ".", "forward", "(", "prev_states", "[", "i", "]", ",", "x2", ")", "\n", "if", "not", "self", ".", "residual_connections", "or", "i", "<", "self", ".", "first_residual_output", ":", "\n", "                ", "x", "=", "states", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "x", "+=", "states", "[", "i", "]", "\n", "", "", "return", "x", ",", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.GRUStack.forward": [[469, 530], ["enumerate", "tensorflow.zeros", "tensorflow.reverse", "tensorflow.expand_dims", "layers.RecurrentLayer", "gru.forward", "tensorflow.concat", "gru.precompute_from_x", "layers.RecurrentLayer.forward", "tensorflow.reverse", "gru.precompute_from_x", "layers.RecurrentLayer.forward", "tensorflow.reverse", "len", "layers.GRUStack.forward.create_step_fun"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.DeepTransitionGRUStep.precompute_from_x", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.DeepTransitionGRUStep.precompute_from_x", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_mask", "=", "None", ",", "context_layer", "=", "None", ",", "init_state", "=", "None", ")", ":", "\n", "\n", "        ", "assert", "not", "(", "self", ".", "reverse_alternation", "and", "x_mask", "==", "None", ")", "\n", "\n", "#        assert (context_layer == None or", "\n", "#                tf.shape(context_layer)[-1] == self.context_state_size)", "\n", "\n", "def", "create_step_fun", "(", "gru", ")", ":", "\n", "            ", "def", "step_fn", "(", "prev_state", ",", "x", ")", ":", "\n", "                ", "gates_x2d", ",", "proposal_x2d", "=", "x", "[", "0", "]", ",", "x", "[", "1", "]", "\n", "new_state", "=", "gru", ".", "forward", "(", "prev_state", ",", "\n", "gates_x", "=", "gates_x2d", ",", "\n", "proposal_x", "=", "proposal_x2d", ")", "\n", "if", "len", "(", "x", ")", ">", "2", ":", "\n", "                    ", "mask", "=", "x", "[", "2", "]", "\n", "new_state", "*=", "mask", "# batch x 1", "\n", "# first couple of states of reversed encoder should be zero", "\n", "# this is why we need to multiply by mask", "\n", "# this way, when the reversed encoder reaches actual words", "\n", "# the state will be zeros and not some accumulated garbage", "\n", "", "return", "new_state", "\n", "", "return", "step_fn", "\n", "\n", "", "if", "init_state", "is", "None", ":", "\n", "            ", "init_state", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "self", ".", "batch_size", ",", "self", ".", "state_size", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "if", "x_mask", "!=", "None", ":", "\n", "            ", "x_mask_r", "=", "tf", ".", "reverse", "(", "x_mask", ",", "axis", "=", "[", "0", "]", ")", "\n", "x_mask_bwd", "=", "tf", ".", "expand_dims", "(", "x_mask_r", ",", "axis", "=", "[", "2", "]", ")", "#seqLen x batch x 1", "\n", "\n", "", "for", "i", ",", "gru", "in", "enumerate", "(", "self", ".", "grus", ")", ":", "\n", "            ", "layer", "=", "RecurrentLayer", "(", "initial_state", "=", "init_state", ",", "\n", "step_fn", "=", "create_step_fun", "(", "gru", ")", ")", "\n", "if", "context_layer", "==", "None", ":", "\n", "                ", "x2", "=", "x", "\n", "", "else", ":", "\n", "                ", "x2", "=", "tf", ".", "concat", "(", "[", "x", ",", "context_layer", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "if", "not", "self", ".", "alternating", ":", "\n", "                ", "left_to_right", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "reverse_alternation", ":", "\n", "                    ", "left_to_right", "=", "(", "i", "%", "2", "==", "1", ")", "\n", "", "else", ":", "\n", "                    ", "left_to_right", "=", "(", "i", "%", "2", "==", "0", ")", "\n", "", "", "if", "left_to_right", ":", "\n", "# Recurrent state flows from left to right in this layer.", "\n", "                ", "gates_x", ",", "proposal_x", "=", "gru", ".", "precompute_from_x", "(", "x2", ")", "\n", "h", "=", "layer", ".", "forward", "(", "(", "gates_x", ",", "proposal_x", ")", ")", "\n", "", "else", ":", "\n", "# Recurrent state flows from right to left in this layer.", "\n", "                ", "x2_reversed", "=", "tf", ".", "reverse", "(", "x2", ",", "axis", "=", "[", "0", "]", ")", "\n", "gates_x", ",", "proposal_x", "=", "gru", ".", "precompute_from_x", "(", "x2_reversed", ")", "\n", "h_reversed", "=", "layer", ".", "forward", "(", "(", "gates_x", ",", "proposal_x", ",", "x_mask_bwd", ")", ")", "\n", "h", "=", "tf", ".", "reverse", "(", "h_reversed", ",", "axis", "=", "[", "0", "]", ")", "\n", "# Compute the word states, which will become the input for the", "\n", "# next layer (or the output of the stack if we're at the top).", "\n", "", "if", "not", "self", ".", "residual_connections", "or", "i", "<", "self", ".", "first_residual_output", ":", "\n", "                ", "x", "=", "h", "\n", "", "else", ":", "\n", "                ", "x", "+=", "h", "# Residual connection", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.AttentionStep.__init__": [[533, 588], ["initializers.norm_weight", "tensorflow.compat.v1.get_variable", "initializers.norm_weight", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "initializers.norm_weight", "tensorflow.compat.v1.get_variable", "layers.apply_dropout_mask", "layers.matmul3d", "tensorflow.shape", "tensorflow.ones", "dropout_context", "tensorflow.ones", "dropout_state", "layers.AttentionStep.hidden_context_norm.forward", "tensorflow.compat.v1.variable_scope", "layers.AttentionStep.use_layer_norm", "tensorflow.compat.v1.variable_scope", "layers.AttentionStep.use_layer_norm"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.matmul3d", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["    ", "def", "__init__", "(", "self", ",", "\n", "context", ",", "\n", "context_state_size", ",", "\n", "context_mask", ",", "\n", "state_size", ",", "\n", "hidden_size", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "dropout_context", "=", "None", ",", "\n", "dropout_state", "=", "None", ")", ":", "\n", "        ", "init", "=", "initializers", ".", "norm_weight", "(", "state_size", ",", "hidden_size", ")", "\n", "self", ".", "state_to_hidden", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'state_to_hidden'", ",", "\n", "initializer", "=", "init", ")", "\n", "#TODO: Nematus uses ortho_weight here - important?", "\n", "init", "=", "initializers", ".", "norm_weight", "(", "context_state_size", ",", "hidden_size", ")", "\n", "self", ".", "context_to_hidden", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'context_to_hidden'", ",", "\n", "initializer", "=", "init", ")", "\n", "self", ".", "hidden_bias", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'hidden_bias'", ",", "[", "hidden_size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", ")", "\n", "init", "=", "initializers", ".", "norm_weight", "(", "hidden_size", ",", "1", ")", "\n", "self", ".", "hidden_to_score", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'hidden_to_score'", ",", "\n", "initializer", "=", "init", ")", "\n", "self", ".", "use_layer_norm", "=", "use_layer_norm", "\n", "if", "self", ".", "use_layer_norm", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'hidden_context_norm'", ")", ":", "\n", "                ", "self", ".", "hidden_context_norm", "=", "self", ".", "use_layer_norm", "(", "layer_size", "=", "hidden_size", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'hidden_state_norm'", ")", ":", "\n", "                ", "self", ".", "hidden_state_norm", "=", "self", ".", "use_layer_norm", "(", "layer_size", "=", "hidden_size", ")", "\n", "", "", "self", ".", "context", "=", "context", "\n", "self", ".", "context_mask", "=", "context_mask", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "input", "=", "context", ")", "[", "1", "]", "\n", "\n", "# Create a dropout mask for context values (reused at every timestep).", "\n", "if", "dropout_context", "==", "None", ":", "\n", "            ", "self", ".", "dropout_mask_context_to_hidden", "=", "None", "\n", "", "else", ":", "\n", "            ", "ones", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "context_state_size", "]", ")", "\n", "self", ".", "dropout_mask_context_to_hidden", "=", "dropout_context", "(", "ones", ")", "\n", "\n", "# Create a dropout mask for state values (reused at every timestep).", "\n", "", "if", "dropout_state", "==", "None", ":", "\n", "            ", "self", ".", "dropout_mask_state_to_hidden", "=", "None", "\n", "", "else", ":", "\n", "            ", "ones", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "state_size", "]", ")", "\n", "self", ".", "dropout_mask_state_to_hidden", "=", "dropout_state", "(", "ones", ")", "\n", "\n", "# precompute these activations, they are the same at each step", "\n", "# Ideally the compiler would have figured out that too", "\n", "", "context", "=", "apply_dropout_mask", "(", "context", ",", "\n", "self", ".", "dropout_mask_context_to_hidden", ",", "True", ")", "\n", "self", ".", "hidden_from_context", "=", "matmul3d", "(", "context", ",", "self", ".", "context_to_hidden", ")", "\n", "self", ".", "hidden_from_context", "+=", "self", ".", "hidden_bias", "\n", "if", "self", ".", "use_layer_norm", ":", "\n", "            ", "self", ".", "hidden_from_context", "=", "self", ".", "hidden_context_norm", ".", "forward", "(", "self", ".", "hidden_from_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.AttentionStep.forward": [[589, 612], ["layers.apply_dropout_mask", "tensorflow.matmul", "tensorflow.nn.tanh", "layers.matmul3d", "tensorflow.squeeze", "tensorflow.exp", "tensorflow.reduce_sum", "layers.AttentionStep.hidden_state_norm.forward", "tensorflow.reduce_max", "tensorflow.reduce_sum", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.matmul3d", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "forward", "(", "self", ",", "prev_state", ")", ":", "\n", "        ", "prev_state", "=", "apply_dropout_mask", "(", "prev_state", ",", "\n", "self", ".", "dropout_mask_state_to_hidden", ")", "\n", "hidden_from_state", "=", "tf", ".", "matmul", "(", "prev_state", ",", "self", ".", "state_to_hidden", ")", "\n", "if", "self", ".", "use_layer_norm", ":", "\n", "            ", "hidden_from_state", "=", "self", ".", "hidden_state_norm", ".", "forward", "(", "hidden_from_state", ")", "\n", "", "hidden", "=", "self", ".", "hidden_from_context", "+", "hidden_from_state", "\n", "hidden", "=", "tf", ".", "nn", ".", "tanh", "(", "hidden", ")", "\n", "# context has shape seqLen x batch x context_state_size", "\n", "# mask has shape seqLen x batch", "\n", "\n", "scores", "=", "matmul3d", "(", "hidden", ",", "self", ".", "hidden_to_score", ")", "# seqLen x batch x 1", "\n", "scores", "=", "tf", ".", "squeeze", "(", "scores", ",", "axis", "=", "2", ")", "\n", "scores", "=", "scores", "-", "tf", ".", "reduce_max", "(", "input_tensor", "=", "scores", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "scores", "=", "tf", ".", "exp", "(", "scores", ")", "\n", "scores", "*=", "self", ".", "context_mask", "\n", "scores", "=", "scores", "/", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "scores", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "\n", "attention_context", "=", "self", ".", "context", "*", "tf", ".", "expand_dims", "(", "scores", ",", "axis", "=", "2", ")", "\n", "attention_context", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "attention_context", ",", "axis", "=", "0", ",", "keepdims", "=", "False", ")", "\n", "\n", "return", "attention_context", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.Masked_cross_entropy_loss.__init__": [[614, 627], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "y_true", ",", "\n", "y_mask", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "training", "=", "False", ")", ":", "\n", "        ", "self", ".", "y_true", "=", "y_true", "\n", "self", ".", "y_mask", "=", "y_mask", "\n", "\n", "if", "label_smoothing", ":", "\n", "           ", "self", ".", "label_smoothing", "=", "True", "\n", "self", ".", "smoothing_factor", "=", "label_smoothing", "\n", "", "else", ":", "\n", "           ", "self", ".", "label_smoothing", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.Masked_cross_entropy_loss.forward": [[629, 648], ["tensorflow.reduce_sum", "tensorflow.one_hot", "tensorflow.compat.v1.losses.softmax_cross_entropy", "tensorflow.compat.v1.losses.sparse_softmax_cross_entropy", "tensorflow.cast", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "logits", ")", ":", "\n", "        ", "if", "self", ".", "label_smoothing", ":", "\n", "            ", "uniform_prob", "=", "self", ".", "smoothing_factor", "/", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "input", "=", "logits", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "\n", "smoothed_prob", "=", "1.0", "-", "self", ".", "smoothing_factor", "+", "uniform_prob", "\n", "onehot_labels", "=", "tf", ".", "one_hot", "(", "self", ".", "y_true", ",", "tf", ".", "shape", "(", "input", "=", "logits", ")", "[", "-", "1", "]", ",", "on_value", "=", "smoothed_prob", ",", "off_value", "=", "uniform_prob", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "cost", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "softmax_cross_entropy", "(", "\n", "onehot_labels", "=", "onehot_labels", ",", "\n", "logits", "=", "logits", ",", "\n", "weights", "=", "self", ".", "y_mask", ",", "\n", "reduction", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "Reduction", ".", "NONE", ")", "\n", "", "else", ":", "\n", "            ", "cost", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "sparse_softmax_cross_entropy", "(", "\n", "labels", "=", "self", ".", "y_true", ",", "\n", "logits", "=", "logits", ",", "\n", "weights", "=", "self", ".", "y_mask", ",", "\n", "reduction", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "Reduction", ".", "NONE", ")", "\n", "\n", "", "cost", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "cost", ",", "axis", "=", "0", ",", "keepdims", "=", "False", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.LexicalModel.__init__": [[650, 670], ["layers.FeedForwardLayer", "tensorflow.ones", "dropout_embedding"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "in_size", ",", "\n", "out_size", ",", "\n", "batch_size", ",", "\n", "use_layer_norm", "=", "False", ",", "\n", "dropout_embedding", "=", "None", ",", "\n", "dropout_hidden", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "ff", "=", "FeedForwardLayer", "(", "\n", "in_size", "=", "in_size", ",", "\n", "out_size", "=", "out_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "use_layer_norm", ",", "\n", "dropout_input", "=", "dropout_hidden", ")", "\n", "\n", "if", "dropout_embedding", "is", "None", ":", "\n", "            ", "self", ".", "dropout_mask_embedding", "=", "None", "\n", "", "else", ":", "\n", "            ", "ones", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "in_size", "]", ")", "\n", "self", ".", "dropout_mask_embedding", "=", "dropout_embedding", "(", "ones", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.LexicalModel.forward": [[671, 678], ["layers.apply_dropout_mask", "tensorflow.nn.tanh", "tensorflow.expand_dims", "tensorflow.reduce_sum", "layers.LexicalModel.ff.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "forward", "(", "self", ",", "x_embs", ",", "att_alphas", ",", "multi_step", "=", "False", ")", ":", "\n", "        ", "x_embs", "=", "apply_dropout_mask", "(", "x_embs", ",", "self", ".", "dropout_mask_embedding", ",", "input_is_3d", "=", "True", ")", "\n", "x_emb_weighted", "=", "x_embs", "*", "tf", ".", "expand_dims", "(", "att_alphas", ",", "axis", "=", "(", "3", "if", "multi_step", "else", "2", ")", ")", "\n", "x_emb_weighted", "=", "tf", ".", "nn", ".", "tanh", "(", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "x_emb_weighted", ",", "axis", "=", "(", "1", "if", "multi_step", "else", "0", ")", ",", "keepdims", "=", "False", ")", ")", "\n", "lexical_state", "=", "self", ".", "ff", ".", "forward", "(", "x_emb_weighted", ",", "input_is_3d", "=", "multi_step", ")", "+", "x_emb_weighted", "\n", "\n", "return", "lexical_state", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.__init__": [[680, 685], ["tensorflow.compat.v1.get_variable", "tensorflow.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "in_size", ",", "\n", "initial_slope", "=", "1.0", ")", ":", "\n", "        ", "init", "=", "initial_slope", "*", "tf", ".", "ones", "(", "[", "in_size", "]", ")", "\n", "self", ".", "slope", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'slope'", ",", "initializer", "=", "init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward": [[686, 691], ["tensorflow.nn.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "pos", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "neg", "=", "x", "-", "pos", "\n", "y", "=", "pos", "+", "self", ".", "slope", "*", "neg", "\n", "return", "y", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.matmul3d": [[43, 50], ["tensorflow.shape", "tensorflow.shape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape"], "function", ["None"], ["", "def", "matmul3d", "(", "x3d", ",", "matrix", ")", ":", "\n", "    ", "shape", "=", "tf", ".", "shape", "(", "input", "=", "x3d", ")", "\n", "mat_shape", "=", "tf", ".", "shape", "(", "input", "=", "matrix", ")", "\n", "x2d", "=", "tf", ".", "reshape", "(", "x3d", ",", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "result2d", "=", "tf", ".", "matmul", "(", "x2d", ",", "matrix", ")", "\n", "result3d", "=", "tf", ".", "reshape", "(", "result2d", ",", "[", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "mat_shape", "[", "1", "]", "]", ")", "\n", "return", "result3d", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.apply_dropout_mask": [[51, 60], ["tensorflow.expand_dims", "tensorflow.tile", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.shape"], "function", ["None"], ["", "def", "apply_dropout_mask", "(", "x", ",", "mask", ",", "input_is_3d", "=", "False", ")", ":", "\n", "    ", "if", "mask", "==", "None", ":", "\n", "        ", "return", "x", "\n", "", "if", "input_is_3d", ":", "\n", "        ", "mask_3d", "=", "tf", ".", "expand_dims", "(", "mask", ",", "0", ")", "\n", "mask_3d", "=", "tf", ".", "tile", "(", "mask_3d", ",", "[", "tf", ".", "shape", "(", "input", "=", "x", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "return", "tf", ".", "multiply", "(", "x", ",", "mask_3d", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "multiply", "(", "x", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater.__init__": [[35, 73], ["model_updater._ModelUpdateGraph", "len", "len", "BeamSearchSampler", "RandomSampler", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "config", ",", "num_gpus", ",", "replicas", ",", "optimizer", ",", "global_step", ",", "\n", "summary_writer", "=", "None", ")", ":", "\n", "        ", "\"\"\"Builds TF graph nodes for model updating (via _ModelUpdateGraph).\n\n        Args:\n            config: the model config (an argparse.Namespace)\n            num_gpus: the number of available GPUs.\n            replicas: a list of RNNModel or Transformer objects.\n            optimizer: a TensorFlow optimizer.\n            global_step: a tf.Variable to be updated by optimizer.\n            summary_writer: a tf.summary.FileWriter object.\n        \"\"\"", "\n", "assert", "len", "(", "replicas", ")", ">", "0", "\n", "\n", "assert", "(", "len", "(", "replicas", ")", "==", "num_gpus", "\n", "or", "(", "len", "(", "replicas", ")", "==", "1", "and", "num_gpus", "==", "0", ")", ")", "\n", "\n", "self", ".", "_config", "=", "config", "\n", "self", ".", "_replicas", "=", "replicas", "\n", "self", ".", "_summary_writer", "=", "summary_writer", "\n", "\n", "self", ".", "_graph", "=", "_ModelUpdateGraph", "(", "config", ",", "num_gpus", ",", "replicas", ",", "optimizer", ",", "\n", "global_step", ")", "\n", "\n", "if", "config", ".", "loss_function", "==", "'MRT'", ":", "\n", "            ", "if", "config", ".", "sample_way", "==", "'beam_search'", ":", "\n", "                ", "self", ".", "_mrt_sampler", "=", "BeamSearchSampler", "(", "\n", "models", "=", "[", "replicas", "[", "0", "]", "]", ",", "\n", "configs", "=", "[", "config", "]", ",", "\n", "beam_size", "=", "config", ".", "samplesN", ")", "\n", "", "else", ":", "\n", "                ", "assert", "config", ".", "sample_way", "==", "'randomly_sample'", "\n", "# Set beam_size to config.samplesN instead of using", "\n", "#      np.repeat to expand input in full_sampler()", "\n", "self", ".", "_mrt_sampler", "=", "RandomSampler", "(", "\n", "models", "=", "[", "replicas", "[", "0", "]", "]", ",", "\n", "configs", "=", "[", "config", "]", ",", "\n", "beam_size", "=", "config", ".", "samplesN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater.update": [[75, 194], ["range", "mru.full_sampler", "mru.cal_metrics_score", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "model_updater.ModelUpdater._split_minibatch_for_device_size", "model_updater.ModelUpdater._split_minibatch_into_n", "model_updater.ModelUpdater._split_and_pad_minibatch_mrt", "model_updater.ModelUpdater._split_and_pad_minibatch", "len", "len", "range", "session.run", "len", "sum", "len", "session.run", "session.run", "range", "session.run", "session.run", "model_updater.ModelUpdater._summary_writer.add_summary", "len", "print_pro.append", "[].tolist"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.mrt_utils.full_sampler", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.mrt_utils.cal_metrics_score", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater._split_minibatch_for_device_size", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater._split_minibatch_into_n", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater._split_and_pad_minibatch_mrt", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater._split_and_pad_minibatch"], ["", "", "", "def", "update", "(", "self", ",", "session", ",", "x", ",", "x_mask", ",", "y", ",", "y_mask", ",", "num_to_target", ",", "\n", "write_summary", ")", ":", "\n", "        ", "\"\"\"Updates the model for a single minibatch.\n\n        Args:\n            x: Numpy array with shape (factors, seq_len, batch_size)\n            x_mask: Numpy array with shape (seq_len, batch_size)\n            y: Numpy array with shape (seq_len, batch_size)\n            y_mask: Numpy array with shape (seq_len, batch_size)\n            num_to_target: dictionary used for MRT training\n            write_summary: Boolean\n\n        Returns:\n            The sum of the individual sentence losses. The loss for a sentence\n            is the sentence-level or token-level cross entropy, optionally with\n            L2 or MAP-L2 regularization.\n        \"\"\"", "\n", "\n", "# Split the minibatch into sub-batches. The number of sub-batches is", "\n", "# determined based on either the per-device size limit, if set, or on", "\n", "# a fixed number of aggregation steps (which defaults to 1).", "\n", "#", "\n", "# If necessary, dummy sub-batches are added to get a multiple of the", "\n", "# number of replicas, since each replica has to receive some input (the", "\n", "# dummy sub-batches will have a weight of zero).", "\n", "\n", "index", "=", "None", "\n", "if", "self", ".", "_config", ".", "loss_function", "==", "'MRT'", ":", "\n", "# Generate candidate sentences (sampling) based on source sentences in each minibatch", "\n", "# outputs are 'sampleN' times larger than inputs", "\n", "# replica only use single model since multi-GPU sampling isn't supported in Transformer", "\n", "            ", "x", ",", "x_mask", ",", "y", ",", "y_mask", ",", "refs", ",", "index", "=", "mru", ".", "full_sampler", "(", "self", ".", "_replicas", "[", "0", "]", ",", "self", ".", "_mrt_sampler", ",", "session", ",", "\n", "self", ".", "_config", ",", "x", ",", "x_mask", ",", "y", ",", "y_mask", ")", "\n", "\n", "# calculate evaluation metrics score for each sampled candidate sentence", "\n", "score", "=", "mru", ".", "cal_metrics_score", "(", "y", ",", "self", ".", "_config", ",", "num_to_target", ",", "refs", ",", "index", ")", "\n", "# convert list to numpy list", "\n", "x", "=", "numpy", ".", "array", "(", "x", ")", "\n", "x_mask", "=", "numpy", ".", "array", "(", "x_mask", ")", "\n", "y", "=", "numpy", ".", "array", "(", "y", ")", "\n", "y_mask", "=", "numpy", ".", "array", "(", "y_mask", ")", "\n", "\n", "", "if", "(", "self", ".", "_config", ".", "max_sentences_per_device", "!=", "0", "\n", "or", "self", ".", "_config", ".", "max_tokens_per_device", "!=", "0", ")", ":", "\n", "            ", "start_points", "=", "self", ".", "_split_minibatch_for_device_size", "(", "\n", "x_mask", ",", "y_mask", ",", "self", ".", "_config", ".", "max_sentences_per_device", ",", "\n", "self", ".", "_config", ".", "max_tokens_per_device", ",", "index", ")", "\n", "", "else", ":", "\n", "            ", "n", "=", "len", "(", "self", ".", "_replicas", ")", "*", "self", ".", "_config", ".", "gradient_aggregation_steps", "\n", "start_points", "=", "self", ".", "_split_minibatch_into_n", "(", "x_mask", ",", "y_mask", ",", "n", ")", "\n", "\n", "", "if", "self", ".", "_config", ".", "loss_function", "==", "'MRT'", ":", "\n", "            ", "split_x", ",", "split_x_mask", ",", "split_y", ",", "split_y_mask", ",", "split_score", ",", "weights", ",", "split_index", "=", "self", ".", "_split_and_pad_minibatch_mrt", "(", "x", ",", "x_mask", ",", "y", ",", "y_mask", ",", "score", ",", "start_points", ",", "index", ")", "\n", "", "else", ":", "\n", "            ", "split_x", ",", "split_x_mask", ",", "split_y", ",", "split_y_mask", ",", "weights", "=", "self", ".", "_split_and_pad_minibatch", "(", "x", ",", "x_mask", ",", "y", ",", "y_mask", ",", "start_points", ")", "\n", "\n", "# Normalize the weights so that _ModelUpdateGraph can just sum the", "\n", "# weighted gradients from each sub-batch (without needing a", "\n", "# subsequent division step).", "\n", "", "normalized_weights", "=", "[", "w", "/", "sum", "(", "weights", ")", "for", "w", "in", "weights", "]", "\n", "\n", "# Scale the weights so that short minibatches (e.g. at the end of", "\n", "# maxibatches) contribute less.", "\n", "if", "self", ".", "_config", ".", "token_batch_size", "==", "0", ":", "\n", "# Actual batch size / Max batch size, in sentences", "\n", "            ", "scaling_factor", "=", "x", ".", "shape", "[", "-", "1", "]", "/", "self", ".", "_config", ".", "batch_size", "\n", "", "else", ":", "\n", "# Actual batch size / Max batch size, in tokens", "\n", "            ", "scaling_factor", "=", "(", "x_mask", ".", "shape", "[", "0", "]", "*", "x_mask", ".", "shape", "[", "1", "]", ")", "/", "self", ".", "_config", ".", "token_batch_size", "\n", "\n", "# Accumulate gradients.", "\n", "# the list to store the per-token-probability if required", "\n", "", "print_pro", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "split_x", ")", ",", "len", "(", "self", ".", "_replicas", ")", ")", ":", "\n", "            ", "feed_dict", "=", "{", "}", "\n", "feed_dict", "[", "self", ".", "_graph", ".", "scaling_factor", "]", "=", "scaling_factor", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "_replicas", ")", ")", ":", "\n", "                ", "feed_dict", "[", "self", ".", "_graph", ".", "replica_weights", "[", "j", "]", "]", "=", "normalized_weights", "[", "i", "+", "j", "]", "\n", "feed_dict", "[", "self", ".", "_replicas", "[", "j", "]", ".", "inputs", ".", "x", "]", "=", "split_x", "[", "i", "+", "j", "]", "\n", "feed_dict", "[", "self", ".", "_replicas", "[", "j", "]", ".", "inputs", ".", "x_mask", "]", "=", "split_x_mask", "[", "i", "+", "j", "]", "\n", "feed_dict", "[", "self", ".", "_replicas", "[", "j", "]", ".", "inputs", ".", "y", "]", "=", "split_y", "[", "i", "+", "j", "]", "\n", "feed_dict", "[", "self", ".", "_replicas", "[", "j", "]", ".", "inputs", ".", "y_mask", "]", "=", "split_y_mask", "[", "i", "+", "j", "]", "\n", "if", "self", ".", "_config", ".", "loss_function", "==", "'MRT'", ":", "\n", "# convert evaluation score of each candidates into tensor for subsequent expected risk calculations", "\n", "                    ", "feed_dict", "[", "self", ".", "_replicas", "[", "j", "]", ".", "inputs", ".", "scores", "]", "=", "split_score", "[", "i", "+", "j", "]", "\n", "# also convey information of starting point of each source sentences to later calculation", "\n", "feed_dict", "[", "self", ".", "_replicas", "[", "j", "]", ".", "inputs", ".", "index", "]", "=", "split_index", "[", "i", "+", "j", "]", "\n", "", "feed_dict", "[", "self", ".", "_replicas", "[", "j", "]", ".", "inputs", ".", "training", "]", "=", "True", "\n", "\n", "", "if", "self", ".", "_config", ".", "print_per_token_pro", "==", "False", ":", "\n", "                ", "session", ".", "run", "(", "[", "self", ".", "_graph", ".", "accum_ops", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "", "else", ":", "\n", "                ", "tmp", "=", "session", ".", "run", "(", "[", "self", ".", "_graph", ".", "accum_ops", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "tmp", "[", "0", "]", ")", ")", ":", "\n", "                    ", "print_pro", ".", "append", "(", "tmp", "[", "0", "]", "[", "i", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "", "if", "self", ".", "_config", ".", "print_per_token_pro", "==", "False", ":", "\n", "# Apply the gradients (and optionally write the summary).", "\n", "            ", "if", "not", "write_summary", ":", "\n", "                ", "fetches", "=", "self", ".", "_graph", ".", "apply_ops", "\n", "global_step", ",", "apply_grads", ",", "mean_loss_per_sent", "=", "session", ".", "run", "(", "fetches", ")", "\n", "", "else", ":", "\n", "                ", "assert", "self", ".", "_summary_writer", "is", "not", "None", "\n", "fetches", "=", "self", ".", "_graph", ".", "apply_ops", "+", "self", ".", "_graph", ".", "summary_ops", "\n", "global_step", ",", "apply_grads", ",", "mean_loss_per_sent", ",", "merged_summary", "=", "session", ".", "run", "(", "fetches", ")", "\n", "self", ".", "_summary_writer", ".", "add_summary", "(", "merged_summary", ",", "global_step", ")", "\n", "\n", "# Reset accumulated values to zero ready for the next call.", "\n", "", "session", ".", "run", "(", "self", ".", "_graph", ".", "reset_ops", ")", "\n", "\n", "# Return the sum of the individual sentence losses.", "\n", "return", "mean_loss_per_sent", "*", "x", ".", "shape", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "return", "print_pro", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater._split_minibatch_into_n": [[195, 244], ["numpy.sum", "numpy.sum", "len", "math.ceil", "len", "len", "max", "max", "range", "start_points.append", "len", "max", "max"], "methods", ["None"], ["", "", "def", "_split_minibatch_into_n", "(", "self", ",", "x_mask", ",", "y_mask", ",", "n", ")", ":", "\n", "        ", "\"\"\"Determines how to split a minibatch into n equal-sized sub-batches.\n\n        The sub-batch size is (approximately) the minibatch size divided by n,\n        where size is defined as the number of source + target tokens.\n\n        Args:\n            x_mask: Numpy array with shape (seq_len, batch_size)\n            y_mask: Numpy array with shape (seq_len, batch_size)\n            n: int\n\n        Returns:\n            A list of indices representing the starting points of each\n            sub-batch.\n        \"\"\"", "\n", "\n", "source_lengths", "=", "numpy", ".", "sum", "(", "x_mask", ",", "axis", "=", "0", ")", "\n", "target_lengths", "=", "numpy", ".", "sum", "(", "y_mask", ",", "axis", "=", "0", ")", "\n", "assert", "len", "(", "source_lengths", ")", "==", "len", "(", "target_lengths", ")", "\n", "num_sents", "=", "len", "(", "source_lengths", ")", "\n", "\n", "# Calculate the source + target batch sizes, then divide by n to get", "\n", "# the max size of each sub-batch.", "\n", "s_total", "=", "max", "(", "source_lengths", ")", "*", "num_sents", "\n", "t_total", "=", "max", "(", "target_lengths", ")", "*", "num_sents", "\n", "soft_limit", "=", "math", ".", "ceil", "(", "(", "s_total", "+", "t_total", ")", "/", "n", ")", "\n", "\n", "start_points", "=", "[", "0", "]", "\n", "while", "True", ":", "\n", "            ", "i", "=", "start_points", "[", "-", "1", "]", "\n", "s_longest", "=", "source_lengths", "[", "i", "]", "\n", "t_longest", "=", "target_lengths", "[", "i", "]", "\n", "next_start_point", "=", "None", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ",", "num_sents", ")", ":", "\n", "                ", "s_longest", "=", "max", "(", "s_longest", ",", "source_lengths", "[", "j", "]", ")", "\n", "t_longest", "=", "max", "(", "t_longest", ",", "target_lengths", "[", "j", "]", ")", "\n", "s_tokens", "=", "s_longest", "*", "(", "j", "-", "i", "+", "1", ")", "\n", "t_tokens", "=", "t_longest", "*", "(", "j", "-", "i", "+", "1", ")", "\n", "if", "s_tokens", "+", "t_tokens", ">", "soft_limit", ":", "\n", "# Allow the sub-batch to be over-filled, but only by one", "\n", "# sentence worth of tokens.", "\n", "                    ", "next_start_point", "=", "j", "+", "1", "\n", "break", "\n", "", "", "if", "next_start_point", "is", "None", "or", "next_start_point", ">=", "num_sents", ":", "\n", "                ", "break", "\n", "", "start_points", ".", "append", "(", "next_start_point", ")", "\n", "\n", "", "assert", "len", "(", "start_points", ")", "<=", "n", "\n", "return", "start_points", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater._split_minibatch_for_device_size": [[245, 327], ["numpy.sum", "numpy.sum", "len", "dict", "len", "len", "list", "zip", "range", "list", "range", "list.append", "range", "list.append", "range", "max", "max", "max", "max", "len"], "methods", ["None"], ["", "def", "_split_minibatch_for_device_size", "(", "self", ",", "x_mask", ",", "y_mask", ",", "\n", "max_sents_per_device", "=", "0", ",", "\n", "max_tokens_per_device", "=", "0", ",", "index", "=", "None", ")", ":", "\n", "        ", "\"\"\"Determines how to split a minibatch into device-sized sub-batches.\n\n        Either max_sents_per_device or max_tokens_per_device must be given.\n\n        Args:\n            x_mask: Numpy array with shape (seq_len, batch_size)\n            y_mask: Numpy array with shape (seq_len, batch_size)\n            max_sents_per_device: int\n            max_tokens_per_device: int\n\n        Returns:\n            A list of indices representing the starting points of each\n            sub-batch.\n        \"\"\"", "\n", "\n", "assert", "max_sents_per_device", "==", "0", "or", "max_tokens_per_device", "==", "0", "\n", "assert", "not", "(", "max_sents_per_device", "==", "0", "and", "max_tokens_per_device", "==", "0", ")", "\n", "if", "index", "is", "not", "None", ":", "\n", "            ", "s_index", "=", "dict", "(", "zip", "(", "index", "[", "0", "]", ",", "list", "(", "range", "(", "len", "(", "index", "[", "0", "]", ")", ")", ")", ")", ")", "\n", "\n", "", "source_lengths", "=", "numpy", ".", "sum", "(", "x_mask", ",", "axis", "=", "0", ")", "\n", "target_lengths", "=", "numpy", ".", "sum", "(", "y_mask", ",", "axis", "=", "0", ")", "\n", "assert", "len", "(", "source_lengths", ")", "==", "len", "(", "target_lengths", ")", "\n", "num_sents", "=", "len", "(", "source_lengths", ")", "\n", "\n", "# Determine where to split the minibatch to produce sub-batches that", "\n", "# fit the device capacity.", "\n", "if", "max_sents_per_device", "!=", "0", ":", "\n", "            ", "start_points", "=", "list", "(", "range", "(", "0", ",", "num_sents", ",", "max_sents_per_device", ")", ")", "\n", "", "else", ":", "\n", "            ", "start_points", "=", "[", "0", "]", "\n", "if", "index", "is", "None", ":", "\n", "                ", "while", "True", ":", "\n", "                    ", "i", "=", "start_points", "[", "-", "1", "]", "\n", "s_longest", "=", "source_lengths", "[", "i", "]", "\n", "t_longest", "=", "target_lengths", "[", "i", "]", "\n", "next_start_point", "=", "None", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ",", "num_sents", ")", ":", "\n", "                        ", "s_longest", "=", "max", "(", "s_longest", ",", "source_lengths", "[", "j", "]", ")", "\n", "t_longest", "=", "max", "(", "t_longest", ",", "target_lengths", "[", "j", "]", ")", "\n", "s_tokens", "=", "s_longest", "*", "(", "j", "-", "i", "+", "1", ")", "\n", "t_tokens", "=", "t_longest", "*", "(", "j", "-", "i", "+", "1", ")", "\n", "if", "(", "s_tokens", ">", "max_tokens_per_device", "\n", "or", "t_tokens", ">", "max_tokens_per_device", ")", ":", "\n", "                            ", "next_start_point", "=", "j", "\n", "break", "\n", "", "", "if", "next_start_point", "is", "None", ":", "\n", "                        ", "break", "\n", "", "start_points", ".", "append", "(", "next_start_point", ")", "\n", "", "", "else", ":", "\n", "# split the dataset based on index points which indicates the index of each group of candidate", "\n", "# translations of MRT", "\n", "                ", "while", "True", ":", "\n", "                    ", "i", "=", "start_points", "[", "-", "1", "]", "\n", "s_longest", "=", "source_lengths", "[", "i", "]", "\n", "t_longest", "=", "target_lengths", "[", "i", "]", "\n", "next_start_point", "=", "None", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ",", "num_sents", ")", ":", "\n", "                        ", "s_longest", "=", "max", "(", "s_longest", ",", "source_lengths", "[", "j", "]", ")", "\n", "t_longest", "=", "max", "(", "t_longest", ",", "target_lengths", "[", "j", "]", ")", "\n", "s_tokens", "=", "s_longest", "*", "(", "j", "-", "i", "+", "1", ")", "\n", "t_tokens", "=", "t_longest", "*", "(", "j", "-", "i", "+", "1", ")", "\n", "if", "(", "s_tokens", ">", "max_tokens_per_device", "\n", "or", "t_tokens", ">", "max_tokens_per_device", ")", ":", "\n", "                            ", "if", "j", "in", "s_index", ":", "\n", "                                ", "next_start_point", "=", "j", "\n", "break", "\n", "", "else", ":", "\n", "                                ", "while", "True", ":", "\n", "                                    ", "j", "-=", "1", "\n", "if", "j", "in", "s_index", ":", "\n", "                                        ", "break", "\n", "", "", "next_start_point", "=", "j", "\n", "break", "\n", "", "", "", "if", "next_start_point", "is", "None", ":", "\n", "                        ", "break", "\n", "", "start_points", ".", "append", "(", "next_start_point", ")", "\n", "\n", "", "", "", "return", "start_points", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater._split_and_pad_minibatch": [[328, 400], ["model_updater.ModelUpdater._split_and_pad_minibatch.split_array"], "methods", ["None"], ["", "def", "_split_and_pad_minibatch", "(", "self", ",", "x", ",", "x_mask", ",", "y", ",", "y_mask", ",", "start_points", ")", ":", "\n", "        ", "\"\"\"Splits a minibatch according to a list of split points.\n\n        Args:\n            x: Numpy array with shape (factors, seq_len, batch_size)\n            x_mask: Numpy array with shape (seq_len, batch_size)\n            y: Numpy array with shape (seq_len, batch_size)\n            y_mask: Numpy array with shape (seq_len, batch_size)\n            start_points: list of zero-based indices\n\n        Returns:\n            Five lists: for each of x, x_mask, y, and y_mask, respectively,\n            a list is returned containing the split version. The fifth list\n            contains the (unnormalized) weights of the sub-batches.\n        \"\"\"", "\n", "\n", "# Split the individual arrays.", "\n", "\n", "def", "split_array", "(", "a", ",", "start_points", ")", ":", "\n", "            ", "batch_size", "=", "a", ".", "shape", "[", "-", "1", "]", "\n", "next_points", "=", "start_points", "[", "1", ":", "]", "+", "[", "batch_size", "]", "\n", "return", "[", "a", "[", "...", ",", "p", ":", "q", "]", "for", "p", ",", "q", "in", "zip", "(", "start_points", ",", "next_points", ")", "]", "\n", "\n", "", "split_x", "=", "split_array", "(", "x", ",", "start_points", ")", "\n", "split_x_mask", "=", "split_array", "(", "x_mask", ",", "start_points", ")", "\n", "split_y", "=", "split_array", "(", "y", ",", "start_points", ")", "\n", "split_y_mask", "=", "split_array", "(", "y_mask", ",", "start_points", ")", "\n", "\n", "# Trim arrays so that the seq_len dimension is equal to the longest", "\n", "# source / target sentence in the sub-batch (rather than the whole", "\n", "# minibatch).", "\n", "\n", "def", "trim_arrays", "(", "arrays", ",", "new_seq_lens", ")", ":", "\n", "            ", "return", "[", "a", "[", "...", ",", "0", ":", "l", ",", ":", "]", "for", "a", ",", "l", "in", "zip", "(", "arrays", ",", "new_seq_lens", ")", "]", "\n", "\n", "", "max_lens", "=", "[", "int", "(", "numpy", ".", "max", "(", "numpy", ".", "sum", "(", "m", ",", "axis", "=", "0", ")", ")", ")", "for", "m", "in", "split_x_mask", "]", "\n", "split_x", "=", "trim_arrays", "(", "split_x", ",", "max_lens", ")", "\n", "split_x_mask", "=", "trim_arrays", "(", "split_x_mask", ",", "max_lens", ")", "\n", "\n", "max_lens", "=", "[", "int", "(", "numpy", ".", "max", "(", "numpy", ".", "sum", "(", "m", ",", "axis", "=", "0", ")", ")", ")", "for", "m", "in", "split_y_mask", "]", "\n", "split_y", "=", "trim_arrays", "(", "split_y", ",", "max_lens", ")", "\n", "split_y_mask", "=", "trim_arrays", "(", "split_y_mask", ",", "max_lens", ")", "\n", "\n", "# Compute the weight of each sub-batch by summing the number of", "\n", "# source and target tokens. Note that this counts actual tokens", "\n", "# (up to and including the <EOS> tokens) not the capacity of the", "\n", "# sub-batch.", "\n", "# TODO: loss is calculated according to target side, hence here should be weighted by target tokens only.", "\n", "weights", "=", "[", "numpy", ".", "sum", "(", "t", ")", "\n", "for", "t", "in", "split_y_mask", "]", "\n", "\n", "# Pad the split lists with dummy arrays so that the total number of", "\n", "# sub-batches is a multiple of the number of replicas.", "\n", "\n", "remainder", "=", "len", "(", "start_points", ")", "%", "len", "(", "self", ".", "_replicas", ")", "\n", "padding_size", "=", "0", "if", "remainder", "==", "0", "else", "len", "(", "self", ".", "_replicas", ")", "-", "remainder", "\n", "\n", "def", "pad", "(", "split_a", ",", "padding_size", ")", ":", "\n", "            ", "assert", "len", "(", "split_a", ")", ">", "0", "\n", "dummy_array", "=", "split_a", "[", "0", "]", "[", "...", ",", "-", "1", ":", "]", "\n", "for", "i", "in", "range", "(", "padding_size", ")", ":", "\n", "                ", "split_a", ".", "append", "(", "dummy_array", ")", "\n", "\n", "", "", "pad", "(", "split_x", ",", "padding_size", ")", "\n", "pad", "(", "split_x_mask", ",", "padding_size", ")", "\n", "pad", "(", "split_y", ",", "padding_size", ")", "\n", "pad", "(", "split_y_mask", ",", "padding_size", ")", "\n", "\n", "for", "i", "in", "range", "(", "padding_size", ")", ":", "\n", "            ", "weights", ".", "append", "(", "0.0", ")", "\n", "\n", "", "return", "split_x", ",", "split_x_mask", ",", "split_y", ",", "split_y_mask", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater.ModelUpdater._split_and_pad_minibatch_mrt": [[402, 487], ["dict", "range", "model_updater.ModelUpdater._split_and_pad_minibatch.split_array"], "methods", ["None"], ["", "def", "_split_and_pad_minibatch_mrt", "(", "self", ",", "x", ",", "x_mask", ",", "y", ",", "y_mask", ",", "score", ",", "start_points", ",", "index", ")", ":", "\n", "        ", "\"\"\"Splits a minibatch according to a list of split points (function basically same as _split_and_pad_minibatch),\n        only difference is that the evaluation score of each sentence would also be split accordingly.\n\n        Args:\n            x: Numpy array with shape (factors, seq_len, batch_size)\n            x_mask: Numpy array with shape (seq_len, batch_size)\n            y: Numpy array with shape (seq_len, batch_size)\n            y_mask: Numpy array with shape (seq_len, batch_size)\n            score: Numpy array with shape (batch_size)\n            start_points: list of zero-based indices\n\n        Returns:\n            Six lists: for each of x, x_mask, y, y_mask and score respectively,\n            a list is returned containing the split version. The sixth list\n            contains the (un-normalized) weights of the sub-batches.\n        \"\"\"", "\n", "\n", "# Split the individual arrays.", "\n", "\n", "# change shape from batch_size to (1, batch_size)", "\n", "score", "=", "score", "[", "numpy", ".", "newaxis", ",", ":", "]", "\n", "\n", "# split the index for the subsequent calculation of expected risk", "\n", "tmp", "=", "[", "]", "\n", "batch_size", "=", "x_mask", ".", "shape", "[", "-", "1", "]", "\n", "start_points_new", "=", "start_points", "+", "[", "batch_size", "]", "\n", "s_index", "=", "dict", "(", "zip", "(", "index", "[", "0", "]", ",", "list", "(", "range", "(", "len", "(", "index", "[", "0", "]", ")", ")", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "start_points_new", ")", "-", "1", ")", ":", "\n", "            ", "sub_list", "=", "index", "[", "0", "]", "[", "s_index", "[", "start_points_new", "[", "i", "]", "]", ":", "s_index", "[", "start_points_new", "[", "i", "+", "1", "]", "]", "+", "1", "]", "\n", "tmp", ".", "append", "(", "numpy", ".", "array", "(", "[", "l", "-", "start_points_new", "[", "i", "]", "for", "l", "in", "sub_list", "]", ")", ")", "\n", "\n", "", "def", "split_array", "(", "a", ",", "start_points", ")", ":", "\n", "            ", "batch_size", "=", "a", ".", "shape", "[", "-", "1", "]", "\n", "next_points", "=", "start_points", "[", "1", ":", "]", "+", "[", "batch_size", "]", "\n", "return", "[", "a", "[", "...", ",", "p", ":", "q", "]", "for", "p", ",", "q", "in", "zip", "(", "start_points", ",", "next_points", ")", "]", "\n", "\n", "", "split_x", "=", "split_array", "(", "x", ",", "start_points", ")", "\n", "split_x_mask", "=", "split_array", "(", "x_mask", ",", "start_points", ")", "\n", "split_y", "=", "split_array", "(", "y", ",", "start_points", ")", "\n", "split_y_mask", "=", "split_array", "(", "y_mask", ",", "start_points", ")", "\n", "split_score", "=", "split_array", "(", "score", ",", "start_points", ")", "\n", "\n", "\n", "# Trim arrays so that the seq_len dimension is equal to the longest", "\n", "# source / target sentence in the sub-batch (rather than the whole", "\n", "# minibatch).", "\n", "\n", "def", "trim_arrays", "(", "arrays", ",", "new_seq_lens", ")", ":", "\n", "            ", "return", "[", "a", "[", "...", ",", "0", ":", "l", ",", ":", "]", "for", "a", ",", "l", "in", "zip", "(", "arrays", ",", "new_seq_lens", ")", "]", "\n", "\n", "", "max_lens", "=", "[", "int", "(", "numpy", ".", "max", "(", "numpy", ".", "sum", "(", "m", ",", "axis", "=", "0", ")", ")", ")", "for", "m", "in", "split_x_mask", "]", "\n", "split_x", "=", "trim_arrays", "(", "split_x", ",", "max_lens", ")", "\n", "split_x_mask", "=", "trim_arrays", "(", "split_x_mask", ",", "max_lens", ")", "\n", "\n", "max_lens", "=", "[", "int", "(", "numpy", ".", "max", "(", "numpy", ".", "sum", "(", "m", ",", "axis", "=", "0", ")", ")", ")", "for", "m", "in", "split_y_mask", "]", "\n", "split_y", "=", "trim_arrays", "(", "split_y", ",", "max_lens", ")", "\n", "split_y_mask", "=", "trim_arrays", "(", "split_y_mask", ",", "max_lens", ")", "\n", "\n", "# number of real sentences(before sampling candidates) of each sub-batch.", "\n", "weights", "=", "[", "len", "(", "t", ")", "-", "1", "for", "t", "in", "tmp", "]", "\n", "\n", "# Pad the split lists with dummy arrays so that the total number of", "\n", "# sub-batches is a multiple of the number of replicas.", "\n", "\n", "remainder", "=", "len", "(", "start_points", ")", "%", "len", "(", "self", ".", "_replicas", ")", "\n", "padding_size", "=", "0", "if", "remainder", "==", "0", "else", "len", "(", "self", ".", "_replicas", ")", "-", "remainder", "\n", "\n", "def", "pad", "(", "split_a", ",", "padding_size", ")", ":", "\n", "            ", "assert", "len", "(", "split_a", ")", ">", "0", "\n", "dummy_array", "=", "split_a", "[", "0", "]", "[", "...", ",", "-", "1", ":", "]", "\n", "for", "i", "in", "range", "(", "padding_size", ")", ":", "\n", "                ", "split_a", ".", "append", "(", "dummy_array", ")", "\n", "\n", "", "", "pad", "(", "split_x", ",", "padding_size", ")", "\n", "pad", "(", "split_x_mask", ",", "padding_size", ")", "\n", "pad", "(", "split_y", ",", "padding_size", ")", "\n", "pad", "(", "split_y_mask", ",", "padding_size", ")", "\n", "pad", "(", "tmp", ",", "padding_size", ")", "\n", "\n", "for", "i", "in", "range", "(", "padding_size", ")", ":", "\n", "            ", "weights", ".", "append", "(", "0.0", ")", "\n", "split_score", ".", "append", "(", "0.0", ")", "\n", "\n", "", "return", "split_x", ",", "split_x_mask", ",", "split_y", ",", "split_y_mask", ",", "split_score", ",", "weights", ",", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph.__init__": [[492, 558], ["tensorflow.compat.v1.placeholder", "range", "tensorflow.compat.v1.get_variable", "enumerate", "model_updater._ModelUpdateGraph._define_accum_ops", "model_updater._ModelUpdateGraph._define_apply_ops", "model_updater._ModelUpdateGraph._define_reset_ops", "model_updater._ModelUpdateGraph._define_summary_ops", "len", "tensorflow.compat.v1.placeholder", "model_updater._ModelUpdateGraph._replica_weights.append", "tensorflow.compat.v1.trainable_variables", "tensorflow.compat.v1.get_variable", "tensorflow.zeros_initializer", "tensorflow.zeros_like", "str"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._define_accum_ops", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._define_apply_ops", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._define_reset_ops", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._define_summary_ops"], ["def", "__init__", "(", "self", ",", "config", ",", "num_gpus", ",", "replicas", ",", "optimizer", ",", "global_step", ")", ":", "\n", "        ", "\"\"\"Constructs the graph nodes used by ModelUpdater.\n\n        The graph has a placeholder input for each replica weight (the weight\n        should be the normalized weight of the sub-batch being run by that\n        replica). The placeholders are exposed to ModelUpdater via the\n        self.replica_weights property.\n\n        At various points, ModelUpdater.update() will run different parts of\n        the graph depending on whether it is accumulating, applying, or\n        resetting the gradients. Operations for each are exposed to\n        ModelUpdater via the following properties:\n\n            self.accum_ops\n            self.apply_ops\n            self.reset_ops\n\n        The self.summary_ops property is provided for summary writing.\n\n        Args:\n            config: the model config (an argparse.Namespace)\n            num_gpus: the number of available GPUs.\n            replicas: a list of RNNModel or Transformer objects.\n            optimizer: a TensorFlow optimizer.\n            global_step: a tf.Variable to be updated by optimizer.\n        \"\"\"", "\n", "self", ".", "_config", "=", "config", "\n", "self", ".", "_num_gpus", "=", "num_gpus", "\n", "self", ".", "_replicas", "=", "replicas", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_global_step", "=", "global_step", "\n", "\n", "# Create the placeholder for the scaling factor.", "\n", "self", ".", "_scaling_factor", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "name", "=", "'scaling_factor'", ",", "\n", "shape", "=", "(", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Create the placeholders for the replica weights.", "\n", "self", ".", "_replica_weights", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_replicas", ")", ")", ":", "\n", "            ", "name", "=", "'replica_weight_{}'", ".", "format", "(", "i", ")", "\n", "placeholder", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "name", "=", "name", ",", "shape", "=", "(", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_replica_weights", ".", "append", "(", "placeholder", ")", "\n", "\n", "# Define the (non-trainable) variables for accumulating gradients and", "\n", "# losses. These need to be variables because their values must be", "\n", "# preserved over multiple runs.", "\n", "\n", "", "self", ".", "_accumulated_loss", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "'accumulated_loss'", ",", "\n", "shape", "=", "[", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "self", ".", "_trainables", ",", "self", ".", "_accumulated_gradients", "=", "{", "}", ",", "{", "}", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ")", ":", "\n", "            ", "self", ".", "_trainables", "[", "v", ".", "name", "]", "=", "v", "\n", "g", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "name", "=", "'accum'", "+", "str", "(", "i", ")", ",", "# FIXME better name. Variable scope?", "\n", "initializer", "=", "tf", ".", "zeros_like", "(", "v", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "self", ".", "_accumulated_gradients", "[", "v", ".", "name", "]", "=", "g", "\n", "\n", "", "self", ".", "_define_accum_ops", "(", ")", "\n", "self", ".", "_define_apply_ops", "(", ")", "\n", "self", ".", "_define_reset_ops", "(", ")", "\n", "self", ".", "_define_summary_ops", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph.scaling_factor": [[559, 562], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scaling_factor", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_scaling_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph.replica_weights": [[563, 566], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "replica_weights", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_replica_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph.accum_ops": [[567, 570], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "accum_ops", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_accum_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph.apply_ops": [[571, 574], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "apply_ops", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_apply_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph.reset_ops": [[575, 578], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "reset_ops", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_reset_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph.summary_ops": [[579, 582], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "summary_ops", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_summary_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._define_reset_ops": [[583, 588], ["v.assign", "tensorflow.zeros_like", "list", "model_updater._ModelUpdateGraph._accumulated_gradients.values"], "methods", ["None"], ["", "def", "_define_reset_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines a set of ops to reset the accumulated values to zero.\"\"\"", "\n", "self", ".", "_reset_ops", "=", "[", "v", ".", "assign", "(", "tf", ".", "zeros_like", "(", "v", ")", ")", "\n", "for", "v", "in", "[", "self", ".", "_accumulated_loss", "]", "+", "\n", "list", "(", "self", ".", "_accumulated_gradients", ".", "values", "(", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._define_accum_ops": [[589, 639], ["range", "len", "tensorflow.DeviceSpec", "sum", "model_updater._ModelUpdateGraph._sum_gradients", "tensorflow.device", "tensorflow.compat.v1.assign_add", "tensorflow.compat.v1.assign_add", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable_scope", "model_updater._ModelUpdateGraph._regularize", "model_updater._ModelUpdateGraph._optimizer.compute_gradients", "all_grad_vars.append", "weighted_losses.append", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._sum_gradients", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._regularize"], ["", "def", "_define_accum_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines the graph nodes used for a single accumulation step.\"\"\"", "\n", "\n", "weighted_losses", "=", "[", "]", "\n", "all_grad_vars", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_replicas", ")", ")", ":", "\n", "            ", "device_type", "=", "\"GPU\"", "if", "self", ".", "_num_gpus", ">", "0", "else", "\"CPU\"", "\n", "device_spec", "=", "tf", ".", "DeviceSpec", "(", "device_type", "=", "device_type", ",", "\n", "device_index", "=", "i", ")", "\n", "with", "tf", ".", "device", "(", "device_spec", ")", ":", "\n", "                ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "tf", ".", "compat", ".", "v1", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "(", "i", ">", "0", ")", ")", ":", "\n", "                    ", "if", "self", ".", "_config", ".", "print_per_token_pro", ":", "\n", "                        ", "print_pro", "=", "self", ".", "_replicas", "[", "i", "]", ".", "print_pro", "\n", "", "elif", "self", ".", "_config", ".", "loss_function", "==", "\"cross-entropy\"", ":", "# \u6b63\u5e38\u7684loss/n,n\u662fsample\u6570", "\n", "                        ", "loss", "=", "self", ".", "_replicas", "[", "i", "]", ".", "loss", "\n", "", "elif", "self", ".", "_config", ".", "loss_function", "==", "\"per-token-cross-entropy\"", ":", "\n", "                        ", "ce_per_sent", "=", "self", ".", "_replicas", "[", "i", "]", ".", "loss_per_sentence", "\n", "ce_total", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "ce_per_sent", ")", "\n", "num_tokens", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "self", ".", "_replicas", "[", "i", "]", ".", "inputs", ".", "y_mask", ")", "\n", "loss", "=", "ce_total", "/", "tf", ".", "cast", "(", "num_tokens", ",", "tf", ".", "float32", ")", "\n", "", "elif", "self", ".", "_config", ".", "loss_function", "==", "\"MRT\"", ":", "\n", "# here the expected risk is the expected risk per real sentences(before sampling)", "\n", "# over a sub-batch", "\n", "                        ", "loss", "=", "self", ".", "_replicas", "[", "i", "]", ".", "risk", "\n", "", "else", ":", "\n", "                        ", "assert", "False", "\n", "", "if", "self", ".", "_config", ".", "print_per_token_pro", "==", "False", ":", "\n", "                        ", "loss", "=", "self", ".", "_regularize", "(", "loss", ",", "self", ".", "_config", ".", "decay_c", ",", "\n", "self", ".", "_config", ".", "map_decay_c", ")", "\n", "grad_vars", "=", "self", ".", "_optimizer", ".", "compute_gradients", "(", "loss", ")", "\n", "all_grad_vars", ".", "append", "(", "grad_vars", ")", "\n", "weight", "=", "self", ".", "_replica_weights", "[", "i", "]", "\n", "weighted_losses", ".", "append", "(", "loss", "*", "weight", ")", "\n", "\n", "", "", "", "", "if", "self", ".", "_config", ".", "print_per_token_pro", "==", "False", ":", "\n", "            ", "summed_loss", "=", "sum", "(", "weighted_losses", ")", "\n", "\n", "summed_grad_vars", "=", "self", ".", "_sum_gradients", "(", "all_grad_vars", ",", "\n", "self", ".", "_replica_weights", ")", "\n", "\n", "self", ".", "_accum_ops", "=", "[", "tf", ".", "compat", ".", "v1", ".", "assign_add", "(", "self", ".", "_accumulated_loss", ",", "summed_loss", ")", "]", "\n", "\n", "self", ".", "_accum_ops", "+=", "[", "tf", ".", "compat", ".", "v1", ".", "assign_add", "(", "self", ".", "_accumulated_gradients", "[", "v", ".", "name", "]", ",", "\n", "g", "*", "self", ".", "_scaling_factor", ")", "\n", "for", "g", ",", "v", "in", "summed_grad_vars", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_accum_ops", "=", "print_pro", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._define_apply_ops": [[640, 662], ["model_updater._ModelUpdateGraph._optimizer.apply_gradients", "list", "tensorflow.clip_by_global_norm", "list", "model_updater._ModelUpdateGraph._trainables.keys", "zip", "zip"], "methods", ["None"], ["", "", "def", "_define_apply_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines the graph nodes for applying the accumulated gradients.\"\"\"", "\n", "\n", "final_loss", "=", "self", ".", "_accumulated_loss", "\n", "\n", "final_grad_vars", "=", "[", "(", "self", ".", "_accumulated_gradients", "[", "key", "]", ",", "\n", "self", ".", "_trainables", "[", "key", "]", ")", "\n", "for", "key", "in", "self", ".", "_trainables", ".", "keys", "(", ")", "]", "\n", "\n", "if", "self", ".", "_config", ".", "clip_c", ">", "0.0", ":", "\n", "            ", "grads", ",", "varss", "=", "list", "(", "zip", "(", "*", "final_grad_vars", ")", ")", "\n", "clipped_grads", ",", "global_norm", "=", "tf", ".", "clip_by_global_norm", "(", "\n", "grads", ",", "clip_norm", "=", "self", ".", "_config", ".", "clip_c", ")", "\n", "# Might be interesting to see how the global norm changes over", "\n", "# time, attach a summary?", "\n", "final_grad_vars", "=", "list", "(", "zip", "(", "clipped_grads", ",", "varss", ")", ")", "\n", "\n", "", "apply_grads", "=", "self", ".", "_optimizer", ".", "apply_gradients", "(", "\n", "final_grad_vars", ",", "\n", "global_step", "=", "self", ".", "_global_step", ")", "\n", "\n", "self", ".", "_apply_ops", "=", "[", "self", ".", "_global_step", ",", "apply_grads", ",", "final_loss", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._define_summary_ops": [[663, 668], ["tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.merge_all"], "methods", ["None"], ["", "def", "_define_summary_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines the summary ops.\"\"\"", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "name", "=", "'mean_cost'", ",", "tensor", "=", "self", ".", "_accumulated_loss", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "name", "=", "'t'", ",", "tensor", "=", "self", ".", "_global_step", ")", "\n", "self", ".", "_summary_ops", "=", "[", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "merge_all", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._regularize": [[669, 693], ["tensorflow.compat.v1.variable_scope", "tensorflow.add_n", "tensorflow.constant", "tensorflow.compat.v1.trainable_variables", "tensorflow.constant", "tensorflow.compat.v1.get_variable", "map_l2_acc.append", "tensorflow.add_n", "tensorflow.constant", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.compat.v1.trainable_variables", "v.name.split", "v.initialized_value", "v.initialized_value"], "methods", ["None"], ["", "def", "_regularize", "(", "self", ",", "loss", ",", "decay_c", ",", "map_decay_c", ")", ":", "\n", "        ", "\"\"\"Optionally, adds L2 and MAP-L2 regularization terms to the loss.\"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"loss\"", ")", ":", "\n", "# Optionally, add an L2 loss term.", "\n", "            ", "if", "decay_c", ">", "0.0", ":", "\n", "                ", "l2_sum", "=", "tf", ".", "add_n", "(", "[", "tf", ".", "nn", ".", "l2_loss", "(", "v", ")", "\n", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", "]", ")", "\n", "l2_loss", "=", "l2_sum", "*", "tf", ".", "constant", "(", "decay_c", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "loss", "+=", "l2_loss", "\n", "# Optionally, add an L2 loss term based on a prior model.", "\n", "", "if", "map_decay_c", ">", "0.0", ":", "\n", "                ", "map_l2_loss", "=", "tf", ".", "constant", "(", "0.0", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "map_l2_acc", "=", "[", "]", "\n", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ":", "\n", "                    ", "prior_name", "=", "'prior/'", "+", "v", ".", "name", ".", "split", "(", "':'", ")", "[", "0", "]", "\n", "prior_v", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\n", "prior_name", ",", "initializer", "=", "v", ".", "initialized_value", "(", ")", ",", "\n", "trainable", "=", "False", ",", "collections", "=", "[", "'prior_variables'", "]", ",", "\n", "dtype", "=", "v", ".", "initialized_value", "(", ")", ".", "dtype", ")", "\n", "map_l2_acc", ".", "append", "(", "tf", ".", "nn", ".", "l2_loss", "(", "v", "-", "prior_v", ")", ")", "\n", "", "map_l2_loss", "=", "(", "tf", ".", "add_n", "(", "map_l2_acc", ")", "\n", "*", "tf", ".", "constant", "(", "map_decay_c", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "loss", "+=", "map_l2_loss", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_updater._ModelUpdateGraph._sum_gradients": [[694, 739], ["list", "d.items", "d[].append", "avg_grad_vars.append", "enumerate", "tensorflow.concat", "tensorflow.reduce_sum", "avg_grad_vars.append", "tensorflow.expand_dims", "weighted_grads.append"], "methods", ["None"], ["", "def", "_sum_gradients", "(", "self", ",", "all_grad_vars", ",", "weights", ")", ":", "\n", "        ", "\"\"\"Computes the weighted sums of gradients from multiple sub-batches.\n\n        Args:\n            all_grad_vars: a list of lists of (gradient, variable) pairs. The\n                outer list should contain one entry for each sub-batch. Each\n                inner list should contain the optimizer's (gradient, variable)\n                list for that sub-batch.\n            weights: a list containing the normalized weight of each sub-batch.\n\n        Returns:\n            A list of (gradient, variable) pairs.\n        \"\"\"", "\n", "# Create a dictionary mapping each variable name to a list of", "\n", "# (gradient, variable) pairs (one pair from each sub-batch).", "\n", "d", "=", "{", "}", "\n", "for", "grad_vars", "in", "all_grad_vars", ":", "\n", "            ", "for", "g", ",", "v", "in", "grad_vars", ":", "\n", "                ", "if", "v", ".", "name", "not", "in", "d", ":", "\n", "                    ", "d", "[", "v", ".", "name", "]", "=", "[", "]", "\n", "", "d", "[", "v", ".", "name", "]", ".", "append", "(", "(", "g", ",", "v", ")", ")", "\n", "\n", "# For each variable, sum the gradients from all sub-batches and store", "\n", "# the result in avg_grad_vars.", "\n", "", "", "avg_grad_vars", "=", "[", "]", "\n", "for", "var_name", ",", "gv_list", "in", "list", "(", "d", ".", "items", "(", ")", ")", ":", "\n", "            ", "var", "=", "gv_list", "[", "0", "]", "[", "1", "]", "\n", "found_none_value", "=", "False", "\n", "for", "g", ",", "v", "in", "gv_list", ":", "\n", "                ", "if", "g", "is", "None", ":", "\n", "                    ", "found_none_value", "=", "True", "\n", "break", "\n", "", "", "if", "found_none_value", ":", "\n", "                ", "avg_grad_vars", ".", "append", "(", "(", "None", ",", "var", ")", ")", "\n", "", "else", ":", "\n", "                ", "weighted_grads", "=", "[", "]", "\n", "for", "i", ",", "(", "g", ",", "v", ")", "in", "enumerate", "(", "gv_list", ")", ":", "\n", "                    ", "assert", "v", "==", "var", "\n", "expanded", "=", "tf", ".", "expand_dims", "(", "g", "*", "weights", "[", "i", "]", ",", "0", ")", "\n", "weighted_grads", ".", "append", "(", "expanded", ")", "\n", "", "tmp", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "weighted_grads", ")", "\n", "avg_grad", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "tmp", ",", "axis", "=", "0", ")", "\n", "avg_grad_vars", ".", "append", "(", "(", "avg_grad", ",", "var", ")", ")", "\n", "\n", "", "", "return", "avg_grad_vars", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.EncoderOutput.__init__": [[21, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "enc_output", ",", "cross_attn_mask", ")", ":", "\n", "        ", "self", ".", "enc_output", "=", "enc_output", "\n", "self", ".", "cross_attn_mask", "=", "cross_attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.__init__": [[35, 39], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "config", ",", "scope", ")", ":", "\n", "        ", "self", ".", "_model", "=", "model", "\n", "self", ".", "_config", "=", "config", "\n", "self", ".", "_scope", "=", "scope", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.model": [[40, 43], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.config": [[44, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_config", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.target_vocab_size": [[48, 51], ["transformer_inference.ModelAdapter._model.dec.embedding_layer.get_vocab_size"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.get_vocab_size"], ["", "@", "property", "\n", "def", "target_vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", ".", "dec", ".", "embedding_layer", ".", "get_vocab_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.batch_size": [[52, 55], ["tensorflow.shape"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "shape", "(", "input", "=", "self", ".", "_model", ".", "inputs", ".", "x", ")", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.encode": [[56, 61], ["tensorflow.compat.v1.name_scope", "transformer_inference.ModelAdapter._model.enc.encode", "transformer_inference.EncoderOutput"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder.encode"], ["", "def", "encode", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "            ", "enc_output", ",", "cross_attn_mask", "=", "self", ".", "_model", ".", "enc", ".", "encode", "(", "\n", "self", ".", "_model", ".", "source_ids", ",", "self", ".", "_model", ".", "source_mask", ")", "\n", "return", "EncoderOutput", "(", "enc_output", ",", "cross_attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.generate_decoding_function": [[62, 126], ["tensorflow.compat.v1.name_scope", "get_positional_signal", "tensorflow.keras.layers.Dropout", "tensorflow.compat.v1.name_scope", "tensorflow.reshape", "decoder._embed", "range", "decoder.softmax_projection_layer.project", "tensorflow.keras.layers.Dropout.", "layer[].forward", "layer[].forward", "layer[].forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.get_positional_signal", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder._embed", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.project", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "generate_decoding_function", "(", "self", ",", "encoder_output", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "# Generate a positional signal for the longest possible output.", "\n", "            ", "positional_signal", "=", "get_positional_signal", "(", "\n", "self", ".", "_config", ".", "translation_maxlen", ",", "\n", "self", ".", "_config", ".", "embedding_size", ",", "\n", "FLOAT_DTYPE", ")", "\n", "\n", "", "decoder", "=", "self", ".", "_model", ".", "dec", "\n", "\n", "if", "self", ".", "config", ".", "transformer_dropout_embeddings", ">", "0", ":", "\n", "            ", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", "=", "self", ".", "config", ".", "transformer_dropout_embeddings", ")", "\n", "", "else", ":", "\n", "            ", "dropout", "=", "None", "\n", "\n", "", "def", "_decoding_function", "(", "step_target_ids", ",", "current_time_step", ",", "memories", ")", ":", "\n", "            ", "\"\"\"Single-step decoding function.\n\n            Args:\n                step_target_ids: Tensor with shape (batch_size)\n                current_time_step: scalar Tensor.\n                memories: dictionary (see top-level class description)\n\n            Returns:\n            \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "# TODO Is this necessary?", "\n", "                ", "vocab_ids", "=", "tf", ".", "reshape", "(", "step_target_ids", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "# Look up embeddings for target IDs.", "\n", "target_embeddings", "=", "decoder", ".", "_embed", "(", "vocab_ids", ")", "\n", "# Add positional signal.", "\n", "signal_slice", "=", "positional_signal", "[", "\n", ":", ",", "current_time_step", "-", "1", ":", "current_time_step", ",", ":", "]", "\n", "target_embeddings", "+=", "signal_slice", "\n", "# Optionally, apply dropout to embeddings.", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "                    ", "target_embeddings", "=", "dropout", "(", "\n", "target_embeddings", ",", "\n", "training", "=", "decoder", ".", "training", ")", "\n", "# Propagate values through the decoder stack.", "\n", "# NOTE: No self-attention mask is applied at decoding, as", "\n", "#       future information is unavailable.", "\n", "", "layer_output", "=", "target_embeddings", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "config", ".", "transformer_dec_depth", "+", "1", ")", ":", "\n", "                    ", "layer", "=", "decoder", ".", "decoder_stack", "[", "layer_id", "]", "\n", "mem_key", "=", "'layer_{:d}'", ".", "format", "(", "layer_id", ")", "\n", "layer_output", ",", "memories", "[", "mem_key", "]", "=", "layer", "[", "'self_attn'", "]", ".", "forward", "(", "\n", "layer_output", ",", "None", ",", "None", ",", "memories", "[", "mem_key", "]", ")", "\n", "layer_output", ",", "_", "=", "layer", "[", "'cross_attn'", "]", ".", "forward", "(", "\n", "layer_output", ",", "encoder_output", ".", "enc_output", ",", "\n", "encoder_output", ".", "cross_attn_mask", ")", "\n", "layer_output", "=", "layer", "[", "'ffn'", "]", ".", "forward", "(", "layer_output", ")", "\n", "# Return prediction at the final time-step to be consistent", "\n", "# with the inference pipeline.", "\n", "", "dec_output", "=", "layer_output", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "# Project decoder stack outputs and apply the soft-max", "\n", "# non-linearity.", "\n", "step_logits", "=", "decoder", ".", "softmax_projection_layer", ".", "project", "(", "dec_output", ")", "\n", "return", "step_logits", ",", "memories", "\n", "\n", "", "", "return", "_decoding_function", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.generate_initial_memories": [[127, 139], ["tensorflow.compat.v1.name_scope", "range", "tensorflow.tile", "tensorflow.tile", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["None"], ["", "def", "generate_initial_memories", "(", "self", ",", "batch_size", ",", "beam_size", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "            ", "state_size", "=", "self", ".", "config", ".", "state_size", "\n", "memories", "=", "{", "}", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "config", ".", "transformer_dec_depth", "+", "1", ")", ":", "\n", "                ", "memories", "[", "'layer_{:d}'", ".", "format", "(", "layer_id", ")", "]", "=", "{", "'keys'", ":", "tf", ".", "tile", "(", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "state_size", "]", ")", ",", "\n", "[", "beam_size", ",", "1", ",", "1", "]", ")", ",", "\n", "'values'", ":", "tf", ".", "tile", "(", "tf", ".", "zeros", "(", "[", "batch_size", ",", "0", ",", "state_size", "]", ")", ",", "\n", "[", "beam_size", ",", "1", ",", "1", "]", ")", "\n", "}", "\n", "", "return", "memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.get_memory_invariants": [[140, 159], ["tensorflow.compat.v1.name_scope", "dict", "memories.keys", "tensorflow.TensorShape", "layer_mems.keys", "len", "tf_utils.get_shape_list"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "", "def", "get_memory_invariants", "(", "self", ",", "memories", ")", ":", "\n", "        ", "\"\"\"Generate shape invariants for memories.\n\n        Args:\n            memories: dictionary (see top-level class description)\n\n        Returns:\n            Dictionary of shape invariants with same structure as memories.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "            ", "invariants", "=", "dict", "(", ")", "\n", "for", "layer_id", "in", "memories", ".", "keys", "(", ")", ":", "\n", "                ", "layer_mems", "=", "memories", "[", "layer_id", "]", "\n", "invariants", "[", "layer_id", "]", "=", "{", "\n", "key", ":", "tf", ".", "TensorShape", "(", "\n", "[", "None", "]", "*", "len", "(", "tf_utils", ".", "get_shape_list", "(", "layer_mems", "[", "key", "]", ")", ")", ")", "\n", "for", "key", "in", "layer_mems", ".", "keys", "(", ")", "\n", "}", "\n", "", "return", "invariants", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_inference.ModelAdapter.gather_memories": [[160, 203], ["tensorflow.compat.v1.name_scope", "tf_utils.assert_shapes", "tensorflow.shape", "dict", "memories.keys", "tf_utils.assert_shapes", "tf_utils.get_shape_list", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.gather_nd", "tensorflow.transpose", "tensorflow.reshape", "dict", "layer_dict.keys", "transformer_inference.ModelAdapter.gather_memories.gather_attn"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.assert_shapes", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.assert_shapes", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "", "def", "gather_memories", "(", "self", ",", "memories", ",", "gather_coordinates", ")", ":", "\n", "        ", "\"\"\" Gathers layer-wise memory tensors for selected beam entries.\n\n        Args:\n            memories: dictionary (see top-level class description)\n            gather_coordinates: Tensor with shape [batch_size_x, beam_size, 2]\n\n        Returns:\n            Dictionary containing gathered memories.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "\n", "            ", "shapes", "=", "{", "gather_coordinates", ":", "(", "'batch_size_x'", ",", "'beam_size'", ",", "2", ")", "}", "\n", "tf_utils", ".", "assert_shapes", "(", "shapes", ")", "\n", "\n", "coords_shape", "=", "tf", ".", "shape", "(", "input", "=", "gather_coordinates", ")", "\n", "batch_size_x", ",", "beam_size", "=", "coords_shape", "[", "0", "]", ",", "coords_shape", "[", "1", "]", "\n", "\n", "def", "gather_attn", "(", "attn", ")", ":", "\n", "# TODO Specify second and third?", "\n", "                ", "shapes", "=", "{", "attn", ":", "(", "'batch_size'", ",", "None", ",", "None", ")", "}", "\n", "tf_utils", ".", "assert_shapes", "(", "shapes", ")", "\n", "attn_dims", "=", "tf_utils", ".", "get_shape_list", "(", "attn", ")", "\n", "new_shape", "=", "[", "beam_size", ",", "batch_size_x", "]", "+", "attn_dims", "[", "1", ":", "]", "\n", "tmp", "=", "tf", ".", "reshape", "(", "attn", ",", "new_shape", ")", "\n", "flat_tensor", "=", "tf", ".", "transpose", "(", "a", "=", "tmp", ",", "perm", "=", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", "\n", "tmp", "=", "tf", ".", "gather_nd", "(", "flat_tensor", ",", "gather_coordinates", ")", "\n", "tmp", "=", "tf", ".", "transpose", "(", "a", "=", "tmp", ",", "perm", "=", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", "\n", "gathered_values", "=", "tf", ".", "reshape", "(", "tmp", ",", "attn_dims", ")", "\n", "return", "gathered_values", "\n", "\n", "", "gathered_memories", "=", "dict", "(", ")", "\n", "\n", "for", "layer_key", "in", "memories", ".", "keys", "(", ")", ":", "\n", "                ", "layer_dict", "=", "memories", "[", "layer_key", "]", "\n", "gathered_memories", "[", "layer_key", "]", "=", "dict", "(", ")", "\n", "\n", "for", "attn_key", "in", "layer_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "attn_tensor", "=", "layer_dict", "[", "attn_key", "]", "\n", "gathered_memories", "[", "layer_key", "]", "[", "attn_key", "]", "=", "gather_attn", "(", "attn_tensor", ")", "\n", "\n", "", "", "return", "gathered_memories", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.exception.Error.__init__": [[2, 4], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "msg", "=", "msg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sampler_inputs.SamplerInputs.__init__": [[7, 30], ["tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "# Number of sentences in the input. When sampling, this is not", "\n", "# necessarily the same as the batch size, hence the modified name. The", "\n", "# actual batch size (i.e. as seen by the model) will vary: usually", "\n", "# it's batch_size_x * beam_size because we tile the input sentences,", "\n", "# but in the Transformer encoder it's just batch_size_x.", "\n", "        ", "self", ".", "batch_size_x", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'batch_size_x'", ",", "\n", "shape", "=", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "# Maximum translation length.", "\n", "self", ".", "max_translation_len", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'max_translation_len'", ",", "\n", "shape", "=", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "# Alpha parameter for length normalization.", "\n", "self", ".", "normalization_alpha", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'normalization_alpha'", ",", "\n", "shape", "=", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_inputs.ModelInputs.__init__": [[5, 44], ["tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder_with_default"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "# variable dimensions", "\n", "        ", "seq_len", ",", "batch_size", ",", "mrt_sampleN", "=", "None", ",", "None", ",", "None", "\n", "# mrt_sampleN = batch_size X sampleN", "\n", "\n", "self", ".", "x", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'x'", ",", "\n", "shape", "=", "(", "config", ".", "factors", ",", "seq_len", ",", "batch_size", ")", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "self", ".", "x_mask", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'x_mask'", ",", "\n", "shape", "=", "(", "seq_len", ",", "batch_size", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "self", ".", "y", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'y'", ",", "\n", "shape", "=", "(", "seq_len", ",", "batch_size", ")", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "self", ".", "y_mask", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'y_mask'", ",", "\n", "shape", "=", "(", "seq_len", ",", "batch_size", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "self", ".", "scores", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'scores'", ",", "\n", "shape", "=", "(", "mrt_sampleN", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "self", ".", "index", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "name", "=", "'index'", ",", "\n", "shape", "=", "(", "mrt_sampleN", ")", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "self", ".", "training", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder_with_default", "(", "\n", "False", ",", "\n", "name", "=", "'training'", ",", "\n", "shape", "=", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.score.calc_scores": [[47, 115], ["tensorflow.Graph", "tf.Graph.as_default", "tensorflow.compat.v1.ConfigProto", "tensorflow.compat.v1.Session", "logging.info", "model_loader.init_or_restore_variables", "TextIterator", "train.calc_cross_entropy_per_sentence", "scores.append", "transformer.Transformer", "rnn_model.RNNModel", "ExponentialSmoothing", "sess.run", "float"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader.init_or_restore_variables", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.train.calc_cross_entropy_per_sentence"], ["", "def", "calc_scores", "(", "source_file", ",", "target_file", ",", "scorer_settings", ",", "configs", ")", ":", "\n", "    ", "\"\"\"Calculates sentence pair scores using each of the specified models.\n\n    By default (when scorer_settings.normalization_alpha is 0.0), the score\n    is the sentence-level cross entropy, otherwise it's a normalized version.\n\n    Args:\n        source_file: file object for file containing source sentences.\n        target_file: file object for file containing target sentences.\n        scorer_settings: a ScorerSettings object.\n        configs: a list of Namespace objects specifying the model configs.\n\n    Returns:\n        A list of lists of floats. The outer list contains one list for each\n        model (in the same order given by configs). The inner list contains\n        one score for each sentence pair.\n    \"\"\"", "\n", "scores", "=", "[", "]", "\n", "for", "config", "in", "configs", ":", "\n", "        ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "            ", "tf_config", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", ")", "\n", "tf_config", ".", "allow_soft_placement", "=", "True", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "config", "=", "tf_config", ")", "as", "sess", ":", "\n", "\n", "                ", "logging", ".", "info", "(", "'Building model...'", ")", "\n", "\n", "# Create the model graph.", "\n", "if", "config", ".", "model_type", "==", "'transformer'", ":", "\n", "                    ", "model", "=", "transformer", ".", "Transformer", "(", "config", ")", "\n", "", "else", ":", "\n", "                    ", "model", "=", "rnn_model", ".", "RNNModel", "(", "config", ")", "\n", "\n", "# Add smoothing variables (if the model was trained with", "\n", "# smoothing).", "\n", "", "if", "config", ".", "exponential_smoothing", ">", "0.0", ":", "\n", "                    ", "smoothing", "=", "ExponentialSmoothing", "(", "\n", "config", ".", "exponential_smoothing", ")", "\n", "\n", "# Restore the model variables.", "\n", "", "saver", "=", "model_loader", ".", "init_or_restore_variables", "(", "config", ",", "sess", ")", "\n", "\n", "# Swap-in the smoothed versions of the variables (if present).", "\n", "if", "config", ".", "exponential_smoothing", ">", "0.0", ":", "\n", "                    ", "sess", ".", "run", "(", "fetches", "=", "smoothing", ".", "swap_ops", ")", "\n", "\n", "", "text_iterator", "=", "TextIterator", "(", "\n", "source", "=", "source_file", ".", "name", ",", "\n", "target", "=", "target_file", ".", "name", ",", "\n", "source_dicts", "=", "config", ".", "source_dicts", ",", "\n", "target_dict", "=", "config", ".", "target_dict", ",", "\n", "model_type", "=", "config", ".", "model_type", ",", "\n", "batch_size", "=", "scorer_settings", ".", "minibatch_size", ",", "\n", "maxlen", "=", "float", "(", "'inf'", ")", ",", "\n", "source_vocab_sizes", "=", "config", ".", "source_vocab_sizes", ",", "\n", "target_vocab_size", "=", "config", ".", "target_vocab_size", ",", "\n", "use_factor", "=", "(", "config", ".", "factors", ">", "1", ")", ",", "\n", "sort_by_length", "=", "False", ")", "\n", "\n", "ce_vals", ",", "_", "=", "train", ".", "calc_cross_entropy_per_sentence", "(", "\n", "sess", ",", "\n", "model", ",", "\n", "config", ",", "\n", "text_iterator", ",", "\n", "normalization_alpha", "=", "scorer_settings", ".", "normalization_alpha", ")", "\n", "\n", "scores", ".", "append", "(", "ce_vals", ")", "\n", "", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.score.write_scores": [[117, 129], ["source_file.seek", "target_file.seek", "source_file.readlines", "target_file.readlines", "enumerate", "output_file.write", "map", "output_file.write", "line.strip"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.seek", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.seek"], ["", "def", "write_scores", "(", "source_file", ",", "target_file", ",", "scores", ",", "output_file", ",", "scorer_settings", ")", ":", "\n", "\n", "    ", "source_file", ".", "seek", "(", "0", ")", "\n", "target_file", ".", "seek", "(", "0", ")", "\n", "source_lines", "=", "source_file", ".", "readlines", "(", ")", "\n", "target_lines", "=", "target_file", ".", "readlines", "(", ")", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "target_lines", ")", ":", "\n", "        ", "score_str", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "[", "s", "[", "i", "]", "for", "s", "in", "scores", "]", ")", ")", "\n", "if", "scorer_settings", ".", "verbose", ":", "\n", "            ", "output_file", ".", "write", "(", "'{0} '", ".", "format", "(", "line", ".", "strip", "(", ")", ")", ")", "\n", "", "output_file", ".", "write", "(", "'{0}\\n'", ".", "format", "(", "score_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.score.main": [[131, 141], ["score.calc_scores", "score.write_scores", "load_config_from_json_file", "setattr", "configs.append"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.score.calc_scores", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.score.write_scores", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.load_config_from_json_file"], ["", "", "def", "main", "(", "source_file", ",", "target_file", ",", "output_file", ",", "scorer_settings", ")", ":", "\n", "# load model model_options", "\n", "    ", "configs", "=", "[", "]", "\n", "for", "model", "in", "scorer_settings", ".", "models", ":", "\n", "        ", "config", "=", "load_config_from_json_file", "(", "model", ")", "\n", "setattr", "(", "config", ",", "'reload'", ",", "model", ")", "\n", "configs", ".", "append", "(", "config", ")", "\n", "\n", "", "scores", "=", "calc_scores", "(", "source_file", ",", "target_file", ",", "scorer_settings", ",", "configs", ")", "\n", "write_scores", "(", "source_file", ",", "target_file", ",", "scores", ",", "output_file", ",", "scorer_settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.ortho_weight": [[7, 11], ["numpy.random.randn", "numpy.linalg.svd", "u.astype"], "function", ["None"], ["def", "ortho_weight", "(", "ndim", ")", ":", "\n", "    ", "W", "=", "numpy", ".", "random", ".", "randn", "(", "ndim", ",", "ndim", ")", "\n", "u", ",", "s", ",", "v", "=", "numpy", ".", "linalg", ".", "svd", "(", "W", ")", "\n", "return", "u", ".", "astype", "(", "'float32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.norm_weight": [[12, 20], ["ortho_weight.astype", "initializers.ortho_weight", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.initializers.ortho_weight"], ["", "def", "norm_weight", "(", "nin", ",", "nout", "=", "None", ",", "scale", "=", "0.01", ",", "ortho", "=", "True", ")", ":", "\n", "    ", "if", "nout", "is", "None", ":", "\n", "        ", "nout", "=", "nin", "\n", "", "if", "nout", "==", "nin", "and", "ortho", ":", "\n", "        ", "W", "=", "ortho_weight", "(", "nin", ")", "\n", "", "else", ":", "\n", "        ", "W", "=", "scale", "*", "numpy", ".", "random", ".", "randn", "(", "nin", ",", "nout", ")", "\n", "", "return", "W", ".", "astype", "(", "'float32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.prepare_data": [[19, 58], ["len", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "numpy.zeros().astype", "enumerate", "len", "len", "zip", "numpy.max", "numpy.max", "zip", "list", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "zip", "new_seqs_x.append", "new_lengths_x.append", "new_seqs_y.append", "new_lengths_y.append", "len", "len"], "function", ["None"], ["", "def", "prepare_data", "(", "seqs_x", ",", "seqs_y", ",", "n_factors", ",", "maxlen", "=", "None", ")", ":", "\n", "# x: a list of sentences", "\n", "    ", "lengths_x", "=", "[", "len", "(", "s", ")", "for", "s", "in", "seqs_x", "]", "\n", "lengths_y", "=", "[", "len", "(", "s", ")", "for", "s", "in", "seqs_y", "]", "\n", "\n", "if", "maxlen", "is", "not", "None", ":", "\n", "        ", "new_seqs_x", "=", "[", "]", "\n", "new_seqs_y", "=", "[", "]", "\n", "new_lengths_x", "=", "[", "]", "\n", "new_lengths_y", "=", "[", "]", "\n", "for", "l_x", ",", "s_x", ",", "l_y", ",", "s_y", "in", "zip", "(", "lengths_x", ",", "seqs_x", ",", "lengths_y", ",", "seqs_y", ")", ":", "\n", "            ", "if", "l_x", "<", "maxlen", "and", "l_y", "<", "maxlen", ":", "\n", "                ", "new_seqs_x", ".", "append", "(", "s_x", ")", "\n", "new_lengths_x", ".", "append", "(", "l_x", ")", "\n", "new_seqs_y", ".", "append", "(", "s_y", ")", "\n", "new_lengths_y", ".", "append", "(", "l_y", ")", "\n", "", "", "lengths_x", "=", "new_lengths_x", "\n", "seqs_x", "=", "new_seqs_x", "\n", "lengths_y", "=", "new_lengths_y", "\n", "seqs_y", "=", "new_seqs_y", "\n", "\n", "if", "len", "(", "lengths_x", ")", "<", "1", "or", "len", "(", "lengths_y", ")", "<", "1", ":", "\n", "            ", "return", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "", "", "n_samples", "=", "len", "(", "seqs_x", ")", "\n", "maxlen_x", "=", "numpy", ".", "max", "(", "lengths_x", ")", "+", "1", "\n", "maxlen_y", "=", "numpy", ".", "max", "(", "lengths_y", ")", "+", "1", "\n", "\n", "x", "=", "numpy", ".", "zeros", "(", "(", "n_factors", ",", "maxlen_x", ",", "n_samples", ")", ")", ".", "astype", "(", "'int64'", ")", "\n", "y", "=", "numpy", ".", "zeros", "(", "(", "maxlen_y", ",", "n_samples", ")", ")", ".", "astype", "(", "'int64'", ")", "\n", "x_mask", "=", "numpy", ".", "zeros", "(", "(", "maxlen_x", ",", "n_samples", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "y_mask", "=", "numpy", ".", "zeros", "(", "(", "maxlen_y", ",", "n_samples", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "for", "idx", ",", "[", "s_x", ",", "s_y", "]", "in", "enumerate", "(", "zip", "(", "seqs_x", ",", "seqs_y", ")", ")", ":", "\n", "        ", "x", "[", ":", ",", ":", "lengths_x", "[", "idx", "]", ",", "idx", "]", "=", "list", "(", "zip", "(", "*", "s_x", ")", ")", "\n", "x_mask", "[", ":", "lengths_x", "[", "idx", "]", "+", "1", ",", "idx", "]", "=", "1.", "\n", "y", "[", ":", "lengths_y", "[", "idx", "]", ",", "idx", "]", "=", "s_y", "\n", "y_mask", "[", ":", "lengths_y", "[", "idx", "]", "+", "1", ",", "idx", "]", "=", "1.", "\n", "\n", "", "return", "x", ",", "x_mask", ",", "y", ",", "y_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dict": [[60, 81], ["logging.error", "sys.exit", "open", "json.load", "open", "pickle.load"], "function", ["None"], ["", "def", "load_dict", "(", "filename", ",", "model_type", ")", ":", "\n", "    ", "try", ":", "\n", "# build_dictionary.py writes JSON files as UTF-8 so assume that here.", "\n", "        ", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "d", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "except", ":", "\n", "# FIXME Should we be assuming UTF-8?", "\n", "        ", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "d", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "# The transformer model requires vocab dictionaries to use the new style", "\n", "# special symbols. If the dictionary looks like an old one then tell the", "\n", "# user to update it.", "\n", "", "", "if", "model_type", "==", "'transformer'", "and", "(", "\"<GO>\"", "not", "in", "d", "or", "d", "[", "\"<GO>\"", "]", "!=", "1", ")", ":", "\n", "        ", "logging", ".", "error", "(", "'you must update \\'{}\\' for use with the '", "\n", "'\\'transformer\\' model type. Please re-run '", "\n", "'build_dictionary.py to generate a new vocabulary '", "\n", "'dictionary.'", ".", "format", "(", "filename", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words": [[83, 89], ["numpy.array", "util.factoredseq2words", "len", "numpy.array.reshape"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.factoredseq2words"], ["", "def", "seq2words", "(", "seq", ",", "inverse_dictionary", ",", "join", "=", "True", ")", ":", "\n", "    ", "seq", "=", "numpy", ".", "array", "(", "seq", ",", "dtype", "=", "'int64'", ")", "\n", "assert", "len", "(", "seq", ".", "shape", ")", "==", "1", "\n", "return", "factoredseq2words", "(", "seq", ".", "reshape", "(", "[", "seq", ".", "shape", "[", "0", "]", ",", "1", "]", ")", ",", "\n", "[", "inverse_dictionary", "]", ",", "\n", "join", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.factoredseq2words": [[90, 115], ["enumerate", "len", "len", "enumerate", "words.append", "factors.append", "factors.append"], "function", ["None"], ["", "def", "factoredseq2words", "(", "seq", ",", "inverse_dictionaries", ",", "join", "=", "True", ")", ":", "\n", "    ", "assert", "len", "(", "seq", ".", "shape", ")", "==", "2", "\n", "assert", "len", "(", "inverse_dictionaries", ")", "==", "seq", ".", "shape", "[", "1", "]", "\n", "words", "=", "[", "]", "\n", "eos_reached", "=", "False", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "seq", ")", ":", "\n", "        ", "if", "eos_reached", ":", "\n", "            ", "break", "\n", "", "factors", "=", "[", "]", "\n", "for", "j", ",", "f", "in", "enumerate", "(", "w", ")", ":", "\n", "            ", "if", "f", "==", "0", ":", "\n", "                ", "eos_reached", "=", "True", "\n", "break", "\n", "# This assert has been commented out because it's possible for", "\n", "# non-zero values to follow zero values for Transformer models.", "\n", "# TODO Check why this happens", "\n", "#assert (i == len(seq) - 1) or (seq[i+1][j] == 0), \\", "\n", "#       ('Zero not at the end of sequence', seq)", "\n", "", "elif", "f", "in", "inverse_dictionaries", "[", "j", "]", ":", "\n", "                ", "factors", ".", "append", "(", "inverse_dictionaries", "[", "j", "]", "[", "f", "]", ")", "\n", "", "else", ":", "\n", "                ", "factors", ".", "append", "(", "'UNK'", ")", "\n", "", "", "word", "=", "'|'", ".", "join", "(", "factors", ")", "\n", "words", ".", "append", "(", "word", ")", "\n", "", "return", "' '", ".", "join", "(", "words", ")", "if", "join", "else", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.reverse_dict": [[116, 120], ["list", "dict", "zip", "list", "zip", "list", "dictt.items"], "function", ["None"], ["", "def", "reverse_dict", "(", "dictt", ")", ":", "\n", "    ", "keys", ",", "values", "=", "list", "(", "zip", "(", "*", "list", "(", "dictt", ".", "items", "(", ")", ")", ")", ")", "\n", "r_dictt", "=", "dict", "(", "list", "(", "zip", "(", "values", ",", "keys", ")", ")", ")", "\n", "return", "r_dictt", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dictionaries": [[122, 129], ["util.load_dict", "util.reverse_dict", "util.load_dict", "util.reverse_dict"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dict", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.reverse_dict", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dict", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.reverse_dict"], ["", "def", "load_dictionaries", "(", "config", ")", ":", "\n", "    ", "model_type", "=", "config", ".", "model_type", "\n", "source_to_num", "=", "[", "load_dict", "(", "d", ",", "model_type", ")", "for", "d", "in", "config", ".", "source_dicts", "]", "\n", "target_to_num", "=", "load_dict", "(", "config", ".", "target_dict", ",", "model_type", ")", "\n", "num_to_source", "=", "[", "reverse_dict", "(", "d", ")", "for", "d", "in", "source_to_num", "]", "\n", "num_to_target", "=", "reverse_dict", "(", "target_to_num", ")", "\n", "return", "source_to_num", ",", "target_to_num", ",", "num_to_source", ",", "num_to_target", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.read_all_lines": [[131, 169], ["util.load_dictionaries", "numpy.array", "numpy.array", "numpy.array.argsort", "range", "zip", "sent.strip().split", "numpy.array.append", "len", "batches.append", "len", "len", "line.append", "len", "list", "sent.strip", "d.items", "len", "exception.Error", "enumerate", "w.split", "len"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dictionaries"], ["", "def", "read_all_lines", "(", "config", ",", "sentences", ",", "batch_size", ")", ":", "\n", "    ", "source_to_num", ",", "_", ",", "_", ",", "_", "=", "load_dictionaries", "(", "config", ")", "\n", "\n", "if", "config", ".", "source_vocab_sizes", "!=", "None", ":", "\n", "        ", "assert", "len", "(", "config", ".", "source_vocab_sizes", ")", "==", "len", "(", "source_to_num", ")", "\n", "for", "d", ",", "vocab_size", "in", "zip", "(", "source_to_num", ",", "config", ".", "source_vocab_sizes", ")", ":", "\n", "            ", "if", "vocab_size", "!=", "None", "and", "vocab_size", ">", "0", ":", "\n", "                ", "for", "key", ",", "idx", "in", "list", "(", "d", ".", "items", "(", ")", ")", ":", "\n", "                    ", "if", "idx", ">=", "vocab_size", ":", "\n", "                        ", "del", "d", "[", "key", "]", "\n", "\n", "", "", "", "", "", "lines", "=", "[", "]", "\n", "for", "sent", "in", "sentences", ":", "\n", "        ", "line", "=", "[", "]", "\n", "for", "w", "in", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", ":", "\n", "            ", "if", "config", ".", "factors", "==", "1", ":", "\n", "                ", "w", "=", "[", "source_to_num", "[", "0", "]", "[", "w", "]", "if", "w", "in", "source_to_num", "[", "0", "]", "else", "2", "]", "\n", "", "else", ":", "\n", "                ", "w", "=", "[", "source_to_num", "[", "i", "]", "[", "f", "]", "if", "f", "in", "source_to_num", "[", "i", "]", "else", "2", "\n", "for", "(", "i", ",", "f", ")", "in", "enumerate", "(", "w", ".", "split", "(", "'|'", ")", ")", "]", "\n", "if", "len", "(", "w", ")", "!=", "config", ".", "factors", ":", "\n", "                    ", "raise", "exception", ".", "Error", "(", "\n", "'Expected {0} factors, but input word has {1}\\n'", ".", "format", "(", "\n", "config", ".", "factors", ",", "len", "(", "w", ")", ")", ")", "\n", "", "", "line", ".", "append", "(", "w", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "lines", "=", "numpy", ".", "array", "(", "lines", ")", "\n", "lengths", "=", "numpy", ".", "array", "(", "[", "len", "(", "l", ")", "for", "l", "in", "lines", "]", ")", "\n", "idxs", "=", "lengths", ".", "argsort", "(", ")", "\n", "lines", "=", "lines", "[", "idxs", "]", "\n", "\n", "#merge into batches", "\n", "batches", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "lines", ")", ",", "batch_size", ")", ":", "\n", "        ", "batch", "=", "lines", "[", "i", ":", "i", "+", "batch_size", "]", "\n", "batches", ".", "append", "(", "batch", ")", "\n", "\n", "", "return", "batches", ",", "idxs", "\n", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sampling_utils.SamplingUtils.__init__": [[6, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config_or_settings_obj", ")", ":", "\n", "        ", "self", ".", "sampling_temperature", "=", "config_or_settings_obj", ".", "sampling_temperature", "\n", "self", ".", "translation_strategy", "=", "config_or_settings_obj", ".", "translation_strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sampling_utils.SamplingUtils.adjust_logits": [[10, 16], ["logging.debug", "tensorflow.constant"], "methods", ["None"], ["", "def", "adjust_logits", "(", "self", ",", "logits", ")", ":", "\n", "        ", "if", "self", ".", "sampling_temperature", "!=", "1.0", ":", "\n", "            ", "logging", ".", "debug", "(", "\"adjust temperature\"", ")", "\n", "logits", "=", "logits", "/", "tf", ".", "constant", "(", "self", ".", "sampling_temperature", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer.__init__": [[28, 52], ["bottle.Bottle", "server.NematusServer._server.install", "logging.info", "logging.info", "server_translator.Translator", "bottle_log.LoggingPlugin"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "server_settings", ")", ":", "\n", "        ", "\"\"\"\n        Loads a translation model and initialises the webserver.\n\n        @param server_settings: see `settings.py`\n        \"\"\"", "\n", "self", ".", "_style", "=", "server_settings", ".", "style", "\n", "self", ".", "_host", "=", "server_settings", ".", "host", "\n", "self", ".", "_port", "=", "server_settings", ".", "port", "\n", "self", ".", "_threads", "=", "server_settings", ".", "threads", "\n", "self", ".", "_debug", "=", "server_settings", ".", "verbose", "\n", "self", ".", "_models", "=", "server_settings", ".", "models", "\n", "self", ".", "_num_processes", "=", "server_settings", ".", "num_processes", "\n", "self", ".", "_status", "=", "self", ".", "STATUS_LOADING", "\n", "# start webserver", "\n", "self", ".", "_server", "=", "Bottle", "(", ")", "\n", "self", ".", "_server", ".", "config", "[", "'logging.level'", "]", "=", "'DEBUG'", "if", "server_settings", ".", "verbose", "else", "'WARNING'", "\n", "self", ".", "_server", ".", "config", "[", "'logging.format'", "]", "=", "'%(levelname)s: %(message)s'", "\n", "self", ".", "_server", ".", "install", "(", "LoggingPlugin", "(", "self", ".", "_server", ".", "config", ")", ")", "\n", "logging", ".", "info", "(", "\"Starting Nematus Server\"", ")", "\n", "# start translation workers", "\n", "logging", ".", "info", "(", "\"Loading translation models\"", ")", "\n", "self", ".", "_translator", "=", "Translator", "(", "server_settings", ")", "\n", "self", ".", "_status", "=", "self", ".", "STATUS_OK", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer.status": [[53, 65], ["json.dumps", "pkg_resources.require"], "methods", ["None"], ["", "def", "status", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reports on the status of this translation server.\n        \"\"\"", "\n", "response_data", "=", "{", "\n", "'status'", ":", "self", ".", "_status", ",", "\n", "'models'", ":", "self", ".", "_models", ",", "\n", "'version'", ":", "pkg_resources", ".", "require", "(", "\"nematus\"", ")", "[", "0", "]", ".", "version", ",", "\n", "'service'", ":", "'nematus'", ",", "\n", "}", "\n", "response", ".", "content_type", "=", "\"application/json\"", "\n", "return", "json", ".", "dumps", "(", "response_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer.translate": [[66, 86], ["server.api.provider.request_provider", "logging.debug", "server.NematusServer._translator.translate", "server.api.provider.response_provider", "logging.debug", "server.api.provider.response_provider.get_content_type", "repr", "repr", "repr"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.provider.request_provider", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.translate", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.provider.response_provider", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.response.TranslationResponse.get_content_type"], ["", "def", "translate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Processes a translation request.\n        \"\"\"", "\n", "translation_request", "=", "request_provider", "(", "self", ".", "_style", ",", "request", ")", "\n", "logging", ".", "debug", "(", "\"REQUEST - \"", "+", "repr", "(", "translation_request", ")", ")", "\n", "\n", "translations", "=", "self", ".", "_translator", ".", "translate", "(", "\n", "translation_request", ".", "segments", ",", "\n", "translation_request", ".", "settings", "\n", ")", "\n", "response_data", "=", "{", "\n", "'status'", ":", "TranslationResponse", ".", "STATUS_OK", ",", "\n", "'segments'", ":", "[", "translation", ".", "target_words", "for", "translation", "in", "translations", "]", ",", "\n", "}", "\n", "translation_response", "=", "response_provider", "(", "self", ".", "_style", ",", "**", "response_data", ")", "\n", "logging", ".", "debug", "(", "\"RESPONSE - \"", "+", "repr", "(", "translation_response", ")", ")", "\n", "\n", "response", ".", "content_type", "=", "translation_response", ".", "get_content_type", "(", ")", "\n", "return", "repr", "(", "translation_response", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer.start": [[87, 94], ["server.NematusServer._route", "server.NematusServer._server.run", "server.NematusServer._cleanup"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer._route", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer._cleanup"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Starts the webserver.\n        \"\"\"", "\n", "self", ".", "_route", "(", ")", "\n", "self", ".", "_server", ".", "run", "(", "host", "=", "self", ".", "_host", ",", "port", "=", "self", ".", "_port", ",", "debug", "=", "self", ".", "_debug", ",", "server", "=", "'tornado'", ",", "threads", "=", "self", ".", "_threads", ")", "\n", "self", ".", "_cleanup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer._cleanup": [[95, 100], ["server.NematusServer._translator.shutdown"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server_translator.Translator.shutdown"], ["", "def", "_cleanup", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Graceful exit for components.\n        \"\"\"", "\n", "self", ".", "_translator", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.server.NematusServer._route": [[101, 107], ["server.NematusServer._server.route", "server.NematusServer._server.route"], "methods", ["None"], ["", "def", "_route", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Routes webserver paths to functions.\n        \"\"\"", "\n", "self", ".", "_server", ".", "route", "(", "'/status'", ",", "method", "=", "\"GET\"", ",", "callback", "=", "self", ".", "status", ")", "\n", "self", ".", "_server", ".", "route", "(", "'/translate'", ",", "method", "=", "\"POST\"", ",", "callback", "=", "self", ".", "translate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.__init__": [[22, 26], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "config", ",", "scope", ")", ":", "\n", "        ", "self", ".", "_model", "=", "model", "\n", "self", ".", "_config", "=", "config", "\n", "self", ".", "_scope", "=", "scope", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.model": [[27, 30], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.config": [[31, 34], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_config", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.target_vocab_size": [[35, 38], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", ".", "decoder", ".", "target_vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.batch_size": [[39, 42], ["tensorflow.shape"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "shape", "(", "input", "=", "self", ".", "_model", ".", "inputs", ".", "x", ")", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.encode": [[43, 45], ["None"], "methods", ["None"], ["", "def", "encode", "(", "self", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.generate_decoding_function": [[46, 125], ["tensorflow.cond", "d.grustep1.forward", "d.attstep.forward", "d.grustep2.forward", "d.predictor.get_logits", "tensorflow.compat.v1.name_scope", "tf_utils.assert_shapes", "rnn_inference.ModelAdapter.generate_decoding_function._decoding_function_inner"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Predictor.get_logits", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.assert_shapes"], ["", "def", "generate_decoding_function", "(", "self", ",", "encoder_output", ")", ":", "\n", "\n", "        ", "def", "_decoding_function_outer", "(", "step_target_ids", ",", "current_time_step", ",", "\n", "memories", ")", ":", "\n", "            ", "\"\"\"Single-step decoding function (outer version).\n\n            This is a wrapper around _decoding_function_inner() that does some\n            housekeeping before calling that function to do the actual work.\n\n            Args:\n                step_target_ids: Tensor with shape (batch_size)\n                current_time_step: scalar Tensor.\n                memories: dictionary (see top-level class description)\n\n            Returns:\n            \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "\n", "                ", "shapes", "=", "{", "step_target_ids", ":", "(", "'batch_size'", ",", ")", "}", "\n", "tf_utils", ".", "assert_shapes", "(", "shapes", ")", "\n", "\n", "logits", ",", "memories", "[", "'base_states'", "]", ",", "memories", "[", "'high_states'", "]", "=", "_decoding_function_inner", "(", "\n", "step_target_ids", ",", "memories", "[", "'base_states'", "]", ",", "\n", "memories", "[", "'high_states'", "]", ",", "current_time_step", ")", "\n", "\n", "return", "logits", ",", "memories", "\n", "\n", "", "", "def", "_decoding_function_inner", "(", "vocab_ids", ",", "prev_base_states", ",", "\n", "prev_high_states", ",", "current_time_step", ")", ":", "\n", "            ", "\"\"\"Single-step decoding function (inner version).\n\n            Args:\n                vocab_ids: TODO\n                prev_base_states: TODO\n                prev_high_states: TODO\n                current_time_step: TODO\n\n            Returns:\n            \"\"\"", "\n", "d", "=", "self", ".", "_model", ".", "decoder", "\n", "\n", "# The first time step is a special case for the RNN since there is", "\n", "# no (valid) input token and no word embeddings to lookup. Like in", "\n", "# training, we use zero-valued dummy embeddings.", "\n", "# This differs from the Transformer model, which has a BOS token", "\n", "# (called <GO>) with an associated embedding that is learned during", "\n", "# training.", "\n", "embeddings", "=", "tf", ".", "cond", "(", "\n", "pred", "=", "tf", ".", "equal", "(", "current_time_step", ",", "1", ")", ",", "\n", "true_fn", "=", "lambda", ":", "d", ".", "y_emb_layer", ".", "zero", "(", "vocab_ids", ",", "factor", "=", "0", ")", ",", "\n", "false_fn", "=", "lambda", ":", "d", ".", "y_emb_layer", ".", "forward", "(", "vocab_ids", ",", "factor", "=", "0", ")", ")", "\n", "\n", "states1", "=", "d", ".", "grustep1", ".", "forward", "(", "prev_base_states", ",", "embeddings", ")", "\n", "att_ctx", ",", "att_alphas", "=", "d", ".", "attstep", ".", "forward", "(", "states1", ")", "\n", "base_states", "=", "d", ".", "grustep2", ".", "forward", "(", "states1", ",", "att_ctx", ")", "\n", "\n", "if", "d", ".", "high_gru_stack", "is", "None", ":", "\n", "                ", "stack_output", "=", "base_states", "\n", "high_states", "=", "[", "]", "\n", "", "elif", "d", ".", "high_gru_stack", ".", "context_state_size", "==", "0", ":", "\n", "                ", "stack_output", ",", "high_states", "=", "d", ".", "high_gru_stack", ".", "forward_single", "(", "\n", "prev_high_states", ",", "base_states", ")", "\n", "", "else", ":", "\n", "                ", "stack_output", ",", "high_states", "=", "d", ".", "high_gru_stack", ".", "forward_single", "(", "\n", "prev_high_states", ",", "base_states", ",", "context", "=", "att_ctx", ")", "\n", "\n", "", "if", "d", ".", "lexical_layer", "is", "not", "None", ":", "\n", "                ", "lexical_state", "=", "d", ".", "lexical_layer", ".", "forward", "(", "d", ".", "x_embs", ",", "att_alphas", ")", "\n", "", "else", ":", "\n", "                ", "lexical_state", "=", "None", "\n", "\n", "", "logits", "=", "d", ".", "predictor", ".", "get_logits", "(", "\n", "embeddings", ",", "stack_output", ",", "att_ctx", ",", "lexical_state", ",", "\n", "multi_step", "=", "False", ")", "\n", "\n", "return", "logits", ",", "base_states", ",", "high_states", "\n", "\n", "", "return", "_decoding_function_outer", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.generate_initial_memories": [[126, 140], ["tensorflow.compat.v1.name_scope", "tf_utils.assert_shapes", "len"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.assert_shapes"], ["", "def", "generate_initial_memories", "(", "self", ",", "batch_size", ",", "beam_size", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "            ", "d", "=", "self", ".", "_model", ".", "decoder", "\n", "\n", "shapes", "=", "{", "d", ".", "init_state", ":", "(", "'batch_size'", ",", "self", ".", "config", ".", "state_size", ")", "}", "\n", "tf_utils", ".", "assert_shapes", "(", "shapes", ")", "\n", "\n", "high_depth", "=", "0", "if", "d", ".", "high_gru_stack", "is", "None", "else", "len", "(", "d", ".", "high_gru_stack", ".", "grus", ")", "\n", "\n", "initial_memories", "=", "{", "}", "\n", "initial_memories", "[", "'base_states'", "]", "=", "d", ".", "init_state", "\n", "initial_memories", "[", "'high_states'", "]", "=", "[", "d", ".", "init_state", "]", "*", "high_depth", "\n", "return", "initial_memories", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.get_memory_invariants": [[142, 165], ["tensorflow.compat.v1.name_scope", "len", "tensorflow.TensorShape", "len", "tf_utils.get_shape_list"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list"], ["", "", "def", "get_memory_invariants", "(", "self", ",", "memories", ")", ":", "\n", "        ", "\"\"\"Generate shape invariants for memories.\n\n        Args:\n            memories: dictionary (see top-level class description)\n\n        Returns:\n            Dictionary of shape invariants with same structure as memories.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "            ", "d", "=", "self", ".", "_model", ".", "decoder", "\n", "\n", "high_depth", "=", "0", "if", "d", ".", "high_gru_stack", "is", "None", "else", "len", "(", "d", ".", "high_gru_stack", ".", "grus", ")", "\n", "\n", "num_dims", "=", "len", "(", "tf_utils", ".", "get_shape_list", "(", "memories", "[", "'base_states'", "]", ")", ")", "\n", "# TODO Specify shape in full?", "\n", "partial_shape", "=", "tf", ".", "TensorShape", "(", "[", "None", "]", "*", "num_dims", ")", "\n", "\n", "invariants", "=", "{", "}", "\n", "invariants", "[", "'base_states'", "]", "=", "partial_shape", "\n", "invariants", "[", "'high_states'", "]", "=", "[", "partial_shape", "]", "*", "high_depth", "\n", "return", "invariants", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_inference.ModelAdapter.gather_memories": [[167, 207], ["tensorflow.compat.v1.name_scope", "tf_utils.assert_shapes", "tensorflow.shape", "rnn_inference.ModelAdapter.gather_memories.gather_states"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.assert_shapes"], ["", "", "def", "gather_memories", "(", "self", ",", "memories", ",", "gather_coordinates", ")", ":", "\n", "        ", "\"\"\"Gathers memories for selected beam entries.\n\n        Args:\n            memories: dictionary (see top-level class description)\n            gather_coordinates: Tensor with shape [batch_size_x, beam_size, 2]\n\n        Returns:\n            Dictionary containing gathered memories.\n        \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "self", ".", "_scope", ")", ":", "\n", "\n", "            ", "shapes", "=", "{", "gather_coordinates", ":", "(", "'batch_size_x'", ",", "'beam_size'", ",", "2", ")", "}", "\n", "tf_utils", ".", "assert_shapes", "(", "shapes", ")", "\n", "\n", "coords_shape", "=", "tf", ".", "shape", "(", "input", "=", "gather_coordinates", ")", "\n", "batch_size_x", ",", "beam_size", "=", "coords_shape", "[", "0", "]", ",", "coords_shape", "[", "1", "]", "\n", "\n", "def", "gather_states", "(", "states", ")", ":", "\n", "                ", "shapes", "=", "{", "states", ":", "(", "'batch_size'", ",", "self", ".", "_config", ".", "state_size", ")", "}", "\n", "tf_utils", ".", "assert_shapes", "(", "shapes", ")", "\n", "states_shape", "=", "tf", ".", "shape", "(", "input", "=", "states", ")", "\n", "state_size", "=", "states_shape", "[", "1", "]", "\n", "tmp", "=", "tf", ".", "reshape", "(", "states", ",", "[", "beam_size", ",", "batch_size_x", ",", "state_size", "]", ")", "\n", "flat_tensor", "=", "tf", ".", "transpose", "(", "a", "=", "tmp", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "tmp", "=", "tf", ".", "gather_nd", "(", "flat_tensor", ",", "gather_coordinates", ")", "\n", "tmp", "=", "tf", ".", "transpose", "(", "a", "=", "tmp", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "gathered_values", "=", "tf", ".", "reshape", "(", "tmp", ",", "states_shape", ")", "\n", "return", "gathered_values", "\n", "\n", "", "gathered_memories", "=", "{", "}", "\n", "\n", "gathered_memories", "[", "'base_states'", "]", "=", "gather_states", "(", "memories", "[", "'base_states'", "]", ")", "\n", "\n", "gathered_memories", "[", "'high_states'", "]", "=", "[", "\n", "gather_states", "(", "states", ")", "for", "states", "in", "memories", "[", "'high_states'", "]", "\n", "]", "\n", "\n", "return", "gathered_memories", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader.init_or_restore_variables": [[23, 156], ["re.compile", "tensorflow.python.framework.ops.get_collection", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.global_variables_initializer", "logging.info", "re.compile.match", "model_loader.init_or_restore_variables.is_excluded_variable"], "function", ["None"], ["", "def", "init_or_restore_variables", "(", "config", ",", "sess", ",", "ensemble_scope", "=", "None", ",", "train", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initializes all variables or restores variables from a checkpoint.\n\n    Prior to calling this function, the model (or models if using an ensemble)\n    should already have been created. If a model uses exponential smoothing,\n    then the _smooth versions of its variables should also have been created\n    (by constructing an ExponentialSmoothing object). This function will then\n    initialize the variables or restore them from a checkpoint (if one can be\n    found).\n\n    When using an ensemble, this function should be called once for each\n    model, with each call using model-specific config and ensemble_scope\n    arguments.\n\n    Args:\n      config: Namespace object specifying the config for the current model.\n      sess: a TensorFlow session.\n      ensemble_scope: a tf.variable_scope for the current model if ensembling.\n      train: Boolean specifying that the model is being used for training.\n\n    Returns:\n      If train is True, returns a pair (saver, progress) where saver is a\n      tf.train.Saver and progress is a training_progress.TrainingProgress\n      object. Otherwise, just returns the saver.\n    \"\"\"", "\n", "\n", "accum_regex", "=", "re", ".", "compile", "(", "'^accum\\d+$'", ")", "\n", "\n", "def", "is_excluded_variable", "(", "name", ")", ":", "\n", "# Exclude gradient accumulation variables.", "\n", "        ", "if", "accum_regex", ".", "match", "(", "name", ")", ":", "\n", "            ", "return", "True", "\n", "", "if", "name", "==", "'accumulated_loss'", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "variables", "=", "ops", ".", "get_collection", "(", "ops", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "\n", "# Construct a mapping between saved variable names and names in the current", "\n", "# scope. There are two reasons why names might be different:", "\n", "#", "\n", "#   1. This model is part of an ensemble, in which case a model-specific", "\n", "#       name scope will be active.", "\n", "#", "\n", "#   2. The saved model is from an old version of Nematus (before deep model", "\n", "#        support was added) and uses a different variable naming scheme", "\n", "#        for the GRUs.", "\n", "\n", "var_map", "=", "{", "}", "\n", "for", "v", "in", "variables", ":", "\n", "        ", "name", "=", "v", ".", "name", ".", "split", "(", "':'", ")", "[", "0", "]", "\n", "if", "ensemble_scope", "==", "None", ":", "\n", "            ", "saved_name", "=", "name", "\n", "", "elif", "v", ".", "name", ".", "startswith", "(", "ensemble_scope", ".", "name", "+", "\"/\"", ")", ":", "\n", "            ", "saved_name", "=", "name", "[", "len", "(", "ensemble_scope", ".", "name", ")", "+", "1", ":", "]", "\n", "# The ensemble scope is repeated for Adam variables. See", "\n", "# https://github.com/tensorflow/tensorflow/issues/8120", "\n", "if", "saved_name", ".", "startswith", "(", "ensemble_scope", ".", "name", "+", "\"/\"", ")", ":", "\n", "                ", "saved_name", "=", "saved_name", "[", "len", "(", "ensemble_scope", ".", "name", ")", "+", "1", ":", "]", "\n", "", "", "else", ":", "# v belongs to a different model in the ensemble.", "\n", "            ", "continue", "\n", "", "if", "is_excluded_variable", "(", "saved_name", ")", ":", "\n", "            ", "continue", "\n", "", "if", "config", ".", "model_version", "==", "0.1", ":", "\n", "# Backwards compatibility with the old variable naming scheme.", "\n", "            ", "saved_name", "=", "_revert_variable_name", "(", "saved_name", ",", "0.1", ")", "\n", "", "var_map", "[", "saved_name", "]", "=", "v", "\n", "", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "var_map", ",", "max_to_keep", "=", "None", ")", "\n", "\n", "# compute reload model filename", "\n", "reload_filename", "=", "None", "\n", "if", "config", ".", "reload", "==", "'latest_checkpoint'", ":", "\n", "        ", "checkpoint_dir", "=", "os", ".", "path", ".", "dirname", "(", "config", ".", "saveto", ")", "\n", "reload_filename", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "if", "reload_filename", "!=", "None", ":", "\n", "            ", "if", "(", "os", ".", "path", ".", "basename", "(", "reload_filename", ")", ".", "rsplit", "(", "'-'", ",", "1", ")", "[", "0", "]", "!=", "\n", "os", ".", "path", ".", "basename", "(", "config", ".", "saveto", ")", ")", ":", "\n", "                ", "logging", ".", "error", "(", "\"Mismatching model filename found in the same directory while reloading from the latest checkpoint\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "logging", ".", "info", "(", "'Latest checkpoint found in directory '", "+", "os", ".", "path", ".", "abspath", "(", "checkpoint_dir", ")", ")", "\n", "", "", "elif", "config", ".", "reload", "!=", "None", ":", "\n", "        ", "reload_filename", "=", "config", ".", "reload", "\n", "", "if", "(", "reload_filename", "==", "None", ")", "and", "(", "config", ".", "prior_model", "!=", "None", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Initializing model parameters from prior'", ")", "\n", "reload_filename", "=", "config", ".", "prior_model", "\n", "\n", "# initialize or reload training progress", "\n", "", "if", "train", ":", "\n", "        ", "progress", "=", "training_progress", ".", "TrainingProgress", "(", ")", "\n", "progress", ".", "bad_counter", "=", "0", "\n", "progress", ".", "uidx", "=", "0", "\n", "progress", ".", "eidx", "=", "0", "\n", "progress", ".", "estop", "=", "False", "\n", "progress", ".", "history_errs", "=", "[", "]", "\n", "progress", ".", "valid_script_scores", "=", "[", "]", "\n", "if", "reload_filename", "and", "config", ".", "reload_training_progress", ":", "\n", "            ", "path", "=", "reload_filename", "+", "'.progress.json'", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "                ", "logging", ".", "info", "(", "'Reloading training progress'", ")", "\n", "progress", ".", "load_from_json", "(", "path", ")", "\n", "if", "(", "progress", ".", "estop", "==", "True", "or", "\n", "progress", ".", "eidx", ">", "config", ".", "max_epochs", "or", "\n", "progress", ".", "uidx", ">=", "config", ".", "finish_after", ")", ":", "\n", "                    ", "logging", ".", "warning", "(", "'Training is already complete. Disable reloading of training progress (--no_reload_training_progress) or remove or modify progress file (%s) to train anyway.'", "%", "path", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "# load prior model", "\n", "", "", "", "", "if", "train", "and", "config", ".", "prior_model", "!=", "None", ":", "\n", "        ", "load_prior", "(", "config", ",", "sess", ",", "saver", ")", "\n", "\n", "", "init_op", "=", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", "\n", "\n", "# initialize or restore model", "\n", "if", "reload_filename", "==", "None", ":", "\n", "        ", "logging", ".", "info", "(", "'Initializing model parameters from scratch...'", ")", "\n", "sess", ".", "run", "(", "init_op", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "'Loading model parameters from file '", "+", "os", ".", "path", ".", "abspath", "(", "reload_filename", ")", ")", "\n", "if", "train", ":", "\n", "# Initialize all variables before restoring from the checkpoint.", "\n", "# This is to allow for variables that are not saved to the", "\n", "# checkpoint. Currently that is just the gradient accumulation", "\n", "# variables, which are unusual in that they persist across multiple", "\n", "# sessions during training (and therefore need to be variables) but", "\n", "# are regularly reset to zero.", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "", "saver", ".", "restore", "(", "sess", ",", "os", ".", "path", ".", "abspath", "(", "reload_filename", ")", ")", "\n", "", "logging", ".", "info", "(", "'Done'", ")", "\n", "\n", "if", "train", ":", "\n", "        ", "return", "saver", ",", "progress", "\n", "", "else", ":", "\n", "        ", "return", "saver", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader.load_prior": [[158, 173], ["logging.info", "saver.restore", "tensorflow.compat.v1.get_collection_ref", "dict", "tensorflow.compat.v1.variables_initializer", "sess.run", "os.path.abspath", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.trainable_variables", "os.path.abspath", "assign_tensors.append", "prior_variable.assign"], "function", ["None"], ["", "", "def", "load_prior", "(", "config", ",", "sess", ",", "saver", ")", ":", "\n", "     ", "logging", ".", "info", "(", "'Loading prior model parameters from file '", "+", "os", ".", "path", ".", "abspath", "(", "config", ".", "prior_model", ")", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "os", ".", "path", ".", "abspath", "(", "config", ".", "prior_model", ")", ")", "\n", "\n", "# fill prior variables with the loaded values", "\n", "prior_variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection_ref", "(", "'prior_variables'", ")", "\n", "prior_variables_dict", "=", "dict", "(", "[", "(", "v", ".", "name", ",", "v", ")", "for", "v", "in", "prior_variables", "]", ")", "\n", "assign_tensors", "=", "[", "]", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'prior'", ")", ":", "\n", "         ", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ":", "\n", "             ", "prior_name", "=", "'loss/prior/'", "+", "v", ".", "name", "\n", "prior_variable", "=", "prior_variables_dict", "[", "prior_name", "]", "\n", "assign_tensors", ".", "append", "(", "prior_variable", ".", "assign", "(", "v", ")", ")", "\n", "", "", "tf", ".", "compat", ".", "v1", ".", "variables_initializer", "(", "prior_variables", ")", "\n", "sess", ".", "run", "(", "assign_tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader._revert_variable_name": [[176, 203], ["name.endswith", "name.endswith", "name.replace", "name.replace", "name.replace", "name.replace", "name.replace", "name.replace.endswith", "name.replace", "model_loader._revert_variable_name", "model_loader._revert_variable_name", "name.replace.replace", "name.replace.endswith", "name.replace.replace", "len", "len"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader._revert_variable_name", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader._revert_variable_name"], ["", "def", "_revert_variable_name", "(", "name", ",", "old_version", ")", ":", "\n", "    ", "assert", "old_version", "==", "0.1", "\n", "if", "name", ".", "endswith", "(", "\"/Adam\"", ")", ":", "\n", "        ", "prefix", "=", "name", "[", ":", "-", "len", "(", "\"/Adam\"", ")", "]", "\n", "return", "_revert_variable_name", "(", "prefix", ",", "old_version", ")", "+", "\"/Adam\"", "\n", "", "if", "name", ".", "endswith", "(", "\"/Adam_1\"", ")", ":", "\n", "        ", "prefix", "=", "name", "[", ":", "-", "len", "(", "\"/Adam_1\"", ")", "]", "\n", "return", "_revert_variable_name", "(", "prefix", ",", "old_version", ")", "+", "\"/Adam_1\"", "\n", "", "if", "\"forward-stack/level0/gru0\"", "in", "name", ":", "\n", "        ", "return", "name", ".", "replace", "(", "\"forward-stack/level0/gru0\"", ",", "\"forwardEncoder\"", ")", "\n", "", "if", "\"backward-stack/level0/gru0\"", "in", "name", ":", "\n", "        ", "return", "name", ".", "replace", "(", "\"backward-stack/level0/gru0\"", ",", "\"backwardEncoder\"", ")", "\n", "", "if", "\"decoder/base/gru0\"", "in", "name", ":", "\n", "        ", "return", "name", ".", "replace", "(", "\"decoder/base/gru0\"", ",", "\"decoder\"", ")", "\n", "", "if", "\"decoder/base/attention\"", "in", "name", ":", "\n", "        ", "return", "name", ".", "replace", "(", "\"decoder/base/attention\"", ",", "\"decoder\"", ")", "\n", "", "if", "\"decoder/base/gru1\"", "in", "name", ":", "\n", "        ", "tmp", "=", "name", ".", "replace", "(", "\"decoder/base/gru1\"", ",", "\"decoder\"", ")", "\n", "if", "tmp", ".", "endswith", "(", "\"/new_mean\"", ")", ":", "\n", "            ", "return", "tmp", ".", "replace", "(", "\"/new_mean\"", ",", "\"_1/new_mean\"", ")", "\n", "", "elif", "tmp", ".", "endswith", "(", "\"/new_std\"", ")", ":", "\n", "            ", "return", "tmp", ".", "replace", "(", "\"/new_std\"", ",", "\"_1/new_std\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "tmp", "+", "\"_1\"", "\n", "", "", "if", "\"decoder/embedding\"", "in", "name", ":", "\n", "        ", "return", "name", ".", "replace", "(", "\"decoder/embedding\"", ",", "\"decoder/y_embeddings_layer\"", ")", "\n", "", "return", "name", "\n", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.Transformer.__init__": [[40, 103], ["model_inputs.ModelInputs", "transformer.Transformer._convert_inputs", "tensorflow.compat.v1.name_scope", "transformer.Transformer._build_graph", "tensorflow.compat.v1.name_scope", "MaskedCrossEntropy", "MaskedCrossEntropy.forward", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "SamplingUtils", "tensorflow.compat.v1.name_scope", "transformer.Transformer.enc.encode", "tensorflow.compat.v1.name_scope", "transformer.Transformer.dec.decode_at_train", "tensorflow.math.exp", "mru.mrt_cost"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.Transformer._convert_inputs", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder._build_graph", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder.encode", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder.decode_at_train", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.mrt_utils.mrt_cost"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "# Set attributes", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "source_vocab_size", "=", "config", ".", "source_vocab_sizes", "[", "0", "]", "\n", "self", ".", "target_vocab_size", "=", "config", ".", "target_vocab_size", "\n", "self", ".", "name", "=", "'transformer'", "\n", "\n", "# Placeholders", "\n", "self", ".", "inputs", "=", "model_inputs", ".", "ModelInputs", "(", "config", ")", "\n", "\n", "# Convert from time-major to batch-major, handle factors", "\n", "self", ".", "source_ids", ",", "self", ".", "source_mask", ",", "self", ".", "target_ids_in", ",", "self", ".", "target_ids_out", ",", "self", ".", "target_mask", "=", "self", ".", "_convert_inputs", "(", "self", ".", "inputs", ")", "\n", "\n", "self", ".", "training", "=", "self", ".", "inputs", ".", "training", "\n", "self", ".", "scores", "=", "self", ".", "inputs", ".", "scores", "\n", "self", ".", "index", "=", "self", ".", "inputs", ".", "index", "\n", "\n", "# Build the common parts of the graph.", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "'{:s}_loss'", ".", "format", "(", "self", ".", "name", ")", ")", ":", "\n", "# (Re-)generate the computational graph", "\n", "            ", "self", ".", "dec_vocab_size", "=", "self", ".", "_build_graph", "(", ")", "\n", "\n", "# Build the training-specific parts of the graph.", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "'{:s}_loss'", ".", "format", "(", "self", ".", "name", ")", ")", ":", "\n", "# Encode source sequences", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "'{:s}_encode'", ".", "format", "(", "self", ".", "name", ")", ")", ":", "\n", "                ", "enc_output", ",", "cross_attn_mask", "=", "self", ".", "enc", ".", "encode", "(", "\n", "self", ".", "source_ids", ",", "self", ".", "source_mask", ")", "\n", "# Decode into target sequences", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "name_scope", "(", "'{:s}_decode'", ".", "format", "(", "self", ".", "name", ")", ")", ":", "\n", "                ", "logits", "=", "self", ".", "dec", ".", "decode_at_train", "(", "self", ".", "target_ids_in", ",", "\n", "enc_output", ",", "\n", "cross_attn_mask", ")", "\n", "# Instantiate loss layer(s)", "\n", "", "loss_layer", "=", "MaskedCrossEntropy", "(", "self", ".", "dec_vocab_size", ",", "\n", "self", ".", "config", ".", "label_smoothing", ",", "\n", "INT_DTYPE", ",", "\n", "FLOAT_DTYPE", ",", "\n", "time_major", "=", "False", ",", "\n", "name", "=", "'loss_layer'", ")", "\n", "# Calculate loss", "\n", "masked_loss", ",", "sentence_loss", ",", "batch_loss", "=", "loss_layer", ".", "forward", "(", "logits", ",", "self", ".", "target_ids_out", ",", "self", ".", "target_mask", ",", "self", ".", "training", ")", "\n", "if", "self", ".", "config", ".", "print_per_token_pro", ":", "\n", "# e**(-(-log(probability))) =  probability", "\n", "                ", "self", ".", "_print_pro", "=", "tf", ".", "math", ".", "exp", "(", "-", "masked_loss", ")", "\n", "\n", "", "sent_lens", "=", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "self", ".", "target_mask", ",", "axis", "=", "1", ",", "keepdims", "=", "False", ")", "\n", "self", ".", "_loss_per_sentence", "=", "sentence_loss", "*", "sent_lens", "\n", "self", ".", "_loss", "=", "tf", ".", "reduce_mean", "(", "input_tensor", "=", "self", ".", "_loss_per_sentence", ",", "keepdims", "=", "False", ")", "\n", "\n", "# calculate expected risk", "\n", "if", "self", ".", "config", ".", "loss_function", "==", "'MRT'", ":", "\n", "# self._loss_per_sentence is negative log probability of the output sentence, each element represents", "\n", "# the loss of each sample pair.", "\n", "                ", "self", ".", "_risk", "=", "mru", ".", "mrt_cost", "(", "self", ".", "_loss_per_sentence", ",", "self", ".", "scores", ",", "self", ".", "index", ",", "self", ".", "config", ")", "\n", "\n", "", "self", ".", "sampling_utils", "=", "SamplingUtils", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.Transformer._build_graph": [[105, 152], ["tensorflow.compat.v1.variable_scope", "EmbeddingLayer", "transformer.TransformerEncoder", "transformer.TransformerDecoder", "EmbeddingLayer", "EmbeddingLayer"], "methods", ["None"], ["", "", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\" Defines the model graph. \"\"\"", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "'{:s}_model'", ".", "format", "(", "self", ".", "name", ")", ")", ":", "\n", "# Instantiate embedding layer(s)", "\n", "            ", "if", "not", "self", ".", "config", ".", "tie_encoder_decoder_embeddings", ":", "\n", "                ", "enc_vocab_size", "=", "self", ".", "source_vocab_size", "\n", "dec_vocab_size", "=", "self", ".", "target_vocab_size", "\n", "", "else", ":", "\n", "                ", "assert", "self", ".", "source_vocab_size", "==", "self", ".", "target_vocab_size", ",", "'Input and output vocabularies should be identical when tying embedding tables.'", "\n", "enc_vocab_size", "=", "dec_vocab_size", "=", "self", ".", "source_vocab_size", "\n", "\n", "", "encoder_embedding_layer", "=", "EmbeddingLayer", "(", "enc_vocab_size", ",", "\n", "self", ".", "config", ".", "embedding_size", ",", "\n", "self", ".", "config", ".", "state_size", ",", "\n", "FLOAT_DTYPE", ",", "\n", "name", "=", "'encoder_embedding_layer'", ")", "\n", "if", "not", "self", ".", "config", ".", "tie_encoder_decoder_embeddings", ":", "\n", "                ", "decoder_embedding_layer", "=", "EmbeddingLayer", "(", "dec_vocab_size", ",", "\n", "self", ".", "config", ".", "embedding_size", ",", "\n", "self", ".", "config", ".", "state_size", ",", "\n", "FLOAT_DTYPE", ",", "\n", "name", "=", "'decoder_embedding_layer'", ")", "\n", "", "else", ":", "\n", "                ", "decoder_embedding_layer", "=", "encoder_embedding_layer", "\n", "\n", "", "if", "not", "self", ".", "config", ".", "tie_decoder_embeddings", ":", "\n", "                ", "softmax_projection_layer", "=", "EmbeddingLayer", "(", "dec_vocab_size", ",", "\n", "self", ".", "config", ".", "embedding_size", ",", "\n", "self", ".", "config", ".", "state_size", ",", "\n", "FLOAT_DTYPE", ",", "\n", "name", "=", "'softmax_projection_layer'", ")", "\n", "", "else", ":", "\n", "                ", "softmax_projection_layer", "=", "decoder_embedding_layer", "\n", "\n", "# Instantiate the component networks", "\n", "", "self", ".", "enc", "=", "TransformerEncoder", "(", "self", ".", "config", ",", "\n", "encoder_embedding_layer", ",", "\n", "self", ".", "training", ",", "\n", "'encoder'", ")", "\n", "self", ".", "dec", "=", "TransformerDecoder", "(", "self", ".", "config", ",", "\n", "decoder_embedding_layer", ",", "\n", "softmax_projection_layer", ",", "\n", "self", ".", "training", ",", "\n", "'decoder'", ")", "\n", "\n", "", "return", "dec_vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.Transformer.loss_per_sentence": [[153, 156], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss_per_sentence", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_loss_per_sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.Transformer.loss": [[157, 160], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.Transformer.risk": [[161, 164], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "risk", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_risk", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.Transformer.print_pro": [[165, 168], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "print_pro", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_print_pro", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.Transformer._convert_inputs": [[169, 186], ["tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.fill", "tensorflow.concat", "tensorflow.transpose", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "_convert_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "# Convert from time-major to batch-major. Note that we take factor 0", "\n", "# from x and ignore any other factors.", "\n", "        ", "source_ids", "=", "tf", ".", "transpose", "(", "a", "=", "inputs", ".", "x", "[", "0", "]", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "source_mask", "=", "tf", ".", "transpose", "(", "a", "=", "inputs", ".", "x_mask", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "target_ids_out", "=", "tf", ".", "transpose", "(", "a", "=", "inputs", ".", "y", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "target_mask", "=", "tf", ".", "transpose", "(", "a", "=", "inputs", ".", "y_mask", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "\n", "# target_ids_in is a bit more complicated since we need to insert", "\n", "# the special <GO> symbol (with value 1) at the start of each sentence", "\n", "max_len", ",", "batch_size", "=", "tf", ".", "shape", "(", "input", "=", "inputs", ".", "y", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "input", "=", "inputs", ".", "y", ")", "[", "1", "]", "\n", "go_symbols", "=", "tf", ".", "fill", "(", "value", "=", "1", ",", "dims", "=", "[", "1", ",", "batch_size", "]", ")", "\n", "tmp", "=", "tf", ".", "concat", "(", "[", "go_symbols", ",", "inputs", ".", "y", "]", ",", "0", ")", "\n", "tmp", "=", "tmp", "[", ":", "-", "1", ",", ":", "]", "\n", "target_ids_in", "=", "tf", ".", "transpose", "(", "a", "=", "tmp", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "return", "(", "source_ids", ",", "source_mask", ",", "target_ids_in", ",", "target_ids_out", ",", "\n", "target_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder.__init__": [[191, 208], ["dict", "transformer.TransformerEncoder._build_graph"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder._build_graph"], ["def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "embedding_layer", ",", "\n", "training", ",", "\n", "name", ")", ":", "\n", "# Set attributes", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "embedding_layer", "=", "embedding_layer", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# Track layers", "\n", "self", ".", "encoder_stack", "=", "dict", "(", ")", "\n", "self", ".", "is_final_layer", "=", "False", "\n", "\n", "# Create nodes", "\n", "self", ".", "_build_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder._embed": [[209, 213], ["transformer.TransformerEncoder.embedding_layer.embed"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.embed"], ["", "def", "_embed", "(", "self", ",", "index_sequence", ")", ":", "\n", "        ", "\"\"\" Embeds source-side indices to obtain the corresponding dense tensor representations. \"\"\"", "\n", "# Embed input tokens", "\n", "return", "self", ".", "embedding_layer", ".", "embed", "(", "index_sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder._build_graph": [[214, 247], ["tensorflow.compat.v1.variable_scope", "range", "tensorflow.keras.layers.Dropout", "dict", "tensorflow.compat.v1.variable_scope", "AttentionBlock", "FFNBlock"], "methods", ["None"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\" Defines the model graph. \"\"\"", "\n", "# Initialize layers", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "\n", "            ", "if", "self", ".", "config", ".", "transformer_dropout_embeddings", ">", "0", ":", "\n", "                ", "self", ".", "dropout_embedding", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", "=", "self", ".", "config", ".", "transformer_dropout_embeddings", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "dropout_embedding", "=", "None", "\n", "\n", "", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "config", ".", "transformer_enc_depth", "+", "1", ")", ":", "\n", "                ", "layer_name", "=", "'layer_{:d}'", ".", "format", "(", "layer_id", ")", "\n", "# Check if constructed layer is final", "\n", "if", "layer_id", "==", "self", ".", "config", ".", "transformer_enc_depth", ":", "\n", "                    ", "self", ".", "is_final_layer", "=", "True", "\n", "# Specify ffn dimensions sequence", "\n", "", "ffn_dims", "=", "[", "self", ".", "config", ".", "transformer_ffn_hidden_size", ",", "self", ".", "config", ".", "state_size", "]", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "# Build layer blocks (see layers.py)", "\n", "                    ", "self_attn_block", "=", "AttentionBlock", "(", "self", ".", "config", ",", "\n", "FLOAT_DTYPE", ",", "\n", "self_attention", "=", "True", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "ffn_block", "=", "FFNBlock", "(", "self", ".", "config", ",", "\n", "ffn_dims", ",", "\n", "FLOAT_DTYPE", ",", "\n", "is_final", "=", "self", ".", "is_final_layer", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "# Maintain layer-wise dict entries for easier data-passing (may change later)", "\n", "", "self", ".", "encoder_stack", "[", "layer_id", "]", "=", "dict", "(", ")", "\n", "self", ".", "encoder_stack", "[", "layer_id", "]", "[", "'self_attn'", "]", "=", "self_attn_block", "\n", "self", ".", "encoder_stack", "[", "layer_id", "]", "[", "'ffn'", "]", "=", "ffn_block", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerEncoder.encode": [[248, 282], ["transformer.TransformerEncoder._embed", "tf_utils.get_shape_list", "tensorflow.cast", "tensorflow.expand_dims", "get_positional_signal", "tensorflow.compat.v1.variable_scope", "transformer.TransformerEncoder.encode._prepare_source"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder._embed", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.tf_utils.get_shape_list", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.get_positional_signal"], ["", "", "", "def", "encode", "(", "self", ",", "source_ids", ",", "source_mask", ")", ":", "\n", "        ", "\"\"\" Encodes source-side input tokens into meaningful, contextually-enriched representations. \"\"\"", "\n", "\n", "def", "_prepare_source", "(", ")", ":", "\n", "            ", "\"\"\" Pre-processes inputs to the encoder and generates the corresponding attention masks.\"\"\"", "\n", "# Embed", "\n", "source_embeddings", "=", "self", ".", "_embed", "(", "source_ids", ")", "\n", "# Obtain length and depth of the input tensors", "\n", "_", ",", "time_steps", ",", "depth", "=", "tf_utils", ".", "get_shape_list", "(", "source_embeddings", ")", "\n", "# Transform input mask into attention mask", "\n", "inverse_mask", "=", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "source_mask", ",", "0.0", ")", ",", "dtype", "=", "FLOAT_DTYPE", ")", "\n", "attn_mask", "=", "inverse_mask", "*", "-", "1e9", "\n", "# Expansion to shape [batch_size, 1, 1, time_steps] is needed for compatibility with attention logits", "\n", "attn_mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "attn_mask", ",", "1", ")", ",", "1", ")", "\n", "# Differentiate between self-attention and cross-attention masks for further, optional modifications", "\n", "self_attn_mask", "=", "attn_mask", "\n", "cross_attn_mask", "=", "attn_mask", "\n", "# Add positional encodings", "\n", "positional_signal", "=", "get_positional_signal", "(", "time_steps", ",", "depth", ",", "FLOAT_DTYPE", ")", "\n", "source_embeddings", "+=", "positional_signal", "\n", "# Apply dropout", "\n", "if", "self", ".", "dropout_embedding", "is", "not", "None", ":", "\n", "                ", "source_embeddings", "=", "self", ".", "dropout_embedding", "(", "source_embeddings", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "source_embeddings", ",", "self_attn_mask", ",", "cross_attn_mask", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "# Prepare inputs to the encoder, get attention masks", "\n", "            ", "enc_inputs", ",", "self_attn_mask", ",", "cross_attn_mask", "=", "_prepare_source", "(", ")", "\n", "# Propagate inputs through the encoder stack", "\n", "enc_output", "=", "enc_inputs", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "config", ".", "transformer_enc_depth", "+", "1", ")", ":", "\n", "                ", "enc_output", ",", "_", "=", "self", ".", "encoder_stack", "[", "layer_id", "]", "[", "'self_attn'", "]", ".", "forward", "(", "enc_output", ",", "None", ",", "self_attn_mask", ")", "\n", "enc_output", "=", "self", ".", "encoder_stack", "[", "layer_id", "]", "[", "'ffn'", "]", ".", "forward", "(", "enc_output", ")", "\n", "", "", "return", "enc_output", ",", "cross_attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder.__init__": [[287, 312], ["dict", "transformer.TransformerDecoder._build_graph"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder._build_graph"], ["def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "embedding_layer", ",", "\n", "softmax_projection_layer", ",", "\n", "training", ",", "\n", "name", ",", "\n", "from_rnn", "=", "False", ")", ":", "\n", "\n", "# Set attributes", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "embedding_layer", "=", "embedding_layer", "\n", "self", ".", "softmax_projection_layer", "=", "softmax_projection_layer", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "from_rnn", "=", "from_rnn", "\n", "\n", "# If the decoder is used in a hybrid system, adjust parameters accordingly", "\n", "self", ".", "time_dim", "=", "0", "if", "from_rnn", "else", "1", "\n", "\n", "# Track layers", "\n", "self", ".", "decoder_stack", "=", "dict", "(", ")", "\n", "self", ".", "is_final_layer", "=", "False", "\n", "\n", "# Create nodes", "\n", "self", ".", "_build_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder._embed": [[313, 316], ["transformer.TransformerDecoder.embedding_layer.embed"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer_layers.EmbeddingLayer.embed"], ["", "def", "_embed", "(", "self", ",", "index_sequence", ")", ":", "\n", "        ", "\"\"\" Embeds target-side indices to obtain the corresponding dense tensor representations. \"\"\"", "\n", "return", "self", ".", "embedding_layer", ".", "embed", "(", "index_sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder._build_graph": [[317, 356], ["tensorflow.compat.v1.variable_scope", "range", "tensorflow.keras.layers.Dropout", "dict", "tensorflow.compat.v1.variable_scope", "AttentionBlock", "AttentionBlock", "FFNBlock"], "methods", ["None"], ["", "def", "_build_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\" Defines the model graph. \"\"\"", "\n", "# Initialize layers", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "\n", "            ", "if", "self", ".", "config", ".", "transformer_dropout_embeddings", ">", "0", ":", "\n", "                ", "self", ".", "dropout_embedding", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", "=", "self", ".", "config", ".", "transformer_dropout_embeddings", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "dropout_embedding", "=", "None", "\n", "\n", "", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "config", ".", "transformer_dec_depth", "+", "1", ")", ":", "\n", "                ", "layer_name", "=", "'layer_{:d}'", ".", "format", "(", "layer_id", ")", "\n", "# Check if constructed layer is final", "\n", "if", "layer_id", "==", "self", ".", "config", ".", "transformer_dec_depth", ":", "\n", "                    ", "self", ".", "is_final_layer", "=", "True", "\n", "# Specify ffn dimensions sequence", "\n", "", "ffn_dims", "=", "[", "self", ".", "config", ".", "transformer_ffn_hidden_size", ",", "self", ".", "config", ".", "state_size", "]", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "layer_name", ")", ":", "\n", "# Build layer blocks (see layers.py)", "\n", "                    ", "self_attn_block", "=", "AttentionBlock", "(", "self", ".", "config", ",", "\n", "FLOAT_DTYPE", ",", "\n", "self_attention", "=", "True", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "cross_attn_block", "=", "AttentionBlock", "(", "self", ".", "config", ",", "\n", "FLOAT_DTYPE", ",", "\n", "self_attention", "=", "False", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "from_rnn", "=", "self", ".", "from_rnn", ")", "\n", "ffn_block", "=", "FFNBlock", "(", "self", ".", "config", ",", "\n", "ffn_dims", ",", "\n", "FLOAT_DTYPE", ",", "\n", "is_final", "=", "self", ".", "is_final_layer", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "# Maintain layer-wise dict entries for easier data-passing (may change later)", "\n", "", "self", ".", "decoder_stack", "[", "layer_id", "]", "=", "dict", "(", ")", "\n", "self", ".", "decoder_stack", "[", "layer_id", "]", "[", "'self_attn'", "]", "=", "self_attn_block", "\n", "self", ".", "decoder_stack", "[", "layer_id", "]", "[", "'cross_attn'", "]", "=", "cross_attn_block", "\n", "self", ".", "decoder_stack", "[", "layer_id", "]", "[", "'ffn'", "]", "=", "ffn_block", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder.decode_at_train": [[357, 404], ["range", "transformer.TransformerDecoder._embed", "transformer.TransformerDecoder.decode_at_train._prepare_targets"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.transformer.TransformerDecoder._embed"], ["", "", "", "def", "decode_at_train", "(", "self", ",", "target_ids", ",", "enc_output", ",", "cross_attn_mask", ")", ":", "\n", "        ", "\"\"\" Returns the probability distribution over target-side tokens conditioned on the output of the encoder;\n         performs decoding in parallel at training time. \"\"\"", "\n", "\n", "def", "_decode_all", "(", "target_embeddings", ")", ":", "\n", "            ", "\"\"\" Decodes the encoder-generated representations into target-side logits in parallel. \"\"\"", "\n", "# Propagate inputs through the encoder stack", "\n", "dec_output", "=", "target_embeddings", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "config", ".", "transformer_dec_depth", "+", "1", ")", ":", "\n", "                ", "dec_output", ",", "_", "=", "self", ".", "decoder_stack", "[", "layer_id", "]", "[", "'self_attn'", "]", ".", "forward", "(", "dec_output", ",", "None", ",", "self_attn_mask", ")", "\n", "dec_output", ",", "_", "=", "self", ".", "decoder_stack", "[", "layer_id", "]", "[", "'cross_attn'", "]", ".", "forward", "(", "dec_output", ",", "enc_output", ",", "cross_attn_mask", ")", "\n", "dec_output", "=", "self", ".", "decoder_stack", "[", "layer_id", "]", "[", "'ffn'", "]", ".", "forward", "(", "dec_output", ")", "\n", "", "return", "dec_output", "\n", "\n", "", "def", "_prepare_targets", "(", ")", ":", "\n", "            ", "\"\"\" Pre-processes target token ids before they're passed on as input to the decoder\n            for parallel decoding. \"\"\"", "\n", "# Embed target_ids", "\n", "target_embeddings", "=", "self", ".", "_embed", "(", "target_ids", ")", "\n", "target_embeddings", "+=", "positional_signal", "\n", "if", "self", ".", "dropout_embedding", "is", "not", "None", ":", "\n", "                ", "target_embeddings", "=", "self", ".", "dropout_embedding", "(", "target_embeddings", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "target_embeddings", "\n", "\n", "", "def", "_decoding_function", "(", ")", ":", "\n", "            ", "\"\"\" Generates logits for target-side tokens. \"\"\"", "\n", "# Embed the model's predictions up to the current time-step; add positional information, mask", "\n", "target_embeddings", "=", "_prepare_targets", "(", ")", "\n", "# Pass encoder context and decoder embeddings through the decoder", "\n", "dec_output", "=", "_decode_all", "(", "target_embeddings", ")", "\n", "# Project decoder stack outputs and apply the soft-max non-linearity", "\n", "full_logits", "=", "self", ".", "softmax_projection_layer", ".", "project", "(", "dec_output", ")", "\n", "return", "full_logits", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "# Transpose encoder information in hybrid models", "\n", "            ", "if", "self", ".", "from_rnn", ":", "\n", "                ", "enc_output", "=", "tf", ".", "transpose", "(", "a", "=", "enc_output", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "cross_attn_mask", "=", "tf", ".", "transpose", "(", "a", "=", "cross_attn_mask", ",", "perm", "=", "[", "3", ",", "1", ",", "2", ",", "0", "]", ")", "\n", "\n", "", "self_attn_mask", "=", "get_right_context_mask", "(", "tf", ".", "shape", "(", "input", "=", "target_ids", ")", "[", "-", "1", "]", ")", "\n", "positional_signal", "=", "get_positional_signal", "(", "tf", ".", "shape", "(", "input", "=", "target_ids", ")", "[", "-", "1", "]", ",", "\n", "self", ".", "config", ".", "embedding_size", ",", "\n", "FLOAT_DTYPE", ")", "\n", "logits", "=", "_decoding_function", "(", ")", "\n", "", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.mrt_utils.full_sampler": [[25, 167], ["int", "min", "list", "list", "len", "numpy.zeros().astype", "numpy.zeros().astype", "enumerate", "enumerate", "range", "map", "map", "range", "len", "numpy.max", "np.repeat.tolist", "np.repeat.tolist", "np.zeros().astype.tolist", "np.zeros().astype.tolist", "math.ceil", "numpy.array_split", "numpy.array_split", "range", "translate_utils.translate_batch", "samples.append", "len", "index[].append", "range", "range", "range", "range", "range", "range", "zip", "zip", "len", "int", "numpy.zeros", "numpy.zeros", "len", "translate_utils.translate_batch", "samples[].append", "samples.append", "math.ceil", "numpy.array_split", "numpy.array_split", "translate_utils.translate_batch", "range", "translate_utils.translate_batch", "len", "len", "samples[].sort", "len", "index.append", "numpy.repeat", "numpy.repeat", "len", "index[].append", "sum", "samples[].append", "samples[].pop", "sample_seq.tolist", "len", "translate_utils.translate_batch", "numpy.concatenate", "samples[].append", "len", "ss[].tolist", "itertools.groupby", "len"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.translate_utils.translate_batch"], ["", "def", "full_sampler", "(", "replica", ",", "sampler", ",", "sess", ",", "config", ",", "x", ",", "x_mask", ",", "y", ",", "y_mask", ")", ":", "\n", "    ", "\"\"\"generate candidate sentences used for Minimum Risk Training\n\n    Args:\n        replica: inference models to do sampling\n        x: (factor, len, batch_size)\n        x_mask: (len, batch_size)\n        y: (len, batch_size)\n        y_mask: (len, batch_size)\n    Returns:\n        x, x_mask, y, y_mask are four lists containing the corresponding content of\n        source-candidate sentence pairs, with shape:\n        x: (factor, len, batch_size*sampleN)\n        x_mask: (len, batch_size*sampleN)\n        y: (len, batch_size*sampleN)\n        y_mask: (len, batch_size*sampleN)\n\n        y is a list of the corresponding references; index is\n        a list of number indicating the starting point of different source sentences.\n    \"\"\"", "\n", "\n", "sampleN", "=", "config", ".", "samplesN", "\n", "\n", "# set maximum number of tokens of sampled candidates", "\n", "dynamic_max_len", "=", "int", "(", "config", ".", "max_len_a", "*", "x_mask", ".", "shape", "[", "0", "]", "+", "config", ".", "max_len_b", ")", "\n", "max_translation_len", "=", "min", "(", "config", ".", "translation_maxlen", ",", "dynamic_max_len", ")", "\n", "\n", "if", "config", ".", "sample_way", "==", "'beam_search'", ":", "\n", "\n", "# split the minibatch into multiple sub-batches, and execute samplings for each sub-batch separately", "\n", "        ", "if", "config", ".", "max_sentences_of_sampling", ">", "0", ":", "\n", "# number of split equals to batch_size / maximum accepted sentences for sampling (in a device)", "\n", "            ", "num_split", "=", "math", ".", "ceil", "(", "x_mask", ".", "shape", "[", "1", "]", "/", "config", ".", "max_sentences_of_sampling", ")", "\n", "# split the numpy array into a list of numpy array", "\n", "split_x", "=", "np", ".", "array_split", "(", "x", ",", "num_split", ",", "2", ")", "\n", "split_x_mask", "=", "np", ".", "array_split", "(", "x_mask", ",", "num_split", ",", "1", ")", "\n", "sample_and_score", "=", "[", "]", "\n", "# feed sub-batch into model to generate samples", "\n", "for", "i", "in", "range", "(", "len", "(", "split_x", ")", ")", ":", "\n", "                ", "sample_and_score", "+=", "translate_utils", ".", "translate_batch", "(", "sess", ",", "sampler", ",", "split_x", "[", "i", "]", ",", "split_x_mask", "[", "i", "]", ",", "max_translation_len", ",", "config", ".", "normalization_alpha", ")", "\n", "", "", "else", ":", "\n", "            ", "sample_and_score", "=", "translate_utils", ".", "translate_batch", "(", "sess", ",", "sampler", ",", "x", ",", "x_mask", ",", "max_translation_len", ",", "config", ".", "normalization_alpha", ")", "\n", "\n", "# sample_and_score: outer: batch_size, inner: sampleN elements(each represents a sample)", "\n", "\n", "# fetch samplings", "\n", "", "samples", "=", "[", "]", "\n", "for", "i", ",", "ss", "in", "enumerate", "(", "sample_and_score", ")", ":", "\n", "            ", "samples", ".", "append", "(", "[", "]", ")", "\n", "for", "(", "sample_seq", ",", "cost", ")", "in", "ss", ":", "\n", "                ", "samples", "[", "i", "]", ".", "append", "(", "sample_seq", ".", "tolist", "(", ")", ")", "\n", "# samples: list with shape (batch_size, sampleN, len), uneven", "\n", "# beam search sampling, no need to remove duplicate samples.", "\n", "\n", "# samples number of each batch (useless in beam sampling mode)", "\n", "", "", "index", "=", "[", "[", "0", "]", "]", "\n", "for", "i", "in", "range", "(", "(", "len", "(", "samples", ")", ")", ")", ":", "\n", "            ", "index", "[", "0", "]", ".", "append", "(", "index", "[", "0", "]", "[", "i", "]", "+", "sampleN", ")", "\n", "\n", "", "", "elif", "config", ".", "sample_way", "==", "'randomly_sample'", ":", "\n", "\n", "        ", "samples", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "x_mask", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "samples", ".", "append", "(", "[", "]", ")", "\n", "\n", "", "if", "config", ".", "max_sentences_of_sampling", ">", "0", ":", "\n", "            ", "num_split", "=", "math", ".", "ceil", "(", "x_mask", ".", "shape", "[", "1", "]", "/", "config", ".", "max_sentences_of_sampling", ")", "\n", "split_x", "=", "np", ".", "array_split", "(", "x", ",", "num_split", ",", "2", ")", "\n", "split_x_mask", "=", "np", ".", "array_split", "(", "x_mask", ",", "num_split", ",", "1", ")", "\n", "# set normalization_alpha to 0 for randomly sampling (no effect on sampled sentences)", "\n", "sample", "=", "translate_utils", ".", "translate_batch", "(", "\n", "sess", ",", "sampler", ",", "split_x", "[", "0", "]", ",", "split_x_mask", "[", "0", "]", ",", "max_translation_len", ",", "0.0", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "split_x", ")", ")", ":", "\n", "                ", "tmp", "=", "translate_utils", ".", "translate_batch", "(", "sess", ",", "sampler", ",", "split_x", "[", "i", "]", ",", "split_x_mask", "[", "i", "]", ",", "max_translation_len", ",", "0.0", ")", "\n", "sample", "=", "np", ".", "concatenate", "(", "(", "sample", ",", "tmp", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "sample", "=", "translate_utils", ".", "translate_batch", "(", "sess", ",", "sampler", ",", "x", ",", "x_mask", ",", "max_translation_len", ",", "0.0", ")", "\n", "# sample: list: (batch_size, sampleN), each element is a tuple of (numpy array of a sampled sentence, its score)", "\n", "", "for", "i", "in", "range", "(", "len", "(", "samples", ")", ")", ":", "\n", "            ", "for", "ss", "in", "sample", "[", "i", "]", ":", "\n", "                ", "samples", "[", "i", "]", ".", "append", "(", "ss", "[", "0", "]", ".", "tolist", "(", ")", ")", "\n", "# samples: list with shape (batch_size, sampleN, len), uneven", "\n", "\n", "# remove duplicate samples", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "samples", ")", ")", ":", "\n", "            ", "samples", "[", "i", "]", ".", "sort", "(", ")", "\n", "samples", "[", "i", "]", "=", "[", "s", "for", "s", ",", "_", "in", "itertools", ".", "groupby", "(", "samples", "[", "i", "]", ")", "]", "\n", "\n", "# remove the corresponding x and x_mask", "\n", "", "index", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "samples", ")", ")", ":", "\n", "            ", "index", ".", "append", "(", "len", "(", "samples", "[", "i", "]", ")", ")", "\n", "", "for", "i", "in", "range", "(", "x_mask", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "x_new", "=", "np", ".", "repeat", "(", "x", ",", "index", ",", "axis", "=", "2", ")", "\n", "x_mask_new", "=", "np", ".", "repeat", "(", "x_mask", ",", "index", ",", "axis", "=", "1", ")", "\n", "\n", "# calculate the the number of remaining candidate samplings for each source sentence,", "\n", "# store the information in 'index' for the subsequent normalisation of distribution and calculation of", "\n", "# expected risk.", "\n", "", "index", "=", "[", "[", "0", "]", "]", "\n", "for", "i", "in", "range", "(", "(", "len", "(", "samples", ")", ")", ")", ":", "\n", "            ", "index", "[", "0", "]", ".", "append", "(", "index", "[", "0", "]", "[", "i", "]", "+", "len", "(", "samples", "[", "i", "]", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "assert", "False", "\n", "\n", "# add reference in candidate sentences:", "\n", "\n", "# convert from time domain to batch domain", "\n", "", "y", "=", "list", "(", "map", "(", "list", ",", "zip", "(", "*", "y", ")", ")", ")", "\n", "# y: batch_size X len", "\n", "y_mask", "=", "list", "(", "map", "(", "list", ",", "zip", "(", "*", "y_mask", ")", ")", ")", "\n", "if", "config", ".", "mrt_reference", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "samples", ")", ")", ":", "\n", "# delete the pad of reference", "\n", "            ", "lenth", "=", "int", "(", "sum", "(", "y_mask", "[", "i", "]", ")", ")", "\n", "y", "[", "i", "]", "=", "y", "[", "i", "]", "[", ":", "lenth", "]", "\n", "# reference always at the first", "\n", "if", "y", "[", "i", "]", "not", "in", "samples", "[", "i", "]", ":", "\n", "                ", "samples", "[", "i", "]", ".", "append", "(", "y", "[", "i", "]", ")", "\n", "samples", "[", "i", "]", ".", "pop", "(", "-", "2", ")", "\n", "\n", "# add padding: (no specific padding token, just assign 0(<EOS>) and masked to avoid generating loss)", "\n", "\n", "# combine samples from different batches (decrease the outermost dimension)", "\n", "", "", "", "ss", "=", "[", "]", "\n", "for", "i", "in", "samples", ":", "\n", "        ", "ss", "+=", "i", "\n", "", "samples", "=", "ss", "\n", "# samples: list with shape (batch_size*sampleN, len), uneven", "\n", "n_samples", "=", "len", "(", "samples", ")", "\n", "lengths_y", "=", "[", "len", "(", "s", ")", "for", "s", "in", "samples", "]", "\n", "maxlen_y", "=", "np", ".", "max", "(", "lengths_y", ")", "+", "1", "\n", "\n", "y_new", "=", "np", ".", "zeros", "(", "(", "maxlen_y", ",", "n_samples", ")", ")", ".", "astype", "(", "'int64'", ")", "\n", "y_mask_new", "=", "np", ".", "zeros", "(", "(", "maxlen_y", ",", "n_samples", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "for", "idx", ",", "s_y", "in", "enumerate", "(", "samples", ")", ":", "\n", "        ", "y_new", "[", ":", "lengths_y", "[", "idx", "]", ",", "idx", "]", "=", "s_y", "\n", "y_mask_new", "[", ":", "lengths_y", "[", "idx", "]", "+", "1", ",", "idx", "]", "=", "1.", "\n", "\n", "", "return", "x_new", ".", "tolist", "(", ")", ",", "x_mask_new", ".", "tolist", "(", ")", ",", "y_new", ".", "tolist", "(", ")", ",", "y_mask_new", ".", "tolist", "(", ")", ",", "y", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.mrt_utils.cal_metrics_score": [[169, 223], ["len", "list", "len", "map", "numpy.zeros().astype", "range", "numpy.zeros().astype", "range", "zip", "int", "util.seq2words().split", "ScorerProvider().get", "ScorerProvider().get.set_reference", "numpy.array", "int", "util.seq2words().split", "ScorerProvider().get", "ScorerProvider().get.set_reference", "numpy.array", "numpy.zeros", "ss.append", "s.split", "ScorerProvider().get.score_matrix", "numpy.zeros", "ss.append", "s.split", "ScorerProvider().get.score_matrix", "util.seq2words", "util.seq2words", "ScorerProvider", "util.seq2words", "util.seq2words", "ScorerProvider"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer.Scorer.score_matrix", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer.Scorer.score_matrix", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.seq2words"], ["", "def", "cal_metrics_score", "(", "samples", ",", "config", ",", "num_to_target", ",", "refs", ",", "index", ")", ":", "\n", "    ", "\"\"\"evaluate candidate sentences based on reference with evaluation metrics\n    Args:\n        samples: candidate sentences in list (with padding) (maxlen, batch_size*sampleN)\n        num_to_target: dictionary to map number to word\n        refs: ground truth translations in list (batch_size, len), uneven\n        index: starting point of each source sentence\n    Return:\n        numpy array contains scores of candidates\n    \"\"\"", "\n", "\n", "samplesN", "=", "config", ".", "samplesN", "\n", "batch_size", "=", "len", "(", "refs", ")", "\n", "\n", "# convert from time domain to batch domain", "\n", "samples", "=", "list", "(", "map", "(", "list", ",", "zip", "(", "*", "samples", ")", ")", ")", "\n", "samples_totalN", "=", "len", "(", "samples", ")", "\n", "\n", "if", "config", ".", "sample_way", "==", "'beam_search'", ":", "\n", "        ", "scores", "=", "np", ".", "zeros", "(", "(", "batch_size", "*", "samplesN", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "for", "i", "in", "range", "(", "int", "(", "batch_size", ")", ")", ":", "\n", "            ", "ref", "=", "util", ".", "seq2words", "(", "refs", "[", "i", "]", ",", "num_to_target", ")", ".", "split", "(", "\" \"", ")", "\n", "\n", "ss", "=", "[", "]", "\n", "for", "j", "in", "samples", "[", "i", "*", "samplesN", ":", "(", "i", "+", "1", ")", "*", "samplesN", "]", ":", "\n", "                ", "ss", ".", "append", "(", "util", ".", "seq2words", "(", "j", ",", "num_to_target", ")", ")", "\n", "", "ss", "=", "[", "s", ".", "split", "(", "\" \"", ")", "for", "s", "in", "ss", "]", "\n", "# ss: list with (samplesN, len), uneven(seq2word could get rid of padding)", "\n", "\n", "# get evaluation metrics (negative smoothed BLEU) for samplings", "\n", "scorer", "=", "ScorerProvider", "(", ")", ".", "get", "(", "config", ".", "mrt_loss", ")", "\n", "scorer", ".", "set_reference", "(", "ref", ")", "\n", "score", "=", "np", ".", "array", "(", "scorer", ".", "score_matrix", "(", "ss", ")", ")", "\n", "# compute the negative BLEU score (use 1-BLEU (BLEU: 0~1))", "\n", "scores", "[", "i", "*", "samplesN", ":", "(", "i", "+", "1", ")", "*", "samplesN", "]", "=", "1", "-", "1", "*", "score", "\n", "", "", "else", ":", "\n", "# for randomly sampling strategy, starting point information needed", "\n", "        ", "scores", "=", "np", ".", "zeros", "(", "(", "samples_totalN", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "for", "i", "in", "range", "(", "int", "(", "batch_size", ")", ")", ":", "\n", "            ", "ref", "=", "util", ".", "seq2words", "(", "refs", "[", "i", "]", ",", "num_to_target", ")", ".", "split", "(", "\" \"", ")", "\n", "\n", "ss", "=", "[", "]", "\n", "for", "j", "in", "samples", "[", "index", "[", "0", "]", "[", "i", "]", ":", "index", "[", "0", "]", "[", "i", "+", "1", "]", "]", ":", "\n", "                ", "ss", ".", "append", "(", "util", ".", "seq2words", "(", "j", ",", "num_to_target", ")", ")", "\n", "", "ss", "=", "[", "s", ".", "split", "(", "\" \"", ")", "for", "s", "in", "ss", "]", "\n", "\n", "# get negative smoothed BLEU for samples", "\n", "scorer", "=", "ScorerProvider", "(", ")", ".", "get", "(", "config", ".", "mrt_loss", ")", "\n", "scorer", ".", "set_reference", "(", "ref", ")", "\n", "score", "=", "np", ".", "array", "(", "scorer", ".", "score_matrix", "(", "ss", ")", ")", "\n", "# compute the negative BLEU score (use 1-BLEU (BLEU: 0~1))", "\n", "scores", "[", "index", "[", "0", "]", "[", "i", "]", ":", "index", "[", "0", "]", "[", "i", "+", "1", "]", "]", "=", "1", "-", "1", "*", "score", "\n", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.mrt_utils.mrt_cost": [[225, 272], ["tensorflow.constant", "tensorflow.multiply", "tensorflow.constant", "tensorflow.while_loop", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.divide", "tensorflow.shape", "tensorflow.constant", "tensorflow.less", "tensorflow.nn.softmax", "tensorflow.cast", "tensorflow.shape", "tensorflow.concat", "tensorflow.concat", "tensorflow.add", "tensorflow.matmul"], "function", ["None"], ["", "def", "mrt_cost", "(", "cost", ",", "score", ",", "index", ",", "config", ")", ":", "\n", "    ", "\"\"\"Calculate expected risk according to evaluation scores and model's translation probability over\n    a subset of candidate sentences\n    Args:\n        cost: translation probabilities, 1D tensor with size: (sub-batch_size, sampleN)\n        score: evaluation score, 1D tensor with size: (sub-batch_size, sampleN)\n    Return:\n        expected risk per real sentence over a sub-batch, a scalar tensor\n    \"\"\"", "\n", "\n", "samplesN", "=", "config", ".", "samplesN", "\n", "total_sample", "=", "tf", ".", "shape", "(", "input", "=", "cost", ")", "[", "0", "]", "\n", "batch_size", "=", "tf", ".", "shape", "(", "input", "=", "index", ")", "[", "0", "]", "-", "tf", ".", "constant", "(", "1", ")", "\n", "\n", "# cancelling the negative of the cost (P**alpha = e**(-alpha*(-logP))", "\n", "alpha", "=", "tf", ".", "constant", "(", "[", "-", "config", ".", "mrt_alpha", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "cost", "=", "tf", ".", "multiply", "(", "cost", ",", "alpha", ")", "\n", "\n", "# normalise costs", "\n", "i", "=", "tf", ".", "constant", "(", "0", ")", "\n", "\n", "def", "while_condition", "(", "i", ",", "_", ")", ":", "\n", "        ", "return", "tf", ".", "less", "(", "i", ",", "batch_size", ")", "\n", "", "def", "body", "(", "i", ",", "cost", ")", ":", "\n", "        ", "normalised_cost", "=", "tf", ".", "nn", ".", "softmax", "(", "cost", "[", "index", "[", "i", "]", ":", "index", "[", "i", "+", "1", "]", "]", ")", "\n", "# assign value of sub-tensor to a tensor iteratively", "\n", "if", "i", "==", "0", ":", "\n", "            ", "val", "=", "normalised_cost", "\n", "part2", "=", "cost", "[", "index", "[", "i", "+", "1", "]", ":", "]", "\n", "cost", "=", "tf", ".", "concat", "(", "[", "val", ",", "part2", "]", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "part1", "=", "cost", "[", ":", "index", "[", "i", "]", "]", "\n", "val", "=", "normalised_cost", "\n", "part2", "=", "cost", "[", "index", "[", "i", "+", "1", "]", ":", "]", "\n", "cost", "=", "tf", ".", "concat", "(", "[", "part1", ",", "val", ",", "part2", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "tf", ".", "add", "(", "i", ",", "1", ")", ",", "cost", "\n", "# do the loop:", "\n", "", "i", ",", "cost", "=", "tf", ".", "while_loop", "(", "cond", "=", "while_condition", ",", "body", "=", "body", ",", "loop_vars", "=", "[", "i", ",", "cost", "]", ")", "\n", "\n", "# compute risk by dot product normalised cost and score", "\n", "cost", "=", "tf", ".", "reshape", "(", "cost", ",", "[", "1", ",", "total_sample", "]", ")", "\n", "score", "=", "tf", ".", "reshape", "(", "score", ",", "[", "total_sample", ",", "1", "]", ")", "\n", "# calculate the risk per real sentence (before sampling)", "\n", "MRTloss", "=", "tf", ".", "divide", "(", "tf", ".", "matmul", "(", "cost", ",", "score", ")", "[", "0", "]", "[", "0", "]", ",", "tf", ".", "cast", "(", "batch_size", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "return", "MRTloss", "\n", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.theano_tf_convert.construct_parameter_map": [[21, 140], ["range", "range", "theano_tf_convert.construct_parameter_map.add_gru_variables"], "function", ["None"], ["def", "construct_parameter_map", "(", "config", ")", ":", "\n", "    ", "def", "drt_tag", "(", "i", ")", ":", "\n", "        ", "return", "\"\"", "if", "i", "==", "0", "else", "\"_drt_{0}\"", ".", "format", "(", "i", ")", "\n", "\n", "", "def", "add_gru_variables", "(", "param_map", ",", "th_prefix", ",", "tf_prefix", ",", "drt_tag", ",", "\n", "alt_names", "=", "False", ")", ":", "\n", "        ", "for", "th_roots", ",", "tf_root", "in", "[", "[", "[", "\"U\"", ",", "\"U_nl\"", "]", ",", "\"state_to_gates\"", "]", ",", "\n", "[", "[", "\"Ux\"", ",", "\"Ux_nl\"", "]", ",", "\"state_to_proposal\"", "]", ",", "\n", "[", "[", "\"W\"", ",", "\"Wc\"", "]", ",", "\"input_to_gates\"", "]", ",", "\n", "[", "[", "\"Wx\"", ",", "\"Wcx\"", "]", ",", "\"input_to_proposal\"", "]", ",", "\n", "[", "[", "\"b\"", ",", "\"b_nl\"", "]", ",", "\"gates_bias\"", "]", ",", "\n", "[", "[", "\"bx\"", ",", "\"bx_nl\"", "]", ",", "\"proposal_bias\"", "]", "]", ":", "\n", "            ", "th_root", "=", "th_roots", "[", "1", "]", "if", "alt_names", "else", "th_roots", "[", "0", "]", "\n", "if", "drt_tag", "!=", "\"\"", "and", "th_root", ".", "startswith", "(", "\"W\"", ")", ":", "\n", "# For deep transition, only the bottom GRU has external inputs.", "\n", "                ", "continue", "\n", "", "key", "=", "\"{0}{1}{2}\"", ".", "format", "(", "th_prefix", ",", "th_root", ",", "drt_tag", ")", "\n", "val", "=", "\"{0}{1}:0\"", ".", "format", "(", "tf_prefix", ",", "tf_root", ")", "\n", "param_map", "[", "key", "]", "=", "val", "\n", "\n", "", "for", "th_roots", ",", "tf_root", "in", "[", "[", "[", "\"U\"", ",", "\"U_nl\"", "]", ",", "\"gates_state_norm\"", "]", ",", "\n", "[", "[", "\"Ux\"", ",", "\"Ux_nl\"", "]", ",", "\"proposal_state_norm\"", "]", ",", "\n", "[", "[", "\"W\"", ",", "\"Wc\"", "]", ",", "\"gates_x_norm\"", "]", ",", "\n", "[", "[", "\"Wx\"", ",", "\"Wcx\"", "]", ",", "\"proposal_x_norm\"", "]", "]", ":", "\n", "            ", "th_root", "=", "th_roots", "[", "1", "]", "if", "alt_names", "else", "th_roots", "[", "0", "]", "\n", "if", "drt_tag", "!=", "\"\"", "and", "th_root", ".", "startswith", "(", "\"W\"", ")", ":", "\n", "# For deep transition, only the bottom GRU has external inputs.", "\n", "                ", "continue", "\n", "", "key", "=", "\"{0}{1}{2}_lnb\"", ".", "format", "(", "th_prefix", ",", "th_root", ",", "drt_tag", ")", "\n", "val", "=", "\"{0}{1}/new_mean:0\"", ".", "format", "(", "tf_prefix", ",", "tf_root", ")", "\n", "param_map", "[", "key", "]", "=", "val", "\n", "key", "=", "\"{0}{1}{2}_lns\"", ".", "format", "(", "th_prefix", ",", "th_root", ",", "drt_tag", ")", "\n", "val", "=", "\"{0}{1}/new_std:0\"", ".", "format", "(", "tf_prefix", ",", "tf_root", ")", "\n", "param_map", "[", "key", "]", "=", "val", "\n", "\n", "", "", "th2tf", "=", "{", "\n", "# encoder/embedding", "\n", "'Wemb'", ":", "'encoder/embedding/embeddings:0'", ",", "\n", "\n", "# decoder/initial_state_constructor", "\n", "'ff_state_W'", ":", "'decoder/initial_state_constructor/W:0'", ",", "\n", "'ff_state_b'", ":", "'decoder/initial_state_constructor/b:0'", ",", "\n", "'ff_state_ln_b'", ":", "'decoder/initial_state_constructor/new_mean:0'", ",", "\n", "'ff_state_ln_s'", ":", "'decoder/initial_state_constructor/new_std:0'", ",", "\n", "\n", "# decoder/embedding", "\n", "'Wemb_dec'", ":", "'decoder/embedding/embeddings:0'", ",", "\n", "\n", "# decoder/base/attention", "\n", "'decoder_U_att'", ":", "'decoder/base/attention/hidden_to_score:0'", ",", "\n", "'decoder_W_comb_att'", ":", "'decoder/base/attention/state_to_hidden:0'", ",", "\n", "'decoder_W_comb_att_lnb'", ":", "'decoder/base/attention/hidden_state_norm/new_mean:0'", ",", "\n", "'decoder_W_comb_att_lns'", ":", "'decoder/base/attention/hidden_state_norm/new_std:0'", ",", "\n", "'decoder_Wc_att'", ":", "'decoder/base/attention/context_to_hidden:0'", ",", "\n", "'decoder_Wc_att_lnb'", ":", "'decoder/base/attention/hidden_context_norm/new_mean:0'", ",", "\n", "'decoder_Wc_att_lns'", ":", "'decoder/base/attention/hidden_context_norm/new_std:0'", ",", "\n", "'decoder_b_att'", ":", "'decoder/base/attention/hidden_bias:0'", ",", "\n", "\n", "# decoder/next_word_predictor", "\n", "'ff_logit_W'", ":", "'decoder/next_word_predictor/hidden_to_logits/W:0'", ",", "\n", "'ff_logit_b'", ":", "'decoder/next_word_predictor/hidden_to_logits/b:0'", ",", "\n", "'ff_logit_ctx_W'", ":", "'decoder/next_word_predictor/attended_context_to_hidden/W:0'", ",", "\n", "'ff_logit_ctx_b'", ":", "'decoder/next_word_predictor/attended_context_to_hidden/b:0'", ",", "\n", "'ff_logit_ctx_ln_b'", ":", "'decoder/next_word_predictor/attended_context_to_hidden/new_mean:0'", ",", "\n", "'ff_logit_ctx_ln_s'", ":", "'decoder/next_word_predictor/attended_context_to_hidden/new_std:0'", ",", "\n", "'ff_logit_lstm_W'", ":", "'decoder/next_word_predictor/state_to_hidden/W:0'", ",", "\n", "'ff_logit_lstm_b'", ":", "'decoder/next_word_predictor/state_to_hidden/b:0'", ",", "\n", "'ff_logit_lstm_ln_b'", ":", "'decoder/next_word_predictor/state_to_hidden/new_mean:0'", ",", "\n", "'ff_logit_lstm_ln_s'", ":", "'decoder/next_word_predictor/state_to_hidden/new_std:0'", ",", "\n", "'ff_logit_prev_W'", ":", "'decoder/next_word_predictor/prev_emb_to_hidden/W:0'", ",", "\n", "'ff_logit_prev_b'", ":", "'decoder/next_word_predictor/prev_emb_to_hidden/b:0'", ",", "\n", "'ff_logit_prev_ln_b'", ":", "'decoder/next_word_predictor/prev_emb_to_hidden/new_mean:0'", ",", "\n", "'ff_logit_prev_ln_s'", ":", "'decoder/next_word_predictor/prev_emb_to_hidden/new_std:0'", ",", "\n", "\n", "# other", "\n", "'decoder_c_tt'", ":", "None", ",", "\n", "'history_errs'", ":", "None", ",", "\n", "'uidx'", ":", "'time:0'", "}", "\n", "\n", "# Add embedding variables for any additional factors.", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "config", ".", "dim_per_factor", ")", ")", ":", "\n", "        ", "th_name", "=", "'Wemb{0}'", ".", "format", "(", "i", ")", "\n", "th2tf", "[", "th_name", "]", "=", "'encoder/embedding/embeddings_{0}:0'", ".", "format", "(", "i", ")", "\n", "\n", "# Add GRU variables for the encoder.", "\n", "", "for", "i", "in", "range", "(", "config", ".", "rnn_enc_depth", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "config", ".", "rnn_enc_transition_depth", ")", ":", "\n", "            ", "th_prefix_f", "=", "\"encoder_\"", "+", "(", "\"\"", "if", "i", "==", "0", "else", "\"{0}_\"", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "tf_prefix_f", "=", "\"encoder/forward-stack/level{0}/gru{1}/\"", ".", "format", "(", "i", ",", "j", ")", "\n", "th_prefix_b", "=", "\"encoder_r_\"", "+", "(", "\"\"", "if", "i", "==", "0", "else", "\"{0}_\"", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "tf_prefix_b", "=", "\"encoder/backward-stack/level{0}/gru{1}/\"", ".", "format", "(", "i", ",", "j", ")", "\n", "if", "i", "%", "2", ":", "\n", "# The variable naming convention differs between the Theano and", "\n", "# Tensorflow versions: in the Theano version, encoder_<i> is", "\n", "# used for the i-th left-to-right encoder GRU, and encoder_r_<i>", "\n", "# is used for the i-th right-to-left one. In the Tensorflow", "\n", "# version, forward-stack/level0 is left-to-right and", "\n", "# backward-stack/level0 is right-to-left, but then the", "\n", "# directions alternate up the stack.  Flipping the th_prefixes", "\n", "# will map the GRU variables accordingly.", "\n", "                ", "th_prefix_f", ",", "th_prefix_b", "=", "th_prefix_b", ",", "th_prefix_f", "\n", "", "add_gru_variables", "(", "th2tf", ",", "th_prefix_f", ",", "tf_prefix_f", ",", "drt_tag", "(", "j", ")", ")", "\n", "add_gru_variables", "(", "th2tf", ",", "th_prefix_b", ",", "tf_prefix_b", ",", "drt_tag", "(", "j", ")", ")", "\n", "\n", "# Add GRU variables for the base level of the decoder.", "\n", "", "", "add_gru_variables", "(", "th2tf", ",", "\"decoder_\"", ",", "\"decoder/base/gru0/\"", ",", "\"\"", ")", "\n", "for", "j", "in", "range", "(", "1", ",", "config", ".", "rnn_dec_base_transition_depth", ")", ":", "\n", "        ", "tf_prefix", "=", "\"decoder/base/gru{0}/\"", ".", "format", "(", "j", ")", "\n", "add_gru_variables", "(", "th2tf", ",", "\"decoder_\"", ",", "tf_prefix", ",", "drt_tag", "(", "j", "-", "1", ")", ",", "\n", "alt_names", "=", "True", ")", "\n", "\n", "# Add GRU variables for the high levels of the decoder.", "\n", "", "for", "i", "in", "range", "(", "config", ".", "rnn_dec_depth", "-", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "config", ".", "rnn_dec_high_transition_depth", ")", ":", "\n", "            ", "th_prefix", "=", "\"decoder_{0}_\"", ".", "format", "(", "i", "+", "2", ")", "\n", "tf_prefix", "=", "\"decoder/high/level{0}/gru{1}/\"", ".", "format", "(", "i", ",", "j", ")", "\n", "add_gru_variables", "(", "th2tf", ",", "th_prefix", ",", "tf_prefix", ",", "drt_tag", "(", "j", ")", ")", "\n", "\n", "", "", "return", "th2tf", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.theano_tf_convert.theano_to_tensorflow_config": [[142, 147], ["config.load_config_from_json_file", "setattr", "setattr"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.load_config_from_json_file"], ["", "def", "theano_to_tensorflow_config", "(", "model_path", ")", ":", "\n", "    ", "config", "=", "load_config_from_json_file", "(", "model_path", ")", "\n", "setattr", "(", "config", ",", "'reload'", ",", "None", ")", "\n", "setattr", "(", "config", ",", "'prior_model'", ",", "None", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.theano_tf_convert.theano_to_tensorflow_model": [[149, 194], ["numpy.load", "theano_tf_convert.theano_to_tensorflow_config", "theano_tf_convert.construct_parameter_map", "tensorflow.compat.v1.Session", "logging.info", "rnn_model.RNNModel", "tensorflow.zeros_initializer", "tensorflow.compat.v1.get_variable", "model_loader.init_or_restore_variables", "set", "list", "sess.run", "model_loader.init_or_restore_variables.save", "tensorflow.compat.v1.get_collection", "logging.info", "logging.info", "np.load.keys", "th_name.startswith", "set.add", "tensorflow.compat.v1.get_default_graph().get_tensor_by_name", "sess.run", "assign_ops.append", "logging.info", "tensorflow.shape", "list", "list", "logging.error", "logging.error", "logging.error", "sys.exit", "tensorflow.compat.v1.assign", "unassigned.append", "tensorflow.compat.v1.get_default_graph"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.theano_tf_convert.theano_to_tensorflow_config", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.theano_tf_convert.construct_parameter_map", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.model_loader.init_or_restore_variables"], ["", "def", "theano_to_tensorflow_model", "(", "in_path", ",", "out_path", ")", ":", "\n", "    ", "saved_model", "=", "np", ".", "load", "(", "in_path", ")", "\n", "config", "=", "theano_to_tensorflow_config", "(", "in_path", ")", "\n", "th2tf", "=", "construct_parameter_map", "(", "config", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "logging", ".", "info", "(", "'Building model...'", ")", "\n", "model", "=", "rnn_model", ".", "RNNModel", "(", "config", ")", "\n", "init", "=", "tf", ".", "zeros_initializer", "(", "dtype", "=", "tf", ".", "int32", ")", "\n", "global_step", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'time'", ",", "[", "]", ",", "initializer", "=", "init", ",", "trainable", "=", "False", ")", "\n", "saver", "=", "model_loader", ".", "init_or_restore_variables", "(", "config", ",", "sess", ")", "\n", "seen", "=", "set", "(", ")", "\n", "assign_ops", "=", "[", "]", "\n", "for", "th_name", "in", "list", "(", "saved_model", ".", "keys", "(", ")", ")", ":", "\n", "# ignore adam parameters", "\n", "            ", "if", "th_name", ".", "startswith", "(", "'adam'", ")", ":", "\n", "                ", "continue", "\n", "", "tf_name", "=", "th2tf", "[", "th_name", "]", "\n", "if", "tf_name", "is", "None", ":", "\n", "                ", "logging", ".", "info", "(", "\"Not saving {} because no TF \"", "\"equivalent\"", ".", "format", "(", "th_name", ")", ")", "\n", "continue", "\n", "", "assert", "tf_name", "not", "in", "seen", "\n", "seen", ".", "add", "(", "tf_name", ")", "\n", "tf_var", "=", "tf", ".", "compat", ".", "v1", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "tf_name", ")", "\n", "tf_shape", "=", "sess", ".", "run", "(", "tf", ".", "shape", "(", "input", "=", "tf_var", ")", ")", "\n", "th_var", "=", "saved_model", "[", "th_name", "]", "\n", "th_shape", "=", "th_var", ".", "shape", "\n", "if", "list", "(", "tf_shape", ")", "!=", "list", "(", "th_shape", ")", ":", "\n", "                ", "logging", ".", "error", "(", "\"Shapes do not match for {} and \"", "\"{}.\"", ".", "format", "(", "tf_name", ",", "th_name", ")", ")", "\n", "logging", ".", "error", "(", "\"Shape of {} is {}\"", ".", "format", "(", "tf_name", ",", "tf_shape", ")", ")", "\n", "logging", ".", "error", "(", "\"Shape of {} is {}\"", ".", "format", "(", "th_name", ",", "th_shape", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "assign_ops", ".", "append", "(", "tf", ".", "compat", ".", "v1", ".", "assign", "(", "tf_var", ",", "th_var", ")", ")", "\n", "", "sess", ".", "run", "(", "assign_ops", ")", "\n", "saver", ".", "save", "(", "sess", ",", "save_path", "=", "out_path", ")", "\n", "\n", "unassigned", "=", "[", "]", "\n", "for", "tf_var", "in", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", ":", "\n", "            ", "if", "tf_var", ".", "name", "not", "in", "seen", ":", "\n", "                ", "unassigned", ".", "append", "(", "tf_var", ".", "name", ")", "\n", "", "", "logging", ".", "info", "(", "\"The following TF variables were not \"", "\"assigned: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "unassigned", ")", ")", ")", "\n", "logging", ".", "info", "(", "\"You should see only the 'time' variable listed\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.theano_tf_convert.tensorflow_to_theano_model": [[196, 223], ["config.load_config_from_json_file", "theano_tf_convert.construct_parameter_map", "list", "numpy.savez", "logging.info", "zip", "tensorflow.compat.v1.Session", "tensorflow.compat.v1.train.import_meta_graph", "tf.compat.v1.train.import_meta_graph.restore", "list", "construct_parameter_map.items", "len", "list", "construct_parameter_map.items", "sess.run", "tensorflow.compat.v1.get_default_graph().get_tensor_by_name", "logging.info", "numpy.zeros", "tensorflow.compat.v1.get_default_graph"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.config.load_config_from_json_file", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.theano_tf_convert.construct_parameter_map"], ["", "", "def", "tensorflow_to_theano_model", "(", "in_path", ",", "out_path", ")", ":", "\n", "    ", "config", "=", "load_config_from_json_file", "(", "in_path", ")", "\n", "th2tf", "=", "construct_parameter_map", "(", "config", ")", "\n", "keys", ",", "values", "=", "list", "(", "zip", "(", "*", "list", "(", "th2tf", ".", "items", "(", ")", ")", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "new_saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "import_meta_graph", "(", "in_path", "+", "'.meta'", ")", "\n", "new_saver", ".", "restore", "(", "sess", ",", "in_path", ")", "\n", "params", "=", "{", "}", "\n", "for", "th_name", ",", "tf_name", "in", "list", "(", "th2tf", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "tf_name", "is", "not", "None", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "tf_name", ")", ")", "\n", "", "except", ":", "\n", "                    ", "logging", ".", "info", "(", "\"Skipping {} because it was not \"", "\"found\"", ".", "format", "(", "tf_name", ")", ")", "\n", "continue", "\n", "", "", "else", ":", "\n", "                ", "if", "th_name", "==", "'history_errs'", ":", "\n", "                    ", "v", "=", "[", "]", "\n", "", "elif", "th_name", "==", "'decoder_c_tt'", ":", "\n", "                    ", "v", "=", "np", ".", "zeros", "(", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "False", ",", "'Need to handle {}'", ".", "format", "(", "th_name", ")", "\n", "", "", "assert", "th_name", "not", "in", "params", ",", "'{} is repeated!'", ".", "format", "(", "th_name", ")", "\n", "params", "[", "th_name", "]", "=", "v", "\n", "", "", "np", ".", "savez", "(", "out_path", ",", "**", "params", ")", "\n", "logging", ".", "info", "(", "'Saved {} params to {}'", ".", "format", "(", "len", "(", "params", ")", ",", "out_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.__init__": [[18, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "host", ",", "port", ")", ":", "\n", "        ", "self", ".", "host", "=", "host", "\n", "self", ".", "port", "=", "port", "\n", "self", ".", "headers", "=", "{", "\n", "'content-type'", ":", "'application/json'", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client._get_url": [[25, 27], ["None"], "methods", ["None"], ["", "def", "_get_url", "(", "self", ",", "path", "=", "'/'", ")", ":", "\n", "        ", "return", "\"http://{0}:{1}{2}\"", ".", "format", "(", "self", ".", "host", ",", "self", ".", "port", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.translate": [[28, 33], ["sample_client.Client.translate_segments"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.translate_segments"], ["", "def", "translate", "(", "self", ",", "segment", ")", ":", "\n", "        ", "\"\"\"\n        Returns the translation of a list of segments.\n        \"\"\"", "\n", "return", "self", ".", "translate_segments", "(", "[", "segment", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.translate_segments": [[34, 42], ["json.dumps", "sample_client.Client._get_url", "requests.post", "requests.post.json"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client._get_url"], ["", "def", "translate_segments", "(", "self", ",", "segments", ")", ":", "\n", "        ", "\"\"\"\n        Returns the translation of a single segment.\n        \"\"\"", "\n", "payload", "=", "json", ".", "dumps", "(", "{", "'segments'", ":", "segments", "}", ")", "\n", "url", "=", "self", ".", "_get_url", "(", "'/translate'", ")", "\n", "response", "=", "requests", ".", "post", "(", "url", ",", "headers", "=", "self", ".", "headers", ",", "data", "=", "payload", ")", "\n", "return", "[", "segment", "[", "'translation'", "]", "for", "segment", "in", "response", ".", "json", "(", ")", "[", "'data'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client.print_server_status": [[43, 50], ["sample_client.Client._get_url", "requests.get", "print", "json.dumps", "requests.get.json"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.sample_client.Client._get_url", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get"], ["", "def", "print_server_status", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Prints the server's status report.\n        \"\"\"", "\n", "url", "=", "self", ".", "_get_url", "(", "'/status'", ")", "\n", "response", "=", "requests", ".", "get", "(", "url", ",", "headers", "=", "self", ".", "headers", ")", "\n", "print", "(", "(", "json", ".", "dumps", "(", "response", ".", "json", "(", ")", ",", "indent", "=", "4", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.RNNModel.__init__": [[30, 102], ["model_inputs.ModelInputs", "SamplingUtils", "tensorflow.shape", "tensorflow.compat.v1.variable_scope", "rnn_model.Encoder", "rnn_model.RNNModel.encoder.get_context", "tensorflow.compat.v1.variable_scope", "rnn_model.Decoder", "rnn_model.RNNModel.decoder.score", "tensorflow.compat.v1.variable_scope", "layers.Masked_cross_entropy_loss", "rnn_model.RNNModel.loss_layer.forward", "tensorflow.reduce_mean", "tensorflow.compat.v1.layers.dropout", "tensorflow.compat.v1.layers.dropout", "tensorflow.compat.v1.layers.dropout", "tensorflow.compat.v1.layers.dropout", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Encoder.get_context", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "inputs", "=", "model_inputs", ".", "ModelInputs", "(", "config", ")", "\n", "\n", "# Dropout functions for words.", "\n", "# These probabilistically zero-out all embedding values for individual", "\n", "# words.", "\n", "dropout_source", ",", "dropout_target", "=", "None", ",", "None", "\n", "if", "config", ".", "rnn_use_dropout", "and", "config", ".", "rnn_dropout_source", ">", "0.0", ":", "\n", "            ", "def", "dropout_source", "(", "x", ")", ":", "\n", "                ", "return", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dropout", "(", "\n", "x", ",", "noise_shape", "=", "(", "tf", ".", "shape", "(", "input", "=", "x", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "input", "=", "x", ")", "[", "1", "]", ",", "1", ")", ",", "\n", "rate", "=", "config", ".", "rnn_dropout_source", ",", "\n", "training", "=", "self", ".", "inputs", ".", "training", ")", "\n", "", "", "if", "config", ".", "rnn_use_dropout", "and", "config", ".", "rnn_dropout_target", ">", "0.0", ":", "\n", "            ", "def", "dropout_target", "(", "y", ")", ":", "\n", "                ", "return", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dropout", "(", "\n", "y", ",", "noise_shape", "=", "(", "tf", ".", "shape", "(", "input", "=", "y", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "input", "=", "y", ")", "[", "1", "]", ",", "1", ")", ",", "\n", "rate", "=", "config", ".", "rnn_dropout_target", ",", "\n", "training", "=", "self", ".", "inputs", ".", "training", ")", "\n", "\n", "# Dropout functions for use within FF, GRU, and attention layers.", "\n", "# We use Gal and Ghahramani (2016)-style dropout, so these functions", "\n", "# will be used to create 2D dropout masks that are reused at every", "\n", "# timestep.", "\n", "", "", "dropout_embedding", ",", "dropout_hidden", "=", "None", ",", "None", "\n", "if", "config", ".", "rnn_use_dropout", "and", "config", ".", "rnn_dropout_embedding", ">", "0.0", ":", "\n", "            ", "def", "dropout_embedding", "(", "e", ")", ":", "\n", "                ", "return", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dropout", "(", "e", ",", "noise_shape", "=", "(", "tf", ".", "shape", "(", "input", "=", "e", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "input", "=", "e", ")", "[", "1", "]", ")", ",", "\n", "rate", "=", "config", ".", "rnn_dropout_embedding", ",", "\n", "training", "=", "self", ".", "inputs", ".", "training", ")", "\n", "", "", "if", "config", ".", "rnn_use_dropout", "and", "config", ".", "rnn_dropout_hidden", ">", "0.0", ":", "\n", "            ", "def", "dropout_hidden", "(", "h", ")", ":", "\n", "                ", "return", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dropout", "(", "h", ",", "noise_shape", "=", "(", "tf", ".", "shape", "(", "input", "=", "h", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "input", "=", "h", ")", "[", "1", "]", ")", ",", "\n", "rate", "=", "config", ".", "rnn_dropout_hidden", ",", "\n", "training", "=", "self", ".", "inputs", ".", "training", ")", "\n", "\n", "# layer normalization can be off, or if it is on,", "\n", "# one of two types: standard layer normalization or RMS layer normalization", "\n", "", "", "if", "config", ".", "rnn_layer_normalization", ":", "\n", "            ", "if", "config", ".", "layer_normalization_type", "==", "'layernorm'", ":", "\n", "                ", "layernorm", "=", "layers", ".", "LayerNormLayer", "\n", "", "elif", "config", ".", "layer_normalization_type", "==", "'rmsnorm'", ":", "\n", "                ", "layernorm", "=", "layers", ".", "RMSNormLayer", "\n", "", "", "else", ":", "\n", "            ", "layernorm", "=", "False", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "input", "=", "self", ".", "inputs", ".", "x", ")", "[", "-", "1", "]", "# dynamic value", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"encoder\"", ")", ":", "\n", "            ", "self", ".", "encoder", "=", "Encoder", "(", "config", ",", "batch_size", ",", "layernorm", ",", "dropout_source", ",", "\n", "dropout_embedding", ",", "dropout_hidden", ")", "\n", "ctx", ",", "embs", "=", "self", ".", "encoder", ".", "get_context", "(", "self", ".", "inputs", ".", "x", ",", "self", ".", "inputs", ".", "x_mask", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"decoder\"", ")", ":", "\n", "            ", "if", "config", ".", "tie_encoder_decoder_embeddings", ":", "\n", "                ", "tied_embeddings", "=", "self", ".", "encoder", ".", "emb_layer", "\n", "", "else", ":", "\n", "                ", "tied_embeddings", "=", "None", "\n", "", "self", ".", "decoder", "=", "Decoder", "(", "config", ",", "ctx", ",", "embs", ",", "self", ".", "inputs", ".", "x_mask", ",", "\n", "layernorm", ",", "\n", "dropout_target", ",", "dropout_embedding", ",", "\n", "dropout_hidden", ",", "tied_embeddings", ")", "\n", "self", ".", "logits", "=", "self", ".", "decoder", ".", "score", "(", "self", ".", "inputs", ".", "y", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"loss\"", ")", ":", "\n", "            ", "self", ".", "loss_layer", "=", "layers", ".", "Masked_cross_entropy_loss", "(", "\n", "self", ".", "inputs", ".", "y", ",", "self", ".", "inputs", ".", "y_mask", ",", "config", ".", "label_smoothing", ",", "\n", "training", "=", "self", ".", "inputs", ".", "training", ")", "\n", "self", ".", "_loss_per_sentence", "=", "self", ".", "loss_layer", ".", "forward", "(", "self", ".", "logits", ")", "\n", "self", ".", "_loss", "=", "tf", ".", "reduce_mean", "(", "input_tensor", "=", "self", ".", "_loss_per_sentence", ",", "keepdims", "=", "False", ")", "\n", "\n", "", "self", ".", "sampling_utils", "=", "SamplingUtils", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.RNNModel.loss_per_sentence": [[103, 106], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss_per_sentence", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_loss_per_sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.RNNModel.loss": [[107, 110], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Decoder.__init__": [[113, 230], ["tensorflow.shape", "tensorflow.compat.v1.variable_scope", "tensorflow.reduce_sum", "layers.FeedForwardLayer", "rnn_model.Decoder.init_state_layer.forward", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.variable_scope", "layers.DeepTransitionGRUStep", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.variable_scope", "rnn_model.Predictor", "tensorflow.expand_dims", "layers.EmbeddingLayer", "tensorflow.compat.v1.variable_scope", "layers.GRUStep", "tensorflow.compat.v1.variable_scope", "layers.AttentionStep", "layers.GRUStack", "tensorflow.compat.v1.variable_scope", "layers.LexicalModel", "rnn_model.Decoder.y_emb_layer.get_embeddings", "tensorflow.transpose", "tensorflow.reduce_sum", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.EmbeddingLayer.get_embeddings"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "context", ",", "x_embs", ",", "x_mask", ",", "layernorm", ",", "\n", "dropout_target", ",", "dropout_embedding", ",", "dropout_hidden", ",", "\n", "encoder_embedding_layer", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "dropout_target", "=", "dropout_target", "\n", "batch_size", "=", "tf", ".", "shape", "(", "input", "=", "x_mask", ")", "[", "1", "]", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"initial_state_constructor\"", ")", ":", "\n", "            ", "context_sum", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "context", "*", "tf", ".", "expand_dims", "(", "x_mask", ",", "axis", "=", "2", ")", ",", "\n", "axis", "=", "0", ")", "\n", "\n", "context_mean", "=", "context_sum", "/", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "reduce_sum", "(", "input_tensor", "=", "x_mask", ",", "axis", "=", "0", ")", ",", "\n", "axis", "=", "1", ")", "\n", "self", ".", "init_state_layer", "=", "layers", ".", "FeedForwardLayer", "(", "\n", "in_size", "=", "config", ".", "state_size", "*", "2", ",", "\n", "out_size", "=", "config", ".", "state_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_input", "=", "dropout_hidden", ")", "\n", "self", ".", "init_state", "=", "self", ".", "init_state_layer", ".", "forward", "(", "context_mean", ")", "\n", "self", ".", "x_embs", "=", "x_embs", "\n", "\n", "self", ".", "translation_maxlen", "=", "config", ".", "translation_maxlen", "\n", "self", ".", "embedding_size", "=", "config", ".", "target_embedding_size", "\n", "self", ".", "state_size", "=", "config", ".", "state_size", "\n", "self", ".", "target_vocab_size", "=", "config", ".", "target_vocab_size", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"embedding\"", ")", ":", "\n", "            ", "if", "encoder_embedding_layer", "==", "None", ":", "\n", "                ", "self", ".", "y_emb_layer", "=", "layers", ".", "EmbeddingLayer", "(", "\n", "vocabulary_sizes", "=", "[", "config", ".", "target_vocab_size", "]", ",", "\n", "dim_per_factor", "=", "[", "config", ".", "target_embedding_size", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "y_emb_layer", "=", "encoder_embedding_layer", "\n", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"base\"", ")", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"gru0\"", ")", ":", "\n", "                ", "if", "config", ".", "theano_compat", ":", "\n", "                    ", "bias_type", "=", "layers", ".", "LegacyBiasType", ".", "THEANO_A", "\n", "", "else", ":", "\n", "                    ", "bias_type", "=", "layers", ".", "LegacyBiasType", ".", "NEMATUS_COMPAT_FALSE", "\n", "", "self", ".", "grustep1", "=", "layers", ".", "GRUStep", "(", "\n", "input_size", "=", "config", ".", "target_embedding_size", ",", "\n", "state_size", "=", "config", ".", "state_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "legacy_bias_type", "=", "bias_type", ",", "\n", "dropout_input", "=", "dropout_embedding", ",", "\n", "dropout_state", "=", "dropout_hidden", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attention\"", ")", ":", "\n", "                ", "self", ".", "attstep", "=", "layers", ".", "AttentionStep", "(", "\n", "context", "=", "context", ",", "\n", "context_state_size", "=", "2", "*", "config", ".", "state_size", ",", "\n", "context_mask", "=", "x_mask", ",", "\n", "state_size", "=", "config", ".", "state_size", ",", "\n", "hidden_size", "=", "2", "*", "config", ".", "state_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_context", "=", "dropout_hidden", ",", "\n", "dropout_state", "=", "dropout_hidden", ")", "\n", "", "if", "config", ".", "theano_compat", ":", "\n", "                ", "bias_type", "=", "layers", ".", "LegacyBiasType", ".", "THEANO_B", "\n", "", "else", ":", "\n", "                ", "bias_type", "=", "layers", ".", "LegacyBiasType", ".", "NEMATUS_COMPAT_TRUE", "\n", "", "self", ".", "grustep2", "=", "layers", ".", "DeepTransitionGRUStep", "(", "\n", "input_size", "=", "2", "*", "config", ".", "state_size", ",", "\n", "state_size", "=", "config", ".", "state_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "legacy_bias_type", "=", "bias_type", ",", "\n", "dropout_input", "=", "dropout_hidden", ",", "\n", "dropout_state", "=", "dropout_hidden", ",", "\n", "transition_depth", "=", "config", ".", "rnn_dec_base_transition_depth", "-", "1", ",", "\n", "var_scope_fn", "=", "lambda", "i", ":", "\"gru{0}\"", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"high\"", ")", ":", "\n", "            ", "if", "config", ".", "rnn_dec_depth", "==", "1", ":", "\n", "                ", "self", ".", "high_gru_stack", "=", "None", "\n", "", "else", ":", "\n", "                ", "if", "config", ".", "theano_compat", ":", "\n", "                    ", "bias_type", "=", "layers", ".", "LegacyBiasType", ".", "THEANO_A", "\n", "", "else", ":", "\n", "                    ", "bias_type", "=", "layers", ".", "LegacyBiasType", ".", "NEMATUS_COMPAT_TRUE", "\n", "", "self", ".", "high_gru_stack", "=", "layers", ".", "GRUStack", "(", "\n", "input_size", "=", "config", ".", "state_size", ",", "\n", "state_size", "=", "config", ".", "state_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "legacy_bias_type", "=", "bias_type", ",", "\n", "dropout_input", "=", "dropout_hidden", ",", "\n", "dropout_state", "=", "dropout_hidden", ",", "\n", "stack_depth", "=", "config", ".", "rnn_dec_depth", "-", "1", ",", "\n", "transition_depth", "=", "config", ".", "rnn_dec_high_transition_depth", ",", "\n", "context_state_size", "=", "(", "2", "*", "config", ".", "state_size", "if", "config", ".", "rnn_dec_deep_context", "else", "0", ")", ",", "\n", "residual_connections", "=", "True", ",", "\n", "first_residual_output", "=", "0", ")", "\n", "\n", "", "", "if", "config", ".", "rnn_lexical_model", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"lexical\"", ")", ":", "\n", "                ", "self", ".", "lexical_layer", "=", "layers", ".", "LexicalModel", "(", "\n", "in_size", "=", "config", ".", "embedding_size", ",", "\n", "out_size", "=", "config", ".", "embedding_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_embedding", "=", "dropout_embedding", ",", "\n", "dropout_hidden", "=", "dropout_hidden", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "lexical_layer", "=", "None", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"next_word_predictor\"", ")", ":", "\n", "            ", "W", "=", "None", "\n", "if", "config", ".", "tie_decoder_embeddings", ":", "\n", "                ", "W", "=", "self", ".", "y_emb_layer", ".", "get_embeddings", "(", "factor", "=", "0", ")", "\n", "W", "=", "tf", ".", "transpose", "(", "a", "=", "W", ")", "\n", "", "self", ".", "predictor", "=", "Predictor", "(", "config", ",", "batch_size", ",", "layernorm", ",", "dropout_embedding", ",", "\n", "dropout_hidden", ",", "hidden_to_logits_W", "=", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Decoder.score": [[232, 278], ["tensorflow.zeros", "tensorflow.zeros", "rnn_model.Decoder.grustep1.precompute_from_x", "layers.RecurrentLayer", "layers.RecurrentLayer.forward", "rnn_model.Decoder.predictor.get_logits", "tensorflow.compat.v1.variable_scope", "tensorflow.slice", "rnn_model.Decoder.y_emb_layer.forward", "tensorflow.pad", "rnn_model.Decoder.grustep1.forward", "rnn_model.Decoder.attstep.forward", "rnn_model.Decoder.grustep2.forward", "rnn_model.Decoder.high_gru_stack.forward", "rnn_model.Decoder.lexical_layer.forward", "rnn_model.Decoder.dropout_target", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.DeepTransitionGRUStep.precompute_from_x", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Predictor.get_logits", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "score", "(", "self", ",", "y", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"y_embeddings_layer\"", ")", ":", "\n", "            ", "y_but_last", "=", "tf", ".", "slice", "(", "y", ",", "[", "0", ",", "0", "]", ",", "[", "tf", ".", "shape", "(", "input", "=", "y", ")", "[", "0", "]", "-", "1", ",", "-", "1", "]", ")", "\n", "y_embs", "=", "self", ".", "y_emb_layer", ".", "forward", "(", "y_but_last", ",", "factor", "=", "0", ")", "\n", "if", "self", ".", "dropout_target", "!=", "None", ":", "\n", "                ", "y_embs", "=", "self", ".", "dropout_target", "(", "y_embs", ")", "\n", "", "y_embs", "=", "tf", ".", "pad", "(", "tensor", "=", "y_embs", ",", "\n", "mode", "=", "'CONSTANT'", ",", "\n", "paddings", "=", "[", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "# prepend zeros", "\n", "\n", "", "init_attended_context", "=", "tf", ".", "zeros", "(", "[", "tf", ".", "shape", "(", "input", "=", "self", ".", "init_state", ")", "[", "0", "]", ",", "self", ".", "state_size", "*", "2", "]", ")", "\n", "init_att_alphas", "=", "tf", ".", "zeros", "(", "[", "tf", ".", "shape", "(", "input", "=", "self", ".", "x_embs", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "input", "=", "self", ".", "x_embs", ")", "[", "1", "]", "]", ")", "\n", "init_state_att_ctx", "=", "(", "self", ".", "init_state", ",", "init_attended_context", ",", "init_att_alphas", ")", "\n", "gates_x", ",", "proposal_x", "=", "self", ".", "grustep1", ".", "precompute_from_x", "(", "y_embs", ")", "\n", "def", "step_fn", "(", "prev", ",", "x", ")", ":", "\n", "            ", "prev_state", "=", "prev", "[", "0", "]", "\n", "prev_att_ctx", "=", "prev", "[", "1", "]", "\n", "prev_lexical_state", "=", "prev", "[", "2", "]", "\n", "gates_x2d", "=", "x", "[", "0", "]", "\n", "proposal_x2d", "=", "x", "[", "1", "]", "\n", "state", "=", "self", ".", "grustep1", ".", "forward", "(", "\n", "prev_state", ",", "\n", "gates_x", "=", "gates_x2d", ",", "\n", "proposal_x", "=", "proposal_x2d", ")", "\n", "att_ctx", ",", "att_alphas", "=", "self", ".", "attstep", ".", "forward", "(", "state", ")", "\n", "state", "=", "self", ".", "grustep2", ".", "forward", "(", "state", ",", "att_ctx", ")", "\n", "#TODO: write att_ctx to tensorArray instead of having it as output of scan?", "\n", "return", "(", "state", ",", "att_ctx", ",", "att_alphas", ")", "\n", "\n", "", "layer", "=", "layers", ".", "RecurrentLayer", "(", "initial_state", "=", "init_state_att_ctx", ",", "\n", "step_fn", "=", "step_fn", ")", "\n", "states", ",", "attended_states", ",", "attention_weights", "=", "layer", ".", "forward", "(", "(", "gates_x", ",", "proposal_x", ")", ")", "\n", "\n", "if", "self", ".", "high_gru_stack", "!=", "None", ":", "\n", "            ", "states", "=", "self", ".", "high_gru_stack", ".", "forward", "(", "\n", "states", ",", "\n", "context_layer", "=", "(", "attended_states", "if", "self", ".", "high_gru_stack", ".", "context_state_size", ">", "0", "else", "None", ")", ",", "\n", "init_state", "=", "self", ".", "init_state", ")", "\n", "\n", "", "if", "self", ".", "lexical_layer", "is", "not", "None", ":", "\n", "            ", "lexical_states", "=", "self", ".", "lexical_layer", ".", "forward", "(", "self", ".", "x_embs", ",", "attention_weights", ",", "multi_step", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "lexical_states", "=", "None", "\n", "\n", "", "logits", "=", "self", ".", "predictor", ".", "get_logits", "(", "y_embs", ",", "states", ",", "attended_states", ",", "lexical_states", ",", "multi_step", "=", "True", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Predictor.__init__": [[280, 348], ["tensorflow.compat.v1.variable_scope", "layers.FeedForwardLayer", "tensorflow.compat.v1.variable_scope", "layers.FeedForwardLayer", "tensorflow.compat.v1.variable_scope", "layers.FeedForwardLayer", "tensorflow.compat.v1.variable_scope", "layers.FeedForwardLayer", "range", "tensorflow.compat.v1.variable_scope", "PReLU", "tensorflow.compat.v1.variable_scope", "layers.FeedForwardLayer", "tensorflow.compat.v1.variable_scope", "layers.FeedForwardLayer", "tensorflow.compat.v1.variable_scope", "layers.FeedForwardLayer", "rnn_model.Predictor.hidden_to_mos_hidden.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "batch_size", ",", "layernorm", ",", "dropout_embedding", ",", "dropout_hidden", ",", "hidden_to_logits_W", "=", "None", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"prev_emb_to_hidden\"", ")", ":", "\n", "            ", "self", ".", "prev_emb_to_hidden", "=", "layers", ".", "FeedForwardLayer", "(", "\n", "in_size", "=", "config", ".", "target_embedding_size", ",", "\n", "out_size", "=", "config", ".", "target_embedding_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "non_linearity", "=", "lambda", "y", ":", "y", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_input", "=", "dropout_embedding", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"state_to_hidden\"", ")", ":", "\n", "            ", "self", ".", "state_to_hidden", "=", "layers", ".", "FeedForwardLayer", "(", "\n", "in_size", "=", "config", ".", "state_size", ",", "\n", "out_size", "=", "config", ".", "target_embedding_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "non_linearity", "=", "lambda", "y", ":", "y", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_input", "=", "dropout_hidden", ")", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attended_context_to_hidden\"", ")", ":", "\n", "            ", "self", ".", "att_ctx_to_hidden", "=", "layers", ".", "FeedForwardLayer", "(", "\n", "in_size", "=", "2", "*", "config", ".", "state_size", ",", "\n", "out_size", "=", "config", ".", "target_embedding_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "non_linearity", "=", "lambda", "y", ":", "y", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_input", "=", "dropout_hidden", ")", "\n", "\n", "", "if", "config", ".", "output_hidden_activation", "==", "'prelu'", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"hidden_prelu\"", ")", ":", "\n", "                ", "self", ".", "hidden_prelu", "=", "PReLU", "(", "in_size", "=", "config", ".", "target_embedding_size", ")", "\n", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"hidden_to_logits\"", ")", ":", "\n", "            ", "self", ".", "hidden_to_logits", "=", "layers", ".", "FeedForwardLayer", "(", "\n", "in_size", "=", "config", ".", "target_embedding_size", ",", "\n", "out_size", "=", "config", ".", "target_vocab_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "non_linearity", "=", "lambda", "y", ":", "y", ",", "\n", "W", "=", "hidden_to_logits_W", ",", "\n", "dropout_input", "=", "dropout_embedding", ")", "\n", "\n", "", "if", "config", ".", "softmax_mixture_size", ">", "1", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"hidden_to_pi_logits\"", ")", ":", "\n", "                ", "self", ".", "hidden_to_pi_logits", "=", "layers", ".", "FeedForwardLayer", "(", "\n", "in_size", "=", "config", ".", "target_embedding_size", ",", "\n", "out_size", "=", "config", ".", "softmax_mixture_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "non_linearity", "=", "lambda", "y", ":", "y", ",", "\n", "dropout_input", "=", "dropout_embedding", ")", "\n", "", "self", ".", "hidden_to_mos_hidden", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "config", ".", "softmax_mixture_size", ")", ":", "\n", "                ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"hidden_to_mos_hidden_{}\"", ".", "format", "(", "k", ")", ")", ":", "\n", "                    ", "layer", "=", "layers", ".", "FeedForwardLayer", "(", "\n", "in_size", "=", "config", ".", "target_embedding_size", ",", "\n", "out_size", "=", "config", ".", "target_embedding_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "dropout_input", "=", "dropout_embedding", ")", "\n", "self", ".", "hidden_to_mos_hidden", ".", "append", "(", "layer", ")", "\n", "\n", "", "", "", "if", "config", ".", "rnn_lexical_model", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"lexical_to_logits\"", ")", ":", "\n", "                ", "self", ".", "lexical_to_logits", "=", "layers", ".", "FeedForwardLayer", "(", "\n", "in_size", "=", "config", ".", "target_embedding_size", ",", "\n", "out_size", "=", "config", ".", "target_vocab_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "non_linearity", "=", "lambda", "y", ":", "y", ",", "\n", "dropout_input", "=", "dropout_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Predictor.get_logits": [[349, 399], ["tensorflow.compat.v1.variable_scope", "rnn_model.Predictor.prev_emb_to_hidden.forward", "tensorflow.compat.v1.variable_scope", "rnn_model.Predictor.state_to_hidden.forward", "tensorflow.compat.v1.variable_scope", "rnn_model.Predictor.att_ctx_to_hidden.forward", "tensorflow.tanh", "rnn_model.Predictor.hidden_to_pi_logits.forward", "tensorflow.nn.softmax", "range", "tensorflow.math.log", "tensorflow.nn.relu", "tensorflow.compat.v1.variable_scope", "rnn_model.Predictor.hidden_to_logits.forward", "rnn_model.Predictor.hidden_to_mos_hidden[].forward", "rnn_model.Predictor.hidden_to_logits.forward", "tensorflow.nn.softmax", "rnn_model.Predictor.hidden_prelu.forward", "tensorflow.compat.v1.variable_scope", "rnn_model.Predictor.lexical_to_logits.forward"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "", "def", "get_logits", "(", "self", ",", "y_embs", ",", "states", ",", "attended_states", ",", "lexical_states", ",", "multi_step", "=", "True", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"prev_emb_to_hidden\"", ")", ":", "\n", "            ", "hidden_emb", "=", "self", ".", "prev_emb_to_hidden", ".", "forward", "(", "y_embs", ",", "input_is_3d", "=", "multi_step", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"state_to_hidden\"", ")", ":", "\n", "            ", "hidden_state", "=", "self", ".", "state_to_hidden", ".", "forward", "(", "states", ",", "input_is_3d", "=", "multi_step", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"attended_context_to_hidden\"", ")", ":", "\n", "            ", "hidden_att_ctx", "=", "self", ".", "att_ctx_to_hidden", ".", "forward", "(", "attended_states", ",", "input_is_3d", "=", "multi_step", ")", "\n", "\n", "", "hidden", "=", "hidden_emb", "+", "hidden_state", "+", "hidden_att_ctx", "\n", "if", "self", ".", "config", ".", "output_hidden_activation", "==", "'tanh'", ":", "\n", "            ", "hidden", "=", "tf", ".", "tanh", "(", "hidden", ")", "\n", "", "elif", "self", ".", "config", ".", "output_hidden_activation", "==", "'relu'", ":", "\n", "            ", "hidden", "=", "tf", ".", "nn", ".", "relu", "(", "hidden", ")", "\n", "", "elif", "self", ".", "config", ".", "output_hidden_activation", "==", "'prelu'", ":", "\n", "            ", "hidden", "=", "self", ".", "hidden_prelu", ".", "forward", "(", "hidden", ")", "\n", "", "elif", "self", ".", "config", ".", "output_hidden_activation", "==", "'linear'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "'Unknown output activation function \"%s\"'", "%", "self", ".", "config", ".", "output_hidden_activation", "\n", "\n", "", "if", "self", ".", "config", ".", "softmax_mixture_size", "==", "1", ":", "\n", "            ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"hidden_to_logits\"", ")", ":", "\n", "                ", "logits", "=", "self", ".", "hidden_to_logits", ".", "forward", "(", "hidden", ",", "input_is_3d", "=", "multi_step", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "rnn_lexical_model", ":", "\n", "                ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"lexical_to_logits\"", ")", ":", "\n", "                    ", "logits", "+=", "self", ".", "lexical_to_logits", ".", "forward", "(", "lexical_states", ",", "input_is_3d", "=", "multi_step", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "assert", "self", ".", "config", ".", "softmax_mixture_size", ">", "1", "\n", "pi_logits", "=", "self", ".", "hidden_to_pi_logits", ".", "forward", "(", "hidden", ",", "\n", "input_is_3d", "=", "multi_step", ")", "\n", "pi", "=", "tf", ".", "nn", ".", "softmax", "(", "pi_logits", ")", "\n", "probs", "=", "None", "\n", "for", "k", "in", "range", "(", "self", ".", "config", ".", "softmax_mixture_size", ")", ":", "\n", "                ", "hidden_k", "=", "self", ".", "hidden_to_mos_hidden", "[", "k", "]", ".", "forward", "(", "hidden", ",", "\n", "input_is_3d", "=", "multi_step", ")", "\n", "logits_k", "=", "self", ".", "hidden_to_logits", ".", "forward", "(", "hidden_k", ",", "\n", "input_is_3d", "=", "multi_step", ")", "\n", "probs_k", "=", "tf", ".", "nn", ".", "softmax", "(", "logits_k", ")", "\n", "weight", "=", "pi", "[", "...", ",", "k", ":", "k", "+", "1", "]", "\n", "if", "k", "==", "0", ":", "\n", "                    ", "probs", "=", "probs_k", "*", "weight", "\n", "", "else", ":", "\n", "                    ", "probs", "+=", "probs_k", "*", "weight", "\n", "", "", "logits", "=", "tf", ".", "math", ".", "log", "(", "probs", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Encoder.__init__": [[402, 446], ["tensorflow.compat.v1.variable_scope", "layers.EmbeddingLayer", "tensorflow.compat.v1.variable_scope", "layers.GRUStack", "tensorflow.compat.v1.variable_scope", "layers.GRUStack"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "batch_size", ",", "layernorm", ",", "dropout_source", ",", "dropout_embedding", ",", "\n", "dropout_hidden", ")", ":", "\n", "\n", "        ", "self", ".", "dropout_source", "=", "dropout_source", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"embedding\"", ")", ":", "\n", "            ", "self", ".", "emb_layer", "=", "layers", ".", "EmbeddingLayer", "(", "config", ".", "source_vocab_sizes", ",", "\n", "config", ".", "dim_per_factor", ")", "\n", "\n", "", "if", "config", ".", "theano_compat", ":", "\n", "            ", "bias_type", "=", "layers", ".", "LegacyBiasType", ".", "THEANO_A", "\n", "", "else", ":", "\n", "            ", "bias_type", "=", "layers", ".", "LegacyBiasType", ".", "NEMATUS_COMPAT_FALSE", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"forward-stack\"", ")", ":", "\n", "            ", "self", ".", "forward_encoder", "=", "layers", ".", "GRUStack", "(", "\n", "input_size", "=", "config", ".", "embedding_size", ",", "\n", "state_size", "=", "config", ".", "state_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "legacy_bias_type", "=", "bias_type", ",", "\n", "dropout_input", "=", "dropout_embedding", ",", "\n", "dropout_state", "=", "dropout_hidden", ",", "\n", "stack_depth", "=", "config", ".", "rnn_enc_depth", ",", "\n", "transition_depth", "=", "config", ".", "rnn_enc_transition_depth", ",", "\n", "alternating", "=", "True", ",", "\n", "residual_connections", "=", "True", ",", "\n", "first_residual_output", "=", "1", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"backward-stack\"", ")", ":", "\n", "            ", "self", ".", "backward_encoder", "=", "layers", ".", "GRUStack", "(", "\n", "input_size", "=", "config", ".", "embedding_size", ",", "\n", "state_size", "=", "config", ".", "state_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "use_layer_norm", "=", "layernorm", ",", "\n", "legacy_bias_type", "=", "bias_type", ",", "\n", "dropout_input", "=", "dropout_embedding", ",", "\n", "dropout_state", "=", "dropout_hidden", ",", "\n", "stack_depth", "=", "config", ".", "rnn_enc_depth", ",", "\n", "transition_depth", "=", "config", ".", "rnn_enc_transition_depth", ",", "\n", "alternating", "=", "True", ",", "\n", "reverse_alternation", "=", "True", ",", "\n", "residual_connections", "=", "True", ",", "\n", "first_residual_output", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.rnn_model.Encoder.get_context": [[447, 469], ["len", "tensorflow.compat.v1.variable_scope", "rnn_model.Encoder.emb_layer.forward", "tensorflow.compat.v1.variable_scope", "rnn_model.Encoder.forward_encoder.forward", "tensorflow.compat.v1.variable_scope", "rnn_model.Encoder.backward_encoder.forward", "tensorflow.concat", "tensorflow.concat", "rnn_model.Encoder.dropout_source"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.layers.PReLU.forward"], ["", "", "def", "get_context", "(", "self", ",", "x", ",", "x_mask", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"embedding\"", ")", ":", "\n", "            ", "embs", "=", "self", ".", "emb_layer", ".", "forward", "(", "x", ")", "\n", "if", "self", ".", "dropout_source", "!=", "None", ":", "\n", "                ", "embs", "=", "self", ".", "dropout_source", "(", "embs", ")", "\n", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"forward-stack\"", ")", ":", "\n", "            ", "fwd_states", "=", "self", ".", "forward_encoder", ".", "forward", "(", "embs", ",", "x_mask", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "\"backward-stack\"", ")", ":", "\n", "            ", "bwd_states", "=", "self", ".", "backward_encoder", ".", "forward", "(", "embs", ",", "x_mask", ")", "\n", "\n", "# Concatenate the left-to-right and the right-to-left states, in that", "\n", "# order. This is for compatibility with models that were trained with", "\n", "# the Theano version.", "\n", "", "stack_depth", "=", "len", "(", "self", ".", "forward_encoder", ".", "grus", ")", "\n", "if", "stack_depth", "%", "2", "==", "0", ":", "\n", "            ", "concat_states", "=", "tf", ".", "concat", "(", "[", "bwd_states", ",", "fwd_states", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "concat_states", "=", "tf", ".", "concat", "(", "[", "fwd_states", ",", "bwd_states", "]", ",", "axis", "=", "2", ")", "\n", "", "return", "concat_states", ",", "embs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.learning_schedule.ConstantSchedule.__init__": [[7, 14], ["tensorflow.constant"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "learning_rate", ")", ":", "\n", "        ", "\"\"\"Builds TF graph nodes defining the learning rate function.\n\n        Args:\n            learning_rate: a float specifying the learning rate.\n        \"\"\"", "\n", "self", ".", "_learning_rate", "=", "tf", ".", "constant", "(", "learning_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.learning_schedule.ConstantSchedule.learning_rate": [[15, 18], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "learning_rate", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.learning_schedule.TransformerSchedule.__init__": [[26, 38], ["tensorflow.cast", "tensorflow.pow", "tensorflow.minimum"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "global_step", ",", "dim", ",", "warmup_steps", ")", ":", "\n", "        ", "\"\"\"Builds TF graph nodes defining the learning rate function.\n\n        Args:\n            global_step: a tf.Variable containing the current update step.\n            dim: an integer specifying the model's hidden state size.\n            warmup_steps: an integer specifying the number of warm-up steps.\n        \"\"\"", "\n", "t", "=", "tf", ".", "cast", "(", "global_step", "+", "1", ",", "tf", ".", "float32", ")", "\n", "a", "=", "tf", ".", "pow", "(", "t", ",", "-", "0.5", ")", "\n", "b", "=", "t", "*", "(", "warmup_steps", "**", "(", "-", "1.5", ")", ")", "\n", "self", ".", "_learning_rate", "=", "dim", "**", "(", "-", "0.5", ")", "*", "tf", ".", "minimum", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.learning_schedule.TransformerSchedule.learning_rate": [[39, 42], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "learning_rate", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.learning_schedule.WarmupPlateauDecaySchedule.__init__": [[55, 77], ["tensorflow.cast", "tensorflow.cast", "tensorflow.minimum", "tensorflow.minimum", "tensorflow.sqrt", "tensorflow.sqrt"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "global_step", ",", "peak_learning_rate", ",", "warmup_steps", ",", "\n", "plateau_steps", ")", ":", "\n", "        ", "\"\"\"Builds TF graph nodes defining the learning rate function.\n\n        Args:\n            global_step: a tf.Variable containing the current update step.\n            peak_learning_rate: a float specifying the peak learning rate.\n            warmup_steps: an integer specifying the number of warm-up steps.\n            plateau_steps: an integer specifying the number of plateau steps.\n        \"\"\"", "\n", "t", "=", "tf", ".", "cast", "(", "global_step", "+", "1", ",", "tf", ".", "float32", ")", "\n", "warmup_float", "=", "tf", ".", "cast", "(", "warmup_steps", ",", "tf", ".", "float32", ")", "\n", "# Function a: warmup", "\n", "a", "=", "(", "t", "/", "warmup_float", ")", "*", "peak_learning_rate", "\n", "# Function b: plateau", "\n", "b", "=", "peak_learning_rate", "\n", "# Function c: decay", "\n", "decay_start", "=", "warmup_float", "+", "plateau_steps", "\n", "c", "=", "(", "tf", ".", "sqrt", "(", "decay_start", ")", "/", "tf", ".", "sqrt", "(", "t", ")", ")", "*", "peak_learning_rate", "\n", "# Take the minimum of a, b, and c. This will be a for t < warmup_steps,", "\n", "# c for t > decay_start, and b in-between.", "\n", "self", ".", "_learning_rate", "=", "tf", ".", "minimum", "(", "tf", ".", "minimum", "(", "a", ",", "b", ")", ",", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.learning_schedule.WarmupPlateauDecaySchedule.learning_rate": [[78, 81], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "learning_rate", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_learning_rate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.__init__": [[26, 30], ["fopen().readlines", "numpy.array", "data_iterator.fopen"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.fopen"], ["    ", "def", "__init__", "(", "self", ",", "fname", ")", ":", "\n", "        ", "self", ".", "pos", "=", "0", "\n", "self", ".", "lines", "=", "fopen", "(", "fname", ")", ".", "readlines", "(", ")", "\n", "self", ".", "lines", "=", "numpy", ".", "array", "(", "self", ".", "lines", ",", "dtype", "=", "numpy", ".", "object", ")", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.__iter__": [[30, 32], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "", "def", "__next__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.__next__": [[32, 38], ["len"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "pos", ">=", "len", "(", "self", ".", "lines", ")", ":", "\n", "            ", "raise", "StopIteration", "\n", "", "l", "=", "self", ".", "lines", "[", "self", ".", "pos", "]", "\n", "self", ".", "pos", "+=", "1", "\n", "return", "l", "\n", "", "def", "reset", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.reset": [[38, 40], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "pos", "=", "0", "\n", "", "def", "seek", "(", "self", ",", "pos", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.seek": [[40, 43], ["None"], "methods", ["None"], ["", "def", "seek", "(", "self", ",", "pos", ")", ":", "\n", "        ", "assert", "pos", "==", "0", "\n", "self", ".", "pos", "=", "0", "\n", "", "def", "readline", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline": [[43, 45], ["next"], "methods", ["None"], ["", "def", "readline", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ")", "\n", "", "def", "shuffle_lines", "(", "self", ",", "perm", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.shuffle_lines": [[45, 48], ["None"], "methods", ["None"], ["", "def", "shuffle_lines", "(", "self", ",", "perm", ")", ":", "\n", "        ", "self", ".", "lines", "=", "self", ".", "lines", "[", "perm", "]", "\n", "self", ".", "pos", "=", "0", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.__len__": [[48, 50], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.TextIterator.__init__": [[53, 139], ["load_dict", "data_iterator.TextIterator.__init__.determine_unk_val"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.util.load_dict"], ["def", "__init__", "(", "self", ",", "source", ",", "target", ",", "\n", "source_dicts", ",", "target_dict", ",", "\n", "model_type", ",", "\n", "batch_size", "=", "128", ",", "\n", "maxlen", "=", "100", ",", "\n", "source_vocab_sizes", "=", "None", ",", "\n", "target_vocab_size", "=", "None", ",", "\n", "skip_empty", "=", "False", ",", "\n", "shuffle_each_epoch", "=", "False", ",", "\n", "sort_by_length", "=", "True", ",", "\n", "use_factor", "=", "False", ",", "\n", "maxibatch_size", "=", "20", ",", "\n", "token_batch_size", "=", "0", ",", "\n", "keep_data_in_memory", "=", "False", ",", "\n", "preprocess_script", "=", "None", ")", ":", "\n", "        ", "self", ".", "preprocess_script", "=", "preprocess_script", "\n", "self", ".", "source_orig", "=", "source", "\n", "self", ".", "target_orig", "=", "target", "\n", "if", "self", ".", "preprocess_script", ":", "\n", "            ", "logging", ".", "info", "(", "\"Executing external preprocessing script...\"", ")", "\n", "proc", "=", "subprocess", ".", "Popen", "(", "self", ".", "preprocess_script", ")", "\n", "proc", ".", "wait", "(", ")", "\n", "logging", ".", "info", "(", "\"done\"", ")", "\n", "", "if", "keep_data_in_memory", ":", "\n", "            ", "self", ".", "source", ",", "self", ".", "target", "=", "FileWrapper", "(", "source", ")", ",", "FileWrapper", "(", "target", ")", "\n", "if", "shuffle_each_epoch", ":", "\n", "                ", "r", "=", "numpy", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "source", ")", ")", "\n", "self", ".", "source", ".", "shuffle_lines", "(", "r", ")", "\n", "self", ".", "target", ".", "shuffle_lines", "(", "r", ")", "\n", "", "", "elif", "shuffle_each_epoch", ":", "\n", "            ", "self", ".", "source", ",", "self", ".", "target", "=", "shuffle", ".", "jointly_shuffle_files", "(", "\n", "[", "self", ".", "source_orig", ",", "self", ".", "target_orig", "]", ",", "temporary", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "source", "=", "fopen", "(", "source", ",", "'r'", ")", "\n", "self", ".", "target", "=", "fopen", "(", "target", ",", "'r'", ")", "\n", "", "self", ".", "source_dicts", "=", "[", "]", "\n", "for", "source_dict", "in", "source_dicts", ":", "\n", "            ", "self", ".", "source_dicts", ".", "append", "(", "load_dict", "(", "source_dict", ",", "model_type", ")", ")", "\n", "", "self", ".", "target_dict", "=", "load_dict", "(", "target_dict", ",", "model_type", ")", "\n", "\n", "# Determine the UNK value for each dictionary (the value depends on", "\n", "# which version of build_dictionary.py was used).", "\n", "\n", "def", "determine_unk_val", "(", "d", ")", ":", "\n", "            ", "if", "'<UNK>'", "in", "d", "and", "d", "[", "'<UNK>'", "]", "==", "2", ":", "\n", "                ", "return", "2", "\n", "", "return", "1", "\n", "\n", "", "self", ".", "source_unk_vals", "=", "[", "determine_unk_val", "(", "d", ")", "\n", "for", "d", "in", "self", ".", "source_dicts", "]", "\n", "self", ".", "target_unk_val", "=", "determine_unk_val", "(", "self", ".", "target_dict", ")", "\n", "\n", "\n", "self", ".", "keep_data_in_memory", "=", "keep_data_in_memory", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "maxlen", "=", "maxlen", "\n", "self", ".", "skip_empty", "=", "skip_empty", "\n", "self", ".", "use_factor", "=", "use_factor", "\n", "\n", "self", ".", "source_vocab_sizes", "=", "source_vocab_sizes", "\n", "self", ".", "target_vocab_size", "=", "target_vocab_size", "\n", "\n", "self", ".", "token_batch_size", "=", "token_batch_size", "\n", "\n", "if", "self", ".", "source_vocab_sizes", "!=", "None", ":", "\n", "            ", "assert", "len", "(", "self", ".", "source_vocab_sizes", ")", "==", "len", "(", "self", ".", "source_dicts", ")", "\n", "for", "d", ",", "vocab_size", "in", "zip", "(", "self", ".", "source_dicts", ",", "self", ".", "source_vocab_sizes", ")", ":", "\n", "                ", "if", "vocab_size", "!=", "None", "and", "vocab_size", ">", "0", ":", "\n", "                    ", "for", "key", ",", "idx", "in", "list", "(", "d", ".", "items", "(", ")", ")", ":", "\n", "                        ", "if", "idx", ">=", "vocab_size", ":", "\n", "                            ", "del", "d", "[", "key", "]", "\n", "\n", "", "", "", "", "", "if", "self", ".", "target_vocab_size", "!=", "None", "and", "self", ".", "target_vocab_size", ">", "0", ":", "\n", "            ", "for", "key", ",", "idx", "in", "list", "(", "self", ".", "target_dict", ".", "items", "(", ")", ")", ":", "\n", "                ", "if", "idx", ">=", "self", ".", "target_vocab_size", ":", "\n", "                    ", "del", "self", ".", "target_dict", "[", "key", "]", "\n", "\n", "", "", "", "self", ".", "shuffle", "=", "shuffle_each_epoch", "\n", "self", ".", "sort_by_length", "=", "sort_by_length", "\n", "\n", "self", ".", "source_buffer", "=", "[", "]", "\n", "self", ".", "target_buffer", "=", "[", "]", "\n", "self", ".", "k", "=", "batch_size", "*", "maxibatch_size", "\n", "\n", "\n", "self", ".", "end_of_data", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.TextIterator.__iter__": [[140, 142], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.TextIterator.reset": [[143, 165], ["logging.info", "subprocess.Popen", "subprocess.Popen.wait", "logging.info", "data_iterator.TextIterator.source.seek", "data_iterator.TextIterator.target.seek", "data_iterator.fopen", "data_iterator.fopen", "numpy.random.permutation", "data_iterator.TextIterator.source.shuffle_lines", "data_iterator.TextIterator.target.shuffle_lines", "shuffle.jointly_shuffle_files", "data_iterator.FileWrapper", "data_iterator.FileWrapper", "len"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.seek", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.seek", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.fopen", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.fopen", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.shuffle_lines", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.shuffle_lines", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.shuffle.jointly_shuffle_files"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "preprocess_script", ":", "\n", "            ", "logging", ".", "info", "(", "\"Executing external preprocessing script...\"", ")", "\n", "proc", "=", "subprocess", ".", "Popen", "(", "self", ".", "preprocess_script", ")", "\n", "proc", ".", "wait", "(", ")", "\n", "logging", ".", "info", "(", "\"done\"", ")", "\n", "if", "self", ".", "keep_data_in_memory", ":", "\n", "                ", "self", ".", "source", ",", "self", ".", "target", "=", "FileWrapper", "(", "self", ".", "source_orig", ")", ",", "FileWrapper", "(", "self", ".", "target_orig", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "source", "=", "fopen", "(", "self", ".", "source_orig", ",", "'r'", ")", "\n", "self", ".", "target", "=", "fopen", "(", "self", ".", "target_orig", ",", "'r'", ")", "\n", "", "", "if", "self", ".", "shuffle", ":", "\n", "            ", "if", "self", ".", "keep_data_in_memory", ":", "\n", "                ", "r", "=", "numpy", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "source", ")", ")", "\n", "self", ".", "source", ".", "shuffle_lines", "(", "r", ")", "\n", "self", ".", "target", ".", "shuffle_lines", "(", "r", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "source", ",", "self", ".", "target", "=", "shuffle", ".", "jointly_shuffle_files", "(", "\n", "[", "self", ".", "source_orig", ",", "self", ".", "target_orig", "]", ",", "temporary", "=", "True", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "source", ".", "seek", "(", "0", ")", "\n", "self", ".", "target", ".", "seek", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.TextIterator.__next__": [[166, 273], ["data_iterator.TextIterator.reset", "len", "len", "len", "data_iterator.TextIterator.split", "data_iterator.TextIterator.target.readline().split", "data_iterator.TextIterator.source_buffer.append", "data_iterator.TextIterator.target_buffer.append", "data_iterator.TextIterator.reset", "numpy.array", "numpy.array.argsort", "data_iterator.TextIterator.source_buffer.reverse", "data_iterator.TextIterator.target_buffer.reverse", "data_iterator.TextIterator.target_buffer.pop", "source.append", "target.append", "max", "max", "len", "len", "len", "data_iterator.TextIterator.source_buffer.pop", "tmp.append", "data_iterator.TextIterator.__next__.lookup_token"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.TextIterator.reset", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.TextIterator.reset"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "end_of_data", ":", "\n", "            ", "self", ".", "end_of_data", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "", "source", "=", "[", "]", "\n", "target", "=", "[", "]", "\n", "\n", "longest_source", "=", "0", "\n", "longest_target", "=", "0", "\n", "\n", "# fill buffer, if it's empty", "\n", "assert", "len", "(", "self", ".", "source_buffer", ")", "==", "len", "(", "self", ".", "target_buffer", ")", ",", "'Buffer size mismatch!'", "\n", "\n", "if", "len", "(", "self", ".", "source_buffer", ")", "==", "0", ":", "\n", "            ", "for", "ss", "in", "self", ".", "source", ":", "\n", "                ", "ss", "=", "ss", ".", "split", "(", ")", "\n", "tt", "=", "self", ".", "target", ".", "readline", "(", ")", ".", "split", "(", ")", "\n", "\n", "if", "self", ".", "skip_empty", "and", "(", "len", "(", "ss", ")", "==", "0", "or", "len", "(", "tt", ")", "==", "0", ")", ":", "\n", "                    ", "continue", "\n", "", "if", "len", "(", "ss", ")", ">", "self", ".", "maxlen", "or", "len", "(", "tt", ")", ">", "self", ".", "maxlen", ":", "\n", "                    ", "continue", "\n", "\n", "", "self", ".", "source_buffer", ".", "append", "(", "ss", ")", "\n", "self", ".", "target_buffer", ".", "append", "(", "tt", ")", "\n", "if", "len", "(", "self", ".", "source_buffer", ")", "==", "self", ".", "k", ":", "\n", "                    ", "break", "\n", "\n", "", "", "if", "len", "(", "self", ".", "source_buffer", ")", "==", "0", "or", "len", "(", "self", ".", "target_buffer", ")", "==", "0", ":", "\n", "                ", "self", ".", "end_of_data", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "# sort by source/target buffer length", "\n", "", "if", "self", ".", "sort_by_length", ":", "\n", "                ", "tlen", "=", "numpy", ".", "array", "(", "[", "max", "(", "len", "(", "s", ")", ",", "len", "(", "t", ")", ")", "for", "(", "s", ",", "t", ")", "in", "zip", "(", "self", ".", "source_buffer", ",", "self", ".", "target_buffer", ")", "]", ")", "\n", "tidx", "=", "tlen", ".", "argsort", "(", ")", "\n", "\n", "_sbuf", "=", "[", "self", ".", "source_buffer", "[", "i", "]", "for", "i", "in", "tidx", "]", "\n", "_tbuf", "=", "[", "self", ".", "target_buffer", "[", "i", "]", "for", "i", "in", "tidx", "]", "\n", "\n", "self", ".", "source_buffer", "=", "_sbuf", "\n", "self", ".", "target_buffer", "=", "_tbuf", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "source_buffer", ".", "reverse", "(", ")", "\n", "self", ".", "target_buffer", ".", "reverse", "(", ")", "\n", "\n", "", "", "def", "lookup_token", "(", "t", ",", "d", ",", "unk_val", ")", ":", "\n", "            ", "return", "d", "[", "t", "]", "if", "t", "in", "d", "else", "unk_val", "\n", "\n", "", "try", ":", "\n", "# actual work here", "\n", "            ", "while", "True", ":", "\n", "\n", "# read from source file and map to word index", "\n", "                ", "try", ":", "\n", "                    ", "ss", "=", "self", ".", "source_buffer", ".", "pop", "(", ")", "\n", "", "except", "IndexError", ":", "\n", "                    ", "break", "\n", "", "tmp", "=", "[", "]", "\n", "for", "w", "in", "ss", ":", "\n", "                    ", "if", "self", ".", "use_factor", ":", "\n", "                        ", "w", "=", "[", "lookup_token", "(", "f", ",", "self", ".", "source_dicts", "[", "i", "]", ",", "\n", "self", ".", "source_unk_vals", "[", "i", "]", ")", "\n", "for", "(", "i", ",", "f", ")", "in", "enumerate", "(", "w", ".", "split", "(", "'|'", ")", ")", "]", "\n", "", "else", ":", "\n", "                        ", "w", "=", "[", "lookup_token", "(", "w", ",", "self", ".", "source_dicts", "[", "0", "]", ",", "\n", "self", ".", "source_unk_vals", "[", "0", "]", ")", "]", "\n", "", "tmp", ".", "append", "(", "w", ")", "\n", "", "ss_indices", "=", "tmp", "\n", "\n", "# read from source file and map to word index", "\n", "tt", "=", "self", ".", "target_buffer", ".", "pop", "(", ")", "\n", "tt_indices", "=", "[", "lookup_token", "(", "w", ",", "self", ".", "target_dict", ",", "\n", "self", ".", "target_unk_val", ")", "for", "w", "in", "tt", "]", "\n", "if", "self", ".", "target_vocab_size", "!=", "None", ":", "\n", "                    ", "tt_indices", "=", "[", "w", "if", "w", "<", "self", ".", "target_vocab_size", "\n", "else", "self", ".", "target_unk_val", "\n", "for", "w", "in", "tt_indices", "]", "\n", "\n", "", "source", ".", "append", "(", "ss_indices", ")", "\n", "target", ".", "append", "(", "tt_indices", ")", "\n", "longest_source", "=", "max", "(", "longest_source", ",", "len", "(", "ss_indices", ")", ")", "\n", "longest_target", "=", "max", "(", "longest_target", ",", "len", "(", "tt_indices", ")", ")", "\n", "\n", "if", "self", ".", "token_batch_size", ":", "\n", "                    ", "if", "len", "(", "source", ")", "*", "longest_source", ">", "self", ".", "token_batch_size", "or", "len", "(", "target", ")", "*", "longest_target", ">", "self", ".", "token_batch_size", ":", "\n", "# remove last sentence pair (that made batch over-long)", "\n", "                        ", "source", ".", "pop", "(", ")", "\n", "target", ".", "pop", "(", ")", "\n", "self", ".", "source_buffer", ".", "append", "(", "ss", ")", "\n", "self", ".", "target_buffer", ".", "append", "(", "tt", ")", "\n", "\n", "break", "\n", "\n", "", "", "else", ":", "\n", "                    ", "if", "len", "(", "source", ")", ">=", "self", ".", "batch_size", "or", "len", "(", "target", ")", ">=", "self", ".", "batch_size", ":", "\n", "                        ", "break", "\n", "", "", "", "", "except", "IOError", ":", "\n", "            ", "self", ".", "end_of_data", "=", "True", "\n", "\n", "", "return", "source", ",", "target", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.fopen": [[20, 24], ["filename.endswith", "open", "gzip.open"], "function", ["None"], ["", "def", "fopen", "(", "filename", ",", "mode", "=", "'r'", ")", ":", "\n", "    ", "if", "filename", ".", "endswith", "(", "'.gz'", ")", ":", "\n", "        ", "return", "gzip", ".", "open", "(", "filename", ",", "mode", ",", "encoding", "=", "\"UTF-8\"", ")", "\n", "", "return", "open", "(", "filename", ",", "mode", ",", "encoding", "=", "\"UTF-8\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.request.TranslationRequest.__init__": [[16, 27], ["settings.TranslationSettings", "request.TranslationRequest._parse"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.nematus_style.TranslationRequestNematus._parse"], ["def", "__init__", "(", "self", ",", "request", ")", ":", "\n", "        ", "\"\"\"\n        Initialises a translation request.\n\n        @type raw_body: str\n        @param raw_body: the POST request submitted to Nematus server.\n        \"\"\"", "\n", "self", ".", "_request", "=", "request", "\n", "self", ".", "segments", "=", "[", "]", "\n", "self", ".", "settings", "=", "TranslationSettings", "(", ")", "# default values", "\n", "self", ".", "_parse", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.request.TranslationRequest._format": [[28, 34], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_format", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Formats this translation response.\n        \"\"\"", "\n", "pass", "# to be implemented in subclasses", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.request.TranslationRequest.__repr__": [[35, 40], ["request.TranslationRequest._format"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.nematus_style.TranslationResponseNematus._format"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the raw body of this translation request.\n        \"\"\"", "\n", "return", "self", ".", "_format", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.request.TranslationRequest._parse": [[41, 55], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_parse", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Parses the request's raw body. Sets or overrides\n        * self.segments\n        * self.beam_width\n        * self.normalize\n        * self.character_level\n        * self.n_best\n        * self.suppress_unk\n        * self.return_word_alignment\n        * self.return_word_probabilities\n        \"\"\"", "\n", "pass", "# to be implemented in subclasses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.response.TranslationResponse.__init__": [[17, 30], ["response.TranslationResponse._format"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.nematus_style.TranslationResponseNematus._format"], ["def", "__init__", "(", "self", ",", "status", ",", "segments", ",", "word_alignments", "=", "None", ",", "word_probabilities", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialises a translation response.\n\n        @type segments: list(str)\n        @param segments: the translated segments to be included.\n        \"\"\"", "\n", "self", ".", "_content_type", "=", "\"application/json\"", "\n", "self", ".", "_status", "=", "status", "\n", "self", ".", "_segments", "=", "segments", "\n", "self", ".", "_word_alignments", "=", "word_alignments", "\n", "self", ".", "_word_probabilities", "=", "word_probabilities", "\n", "self", ".", "_response", "=", "self", ".", "_format", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.response.TranslationResponse._format": [[31, 37], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_format", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Formats this translation response.\n        \"\"\"", "\n", "pass", "# to be implemented in subclasses", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.response.TranslationResponse.__repr__": [[38, 43], ["response.TranslationResponse._format"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.nematus_style.TranslationResponseNematus._format"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the raw body of this translation response.\n        \"\"\"", "\n", "return", "self", ".", "_format", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.server.response.TranslationResponse.get_content_type": [[44, 46], ["None"], "methods", ["None"], ["", "def", "get_content_type", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_content_type", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.provider.request_provider": [[8, 21], ["NotImplementedError"], "function", ["None"], ["def", "request_provider", "(", "style", ",", "request", ")", ":", "\n", "    ", "\"\"\"\n    Turns a raw request body into a TranslationRequest of a given API style\n    @param style.\n    \"\"\"", "\n", "from", ".", "nematus_style", "import", "TranslationRequestNematus", "\n", "mapping", "=", "{", "\n", "'Nematus'", ":", "TranslationRequestNematus", "\n", "}", "\n", "try", ":", "\n", "        ", "return", "mapping", "[", "style", "]", "(", "request", ")", "\n", "", "except", "IndexError", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Invalid API style: {0}\"", ".", "format", "(", "style", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.provider.response_provider": [[22, 35], ["NotImplementedError"], "function", ["None"], ["", "", "def", "response_provider", "(", "style", ",", "**", "response_args", ")", ":", "\n", "    ", "\"\"\"\n    Formats @param response_args as a TranslationResponse of a given API style\n    @param style.\n    \"\"\"", "\n", "from", ".", "nematus_style", "import", "TranslationResponseNematus", "\n", "mapping", "=", "{", "\n", "'Nematus'", ":", "TranslationResponseNematus", "\n", "}", "\n", "try", ":", "\n", "        ", "return", "mapping", "[", "style", "]", "(", "**", "response_args", ")", "\n", "", "except", "IndexError", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Invalid API style: {0}\"", ".", "format", "(", "style", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.nematus_style.TranslationRequestNematus._parse": [[12, 31], ["None"], "methods", ["None"], ["    ", "def", "_parse", "(", "self", ")", ":", "\n", "# never produce search graph", "\n", "        ", "self", ".", "get_search_graph", "=", "False", "\n", "\n", "request", "=", "self", ".", "_request", ".", "json", "\n", "if", "'segments'", "in", "request", ":", "\n", "            ", "self", ".", "segments", "=", "[", "' '", ".", "join", "(", "tokens", ")", "for", "tokens", "in", "request", "[", "'segments'", "]", "]", "\n", "", "if", "'beam_width'", "in", "request", ":", "\n", "            ", "self", ".", "settings", ".", "beam_width", "=", "request", "[", "'beam_width'", "]", "\n", "", "if", "'normalize'", "in", "request", ":", "\n", "            ", "self", ".", "settings", ".", "normalization_alpha", "=", "request", "[", "'normalize'", "]", "\n", "", "if", "'character_level'", "in", "request", ":", "\n", "            ", "self", ".", "settings", ".", "char_level", "=", "request", "[", "'character_level'", "]", "\n", "", "if", "'suppress_unk'", "in", "request", ":", "\n", "            ", "self", ".", "settings", ".", "suppress_unk", "=", "request", "[", "'suppress_unk'", "]", "\n", "", "if", "'return_word_alignment'", "in", "request", ":", "\n", "            ", "self", ".", "settings", ".", "get_alignment", "=", "request", "[", "'return_word_alignment'", "]", "\n", "", "if", "'return_word_probabilities'", "in", "request", ":", "\n", "            ", "self", ".", "settings", ".", "get_word_probs", "=", "request", "[", "'return_word_probabilities'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.nematus_style.TranslationRequestNematus._format": [[32, 38], ["json.dumps", "str"], "methods", ["None"], ["", "", "def", "_format", "(", "self", ")", ":", "\n", "        ", "request", "=", "{", "\n", "'id'", ":", "str", "(", "self", ".", "settings", ".", "request_id", ")", ",", "\n", "'data'", ":", "[", "segment", "for", "segment", "in", "self", ".", "segments", "]", "\n", "}", "\n", "return", "json", ".", "dumps", "(", "request", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.api.nematus_style.TranslationResponseNematus._format": [[40, 57], ["json.dumps", "enumerate", "response[].append"], "methods", ["None"], ["    ", "def", "_format", "(", "self", ")", ":", "\n", "        ", "response", "=", "{", "\n", "'status'", ":", "''", ",", "\n", "'data'", ":", "[", "]", ",", "\n", "}", "\n", "if", "self", ".", "_status", "==", "self", ".", "STATUS_OK", ":", "\n", "            ", "response", "[", "'status'", "]", "=", "'ok'", "\n", "for", "i", ",", "translation", "in", "enumerate", "(", "self", ".", "_segments", ")", ":", "\n", "                ", "segment", "=", "{", "'translation'", ":", "translation", "}", "\n", "if", "self", ".", "_word_alignments", ":", "\n", "                    ", "segment", "[", "'word_alignment'", "]", "=", "self", ".", "_word_alignments", "[", "i", "]", "\n", "", "if", "self", ".", "_word_probabilities", ":", "\n", "                    ", "segment", "[", "'word_probabilities'", "]", "=", "self", ".", "_word_probabilities", "[", "i", "]", "\n", "", "response", "[", "'data'", "]", ".", "append", "(", "segment", ")", "\n", "", "", "else", ":", "\n", "            ", "response", "[", "'status'", "]", "=", "'error'", "\n", "", "return", "json", ".", "dumps", "(", "response", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.chrf.CharacterFScorer.__init__": [[21, 32], ["Scorer.__init__", "list", "list", "chrf.CharacterFScorer._arguments.keys", "chrf.CharacterFScorer._arguments.keys"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__"], ["def", "__init__", "(", "self", ",", "argument_string", ")", ":", "\n", "        ", "\"\"\"\n        Initialises metric-specific parameters.\n        \"\"\"", "\n", "Scorer", ".", "__init__", "(", "self", ",", "argument_string", ")", "\n", "# use character n-gram order of 4 by default", "\n", "if", "not", "'n'", "in", "list", "(", "self", ".", "_arguments", ".", "keys", "(", ")", ")", ":", "\n", "            ", "self", ".", "_arguments", "[", "'n'", "]", "=", "6", "\n", "# use beta = 1 by default (recommendation by Maja Popovic for generative modelling)", "\n", "", "if", "not", "'beta'", "in", "list", "(", "self", ".", "_arguments", ".", "keys", "(", ")", ")", ":", "\n", "            ", "self", ".", "_arguments", "[", "'beta'", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.chrf.CharacterFScorer.set_reference": [[33, 41], ["chrf.CharacterFScoreReference"], "methods", ["None"], ["", "", "def", "set_reference", "(", "self", ",", "reference_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Sets the reference against hypotheses are scored.\n        \"\"\"", "\n", "self", ".", "_reference", "=", "CharacterFScoreReference", "(", "\n", "reference_tokens", ",", "\n", "self", ".", "_arguments", "[", "'n'", "]", ",", "\n", "self", ".", "_arguments", "[", "'beta'", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.chrf.CharacterFScoreReference.__init__": [[48, 70], ["Reference.__init__", "chrf.CharacterFScoreReference._get_ngrams", "ValueError"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuReference._get_ngrams"], ["def", "__init__", "(", "self", ",", "reference_tokens", ",", "n", "=", "6", ",", "beta", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        @param reference the reference translation that hypotheses shall be\n                         scored against.\n        @param n         maximum character n-gram order to consider.\n        @param beta      algorithm paramater beta (interpolation weight, needs to be > 0).\n        \"\"\"", "\n", "if", "beta", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Value of beta needs to be larger than zero!\"", ")", "\n", "\n", "", "Reference", ".", "__init__", "(", "self", ",", "reference_tokens", ")", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "max_order", "=", "n", "\n", "self", ".", "beta_squared", "=", "beta", "**", "2", "\n", "\n", "# The paper specifies that whitespace is ignored, but for a training objective,", "\n", "#it's perhaps better to leave it in. According to the paper, it makes no", "\n", "#difference in practise for scoring.", "\n", "self", ".", "_reference_string", "=", "\" \"", ".", "join", "(", "reference_tokens", ")", ".", "strip", "(", ")", "\n", "\n", "# Get n-grams from reference:", "\n", "self", ".", "_reference_ngrams", "=", "self", ".", "_get_ngrams", "(", "self", ".", "_reference_string", ",", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.chrf.CharacterFScoreReference._get_ngrams": [[71, 93], ["len", "len", "len", "n_grams_list.append", "order_dict.setdefault"], "methods", ["None"], ["", "def", "_get_ngrams", "(", "self", ",", "tokens", ",", "n", ")", ":", "\n", "        ", "\"\"\"\n        Extracts all n-grams up to order @param n from a list of @param tokens.\n        \"\"\"", "\n", "n_grams_dict", "=", "{", "}", "\n", "length", "=", "len", "(", "tokens", ")", "\n", "#If the reference is shorter than n characters, insist on an exact match:", "\n", "if", "len", "(", "tokens", ")", "<", "n", ":", "\n", "            ", "self", ".", "max_order", "=", "len", "(", "tokens", ")", "\n", "", "m", "=", "1", "\n", "while", "m", "<=", "n", ":", "#n-gram order", "\n", "            ", "i", "=", "m", "\n", "n_grams_list", "=", "[", "]", "\n", "order_dict", "=", "{", "}", "\n", "while", "(", "i", "<=", "length", ")", ":", "\n", "                ", "n_grams_list", ".", "append", "(", "tokens", "[", "i", "-", "m", ":", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "for", "ngr", "in", "n_grams_list", ":", "\n", "                ", "order_dict", "[", "ngr", "]", "=", "order_dict", ".", "setdefault", "(", "ngr", ",", "0", ")", "+", "1", "\n", "", "n_grams_dict", "[", "m", "]", "=", "order_dict", "\n", "m", "+=", "1", "\n", "", "return", "n_grams_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.chrf.CharacterFScoreReference.score": [[94, 154], ["chrf.CharacterFScoreReference._get_ngrams", "range", "range", "float", "float", "len", "len", "min", "min"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuReference._get_ngrams"], ["", "def", "score", "(", "self", ",", "hypothesis_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Scores @param hypothesis against this reference.\n\n        @return the sentence-level ChrF score: 1.0 is best, 0.0 worst.\n        \"\"\"", "\n", "#See comment above on treating whitespace.", "\n", "hypothesis_string", "=", "\" \"", ".", "join", "(", "hypothesis_tokens", ")", ".", "strip", "(", ")", "\n", "\n", "#If the hypothesis or the reference is empty, insist on an exact match:", "\n", "if", "len", "(", "self", ".", "_reference_string", ")", "<", "1", "or", "len", "(", "hypothesis_string", ")", "<", "1", ":", "\n", "            ", "if", "hypothesis_string", "==", "self", ".", "_reference_string", ":", "\n", "                ", "return", "1.0", "\n", "", "else", ":", "\n", "                ", "return", "0.0", "\n", "\n", "", "", "hypothesis_ngrams", "=", "self", ".", "_get_ngrams", "(", "hypothesis_string", ",", "self", ".", "n", ")", "\n", "\n", "#Calculate character precision:", "\n", "chrP", "=", "0.0", "\n", "chrR", "=", "0.0", "\n", "for", "m", "in", "range", "(", "1", ",", "self", ".", "n", "+", "1", ")", ":", "\n", "            ", "hyp_count", "=", "0.0", "\n", "count_total", "=", "0.0", "\n", "count_in", "=", "0.0", "\n", "for", "ngr", "in", "hypothesis_ngrams", "[", "m", "]", ":", "\n", "                ", "hyp_count", "=", "hypothesis_ngrams", "[", "m", "]", "[", "ngr", "]", "\n", "count_total", "+=", "hyp_count", "\n", "if", "ngr", "in", "self", ".", "_reference_ngrams", "[", "m", "]", ":", "\n", "                    ", "count_in", "+=", "min", "(", "hyp_count", ",", "self", ".", "_reference_ngrams", "[", "m", "]", "[", "ngr", "]", ")", "\n", "#Catch division by zero:", "\n", "", "", "if", "count_total", "==", "0.0", ":", "\n", "                ", "chrP", "+=", "0.0", "\n", "", "else", ":", "\n", "                ", "chrP", "+=", "count_in", "/", "count_total", "\n", "#average chrP over n-gram orders:        ", "\n", "", "", "chrP", "=", "chrP", "/", "float", "(", "self", ".", "max_order", ")", "\n", "\n", "#Calculate character recall:", "\n", "for", "m", "in", "range", "(", "1", ",", "self", ".", "n", "+", "1", ")", ":", "\n", "            ", "ref_count", "=", "0.0", "\n", "count_total", "=", "0.0", "\n", "count_in", "=", "0.0", "\n", "for", "ngr", "in", "self", ".", "_reference_ngrams", "[", "m", "]", ":", "\n", "                ", "ref_count", "=", "self", ".", "_reference_ngrams", "[", "m", "]", "[", "ngr", "]", "\n", "count_total", "+=", "ref_count", "\n", "if", "ngr", "in", "hypothesis_ngrams", "[", "m", "]", ":", "\n", "                    ", "count_in", "+=", "min", "(", "ref_count", ",", "hypothesis_ngrams", "[", "m", "]", "[", "ngr", "]", ")", "\n", "#Catch division by zero:", "\n", "", "", "if", "count_total", "==", "0.0", ":", "\n", "                ", "chrR", "+=", "0.0", "\n", "", "else", ":", "\n", "                ", "chrR", "+=", "count_in", "/", "count_total", "\n", "#average chrR over n-gram orders:", "\n", "", "", "chrR", "=", "chrR", "/", "float", "(", "self", ".", "max_order", ")", "\n", "\n", "#Catch division by zero:", "\n", "if", "chrP", "==", "0.0", "and", "chrR", "==", "0.0", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "(", "1", "+", "self", ".", "beta_squared", ")", "*", "(", "chrP", "*", "chrR", ")", "/", "(", "(", "self", ".", "beta_squared", "*", "chrP", ")", "+", "chrR", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_scorer_provider.TestScorerProvider.tokenize": [[12, 15], ["sentence.split"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "tokenize", "(", "sentence", ")", ":", "\n", "        ", "return", "sentence", ".", "split", "(", "\" \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_scorer_provider.TestScorerProvider.test_single_metric": [[16, 26], ["test_scorer_provider.TestScorerProvider.tokenize", "metrics.sentence_bleu.SentenceBleuScorer", "metrics.scorer_provider.ScorerProvider().get", "metrics.sentence_bleu.SentenceBleuScorer.set_reference", "metrics.scorer_provider.ScorerProvider().get.set_reference", "test_scorer_provider.TestScorerProvider.assertEqual", "metrics.sentence_bleu.SentenceBleuScorer.score", "metrics.scorer_provider.ScorerProvider().get.score", "metrics.scorer_provider.ScorerProvider"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_single_metric", "(", "self", ")", ":", "\n", "        ", "config_string", "=", "\"SENTENCEBLEU n=4\"", "\n", "segment", "=", "self", ".", "tokenize", "(", "\"Consistency is the last refuge of the unimaginative\"", ")", "\n", "reference_scorer", "=", "SentenceBleuScorer", "(", "'n=4'", ")", "\n", "provided_scorer", "=", "ScorerProvider", "(", ")", ".", "get", "(", "config_string", ")", "\n", "reference_scorer", ".", "set_reference", "(", "segment", ")", "\n", "provided_scorer", ".", "set_reference", "(", "segment", ")", "\n", "self", ".", "assertEqual", "(", "\n", "reference_scorer", ".", "score", "(", "segment", ")", ",", "\n", "provided_scorer", ".", "score", "(", "segment", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_scorer_provider.TestScorerProvider.test_interpolated_metrics": [[28, 38], ["test_scorer_provider.TestScorerProvider.tokenize", "metrics.sentence_bleu.SentenceBleuScorer", "metrics.scorer_provider.ScorerProvider().get", "metrics.sentence_bleu.SentenceBleuScorer.set_reference", "metrics.scorer_provider.ScorerProvider().get.set_reference", "test_scorer_provider.TestScorerProvider.assertEqual", "metrics.sentence_bleu.SentenceBleuScorer.score", "metrics.scorer_provider.ScorerProvider().get.score", "metrics.scorer_provider.ScorerProvider"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_interpolated_metrics", "(", "self", ")", ":", "\n", "        ", "config_string", "=", "\"INTERPOLATE w=0.3,0.7; SENTENCEBLEU n=4; SENTENCEBLEU n=4\"", "\n", "segment", "=", "self", ".", "tokenize", "(", "\"Consistency is the last refuge of the unimaginative\"", ")", "\n", "reference_scorer", "=", "SentenceBleuScorer", "(", "'n=4'", ")", "\n", "provided_scorer", "=", "ScorerProvider", "(", ")", ".", "get", "(", "config_string", ")", "# interpolating BLEU with BLEU should obviously result in the same as just using a single BLEU scorer", "\n", "reference_scorer", ".", "set_reference", "(", "segment", ")", "\n", "provided_scorer", ".", "set_reference", "(", "segment", ")", "\n", "self", ".", "assertEqual", "(", "\n", "reference_scorer", ".", "score", "(", "segment", ")", ",", "\n", "provided_scorer", ".", "score", "(", "segment", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_interpolator.ScorerInterpolator.__init__": [[22, 46], ["config_string.split", "enumerate", "scorer.strip", "scorers[].split", "len", "len", "sum", "scorer_interpolator.ScorerInterpolator._scorers.append", "scorer_interpolator.ScorerInterpolator._weights.append", "instruction.strip", "float", "sp.ScorerProvider().get", "SyntaxError", "weights.split", "sp.ScorerProvider"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get"], ["def", "__init__", "(", "self", ",", "config_string", ")", ":", "\n", "        ", "\"\"\"\n        @param config_string example:\n        `INTERPOLATE w=0.5,0.5; SENTENCEBLEU n=4; METEOR meteor_language=fr, meteor_path=/foo/bar/meteor`\n        \"\"\"", "\n", "self", ".", "_scorers", "=", "[", "]", "\n", "self", ".", "_weights", "=", "[", "]", "\n", "# parse arguments", "\n", "scorers", "=", "config_string", ".", "split", "(", "\";\"", ")", "\n", "scorers", "=", "[", "scorer", ".", "strip", "(", ")", "for", "scorer", "in", "scorers", "]", "\n", "try", ":", "\n", "            ", "instruction", ",", "weights", "=", "scorers", "[", "0", "]", ".", "split", "(", "\"w=\"", ")", "\n", "assert", "instruction", ".", "strip", "(", ")", "==", "\"INTERPOLATE\"", "\n", "weights", "=", "[", "float", "(", "w", ")", "for", "w", "in", "weights", ".", "split", "(", "','", ")", "]", "\n", "scorers", "=", "[", "sp", ".", "ScorerProvider", "(", ")", ".", "get", "(", "s", ")", "for", "s", "in", "scorers", "[", "1", ":", "]", "]", "\n", "", "except", ":", "\n", "            ", "raise", "SyntaxError", "(", "\"Ill-formated interpolation of metrics. Example of valid definition: `INTERPOLATE w=0.5,0.5`.\"", ")", "\n", "# assertions", "\n", "", "assert", "len", "(", "weights", ")", "==", "len", "(", "scorers", ")", "\n", "assert", "sum", "(", "weights", ")", "==", "1.0", "\n", "# init scorers", "\n", "for", "i", ",", "scorer", "in", "enumerate", "(", "scorers", ")", ":", "\n", "            ", "self", ".", "_scorers", ".", "append", "(", "scorer", ")", "\n", "self", ".", "_weights", ".", "append", "(", "weights", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_interpolator.ScorerInterpolator.set_reference": [[47, 54], ["scorer.set_reference"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference"], ["", "", "def", "set_reference", "(", "self", ",", "reference_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Sets the reference against which one or many hypotheses can be scored\n        via `self.score()` and `self.score_matrix()`.\n        \"\"\"", "\n", "for", "scorer", "in", "self", ".", "_scorers", ":", "\n", "            ", "scorer", ".", "set_reference", "(", "reference_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_interpolator.ScorerInterpolator.score": [[55, 61], ["sum", "s.score", "zip"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "", "def", "score", "(", "self", ",", "hypothesis_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Scores @param hypothesis with all scorers added via `self.add_scorer`\n        and interpolates the scores with the respective weights.\n        \"\"\"", "\n", "return", "sum", "(", "[", "s", ".", "score", "(", "hypothesis_tokens", ")", "*", "w", "for", "w", ",", "s", "in", "zip", "(", "self", ".", "_weights", ",", "self", ".", "_scorers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_interpolator.ScorerInterpolator.score_matrix": [[62, 69], ["sum", "s.score_matrix", "zip"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer.Scorer.score_matrix"], ["", "def", "score_matrix", "(", "self", ",", "hypothesis_matrix", ")", ":", "\n", "        ", "\"\"\"\n        Scores every hypothesis in @param hypotheses with all scorers added via\n        `self.add_scorer` and interpolates the scores with the respective\n        weights.\n        \"\"\"", "\n", "return", "sum", "(", "[", "s", ".", "score_matrix", "(", "hypothesis_matrix", ")", "*", "w", "for", "w", ",", "s", "in", "zip", "(", "self", ".", "_weights", ",", "self", ".", "_scorers", ")", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuScorer.__init__": [[25, 33], ["Scorer.__init__", "list", "sentence_bleu.SentenceBleuScorer._arguments.keys"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__"], ["def", "__init__", "(", "self", ",", "argument_string", ")", ":", "\n", "        ", "\"\"\"\n        Initialises metric-specific parameters.\n        \"\"\"", "\n", "Scorer", ".", "__init__", "(", "self", ",", "argument_string", ")", "\n", "# use n-gram order of 4 by default", "\n", "if", "not", "'n'", "in", "list", "(", "self", ".", "_arguments", ".", "keys", "(", ")", ")", ":", "\n", "            ", "self", ".", "_arguments", "[", "'n'", "]", "=", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuScorer.set_reference": [[34, 41], ["sentence_bleu.SentenceBleuReference"], "methods", ["None"], ["", "", "def", "set_reference", "(", "self", ",", "reference_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Sets the reference against hypotheses are scored.\n        \"\"\"", "\n", "self", ".", "_reference", "=", "SentenceBleuReference", "(", "\n", "reference_tokens", ",", "\n", "self", ".", "_arguments", "[", "'n'", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuReference.__init__": [[49, 61], ["Reference.__init__", "len", "sentence_bleu.SentenceBleuReference._get_ngrams"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuReference._get_ngrams"], ["def", "__init__", "(", "self", ",", "reference_tokens", ",", "n", "=", "4", ")", ":", "\n", "        ", "\"\"\"\n        @param reference the reference translation that hypotheses shall be\n                         scored against. Must be an iterable of tokens (any\n                         type).\n        @param n         maximum n-gram order to consider.\n        \"\"\"", "\n", "Reference", ".", "__init__", "(", "self", ",", "reference_tokens", ")", "\n", "self", ".", "n", "=", "n", "\n", "# preprocess reference", "\n", "self", ".", "_reference_length", "=", "len", "(", "self", ".", "_reference_tokens", ")", "\n", "self", ".", "_reference_ngrams", "=", "self", ".", "_get_ngrams", "(", "self", ".", "_reference_tokens", ",", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuReference._get_ngrams": [[62, 73], ["range", "n_grams.append", "zip", "collections.defaultdict", "range"], "methods", ["None"], ["", "def", "_get_ngrams", "(", "self", ",", "tokens", ",", "max_n", ")", ":", "\n", "        ", "\"\"\"\n        Extracts all n-grams of order 1 up to (and including) @param max_n from\n        a list of @param tokens.\n        \"\"\"", "\n", "n_grams", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "1", ",", "max_n", "+", "1", ")", ":", "\n", "            ", "n_grams", ".", "append", "(", "defaultdict", "(", "int", ")", ")", "\n", "for", "n_gram", "in", "zip", "(", "*", "[", "tokens", "[", "i", ":", "]", "for", "i", "in", "range", "(", "n", ")", "]", ")", ":", "\n", "                ", "n_grams", "[", "n", "-", "1", "]", "[", "n_gram", "]", "+=", "1", "\n", "", "", "return", "n_grams", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuReference.score": [[74, 108], ["len", "sentence_bleu.SentenceBleuReference._get_ngrams", "sentence_bleu.SentenceBleuReference.score.ngram_precisions"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.sentence_bleu.SentenceBleuReference._get_ngrams"], ["", "def", "score", "(", "self", ",", "hypothesis_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Scores @param hypothesis against this reference.\n\n        @return the smoothed sentence-level BLEU score: 1.0 is best, 0.0 worst.\n        \"\"\"", "\n", "def", "product", "(", "iterable", ")", ":", "\n", "            ", "return", "reduce", "(", "mul", ",", "iterable", ",", "1", ")", "\n", "", "def", "ngram_precisions", "(", "ref_ngrams", ",", "hyp_ngrams", ")", ":", "\n", "            ", "precisions", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "1", ",", "self", ".", "n", "+", "1", ")", ":", "\n", "                ", "overlap", "=", "0", "\n", "for", "ref_ngram", ",", "ref_ngram_count", "in", "list", "(", "ref_ngrams", "[", "n", "-", "1", "]", ".", "items", "(", ")", ")", ":", "\n", "                    ", "if", "ref_ngram", "in", "hyp_ngrams", "[", "n", "-", "1", "]", ":", "\n", "                        ", "overlap", "+=", "min", "(", "ref_ngram_count", ",", "hyp_ngrams", "[", "n", "-", "1", "]", "[", "ref_ngram", "]", ")", "\n", "", "", "hyp_length", "=", "max", "(", "0", ",", "len", "(", "hypothesis_tokens", ")", "-", "n", "+", "1", ")", "\n", "if", "n", ">=", "2", ":", "\n", "# smoothing as proposed by Lin and Och (2004),", "\n", "# implemented as described in (Chen and Cherry, 2014)", "\n", "                    ", "overlap", "+=", "1", "\n", "hyp_length", "+=", "1", "\n", "", "precisions", ".", "append", "(", "overlap", "/", "hyp_length", "if", "hyp_length", ">", "0", "else", "0.0", ")", "\n", "", "return", "precisions", "\n", "", "def", "brevity_penalty", "(", "ref_length", ",", "hyp_length", ")", ":", "\n", "            ", "return", "min", "(", "1.0", ",", "exp", "(", "1", "-", "(", "ref_length", "/", "hyp_length", "if", "hyp_length", ">", "0", "else", "0.0", ")", ")", ")", "\n", "# preprocess hypothesis", "\n", "", "hypothesis_length", "=", "len", "(", "hypothesis_tokens", ")", "\n", "hypothesis_ngrams", "=", "self", ".", "_get_ngrams", "(", "hypothesis_tokens", ",", "self", ".", "n", ")", "\n", "# calculate n-gram precision for all orders", "\n", "np", "=", "ngram_precisions", "(", "self", ".", "_reference_ngrams", ",", "hypothesis_ngrams", ")", "\n", "# calculate brevity penalty", "\n", "bp", "=", "brevity_penalty", "(", "self", ".", "_reference_length", ",", "hypothesis_length", ")", "\n", "# compose final BLEU score", "\n", "return", "product", "(", "np", ")", "**", "(", "1", "/", "self", ".", "n", ")", "*", "bp", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_sentence_bleu.TestSentenceBleuReference.tokenize": [[11, 14], ["sentence.split"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "tokenize", "(", "sentence", ")", ":", "\n", "        ", "return", "sentence", ".", "split", "(", "\" \"", ")", "\n", "", "def", "test_identical_segments", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_sentence_bleu.TestSentenceBleuReference.test_identical_segments": [[14, 19], ["test_sentence_bleu.TestSentenceBleuReference.tokenize", "metrics.sentence_bleu.SentenceBleuScorer", "metrics.sentence_bleu.SentenceBleuScorer.set_reference", "test_sentence_bleu.TestSentenceBleuReference.assertEqual", "metrics.sentence_bleu.SentenceBleuScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_identical_segments", "(", "self", ")", ":", "\n", "        ", "segment", "=", "self", ".", "tokenize", "(", "\"Consistency is the last refuge of the unimaginative\"", ")", "\n", "scorer", "=", "SentenceBleuScorer", "(", "'n=4'", ")", "\n", "scorer", ".", "set_reference", "(", "segment", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment", ")", ",", "1.0", ")", "\n", "", "def", "test_completely_different_segments", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_sentence_bleu.TestSentenceBleuReference.test_completely_different_segments": [[19, 25], ["test_sentence_bleu.TestSentenceBleuReference.tokenize", "test_sentence_bleu.TestSentenceBleuReference.tokenize", "metrics.sentence_bleu.SentenceBleuScorer", "metrics.sentence_bleu.SentenceBleuScorer.set_reference", "test_sentence_bleu.TestSentenceBleuReference.assertEqual", "metrics.sentence_bleu.SentenceBleuScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_completely_different_segments", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"A A A\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\"B B B\"", ")", "\n", "scorer", "=", "SentenceBleuScorer", "(", "'n=4'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment_b", ")", ",", "0.0", ")", "\n", "", "def", "test_clipping", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_sentence_bleu.TestSentenceBleuReference.test_clipping": [[25, 31], ["test_sentence_bleu.TestSentenceBleuReference.tokenize", "test_sentence_bleu.TestSentenceBleuReference.tokenize", "metrics.sentence_bleu.SentenceBleuScorer", "metrics.sentence_bleu.SentenceBleuScorer.set_reference", "test_sentence_bleu.TestSentenceBleuReference.assertNotEqual", "metrics.sentence_bleu.SentenceBleuScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_clipping", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"The very nice man\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\"man man man man\"", ")", "\n", "scorer", "=", "SentenceBleuScorer", "(", "'n=1'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertNotEqual", "(", "scorer", ".", "score", "(", "segment_b", ")", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.reference.Reference.__init__": [[12, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "reference_tokens", ")", ":", "\n", "        ", "\"\"\"\n        @param reference the reference translation that hypotheses shall be\n                         scored against.\n        \"\"\"", "\n", "self", ".", "_reference_tokens", "=", "reference_tokens", "\n", "#additional (metric-specific) parameters to be defined in subclass", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.reference.Reference.score": [[20, 26], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "score", "(", "self", ",", "hypothesis_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Scores @param hypothesis against this reference.\n        \"\"\"", "\n", "pass", "#to be implemented in sublcass", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.reference.Reference.score_matrix": [[27, 33], ["reference.Reference.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "score_matrix", "(", "self", ",", "hypothesis_matrix", ")", ":", "\n", "        ", "\"\"\"\n        Scores every hypothesis in @param hypotheses against this reference.\n        @param hypothesis_matrix an iterable of iterables of tokens.\n        \"\"\"", "\n", "return", "[", "self", ".", "score", "(", "hypothesis_tokens", ")", "for", "hypothesis_tokens", "in", "hypothesis_matrix", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.__init__": [[29, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer_provider.ScorerProvider.get": [[32, 66], ["config_string.startswith", "si.ScorerInterpolator", "config_string.split", "SentenceBleuScorer", "MeteorScorer", "BeerScorer", "CharacterFScorer", "NotImplementedError"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "config_string", ")", ":", "\n", "        ", "\"\"\"\n        Returns a scorer matching the metric and parameters defined in @param\n        config string.\n\n        Example: ScorerProvider.get(\"BLEU n=4\") returns a SmoothedBleuScorer\n                 object that considers n-gram precision up to n=4.\n\n        If more than one metrics are provided (separated by `;`),\n        an interpolated scorer will be returned.\n\n        Example: ScorerProvider.get(\"INTERPOLATE w=0.5,0.5; SENTENCEBLEU n=4; METEOR meteor_language=fr, meteor_path=/foo/bar/meteor\")\n                 returns an InterpolatedScorer object that scores hypotheses\n                 using 0.5 * bleu_score + 0.5 * meteor_score.\n        \"\"\"", "\n", "# interpolation", "\n", "if", "config_string", ".", "startswith", "(", "\"INTERPOLATE\"", ")", ":", "\n", "            ", "return", "si", ".", "ScorerInterpolator", "(", "config_string", ")", "\n", "", "try", ":", "\n", "            ", "scorer", ",", "arguments", "=", "config_string", ".", "split", "(", "\" \"", ",", "1", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "scorer", "=", "config_string", "\n", "arguments", "=", "''", "\n", "", "if", "scorer", "==", "'SENTENCEBLEU'", ":", "\n", "            ", "return", "SentenceBleuScorer", "(", "arguments", ")", "\n", "", "elif", "scorer", "==", "'METEOR'", ":", "\n", "            ", "return", "MeteorScorer", "(", "arguments", ")", "\n", "", "elif", "scorer", "==", "'BEER'", ":", "\n", "            ", "return", "BeerScorer", "(", "arguments", ")", "\n", "", "elif", "scorer", "==", "'CHRF'", ":", "\n", "            ", "return", "CharacterFScorer", "(", "arguments", ")", "\n", "# add other scorers here", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"No such scorer: %s\"", "%", "scorer", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.beer.BeerError.__init__": [[19, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "value", "=", "value", "\n", "", "def", "__str__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.beer.BeerError.__str__": [[21, 23], ["repr"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "repr", "(", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.beer.BeerScorer.__init__": [[30, 43], ["Scorer.__init__", "threading.Lock", "subprocess.Popen"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__"], ["def", "__init__", "(", "self", ",", "argument_string", ")", ":", "\n", "        ", "Scorer", ".", "__init__", "(", "self", ",", "argument_string", ")", "\n", "\n", "#Lock for the BEER process, which can only handle one request at a time:", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n", "#Get necessary arguments for starting BEER from argument string parsed in Scorer.__init__()", "\n", "self", ".", "_beer_language", "=", "self", ".", "_arguments", "[", "\"beer_language\"", "]", "\n", "self", ".", "_beer_path", "=", "self", ".", "_arguments", "[", "\"beer_path\"", "]", "+", "\"/\"", "\n", "\n", "#Start a BEER process:", "\n", "command", "=", "self", ".", "_beer_path", "+", "\"beer -l \"", "+", "self", ".", "_beer_language", "+", "\" --workingMode interactive \"", "\n", "self", ".", "beer_process", "=", "subprocess", ".", "Popen", "(", "command", ",", "stdin", "=", "subprocess", ".", "PIPE", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ",", "shell", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.beer.BeerScorer.set_reference": [[44, 52], ["beer.BeerScorer.lock.acquire", "beer.BeerReference", "beer.BeerScorer.lock.release"], "methods", ["None"], ["", "def", "set_reference", "(", "self", ",", "reference_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Construct a BeerReference from a sequence of tokens and make it the reference against which the scorer evaluates hypotheses.\n        This can be done any time.\n        \"\"\"", "\n", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "self", ".", "_reference", "=", "BeerReference", "(", "reference_tokens", ",", "self", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.beer.BeerScorer.terminate_process": [[53, 60], ["beer.BeerScorer.lock.acquire", "beer.BeerScorer.beer_process.terminate", "beer.BeerScorer.lock.release"], "methods", ["None"], ["", "def", "terminate_process", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Waits for the current request to be processed and terminates the BEER process.\n        \"\"\"", "\n", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "self", ".", "beer_process", ".", "terminate", "(", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.beer.BeerScorer.kill_process": [[61, 66], ["beer.BeerScorer.beer_process.kill"], "methods", ["None"], ["", "def", "kill_process", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Kills the BEER process right away.\n        \"\"\"", "\n", "self", ".", "beer_process", ".", "kill", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.beer.BeerReference.__init__": [[71, 77], ["Reference.__init__"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__"], ["def", "__init__", "(", "self", ",", "reference_tokens", ",", "beer_scorer", ")", ":", "\n", "        ", "Reference", ".", "__init__", "(", "self", ",", "reference_tokens", ")", "\n", "\n", "#Construct reference string from tokens", "\n", "self", ".", "_reference_string", "=", "\" \"", ".", "join", "(", "reference_tokens", ")", "\n", "self", ".", "_beer_scorer", "=", "beer_scorer", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.beer.BeerReference.score": [[78, 104], ["beer.BeerReference._beer_scorer.lock.acquire", "beer.BeerReference._beer_scorer.beer_process.stdout.readline", "beer.BeerReference._beer_scorer.lock.release", "beer.BeerReference._beer_scorer.beer_process.stdin.write", "float", "beer.BeerError", "beer.BeerError", "beer.BeerReference._beer_scorer.beer_process.stderr.readline().strip", "beer.BeerReference._beer_scorer.beer_process.stderr.readline().strip", "beer.BeerReference._beer_scorer.beer_process.stderr.readline", "beer.BeerReference._beer_scorer.beer_process.stderr.readline"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline"], ["", "def", "score", "(", "self", ",", "hypothesis_tokens", ")", ":", "\n", "\n", "#Construct hypothesis string from hypothesis tokens:", "\n", "        ", "hypothesis_string", "=", "\" \"", ".", "join", "(", "hypothesis_tokens", ")", "\n", "\n", "#Acquire lock to make sure BEER process is not in use:", "\n", "self", ".", "_beer_scorer", ".", "lock", ".", "acquire", "(", ")", "\n", "\n", "#Score hypothesis string against reference string", "\n", "try", ":", "\n", "            ", "self", ".", "_beer_scorer", ".", "beer_process", ".", "stdin", ".", "write", "(", "\"EVAL ||| \"", "+", "hypothesis_string", "+", "\" ||| \"", "+", "self", ".", "_reference_string", "+", "\"\\n\"", ")", "\n", "", "except", ":", "\n", "            ", "raise", "BeerError", "(", "\"Beer returned the following error: \"", "+", "self", ".", "_beer_scorer", ".", "beer_process", ".", "stderr", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "#Read feature values from process output", "\n", "", "std_out", "=", "self", ".", "_beer_scorer", ".", "beer_process", ".", "stdout", ".", "readline", "(", ")", "\n", "#Release the process lock", "\n", "self", ".", "_beer_scorer", ".", "lock", ".", "release", "(", ")", "\n", "\n", "#Check if BEER returned a score:", "\n", "try", ":", "\n", "            ", "n", "=", "float", "(", "std_out", ")", "\n", "", "except", ":", "\n", "            ", "raise", "BeerError", "(", "\"Beer returned the following error: \"", "+", "self", ".", "_beer_scorer", ".", "beer_process", ".", "stderr", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "#Return final score", "\n", "", "return", "n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize": [[11, 14], ["sentence.split"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "tokenize", "(", "sentence", ")", ":", "\n", "        ", "return", "sentence", ".", "split", "(", "\" \"", ")", "\n", "", "def", "test_identical_segments", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.test_identical_segments": [[14, 19], ["test_chrf.TestCharacterFScoreReference.tokenize", "metrics.chrf.CharacterFScorer", "metrics.chrf.CharacterFScorer.set_reference", "test_chrf.TestCharacterFScoreReference.assertEqual", "metrics.chrf.CharacterFScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_identical_segments", "(", "self", ")", ":", "\n", "        ", "segment", "=", "self", ".", "tokenize", "(", "\"Consistency is the last refuge of the unimaginative\"", ")", "\n", "scorer", "=", "CharacterFScorer", "(", "'n=6,beta=3'", ")", "\n", "scorer", ".", "set_reference", "(", "segment", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment", ")", ",", "1.0", ")", "\n", "", "def", "test_completely_different_segments", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.test_completely_different_segments": [[19, 25], ["test_chrf.TestCharacterFScoreReference.tokenize", "test_chrf.TestCharacterFScoreReference.tokenize", "metrics.chrf.CharacterFScorer", "metrics.chrf.CharacterFScorer.set_reference", "test_chrf.TestCharacterFScoreReference.assertEqual", "metrics.chrf.CharacterFScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_completely_different_segments", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"AAAAAA\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\"BBBB\"", ")", "\n", "scorer", "=", "CharacterFScorer", "(", "'n=3,beta=3'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment_b", ")", ",", "0.0", ")", "\n", "", "def", "test_empty_string", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.test_empty_string": [[25, 31], ["test_chrf.TestCharacterFScoreReference.tokenize", "test_chrf.TestCharacterFScoreReference.tokenize", "metrics.chrf.CharacterFScorer", "metrics.chrf.CharacterFScorer.set_reference", "test_chrf.TestCharacterFScoreReference.assertEqual", "metrics.chrf.CharacterFScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_empty_string", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\"\"", ")", "\n", "scorer", "=", "CharacterFScorer", "(", "'n=6,beta=3'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment_b", ")", ",", "1.0", ")", "\n", "", "def", "test_one_character_empty_string", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.test_one_character_empty_string": [[31, 37], ["test_chrf.TestCharacterFScoreReference.tokenize", "test_chrf.TestCharacterFScoreReference.tokenize", "metrics.chrf.CharacterFScorer", "metrics.chrf.CharacterFScorer.set_reference", "test_chrf.TestCharacterFScoreReference.assertEqual", "metrics.chrf.CharacterFScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_one_character_empty_string", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"A\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\"\"", ")", "\n", "scorer", "=", "CharacterFScorer", "(", "'n=6,beta=3'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment_b", ")", ",", "0.0", ")", "\n", "", "def", "test_empty_string_one_character", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.test_empty_string_one_character": [[37, 43], ["test_chrf.TestCharacterFScoreReference.tokenize", "test_chrf.TestCharacterFScoreReference.tokenize", "metrics.chrf.CharacterFScorer", "metrics.chrf.CharacterFScorer.set_reference", "test_chrf.TestCharacterFScoreReference.assertEqual", "metrics.chrf.CharacterFScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_empty_string_one_character", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\"A\"", ")", "\n", "scorer", "=", "CharacterFScorer", "(", "'n=6,beta=3'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment_b", ")", ",", "0.0", ")", "\n", "", "def", "test_half_right", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.test_half_right": [[43, 49], ["test_chrf.TestCharacterFScoreReference.tokenize", "test_chrf.TestCharacterFScoreReference.tokenize", "metrics.chrf.CharacterFScorer", "metrics.chrf.CharacterFScorer.set_reference", "test_chrf.TestCharacterFScoreReference.assertEqual", "metrics.chrf.CharacterFScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_half_right", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"AB\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\"AA\"", ")", "\n", "scorer", "=", "CharacterFScorer", "(", "'n=6,beta=3'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment_b", ")", ",", "0.25", ")", "\n", "", "def", "test_one_character", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.test_one_character": [[49, 55], ["test_chrf.TestCharacterFScoreReference.tokenize", "test_chrf.TestCharacterFScoreReference.tokenize", "metrics.chrf.CharacterFScorer", "metrics.chrf.CharacterFScorer.set_reference", "test_chrf.TestCharacterFScoreReference.assertEqual", "metrics.chrf.CharacterFScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_one_character", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"A\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\"A\"", ")", "\n", "scorer", "=", "CharacterFScorer", "(", "'n=6,beta=3'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertEqual", "(", "scorer", ".", "score", "(", "segment_b", ")", ",", "1.0", ")", "\n", "", "def", "test_almost_correct", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.test_almost_correct": [[55, 61], ["test_chrf.TestCharacterFScoreReference.tokenize", "test_chrf.TestCharacterFScoreReference.tokenize", "metrics.chrf.CharacterFScorer", "metrics.chrf.CharacterFScorer.set_reference", "test_chrf.TestCharacterFScoreReference.assertEqual", "metrics.chrf.CharacterFScorer.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.test_chrf.TestCharacterFScoreReference.tokenize", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "test_almost_correct", "(", "self", ")", ":", "\n", "        ", "segment_a", "=", "self", ".", "tokenize", "(", "\"risk assessment has to be undertaken by those who are qualified and expert in that area - that is the scientists .\"", ")", "\n", "segment_b", "=", "self", ".", "tokenize", "(", "\" risk assessment must be made of those who are qualified and expertise in the sector - these are the scientists .\"", ")", "\n", "scorer", "=", "CharacterFScorer", "(", "'n=6,beta=3'", ")", "\n", "scorer", ".", "set_reference", "(", "segment_a", ")", "\n", "self", ".", "assertEqual", "(", "'{0:.12f}'", ".", "format", "(", "scorer", ".", "score", "(", "segment_b", ")", ")", ",", "\"0.652414427449\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer.Scorer.__init__": [[11, 30], ["argument_string.split", "a.split", "argument.strip.strip.strip", "int.strip", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "argument_string", ")", ":", "\n", "        ", "\"\"\"\n        @param argument_string the metric-specific parameters (such as n-gram\n        order for BLEU, language for METEOR, etc.)\n        \"\"\"", "\n", "# parse arguments", "\n", "self", ".", "_reference", "=", "None", "# to be set via `self.set_reference()`", "\n", "self", ".", "_arguments", "=", "{", "}", "\n", "if", "argument_string", ":", "\n", "            ", "argument_strings", "=", "argument_string", ".", "split", "(", "\",\"", ")", "\n", "for", "a", "in", "argument_strings", ":", "\n", "                ", "argument", ",", "value", "=", "a", ".", "split", "(", "\"=\"", ")", "\n", "argument", "=", "argument", ".", "strip", "(", ")", "\n", "value", "=", "value", ".", "strip", "(", ")", "\n", "try", ":", "\n", "                    ", "value", "=", "int", "(", "value", ")", "# change type to int if applicable", "\n", "", "except", "ValueError", ":", "\n", "                    ", "value", "=", "value", "\n", "", "self", ".", "_arguments", "[", "argument", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer.Scorer.set_reference": [[31, 38], ["None"], "methods", ["None"], ["", "", "", "@", "abstractmethod", "\n", "def", "set_reference", "(", "self", ",", "reference_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Sets the reference against which one or many hypotheses can be scored\n        via `self.score()` and `self.score_matrix()`.\n        \"\"\"", "\n", "pass", "# instantiate a Reference object and store it at self._reference", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer.Scorer.score": [[39, 44], ["scorer.Scorer._reference.score"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score"], ["", "def", "score", "(", "self", ",", "hypothesis_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Scores @param hypothesis against this reference.\n        \"\"\"", "\n", "return", "self", ".", "_reference", ".", "score", "(", "hypothesis_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer.Scorer.score_matrix": [[45, 51], ["scorer.Scorer._reference.score_matrix"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.scorer.Scorer.score_matrix"], ["", "def", "score_matrix", "(", "self", ",", "hypothesis_matrix", ")", ":", "\n", "        ", "\"\"\"\n        Scores every hypothesis in @param hypotheses against this reference.\n        @param hypothesis_matrix an iterable of iterables of tokens.\n        \"\"\"", "\n", "return", "self", ".", "_reference", ".", "score_matrix", "(", "hypothesis_matrix", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorError.__init__": [[18, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "value", "=", "value", "\n", "", "def", "__str__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorError.__str__": [[20, 22], ["repr"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "repr", "(", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.__init__": [[29, 42], ["Scorer.__init__", "threading.Lock", "subprocess.Popen"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__"], ["def", "__init__", "(", "self", ",", "argument_string", ")", ":", "\n", "        ", "Scorer", ".", "__init__", "(", "self", ",", "argument_string", ")", "\n", "\n", "#Lock for the METEOR process, which can only handle one request at a time:", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n", "#Get necessary arguments for starting METEOR from argument string parsed in Scorer.__init__()", "\n", "self", ".", "_meteor_language", "=", "self", ".", "_arguments", "[", "\"meteor_language\"", "]", "\n", "self", ".", "_meteor_path", "=", "self", ".", "_arguments", "[", "\"meteor_path\"", "]", "+", "\"/\"", "\n", "\n", "#Start a METEOR process:", "\n", "command", "=", "\"java -Xmx2G -jar \"", "+", "self", ".", "_meteor_path", "+", "\"meteor-*.jar - - -l \"", "+", "self", ".", "_meteor_language", "+", "\" -stdio\"", "\n", "self", ".", "meteor_process", "=", "subprocess", ".", "Popen", "(", "command", ",", "stdin", "=", "subprocess", ".", "PIPE", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ",", "shell", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.set_reference": [[43, 51], ["meteor.MeteorScorer.lock.acquire", "meteor.MeteorReference", "meteor.MeteorScorer.lock.release"], "methods", ["None"], ["", "def", "set_reference", "(", "self", ",", "reference_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Construct a MeteorReference from a sequence of tokens and make it the reference against which the scorer evaluates hypotheses.\n        This can be done any time.\n        \"\"\"", "\n", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "self", ".", "_reference", "=", "MeteorReference", "(", "reference_tokens", ",", "self", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.terminate_process": [[52, 59], ["meteor.MeteorScorer.lock.acquire", "meteor.MeteorScorer.meteor_process.terminate", "meteor.MeteorScorer.lock.release"], "methods", ["None"], ["", "def", "terminate_process", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Waits for the current request to be processed and terminates the METEOR process.\n        \"\"\"", "\n", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "self", ".", "meteor_process", ".", "terminate", "(", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorScorer.kill_process": [[60, 65], ["meteor.MeteorScorer.meteor_process.kill"], "methods", ["None"], ["", "def", "kill_process", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Kills the METEOR process right away.\n        \"\"\"", "\n", "self", ".", "meteor_process", ".", "kill", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__": [[70, 76], ["Reference.__init__"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.__init__"], ["def", "__init__", "(", "self", ",", "reference_tokens", ",", "meteor_scorer", ")", ":", "\n", "        ", "Reference", ".", "__init__", "(", "self", ",", "reference_tokens", ")", "\n", "\n", "#Construct reference string from tokens", "\n", "self", ".", "_reference_string", "=", "\" \"", ".", "join", "(", "reference_tokens", ")", "\n", "self", ".", "_meteor_scorer", "=", "meteor_scorer", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.metrics.meteor.MeteorReference.score": [[77, 112], ["meteor.MeteorReference._meteor_scorer.lock.acquire", "meteor.MeteorReference._meteor_scorer.meteor_process.stdout.readline", "meteor.MeteorReference._meteor_scorer.meteor_process.stdout.readline", "meteor.MeteorReference._meteor_scorer.lock.release", "meteor.MeteorReference._meteor_scorer.meteor_process.stdin.write", "meteor.MeteorReference._meteor_scorer.meteor_process.stdin.write", "float", "meteor.MeteorError", "meteor.MeteorError", "meteor.MeteorError", "meteor.MeteorReference._meteor_scorer.meteor_process.stderr.readline().strip", "meteor.MeteorReference._meteor_scorer.meteor_process.stderr.readline().strip", "meteor.MeteorReference._meteor_scorer.meteor_process.stderr.readline().strip", "meteor.MeteorReference._meteor_scorer.meteor_process.stderr.readline", "meteor.MeteorReference._meteor_scorer.meteor_process.stderr.readline", "meteor.MeteorReference._meteor_scorer.meteor_process.stderr.readline"], "methods", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline", "home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.readline"], ["", "def", "score", "(", "self", ",", "hypothesis_tokens", ")", ":", "\n", "\n", "#Construct hypothesis string from hypothesis tokens:", "\n", "        ", "hypothesis_string", "=", "\" \"", ".", "join", "(", "hypothesis_tokens", ")", "\n", "\n", "#Acquire lock to make sure METEOR process is not in use:", "\n", "self", ".", "_meteor_scorer", ".", "lock", ".", "acquire", "(", ")", "\n", "\n", "#Score hypothesis string against reference string", "\n", "try", ":", "\n", "            ", "self", ".", "_meteor_scorer", ".", "meteor_process", ".", "stdin", ".", "write", "(", "\"SCORE ||| \"", "+", "self", ".", "_reference_string", "+", "\" ||| \"", "+", "hypothesis_string", "+", "\"\\n\"", ")", "\n", "", "except", ":", "\n", "            ", "raise", "MeteorError", "(", "\"Meteor returned the following error: \"", "+", "self", ".", "_meteor_scorer", ".", "meteor_process", ".", "stderr", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "#Read feature values from process output", "\n", "", "std_out", "=", "self", ".", "_meteor_scorer", ".", "meteor_process", ".", "stdout", ".", "readline", "(", ")", "\n", "\n", "#Pass feature values to METEOR process for computation of the final score", "\n", "try", ":", "\n", "            ", "self", ".", "_meteor_scorer", ".", "meteor_process", ".", "stdin", ".", "write", "(", "\"EVAL ||| \"", "+", "std_out", ")", "\n", "", "except", ":", "\n", "            ", "raise", "MeteorError", "(", "\"Meteor returned the following error: \"", "+", "self", ".", "_meteor_scorer", ".", "meteor_process", ".", "stderr", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "std_out", "=", "self", ".", "_meteor_scorer", ".", "meteor_process", ".", "stdout", ".", "readline", "(", ")", "\n", "\n", "#Release the process lock", "\n", "self", ".", "_meteor_scorer", ".", "lock", ".", "release", "(", ")", "\n", "\n", "#Check if Meteor returned a score:", "\n", "try", ":", "\n", "            ", "n", "=", "float", "(", "std_out", ")", "\n", "", "except", ":", "\n", "            ", "raise", "MeteorError", "(", "\"Meteor returned the following error: \"", "+", "self", ".", "_meteor_scorer", ".", "meteor_process", ".", "stderr", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "#Return final score", "\n", "", "return", "n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.shuffle.jointly_shuffle_files": [[13, 53], ["open", "list", "random.shuffle", "range", "shuffle._sort_file"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.shuffle._sort_file"], []], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.shuffle._sort_file": [[55, 105], ["math.ceil", "os.path.split", "enumerate", "open.seek", "os.path.realpath", "tempfile.TemporaryFile", "open", "chunk.append", "shuffle._sort_file._write_chunk_in_order"], "function", ["home.repos.pwc.inspect_result.EdinburghNLP_nematus.nematus.data_iterator.FileWrapper.seek"], []], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.build_dictionary.main": [[11, 43], ["print", "collections.OrderedDict", "list", "list", "numpy.argsort", "collections.OrderedDict", "enumerate", "print", "open", "collections.OrderedDict.keys", "collections.OrderedDict.values", "open", "json.dump", "line.strip().split", "line.strip"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "for", "filename", "in", "sys", ".", "argv", "[", "1", ":", "]", ":", "\n", "        ", "print", "(", "'Processing'", ",", "filename", ")", "\n", "word_freqs", "=", "OrderedDict", "(", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "words_in", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "for", "w", "in", "words_in", ":", "\n", "                    ", "if", "w", "not", "in", "word_freqs", ":", "\n", "                        ", "word_freqs", "[", "w", "]", "=", "0", "\n", "", "word_freqs", "[", "w", "]", "+=", "1", "\n", "", "", "", "words", "=", "list", "(", "word_freqs", ".", "keys", "(", ")", ")", "\n", "freqs", "=", "list", "(", "word_freqs", ".", "values", "(", ")", ")", "\n", "\n", "sorted_idx", "=", "numpy", ".", "argsort", "(", "freqs", ")", "\n", "sorted_words", "=", "[", "words", "[", "ii", "]", "for", "ii", "in", "sorted_idx", "[", ":", ":", "-", "1", "]", "]", "\n", "\n", "worddict", "=", "OrderedDict", "(", ")", "\n", "worddict", "[", "'<EOS>'", "]", "=", "0", "\n", "worddict", "[", "'<GO>'", "]", "=", "1", "\n", "worddict", "[", "'<UNK>'", "]", "=", "2", "\n", "# FIXME We shouldn't assume <EOS>, <GO>, and <UNK> aren't BPE subwords.", "\n", "for", "ii", ",", "ww", "in", "enumerate", "(", "sorted_words", ")", ":", "\n", "            ", "worddict", "[", "ww", "]", "=", "ii", "+", "3", "\n", "\n", "# The JSON RFC requires that JSON text be represented using either", "\n", "# UTF-8, UTF-16, or UTF-32, with UTF-8 being recommended.", "\n", "# We use UTF-8 regardless of the user's locale settings.", "\n", "", "with", "open", "(", "'%s.json'", "%", "filename", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "worddict", ",", "f", ",", "indent", "=", "2", ",", "ensure_ascii", "=", "False", ")", "\n", "\n", "", "print", "(", "'Done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdinburghNLP_nematus.data.strip_sgml.main": [[5, 14], ["l.strip", "re.sub().strip", "print", "len", "re.sub"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "fin", "=", "sys", ".", "stdin", "\n", "fout", "=", "sys", ".", "stdout", "\n", "for", "l", "in", "fin", ":", "\n", "        ", "line", "=", "l", ".", "strip", "(", ")", "\n", "text", "=", "re", ".", "sub", "(", "'<[^<]+>'", ",", "\"\"", ",", "line", ")", ".", "strip", "(", ")", "\n", "if", "len", "(", "text", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "print", "(", "text", ",", "file", "=", "fout", ")", "\n", "\n"]]}