{"home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.frame_level_models.FrameLevelLogisticModel.create_model": [[57, 91], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_input.get_shape().as_list", "tensorflow.tile", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "model_input.get_shape"], "methods", ["None"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a logistic classifier over the average of the\n\n    frame-level features.\n\n    This class is intended to be an example for implementors of frame level\n    models. If you want to train a model over averaged features it is more\n    efficient to average them beforehand rather than on the fly.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n        input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n        frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "\n", "denominators", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "num_frames", ",", "[", "1", ",", "feature_size", "]", ")", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "avg_pooled", "=", "tf", ".", "reduce_sum", "(", "model_input", ",", "axis", "=", "[", "1", "]", ")", "/", "denominators", "\n", "\n", "output", "=", "slim", ".", "fully_connected", "(", "\n", "avg_pooled", ",", "\n", "vocab_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "1e-8", ")", ")", "\n", "return", "{", "\"predictions\"", ":", "output", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.frame_level_models.DbofModel.create_model": [[116, 215], ["tensorflow.cast", "tensorflow.cast", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.reshape", "tensorflow.reshape", "model_utils.FramePooling", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "print", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "print", "model_utils.SampleRandomFrames", "print", "model_utils.SampleRandomSequence", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.random_normal", "tensorflow.random_normal", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.FramePooling", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomSequence"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_frames", ",", "\n", "iterations", "=", "None", ",", "\n", "add_batch_norm", "=", "None", ",", "\n", "sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "dbof_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "dbof_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "dbof_hidden_size", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "FLAGS", ".", "subsample", ":", "\n", "        ", "if", "random_frames", ":", "\n", "          ", "print", "(", "\"##### Using random Frames. #####\"", ")", "\n", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "          ", "print", "(", "\"##### Using random Sequence. #####\"", ")", "\n", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"We do not subsample.\"", ")", "\n", "", "tf", ".", "add_to_collection", "(", "\"input_batch_raw_a\"", ",", "model_input", ")", "\n", "\n", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"input_hist\"", ",", "reshaped_input", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "      ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\n", "\"cluster_weights\"", ",", "[", "feature_size", ",", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "\n", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\n", "\"cluster_biases\"", ",", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_output\"", ",", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "max_frames", ",", "cluster_size", "]", ")", "\n", "activation", "=", "utils", ".", "FramePooling", "(", "activation", ",", "FLAGS", ".", "dbof_pooling_method", ")", "\n", "\n", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\n", "\"hidden1_weights\"", ",", "[", "cluster_size", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "\n", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_weights\"", ",", "hidden1_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "activation", ",", "hidden1_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\n", "\"hidden1_biases\"", ",", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_output\"", ",", "activation", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "vocab_size", "=", "vocab_size", ",", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.frame_level_models.LstmModel.create_model": [[219, 251], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "getattr", "getattr.create_model", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a stack of LSTMs to represent the video.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n        input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n        frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "stacked_lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "lstm_size", ",", "forget_bias", "=", "1.0", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ")", "\n", "\n", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "stacked_lstm", ",", "model_input", ",", "sequence_length", "=", "num_frames", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", "[", "-", "1", "]", ".", "h", ",", "vocab_size", "=", "vocab_size", ",", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.frame_level_models.LstmFixedModel.create_model": [[255, 292], ["tensorflow.cast", "tensorflow.cast", "tensorflow.contrib.cudnn_rnn.CudnnLSTM", "tensorflow.contrib.cudnn_rnn.CudnnLSTM", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.contrib.cudnn_rnn.CudnnLSTM.", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "print", "print", "model_utils.SampleRandomFrames", "print", "model_utils.SampleRandomSequence", "getattr."], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomSequence"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Fixed size LSTm\n    \"\"\"", "\n", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "random_frames", "=", "FLAGS", ".", "sample_random_frames", "\n", "iterations", "=", "FLAGS", ".", "iterations", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "FLAGS", ".", "subsample", ":", "\n", "        ", "if", "random_frames", ":", "\n", "          ", "print", "(", "\"##### Using random Frames. #####\"", ")", "\n", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "          ", "print", "(", "\"##### Using random Sequence. #####\"", ")", "\n", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"We do not subsample.\"", ")", "\n", "\n", "", "lstm", "=", "tf", ".", "contrib", ".", "cudnn_rnn", ".", "CudnnLSTM", "(", "\n", "num_layers", "=", "number_of_layers", ",", "\n", "num_units", "=", "lstm_size", ",", "\n", "direction", "=", "\"bidirectional\"", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "# lstm.build(model_input.get_shape())", "\n", "model_input", "=", "tf", ".", "transpose", "(", "model_input", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "outputs", ",", "_", "=", "lstm", "(", "model_input", ")", "\n", "outputs", "=", "tf", ".", "reduce_mean", "(", "outputs", ",", "axis", "=", "0", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "outputs", ",", "vocab_size", "=", "vocab_size", ",", "**", "unused_params", ")", "\n", "# lstm_size = FLAGS.lstm_cells", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.__init__": [[63, 81], ["ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "top_n", "=", "None", ")", ":", "\n", "    ", "\"\"\"Construct an AveragePrecisionCalculator to calculate average precision.\n\n    This class is used to calculate the average precision for a single label.\n\n    Args:\n      top_n: A positive Integer specifying the average precision at n, or None\n        to use all provided data points.\n\n    Raises:\n      ValueError: An error occurred when the top_n is not a positive integer.\n    \"\"\"", "\n", "if", "not", "(", "(", "isinstance", "(", "top_n", ",", "int", ")", "and", "top_n", ">=", "0", ")", "or", "top_n", "is", "None", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"top_n must be a positive integer or None.\"", ")", "\n", "\n", "", "self", ".", "_top_n", "=", "top_n", "# average precision at n", "\n", "self", ".", "_total_positives", "=", "0", "# total number of positives have seen", "\n", "self", ".", "_heap", "=", "[", "]", "# max heap of (prediction, actual)", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.heap_size": [[82, 86], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "heap_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the heap size maintained in the class.\"\"\"", "\n", "return", "len", "(", "self", ".", "_heap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.num_accumulated_positives": [[87, 91], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_accumulated_positives", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the number of positive samples that have been accumulated.\"\"\"", "\n", "return", "self", ".", "_total_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.accumulate": [[92, 134], ["range", "len", "len", "ValueError", "numpy.size", "numpy.size", "ValueError", "numpy.where", "heapq.heappush", "isinstance", "len", "heapq.heappop", "heapq.heappush", "numpy.array"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    After the function call, we may call peek_ap_at_n to actually calculate\n    the average precision.\n    Note predictions and actuals must have the same shape.\n\n    Args:\n      predictions: a list storing the prediction scores.\n      actuals: a list storing the ground truth labels. Any value larger than 0\n        will be treated as positives, otherwise as negatives. num_positives = If\n        the 'predictions' and 'actuals' inputs aren't complete, then it's\n        possible some true positives were missed in them. In that case, you can\n        provide 'num_positives' in order to accurately track recall.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "num_positives", "is", "not", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "num_positives", ",", "numbers", ".", "Number", ")", "or", "num_positives", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"'num_positives' was provided but it was a negative number.\"", ")", "\n", "\n", "", "", "if", "num_positives", "is", "not", "None", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "num_positives", "\n", "", "else", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "numpy", ".", "size", "(", "\n", "numpy", ".", "where", "(", "numpy", ".", "array", "(", "actuals", ")", ">", "1e-5", ")", ")", "\n", "", "topk", "=", "self", ".", "_top_n", "\n", "heap", "=", "self", ".", "_heap", "\n", "\n", "for", "i", "in", "range", "(", "numpy", ".", "size", "(", "predictions", ")", ")", ":", "\n", "      ", "if", "topk", "is", "None", "or", "len", "(", "heap", ")", "<", "topk", ":", "\n", "        ", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "predictions", "[", "i", "]", ">", "heap", "[", "0", "]", "[", "0", "]", ":", "# heap[0] is the smallest", "\n", "          ", "heapq", ".", "heappop", "(", "heap", ")", "\n", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.clear": [[135, 139], ["None"], "methods", ["None"], ["", "", "", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the accumulated predictions.\"\"\"", "\n", "self", ".", "_heap", "=", "[", "]", "\n", "self", ".", "_total_positives", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n": [[140, 158], ["numpy.array", "average_precision_calculator.AveragePrecisionCalculator.ap_at_n", "list", "zip"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "def", "peek_ap_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated average precision at n.\n\n    Returns:\n      The non-interpolated average precision at n (default 0).\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n    \"\"\"", "\n", "if", "self", ".", "heap_size", "<=", "0", ":", "\n", "      ", "return", "0", "\n", "", "predlists", "=", "numpy", ".", "array", "(", "list", "(", "zip", "(", "*", "self", ".", "_heap", ")", ")", ")", "\n", "\n", "ap", "=", "self", ".", "ap_at_n", "(", "\n", "predlists", "[", "0", "]", ",", "\n", "predlists", "[", "1", "]", ",", "\n", "n", "=", "self", ".", "_top_n", ",", "\n", "total_num_positives", "=", "self", ".", "_total_positives", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.ap": [[159, 178], ["average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "@", "staticmethod", "\n", "def", "ap", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n        larger than 0 will be treated as positives, otherwise as negatives.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "return", "AveragePrecisionCalculator", ".", "ap_at_n", "(", "predictions", ",", "actuals", ",", "n", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.ap_at_n": [[179, 243], ["numpy.array", "numpy.array", "average_precision_calculator.AveragePrecisionCalculator._shuffle", "sorted", "len", "range", "len", "len", "ValueError", "range", "numpy.size", "min", "min", "ValueError", "len", "numpy.where", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator._shuffle"], ["", "@", "staticmethod", "\n", "def", "ap_at_n", "(", "predictions", ",", "actuals", ",", "n", "=", "20", ",", "total_num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n        larger than 0 will be treated as positives, otherwise as negatives.\n      n: the top n items to be considered in ap@n.\n      total_num_positives : (optionally) you can specify the number of total\n        positive in the list. If specified, it will be used in calculation.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when\n      1) the format of the input is not the numpy 1-D array;\n      2) the shape of predictions and actuals does not match;\n      3) the input n is not a positive integer.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "n", ",", "int", ")", "or", "n", "<=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"n must be 'None' or a positive integer.\"", "\n", "\" It was '%s'.\"", "%", "n", ")", "\n", "\n", "", "", "ap", "=", "0.0", "\n", "\n", "predictions", "=", "numpy", ".", "array", "(", "predictions", ")", "\n", "actuals", "=", "numpy", ".", "array", "(", "actuals", ")", "\n", "\n", "# add a shuffler to avoid overestimating the ap", "\n", "predictions", ",", "actuals", "=", "AveragePrecisionCalculator", ".", "_shuffle", "(", "\n", "predictions", ",", "actuals", ")", "\n", "sortidx", "=", "sorted", "(", "\n", "range", "(", "len", "(", "predictions", ")", ")", ",", "key", "=", "lambda", "k", ":", "predictions", "[", "k", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "if", "total_num_positives", "is", "None", ":", "\n", "      ", "numpos", "=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "else", ":", "\n", "      ", "numpos", "=", "total_num_positives", "\n", "\n", "", "if", "numpos", "==", "0", ":", "\n", "      ", "return", "0", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "numpos", "=", "min", "(", "numpos", ",", "n", ")", "\n", "", "delta_recall", "=", "1.0", "/", "numpos", "\n", "poscount", "=", "0.0", "\n", "\n", "# calculate the ap", "\n", "r", "=", "len", "(", "sortidx", ")", "\n", "if", "n", "is", "not", "None", ":", "\n", "      ", "r", "=", "min", "(", "r", ",", "n", ")", "\n", "", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "      ", "if", "actuals", "[", "sortidx", "[", "i", "]", "]", ">", "0", ":", "\n", "        ", "poscount", "+=", "1", "\n", "ap", "+=", "poscount", "/", "(", "i", "+", "1", ")", "*", "delta_recall", "\n", "", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator._shuffle": [[244, 251], ["random.seed", "random.sample", "range", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_shuffle", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "random", ".", "seed", "(", "0", ")", "\n", "suffidx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "predictions", ")", ")", ",", "len", "(", "predictions", ")", ")", "\n", "predictions", "=", "predictions", "[", "suffidx", "]", "\n", "actuals", "=", "actuals", "[", "suffidx", "]", "\n", "return", "predictions", ",", "actuals", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator._zero_one_normalize": [[252, 272], ["numpy.max", "numpy.min", "numpy.max", "numpy.min"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_zero_one_normalize", "(", "predictions", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"Normalize the predictions to the range between 0.0 and 1.0.\n\n    For some predictions like SVM predictions, we need to normalize them before\n    calculate the interpolated average precision. The normalization will not\n    change the rank in the original list and thus won't change the average\n    precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      epsilon: a small constant to avoid denominator being zero.\n\n    Returns:\n      The normalized prediction.\n    \"\"\"", "\n", "denominator", "=", "numpy", ".", "max", "(", "predictions", ")", "-", "numpy", ".", "min", "(", "predictions", ")", "\n", "ret", "=", "(", "predictions", "-", "numpy", ".", "min", "(", "predictions", ")", ")", "/", "numpy", ".", "max", "(", "\n", "denominator", ",", "epsilon", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.models.BaseModel.create_model": [[20, 22], ["NotImplementedError"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "unused_model_input", ",", "**", "unused_params", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.BaseReader.prepare_reader": [[118, 121], ["NotImplementedError"], "methods", ["None"], ["def", "prepare_reader", "(", "self", ",", "unused_filename_queue", ")", ":", "\n", "    ", "\"\"\"Create a thread for generating prediction and label tensors.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MAggregatedFeatureReader.__init__": [[131, 151], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "# pylint: disable=dangerous-default-value", "\n", "self", ",", "\n", "num_classes", "=", "3862", ",", "\n", "feature_sizes", "=", "[", "1024", ",", "128", "]", ",", "\n", "feature_names", "=", "[", "\"mean_rgb\"", ",", "\"mean_audio\"", "]", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MAggregatedFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "(", "\n", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "\n", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MAggregatedFeatureReader.prepare_reader": [[152, 167], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read_up_to", "tensorflow.add_to_collection", "readers.YT8MAggregatedFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "filename_queue", ",", "batch_size", "=", "1024", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for pre-aggregated YouTube 8M Examples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n      batch_size: batch size used for feature output.\n\n    Returns:\n      A tuple of video indexes, features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_examples", "=", "reader", ".", "read_up_to", "(", "filename_queue", ",", "batch_size", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"serialized_examples\"", ",", "serialized_examples", ")", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MAggregatedFeatureReader.prepare_serialized_examples": [[168, 199], ["len", "range", "tensorflow.parse_example", "tensorflow.sparse_to_indicator", "tensorflow.sparse_to_indicator.set_shape", "tensorflow.concat", "len", "len", "len", "len", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenFeature", "tensorflow.ones", "tensorflow.shape"], "methods", ["None"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_examples", ")", ":", "\n", "    ", "\"\"\"Parse a single video-level TF Example.\"\"\"", "\n", "# set the mapping from the fields to data types in the proto", "\n", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"self.feature_names is empty!\"", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "\n", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "feature_map", "=", "{", "\n", "\"id\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "\n", "}", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_map", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "self", ".", "feature_sizes", "[", "feature_index", "]", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "", "features", "=", "tf", ".", "parse_example", "(", "serialized_examples", ",", "features", "=", "feature_map", ")", "\n", "labels", "=", "tf", ".", "sparse_to_indicator", "(", "features", "[", "\"labels\"", "]", ",", "self", ".", "num_classes", ")", "\n", "labels", ".", "set_shape", "(", "[", "None", ",", "self", ".", "num_classes", "]", ")", "\n", "concatenated_features", "=", "tf", ".", "concat", "(", "\n", "[", "features", "[", "feature_name", "]", "for", "feature_name", "in", "self", ".", "feature_names", "]", ",", "1", ")", "\n", "\n", "output_dict", "=", "{", "\n", "\"video_ids\"", ":", "features", "[", "\"id\"", "]", ",", "\n", "\"video_matrix\"", ":", "concatenated_features", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "\"num_frames\"", ":", "tf", ".", "ones", "(", "[", "tf", ".", "shape", "(", "serialized_examples", ")", "[", "0", "]", "]", ")", "\n", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MFrameFeatureReader.__init__": [[210, 242], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "# pylint: disable=dangerous-default-value", "\n", "self", ",", "\n", "num_classes", "=", "3862", ",", "\n", "feature_sizes", "=", "[", "1024", ",", "128", "]", ",", "\n", "feature_names", "=", "[", "\"rgb\"", ",", "\"audio\"", "]", ",", "\n", "max_frames", "=", "300", ",", "\n", "segment_labels", "=", "False", ",", "\n", "segment_size", "=", "5", ",", "\n", "prepare_distill", "=", "False", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MFrameFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n      max_frames: the maximum number of frames to process.\n      segment_labels: if we read segment labels instead.\n      segment_size: the segment_size used for reading segments.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "(", "\n", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "\n", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "segment_labels", "=", "segment_labels", "\n", "self", ".", "segment_size", "=", "segment_size", "\n", "\n", "self", ".", "prepare_distill", "=", "prepare_distill", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MFrameFeatureReader.get_video_matrix": [[244, 273], ["tensorflow.reshape", "tensorflow.minimum", "utils.Dequantize", "readers.resize_axis", "tensorflow.cast", "tensorflow.reshape", "readers.resize_axis", "tensorflow.decode_raw", "tensorflow.shape", "tensorflow.decode_raw"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.Dequantize", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.resize_axis", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.resize_axis"], ["", "def", "get_video_matrix", "(", "self", ",", "features", ",", "feature_size", ",", "max_frames", ",", "\n", "max_quantized_value", ",", "min_quantized_value", ")", ":", "\n", "    ", "\"\"\"Decodes features from an input string and quantizes it.\n\n    Args:\n      features: raw feature values\n      feature_size: length of each frame feature vector\n      max_frames: number of frames (rows) in the output feature_matrix\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      feature_matrix: matrix of all frame-features\n      num_frames: number of frames in the sequence\n    \"\"\"", "\n", "decoded_features", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "decode_raw", "(", "features", ",", "tf", ".", "uint8", ")", ",", "tf", ".", "float32", ")", ",", "\n", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "\n", "num_frames", "=", "tf", ".", "minimum", "(", "tf", ".", "shape", "(", "decoded_features", ")", "[", "0", "]", ",", "max_frames", ")", "\n", "feature_matrix", "=", "utils", ".", "Dequantize", "(", "decoded_features", ",", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "feature_matrix", "=", "resize_axis", "(", "feature_matrix", ",", "0", ",", "max_frames", ")", "\n", "if", "self", ".", "prepare_distill", ":", "\n", "        ", "def_feature_matrix", "=", "tf", ".", "reshape", "(", "tf", ".", "decode_raw", "(", "features", ",", "tf", ".", "uint8", ")", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "def_feature_matrix", "=", "resize_axis", "(", "def_feature_matrix", ",", "0", ",", "max_frames", ")", "\n", "return", "feature_matrix", ",", "num_frames", ",", "def_feature_matrix", "\n", "\n", "", "return", "feature_matrix", ",", "num_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MFrameFeatureReader.prepare_reader": [[274, 294], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read", "readers.YT8MFrameFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "\n", "filename_queue", ",", "\n", "max_quantized_value", "=", "2", ",", "\n", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for YouTube8M SequenceExamples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      A tuple of video indexes, video features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_example", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_example", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MFrameFeatureReader.prepare_serialized_examples": [[295, 441], ["tensorflow.parse_single_sequence_example", "len", "range", "tensorflow.minimum", "tensorflow.concat", "tensorflow.FixedLenFeature", "context_features.update", "context_features.update", "tensorflow.FixedLenSequenceFeature", "tensorflow.cast", "len", "len", "len", "len", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.unique", "tensorflow.gather_nd", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.stack", "tensorflow.sparse.SparseTensor", "tensorflow.sparse.to_dense", "tensorflow.sparse.SparseTensor", "tensorflow.sparse.to_dense", "tensorflow.sparse.SparseTensor", "tensorflow.sparse.to_dense", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sparse_to_dense", "readers.YT8MFrameFeatureReader.get_video_matrix", "readers.YT8MFrameFeatureReader.get_video_matrix", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.tile", "tensorflow.tile", "tensorflow.ones_like", "tensorflow.expand_dims", "tensorflow.ones_like", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.get_video_matrix", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.get_video_matrix"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "\n", "serialized_example", ",", "\n", "max_quantized_value", "=", "2", ",", "\n", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "    ", "\"\"\"Parse single serialized SequenceExample from the TFRecords.\"\"\"", "\n", "\n", "# Read/parse frame/segment-level labels.", "\n", "context_features", "=", "{", "\n", "\"id\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "}", "\n", "if", "self", ".", "segment_labels", ":", "\n", "      ", "context_features", ".", "update", "(", "{", "\n", "# There is no need to read end-time given we always assume the segment", "\n", "# has the same size.", "\n", "\"segment_labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "\"segment_start_times\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "\"segment_scores\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "float32", ")", "\n", "}", ")", "\n", "", "else", ":", "\n", "      ", "context_features", ".", "update", "(", "{", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", ")", "\n", "", "sequence_features", "=", "{", "\n", "feature_name", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "for", "feature_name", "in", "self", ".", "feature_names", "\n", "}", "\n", "contexts", ",", "features", "=", "tf", ".", "parse_single_sequence_example", "(", "\n", "serialized_example", ",", "\n", "context_features", "=", "context_features", ",", "\n", "sequence_features", "=", "sequence_features", ")", "\n", "if", "not", "self", ".", "segment_labels", ":", "\n", "      ", "labels", "=", "(", "tf", ".", "cast", "(", "\n", "tf", ".", "sparse_to_dense", "(", "contexts", "[", "\"labels\"", "]", ".", "values", ",", "(", "self", ".", "num_classes", ",", ")", ",", "1", ",", "\n", "validate_indices", "=", "False", ")", ",", "\n", "tf", ".", "bool", ")", ")", "\n", "\n", "# loads (potentially) different types of features and concatenates them", "\n", "", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"No feature selected: feature_names is empty!\"", "\n", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "(", "\n", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "\n", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", ")", "\n", "\n", "num_frames", "=", "-", "1", "# the number of frames in the video", "\n", "feature_matrices", "=", "[", "None", "]", "*", "num_features", "# an array of different features", "\n", "def_feature_matrices", "=", "[", "None", "]", "*", "num_features", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "if", "self", ".", "prepare_distill", ":", "\n", "        ", "feature_matrix", ",", "num_frames_in_this_feature", ",", "def_fm", "=", "self", ".", "get_video_matrix", "(", "\n", "features", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", ",", "\n", "self", ".", "feature_sizes", "[", "feature_index", "]", ",", "\n", "self", ".", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "", "else", ":", "\n", "        ", "feature_matrix", ",", "num_frames_in_this_feature", "=", "self", ".", "get_video_matrix", "(", "\n", "features", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", ",", "\n", "self", ".", "feature_sizes", "[", "feature_index", "]", ",", "self", ".", "max_frames", ",", "\n", "max_quantized_value", ",", "min_quantized_value", ")", "\n", "", "if", "num_frames", "==", "-", "1", ":", "\n", "        ", "num_frames", "=", "num_frames_in_this_feature", "\n", "\n", "", "feature_matrices", "[", "feature_index", "]", "=", "feature_matrix", "\n", "if", "self", ".", "prepare_distill", ":", "\n", "        ", "def_feature_matrices", "[", "feature_index", "]", "=", "def_fm", "\n", "\n", "# cap the number of frames at self.max_frames", "\n", "", "", "num_frames", "=", "tf", ".", "minimum", "(", "num_frames", ",", "self", ".", "max_frames", ")", "\n", "\n", "# concatenate different features", "\n", "video_matrix", "=", "tf", ".", "concat", "(", "feature_matrices", ",", "1", ")", "\n", "\n", "if", "self", ".", "prepare_distill", ":", "\n", "        ", "batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "video_matrix", ",", "0", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "batch_frames", "=", "tf", ".", "expand_dims", "(", "num_frames", ",", "0", ")", "\n", "\n", "def_video_matrix", "=", "tf", ".", "concat", "(", "def_feature_matrices", ",", "1", ")", "\n", "def_batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "def_video_matrix", ",", "0", ")", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"id\"", "]", ",", "0", ")", "\n", "return", "batch_video_ids", ",", "batch_video_matrix", ",", "batch_labels", ",", "batch_frames", ",", "def_batch_video_matrix", "\n", "\n", "\n", "# Partition frame-level feature matrix to segment-level feature matrix.", "\n", "", "if", "self", ".", "segment_labels", ":", "\n", "      ", "start_times", "=", "contexts", "[", "\"segment_start_times\"", "]", ".", "values", "\n", "# Here we assume all the segments that started at the same start time has", "\n", "# the same segment_size.", "\n", "uniq_start_times", ",", "seg_idxs", "=", "tf", ".", "unique", "(", "\n", "start_times", ",", "out_idx", "=", "tf", ".", "dtypes", ".", "int64", ")", "\n", "# TODO(zhengxu): Ensure the segment_sizes are all same.", "\n", "segment_size", "=", "self", ".", "segment_size", "\n", "# Range gather matrix, e.g., [[0,1,2],[1,2,3]] for segment_size == 3.", "\n", "range_mtx", "=", "tf", ".", "expand_dims", "(", "\n", "uniq_start_times", ",", "axis", "=", "-", "1", ")", "+", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "range", "(", "0", ",", "segment_size", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "axis", "=", "0", ")", "\n", "# Shape: [num_segment, segment_size, feature_dim].", "\n", "batch_video_matrix", "=", "tf", ".", "gather_nd", "(", "video_matrix", ",", "\n", "tf", ".", "expand_dims", "(", "range_mtx", ",", "axis", "=", "-", "1", ")", ")", "\n", "num_segment", "=", "tf", ".", "shape", "(", "batch_video_matrix", ")", "[", "0", "]", "\n", "batch_video_ids", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "[", "contexts", "[", "\"id\"", "]", "]", ",", "[", "num_segment", "]", ")", ",", "(", "num_segment", ",", ")", ")", "\n", "batch_frames", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "[", "segment_size", "]", ",", "[", "num_segment", "]", ")", ",", "(", "num_segment", ",", ")", ")", "\n", "\n", "# For segment labels, all labels are not exhausively rated. So we only", "\n", "# evaluate the rated labels.", "\n", "\n", "# Label indices for each segment, shape: [num_segment, 2].", "\n", "label_indices", "=", "tf", ".", "stack", "(", "[", "seg_idxs", ",", "contexts", "[", "\"segment_labels\"", "]", ".", "values", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "label_values", "=", "contexts", "[", "\"segment_scores\"", "]", ".", "values", "\n", "sparse_labels", "=", "tf", ".", "sparse", ".", "SparseTensor", "(", "label_indices", ",", "label_values", ",", "\n", "(", "num_segment", ",", "self", ".", "num_classes", ")", ")", "\n", "batch_labels", "=", "tf", ".", "sparse", ".", "to_dense", "(", "sparse_labels", ",", "validate_indices", "=", "False", ")", "\n", "\n", "sparse_label_weights", "=", "tf", ".", "sparse", ".", "SparseTensor", "(", "\n", "label_indices", ",", "tf", ".", "ones_like", "(", "label_values", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "(", "num_segment", ",", "self", ".", "num_classes", ")", ")", "\n", "batch_label_weights", "=", "tf", ".", "sparse", ".", "to_dense", "(", "\n", "sparse_label_weights", ",", "validate_indices", "=", "False", ")", "\n", "", "else", ":", "\n", "# Process video-level labels.", "\n", "      ", "label_indices", "=", "contexts", "[", "\"labels\"", "]", ".", "values", "\n", "sparse_labels", "=", "tf", ".", "sparse", ".", "SparseTensor", "(", "\n", "tf", ".", "expand_dims", "(", "label_indices", ",", "axis", "=", "-", "1", ")", ",", "\n", "tf", ".", "ones_like", "(", "contexts", "[", "\"labels\"", "]", ".", "values", ",", "dtype", "=", "tf", ".", "bool", ")", ",", "\n", "(", "self", ".", "num_classes", ",", ")", ")", "\n", "labels", "=", "tf", ".", "sparse", ".", "to_dense", "(", "\n", "sparse_labels", ",", "default_value", "=", "False", ",", "validate_indices", "=", "False", ")", "\n", "# convert to batch format.", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"id\"", "]", ",", "0", ")", "\n", "batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "video_matrix", ",", "0", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "batch_frames", "=", "tf", ".", "expand_dims", "(", "num_frames", ",", "0", ")", "\n", "batch_label_weights", "=", "None", "\n", "\n", "", "output_dict", "=", "{", "\n", "\"video_ids\"", ":", "batch_video_ids", ",", "\n", "\"video_matrix\"", ":", "batch_video_matrix", ",", "\n", "\"labels\"", ":", "batch_labels", ",", "\n", "\"num_frames\"", ":", "batch_frames", ",", "\n", "}", "\n", "if", "batch_label_weights", "is", "not", "None", ":", "\n", "      ", "output_dict", "[", "\"label_weights\"", "]", "=", "batch_label_weights", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.__init__": [[452, 489], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "# pylint: disable=dangerous-default-value", "\n", "self", ",", "\n", "num_classes", "=", "3862", ",", "\n", "feature_sizes", "=", "[", "1024", ",", "128", "]", ",", "\n", "feature_names", "=", "[", "\"rgb\"", ",", "\"audio\"", "]", ",", "\n", "max_frames", "=", "300", ",", "\n", "segment_labels", "=", "True", ",", "\n", "segment_size", "=", "5", ",", "\n", "frame_it", "=", "False", ",", "\n", "label_presence", "=", "False", ",", "\n", "mask_unlabeled", "=", "False", ",", "\n", "one_prop", "=", "False", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MFrameFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n      max_frames: the maximum number of frames to process.\n      segment_labels: if we read segment labels instead.\n      segment_size: the segment_size used for reading segments.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "(", "\n", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "\n", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "segment_labels", "=", "segment_labels", "\n", "self", ".", "segment_size", "=", "segment_size", "\n", "self", ".", "frame_it", "=", "frame_it", "\n", "self", ".", "label_presence", "=", "label_presence", "\n", "self", ".", "mask_unlabeled", "=", "mask_unlabeled", "\n", "self", ".", "one_prop", "=", "one_prop", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.get_video_matrix": [[490, 515], ["tensorflow.reshape", "tensorflow.minimum", "utils.Dequantize", "readers.resize_axis", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.Dequantize", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.resize_axis"], ["", "def", "get_video_matrix", "(", "self", ",", "features", ",", "feature_size", ",", "max_frames", ",", "\n", "max_quantized_value", ",", "min_quantized_value", ")", ":", "\n", "    ", "\"\"\"Decodes features from an input string and quantizes it.\n\n    Args:\n      features: raw feature values\n      feature_size: length of each frame feature vector\n      max_frames: number of frames (rows) in the output feature_matrix\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      feature_matrix: matrix of all frame-features\n      num_frames: number of frames in the sequence\n    \"\"\"", "\n", "decoded_features", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "decode_raw", "(", "features", ",", "tf", ".", "uint8", ")", ",", "tf", ".", "float32", ")", ",", "\n", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "\n", "num_frames", "=", "tf", ".", "minimum", "(", "tf", ".", "shape", "(", "decoded_features", ")", "[", "0", "]", ",", "max_frames", ")", "\n", "feature_matrix", "=", "utils", ".", "Dequantize", "(", "decoded_features", ",", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "feature_matrix", "=", "resize_axis", "(", "feature_matrix", ",", "0", ",", "max_frames", ")", "\n", "\n", "return", "feature_matrix", ",", "num_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_reader": [[516, 536], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read", "readers.YT8MValFrameFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "\n", "filename_queue", ",", "\n", "max_quantized_value", "=", "2", ",", "\n", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for YouTube8M SequenceExamples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      A tuple of video indexes, video features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_example", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_example", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_serialized_examples": [[537, 675], ["tensorflow.parse_single_sequence_example", "len", "range", "tensorflow.minimum", "tensorflow.concat", "tensorflow.FixedLenFeature", "context_features.update", "context_features.update", "tensorflow.FixedLenSequenceFeature", "tensorflow.cast", "len", "len", "len", "len", "readers.YT8MValFrameFeatureReader.get_video_matrix", "tensorflow.py_func.set_shape", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sparse_to_dense", "tensorflow.py_func", "embedding.set_shape", "tensorflow.expand_dims", "tensorflow.py_func", "tensorflow.py_func", "tensorflow.expand_dims.set_shape", "tensorflow.py_func", "tensorflow.py_func.set_shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.py_func", "tensorflow.py_func.set_shape", "tensorflow.expand_dims", "tensorflow.py_func", "tensorflow.py_func.set_shape", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.shape", "tensorflow.tile", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.get_video_matrix"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "\n", "serialized_example", ",", "\n", "max_quantized_value", "=", "2", ",", "\n", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "    ", "\"\"\"Parse single serialized SequenceExample from the TFRecords.\"\"\"", "\n", "\n", "# Read/parse frame/segment-level labels.", "\n", "context_features", "=", "{", "\n", "\"id\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "}", "\n", "if", "self", ".", "segment_labels", ":", "\n", "      ", "context_features", ".", "update", "(", "{", "\n", "# There is no need to read end-time given we always assume the segment", "\n", "# has the same size.", "\n", "\"segment_labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "\"segment_start_times\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "\"segment_scores\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "float32", ")", "\n", "}", ")", "\n", "", "else", ":", "\n", "      ", "context_features", ".", "update", "(", "{", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", ")", "\n", "", "sequence_features", "=", "{", "\n", "feature_name", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "for", "feature_name", "in", "self", ".", "feature_names", "\n", "}", "\n", "contexts", ",", "features", "=", "tf", ".", "parse_single_sequence_example", "(", "\n", "serialized_example", ",", "\n", "context_features", "=", "context_features", ",", "\n", "sequence_features", "=", "sequence_features", ")", "\n", "if", "not", "self", ".", "segment_labels", ":", "\n", "      ", "labels", "=", "(", "tf", ".", "cast", "(", "\n", "tf", ".", "sparse_to_dense", "(", "contexts", "[", "\"labels\"", "]", ".", "values", ",", "(", "self", ".", "num_classes", ",", ")", ",", "1", ",", "\n", "validate_indices", "=", "False", ")", ",", "\n", "tf", ".", "bool", ")", ")", "\n", "\n", "# loads (potentially) different types of features and concatenates them", "\n", "", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"No feature selected: feature_names is empty!\"", "\n", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "(", "\n", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "\n", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", ")", "\n", "\n", "num_frames", "=", "-", "1", "# the number of frames in the video", "\n", "feature_matrices", "=", "[", "None", "]", "*", "num_features", "# an array of different features", "\n", "def_feature_matrices", "=", "[", "None", "]", "*", "num_features", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_matrix", ",", "num_frames_in_this_feature", "=", "self", ".", "get_video_matrix", "(", "\n", "features", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", ",", "\n", "self", ".", "feature_sizes", "[", "feature_index", "]", ",", "self", ".", "max_frames", ",", "\n", "max_quantized_value", ",", "min_quantized_value", ")", "\n", "if", "num_frames", "==", "-", "1", ":", "\n", "        ", "num_frames", "=", "num_frames_in_this_feature", "\n", "\n", "", "feature_matrices", "[", "feature_index", "]", "=", "feature_matrix", "\n", "\n", "# cap the number of frames at self.max_frames", "\n", "", "num_frames", "=", "tf", ".", "minimum", "(", "num_frames", ",", "self", ".", "max_frames", ")", "\n", "\n", "# concatenate different features", "\n", "video_matrix", "=", "tf", ".", "concat", "(", "feature_matrices", ",", "1", ")", "\n", "\n", "# New stuff here", "\n", "if", "self", ".", "label_presence", ":", "\n", "        ", "if", "self", ".", "one_prop", ":", "\n", "            ", "gen_has_label", "=", "gen_masked_select_one", "\n", "", "elif", "self", ".", "mask_unlabeled", ":", "\n", "            ", "gen_has_label", "=", "gen_masked_has_label", "\n", "\n", "", "else", ":", "\n", "            ", "global", "gen_has_label", "\n", "gen_has_label", "=", "gen_has_label", "\n", "\n", "", "if", "self", ".", "one_prop", ":", "\n", "            ", "labels", ",", "embedding", "=", "tf", ".", "py_func", "(", "gen_has_label", ",", "\n", "[", "contexts", "[", "\"segment_scores\"", "]", ".", "values", ",", "contexts", "[", "\"segment_start_times\"", "]", ".", "values", ",", "\n", "contexts", "[", "\"segment_labels\"", "]", ".", "values", "]", ",", "\n", "[", "tf", ".", "int8", ",", "tf", ".", "int64", "]", ")", "\n", "embedding", ".", "set_shape", "(", "(", "1", ",", ")", ")", "\n", "batch_embedding", "=", "tf", ".", "expand_dims", "(", "embedding", ",", "0", ")", "\n", "\n", "", "else", ":", "\n", "            ", "labels", "=", "tf", ".", "py_func", "(", "gen_has_label", ",", "\n", "[", "contexts", "[", "\"segment_scores\"", "]", ".", "values", ",", "contexts", "[", "\"segment_start_times\"", "]", ".", "values", "]", ",", "\n", "tf", ".", "int8", "if", "self", ".", "mask_unlabeled", "else", "tf", ".", "bool", ")", "\n", "", "labels", ".", "set_shape", "(", "(", "300", ",", ")", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"id\"", "]", ",", "0", ")", "\n", "batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "video_matrix", ",", "0", ")", "\n", "batch_frames", "=", "tf", ".", "expand_dims", "(", "num_frames", ",", "0", ")", "\n", "\n", "", "elif", "self", ".", "frame_it", ":", "\n", "        ", "batch_video_matrix", "=", "tf", ".", "py_func", "(", "reshape_input", ",", "[", "video_matrix", ",", "num_frames", "]", ",", "tf", ".", "float32", ")", "\n", "batch_video_matrix", ".", "set_shape", "(", "(", "None", ",", "5", ",", "1024", "+", "128", ")", ")", "\n", "\n", "labels", "=", "tf", ".", "py_func", "(", "gen_labels_matrix_flat", ",", "\n", "[", "\n", "contexts", "[", "\"segment_labels\"", "]", ".", "values", ",", "\n", "contexts", "[", "\"segment_start_times\"", "]", ".", "values", ",", "\n", "contexts", "[", "\"segment_scores\"", "]", ".", "values", ",", "\n", "num_frames", "\n", "]", ",", "\n", "tf", ".", "bool", ")", "\n", "labels", ".", "set_shape", "(", "(", "None", ",", "3862", ")", ")", "\n", "batch_labels", "=", "labels", "\n", "batch_shape", "=", "tf", ".", "shape", "(", "labels", ")", "[", "0", "]", "\n", "batch_frames", "=", "tf", ".", "reshape", "(", "tf", ".", "tile", "(", "[", "5", "]", ",", "[", "batch_shape", "]", ")", ",", "(", "batch_shape", ",", ")", ")", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"id\"", "]", ",", "0", ")", "\n", "batch_video_ids", "=", "tf", ".", "tile", "(", "batch_video_ids", ",", "[", "tf", ".", "shape", "(", "batch_frames", ")", "[", "0", "]", "]", ")", "\n", "\n", "", "else", ":", "\n", "      ", "labels", "=", "tf", ".", "py_func", "(", "gen_label_matrix", ",", "\n", "[", "\n", "contexts", "[", "\"segment_labels\"", "]", ".", "values", ",", "\n", "contexts", "[", "\"segment_start_times\"", "]", ".", "values", ",", "\n", "contexts", "[", "\"segment_scores\"", "]", ".", "values", "]", ",", "\n", "tf", ".", "bool", ")", "\n", "labels", ".", "set_shape", "(", "(", "60", ",", "3862", ")", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "\n", "mask", "=", "tf", ".", "py_func", "(", "gen_label_mask", ",", "[", "num_frames", "]", ",", "tf", ".", "bool", ")", "\n", "mask", ".", "set_shape", "(", "(", "60", ",", ")", ")", "\n", "batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "video_matrix", ",", "0", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "batch_frames", "=", "tf", ".", "expand_dims", "(", "num_frames", ",", "0", ")", "\n", "batch_mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "0", ")", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"id\"", "]", ",", "0", ")", "# TODO: fix it", "\n", "\n", "\n", "", "output_dict", "=", "{", "\n", "# \"video_mask\": batch_mask,", "\n", "\"video_ids\"", ":", "batch_video_ids", ",", "\n", "\"video_matrix\"", ":", "batch_video_matrix", ",", "\n", "\"labels\"", ":", "batch_labels", ",", "\n", "\"num_frames\"", ":", "batch_frames", ",", "\n", "}", "\n", "if", "self", ".", "one_prop", ":", "\n", "        ", "output_dict", "[", "\"sel_label\"", "]", "=", "batch_embedding", "\n", "", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.gen_label_matrix": [[21, 26], ["numpy.zeros", "zip"], "function", ["None"], ["def", "gen_label_matrix", "(", "label", ",", "label_start", ",", "is_valid", ")", ":", "\n", "    ", "output", "=", "np", ".", "zeros", "(", "(", "60", ",", "3862", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "for", "lab", ",", "ls", ",", "val_l", "in", "zip", "(", "label", ",", "label_start", "//", "5", ",", "is_valid", ")", ":", "\n", "        ", "output", "[", "ls", ",", "lab", "]", "=", "val_l", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.gen_labels_matrix_flat": [[28, 35], ["numpy.zeros", "zip"], "function", ["None"], ["", "def", "gen_labels_matrix_flat", "(", "label", ",", "label_start", ",", "is_valid", ",", "seq_len", ")", ":", "\n", "    ", "n_elements", "=", "seq_len", "//", "5", "\n", "output", "=", "np", ".", "zeros", "(", "(", "n_elements", ",", "3862", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "for", "lab", ",", "ls", ",", "val_l", "in", "zip", "(", "label", ",", "label_start", "//", "5", ",", "is_valid", ")", ":", "\n", "        ", "if", "ls", "<", "n_elements", ":", "# This should not be the case!", "\n", "            ", "output", "[", "ls", ",", "lab", "]", "=", "val_l", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.reshape_input": [[36, 42], ["numpy.zeros", "range"], "function", ["None"], ["", "def", "reshape_input", "(", "in_matrix", ",", "seq_len", ")", ":", "\n", "    ", "outshape", "=", "seq_len", "//", "5", "\n", "out_matrix", "=", "np", ".", "zeros", "(", "(", "outshape", ",", "5", ",", "1152", ")", ",", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "outshape", ")", ":", "\n", "        ", "out_matrix", "[", "i", "]", "=", "in_matrix", "[", "i", "*", "5", ":", "i", "*", "5", "+", "5", "]", "\n", "", "return", "out_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.gen_label_mask": [[43, 47], ["numpy.zeros"], "function", ["None"], ["", "def", "gen_label_mask", "(", "seq_len", ")", ":", "\n", "    ", "mask", "=", "np", ".", "zeros", "(", "(", "60", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "mask", "[", ":", "seq_len", "]", "=", "1", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.gen_has_label": [[48, 54], ["numpy.zeros", "zip"], "function", ["None"], ["", "def", "gen_has_label", "(", "is_valid", ",", "label_start", ")", ":", "\n", "    ", "output", "=", "np", ".", "zeros", "(", "(", "300", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "for", "label_val", ",", "s_idx", "in", "zip", "(", "is_valid", ",", "label_start", ")", ":", "\n", "        ", "if", "label_val", ":", "\n", "            ", "output", "[", "s_idx", ":", "s_idx", "+", "5", "]", "=", "1", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.gen_masked_has_label": [[55, 62], ["numpy.zeros"], "function", ["None"], ["", "def", "gen_masked_has_label", "(", "is_valid", ",", "label_start", ")", ":", "\n", "    ", "output", "=", "np", ".", "zeros", "(", "(", "300", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "for", "s_idx", "in", "label_start", "[", "is_valid", "==", "0", "]", ":", "\n", "        ", "output", "[", "s_idx", ":", "s_idx", "+", "5", "]", "=", "-", "1", "\n", "", "for", "s_idx", "in", "label_start", "[", "is_valid", "==", "1", "]", ":", "\n", "        ", "output", "[", "s_idx", ":", "s_idx", "+", "5", "]", "=", "1", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.gen_masked_select_one": [[63, 75], ["numpy.zeros", "numpy.random.choice", "numpy.unique", "numpy.array().reshape", "numpy.array"], "function", ["None"], ["", "def", "gen_masked_select_one", "(", "is_valid", ",", "label_start", ",", "label_type", ")", ":", "\n", "    ", "output", "=", "np", ".", "zeros", "(", "(", "300", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "selected_label", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "unique", "(", "label_type", ")", ")", "\n", "select_idx", "=", "label_type", "==", "selected_label", "\n", "is_valid", "=", "is_valid", "[", "select_idx", "]", "\n", "label_start", "=", "label_start", "[", "select_idx", "]", "\n", "\n", "for", "s_idx", "in", "label_start", "[", "is_valid", "==", "0", "]", ":", "\n", "        ", "output", "[", "s_idx", ":", "s_idx", "+", "5", "]", "=", "-", "1", "\n", "", "for", "s_idx", "in", "label_start", "[", "is_valid", "==", "1", "]", ":", "\n", "        ", "output", "[", "s_idx", ":", "s_idx", "+", "5", "]", "=", "1", "\n", "", "return", "output", ",", "np", ".", "array", "(", "selected_label", ")", ".", "reshape", "(", "(", "1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.resize_axis": [[77, 113], ["tensorflow.convert_to_tensor", "tensorflow.unstack", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.stack", "tensorflow.concat", "tf.convert_to_tensor.get_shape().as_list", "tf.concat.set_shape", "tensorflow.shape", "tensorflow.slice", "tensorflow.fill", "tf.convert_to_tensor.get_shape", "tensorflow.zeros_like", "tensorflow.stack", "tensorflow.cast"], "function", ["None"], ["", "def", "resize_axis", "(", "tensor", ",", "axis", ",", "new_size", ",", "fill_value", "=", "0", ")", ":", "\n", "  ", "\"\"\"Truncates or pads a tensor to new_size on on a given axis.\n\n  Truncate or extend tensor such that tensor.shape[axis] == new_size. If the\n  size increases, the padding will be performed at the end, using fill_value.\n\n  Args:\n    tensor: The tensor to be resized.\n    axis: An integer representing the dimension to be sliced.\n    new_size: An integer or 0d tensor representing the new value for\n      tensor.shape[axis].\n    fill_value: Value to use to fill any new entries in the tensor. Will be cast\n      to the type of tensor.\n\n  Returns:\n    The resized tensor.\n  \"\"\"", "\n", "tensor", "=", "tf", ".", "convert_to_tensor", "(", "tensor", ")", "\n", "shape", "=", "tf", ".", "unstack", "(", "tf", ".", "shape", "(", "tensor", ")", ")", "\n", "\n", "pad_shape", "=", "shape", "[", ":", "]", "\n", "pad_shape", "[", "axis", "]", "=", "tf", ".", "maximum", "(", "0", ",", "new_size", "-", "shape", "[", "axis", "]", ")", "\n", "\n", "shape", "[", "axis", "]", "=", "tf", ".", "minimum", "(", "shape", "[", "axis", "]", ",", "new_size", ")", "\n", "shape", "=", "tf", ".", "stack", "(", "shape", ")", "\n", "\n", "resized", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "slice", "(", "tensor", ",", "tf", ".", "zeros_like", "(", "shape", ")", ",", "shape", ")", ",", "\n", "tf", ".", "fill", "(", "tf", ".", "stack", "(", "pad_shape", ")", ",", "tf", ".", "cast", "(", "fill_value", ",", "tensor", ".", "dtype", ")", ")", "\n", "]", ",", "axis", ")", "\n", "\n", "# Update shape.", "\n", "new_shape", "=", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "# A copy is being made.", "\n", "new_shape", "[", "axis", "]", "=", "new_size", "\n", "resized", ".", "set_shape", "(", "new_shape", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.export_model.ModelExporter.__init__": [[30, 39], ["tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "export_model.ModelExporter.build_inputs_and_outputs", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.Graph", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.export_model.ModelExporter.build_inputs_and_outputs"], ["  ", "def", "__init__", "(", "self", ",", "frame_features", ",", "model", ",", "reader", ")", ":", "\n", "    ", "self", ".", "frame_features", "=", "frame_features", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "      ", "self", ".", "inputs", ",", "self", ".", "outputs", "=", "self", ".", "build_inputs_and_outputs", "(", ")", "\n", "self", ".", "graph", "=", "graph", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ",", "sharded", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.export_model.ModelExporter.export_model": [[40, 64], ["export_model.ModelExporter.graph.as_default", "tensorflow.Session", "tensorflow.Session", "session.run", "export_model.ModelExporter.saver.restore", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder.add_meta_graph_and_variables", "tensorflow.python.saved_model.builder.SavedModelBuilder.save", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run"], ["", "", "def", "export_model", "(", "self", ",", "model_dir", ",", "global_step_val", ",", "last_checkpoint", ")", ":", "\n", "    ", "\"\"\"Exports the model so that it can used for batch predictions.\"\"\"", "\n", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "      ", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "saver", ".", "restore", "(", "session", ",", "last_checkpoint", ")", "\n", "\n", "signature", "=", "signature_def_utils", ".", "build_signature_def", "(", "\n", "inputs", "=", "self", ".", "inputs", ",", "\n", "outputs", "=", "self", ".", "outputs", ",", "\n", "method_name", "=", "signature_constants", ".", "PREDICT_METHOD_NAME", ")", "\n", "\n", "signature_map", "=", "{", "\n", "signature_constants", ".", "DEFAULT_SERVING_SIGNATURE_DEF_KEY", ":", "signature", "\n", "}", "\n", "\n", "model_builder", "=", "saved_model_builder", ".", "SavedModelBuilder", "(", "model_dir", ")", "\n", "model_builder", ".", "add_meta_graph_and_variables", "(", "\n", "session", ",", "\n", "tags", "=", "[", "tag_constants", ".", "SERVING", "]", ",", "\n", "signature_def_map", "=", "signature_map", ",", "\n", "clear_devices", "=", "True", ")", "\n", "model_builder", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.export_model.ModelExporter.build_inputs_and_outputs": [[65, 95], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.map_fn", "tensorflow.map_fn", "tensorflow.placeholder", "tensorflow.placeholder", "export_model.ModelExporter.build_prediction_graph", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "export_model.ModelExporter.build_prediction_graph"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.export_model.ModelExporter.build_prediction_graph", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.export_model.ModelExporter.build_prediction_graph"], ["", "", "", "def", "build_inputs_and_outputs", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "frame_features", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "fn", "=", "lambda", "x", ":", "self", ".", "build_prediction_graph", "(", "x", ")", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "tf", ".", "map_fn", "(", "\n", "fn", ",", "serialized_examples", ",", "dtype", "=", "(", "tf", ".", "string", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "self", ".", "build_prediction_graph", "(", "serialized_examples", ")", ")", "\n", "\n", "", "inputs", "=", "{", "\n", "\"example_bytes\"", ":", "\n", "saved_model_utils", ".", "build_tensor_info", "(", "serialized_examples", ")", "\n", "}", "\n", "\n", "outputs", "=", "{", "\n", "\"video_id\"", ":", "\n", "saved_model_utils", ".", "build_tensor_info", "(", "video_id_output", ")", ",", "\n", "\"class_indexes\"", ":", "\n", "saved_model_utils", ".", "build_tensor_info", "(", "top_indices_output", ")", ",", "\n", "\"predictions\"", ":", "\n", "saved_model_utils", ".", "build_tensor_info", "(", "top_predictions_output", ")", "\n", "}", "\n", "\n", "return", "inputs", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.export_model.ModelExporter.build_prediction_graph": [[96, 123], ["export_model.ModelExporter.reader.prepare_serialized_examples", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "len", "tensorflow.variable_scope", "tensorflow.variable_scope", "export_model.ModelExporter.model.create_model", "tensorflow.get_model_variables", "tensorflow.get_model_variables", "tensorflow.nn.top_k", "tensorflow.nn.top_k", "model_input_raw.get_shape", "tensorflow.summary.histogram", "tensorflow.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_serialized_examples", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model"], ["", "def", "build_prediction_graph", "(", "self", ",", "serialized_examples", ")", ":", "\n", "    ", "input_data_dict", "=", "(", "\n", "self", ".", "reader", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", ")", "\n", "video_id", "=", "input_data_dict", "[", "\"video_ids\"", "]", "\n", "model_input_raw", "=", "input_data_dict", "[", "\"video_matrix\"", "]", "\n", "labels_batch", "=", "input_data_dict", "[", "\"labels\"", "]", "\n", "num_frames", "=", "input_data_dict", "[", "\"num_frames\"", "]", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "      ", "result", "=", "self", ".", "model", ".", "create_model", "(", "\n", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "self", ".", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "False", ")", "\n", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "\n", "top_predictions", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "predictions", ",", "\n", "_TOP_PREDICTIONS_IN_OUTPUT", ")", "\n", "", "return", "video_id", ",", "top_indices", ",", "top_predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.mean_average_precision_calculator.MeanAveragePrecisionCalculator.__init__": [[45, 67], ["range", "ValueError", "mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators.append", "isinstance", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ",", "filter_empty_classes", "=", "True", ",", "top_n", "=", "None", ")", ":", "\n", "    ", "\"\"\"Construct a calculator to calculate the (macro) average precision.\n\n    Args:\n      num_class: A positive Integer specifying the number of classes.\n      filter_empty_classes: whether to filter classes without any positives.\n      top_n: A positive Integer specifying the average precision at n, or None\n        to use all provided data points.\n\n    Raises:\n      ValueError: An error occurred when num_class is not a positive integer;\n      or the top_n_array is not a list of positive integers.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "num_class", ",", "int", ")", "or", "num_class", "<=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"num_class must be a positive integer.\"", ")", "\n", "\n", "", "self", ".", "_ap_calculators", "=", "[", "]", "# member of AveragePrecisionCalculator", "\n", "self", ".", "_num_class", "=", "num_class", "# total number of classes", "\n", "self", ".", "_filter_empty_classes", "=", "filter_empty_classes", "\n", "for", "_", "in", "range", "(", "num_class", ")", ":", "\n", "      ", "self", ".", "_ap_calculators", ".", "append", "(", "\n", "average_precision_calculator", ".", "AveragePrecisionCalculator", "(", "top_n", "=", "top_n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.mean_average_precision_calculator.MeanAveragePrecisionCalculator.accumulate": [[68, 91], ["range", "calculators[].accumulate", "range"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.accumulate"], ["", "", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    Args:\n      predictions: A list of lists storing the prediction scores. The outer\n        dimension corresponds to classes.\n      actuals: A list of lists storing the ground truth labels. The dimensions\n        should correspond to the predictions input. Any value larger than 0 will\n        be treated as positives, otherwise as negatives.\n      num_positives: If provided, it is a list of numbers representing the\n        number of true positives for each class. If not provided, the number of\n        true positives will be inferred from the 'actuals' array.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n      does not match.\n    \"\"\"", "\n", "if", "not", "num_positives", ":", "\n", "      ", "num_positives", "=", "[", "None", "for", "i", "in", "range", "(", "self", ".", "_num_class", ")", "]", "\n", "\n", "", "calculators", "=", "self", ".", "_ap_calculators", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_class", ")", ":", "\n", "      ", "calculators", "[", "i", "]", ".", "accumulate", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ",", "num_positives", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.mean_average_precision_calculator.MeanAveragePrecisionCalculator.clear": [[92, 95], ["calculator.clear"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.clear"], ["", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "for", "calculator", "in", "self", ".", "_ap_calculators", ":", "\n", "      ", "calculator", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.mean_average_precision_calculator.MeanAveragePrecisionCalculator.is_empty": [[96, 99], ["range"], "methods", ["None"], ["", "", "def", "is_empty", "(", "self", ")", ":", "\n", "    ", "return", "(", "[", "calculator", ".", "heap_size", "for", "calculator", "in", "self", ".", "_ap_calculators", "\n", "]", "==", "[", "0", "for", "_", "in", "range", "(", "self", ".", "_num_class", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n": [[100, 114], ["range", "mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators[].peek_ap_at_n", "aps.append"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "peek_map_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated mean average precision at n.\n\n    Returns:\n      An array of non-interpolated average precision at n (default 0) for each\n      class.\n    \"\"\"", "\n", "aps", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_class", ")", ":", "\n", "      ", "if", "(", "not", "self", ".", "_filter_empty_classes", "or", "\n", "self", ".", "_ap_calculators", "[", "i", "]", ".", "num_accumulated_positives", ">", "0", ")", ":", "\n", "        ", "ap", "=", "self", ".", "_ap_calculators", "[", "i", "]", ".", "peek_ap_at_n", "(", ")", "\n", "aps", ".", "append", "(", "ap", ")", "\n", "", "", "return", "aps", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.attention_frames_v0.create_model": [[69, 133], ["tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.concat", "getattr", "getattr.create_model", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.transpose", "tensorflow.transpose", "getattr."], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model"], ["    ", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "        ", "video_in", "=", "model_input", "[", ":", ",", ":", ",", ":", "1024", "]", "\n", "audio_in", "=", "model_input", "[", ":", ",", ":", ",", "1024", ":", "]", "\n", "\n", "video_bn", "=", "slim", ".", "batch_norm", "(", "\n", "video_in", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"video_input_bn\"", ")", "\n", "audio_bn", "=", "slim", ".", "batch_norm", "(", "\n", "audio_in", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"audio_input_bn\"", ")", "\n", "\n", "# Transform input", "\n", "activation_video", "=", "slim", ".", "fully_connected", "(", "video_bn", ",", "2048", ",", "activation_fn", "=", "None", ",", "biases_initializer", "=", "None", ")", "\n", "activation_audio", "=", "slim", ".", "fully_connected", "(", "audio_bn", ",", "256", ",", "activation_fn", "=", "None", ",", "biases_initializer", "=", "None", ")", "\n", "\n", "activation_video", "=", "slim", ".", "batch_norm", "(", "\n", "activation_video", ",", "\n", "fused", "=", "False", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"video_cluster_bn\"", ")", "\n", "activation_audio", "=", "slim", ".", "batch_norm", "(", "\n", "activation_audio", ",", "\n", "center", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"audio_cluster_bn\"", ")", "\n", "\n", "activation_video", "=", "tf", ".", "nn", ".", "relu6", "(", "activation_video", ")", "\n", "activation_audio", "=", "tf", ".", "nn", ".", "relu6", "(", "activation_audio", ")", "\n", "\n", "# Compute Gates", "\n", "gate_video", "=", "slim", ".", "fully_connected", "(", "video_bn", ",", "1", ",", "activation_fn", "=", "None", ",", "biases_initializer", "=", "None", ")", "\n", "gate_audio", "=", "slim", ".", "fully_connected", "(", "audio_bn", ",", "1", ",", "activation_fn", "=", "None", ",", "biases_initializer", "=", "None", ")", "\n", "\n", "# Apply activations and reduce values", "\n", "video_vals", "=", "tf", ".", "transpose", "(", "activation_video", ",", "(", "2", ",", "0", ",", "1", ")", ")", "*", "tf", ".", "nn", ".", "softmax", "(", "gate_video", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "video_vals", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "transpose", "(", "video_vals", ",", "(", "1", ",", "2", ",", "0", ")", ")", ",", "axis", "=", "1", ")", "\n", "\n", "audio_vals", "=", "tf", ".", "transpose", "(", "activation_audio", ",", "(", "2", ",", "0", ",", "1", ")", ")", "*", "tf", ".", "nn", ".", "softmax", "(", "gate_audio", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "audio_vals", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "transpose", "(", "audio_vals", ",", "(", "1", ",", "2", ",", "0", ")", ")", ",", "axis", "=", "1", ")", "\n", "\n", "frame_agg", "=", "tf", ".", "concat", "(", "[", "video_vals", ",", "audio_vals", "]", ",", "axis", "=", "1", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "\"LogisticModel\"", ")", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "frame_agg", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.NetVLAD.__init__": [[137, 143], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "feature_size", ",", "max_frames", ",", "cluster_size", ",", "add_batch_norm", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "add_batch_norm", "=", "add_batch_norm", "\n", "self", ".", "cluster_size", "=", "cluster_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.NetVLAD.forward": [[144, 197], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.subtract", "tensorflow.subtract", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "reshaped_input", ")", ":", "\n", "\n", "        ", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "self", ".", "feature_size", ",", "self", ".", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "feature_size", ")", ")", ")", "\n", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "\n", "if", "self", ".", "add_batch_norm", ":", "\n", "            ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "self", ".", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "            ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "\n", "", "activation", "=", "tf", ".", "nn", ".", "softmax", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_output\"", ",", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "self", ".", "max_frames", ",", "self", ".", "cluster_size", "]", ")", "\n", "\n", "a_sum", "=", "tf", ".", "reduce_sum", "(", "activation", ",", "-", "2", ",", "keep_dims", "=", "True", ")", "\n", "\n", "cluster_weights2", "=", "tf", ".", "get_variable", "(", "\"cluster_weights2\"", ",", "\n", "[", "1", ",", "self", ".", "feature_size", ",", "self", ".", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "feature_size", ")", ")", ")", "\n", "\n", "a", "=", "tf", ".", "multiply", "(", "a_sum", ",", "cluster_weights2", ")", "\n", "\n", "activation", "=", "tf", ".", "transpose", "(", "activation", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "reshaped_input", ",", "[", "-", "1", ",", "self", ".", "max_frames", ",", "self", ".", "feature_size", "]", ")", "\n", "vlad", "=", "tf", ".", "matmul", "(", "activation", ",", "reshaped_input", ")", "\n", "vlad", "=", "tf", ".", "transpose", "(", "vlad", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "vlad", "=", "tf", ".", "subtract", "(", "vlad", ",", "a", ")", "\n", "\n", "vlad", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "vlad", ",", "1", ")", "\n", "\n", "vlad", "=", "tf", ".", "reshape", "(", "vlad", ",", "[", "-", "1", ",", "self", ".", "cluster_size", "*", "self", ".", "feature_size", "]", ")", "\n", "vlad", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "vlad", ",", "1", ")", "\n", "\n", "return", "vlad", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.LightVLAD.__init__": [[200, 206], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "feature_size", ",", "max_frames", ",", "cluster_size", ",", "add_batch_norm", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "add_batch_norm", "=", "add_batch_norm", "\n", "self", ".", "cluster_size", "=", "cluster_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.LightVLAD.forward": [[207, 248], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "reshaped_input", ")", ":", "\n", "\n", "        ", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "self", ".", "feature_size", ",", "self", ".", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "feature_size", ")", ")", ")", "\n", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "\n", "if", "self", ".", "add_batch_norm", ":", "\n", "            ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "self", ".", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "            ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "\n", "", "activation", "=", "tf", ".", "nn", ".", "softmax", "(", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "self", ".", "max_frames", ",", "self", ".", "cluster_size", "]", ")", "\n", "\n", "activation", "=", "tf", ".", "transpose", "(", "activation", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "reshaped_input", ",", "[", "-", "1", ",", "self", ".", "max_frames", ",", "self", ".", "feature_size", "]", ")", "\n", "vlad", "=", "tf", ".", "matmul", "(", "activation", ",", "reshaped_input", ")", "\n", "\n", "vlad", "=", "tf", ".", "transpose", "(", "vlad", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "vlad", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "vlad", ",", "1", ")", "\n", "\n", "vlad", "=", "tf", ".", "reshape", "(", "vlad", ",", "[", "-", "1", ",", "self", ".", "cluster_size", "*", "self", ".", "feature_size", "]", ")", "\n", "vlad", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "vlad", ",", "1", ")", "\n", "\n", "return", "vlad", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.NetVLADModelLF.create_model": [[264, 403], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "print", "print", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "devel_models.LightVLAD", "devel_models.LightVLAD", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.variable_scope", "tensorflow.variable_scope", "devel_models.NetVLAD.forward", "tensorflow.variable_scope", "tensorflow.variable_scope", "devel_models.NetVLAD.forward", "tensorflow.concat.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.multiply", "tensorflow.multiply", "print", "model_utils.SampleRandomFrames", "print", "model_utils.SampleRandomSequence", "NetVLAGD", "NetVLAGD", "devel_models.NetVLAD", "devel_models.NetVLAD", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.matrix_diag_part", "tensorflow.matrix_diag_part", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.concat.get_shape", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.random_normal", "tensorflow.random_normal", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomSequence"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_frames", ",", "\n", "iterations", "=", "None", ",", "\n", "add_batch_norm", "=", "None", ",", "\n", "sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "        ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "netvlad_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "netvlad_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "netvlad_hidden_size", "\n", "relu", "=", "FLAGS", ".", "netvlad_relu", "\n", "dimred", "=", "FLAGS", ".", "netvlad_dimred", "\n", "gating", "=", "FLAGS", ".", "gating", "\n", "remove_diag", "=", "FLAGS", ".", "gating_remove_diag", "\n", "lightvlad", "=", "FLAGS", ".", "lightvlad", "\n", "vlagd", "=", "FLAGS", ".", "vlagd", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "FLAGS", ".", "subsample", ":", "\n", "            ", "if", "random_frames", ":", "\n", "                ", "print", "(", "\"##### Using random Frames. #####\"", ")", "\n", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"##### Using random Sequence. #####\"", ")", "\n", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "\n", "# if random_frames:", "\n", "#     model_input = utils.SampleRandomFrames(model_input, num_frames,", "\n", "#                                            iterations)", "\n", "# else:", "\n", "#     model_input = utils.SampleRandomSequence(model_input, num_frames,", "\n", "#                                              iterations)", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"##### We are not subsampling.\"", ")", "\n", "print", "(", "\"#########################\"", ")", "\n", "", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "\n", "if", "lightvlad", ":", "\n", "            ", "video_NetVLAD", "=", "LightVLAD", "(", "1024", ",", "max_frames", ",", "cluster_size", ",", "add_batch_norm", ",", "is_training", ")", "\n", "audio_NetVLAD", "=", "LightVLAD", "(", "128", ",", "max_frames", ",", "cluster_size", "/", "2", ",", "add_batch_norm", ",", "is_training", ")", "\n", "", "elif", "vlagd", ":", "\n", "            ", "video_NetVLAD", "=", "NetVLAGD", "(", "1024", ",", "max_frames", ",", "cluster_size", ",", "add_batch_norm", ",", "is_training", ")", "\n", "audio_NetVLAD", "=", "NetVLAGD", "(", "128", ",", "max_frames", ",", "cluster_size", "/", "2", ",", "add_batch_norm", ",", "is_training", ")", "\n", "", "else", ":", "\n", "            ", "video_NetVLAD", "=", "NetVLAD", "(", "1024", ",", "max_frames", ",", "cluster_size", ",", "add_batch_norm", ",", "is_training", ")", "\n", "audio_NetVLAD", "=", "NetVLAD", "(", "128", ",", "max_frames", ",", "cluster_size", "/", "2", ",", "add_batch_norm", ",", "is_training", ")", "\n", "\n", "", "if", "add_batch_norm", ":", "# and not lightvlad:", "\n", "            ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"video_VLAD\"", ")", ":", "\n", "            ", "vlad_video", "=", "video_NetVLAD", ".", "forward", "(", "reshaped_input", "[", ":", ",", "0", ":", "1024", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"audio_VLAD\"", ")", ":", "\n", "            ", "vlad_audio", "=", "audio_NetVLAD", ".", "forward", "(", "reshaped_input", "[", ":", ",", "1024", ":", "]", ")", "\n", "\n", "", "vlad", "=", "tf", ".", "concat", "(", "[", "vlad_video", ",", "vlad_audio", "]", ",", "1", ")", "\n", "\n", "vlad_dim", "=", "vlad", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\"hidden1_weights\"", ",", "\n", "[", "vlad_dim", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "\n", "activation", "=", "tf", ".", "matmul", "(", "vlad", ",", "hidden1_weights", ")", "\n", "\n", "if", "add_batch_norm", "and", "relu", ":", "\n", "            ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "\n", "", "else", ":", "\n", "            ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\"hidden1_biases\"", ",", "\n", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "\n", "", "if", "relu", ":", "\n", "            ", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "\n", "", "if", "gating", ":", "\n", "            ", "gating_weights", "=", "tf", ".", "get_variable", "(", "\"gating_weights_2\"", ",", "\n", "[", "hidden1_size", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "hidden1_size", ")", ")", ")", "\n", "\n", "gates", "=", "tf", ".", "matmul", "(", "activation", ",", "gating_weights", ")", "\n", "\n", "if", "remove_diag", ":", "\n", "# removes diagonals coefficients", "\n", "                ", "diagonals", "=", "tf", ".", "matrix_diag_part", "(", "gating_weights", ")", "\n", "gates", "=", "gates", "-", "tf", ".", "multiply", "(", "diagonals", ",", "activation", ")", "\n", "\n", "", "if", "add_batch_norm", ":", "\n", "                ", "gates", "=", "slim", ".", "batch_norm", "(", "\n", "gates", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"gating_bn\"", ")", "\n", "", "else", ":", "\n", "                ", "gating_biases", "=", "tf", ".", "get_variable", "(", "\"gating_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "gates", "+=", "gating_biases", "\n", "\n", "", "gates", "=", "tf", ".", "sigmoid", "(", "gates", ")", "\n", "\n", "activation", "=", "tf", ".", "multiply", "(", "activation", ",", "gates", ")", "\n", "\n", "", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "is_training", "=", "is_training", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.NetFVModelLF.create_model": [[422, 532], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "devel_models.NetFV", "devel_models.NetFV", "tensorflow.concat", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_utils.SampleRandomFrames", "model_utils.SampleRandomSequence", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.variable_scope", "tensorflow.variable_scope", "devel_models.NetFV.forward", "tensorflow.variable_scope", "tensorflow.variable_scope", "devel_models.NetFV.forward", "tensorflow.concat.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.concat.get_shape", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal", "tensorflow.random_normal", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomSequence", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_frames", ",", "\n", "iterations", "=", "None", ",", "\n", "add_batch_norm", "=", "None", ",", "\n", "sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "        ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "netvlad_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "fv_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "fv_hidden_size", "\n", "relu", "=", "FLAGS", ".", "fv_relu", "\n", "gating", "=", "FLAGS", ".", "gating", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "random_frames", ":", "\n", "            ", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "            ", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"input_hist\"", ",", "reshaped_input", ")", "\n", "\n", "video_NetFV", "=", "NetFV", "(", "1024", ",", "max_frames", ",", "cluster_size", ",", "add_batch_norm", ",", "is_training", ")", "\n", "audio_NetFV", "=", "NetFV", "(", "128", ",", "max_frames", ",", "cluster_size", "/", "2", ",", "add_batch_norm", ",", "is_training", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "            ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"video_FV\"", ")", ":", "\n", "            ", "fv_video", "=", "video_NetFV", ".", "forward", "(", "reshaped_input", "[", ":", ",", "0", ":", "1024", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"audio_FV\"", ")", ":", "\n", "            ", "fv_audio", "=", "audio_NetFV", ".", "forward", "(", "reshaped_input", "[", ":", ",", "1024", ":", "]", ")", "\n", "\n", "", "fv", "=", "tf", ".", "concat", "(", "[", "fv_video", ",", "fv_audio", "]", ",", "1", ")", "\n", "\n", "fv_dim", "=", "fv", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\"hidden1_weights\"", ",", "\n", "[", "fv_dim", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "\n", "activation", "=", "tf", ".", "matmul", "(", "fv", ",", "hidden1_weights", ")", "\n", "\n", "if", "add_batch_norm", "and", "relu", ":", "\n", "            ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "", "else", ":", "\n", "            ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\"hidden1_biases\"", ",", "\n", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "\n", "", "if", "relu", ":", "\n", "            ", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "\n", "", "if", "gating", ":", "\n", "            ", "gating_weights", "=", "tf", ".", "get_variable", "(", "\"gating_weights_2\"", ",", "\n", "[", "hidden1_size", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "hidden1_size", ")", ")", ")", "\n", "\n", "gates", "=", "tf", ".", "matmul", "(", "activation", ",", "gating_weights", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "                ", "gates", "=", "slim", ".", "batch_norm", "(", "\n", "gates", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"gating_bn\"", ")", "\n", "", "else", ":", "\n", "                ", "gating_biases", "=", "tf", ".", "get_variable", "(", "\"gating_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "gates", "+=", "gating_biases", "\n", "\n", "", "gates", "=", "tf", ".", "sigmoid", "(", "gates", ")", "\n", "\n", "activation", "=", "tf", ".", "multiply", "(", "activation", ",", "gates", ")", "\n", "\n", "", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "is_training", "=", "is_training", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.NetFV.__init__": [[535, 541], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "feature_size", ",", "max_frames", ",", "cluster_size", ",", "add_batch_norm", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "add_batch_norm", "=", "add_batch_norm", "\n", "self", ".", "cluster_size", "=", "cluster_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.NetFV.forward": [[542, 624], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.square", "tensorflow.square", "tensorflow.constant", "tensorflow.constant", "tensorflow.add", "tensorflow.add", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.add_n", "tensorflow.add_n", "tensorflow.divide", "tensorflow.divide", "tensorflow.subtract", "tensorflow.subtract", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.subtract", "tensorflow.subtract", "tensorflow.divide", "tensorflow.divide", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.concat", "tensorflow.concat", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.scalar_mul", "tensorflow.scalar_mul", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.scalar_mul", "tensorflow.scalar_mul", "tensorflow.random_normal", "tensorflow.random_normal", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "reshaped_input", ")", ":", "\n", "        ", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "self", ".", "feature_size", ",", "self", ".", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "feature_size", ")", ")", ")", "\n", "\n", "covar_weights", "=", "tf", ".", "get_variable", "(", "\"covar_weights\"", ",", "\n", "[", "self", ".", "feature_size", ",", "self", ".", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "1.0", ",", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "\n", "self", ".", "feature_size", ")", ")", ")", "\n", "\n", "covar_weights", "=", "tf", ".", "square", "(", "covar_weights", ")", "\n", "eps", "=", "tf", ".", "constant", "(", "[", "1e-6", "]", ")", "\n", "covar_weights", "=", "tf", ".", "add", "(", "covar_weights", ",", "eps", ")", "\n", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "if", "self", ".", "add_batch_norm", ":", "\n", "            ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "is_training", "=", "self", ".", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "            ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "self", ".", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "\n", "", "activation", "=", "tf", ".", "nn", ".", "softmax", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_output\"", ",", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "self", ".", "max_frames", ",", "self", ".", "cluster_size", "]", ")", "\n", "\n", "a_sum", "=", "tf", ".", "reduce_sum", "(", "activation", ",", "-", "2", ",", "keep_dims", "=", "True", ")", "\n", "\n", "if", "not", "FLAGS", ".", "fv_couple_weights", ":", "\n", "            ", "cluster_weights2", "=", "tf", ".", "get_variable", "(", "\"cluster_weights2\"", ",", "\n", "[", "1", ",", "self", ".", "feature_size", ",", "self", ".", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "feature_size", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "cluster_weights2", "=", "tf", ".", "scalar_mul", "(", "FLAGS", ".", "fv_coupling_factor", ",", "cluster_weights", ")", "\n", "\n", "", "a", "=", "tf", ".", "multiply", "(", "a_sum", ",", "cluster_weights2", ")", "\n", "\n", "activation", "=", "tf", ".", "transpose", "(", "activation", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "reshaped_input", ",", "[", "-", "1", ",", "self", ".", "max_frames", ",", "self", ".", "feature_size", "]", ")", "\n", "fv1", "=", "tf", ".", "matmul", "(", "activation", ",", "reshaped_input", ")", "\n", "\n", "fv1", "=", "tf", ".", "transpose", "(", "fv1", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "# computing second order FV", "\n", "a2", "=", "tf", ".", "multiply", "(", "a_sum", ",", "tf", ".", "square", "(", "cluster_weights2", ")", ")", "\n", "\n", "b2", "=", "tf", ".", "multiply", "(", "fv1", ",", "cluster_weights2", ")", "\n", "fv2", "=", "tf", ".", "matmul", "(", "activation", ",", "tf", ".", "square", "(", "reshaped_input", ")", ")", "\n", "\n", "fv2", "=", "tf", ".", "transpose", "(", "fv2", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "fv2", "=", "tf", ".", "add_n", "(", "[", "a2", ",", "fv2", ",", "tf", ".", "scalar_mul", "(", "-", "2", ",", "b2", ")", "]", ")", "\n", "\n", "fv2", "=", "tf", ".", "divide", "(", "fv2", ",", "tf", ".", "square", "(", "covar_weights", ")", ")", "\n", "fv2", "=", "tf", ".", "subtract", "(", "fv2", ",", "a_sum", ")", "\n", "\n", "fv2", "=", "tf", ".", "reshape", "(", "fv2", ",", "[", "-", "1", ",", "self", ".", "cluster_size", "*", "self", ".", "feature_size", "]", ")", "\n", "\n", "fv2", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "fv2", ",", "1", ")", "\n", "fv2", "=", "tf", ".", "reshape", "(", "fv2", ",", "[", "-", "1", ",", "self", ".", "cluster_size", "*", "self", ".", "feature_size", "]", ")", "\n", "fv2", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "fv2", ",", "1", ")", "\n", "\n", "fv1", "=", "tf", ".", "subtract", "(", "fv1", ",", "a", ")", "\n", "fv1", "=", "tf", ".", "divide", "(", "fv1", ",", "covar_weights", ")", "\n", "\n", "fv1", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "fv1", ",", "1", ")", "\n", "fv1", "=", "tf", ".", "reshape", "(", "fv1", ",", "[", "-", "1", ",", "self", ".", "cluster_size", "*", "self", ".", "feature_size", "]", ")", "\n", "fv1", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "fv1", ",", "1", ")", "\n", "\n", "return", "tf", ".", "concat", "(", "[", "fv1", ",", "fv2", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.GatedDBoF.__init__": [[627, 634], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "feature_size", ",", "max_frames", ",", "cluster_size", ",", "max_pool", ",", "add_batch_norm", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "add_batch_norm", "=", "add_batch_norm", "\n", "self", ".", "cluster_size", "=", "cluster_size", "\n", "self", ".", "max_pool", "=", "max_pool", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.GatedDBoF.forward": [[635, 710], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal", "tensorflow.random_normal", "tensorflow.random_normal", "tensorflow.random_normal", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "reshaped_input", ")", ":", "\n", "\n", "        ", "feature_size", "=", "self", ".", "feature_size", "\n", "cluster_size", "=", "self", ".", "cluster_size", "\n", "add_batch_norm", "=", "self", ".", "add_batch_norm", "\n", "max_frames", "=", "self", ".", "max_frames", "\n", "is_training", "=", "self", ".", "is_training", "\n", "max_pool", "=", "self", ".", "max_pool", "\n", "\n", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "feature_size", ",", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "            ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "            ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "\n", "", "activation", "=", "tf", ".", "nn", ".", "softmax", "(", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "max_frames", ",", "cluster_size", "]", ")", "\n", "\n", "activation_sum", "=", "tf", ".", "reduce_sum", "(", "activation", ",", "1", ")", "\n", "\n", "activation_max", "=", "tf", ".", "reduce_max", "(", "activation", ",", "1", ")", "\n", "activation_max", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "activation_max", ",", "1", ")", "\n", "\n", "dim_red", "=", "tf", ".", "get_variable", "(", "\"dim_red\"", ",", "\n", "[", "cluster_size", ",", "feature_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "\n", "cluster_weights_2", "=", "tf", ".", "get_variable", "(", "\"cluster_weights_2\"", ",", "\n", "[", "feature_size", ",", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights_2\"", ",", "cluster_weights_2", ")", "\n", "\n", "activation", "=", "tf", ".", "matmul", "(", "activation_max", ",", "dim_red", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "activation", ",", "cluster_weights_2", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "            ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"cluster_bn_2\"", ")", "\n", "", "else", ":", "\n", "            ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases_2\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases_2\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "\n", "", "activation", "=", "tf", ".", "sigmoid", "(", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "multiply", "(", "activation", ",", "activation_sum", ")", "\n", "activation", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "activation", ",", "1", ")", "\n", "\n", "return", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.SoftDBoF.__init__": [[713, 720], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "feature_size", ",", "max_frames", ",", "cluster_size", ",", "max_pool", ",", "add_batch_norm", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "feature_size", "=", "feature_size", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "add_batch_norm", "=", "add_batch_norm", "\n", "self", ".", "cluster_size", "=", "cluster_size", "\n", "self", ".", "max_pool", "=", "max_pool", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.SoftDBoF.forward": [[721, 767], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.concat", "tensorflow.concat", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal", "tensorflow.random_normal", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "reshaped_input", ")", ":", "\n", "\n", "        ", "feature_size", "=", "self", ".", "feature_size", "\n", "cluster_size", "=", "self", ".", "cluster_size", "\n", "add_batch_norm", "=", "self", ".", "add_batch_norm", "\n", "max_frames", "=", "self", ".", "max_frames", "\n", "is_training", "=", "self", ".", "is_training", "\n", "max_pool", "=", "self", ".", "max_pool", "\n", "\n", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "feature_size", ",", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "            ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "fused", "=", "False", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "            ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "\n", "", "activation", "=", "tf", ".", "nn", ".", "softmax", "(", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "max_frames", ",", "cluster_size", "]", ")", "\n", "\n", "activation_sum", "=", "tf", ".", "reduce_sum", "(", "activation", ",", "1", ")", "\n", "activation_sum", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "activation_sum", ",", "1", ")", "\n", "\n", "if", "max_pool", ":", "\n", "            ", "activation_max", "=", "tf", ".", "reduce_max", "(", "activation", ",", "1", ")", "\n", "activation_max", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "activation_max", ",", "1", ")", "\n", "activation", "=", "tf", ".", "concat", "(", "[", "activation_sum", ",", "activation_max", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "activation", "=", "activation_sum", "\n", "\n", "", "return", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.SoftDbofModelLF.create_model": [[788, 879], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "devel_models.SoftDBoF", "devel_models.SoftDBoF", "tensorflow.concat", "tensorflow.concat", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_utils.SampleRandomFrames", "model_utils.SampleRandomSequence", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.variable_scope", "tensorflow.variable_scope", "devel_models.SoftDBoF.forward", "tensorflow.variable_scope", "tensorflow.variable_scope", "devel_models.SoftDBoF.forward", "tensorflow.concat.get_shape().as_list", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.concat.get_shape", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomSequence", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_frames", ",", "\n", "iterations", "=", "None", ",", "\n", "add_batch_norm", "=", "None", ",", "\n", "sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "        ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "dbof_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "dbof_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "dbof_hidden_size", "\n", "fc_dimred", "=", "FLAGS", ".", "fc_dimred", "\n", "relu", "=", "FLAGS", ".", "dbof_relu", "\n", "max_pool", "=", "FLAGS", ".", "softdbof_maxpool", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "random_frames", ":", "\n", "            ", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "            ", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"input_hist\"", ",", "reshaped_input", ")", "\n", "\n", "video_Dbof", "=", "SoftDBoF", "(", "1024", ",", "max_frames", ",", "cluster_size", ",", "max_pool", ",", "add_batch_norm", ",", "is_training", ")", "\n", "audio_Dbof", "=", "SoftDBoF", "(", "128", ",", "max_frames", ",", "cluster_size", "/", "8", ",", "max_pool", ",", "add_batch_norm", ",", "is_training", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "            ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"video_DBOF\"", ")", ":", "\n", "            ", "dbof_video", "=", "video_Dbof", ".", "forward", "(", "reshaped_input", "[", ":", ",", "0", ":", "1024", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"audio_DBOF\"", ")", ":", "\n", "            ", "dbof_audio", "=", "audio_Dbof", ".", "forward", "(", "reshaped_input", "[", ":", ",", "1024", ":", "]", ")", "\n", "\n", "", "dbof", "=", "tf", ".", "concat", "(", "[", "dbof_video", ",", "dbof_audio", "]", ",", "1", ")", "\n", "\n", "dbof_dim", "=", "dbof", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "if", "fc_dimred", ":", "\n", "            ", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\"hidden1_weights\"", ",", "\n", "[", "dbof_dim", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_weights\"", ",", "hidden1_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "dbof", ",", "hidden1_weights", ")", "\n", "\n", "if", "add_batch_norm", "and", "relu", ":", "\n", "                ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "", "else", ":", "\n", "                ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\"hidden1_biases\"", ",", "\n", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "\n", "", "if", "relu", ":", "\n", "                ", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_output\"", ",", "activation", ")", "\n", "", "else", ":", "\n", "            ", "activation", "=", "dbof", "\n", "\n", "", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "is_training", "=", "is_training", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.devel_models.GatedDbofModelLF.create_model": [[900, 991], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "devel_models.GatedDBoF", "devel_models.SoftDBoF", "tensorflow.concat", "tensorflow.concat", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_utils.SampleRandomFrames", "model_utils.SampleRandomSequence", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.variable_scope", "tensorflow.variable_scope", "devel_models.GatedDBoF.forward", "tensorflow.variable_scope", "tensorflow.variable_scope", "devel_models.SoftDBoF.forward", "tensorflow.concat.get_shape().as_list", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.concat.get_shape", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomSequence", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_frames", ",", "\n", "iterations", "=", "None", ",", "\n", "add_batch_norm", "=", "None", ",", "\n", "sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "        ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "dbof_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "dbof_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "dbof_hidden_size", "\n", "fc_dimred", "=", "FLAGS", ".", "fc_dimred", "\n", "relu", "=", "FLAGS", ".", "dbof_relu", "\n", "max_pool", "=", "FLAGS", ".", "softdbof_maxpool", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "random_frames", ":", "\n", "            ", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "            ", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"input_hist\"", ",", "reshaped_input", ")", "\n", "\n", "video_Dbof", "=", "GatedDBoF", "(", "1024", ",", "max_frames", ",", "cluster_size", ",", "max_pool", ",", "add_batch_norm", ",", "is_training", ")", "\n", "audio_Dbof", "=", "SoftDBoF", "(", "128", ",", "max_frames", ",", "cluster_size", "/", "8", ",", "max_pool", ",", "add_batch_norm", ",", "is_training", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "            ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"video_DBOF\"", ")", ":", "\n", "            ", "dbof_video", "=", "video_Dbof", ".", "forward", "(", "reshaped_input", "[", ":", ",", "0", ":", "1024", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"audio_DBOF\"", ")", ":", "\n", "            ", "dbof_audio", "=", "audio_Dbof", ".", "forward", "(", "reshaped_input", "[", ":", ",", "1024", ":", "]", ")", "\n", "\n", "", "dbof", "=", "tf", ".", "concat", "(", "[", "dbof_video", ",", "dbof_audio", "]", ",", "1", ")", "\n", "\n", "dbof_dim", "=", "dbof", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "if", "fc_dimred", ":", "\n", "            ", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\"hidden1_weights\"", ",", "\n", "[", "dbof_dim", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_weights\"", ",", "hidden1_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "dbof", ",", "hidden1_weights", ")", "\n", "\n", "if", "add_batch_norm", "and", "relu", ":", "\n", "                ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "fused", "=", "False", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "", "else", ":", "\n", "                ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\"hidden1_biases\"", ",", "\n", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "\n", "", "if", "relu", ":", "\n", "                ", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_output\"", ",", "activation", ")", "\n", "", "else", ":", "\n", "            ", "activation", "=", "dbof", "\n", "\n", "", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "is_training", "=", "is_training", ",", "\n", "**", "unused_params", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_localization.BiLSTM_model.__init__": [[118, 129], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.2_train_videolevel_keras.YT8MSequence.__init__"], ["def", "__init__", "(", "self", ",", "in_shape", "=", "1152", ",", "hidden_size", "=", "256", ",", "max_len", "=", "300", ",", "embedd_size", "=", "32", ")", ":", "\n", "        ", "super", "(", "BiLSTM_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "in_shape", "+", "embedd_size", ",", "hidden_size", ",", "\n", "batch_first", "=", "True", ",", "num_layers", "=", "2", ",", "\n", "bidirectional", "=", "True", ")", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "1", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "1", ")", "\n", "self", ".", "embed", "=", "torch", ".", "nn", ".", "Embedding", "(", "1000", ",", "embedd_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_localization.BiLSTM_model.forward": [[130, 142], ["inference_localization.BiLSTM_model.embed", "torch.transpose.view().repeat", "torch.transpose.view().repeat", "torch.transpose.view().repeat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "inference_localization.BiLSTM_model.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "inference_localization.BiLSTM_model.sigmoid", "torch.transpose.view", "torch.transpose.view", "torch.transpose.view", "inference_localization.BiLSTM_model.linear().squeeze", "inference_localization.BiLSTM_model.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "input_lengths", ",", "mask", ",", "embeddings", ")", ":", "\n", "        ", "ebedd", "=", "self", ".", "embed", "(", "embeddings", ")", "\n", "ebedd", "=", "ebedd", ".", "view", "(", "ebedd", ".", "shape", "[", "0", "]", ",", "ebedd", ".", "shape", "[", "1", "]", ",", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "300", ")", "\n", "ebedd", "=", "torch", ".", "transpose", "(", "ebedd", ",", "1", ",", "2", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "ebedd", "]", ",", "dim", "=", "2", ")", "\n", "\n", "x", "=", "pack_padded_sequence", "(", "x", ",", "input_lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "\n", "out", "=", "self", ".", "lstm", "(", "x", ")", "\n", "unpacked", ",", "_", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "out", "[", "0", "]", ",", "batch_first", "=", "True", ",", "total_length", "=", "self", ".", "max_len", ")", "\n", "return", "self", ".", "sigmoid", "(", "self", ".", "linear", "(", "unpacked", ")", ".", "squeeze", "(", ")", ")", "*", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_localization.find_class_by_name": [[144, 148], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_localization.format_lines": [[150, 164], ["len", "range", "sorted", "numpy.argpartition", "video_ids[].decode"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "predictions", ",", "top_k", ",", "whitelisted_cls_mask", "=", "None", ")", ":", "\n", "  ", "\"\"\"Create an information line the submission file.\"\"\"", "\n", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "video_prediction", "=", "predictions", "[", "video_index", "]", "\n", "if", "whitelisted_cls_mask", "is", "not", "None", ":", "\n", "# Whitelist classes.", "\n", "      ", "video_prediction", "*=", "whitelisted_cls_mask", "\n", "", "top_indices", "=", "np", ".", "argpartition", "(", "video_prediction", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "\"utf-8\"", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\n", "\"%i %g\"", "%", "(", "label", ",", "score", ")", "for", "(", "label", ",", "score", ")", "in", "line", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_localization.get_input_data_tensors": [[166, 205], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "input_data_dict", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "\n", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "video_id_batch", "=", "input_data_dict", "[", "\"video_ids\"", "]", "\n", "video_batch", "=", "input_data_dict", "[", "\"video_matrix\"", "]", "\n", "num_frames_batch", "=", "input_data_dict", "[", "\"num_frames\"", "]", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_localization.build_data_providers": [[207, 219], ["inference_localization.get_input_data_tensors"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.get_input_data_tensors"], ["", "", "def", "build_data_providers", "(", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "input_data_dict", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_readers", "=", "num_readers", ")", ")", "\n", "return", "input_data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_localization.inference": [[220, 319], ["inference_localization.build_data_providers", "tensorflow.Session", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "models[].load_state_dict", "models[].cuda", "models[].eval", "tf.train.Coordinator.join", "sess.close", "readers.YT8MValFrameFeatureReader", "list", "init_op_list.append", "list", "init_op_list.append", "inference_localization.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.build_data_providers", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run"], ["", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "\n", "top_k", ")", ":", "\n", "  ", "\"\"\"Inference function.\"\"\"", "\n", "all_preds", "=", "[", "]", "\n", "all_ids", "=", "[", "]", "\n", "\n", "data_dict", "=", "build_data_providers", "(", "reader", "=", "readers", ".", "YT8MValFrameFeatureReader", "(", "label_presence", "=", "True", ")", ",", "\n", "train_data_pattern", "=", "data_pattern", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "1", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ":", "\n", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "    ", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "\n", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "\n", "# Torch model setup", "\n", "torch", ".", "cuda", ".", "set_device", "(", "FLAGS", ".", "device", ")", "\n", "# models = [BiLSTM_model(hidden_size=256) for i in range(5)]", "\n", "models", "=", "[", "BiLSTM_model", "(", "hidden_size", "=", "256", ")", "]", "\n", "#for i, model in enumerate(models):", "\n", "# model.load_state_dict(torch.load(\"/mnt/4tbyoutube/model/torched_masking_unlabaled/torch_model_3epochs_256hidden_run{}.pth\".format(i+1)))", "\n", "models", "[", "0", "]", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"/mnt/4tbyoutube/shared/torched_embedd/torch_model_3epochs_256hidden.pth\"", ")", ")", "\n", "models", "[", "0", "]", ".", "cuda", "(", "FLAGS", ".", "device", ")", "\n", "models", "[", "0", "]", ".", "eval", "(", ")", "\n", "\n", "num_examples_processed", "=", "0", "\n", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "\n", "        ", "data", "=", "sess", ".", "run", "(", "data_dict", ")", "\n", "\n", "x", "=", "data", "[", "1", "]", "\n", "x_len", "=", "data", "[", "2", "]", "\n", "x_ids", "=", "data", "[", "0", "]", "\n", "\n", "# Preprocess the sequences", "\n", "soder", "=", "np", ".", "argsort", "(", "x_len", ")", "[", ":", ":", "-", "1", "]", "\n", "x", "=", "x", "[", "soder", "]", "\n", "x_len", "=", "x_len", "[", "soder", "]", "\n", "x_ids", "=", "x_ids", "[", "soder", "]", "\n", "mask", "=", "np", ".", "zeros", "(", "(", "x", ".", "shape", "[", "0", "]", ",", "300", ")", ",", "np", ".", "bool", ")", "\n", "\n", "embedds", "=", "torch", ".", "zeros", "(", "x_len", ".", "shape", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "cuda", "(", "FLAGS", ".", "device", ")", "+", "FLAGS", ".", "embedd", "\n", "\n", "for", "i", ",", "slen", "in", "enumerate", "(", "x_len", ")", ":", "\n", "            ", "mask", "[", "i", ",", ":", "slen", "]", "=", "1", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "x_input", "=", "torch", ".", "tensor", "(", "x", ",", "device", "=", "'cuda:{}'", ".", "format", "(", "FLAGS", ".", "device", ")", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "mask", ",", "device", "=", "'cuda:{}'", ".", "format", "(", "FLAGS", ".", "device", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "predictions_val", "=", "np", ".", "mean", "(", "[", "model", ".", "forward", "(", "x_input", ",", "x_len", ",", "mask", ",", "embedds", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "model", "in", "models", "]", ",", "axis", "=", "0", ")", "\n", "# predictions_val = model.forward(x_input, x_len, mask).cpu().numpy()", "\n", "\n", "", "all_preds", ".", "append", "(", "predictions_val", ")", "\n", "all_ids", ".", "append", "(", "x_ids", ")", "\n", "\n", "num_examples_processed", "+=", "x", ".", "shape", "[", "0", "]", "\n", "logging", ".", "info", "(", "\"Processed: \"", "+", "str", "(", "num_examples_processed", ")", ")", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "      ", "logging", ".", "info", "(", "\"Done with inference. The output file was written to \"", "+", "FLAGS", ".", "prediction_file", ")", "\n", "", "finally", ":", "\n", "      ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "all_preds", "=", "np", ".", "concatenate", "(", "all_preds", ",", "axis", "=", "0", ")", "\n", "all_ids", "=", "np", ".", "concatenate", "(", "all_ids", ",", "axis", "=", "0", ")", "\n", "np", ".", "save", "(", "FLAGS", ".", "prediction_file", "+", "'_{}_preds.npy'", ".", "format", "(", "FLAGS", ".", "embedd", ")", ",", "all_preds", ")", "\n", "np", ".", "save", "(", "FLAGS", ".", "prediction_file", "+", "'_{}_ids.npy'", ".", "format", "(", "FLAGS", ".", "embedd", ")", ",", "all_ids", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_localization.main": [[321, 330], ["tensorflow.logging.set_verbosity", "inference_localization.inference", "ValueError"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_direct.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "if", "not", "FLAGS", ".", "input_data_pattern", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "None", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomSequence": [[22, 48], ["tensorflow.tile", "tensorflow.maximum", "tensorflow.cast", "tensorflow.minimum", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.random_uniform", "tensorflow.cast", "tensorflow.range"], "function", ["None"], ["def", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random sequence of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index_offset", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "num_samples", ")", ",", "0", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "max_start_frame_index", "=", "tf", ".", "maximum", "(", "num_frames", "-", "num_samples", ",", "0", ")", "\n", "start_frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "1", "]", ")", ",", "\n", "tf", ".", "cast", "(", "max_start_frame_index", "+", "1", ",", "tf", ".", "float32", ")", ")", ",", "tf", ".", "int32", ")", "\n", "frame_index", "=", "tf", ".", "minimum", "(", "start_frame_index", "+", "frame_index_offset", ",", "\n", "tf", ".", "cast", "(", "num_frames", "-", "1", ",", "tf", ".", "int32", ")", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.SampleRandomFrames": [[50, 70], ["tensorflow.cast", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.multiply", "tensorflow.expand_dims", "tensorflow.random_uniform", "tensorflow.tile", "tensorflow.range", "tensorflow.cast"], "function", ["None"], ["", "def", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random set of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "num_samples", "]", ")", ",", "\n", "tf", ".", "tile", "(", "tf", ".", "cast", "(", "num_frames", ",", "tf", ".", "float32", ")", ",", "[", "1", ",", "num_samples", "]", ")", ")", ",", "tf", ".", "int32", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.model_utils.FramePooling": [[72, 97], ["tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reshape", "ValueError", "frames.shape_as_list"], "function", ["None"], ["", "def", "FramePooling", "(", "frames", ",", "method", ",", "**", "unused_params", ")", ":", "\n", "  ", "\"\"\"Pools over the frames of a video.\n\n  Args:\n    frames: A tensor with shape [batch_size, num_frames, feature_size].\n    method: \"average\", \"max\", \"attention\", or \"none\".\n\n  Returns:\n    A tensor with shape [batch_size, feature_size] for average, max, or\n    attention pooling. A tensor with shape [batch_size*num_frames, feature_size]\n    for none pooling.\n\n  Raises:\n    ValueError: if method is other than \"average\", \"max\", \"attention\", or\n    \"none\".\n  \"\"\"", "\n", "if", "method", "==", "\"average\"", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"max\"", ":", "\n", "    ", "return", "tf", ".", "reduce_max", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"none\"", ":", "\n", "    ", "feature_size", "=", "frames", ".", "shape_as_list", "(", ")", "[", "2", "]", "\n", "return", "tf", ".", "reshape", "(", "frames", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unrecognized pooling method: %s\"", "%", "method", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_direct.format_lines": [[83, 97], ["len", "range", "sorted", "numpy.argpartition", "video_ids[].decode"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "predictions", ",", "top_k", ",", "whitelisted_cls_mask", "=", "None", ")", ":", "\n", "  ", "\"\"\"Create an information line the submission file.\"\"\"", "\n", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "video_prediction", "=", "predictions", "[", "video_index", "]", "\n", "if", "whitelisted_cls_mask", "is", "not", "None", ":", "\n", "# Whitelist classes.", "\n", "      ", "video_prediction", "*=", "whitelisted_cls_mask", "\n", "", "top_indices", "=", "np", ".", "argpartition", "(", "video_prediction", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "\"utf-8\"", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\n", "\"%i %g\"", "%", "(", "label", ",", "score", ")", "for", "(", "label", ",", "score", ")", "in", "line", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_direct.find_class_by_name": [[99, 103], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_direct.get_input_data_tensors": [[104, 143], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "input_data_dict", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "\n", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "video_id_batch", "=", "input_data_dict", "[", "\"video_ids\"", "]", "\n", "video_batch", "=", "input_data_dict", "[", "\"video_matrix\"", "]", "\n", "num_frames_batch", "=", "input_data_dict", "[", "\"num_frames\"", "]", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_direct.get_segments": [[145, 179], ["batch_video_mtx.reshape", "frame_bags[].reshape", "numpy.arange", "num_segments.reshape", "numpy.tile", "numpy.tile", "numpy.stack().reshape", "numpy.arange", "numpy.arange", "numpy.stack", "segment_mask.reshape"], "function", ["None"], ["", "", "def", "get_segments", "(", "batch_video_mtx", ",", "batch_num_frames", ",", "segment_size", ")", ":", "\n", "  ", "\"\"\"Get segment-level inputs from frame-level features.\"\"\"", "\n", "video_batch_size", "=", "batch_video_mtx", ".", "shape", "[", "0", "]", "\n", "max_frame", "=", "batch_video_mtx", ".", "shape", "[", "1", "]", "\n", "feature_dim", "=", "batch_video_mtx", ".", "shape", "[", "-", "1", "]", "\n", "padded_segment_sizes", "=", "(", "batch_num_frames", "+", "segment_size", "-", "1", ")", "//", "segment_size", "\n", "padded_segment_sizes", "*=", "segment_size", "\n", "segment_mask", "=", "(", "\n", "0", "<", "(", "padded_segment_sizes", "[", ":", ",", "np", ".", "newaxis", "]", "-", "np", ".", "arange", "(", "0", ",", "max_frame", ")", ")", ")", "\n", "\n", "# Segment bags.", "\n", "frame_bags", "=", "batch_video_mtx", ".", "reshape", "(", "(", "-", "1", ",", "feature_dim", ")", ")", "\n", "segment_frames", "=", "frame_bags", "[", "segment_mask", ".", "reshape", "(", "-", "1", ")", "]", ".", "reshape", "(", "\n", "(", "-", "1", ",", "segment_size", ",", "feature_dim", ")", ")", "\n", "\n", "# Segment num frames.", "\n", "segment_start_times", "=", "np", ".", "arange", "(", "0", ",", "max_frame", ",", "segment_size", ")", "\n", "num_segments", "=", "batch_num_frames", "[", ":", ",", "np", ".", "newaxis", "]", "-", "segment_start_times", "\n", "num_segment_bags", "=", "num_segments", ".", "reshape", "(", "(", "-", "1", ")", ")", "\n", "valid_segment_mask", "=", "num_segment_bags", ">", "0", "\n", "segment_num_frames", "=", "num_segment_bags", "[", "valid_segment_mask", "]", "\n", "segment_num_frames", "[", "segment_num_frames", ">", "segment_size", "]", "=", "segment_size", "\n", "\n", "max_segment_num", "=", "(", "max_frame", "+", "segment_size", "-", "1", ")", "//", "segment_size", "\n", "video_idxs", "=", "np", ".", "tile", "(", "\n", "np", ".", "arange", "(", "0", ",", "video_batch_size", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "[", "1", ",", "max_segment_num", "]", ")", "\n", "segment_idxs", "=", "np", ".", "tile", "(", "segment_start_times", ",", "[", "video_batch_size", ",", "1", "]", ")", "\n", "idx_bags", "=", "np", ".", "stack", "(", "[", "video_idxs", ",", "segment_idxs", "]", ",", "axis", "=", "-", "1", ")", ".", "reshape", "(", "(", "-", "1", ",", "2", ")", ")", "\n", "video_segment_ids", "=", "idx_bags", "[", "valid_segment_mask", "]", "\n", "\n", "return", "{", "\n", "\"video_batch\"", ":", "segment_frames", ",", "\n", "\"num_frames_batch\"", ":", "segment_num_frames", ",", "\n", "\"video_segment_ids\"", ":", "video_segment_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_direct.inference": [[182, 370], ["tensorflow.Session", "tensorflow.gfile.Open", "inference_direct.get_input_data_tensors", "tensorflow.placeholder", "tensorflow.nn.l2_normalize", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "tempfile.NamedTemporaryFile.write", "set().union", "os.path.join", "tensorflow.python.pywrap_tensorflow.NewCheckpointReader", "sess.run", "tensorflow.logging.info", "tf.train.Coordinator.join", "sess.close", "inference_direct.find_class_by_name", "len", "tensorflow.device", "list", "init_op_list.append", "inference_direct.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.get_input_data_tensors", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.find_class_by_name"], ["", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "\n", "top_k", ")", ":", "\n", "  ", "\"\"\"Inference function.\"\"\"", "\n", "all_preds", "=", "[", "]", "\n", "all_ids", "=", "[", "]", "\n", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\n", "\"w+\"", ")", "as", "out_file", ":", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "=", "get_input_data_tensors", "(", "\n", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "\n", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "# Normalize input features.", "\n", "feature_dim", "=", "len", "(", "video_batch", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "input_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "5", ",", "1152", ")", ")", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "input_ph", ",", "feature_dim", ")", "\n", "with", "tf", ".", "device", "(", "\"/device:GPU:0\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "            ", "result", "=", "model", ".", "create_model", "(", "\n", "model_input", ",", "\n", "num_frames", "=", "num_frames_batch", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "is_training", "=", "False", ")", "\n", "", "", "predictions_tensor", "=", "result", "[", "'predictions'", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "\n", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "whitelisted_cls_mask", "=", "None", "\n", "if", "FLAGS", ".", "segment_labels", ":", "\n", "      ", "final_out_file", "=", "out_file", "\n", "out_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "logging", ".", "info", "(", "\"Segment temp prediction output will be written to temp file: %s\"", ",", "out_file", ".", "name", ")", "\n", "if", "FLAGS", ".", "segment_label_ids_file", ":", "\n", "        ", "whitelisted_cls_mask", "=", "np", ".", "zeros", "(", "(", "predictions_tensor", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "with", "open", "(", "FLAGS", ".", "segment_label_ids_file", ")", "as", "fobj", ":", "\n", "          ", "for", "line", "in", "fobj", ":", "\n", "            ", "try", ":", "\n", "              ", "cls_id", "=", "int", "(", "line", ")", "\n", "whitelisted_cls_mask", "[", "cls_id", "]", "=", "1.", "\n", "", "except", "ValueError", ":", "\n", "              ", "continue", "\n", "\n", "", "", "", "whitelisted_bool", "=", "whitelisted_cls_mask", ".", "astype", "(", "np", ".", "bool", ")", "\n", "", "", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "\n", "model_vars", "=", "set", "(", "tf", ".", "trainable_variables", "(", ")", ")", ".", "union", "(", "slim", ".", "get_model_variables", "(", ")", ")", "\n", "ckpt_point", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "\"model.ckpt-{}\"", ".", "format", "(", "FLAGS", ".", "checkpoint", ")", ")", "\n", "ckpt_reader", "=", "pywrap_tensorflow", ".", "NewCheckpointReader", "(", "ckpt_point", ")", "\n", "\n", "n", "=", "0", "\n", "sess", ".", "run", "(", "tf", ".", "initialize_all_variables", "(", ")", ")", "\n", "for", "orig_tensor", "in", "model_vars", ":", "\n", "        ", "n", "+=", "1", "\n", "new_vals", "=", "ckpt_reader", ".", "get_tensor", "(", "orig_tensor", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ")", "\n", "orig_tensor", ".", "load", "(", "new_vals", ",", "session", "=", "sess", ")", "\n", "", "logging", ".", "info", "(", "\"##### {} Tensors were replaced.\"", ".", "format", "(", "n", ")", ")", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "        ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", "=", "sess", ".", "run", "(", "\n", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "]", ")", "\n", "if", "FLAGS", ".", "segment_labels", ":", "\n", "          ", "results", "=", "get_segments", "(", "video_batch_val", ",", "num_frames_batch_val", ",", "5", ")", "\n", "video_segment_ids", "=", "results", "[", "\"video_segment_ids\"", "]", "\n", "video_id_batch_val", "=", "video_id_batch_val", "[", "video_segment_ids", "[", ":", ",", "0", "]", "]", "\n", "video_id_batch_val", "=", "np", ".", "array", "(", "[", "\n", "\"%s:%d\"", "%", "(", "x", ",", "y", ")", "\n", "for", "x", ",", "y", "in", "zip", "(", "video_id_batch_val", ",", "video_segment_ids", "[", ":", ",", "1", "]", ")", "\n", "]", ")", "\n", "video_batch_val", "=", "results", "[", "\"video_batch\"", "]", "\n", "num_frames_batch_val", "=", "results", "[", "\"num_frames_batch\"", "]", "\n", "if", "5", "!=", "video_batch_val", ".", "shape", "[", "1", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"max_frames mismatch. Please re-run the eval.py \"", "\n", "\"with correct segment_labels settings.\"", ")", "\n", "\n", "", "", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "\n", "feed_dict", "=", "{", "\n", "input_ph", ":", "video_batch_val", ",", "\n", "num_frames_batch", ":", "num_frames_batch_val", "\n", "}", ")", "\n", "all_preds", ".", "append", "(", "predictions_val", ".", "T", "[", "whitelisted_bool", "]", ".", "T", ")", "\n", "all_ids", ".", "append", "(", "video_id_batch_val", ")", "\n", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\n", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "if", "not", "FLAGS", ".", "prediction_file", ":", "\n", "          ", "for", "line", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ",", "\n", "whitelisted_cls_mask", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "line", ")", "\n", "", "out_file", ".", "flush", "(", ")", "\n", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "      ", "if", "not", "FLAGS", ".", "prediction_file", ":", "\n", "        ", "logging", ".", "info", "(", "\"Done with inference. The output file was written to \"", "+", "\n", "out_file", ".", "name", ")", "\n", "", "", "finally", ":", "\n", "      ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "all_preds", "=", "np", ".", "concatenate", "(", "all_preds", ",", "axis", "=", "0", ")", "\n", "all_ids", "=", "np", ".", "concatenate", "(", "all_ids", ",", "axis", "=", "0", ")", "\n", "assert", "all_preds", ".", "shape", "[", "0", "]", "==", "2062258", ",", "\"Invalid shape, you have {} elements!\"", ".", "format", "(", "all_preds", ".", "shape", "[", "0", "]", ")", "\n", "\n", "if", "FLAGS", ".", "prediction_file", ":", "\n", "          ", "np", ".", "save", "(", "FLAGS", ".", "prediction_file", "+", "'preds.npy'", ",", "all_preds", ")", "\n", "np", ".", "save", "(", "FLAGS", ".", "prediction_file", "+", "'ids.npy'", ",", "all_ids", ")", "\n", "exit", "(", ")", "\n", "\n", "", "if", "FLAGS", ".", "segment_labels", ":", "\n", "        ", "logging", ".", "info", "(", "\"Post-processing segment predictions...\"", ")", "\n", "\n", "heaps", "=", "{", "}", "\n", "out_file", ".", "seek", "(", "0", ",", "0", ")", "\n", "valid_cls", "=", "set", "(", "np", ".", "where", "(", "whitelisted_cls_mask", ")", "[", "0", "]", ")", "\n", "for", "line", "in", "out_file", ":", "\n", "            ", "segment_id", ",", "preds", "=", "line", ".", "split", "(", "\",\"", ")", "\n", "if", "segment_id", "==", "\"VideoId\"", ":", "\n", "# Skip the headline.", "\n", "                ", "continue", "\n", "", "preds", "=", "preds", ".", "split", "(", "\" \"", ")", "\n", "pred_cls_ids", "=", "[", "int", "(", "preds", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "0", ",", "len", "(", "preds", ")", ",", "2", ")", "]", "\n", "pred_cls_scores", "=", "[", "\n", "float", "(", "preds", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "1", ",", "len", "(", "preds", ")", ",", "2", ")", "\n", "]", "\n", "for", "cls", ",", "score", "in", "zip", "(", "pred_cls_ids", ",", "pred_cls_scores", ")", ":", "\n", "                ", "if", "cls", "not", "in", "valid_cls", ":", "\n", "                    ", "continue", "\n", "", "if", "cls", "not", "in", "heaps", ":", "\n", "                    ", "heaps", "[", "cls", "]", "=", "[", "]", "\n", "", "if", "len", "(", "heaps", "[", "cls", "]", ")", ">=", "FLAGS", ".", "segment_max_pred", ":", "\n", "                    ", "heapq", ".", "heappushpop", "(", "heaps", "[", "cls", "]", ",", "(", "score", ",", "segment_id", ")", ")", "\n", "", "else", ":", "\n", "                    ", "heapq", ".", "heappush", "(", "heaps", "[", "cls", "]", ",", "(", "score", ",", "segment_id", ")", ")", "\n", "", "", "", "logging", ".", "info", "(", "\"Writing sorted segment predictions to: %s\"", ",", "\n", "final_out_file", ".", "name", ")", "\n", "final_out_file", ".", "write", "(", "\"Class,Segments\\n\"", ")", "\n", "\n", "class_to_idx", "=", "{", "idx", ":", "i", "for", "i", ",", "idx", "in", "enumerate", "(", "np", ".", "where", "(", "whitelisted_cls_mask", ")", "[", "0", "]", ")", "}", "\n", "\n", "# Append to the heaps", "\n", "found_keys", "=", "list", "(", "heaps", ".", "keys", "(", ")", ")", "\n", "missing", "=", "[", "x", "for", "x", "in", "np", ".", "where", "(", "whitelisted_cls_mask", ")", "[", "0", "]", "if", "not", "x", "in", "found_keys", "]", "\n", "for", "x", "in", "missing", ":", "\n", "            ", "heaps", "[", "x", "]", "=", "[", "]", "\n", "\n", "", "for", "cls", ",", "cls_heap", "in", "tqdm", "(", "heaps", ".", "items", "(", ")", ")", ":", "\n", "            ", "cls_heap", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "# Fill up labels up to segment_max_pred", "\n", "if", "len", "(", "cls_heap", ")", "<", "FLAGS", ".", "segment_max_pred", ":", "\n", "                ", "included", "=", "set", "(", "[", "x", "[", "1", "]", "for", "x", "in", "cls_heap", "]", ")", "\n", "i", "=", "class_to_idx", "[", "cls", "]", "\n", "pred_group", "=", "all_preds", "[", ":", ",", "i", "]", "\n", "label_top_hits", "=", "all_ids", "[", "pred_group", ".", "argsort", "(", ")", "[", "-", "FLAGS", ".", "segment_max_pred", ":", "]", "[", ":", ":", "-", "1", "]", "]", "\n", "for", "label", "in", "label_top_hits", ":", "\n", "                    ", "if", "label", "not", "in", "included", ":", "\n", "                        ", "cls_heap", ".", "append", "(", "(", "0", ",", "label", ")", ")", "\n", "", "if", "len", "(", "cls_heap", ")", "==", "FLAGS", ".", "segment_max_pred", ":", "\n", "                        ", "break", "\n", "\n", "", "", "", "final_out_file", ".", "write", "(", "\"%d,%s\\n\"", "%", "\n", "(", "cls", ",", "\" \"", ".", "join", "(", "[", "x", "[", "1", "]", "for", "x", "in", "cls_heap", "]", ")", ")", ")", "\n", "\n", "", "final_out_file", ".", "close", "(", ")", "\n", "\n", "", "out_file", ".", "close", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_direct.main": [[372, 400], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "os.path.join", "inference_direct.inference", "ValueError", "ValueError", "ValueError", "os.path.isfile", "ValueError"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.inference_direct.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\"rgb,audio\"", ",", "\"1024,128\"", ")", "\n", "\n", "\n", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "if", "not", "FLAGS", ".", "output_file", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "not", "FLAGS", ".", "input_data_pattern", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "", "if", "not", "FLAGS", ".", "train_dir", ":", "\n", "    ", "raise", "ValueError", "(", "\"'train_dir' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "ckpt_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "\"model.ckpt-{}.meta\"", ".", "format", "(", "FLAGS", ".", "checkpoint", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "ckpt_file", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Checkpoint file: '{}' does not exist.\"", ".", "format", "(", "ckpt_file", ")", ")", "\n", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.LogisticModel.create_model": [[33, 55], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a logistic model.\n\n    Args:\n      model_input: 'batch' x 'num_features' matrix of input features.\n      vocab_size: The number of classes in the dataset.\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      batch_size x num_classes.\n    \"\"\"", "\n", "output", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ")", "\n", "return", "{", "\"predictions\"", ":", "output", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model": [[60, 114], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a Mixture of (Logistic) Experts model.\n\n     The model consists of a per-class softmax distribution over a\n     configurable number of logistic classifiers. One of the classifiers in the\n     mixture is not trained, and always predicts 0.\n\n    Args:\n      model_input: 'batch_size' x 'num_features' matrix of input features.\n      vocab_size: The number of classes in the dataset.\n      num_mixtures: The number of mixtures (excluding a dummy 'expert' that\n        always predicts the non-existence of an entity).\n      l2_penalty: How much to penalize the squared magnitudes of parameter\n        values.\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      batch_size x num_classes.\n    \"\"\"", "\n", "num_mixtures", "=", "num_mixtures", "or", "FLAGS", ".", "moe_num_mixtures", "\n", "\n", "gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", "*", "(", "num_mixtures", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gates\"", ")", "\n", "expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", "*", "num_mixtures", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"experts\"", ")", "\n", "\n", "gating_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "\n", "tf", ".", "reshape", "(", "\n", "gate_activations", ",", "\n", "[", "-", "1", ",", "num_mixtures", "+", "1", "]", ")", ")", "# (Batch * #Labels) x (num_mixtures + 1)", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "\n", "tf", ".", "reshape", "(", "expert_activations", ",", "\n", "[", "-", "1", ",", "num_mixtures", "]", ")", ")", "# (Batch * #Labels) x num_mixtures", "\n", "\n", "final_probabilities_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gating_distribution", "[", ":", ",", ":", "num_mixtures", "]", "*", "expert_distribution", ",", "1", ")", "\n", "final_probabilities", "=", "tf", ".", "reshape", "(", "final_probabilities_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "vocab_size", "]", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.__init__": [[403, 436], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "cluster", ",", "\n", "task", ",", "\n", "train_dir", ",", "\n", "model", ",", "\n", "reader", ",", "\n", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "\n", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed. None\n        otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "\n", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.run": [[438, 585], ["os.path.join", "tensorflow.python.lib.io.file_io.file_exists", "tensorflow.python.lib.io.file_io.file_exists", "train.Trainer.start_server_if_distributed", "train.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "train.Trainer.remove_training_directory", "os.path.exists", "os.makedirs", "json.load", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "train.task_as_string", "tensorflow.train.Supervisor.managed_session", "train.task_as_string", "tensorflow.python.lib.io.file_io.FileIO", "tensorflow.python.lib.io.file_io.FileIO", "tensorflow.logging.error", "tensorflow.logging.error", "tensorflow.logging.error", "tensorflow.logging.error", "tensorflow.logging.error", "tensorflow.logging.error", "exit", "tensorflow.python.lib.io.file_io.FileIO", "tensorflow.python.lib.io.file_io.FileIO", "fout.write", "train.Trainer.recover_model", "tensorflow.device", "tensorflow.device", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.python.pywrap_tensorflow.NewCheckpointReader", "tensorflow.python.pywrap_tensorflow.NewCheckpointReader", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "str", "str", "json.dumps", "tensorflow.Graph", "tensorflow.Graph", "train.Trainer.build_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "graph.as_default", "set().union", "tensorflow.python.pywrap_tensorflow.NewCheckpointReader.get_tensor", "orig_tensor.load", "ValueError", "train.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "train.Trainer.export_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_model_variables", "tensorflow.get_model_variables", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "set", "orig_tensor.name.split", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "train.Trainer.export_model", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "str", "str"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.recover_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.build_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.export_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.calculate_gap", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "train_dir", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "model_flags_dict", "=", "{", "\n", "\"model\"", ":", "FLAGS", ".", "model", ",", "\n", "\"feature_sizes\"", ":", "FLAGS", ".", "feature_sizes", ",", "\n", "\"feature_names\"", ":", "FLAGS", ".", "feature_names", ",", "\n", "\"frame_features\"", ":", "FLAGS", ".", "frame_features", ",", "\n", "\"label_loss\"", ":", "FLAGS", ".", "label_loss", ",", "\n", "}", "\n", "flags_json_path", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "\"model_flags.json\"", ")", "\n", "if", "file_io", ".", "file_exists", "(", "flags_json_path", ")", ":", "\n", "      ", "existing_flags", "=", "json", ".", "load", "(", "file_io", ".", "FileIO", "(", "flags_json_path", ",", "mode", "=", "\"r\"", ")", ")", "\n", "if", "existing_flags", "!=", "model_flags_dict", ":", "\n", "        ", "logging", ".", "error", "(", "\n", "\"Model flags do not match existing file %s. Please \"", "\n", "\"delete the file, change --train_dir, or pass flag \"", "\n", "\"--start_new_model\"", ",", "flags_json_path", ")", "\n", "logging", ".", "error", "(", "\"Ran model with flags: %s\"", ",", "str", "(", "model_flags_dict", ")", ")", "\n", "logging", ".", "error", "(", "\"Previously ran with flags: %s\"", ",", "str", "(", "existing_flags", ")", ")", "\n", "exit", "(", "1", ")", "\n", "", "", "else", ":", "\n", "# Write the file.", "\n", "      ", "with", "file_io", ".", "FileIO", "(", "flags_json_path", ",", "mode", "=", "\"w\"", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "json", ".", "dumps", "(", "model_flags_dict", ")", ")", "\n", "\n", "", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "      ", "if", "meta_filename", ":", "\n", "        ", "saver", "=", "self", ".", "recover_model", "(", "meta_filename", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "        ", "if", "not", "meta_filename", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "if", "FLAGS", ".", "mask", ":", "\n", "            ", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions_masked\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels_masked\"", ")", "[", "0", "]", "\n", "\n", "", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "15", "*", "60", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "if", "FLAGS", ".", "seed_weights", ":", "\n", "        ", "logging", ".", "info", "(", "\"##############################\"", ")", "\n", "logging", ".", "info", "(", "\"##### Loading existing weights.\"", ")", "\n", "logging", ".", "info", "(", "\"##############################\"", ")", "\n", "with", "graph", ".", "as_default", "(", ")", ":", "\n", "          ", "model_vars", "=", "set", "(", "tf", ".", "trainable_variables", "(", ")", ")", ".", "union", "(", "slim", ".", "get_model_variables", "(", ")", ")", "\n", "", "ckpt_reader", "=", "pywrap_tensorflow", ".", "NewCheckpointReader", "(", "FLAGS", ".", "seed_weights", ")", "\n", "\n", "n", "=", "0", "\n", "for", "orig_tensor", "in", "model_vars", ":", "\n", "          ", "n", "+=", "1", "\n", "new_vals", "=", "ckpt_reader", ".", "get_tensor", "(", "orig_tensor", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ")", "\n", "orig_tensor", ".", "load", "(", "new_vals", ",", "session", "=", "sess", ")", "\n", "", "if", "n", "==", "0", ":", "\n", "          ", "raise", "ValueError", "(", "\"Something went wrong , no seed weights were imported!\"", ")", "\n", "", "logging", ".", "info", "(", "\"###############################\"", ")", "\n", "logging", ".", "info", "(", "\"##### {} Tensors were replaced.\"", ".", "format", "(", "n", ")", ")", "\n", "logging", ".", "info", "(", "\"###############################\"", ")", "\n", "\n", "", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "10", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "\n", "predictions_val", ",", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "\n", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", ">=", "\n", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "\n", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.export_model": [[586, 593], ["saver.save"], "methods", ["None"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.start_server_if_distributed": [[595, 611], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "train.task_as_string", "train.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.start_server", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.remove_training_directory": [[612, 623], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "train.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.get_meta_filename": [[624, 643], ["tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "train.task_as_string", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "not", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No checkpoint file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.recover_model": [[644, 648], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.Trainer.build_model": [[649, 671], ["train.find_class_by_name", "train.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "train.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.find_class_by_name", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.build_graph", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "\n", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "0.25", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.ParameterServer.__init__": [[695, 706], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed. None\n        otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.ParameterServer.run": [[707, 714], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "start_server.join", "train.task_as_string", "train.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.start_server", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.validate_class_name": [[135, 162], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages (e.g.\n      'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\n", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.get_input_data_tensors": [[164, 207], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None' to\n      run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"#### Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "10", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.find_class_by_name": [[209, 213], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.build_graph": [[215, 399], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "train.get_input_data_tensors", "print", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "os.path.dirname", "numpy.zeros().astype", "pandas.read_csv", "tensorflow.convert_to_tensor", "tensorflow.transpose", "tower_predictions_masked.append", "tensorflow.transpose", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "os.path.abspath", "os.path.join", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.concat", "tensorflow.cast", "tensorflow.control_dependencies", "tensorflow.no_op", "numpy.zeros", "numpy.array", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.control_dependencies", "tensorflow.identity", "tensorflow.boolean_mask", "tensorflow.transpose"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.get_input_data_tensors", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.combine_gradients", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.video_level_models.MoeModel.create_model", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit from\n      BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n      from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n      compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an unlimited\n      number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "\"GPU\"", "]", "\n", "gpus", "=", "gpus", "[", ":", "FLAGS", ".", "num_gpu", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "\"/device:GPU:%d\"", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "\"/cpu:%d\"", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"learning_rate\"", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "input_data_dict", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "model_input_raw", "=", "input_data_dict", "[", "\"video_matrix\"", "]", "\n", "labels_batch", "=", "input_data_dict", "[", "\"labels\"", "]", "\n", "num_frames", "=", "input_data_dict", "[", "\"num_frames\"", "]", "\n", "print", "(", "\"model_input_shape, \"", ",", "model_input_raw", ".", "shape", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "\n", "tower_predictions_masked", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "\n", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ")", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "if", "FLAGS", ".", "mask", ":", "\n", "            ", "logging", ".", "info", "(", "\"###############################\"", ")", "\n", "logging", ".", "info", "(", "\"##### Masking predictions. ####\"", ")", "\n", "logging", ".", "info", "(", "\"###############################\"", ")", "\n", "basedir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "predictions", ".", "shape", "[", "1", "]", ".", "value", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "valids", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "basedir", ",", "'segment_label_ids.csv'", ")", ")", "\n", "mask", "[", "np", ".", "array", "(", "valids", "[", "\"Index\"", "]", ")", "]", "=", "True", "\n", "\n", "mask_tf", "=", "tf", ".", "convert_to_tensor", "(", "mask", ")", "# Convert mask to TF.", "\n", "predictions", "=", "tf", ".", "transpose", "(", "tf", ".", "boolean_mask", "(", "tf", ".", "transpose", "(", "predictions", ")", ",", "mask_tf", ")", ")", "\n", "tower_predictions_masked", ".", "append", "(", "predictions", ")", "\n", "\n", "tower_labels", "[", "i", "]", "=", "tf", ".", "transpose", "(", "tf", ".", "boolean_mask", "(", "tf", ".", "transpose", "(", "tower_labels", "[", "i", "]", ")", ",", "mask_tf", ")", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"predictions_masked\"", ",", "tf", ".", "concat", "(", "tower_predictions_masked", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels_masked\"", ",", "tf", ".", "cast", "(", "tf", ".", "transpose", "(", "tf", ".", "boolean_mask", "(", "tf", ".", "transpose", "(", "labels_batch", ")", ",", "\n", "mask_tf", ")", ")", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "\n", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "\n", "final_loss", ",", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"clip_grads\"", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "\n", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "\n", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.get_reader": [[673, 690], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MValFrameFeatureReader", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "if", "FLAGS", ".", "full_seq", "and", "FLAGS", ".", "segment_labels", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MValFrameFeatureReader", "(", "frame_it", "=", "True", ")", "\n", "\n", "", "elif", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ",", "\n", "segment_labels", "=", "FLAGS", ".", "segment_labels", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.start_server": [[716, 738], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "train.task_as_string", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed. None\n      otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.task_as_string": [[740, 742], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.main": [[744, 782], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "train.task_as_string", "train.get_reader", "train.Trainer.run", "train.find_class_by_name", "train.ParameterServer.run", "ValueError", "os.path.isfile", "ValueError", "train.Trainer", "train.ParameterServer", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train.get_reader", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.find_class_by_name", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "task_as_string", "(", "task", ")", ",", "\n", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "if", "FLAGS", ".", "seed_weights", ":", "\n", "        ", "ckpt_file", "=", "FLAGS", ".", "seed_weights", "+", "\".meta\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "ckpt_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Checkpoint file: '{}' does not exist.\"", ".", "format", "(", "ckpt_file", ")", ")", "\n", "\n", "", "", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "None", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.__init__": [[147, 169], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ",", "top_k", ",", "top_n", ")", ":", "\n", "    ", "\"\"\"Construct an EvaluationMetrics object to store the evaluation metrics.\n\n    Args:\n      num_class: A positive integer specifying the number of classes.\n      top_k: A positive integer specifying how many predictions are considered\n        per video.\n      top_n: A positive Integer specifying the average precision at n, or None\n        to use all provided data points.\n\n    Raises:\n      ValueError: An error occurred when MeanAveragePrecisionCalculator cannot\n        not be constructed.\n    \"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", "=", "map_calculator", ".", "MeanAveragePrecisionCalculator", "(", "\n", "num_class", ",", "top_n", "=", "top_n", ")", "\n", "self", ".", "global_ap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "num_examples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.accumulate": [[170, 206], ["eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "numpy.mean", "eval_util.top_k_by_class", "eval_util.EvaluationMetrics.map_calculator.accumulate", "eval_util.EvaluationMetrics.global_ap_calculator.accumulate", "eval_util.flatten", "eval_util.flatten", "sum"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.flatten", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.flatten"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "labels", ",", "loss", ")", ":", "\n", "    ", "\"\"\"Accumulate the metrics calculated locally for this mini-batch.\n\n    Args:\n      predictions: A numpy matrix containing the outputs of the model.\n        Dimensions are 'batch' x 'num_classes'.\n      labels: A numpy matrix containing the ground truth labels. Dimensions are\n        'batch' x 'num_classes'.\n      loss: A numpy array containing the loss for each sample.\n\n    Returns:\n      dictionary: A dictionary storing the metrics for the mini-batch.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n        does not match.\n    \"\"\"", "\n", "batch_size", "=", "labels", ".", "shape", "[", "0", "]", "\n", "mean_hit_at_one", "=", "calculate_hit_at_one", "(", "predictions", ",", "labels", ")", "\n", "mean_perr", "=", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "labels", ")", "\n", "mean_loss", "=", "numpy", ".", "mean", "(", "loss", ")", "\n", "\n", "# Take the top 20 predictions.", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "\n", "predictions", ",", "labels", ",", "self", ".", "top_k", ")", "\n", "self", ".", "map_calculator", ".", "accumulate", "(", "sparse_predictions", ",", "sparse_labels", ",", "\n", "num_positives", ")", "\n", "self", ".", "global_ap_calculator", ".", "accumulate", "(", "\n", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "\n", "self", ".", "num_examples", "+=", "batch_size", "\n", "self", ".", "sum_hit_at_one", "+=", "mean_hit_at_one", "*", "batch_size", "\n", "self", ".", "sum_perr", "+=", "mean_perr", "*", "batch_size", "\n", "self", ".", "sum_loss", "+=", "mean_loss", "*", "batch_size", "\n", "\n", "return", "{", "\"hit_at_one\"", ":", "mean_hit_at_one", ",", "\"perr\"", ":", "mean_perr", ",", "\"loss\"", ":", "mean_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get": [[207, 235], ["eval_util.EvaluationMetrics.map_calculator.peek_map_at_n", "eval_util.EvaluationMetrics.global_ap_calculator.peek_ap_at_n", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "get", "(", "self", ")", ":", "\n", "    ", "\"\"\"Calculate the evaluation metrics for the whole epoch.\n\n    Raises:\n      ValueError: If no examples were accumulated.\n\n    Returns:\n      dictionary: a dictionary storing the evaluation metrics for the epoch. The\n        dictionary has the fields: avg_hit_at_one, avg_perr, avg_loss, and\n        aps (default nan).\n    \"\"\"", "\n", "if", "self", ".", "num_examples", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"total_sample must be positive.\"", ")", "\n", "", "avg_hit_at_one", "=", "self", ".", "sum_hit_at_one", "/", "self", ".", "num_examples", "\n", "avg_perr", "=", "self", ".", "sum_perr", "/", "self", ".", "num_examples", "\n", "avg_loss", "=", "self", ".", "sum_loss", "/", "self", ".", "num_examples", "\n", "\n", "aps", "=", "self", ".", "map_calculator", ".", "peek_map_at_n", "(", ")", "\n", "gap", "=", "self", ".", "global_ap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n", "epoch_info_dict", "=", "{", "\n", "\"avg_hit_at_one\"", ":", "avg_hit_at_one", ",", "\n", "\"avg_perr\"", ":", "avg_perr", ",", "\n", "\"avg_loss\"", ":", "avg_loss", ",", "\n", "\"aps\"", ":", "aps", ",", "\n", "\"gap\"", ":", "gap", "\n", "}", "\n", "return", "epoch_info_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.clear": [[236, 244], ["eval_util.EvaluationMetrics.map_calculator.clear", "eval_util.EvaluationMetrics.global_ap_calculator.clear"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the evaluation metrics and reset the EvaluationMetrics object.\"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", ".", "clear", "(", ")", "\n", "self", ".", "global_ap_calculator", ".", "clear", "(", ")", "\n", "self", ".", "num_examples", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.flatten": [[21, 24], ["None"], "function", ["None"], ["def", "flatten", "(", "l", ")", ":", "\n", "  ", "\"\"\"Merges a list of lists into a single list. \"\"\"", "\n", "return", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.calculate_hit_at_one": [[26, 41], ["numpy.argmax", "numpy.average", "numpy.arange"], "function", ["None"], ["", "def", "calculate_hit_at_one", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the hit at one.\n\n  Args:\n    predictions: Matrix containing the outputs of the model. Dimensions are\n      'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels. Dimensions are 'batch' x\n      'num_classes'.\n\n  Returns:\n    float: The average hit at one across the entire batch.\n  \"\"\"", "\n", "top_prediction", "=", "numpy", ".", "argmax", "(", "predictions", ",", "1", ")", "\n", "hits", "=", "actuals", "[", "numpy", ".", "arange", "(", "actuals", ".", "shape", "[", "0", "]", ")", ",", "top_prediction", "]", "\n", "return", "numpy", ".", "average", "(", "hits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.calculate_precision_at_equal_recall_rate": [[43, 69], ["numpy.arange", "int", "numpy.sum", "numpy.argpartition"], "function", ["None"], ["", "def", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the PERR.\n\n  Args:\n    predictions: Matrix containing the outputs of the model. Dimensions are\n      'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels. Dimensions are 'batch' x\n      'num_classes'.\n\n  Returns:\n    float: The average precision at equal recall rate across the entire batch.\n  \"\"\"", "\n", "aggregated_precision", "=", "0.0", "\n", "num_videos", "=", "actuals", ".", "shape", "[", "0", "]", "\n", "for", "row", "in", "numpy", ".", "arange", "(", "num_videos", ")", ":", "\n", "    ", "num_labels", "=", "int", "(", "numpy", ".", "sum", "(", "actuals", "[", "row", "]", ")", ")", "\n", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "row", "]", ",", "\n", "-", "num_labels", ")", "[", "-", "num_labels", ":", "]", "\n", "item_precision", "=", "0.0", "\n", "for", "label_index", "in", "top_indices", ":", "\n", "      ", "if", "predictions", "[", "row", "]", "[", "label_index", "]", ">", "0", ":", "\n", "        ", "item_precision", "+=", "actuals", "[", "row", "]", "[", "label_index", "]", "\n", "", "", "item_precision", "/=", "top_indices", ".", "size", "\n", "aggregated_precision", "+=", "item_precision", "\n", "", "aggregated_precision", "/=", "num_videos", "\n", "return", "aggregated_precision", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.calculate_gap": [[71, 92], ["average_precision_calculator.AveragePrecisionCalculator", "eval_util.top_k_by_class", "ap_calculator.AveragePrecisionCalculator.accumulate", "ap_calculator.AveragePrecisionCalculator.peek_ap_at_n", "eval_util.flatten", "eval_util.flatten", "sum"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.flatten", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.flatten"], ["", "def", "calculate_gap", "(", "predictions", ",", "actuals", ",", "top_k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the global average precision.\n\n  Only the top_k predictions are taken for each of the videos.\n\n  Args:\n    predictions: Matrix containing the outputs of the model. Dimensions are\n      'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels. Dimensions are 'batch' x\n      'num_classes'.\n    top_k: How many predictions to use per video.\n\n  Returns:\n    float: The global average precision.\n  \"\"\"", "\n", "gap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "\n", "predictions", ",", "actuals", ",", "top_k", ")", "\n", "gap_calculator", ".", "accumulate", "(", "\n", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "return", "gap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.top_k_by_class": [[94, 130], ["min", "range", "ValueError", "prediction_triplets.extend", "out_predictions[].append", "out_labels[].append", "numpy.sum", "eval_util.top_k_triplets", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.top_k_triplets"], ["", "def", "top_k_by_class", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Extracts the top k predictions for each video, sorted by class.\n\n  Args:\n    predictions: A numpy matrix containing the outputs of the model. Dimensions\n      are 'batch' x 'num_classes'.\n    k: the top k non-zero entries to preserve in each prediction.\n\n  Returns:\n    A tuple (predictions,labels, true_positives). 'predictions' and 'labels'\n    are lists of lists of floats. 'true_positives' is a list of scalars. The\n    length of the lists are equal to the number of classes. The entries in the\n    predictions variable are probability predictions, and\n    the corresponding entries in the labels variable are the ground truth for\n    those predictions. The entries in 'true_positives' are the number of true\n    positives for each class in the ground truth.\n\n  Raises:\n    ValueError: An error occurred when the k is not a positive integer.\n  \"\"\"", "\n", "if", "k", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"k must be a positive integer.\"", ")", "\n", "", "k", "=", "min", "(", "k", ",", "predictions", ".", "shape", "[", "1", "]", ")", "\n", "num_classes", "=", "predictions", ".", "shape", "[", "1", "]", "\n", "prediction_triplets", "=", "[", "]", "\n", "for", "video_index", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "prediction_triplets", ".", "extend", "(", "\n", "top_k_triplets", "(", "predictions", "[", "video_index", "]", ",", "labels", "[", "video_index", "]", ",", "k", ")", ")", "\n", "", "out_predictions", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_classes", ")", "]", "\n", "out_labels", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_classes", ")", "]", "\n", "for", "triplet", "in", "prediction_triplets", ":", "\n", "    ", "out_predictions", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "1", "]", ")", "\n", "out_labels", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "2", "]", ")", "\n", "", "out_true_positives", "=", "[", "numpy", ".", "sum", "(", "labels", "[", ":", ",", "i", "]", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "\n", "return", "out_predictions", ",", "out_labels", ",", "out_true_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.top_k_triplets": [[132, 142], ["len", "min", "numpy.argpartition"], "function", ["None"], ["", "def", "top_k_triplets", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Get the top_k for a 1-d numpy array.\n\n  Returns a sparse list of tuples in\n  (prediction, class) format\n  \"\"\"", "\n", "m", "=", "len", "(", "predictions", ")", "\n", "k", "=", "min", "(", "k", ",", "m", ")", "\n", "indices", "=", "numpy", ".", "argpartition", "(", "predictions", ",", "-", "k", ")", "[", "-", "k", ":", "]", "\n", "return", "[", "(", "index", ",", "predictions", "[", "index", "]", ",", "labels", "[", "index", "]", ")", "for", "index", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.__init__": [[118, 129], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.2_train_videolevel_keras.YT8MSequence.__init__"], ["def", "__init__", "(", "self", ",", "in_shape", "=", "1152", ",", "hidden_size", "=", "256", ",", "max_len", "=", "300", ",", "embedd_size", "=", "32", ")", ":", "\n", "        ", "super", "(", "BiLSTM_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "in_shape", "+", "embedd_size", ",", "hidden_size", ",", "\n", "batch_first", "=", "True", ",", "num_layers", "=", "2", ",", "\n", "bidirectional", "=", "True", ")", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "1", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "1", ")", "\n", "self", ".", "embed", "=", "torch", ".", "nn", ".", "Embedding", "(", "1000", ",", "embedd_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward": [[130, 142], ["train_localization.BiLSTM_model.embed", "torch.transpose.view().repeat", "torch.transpose.view().repeat", "torch.transpose.view().repeat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "train_localization.BiLSTM_model.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "train_localization.BiLSTM_model.sigmoid", "torch.transpose.view", "torch.transpose.view", "torch.transpose.view", "train_localization.BiLSTM_model.linear().squeeze", "train_localization.BiLSTM_model.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "input_lengths", ",", "mask", ",", "embeddings", ")", ":", "\n", "        ", "ebedd", "=", "self", ".", "embed", "(", "embeddings", ")", "\n", "ebedd", "=", "ebedd", ".", "view", "(", "ebedd", ".", "shape", "[", "0", "]", ",", "ebedd", ".", "shape", "[", "1", "]", ",", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "300", ")", "\n", "ebedd", "=", "torch", ".", "transpose", "(", "ebedd", ",", "1", ",", "2", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "ebedd", "]", ",", "dim", "=", "2", ")", "\n", "\n", "x", "=", "pack_padded_sequence", "(", "x", ",", "input_lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "\n", "out", "=", "self", ".", "lstm", "(", "x", ")", "\n", "unpacked", ",", "_", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "out", "[", "0", "]", ",", "batch_first", "=", "True", ",", "total_length", "=", "self", ".", "max_len", ")", "\n", "return", "self", ".", "sigmoid", "(", "self", ".", "linear", "(", "unpacked", ")", ".", "squeeze", "(", ")", ")", "*", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.__init__": [[213, 239], ["tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "cluster", ",", "\n", "task", ",", "\n", "train_dir", ",", "\n", "model", ",", "\n", "reader", ",", "\n", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "\n", "max_steps", "=", "None", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "\n", "device_count", "=", "{", "'GPU'", ":", "0", "}", ",", "\n", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run": [[241, 346], ["torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "train_localization.BiLSTM_model", "BiLSTM_model.cuda", "BiLSTM_model.train", "torch.Adam", "torch.Adam", "torch.Adam", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "BiLSTM_model.parameters", "os.path.exists", "os.makedirs", "tensorflow.device", "train_localization.build_data_providers", "tensorflow.train.Supervisor", "pd.read_csv", "train_localization.task_as_string", "tensorflow.get_default_graph", "tensorflow.train.Supervisor.managed_session", "tensorflow.global_variables_initializer", "enumerate", "tensorflow.logging.info", "train_localization.task_as_string", "sess.run", "numpy.array", "torch.Adam.zero_grad", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "train_localization.BiLSTM_model.forward", "torch.BCELoss.", "nn.BCELoss.backward", "torch.Adam.step", "float", "print", "tensorflow.logging.info", "numpy.argsort", "numpy.zeros", "enumerate", "nn.BCELoss.data.cpu().numpy", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "exit", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "exit", "train_localization.task_as_string", "BiLSTM_model.state_dict", "os.path.join", "BiLSTM_model.state_dict", "os.path.join", "nn.BCELoss.data.cpu"], "methods", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.build_data_providers", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.BiLSTM_model.forward", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "torch", ".", "cuda", ".", "set_device", "(", "0", ")", "\n", "model", "=", "BiLSTM_model", "(", "hidden_size", "=", "256", ")", "\n", "model", ".", "cuda", "(", "0", ")", "\n", "# model = nn.DataParallel(model)", "\n", "\n", "\n", "model", ".", "train", "(", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0.001", ")", "\n", "bcloss", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "train_dir", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "self", ".", "train_dir", ")", "\n", "", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "data_dict", "=", "build_data_providers", "(", "self", ".", "reader", ",", "\n", "FLAGS", ".", "train_data_pattern", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "tf", ".", "get_default_graph", "(", ")", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "import", "pandas", "as", "pd", "\n", "df", "=", "pd", ".", "read_csv", "(", "\"./youtube-8m/segment_label_ids.csv\"", ")", "\n", "idx_val", "=", "{", "x", ":", "i", "for", "i", ",", "x", "in", "enumerate", "(", "df", ".", "Index", ")", "}", "\n", "step", "=", "0", "\n", "with", "sv", ".", "managed_session", "(", "\"\"", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "# with tf.Session(config=self.config) as sess:", "\n", "          ", "try", ":", "\n", "            ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "while", "True", ":", "# (not sv.should_stop()) and (not self.max_steps_reached):", "\n", "                ", "step", "+=", "1", "\n", "data", "=", "sess", ".", "run", "(", "data_dict", ")", "\n", "x", "=", "data", "[", "'video_matrix'", "]", "\n", "y", "=", "data", "[", "'labels'", "]", "\n", "x_len", "=", "data", "[", "'num_frames'", "]", "\n", "\n", "label_type", "=", "np", ".", "array", "(", "[", "idx_val", "[", "xx", "[", "0", "]", "]", "for", "xx", "in", "data", "[", "'sel_label'", "]", "]", ")", "\n", "\n", "# Preprocess the sequences", "\n", "soder", "=", "np", ".", "argsort", "(", "x_len", ")", "[", ":", ":", "-", "1", "]", "\n", "x", "=", "x", "[", "soder", "]", "\n", "y", "=", "y", "[", "soder", "]", "\n", "label_type", "=", "label_type", "[", "soder", "]", "\n", "\n", "x_len", "=", "x_len", "[", "soder", "]", "\n", "if", "FLAGS", ".", "mask_unlabeled", ":", "\n", "                    ", "mask", "=", "y", "!=", "0", "\n", "y", "=", "y", "==", "1", "\n", "", "else", ":", "\n", "                    ", "mask", "=", "np", ".", "zeros", "(", "(", "x", ".", "shape", "[", "0", "]", ",", "300", ")", ",", "np", ".", "bool", ")", "\n", "for", "i", ",", "slen", "in", "enumerate", "(", "x_len", ")", ":", "\n", "                        ", "mask", "[", "i", ",", ":", "slen", "]", "=", "1", "\n", "\n", "# model processing", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "y_input", "=", "torch", ".", "tensor", "(", "y", ",", "device", "=", "'cuda:0'", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "x_input", "=", "torch", ".", "tensor", "(", "x", ",", "device", "=", "'cuda:0'", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "mask", ",", "device", "=", "'cuda:0'", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "label_type", "=", "torch", ".", "tensor", "(", "label_type", ",", "device", "=", "'cuda:0'", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n", "preds", "=", "model", ".", "forward", "(", "x_input", ",", "x_len", ",", "mask", ",", "label_type", ")", "\n", "\n", "my_loss", "=", "bcloss", "(", "preds", ",", "y_input", "*", "mask", ")", "\n", "my_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "closs", "=", "float", "(", "my_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "print", "(", "\"step: {}, loss: {:.5f}\"", ".", "format", "(", "step", ",", "closs", ")", ")", "\n", "\n", "if", "step", "==", "92", ":", "\n", "                    ", "print", "(", "\"Reducing LR\"", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "0.0001", "\n", "", "", "if", "step", "==", "92", "*", "2", ":", "\n", "                    ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "0.00002", "\n", "", "", "if", "step", "==", "92", "*", "3", ":", "\n", "                    ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "self", ".", "train_dir", ",", "\"torch_model_3epochs_256hidden.pth\"", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "# print(\"Reducing LR\")", "\n", "# for param_group in optimizer.param_groups:", "\n", "#     param_group['lr'] = 0.00002", "\n", "\n", "", "if", "step", "==", "92", "*", "12", ":", "\n", "                    ", "print", "(", "\"We are done.\"", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "self", ".", "train_dir", ",", "\"torch_model_longer_wider.pth\"", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "            ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "\n", "", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.validate_class_name": [[144, 157], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\n", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.get_input_data_tensors": [[159, 187], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.readers.YT8MValFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "8", ")", ":", "\n", "  ", "\"\"\"\n  Creates the section of the graph which reads the training data.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"#### Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "10", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.find_class_by_name": [[189, 193], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.build_data_providers": [[195, 209], ["train_localization.get_input_data_tensors"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.get_input_data_tensors"], ["", "def", "build_data_providers", "(", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "\n", "  ", "input_data_dict", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "return", "input_data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string": [[348, 350], ["None"], "function", ["None"], ["", "", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.main": [[352, 379], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "train_localization.task_as_string", "readers.YT8MValFrameFeatureReader", "train_localization.Trainer.run", "train_localization.find_class_by_name", "train_localization.Trainer"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.task_as_string", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.Trainer.run", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.train_localization.find_class_by_name"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "task_as_string", "(", "task", ")", ",", "\n", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "readers", ".", "YT8MValFrameFeatureReader", "(", "label_presence", "=", "True", ",", "mask_unlabeled", "=", "FLAGS", ".", "mask_unlabeled", ",", "\n", "one_prop", "=", "True", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "None", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ")", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.Dequantize": [[26, 42], ["None"], "function", ["None"], ["", "def", "Dequantize", "(", "feat_vector", ",", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "  ", "\"\"\"Dequantize the feature from the byte format to the float format.\n\n  Args:\n    feat_vector: the input 1-d vector.\n    max_quantized_value: the maximum of the quantized value.\n    min_quantized_value: the minimum of the quantized value.\n\n  Returns:\n    A float vector which has the same shape as feat_vector.\n  \"\"\"", "\n", "assert", "max_quantized_value", ">", "min_quantized_value", "\n", "quantized_range", "=", "max_quantized_value", "-", "min_quantized_value", "\n", "scalar", "=", "quantized_range", "/", "255.0", "\n", "bias", "=", "(", "quantized_range", "/", "512.0", ")", "+", "min_quantized_value", "\n", "return", "feat_vector", "*", "scalar", "+", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary": [[44, 51], ["tensorflow.Summary", "tf.Summary.value.add", "str", "float"], "function", ["None"], ["", "def", "MakeSummary", "(", "name", ",", "value", ")", ":", "\n", "  ", "\"\"\"Creates a tf.Summary proto with the given name and value.\"\"\"", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "val", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "val", ".", "tag", "=", "str", "(", "name", ")", "\n", "val", ".", "simple_value", "=", "float", "(", "value", ")", "\n", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.AddGlobalStepSummary": [[53, 96], ["global_step_info_dict.get", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "summary_writer.add_summary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary"], ["", "def", "AddGlobalStepSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "global_step_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the global_step summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    global_step_info_dict: a dictionary of the evaluation metrics calculated for\n      a mini-batch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "this_hit_at_one", "=", "global_step_info_dict", "[", "\"hit_at_one\"", "]", "\n", "this_perr", "=", "global_step_info_dict", "[", "\"perr\"", "]", "\n", "this_loss", "=", "global_step_info_dict", "[", "\"loss\"", "]", "\n", "examples_per_second", "=", "global_step_info_dict", ".", "get", "(", "\"examples_per_second\"", ",", "-", "1", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Hit@1\"", ",", "this_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Perr\"", ",", "this_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Loss\"", ",", "this_loss", ")", ",", "\n", "global_step_val", ")", "\n", "\n", "if", "examples_per_second", "!=", "-", "1", ":", "\n", "    ", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Example_Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "info", "=", "(", "\n", "\"global_step {0} | Batch Hit@1: {1:.3f} | Batch PERR: {2:.3f} | Batch \"", "\n", "\"Loss: {3:.3f} | Examples_per_sec: {4:.3f}\"", ")", ".", "format", "(", "\n", "global_step_val", ",", "this_hit_at_one", ",", "this_perr", ",", "this_loss", ",", "\n", "examples_per_second", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.AddEpochSummary": [[98, 143], ["numpy.mean", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "print", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "len"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.MakeSummary"], ["", "def", "AddEpochSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the epoch summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    epoch_info_dict: a dictionary of the evaluation metrics calculated for the\n      whole epoch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "epoch_id", "=", "epoch_info_dict", "[", "\"epoch_id\"", "]", "\n", "avg_hit_at_one", "=", "epoch_info_dict", "[", "\"avg_hit_at_one\"", "]", "\n", "avg_perr", "=", "epoch_info_dict", "[", "\"avg_perr\"", "]", "\n", "avg_loss", "=", "epoch_info_dict", "[", "\"avg_loss\"", "]", "\n", "aps", "=", "epoch_info_dict", "[", "\"aps\"", "]", "\n", "gap", "=", "epoch_info_dict", "[", "\"gap\"", "]", "\n", "mean_ap", "=", "numpy", ".", "mean", "(", "aps", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Hit@1\"", ",", "avg_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Perr\"", ",", "avg_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Loss\"", ",", "avg_loss", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_MAP\"", ",", "mean_ap", ")", ",", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "info", "=", "(", "\"epoch/eval number {0} | Avg_Hit@1: {1:.3f} | Avg_PERR: {2:.3f} \"", "\n", "\"| MAP: {3:.3f} | GAP: {4:.3f} | Avg_Loss: {5:3f} | num_classes: {6}\"", "\n", ")", ".", "format", "(", "epoch_id", ",", "avg_hit_at_one", ",", "avg_perr", ",", "mean_ap", ",", "gap", ",", "avg_loss", ",", "\n", "len", "(", "aps", ")", ")", "\n", "print", "(", "info", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.GetListOfFeatureNamesAndSizes": [[145, 170], ["feature_names.strip", "int", "len", "len", "tensorflow.logging.error", "feature_names.split", "feature_sizes.split", "str", "len", "str", "len"], "function", ["None"], ["", "def", "GetListOfFeatureNamesAndSizes", "(", "feature_names", ",", "feature_sizes", ")", ":", "\n", "  ", "\"\"\"Extract the list of feature names and the dimensionality of each feature\n\n     from string of comma separated values.\n\n  Args:\n    feature_names: string containing comma separated list of feature names\n    feature_sizes: string containing comma separated list of feature sizes\n\n  Returns:\n    List of the feature names and list of the dimensionality of each feature.\n    Elements in the first/second list are strings/integers.\n  \"\"\"", "\n", "list_of_feature_names", "=", "[", "\n", "feature_names", ".", "strip", "(", ")", "for", "feature_names", "in", "feature_names", ".", "split", "(", "\",\"", ")", "\n", "]", "\n", "list_of_feature_sizes", "=", "[", "\n", "int", "(", "feature_sizes", ")", "for", "feature_sizes", "in", "feature_sizes", ".", "split", "(", "\",\"", ")", "\n", "]", "\n", "if", "len", "(", "list_of_feature_names", ")", "!=", "len", "(", "list_of_feature_sizes", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"length of the feature names (=\"", "+", "\n", "str", "(", "len", "(", "list_of_feature_names", ")", ")", "+", "\") != length of feature \"", "\n", "\"sizes (=\"", "+", "str", "(", "len", "(", "list_of_feature_sizes", ")", ")", "+", "\")\"", ")", "\n", "\n", "", "return", "list_of_feature_names", ",", "list_of_feature_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.clip_gradient_norms": [[172, 192], ["clipped_grads_and_vars.append", "isinstance", "tensorflow.clip_by_norm", "tensorflow.IndexedSlices", "tensorflow.clip_by_norm"], "function", ["None"], ["", "def", "clip_gradient_norms", "(", "gradients_to_variables", ",", "max_norm", ")", ":", "\n", "  ", "\"\"\"Clips the gradients by the given value.\n\n  Args:\n    gradients_to_variables: A list of gradient to variable pairs (tuples).\n    max_norm: the maximum norm value.\n\n  Returns:\n    A list of clipped gradient to variable pairs.\n  \"\"\"", "\n", "clipped_grads_and_vars", "=", "[", "]", "\n", "for", "grad", ",", "var", "in", "gradients_to_variables", ":", "\n", "    ", "if", "grad", "is", "not", "None", ":", "\n", "      ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "        ", "tmp", "=", "tf", ".", "clip_by_norm", "(", "grad", ".", "values", ",", "max_norm", ")", "\n", "grad", "=", "tf", ".", "IndexedSlices", "(", "tmp", ",", "grad", ".", "indices", ",", "grad", ".", "dense_shape", ")", "\n", "", "else", ":", "\n", "        ", "grad", "=", "tf", ".", "clip_by_norm", "(", "grad", ",", "max_norm", ")", "\n", "", "", "clipped_grads_and_vars", ".", "append", "(", "(", "grad", ",", "var", ")", ")", "\n", "", "return", "clipped_grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.utils.combine_gradients": [[194, 222], ["xrange", "len", "tensorflow.stack", "tensorflow.reduce_sum", "final_grads.append", "xrange", "len"], "function", ["None"], ["", "def", "combine_gradients", "(", "tower_grads", ")", ":", "\n", "  ", "\"\"\"Calculate the combined gradient for each shared variable across all towers.\n\n  Note that this function provides a synchronization point across all towers.\n\n  Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list is\n      over individual gradients. The inner list is over the gradient calculation\n      for each tower.\n\n  Returns:\n     List of pairs of (gradient, variable) where the gradient has been summed\n     across all towers.\n  \"\"\"", "\n", "filtered_grads", "=", "[", "\n", "[", "x", "for", "x", "in", "grad_list", "if", "x", "[", "0", "]", "is", "not", "None", "]", "for", "grad_list", "in", "tower_grads", "\n", "]", "\n", "final_grads", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "filtered_grads", "[", "0", "]", ")", ")", ":", "\n", "    ", "grads", "=", "[", "filtered_grads", "[", "t", "]", "[", "i", "]", "for", "t", "in", "xrange", "(", "len", "(", "filtered_grads", ")", ")", "]", "\n", "grad", "=", "tf", ".", "stack", "(", "[", "x", "[", "0", "]", "for", "x", "in", "grads", "]", ",", "0", ")", "\n", "grad", "=", "tf", ".", "reduce_sum", "(", "grad", ",", "0", ")", "\n", "final_grads", ".", "append", "(", "(", "\n", "grad", ",", "\n", "filtered_grads", "[", "0", "]", "[", "i", "]", "[", "1", "]", ",", "\n", ")", ")", "\n", "\n", "", "return", "final_grads", "\n", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.losses.BaseLoss.calculate_loss": [[22, 37], ["NotImplementedError"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "unused_predictions", ",", "unused_labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Calculates the average loss of the examples in a mini-batch.\n\n     Args:\n      unused_predictions: a 2-d tensor storing the prediction scores, in which\n        each row represents a sample in the mini-batch and each column\n        represents a class.\n      unused_labels: a 2-d tensor storing the labels, which has the same shape\n        as the unused_predictions. The labels must be in the range of 0 and 1.\n      unused_params: loss specific parameters.\n\n    Returns:\n      A scalar loss tensor.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.losses.CrossEntropyLoss.calculate_loss": [[42, 56], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.negative", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "\n", "predictions", ",", "\n", "labels", ",", "\n", "label_weights", "=", "None", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_xent\"", ")", ":", "\n", "      ", "epsilon", "=", "1e-5", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "cross_entropy_loss", "=", "float_labels", "*", "tf", ".", "log", "(", "predictions", "+", "epsilon", ")", "+", "(", "\n", "1", "-", "float_labels", ")", "*", "tf", ".", "log", "(", "1", "-", "predictions", "+", "epsilon", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "negative", "(", "cross_entropy_loss", ")", "\n", "if", "label_weights", "is", "not", "None", ":", "\n", "        ", "cross_entropy_loss", "*=", "label_weights", "\n", "", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.losses.HingeLoss.calculate_loss": [[66, 76], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.zeros", "tensorflow.ones", "tensorflow.subtract", "tensorflow.maximum", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape", "tensorflow.scalar_mul", "tensorflow.reduce_sum", "tensorflow.scalar_mul"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "b", "=", "1.0", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_hinge\"", ")", ":", "\n", "      ", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "all_zeros", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "sign_labels", "=", "tf", ".", "subtract", "(", "tf", ".", "scalar_mul", "(", "2", ",", "float_labels", ")", ",", "all_ones", ")", "\n", "hinge_loss", "=", "tf", ".", "maximum", "(", "\n", "all_zeros", ",", "\n", "tf", ".", "scalar_mul", "(", "b", ",", "all_ones", ")", "-", "sign_labels", "*", "predictions", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "hinge_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.losses.SoftmaxLoss.calculate_loss": [[90, 103], ["tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.maximum", "tensorflow.div", "tensorflow.nn.softmax", "tensorflow.negative", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_softmax\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-8", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "# l1 normalization (labels are no less than 0)", "\n", "label_rowsum", "=", "tf", ".", "maximum", "(", "\n", "tf", ".", "reduce_sum", "(", "float_labels", ",", "1", ",", "keep_dims", "=", "True", ")", ",", "epsilon", ")", "\n", "norm_float_labels", "=", "tf", ".", "div", "(", "float_labels", ",", "label_rowsum", ")", "\n", "softmax_outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "predictions", ")", "\n", "softmax_loss", "=", "tf", ".", "negative", "(", "\n", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "norm_float_labels", ",", "tf", ".", "log", "(", "softmax_outputs", ")", ")", ",", "1", ")", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "softmax_loss", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.7_create_submission.process_class": [[37, 58], ["sorted", "print", "sorted", "len", "len", "range", "len", "preds.append", "probs.mean", "len"], "function", ["None"], ["def", "process_class", "(", "cls", ")", ":", "\n", "    ", "pairs", "=", "sorted", "(", "pred_pairs", "[", "cls", "]", ",", "reverse", "=", "True", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "thresh", "=", "2e-4", "\n", "videos", "=", "[", "p", "[", "0", "]", "for", "p", "in", "pairs", "if", "p", "[", "1", "]", ">", "thresh", "]", "\n", "pairs", "=", "[", "p", "for", "p", "in", "pairs", "if", "p", "[", "1", "]", ">", "thresh", "]", "\n", "assert", "len", "(", "videos", ")", "==", "len", "(", "pairs", ")", "\n", "\n", "cls_model_preds", "=", "xgb_pred_matrix", "[", ":", ",", "class_to_idx", "[", "cls", "]", "]", "\n", "\n", "preds", "=", "[", "]", "\n", "for", "_id", ",", "conf", "in", "pairs", ":", "\n", "        ", "for", "i", "in", "range", "(", "60", ")", ":", "\n", "#                 print(video_indices[_id] + i*5, video_indices[_id]+(i+1)*5)", "\n", "            ", "probs", "=", "cls_model_preds", "[", "video_indices", "[", "_id", "]", "+", "i", "*", "5", "-", "2", ":", "video_indices", "[", "_id", "]", "+", "(", "i", "+", "1", ")", "*", "5", "+", "2", "]", "**", "POW", "\n", "p", "=", "probs", ".", "mean", "(", ")", "if", "len", "(", "probs", ")", ">", "0", "else", "0", "\n", "#                 print(conf, p)", "\n", "preds", ".", "append", "(", "(", "'{}:{}'", ".", "format", "(", "_id", ",", "i", "*", "5", ")", ",", "p", "*", "conf", ")", ")", "\n", "", "", "print", "(", "len", "(", "preds", ")", ")", "\n", "sorted_preds", "=", "sorted", "(", "preds", ",", "reverse", "=", "True", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "\n", "return", "(", "cls", ",", "'{},{}\\n'", ".", "format", "(", "cls", ",", "' '", ".", "join", "(", "[", "p", "[", "0", "]", "for", "p", "in", "sorted_preds", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.5_train_all_xgb.run_cls": [[21, 28], ["print", "mlcrate.time.Timer", "str", "print", "subprocess.check_output", "mlc.time.Timer.fsince", "str", "str.split"], "function", ["None"], ["def", "run_cls", "(", "target_cls", ")", ":", "\n", "    ", "print", "(", "'Starting class {}'", ".", "format", "(", "target_cls", ")", ")", "\n", "t0", "=", "mlc", ".", "time", ".", "Timer", "(", ")", "\n", "\n", "output", "=", "str", "(", "subprocess", ".", "check_output", "(", "[", "'python'", ",", "'train_cls_xgb.py'", ",", "str", "(", "target_cls", ")", "]", ")", ")", "\n", "\n", "print", "(", "'Finished class {}, time {}: {}'", ".", "format", "(", "target_cls", ",", "t0", ".", "fsince", "(", ")", ",", "output", ".", "split", "(", "'\\\\n'", ")", "[", "-", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.6_predict_all_xgb.CLSEnsemble.__init__": [[27, 29], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "self", ".", "models", "=", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.6_predict_all_xgb.CLSEnsemble.predict_proba": [[30, 39], ["numpy.corrcoef", "print", "numpy.mean", "numpy.mean.append", "model.predict"], "methods", ["None"], ["", "def", "predict_proba", "(", "self", ",", "darr", ")", ":", "\n", "# darr = xgb.DMatrix(arr)", "\n", "        ", "preds", "=", "[", "]", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "preds", ".", "append", "(", "model", ".", "predict", "(", "darr", ")", ")", "\n", "", "corr", "=", "np", ".", "corrcoef", "(", "preds", ")", "\n", "print", "(", "'corr'", ",", "corr", "[", "0", ",", "1", "]", ")", "\n", "preds", "=", "np", ".", "mean", "(", "preds", ",", "axis", "=", "0", ")", "\n", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.train_cls_xgb.get_importances": [[14, 38], ["open", "enumerate", "open.close", "model.get_fscore", "sorted", "os.remove", "numpy.random.randint", "open.write", "sorted.items"], "function", ["None"], ["def", "get_importances", "(", "model", ",", "features", ")", ":", "\n", "    ", "\"\"\"Get XGBoost feature importances from an xgboost model and list of features.\n    Keyword arguments:\n    model -- a trained xgboost.Booster object\n    features -- a list of feature names corresponding to the features the model was trained on.\n    Returns:\n    importance -- A list of (feature, importance) tuples representing sorted importance\n    \"\"\"", "\n", "\n", "for", "feature", "in", "features", ":", "\n", "        ", "assert", "'\\n'", "not", "in", "feature", "and", "'\\t'", "not", "in", "feature", ",", "\"\\\\n and \\\\t cannot be in feature names\"", "\n", "\n", "", "fn", "=", "'mlcrate_xgb_{}.fmap'", ".", "format", "(", "np", ".", "random", ".", "randint", "(", "100000", ")", ")", "\n", "outfile", "=", "open", "(", "fn", ",", "'w'", ")", "\n", "for", "i", ",", "feat", "in", "enumerate", "(", "features", ")", ":", "\n", "        ", "outfile", ".", "write", "(", "'{0}\\t{1}\\tq\\n'", ".", "format", "(", "i", ",", "feat", ")", ")", "\n", "", "outfile", ".", "close", "(", ")", "\n", "\n", "importance", "=", "model", ".", "get_fscore", "(", "fmap", "=", "fn", ")", "\n", "importance", "=", "sorted", "(", "importance", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "os", ".", "remove", "(", "fn", ")", "\n", "\n", "return", "importance", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.train_cls_xgb.train_kfold": [[39, 176], ["hasattr", "numpy.asarray", "numpy.array", "print", "mlcrate.time.Timer", "isinstance", "numpy.zeros_like", "defaultdict", "print", "gc.collect", "numpy.arange().astype", "numpy.asarray", "xgb.DMatrix", "print", "xgb.DMatrix", "xgb.DMatrix", "mlcrate.time.Timer.add", "xgb.train", "scores.append", "print", "train_cls_xgb.get_importances", "xgb.train.predict", "models.append", "numpy.mean", "print", "StratifiedKFold", "KFold.split", "KFold", "KFold.split", "params.get", "print", "xgb.train.predict", "ps_test.append", "mlcrate.time.Timer.fsince", "sorted", "numpy.arange", "len", "len", "params.get", "params.get", "mlcrate.time.Timer.fsince", "numpy.mean", "defaultdict.items", "print"], "function", ["home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.train_cls_xgb.get_importances", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.deep_learning_for_event_localization.eval_util.EvaluationMetrics.get"], ["", "def", "train_kfold", "(", "params", ",", "x_train", ",", "y_train", ",", "x_test", "=", "None", ",", "folds", "=", "5", ",", "stratify", "=", "None", ",", "random_state", "=", "1337", ",", "skip_checks", "=", "False", ",", "print_imp", "=", "'final'", ")", ":", "\n", "    ", "\"\"\"Trains a set of XGBoost models with chosen parameters on a KFold split dataset, returning full out-of-fold\n    training set predictions (useful for stacking) as well as test set predictions and the models themselves.\n    Test set predictions are generated by averaging predictions from all the individual fold models - this means\n    1 model fewer has to be trained and from my experience performs better than retraining a single model on the full set.\n    Optionally, the split can be stratified along a passed array. Feature importances are also computed and summed across all folds for convenience.\n    Keyword arguments:\n    params -- Parameters passed to the xgboost model, as well as ['early_stopping_rounds', 'nrounds', 'verbose_eval'], which are passed to xgb.train()\n              Defaults: early_stopping_rounds = 50, nrounds = 100000, verbose_eval = 1\n    x_train -- The training set features\n    y_train -- The training set labels\n    x_test (optional) -- The test set features\n    folds (default: 5) -- The number of folds to perform\n    stratify (optional) -- An array to stratify the splits along\n    random_state (default: 1337) -- Random seed for splitting folds\n    skip_checks -- By default, this function tries to reorder the test set columns to match the order of the training set columns. Set this to disable this behaviour.\n    print_imp -- One of ['every', 'final', None] - 'every' prints importances for every fold, 'final' prints combined importances at the end, None does not print importance\n    Returns:\n    models -- a list of trained xgboost.Booster objects\n    p_train -- Out-of-fold training set predictions (shaped like y_train)\n    p_test -- Mean of test set predictions from the models\n    imps -- dict with \\{feature: importance\\} pairs representing the sum feature importance from all the models.\n    \"\"\"", "\n", "\n", "from", "sklearn", ".", "model_selection", "import", "KFold", ",", "StratifiedKFold", "# Optional dependencies", "\n", "from", "collections", "import", "defaultdict", "\n", "import", "numpy", "as", "np", "\n", "import", "xgboost", "as", "xgb", "\n", "\n", "assert", "print_imp", "in", "[", "'every'", ",", "'final'", ",", "None", "]", "\n", "\n", "# If it's a dataframe, we can take column names, otherwise just use column indices (eg. for printing importances).", "\n", "if", "hasattr", "(", "x_train", ",", "'columns'", ")", ":", "\n", "        ", "columns", "=", "x_train", ".", "columns", ".", "values", "\n", "columns_exists", "=", "True", "\n", "", "else", ":", "\n", "        ", "columns", "=", "np", ".", "arange", "(", "x_train", ".", "shape", "[", "1", "]", ")", ".", "astype", "(", "str", ")", "# MODIFIED", "\n", "columns_exists", "=", "False", "\n", "\n", "", "x_train", "=", "np", ".", "asarray", "(", "x_train", ")", "\n", "y_train", "=", "np", ".", "array", "(", "y_train", ")", "\n", "\n", "if", "x_test", "is", "not", "None", ":", "\n", "        ", "if", "columns_exists", "and", "not", "skip_checks", ":", "\n", "            ", "try", ":", "\n", "                ", "x_test", "=", "x_test", "[", "columns", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "'[mlcrate] Could not coerce x_test columns to match x_train columns. Set skip_checks=True to run anyway.'", ")", "\n", "raise", "e", "\n", "\n", "", "", "x_test", "=", "np", ".", "asarray", "(", "x_test", ")", "\n", "d_test", "=", "xgb", ".", "DMatrix", "(", "x_test", ")", "\n", "\n", "# MODIFIED", "\n", "if", "not", "skip_checks", ":", "\n", "            ", "assert", "x_train", ".", "shape", "[", "1", "]", "==", "x_test", ".", "shape", "[", "1", "]", ",", "\"x_train and x_test have different numbers of features.\"", "\n", "", "", "else", ":", "\n", "        ", "d_test", "=", "None", "\n", "\n", "", "print", "(", "'[mlcrate] Training {} {}XGBoost models on training set {} {}'", ".", "format", "(", "folds", ",", "'stratified '", "if", "stratify", "is", "not", "None", "else", "''", ",", "\n", "x_train", ".", "shape", ",", "'with test set {}'", ".", "format", "(", "x_test", ".", "shape", ")", "if", "x_test", "is", "not", "None", "else", "'without a test set'", ")", ")", "\n", "\n", "# Init a timer to get fold durations", "\n", "t", "=", "Timer", "(", ")", "\n", "\n", "if", "isinstance", "(", "folds", ",", "int", ")", ":", "\n", "        ", "if", "stratify", "is", "not", "None", ":", "\n", "            ", "kf", "=", "StratifiedKFold", "(", "n_splits", "=", "folds", ",", "shuffle", "=", "True", ",", "random_state", "=", "random_state", ")", "\n", "splits", "=", "kf", ".", "split", "(", "x_train", ",", "stratify", ")", "\n", "", "else", ":", "\n", "            ", "kf", "=", "KFold", "(", "n_splits", "=", "folds", ",", "shuffle", "=", "True", ",", "random_state", "=", "4242", ")", "\n", "splits", "=", "kf", ".", "split", "(", "x_train", ")", "\n", "", "", "else", ":", "\n", "# Use provided-folds as is", "\n", "        ", "splits", "=", "folds", "#.split(x_train)", "\n", "\n", "", "p_train", "=", "np", ".", "zeros_like", "(", "y_train", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "ps_test", "=", "[", "]", "\n", "models", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "imps", "=", "defaultdict", "(", "int", ")", "\n", "\n", "fold_i", "=", "0", "\n", "for", "train_kf", ",", "valid_kf", "in", "splits", ":", "\n", "        ", "print", "(", "'[mlcrate] Running fold {}, {} train samples, {} validation samples'", ".", "format", "(", "fold_i", ",", "len", "(", "train_kf", ")", ",", "len", "(", "valid_kf", ")", ")", ")", "\n", "d_train", "=", "xgb", ".", "DMatrix", "(", "x_train", "[", "train_kf", "]", ",", "label", "=", "y_train", "[", "train_kf", "]", ")", "\n", "d_valid", "=", "xgb", ".", "DMatrix", "(", "x_train", "[", "valid_kf", "]", ",", "label", "=", "y_train", "[", "valid_kf", "]", ")", "\n", "\n", "# Start a timer for the fold", "\n", "t", ".", "add", "(", "'fold{}'", ".", "format", "(", "fold_i", ")", ")", "\n", "\n", "# Metrics to print", "\n", "watchlist", "=", "[", "(", "d_train", ",", "'train'", ")", ",", "(", "d_valid", ",", "'valid'", ")", "]", "\n", "\n", "mdl", "=", "xgb", ".", "train", "(", "params", ",", "d_train", ",", "params", ".", "get", "(", "'nrounds'", ",", "100000", ")", ",", "watchlist", ",", "\n", "early_stopping_rounds", "=", "params", ".", "get", "(", "'early_stopping_rounds'", ",", "50", ")", ",", "verbose_eval", "=", "params", ".", "get", "(", "'verbose_eval'", ",", "1", ")", ")", "\n", "\n", "scores", ".", "append", "(", "mdl", ".", "best_score", ")", "\n", "\n", "print", "(", "'[mlcrate] Finished training fold {} - took {} - running score {}'", ".", "format", "(", "fold_i", ",", "t", ".", "fsince", "(", "'fold{}'", ".", "format", "(", "fold_i", ")", ")", ",", "np", ".", "mean", "(", "scores", ")", ")", ")", "\n", "\n", "# Get importances for this model and add to global importance", "\n", "imp", "=", "get_importances", "(", "mdl", ",", "columns", ")", "\n", "if", "print_imp", "==", "'every'", ":", "\n", "            ", "print", "(", "'Fold {} importances:'", ".", "format", "(", "fold_i", ")", ",", "imp", ")", "\n", "\n", "", "for", "f", ",", "i", "in", "imp", ":", "\n", "            ", "imps", "[", "f", "]", "+=", "i", "\n", "\n", "# Get predictions from the model", "\n", "", "p_valid", "=", "mdl", ".", "predict", "(", "d_valid", ",", "ntree_limit", "=", "mdl", ".", "best_ntree_limit", ")", "\n", "if", "x_test", "is", "not", "None", ":", "\n", "            ", "p_test", "=", "mdl", ".", "predict", "(", "d_test", ",", "ntree_limit", "=", "mdl", ".", "best_ntree_limit", ")", "\n", "\n", "", "p_train", "[", "valid_kf", "]", "=", "p_valid", "\n", "\n", "if", "x_test", "is", "not", "None", ":", "# MODIFIED", "\n", "            ", "ps_test", ".", "append", "(", "p_test", ")", "\n", "", "models", ".", "append", "(", "mdl", ")", "\n", "\n", "fold_i", "+=", "1", "\n", "\n", "", "if", "x_test", "is", "not", "None", ":", "\n", "        ", "p_test", "=", "np", ".", "mean", "(", "ps_test", ",", "axis", "=", "0", ")", "\n", "\n", "", "print", "(", "'[mlcrate] Finished training {} XGBoost models, took {}'", ".", "format", "(", "folds", ",", "t", ".", "fsince", "(", "0", ")", ")", ")", "\n", "\n", "if", "print_imp", "in", "[", "'every'", ",", "'final'", "]", ":", "\n", "        ", "print", "(", "'[mlcrate] Overall feature importances:'", ",", "sorted", "(", "imps", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "\n", "", "if", "x_test", "is", "None", ":", "\n", "        ", "p_test", "=", "None", "\n", "\n", "", "del", "x_train", ",", "d_train", ",", "d_valid", ",", "x_test", ",", "d_test", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "return", "models", ",", "p_train", ",", "p_test", ",", "imps", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.1_ingest_framelevel.process_record": [[11, 36], ["tensorflow.reset_default_graph", "tensorflow.Session", "sess.as_default", "tensorflow.python_io.tf_record_iterator", "tensorflow.train.Example.FromString", "tf.train.Example.FromString.features.feature[].bytes_list.value[].decode", "metadata.append", "tensorflow.parse_single_sequence_example", "tensorflow.decode_raw().eval", "tensorflow.decode_raw().eval", "numpy.concatenate", "list", "list", "tensorflow.decode_raw", "tensorflow.decode_raw", "zip", "tensorflow.FixedLenSequenceFeature", "tensorflow.FixedLenSequenceFeature"], "function", ["None"], ["def", "process_record", "(", "record", ")", ":", "\n", "    ", "tf", ".", "reset_default_graph", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "            ", "metadata", "=", "[", "]", "\n", "all_av", "=", "{", "}", "\n", "\n", "for", "example", "in", "tf", ".", "python_io", ".", "tf_record_iterator", "(", "record", ")", ":", "\n", "                ", "tf_example", "=", "tf", ".", "train", ".", "Example", ".", "FromString", "(", "example", ")", "\n", "vid_id", "=", "tf_example", ".", "features", ".", "feature", "[", "'id'", "]", ".", "bytes_list", ".", "value", "[", "0", "]", ".", "decode", "(", "encoding", "=", "'UTF-8'", ")", "\n", "vid_labels", "=", "tf_example", ".", "features", ".", "feature", "[", "'labels'", "]", ".", "int64_list", ".", "value", "\n", "segment_start_times", "=", "tf_example", ".", "features", ".", "feature", "[", "'segment_start_times'", "]", ".", "int64_list", ".", "value", "\n", "#     segment_end_times = tf_example.features.feature['segment_end_times'].int64_list.value", "\n", "segment_labels", "=", "tf_example", ".", "features", ".", "feature", "[", "'segment_labels'", "]", ".", "int64_list", ".", "value", "\n", "segment_scores", "=", "tf_example", ".", "features", ".", "feature", "[", "'segment_scores'", "]", ".", "float_list", ".", "value", "\n", "metadata", ".", "append", "(", "(", "vid_id", ",", "list", "(", "vid_labels", ")", ",", "list", "(", "zip", "(", "segment_start_times", ",", "segment_labels", ",", "segment_scores", ")", ")", ")", ")", "\n", "\n", "x", ",", "y", "=", "tf", ".", "parse_single_sequence_example", "(", "example", ",", "sequence_features", "=", "{", "'rgb'", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "'audio'", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "}", ")", "\n", "rgb_frames", "=", "tf", ".", "decode_raw", "(", "y", "[", "'rgb'", "]", ",", "tf", ".", "uint8", ")", ".", "eval", "(", ")", "\n", "audio_frames", "=", "tf", ".", "decode_raw", "(", "y", "[", "'audio'", "]", ",", "tf", ".", "uint8", ")", ".", "eval", "(", ")", "\n", "av", "=", "np", ".", "concatenate", "(", "[", "rgb_frames", ",", "audio_frames", "]", ",", "1", ")", "\n", "\n", "all_av", "[", "vid_id", "]", "=", "av", "\n", "\n", "", "return", "metadata", ",", "all_av", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.2_train_videolevel_keras.YT8MSequence.__init__": [[26, 30], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "h5", ",", "meta", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "h5", "=", "h5", "\n", "self", ".", "meta", "=", "meta", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.2_train_videolevel_keras.YT8MSequence.__len__": [[31, 33], ["int", "numpy.ceil", "len", "float"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "np", ".", "ceil", "(", "len", "(", "self", ".", "h5", ")", "/", "float", "(", "self", ".", "batch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.2_train_videolevel_keras.YT8MSequence.__getitem__": [[34, 44], ["numpy.zeros", "enumerate", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "batch_x", "=", "self", ".", "h5", "[", "idx", "*", "self", ".", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "self", ".", "batch_size", "]", "\n", "batch_meta", "=", "self", ".", "meta", "[", "idx", "*", "self", ".", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "self", ".", "batch_size", "]", "\n", "batch_y", "=", "np", ".", "zeros", "(", "(", "len", "(", "batch_x", ")", ",", "1000", ")", ")", "\n", "for", "i", ",", "(", "_", ",", "clss", ")", "in", "enumerate", "(", "batch_meta", ")", ":", "\n", "            ", "for", "cls", "in", "clss", ":", "\n", "                ", "if", "cls", "in", "class_to_idx", ":", "\n", "                    ", "batch_y", "[", "i", ",", "class_to_idx", "[", "cls", "]", "]", "=", "1", "\n", "\n", "", "", "", "return", "batch_x", ",", "batch_y", "\n", "\n"]], "home.repos.pwc.inspect_result.mxbi_youtube8m-2019.gbm_for_event_localization.1_ingest_videolevel.process_record": [[14, 29], ["tensorflow.reset_default_graph", "tensorflow.Session", "sess.as_default", "tensorflow.python_io.tf_record_iterator", "tensorflow.train.Example.FromString", "tf.train.Example.FromString.features.feature[].bytes_list.value[].decode", "list", "metadata.append", "numpy.concatenate"], "function", ["None"], ["def", "process_record", "(", "record", ")", ":", "\n", "    ", "tf", ".", "reset_default_graph", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "            ", "metadata", "=", "[", "]", "\n", "\n", "for", "example", "in", "tf", ".", "python_io", ".", "tf_record_iterator", "(", "record", ")", ":", "\n", "                ", "tf_example", "=", "tf", ".", "train", ".", "Example", ".", "FromString", "(", "example", ")", "\n", "vid_id", "=", "tf_example", ".", "features", ".", "feature", "[", "'id'", "]", ".", "bytes_list", ".", "value", "[", "0", "]", ".", "decode", "(", "encoding", "=", "'UTF-8'", ")", "\n", "vid_labels", "=", "list", "(", "tf_example", ".", "features", ".", "feature", "[", "'labels'", "]", ".", "int64_list", ".", "value", ")", "\n", "mean_video", "=", "tf_example", ".", "features", ".", "feature", "[", "'mean_rgb'", "]", ".", "float_list", ".", "value", "\n", "mean_audio", "=", "tf_example", ".", "features", ".", "feature", "[", "'mean_audio'", "]", ".", "float_list", ".", "value", "\n", "metadata", ".", "append", "(", "(", "vid_id", ",", "vid_labels", ",", "np", ".", "concatenate", "(", "[", "mean_video", ",", "mean_audio", "]", ")", ")", ")", "\n", "\n", "", "return", "metadata", "\n", "\n"]]}