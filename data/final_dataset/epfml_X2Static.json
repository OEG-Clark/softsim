{"home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_roberta_ver2.ll_loss": [[21, 28], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["def", "ll_loss", "(", "scores", ")", ":", "\n", "    ", "\"\"\"\n        Clamped logistic loss\n    \"\"\"", "\n", "scores", "=", "torch", ".", "clamp", "(", "scores", ",", "min", "=", "-", "20", ",", "max", "=", "20", ")", "\n", "new_scores", "=", "torch", ".", "mean", "(", "torch", ".", "log", "(", "1", "+", "torch", ".", "exp", "(", "-", "scores", ")", ")", ")", "\n", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_roberta_ver2.rejection_probs": [[29, 39], ["range", "len", "rej_prob.append", "min", "math.sqrt"], "function", ["None"], ["", "def", "rejection_probs", "(", "t", ",", "id2counts", ")", ":", "\n", "    ", "total_counts", "=", "0", "\n", "rej_prob", "=", "[", "]", "\n", "for", "counts", "in", "id2counts", ":", "\n", "        ", "total_counts", "+=", "counts", "\n", "", "for", "i", "in", "range", "(", "len", "(", "id2counts", ")", ")", ":", "\n", "        ", "freq_scaled", "=", "id2counts", "[", "i", "]", "/", "total_counts", "\n", "rej_prob", ".", "append", "(", "1", "-", "min", "(", "1", ",", "math", ".", "sqrt", "(", "t", "/", "freq_scaled", ")", "+", "t", "/", "freq_scaled", ")", ")", "\n", "\n", "", "return", "rej_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.word_embeddings.word_embeddings.__init__": [[11, 22], ["torch.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "word_embeddings.word_embeddings.embeddings.weight.data.uniform_"], "methods", ["home.repos.pwc.inspect_result.epfml_X2Static.src.word_embeddings.word_embeddings.__init__"], ["def", "__init__", "(", "self", ",", "id2word", ",", "word2id", ",", "id2counts", ",", "vocab_size", ",", "word_emb_size", ",", "sparse", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id2word", "=", "id2word", "\n", "self", ".", "word2id", "=", "word2id", "\n", "self", ".", "id2counts", "=", "id2counts", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "word_emb_size", "=", "word_emb_size", "\n", "self", ".", "on_cuda", "=", "False", "\n", "self", ".", "isSparse", "=", "sparse", "\n", "self", ".", "embeddings", "=", "torch", ".", "nn", ".", "Embedding", "(", "vocab_size", ",", "word_emb_size", ",", "sparse", "=", "sparse", ")", "\n", "self", ".", "embeddings", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "1", "/", "word_emb_size", ",", "1", "/", "word_emb_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.word_embeddings.word_embeddings.forward": [[23, 25], ["word_embeddings.word_embeddings.embeddings"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "indices", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.word_embeddings.word_embeddings.save_embeddings_w2v_format": [[26, 41], ["open", "open.write", "open.close", "open.write", "word_embeddings.word_embeddings.tolist", "open.write", "word_embeddings.word_embeddings.forward().squeeze", "word_embeddings.word_embeddings.forward().squeeze", "open.write", "str", "str", "word_embeddings.word_embeddings.forward", "word_embeddings.word_embeddings.forward", "str", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.epfml_X2Static.src.word_embeddings.word_embeddings.forward", "home.repos.pwc.inspect_result.epfml_X2Static.src.word_embeddings.word_embeddings.forward"], ["", "def", "save_embeddings_w2v_format", "(", "self", ",", "file_name", ")", ":", "\n", "        ", "file", "=", "open", "(", "file_name", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "file", ".", "write", "(", "str", "(", "self", ".", "vocab_size", ")", "+", "\" \"", "+", "str", "(", "self", ".", "word_emb_size", ")", "+", "\"\\n\"", ")", "\n", "for", "word", "in", "self", ".", "word2id", ":", "\n", "            ", "file", ".", "write", "(", "word", "+", "\" \"", ")", "\n", "if", "self", ".", "on_cuda", "==", "True", ":", "\n", "                ", "embedding", "=", "self", ".", "forward", "(", "torch", ".", "tensor", "(", "[", "self", ".", "word2id", "[", "word", "]", "]", ")", ".", "cuda", "(", ")", ")", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "                ", "embedding", "=", "self", ".", "forward", "(", "torch", ".", "tensor", "(", "[", "self", ".", "word2id", "[", "word", "]", "]", ")", ")", ".", "squeeze", "(", ")", "\n", "", "embedding", "=", "embedding", ".", "tolist", "(", ")", "\n", "for", "entry", "in", "embedding", ":", "\n", "                ", "file", ".", "write", "(", "str", "(", "(", "entry", ")", ")", "+", "\" \"", ")", "\n", "", "file", ".", "write", "(", "\"\\n\"", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "return", "\n", "", "", ""]], "home.repos.pwc.inspect_result.epfml_X2Static.src.make_vocab_dataset.construct_vocab": [[6, 55], ["dict", "open", "enumerate", "dict", "sorted", "dict", "dict", "open.close", "line.split", "list", "len", "id2word.append", "id2counts.append", "print", "word.lower.lower", "dict.items", "str"], "function", ["None"], ["def", "construct_vocab", "(", "file_location", ",", "min_count", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\" Constructing vocabulary for the dataset\n\n        Keyword arguments:\n        file_location : Location of the dataset(The dataset is assumed to be in a tokenized format)\n        min_count : minimum count of each word to be included in the vocabulary\n        vocab_size: Maximum vocabulary size allowed\n\n        Output:\n        id2word,word2id,id2counts,word_counts (self-explainable)\n    \"\"\"", "\n", "word_counts", "=", "dict", "(", ")", "\n", "\n", "file", "=", "open", "(", "file_location", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "file", ")", ":", "\n", "        ", "if", "i", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "str", "(", "i", ")", "+", "\" lines processed.\"", ",", "end", "=", "\"\\r\"", ")", "\n", "", "for", "word", "in", "line", ".", "split", "(", ")", ":", "\n", "            ", "word", "=", "word", ".", "lower", "(", ")", "\n", "if", "word", "in", "word_counts", ":", "\n", "                ", "word_counts", "[", "word", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "word_counts", "[", "word", "]", "=", "1", "\n", "\n", "", "", "", "new_word_counts", "=", "dict", "(", ")", "\n", "for", "word", "in", "word_counts", ":", "\n", "        ", "if", "word_counts", "[", "word", "]", ">=", "min_count", ":", "\n", "            ", "new_word_counts", "[", "word", "]", "=", "word_counts", "[", "word", "]", "\n", "\n", "", "", "sorted_word_counts", "=", "sorted", "(", "list", "(", "new_word_counts", ".", "items", "(", ")", ")", ",", "key", "=", "lambda", "count", ":", "count", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "if", "len", "(", "sorted_word_counts", ")", ">", "vocab_size", ":", "\n", "        ", "sorted_word_counts", "=", "sorted_word_counts", "[", ":", "vocab_size", "]", "\n", "\n", "", "word_counts", "=", "dict", "(", ")", "\n", "word2id", "=", "dict", "(", ")", "\n", "id2word", "=", "[", "]", "\n", "id2counts", "=", "[", "]", "\n", "i", "=", "0", "\n", "\n", "for", "word_count_pair", "in", "sorted_word_counts", ":", "\n", "        ", "word_counts", "[", "word_count_pair", "[", "0", "]", "]", "=", "word_count_pair", "[", "1", "]", "\n", "word2id", "[", "word_count_pair", "[", "0", "]", "]", "=", "i", "\n", "id2word", ".", "append", "(", "word_count_pair", "[", "0", "]", ")", "\n", "id2counts", ".", "append", "(", "word_count_pair", "[", "1", "]", ")", "\n", "i", "+=", "1", "\n", "", "file", ".", "close", "(", ")", "\n", "return", "id2word", ",", "word2id", ",", "id2counts", ",", "word_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.make_vocab_dataset.construct_dataset": [[56, 88], ["open", "enumerate", "open.close", "line.lower.lower", "enumerate", "lines.append", "words_locs.append", "num_words.append", "print", "line.lower.split", "words_loc.append", "str"], "function", ["None"], ["", "def", "construct_dataset", "(", "file_location", ",", "word2id", ")", ":", "\n", "    ", "\"\"\" Constructing vocabulary for the dataset\n        Keyword arguments:\n        file_location : Location of the dataset(The dataset is assumed to be in a tokenized format)\n        word2id : dictionary which maps words to ids\n\n        Output:\n        lines: Dataset stored in an array format. Each entry represents a sentence.\n        words_locs: Location of words in the vocabulary(word2id) for each line in lines\n        num_words: Number of words in the vocabulary(word2id) for each line in lines\n    \"\"\"", "\n", "lines", "=", "[", "]", "\n", "words_locs", "=", "[", "]", "\n", "num_words", "=", "[", "]", "\n", "file", "=", "open", "(", "file_location", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "file", ")", ":", "\n", "        ", "if", "i", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "str", "(", "i", ")", "+", "\" lines processed.\"", ",", "end", "=", "\"\\r\"", ")", "\n", "", "line", "=", "line", ".", "lower", "(", ")", "\n", "words_loc", "=", "[", "]", "\n", "words_in_vocab", "=", "0", "\n", "for", "j", ",", "word", "in", "enumerate", "(", "line", ".", "split", "(", ")", ")", ":", "\n", "            ", "if", "word", "in", "word2id", ":", "\n", "                ", "words_loc", ".", "append", "(", "j", ")", "\n", "words_in_vocab", "+=", "1", "\n", "", "", "if", "words_in_vocab", "==", "0", ":", "\n", "            ", "continue", "\n", "", "lines", ".", "append", "(", "line", "[", ":", "-", "1", "]", ")", "\n", "words_locs", ".", "append", "(", "words_loc", ")", "\n", "num_words", ".", "append", "(", "words_in_vocab", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "return", "lines", ",", "words_locs", ",", "num_words", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_bert_ver2.ll_loss": [[21, 28], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["def", "ll_loss", "(", "scores", ")", ":", "\n", "    ", "\"\"\"\n        Clamped logistic loss\n    \"\"\"", "\n", "scores", "=", "torch", ".", "clamp", "(", "scores", ",", "min", "=", "-", "20", ",", "max", "=", "20", ")", "\n", "new_scores", "=", "torch", ".", "mean", "(", "torch", ".", "log", "(", "1", "+", "torch", ".", "exp", "(", "-", "scores", ")", ")", ")", "\n", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_bert_ver2.rejection_probs": [[29, 39], ["range", "len", "rej_prob.append", "min", "math.sqrt"], "function", ["None"], ["", "def", "rejection_probs", "(", "t", ",", "id2counts", ")", ":", "\n", "    ", "total_counts", "=", "0", "\n", "rej_prob", "=", "[", "]", "\n", "for", "counts", "in", "id2counts", ":", "\n", "        ", "total_counts", "+=", "counts", "\n", "", "for", "i", "in", "range", "(", "len", "(", "id2counts", ")", ")", ":", "\n", "        ", "freq_scaled", "=", "id2counts", "[", "i", "]", "/", "total_counts", "\n", "rej_prob", ".", "append", "(", "1", "-", "min", "(", "1", ",", "math", ".", "sqrt", "(", "t", "/", "freq_scaled", ")", "+", "t", "/", "freq_scaled", ")", ")", "\n", "\n", "", "return", "rej_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_gpt2_ver2.ll_loss": [[19, 26], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["def", "ll_loss", "(", "scores", ")", ":", "\n", "    ", "\"\"\"\n        Clamped logistic loss\n    \"\"\"", "\n", "scores", "=", "torch", ".", "clamp", "(", "scores", ",", "min", "=", "-", "20", ",", "max", "=", "20", ")", "\n", "new_scores", "=", "torch", ".", "mean", "(", "torch", ".", "log", "(", "1", "+", "torch", ".", "exp", "(", "-", "scores", ")", ")", ")", "\n", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_gpt2_ver2.rejection_probs": [[27, 37], ["range", "len", "rej_prob.append", "min", "math.sqrt"], "function", ["None"], ["", "def", "rejection_probs", "(", "t", ",", "id2counts", ")", ":", "\n", "    ", "total_counts", "=", "0", "\n", "rej_prob", "=", "[", "]", "\n", "for", "counts", "in", "id2counts", ":", "\n", "        ", "total_counts", "+=", "counts", "\n", "", "for", "i", "in", "range", "(", "len", "(", "id2counts", ")", ")", ":", "\n", "        ", "freq_scaled", "=", "id2counts", "[", "i", "]", "/", "total_counts", "\n", "rej_prob", ".", "append", "(", "1", "-", "min", "(", "1", ",", "math", ".", "sqrt", "(", "t", "/", "freq_scaled", ")", "+", "t", "/", "freq_scaled", ")", ")", "\n", "\n", "", "return", "rej_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_gpt2_ver2_paragraph.ll_loss": [[20, 27], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["def", "ll_loss", "(", "scores", ")", ":", "\n", "    ", "\"\"\"\n        Clamped logistic loss\n    \"\"\"", "\n", "scores", "=", "torch", ".", "clamp", "(", "scores", ",", "min", "=", "-", "20", ",", "max", "=", "20", ")", "\n", "new_scores", "=", "torch", ".", "mean", "(", "torch", ".", "log", "(", "1", "+", "torch", ".", "exp", "(", "-", "scores", ")", ")", ")", "\n", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_gpt2_ver2_paragraph.rejection_probs": [[28, 38], ["range", "len", "rej_prob.append", "min", "math.sqrt"], "function", ["None"], ["", "def", "rejection_probs", "(", "t", ",", "id2counts", ")", ":", "\n", "    ", "total_counts", "=", "0", "\n", "rej_prob", "=", "[", "]", "\n", "for", "counts", "in", "id2counts", ":", "\n", "        ", "total_counts", "+=", "counts", "\n", "", "for", "i", "in", "range", "(", "len", "(", "id2counts", ")", ")", ":", "\n", "        ", "freq_scaled", "=", "id2counts", "[", "i", "]", "/", "total_counts", "\n", "rej_prob", ".", "append", "(", "1", "-", "min", "(", "1", ",", "math", ".", "sqrt", "(", "t", "/", "freq_scaled", ")", "+", "t", "/", "freq_scaled", ")", ")", "\n", "\n", "", "return", "rej_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_bert_ver2_paragraph.ll_loss": [[21, 28], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["def", "ll_loss", "(", "scores", ")", ":", "\n", "    ", "\"\"\"\n        Clamped logistic loss\n    \"\"\"", "\n", "scores", "=", "torch", ".", "clamp", "(", "scores", ",", "min", "=", "-", "20", ",", "max", "=", "20", ")", "\n", "new_scores", "=", "torch", ".", "mean", "(", "torch", ".", "log", "(", "1", "+", "torch", ".", "exp", "(", "-", "scores", ")", ")", ")", "\n", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_bert_ver2_paragraph.rejection_probs": [[29, 39], ["range", "len", "rej_prob.append", "min", "math.sqrt"], "function", ["None"], ["", "def", "rejection_probs", "(", "t", ",", "id2counts", ")", ":", "\n", "    ", "total_counts", "=", "0", "\n", "rej_prob", "=", "[", "]", "\n", "for", "counts", "in", "id2counts", ":", "\n", "        ", "total_counts", "+=", "counts", "\n", "", "for", "i", "in", "range", "(", "len", "(", "id2counts", ")", ")", ":", "\n", "        ", "freq_scaled", "=", "id2counts", "[", "i", "]", "/", "total_counts", "\n", "rej_prob", ".", "append", "(", "1", "-", "min", "(", "1", ",", "math", ".", "sqrt", "(", "t", "/", "freq_scaled", ")", "+", "t", "/", "freq_scaled", ")", ")", "\n", "\n", "", "return", "rej_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_roberta_ver2_paragraph.ll_loss": [[20, 27], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["def", "ll_loss", "(", "scores", ")", ":", "\n", "    ", "\"\"\"\n        Clamped logistic loss\n    \"\"\"", "\n", "scores", "=", "torch", ".", "clamp", "(", "scores", ",", "min", "=", "-", "20", ",", "max", "=", "20", ")", "\n", "new_scores", "=", "torch", ".", "mean", "(", "torch", ".", "log", "(", "1", "+", "torch", ".", "exp", "(", "-", "scores", ")", ")", ")", "\n", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.epfml_X2Static.src.learn_from_roberta_ver2_paragraph.rejection_probs": [[28, 38], ["range", "len", "rej_prob.append", "min", "math.sqrt"], "function", ["None"], ["", "def", "rejection_probs", "(", "t", ",", "id2counts", ")", ":", "\n", "    ", "total_counts", "=", "0", "\n", "rej_prob", "=", "[", "]", "\n", "for", "counts", "in", "id2counts", ":", "\n", "        ", "total_counts", "+=", "counts", "\n", "", "for", "i", "in", "range", "(", "len", "(", "id2counts", ")", ")", ":", "\n", "        ", "freq_scaled", "=", "id2counts", "[", "i", "]", "/", "total_counts", "\n", "rej_prob", ".", "append", "(", "1", "-", "min", "(", "1", ",", "math", ".", "sqrt", "(", "t", "/", "freq_scaled", ")", "+", "t", "/", "freq_scaled", ")", ")", "\n", "\n", "", "return", "rej_prob", "\n", "\n"]]}