{"home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.HFSequenceClassificationMetadata.reinitialize": [[58, 61], ["setattr", "hf_utils.HFSequenceClassificationMetadata.init_fn", "hf_utils.HFSequenceClassificationMetadata.head_type"], "methods", ["None"], ["def", "reinitialize", "(", "self", ",", "config", ":", "PretrainedConfig", ",", "model", ":", "PreTrainedModel", ")", ":", "\n", "        ", "setattr", "(", "model", ",", "self", ".", "attr", ",", "self", ".", "head_type", "(", "config", ")", ")", "\n", "self", ".", "init_fn", "(", "config", ",", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils._reinit_classifier_head": [[33, 41], ["model.classifier.modules", "isinstance", "module.weight.data.normal_", "isinstance", "module.bias.data.zero_"], "function", ["None"], ["def", "_reinit_classifier_head", "(", "config", ":", "PretrainedConfig", ",", "model", ":", "PreTrainedModel", ")", ":", "\n", "    ", "for", "module", "in", "model", ".", "classifier", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "config", ".", "initializer_range", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils._xlnet_reinit_classifier_head": [[43, 45], ["model._init_weights"], "function", ["None"], ["", "", "", "def", "_xlnet_reinit_classifier_head", "(", "config", ":", "PretrainedConfig", ",", "model", ":", "XLNetForSequenceClassification", ")", ":", "\n", "    ", "model", ".", "_init_weights", "(", "model", ".", "logits_proj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils._bart_reinit_classifier_head": [[47, 50], ["model._init_weights", "model._init_weights"], "function", ["None"], ["", "def", "_bart_reinit_classifier_head", "(", "config", ":", "PretrainedConfig", ",", "model", ":", "BartForSequenceClassification", ")", ":", "\n", "    ", "model", ".", "_init_weights", "(", "model", ".", "classification_head", ".", "dense", ")", "\n", "model", ".", "_init_weights", "(", "model", ".", "classification_head", ".", "out_proj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_model_inputs": [[63, 78], ["dict"], "function", ["None"], ["", "", "def", "get_model_inputs", "(", "\n", "model_type", ":", "str", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", "\n", ")", "->", "Mapping", "[", "str", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "    ", "inputs", "=", "dict", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "        ", "inputs", "[", "\"labels\"", "]", "=", "labels", "\n", "\n", "", "if", "model_type", "!=", "\"distilbert\"", ":", "\n", "        ", "inputs", "[", "\"token_type_ids\"", "]", "=", "token_type_ids", "if", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_last_layer_hidden_states": [[98, 110], ["None"], "function", ["None"], ["def", "get_last_layer_hidden_states", "(", "\n", "config", ":", "PretrainedConfig", ",", "model_output", ":", "Union", "[", "SequenceClassifierOutput", ",", "MultipleChoiceModelOutput", "]", "\n", ")", "->", "Optional", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "if", "model_output", ".", "hidden_states", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "if", "config", ".", "model_type", "==", "\"xlnet\"", ":", "\n", "        ", "cls_index", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "cls_index", "=", "0", "\n", "\n", "", "return", "model_output", ".", "hidden_states", "[", "-", "1", "]", "[", ":", ",", "cls_index", ",", ":", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.KnnModelOutput.is_empty": [[37, 40], ["modeling.KnnModelOutput.selected_neighbors.nelement"], "methods", ["None"], ["@", "property", "\n", "def", "is_empty", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "selected_neighbors", "is", "None", "or", "self", ".", "selected_neighbors", ".", "nelement", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.KnnModelOutput.has_selected_ranks": [[41, 44], ["modeling.KnnModelOutput.selected_ranks.nelement"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_selected_ranks", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "selected_ranks", "is", "not", "None", "and", "self", ".", "selected_ranks", ".", "nelement", "(", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.KnnModelOutput.has_selected_distances": [[45, 48], ["modeling.KnnModelOutput.selected_distances.nelement"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_selected_distances", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "selected_distances", "is", "not", "None", "and", "self", ".", "selected_distances", ".", "nelement", "(", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.KDHead.__init__": [[51, 59], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "teacher", ":", "PreTrainedModel", ",", "\n", "temperature", ":", "float", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "teacher", "=", "teacher", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.KDHead.forward": [[60, 94], ["torch.nn.KLDivLoss", "torch.nn.KLDivLoss", "hf_utils.get_last_layer_hidden_states", "teacher_logits.size", "student_logits.size", "torch.nn.KLDivLoss.", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "modeling.KDHead.teacher", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_last_layer_hidden_states"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "student_logits", ",", "\n", "teacher_logits", "=", "None", ",", "\n", "input_ids", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "output_hidden_states", ":", "bool", "=", "None", ",", "\n", ")", ":", "\n", "        ", "teacher_hidden_states", "=", "None", "\n", "if", "teacher_logits", "is", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "teacher_output", "=", "self", ".", "teacher", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", ")", "\n", "\n", "", "teacher_logits", "=", "teacher_output", ".", "logits", "\n", "teacher_hidden_states", "=", "get_last_layer_hidden_states", "(", "self", ".", "teacher", ".", "config", ",", "teacher_output", ")", "\n", "\n", "", "assert", "teacher_logits", ".", "size", "(", ")", "==", "student_logits", ".", "size", "(", ")", "\n", "\n", "loss_fct", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "\"batchmean\"", ")", "\n", "loss_ce", "=", "(", "\n", "loss_fct", "(", "\n", "F", ".", "log_softmax", "(", "student_logits", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "F", ".", "softmax", "(", "teacher_logits", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", ")", "\n", "*", "(", "self", ".", "temperature", "**", "2", ")", "\n", ")", "\n", "\n", "return", "loss_ce", ",", "teacher_hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.KDHeadFast.__init__": [[97, 105], ["torch.nn.Module.__init__", "modeling.KDHeadFast.register_buffer"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "teacher_logits", ":", "torch", ".", "Tensor", ",", "\n", "temperature", ":", "float", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "\"teacher_logits\"", ",", "teacher_logits", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.KDHeadFast.forward": [[106, 131], ["torch.nn.KLDivLoss", "torch.nn.KLDivLoss", "teacher_logits.size", "student_logits.size", "torch.nn.KLDivLoss.", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "student_logits", ",", "\n", "teacher_logits", "=", "None", ",", "\n", "example_indices", "=", "None", ",", "\n", "augmented_indices", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "teacher_logits", "is", "None", ":", "\n", "            ", "assert", "example_indices", "is", "not", "None", "\n", "if", "augmented_indices", "is", "None", ":", "\n", "                ", "augmented_indices", "=", "torch", ".", "zeros_like", "(", "example_indices", ")", "\n", "", "teacher_logits", "=", "self", ".", "teacher_logits", "[", "example_indices", ",", "augmented_indices", "]", "\n", "\n", "", "assert", "teacher_logits", ".", "size", "(", ")", "==", "student_logits", ".", "size", "(", ")", "\n", "\n", "loss_fct", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "\"batchmean\"", ")", "\n", "loss_ce", "=", "(", "\n", "loss_fct", "(", "\n", "F", ".", "log_softmax", "(", "student_logits", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "F", ".", "softmax", "(", "teacher_logits", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", ")", "\n", "*", "(", "self", ".", "temperature", "**", "2", ")", "\n", ")", "\n", "\n", "return", "loss_ce", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.ReferenceL2Head.__init__": [[134, 148], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.PairwiseDistance", "torch.nn.PairwiseDistance", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.MSELoss", "torch.nn.MSELoss"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ref_dim", ":", "int", ",", "teacher_dim", ":", "int", ",", "student_dim", ":", "int", ",", "loss_type", ":", "str", "=", "\"MSE\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "teacher_proj", "=", "nn", ".", "Linear", "(", "ref_dim", ",", "teacher_dim", ")", "\n", "self", ".", "teacher_dim", "=", "teacher_dim", "\n", "\n", "self", ".", "student_proj", "=", "nn", ".", "Linear", "(", "ref_dim", ",", "student_dim", ")", "\n", "self", ".", "student_dim", "=", "student_dim", "\n", "\n", "if", "loss_type", "in", "(", "\"MAE\"", ",", "\"L1\"", ")", ":", "\n", "            ", "self", ".", "loss_fn", "=", "nn", ".", "L1Loss", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_fn", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "", "self", ".", "pdist", "=", "nn", ".", "PairwiseDistance", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.ReferenceL2Head.forward": [[149, 154], ["modeling.ReferenceL2Head.loss_fn", "modeling.ReferenceL2Head.pdist", "numpy.sqrt", "modeling.ReferenceL2Head.pdist", "numpy.sqrt", "modeling.ReferenceL2Head.teacher_proj", "modeling.ReferenceL2Head.student_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "ref_hidden_states", ",", "teacher_hidden_states", ",", "student_hidden_states", ")", ":", "\n", "        ", "d1", "=", "self", ".", "pdist", "(", "self", ".", "teacher_proj", "(", "ref_hidden_states", ")", ",", "teacher_hidden_states", ")", "/", "np", ".", "sqrt", "(", "self", ".", "teacher_dim", ")", "\n", "d2", "=", "self", ".", "pdist", "(", "self", ".", "student_proj", "(", "ref_hidden_states", ")", ",", "student_hidden_states", ")", "/", "np", ".", "sqrt", "(", "self", ".", "student_dim", ")", "\n", "\n", "return", "self", ".", "loss_fn", "(", "d1", ",", "d2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.MinimaxKnnHead.__init__": [[157, 179], ["torch.nn.Module.__init__", "modeling.MinimaxKnnHead._detach", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__init__", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.MinimaxKnnHeadFast._detach"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "teacher", ":", "PreTrainedModel", ",", "\n", "student", ":", "PreTrainedModel", ",", "\n", "temperature", ":", "float", ",", "\n", "min_distance", ":", "float", "=", "0.0", ",", "\n", "max_distance", ":", "float", "=", "0.0", ",", "\n", "maxim_func", ":", "str", "=", "\"ce\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "teacher", "=", "teacher", "\n", "self", ".", "student", "=", "self", ".", "_detach", "(", "student", ")", "\n", "\n", "if", "self", ".", "teacher", ".", "config", ".", "hidden_size", "!=", "self", ".", "student", ".", "config", ".", "hidden_size", ":", "\n", "            ", "self", ".", "teacher_proj", "=", "nn", ".", "Linear", "(", "self", ".", "teacher", ".", "config", ".", "hidden_size", ",", "self", ".", "student", ".", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "teacher_proj", "=", "lambda", "t", ":", "t", "\n", "\n", "", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "min_distance", "=", "min_distance", "\n", "self", ".", "max_distance", "=", "max_distance", "\n", "self", ".", "maxim_func", "=", "maxim_func", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.MinimaxKnnHead._detach": [[180, 185], ["type", "type.", "type.load_state_dict", "model.state_dict"], "methods", ["None"], ["", "def", "_detach", "(", "self", ",", "model", ":", "PreTrainedModel", ")", "->", "PreTrainedModel", ":", "\n", "        ", "model_class", "=", "type", "(", "model", ")", "\n", "detached_model", "=", "model_class", "(", "model", ".", "config", ")", "\n", "detached_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "detached_model", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.MinimaxKnnHead.forward": [[186, 290], ["dict", "hf_utils.get_last_layer_hidden_states", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "modeling.KnnModelOutput", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "modeling.MinimaxKnnHead.student", "modeling.MinimaxKnnHead.teacher", "hf_utils.get_last_layer_hidden_states", "torch.acos", "torch.acos", "torch.acos", "torch.acos", "torch.nn.PairwiseDistance", "torch.nn.PairwiseDistance", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss.sum", "nn.KLDivLoss.sum.nelement", "range", "torch.nn.CosineSimilarity.", "torch.nn.PairwiseDistance.", "numpy.sqrt", "torch_scatter.scatter_max", "float", "modeling.MinimaxKnnHead.teacher_proj", "torch.nn.KLDivLoss.", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "_dists.isinf", "_dists.isinf"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_last_layer_hidden_states", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_last_layer_hidden_states"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "augment_rank", ":", "int", ",", "\n", "nn_mask", ",", "\n", "tea_orig_hidden_states", ",", "\n", "input_ids", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "nn_ranks", "=", "None", ",", "\n", ")", ":", "\n", "        ", "inputs", "=", "dict", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", ")", "\n", "l2_enabled", "=", "self", ".", "maxim_func", "==", "\"l2\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "stu_output", "=", "self", ".", "student", "(", "**", "inputs", ",", "output_hidden_states", "=", "l2_enabled", ")", "\n", "tea_output", "=", "self", ".", "teacher", "(", "**", "inputs", ",", "output_hidden_states", "=", "True", ")", "\n", "\n", "", "stu_logits", "=", "stu_output", ".", "logits", "\n", "tea_logits", "=", "tea_output", ".", "logits", "\n", "tea_hidden_states", "=", "get_last_layer_hidden_states", "(", "self", ".", "teacher", ".", "config", ",", "tea_output", ")", "\n", "if", "l2_enabled", ":", "\n", "            ", "stu_hidden_states", "=", "get_last_layer_hidden_states", "(", "self", ".", "student", ".", "config", ",", "stu_output", ")", "\n", "\n", "", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "-", "1", ")", "\n", "tea_orig_hidden_states", "=", "tea_orig_hidden_states", "[", "nn_mask", "]", "\n", "nn_distances", "=", "torch", ".", "acos", "(", "cos", "(", "tea_orig_hidden_states", ",", "tea_hidden_states", ")", ")", "/", "np", ".", "pi", "\n", "\n", "min_filtered_ranks", ",", "max_filtered_ranks", "=", "None", ",", "None", "\n", "if", "self", ".", "max_distance", ">", "0", "or", "self", ".", "min_distance", ">", "0", ":", "\n", "            ", "if", "nn_ranks", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "max_distance", ">", "0", ":", "\n", "                    ", "max_filtered_ranks", "=", "nn_ranks", "[", "nn_distances", ">", "self", ".", "max_distance", "]", "\n", "", "if", "self", ".", "min_distance", ">", "0", ":", "\n", "                    ", "min_filtered_ranks", "=", "nn_ranks", "[", "nn_distances", "<", "self", ".", "min_distance", "]", "\n", "\n", "", "", "if", "self", ".", "max_distance", ">", "0", ":", "\n", "                ", "nn_mask", "=", "nn_mask", "[", "nn_distances", "<=", "self", ".", "max_distance", "]", "\n", "stu_logits", "=", "stu_logits", "[", "nn_distances", "<=", "self", ".", "max_distance", ",", ":", "]", "\n", "tea_logits", "=", "tea_logits", "[", "nn_distances", "<=", "self", ".", "max_distance", ",", ":", "]", "\n", "if", "l2_enabled", ":", "\n", "                    ", "stu_hidden_states", "=", "stu_hidden_states", "[", "nn_distances", "<=", "self", ".", "max_distance", ",", ":", "]", "\n", "tea_hidden_states", "=", "tea_hidden_states", "[", "nn_distances", "<=", "self", ".", "max_distance", ",", ":", "]", "\n", "", "nn_distances", "=", "nn_distances", "[", "nn_distances", "<=", "self", ".", "max_distance", "]", "\n", "\n", "", "if", "self", ".", "min_distance", ">", "0", ":", "\n", "                ", "nn_mask", "=", "nn_mask", "[", "nn_distances", ">=", "self", ".", "min_distance", "]", "\n", "stu_logits", "=", "stu_logits", "[", "nn_distances", ">=", "self", ".", "min_distance", ",", ":", "]", "\n", "tea_logits", "=", "tea_logits", "[", "nn_distances", ">=", "self", ".", "min_distance", ",", ":", "]", "\n", "if", "l2_enabled", ":", "\n", "                    ", "stu_hidden_states", "=", "stu_hidden_states", "[", "nn_distances", ">=", "self", ".", "min_distance", ",", ":", "]", "\n", "tea_hidden_states", "=", "tea_hidden_states", "[", "nn_distances", ">=", "self", ".", "min_distance", ",", ":", "]", "\n", "", "nn_distances", "=", "nn_distances", "[", "nn_distances", ">=", "self", ".", "min_distance", "]", "\n", "\n", "", "", "if", "l2_enabled", ":", "\n", "            ", "pdist", "=", "nn", ".", "PairwiseDistance", "(", ")", "\n", "distances", "=", "pdist", "(", "self", ".", "teacher_proj", "(", "tea_hidden_states", ")", ",", "stu_hidden_states", ")", "/", "np", ".", "sqrt", "(", "\n", "self", ".", "student", ".", "config", ".", "hidden_size", "\n", ")", "\n", "", "else", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "\"none\"", ")", "\n", "distances", "=", "loss_fct", "(", "\n", "F", ".", "log_softmax", "(", "stu_logits", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "F", ".", "softmax", "(", "tea_logits", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "selected_ranks", "=", "None", "\n", "if", "distances", ".", "nelement", "(", ")", ">", "0", ":", "\n", "            ", "_dists", ",", "_indices", "=", "None", ",", "None", "\n", "\n", "for", "j", "in", "range", "(", "augment_rank", ")", ":", "\n", "                ", "_dists", ",", "_indices", "=", "scatter_max", "(", "distances", ",", "nn_mask", ")", "\n", "if", "j", ">", "0", "or", "self", ".", "max_distance", ">", "0", "or", "self", ".", "min_distance", ">", "0", ":", "\n", "                    ", "_indices", "=", "_indices", "[", "(", "_dists", "!=", "0", ")", "&", "~", "_dists", ".", "isinf", "(", ")", "]", "\n", "_dists", "=", "_dists", "[", "(", "_dists", "!=", "0", ")", "&", "~", "_dists", ".", "isinf", "(", ")", "]", "\n", "\n", "", "distances", "[", "_indices", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "", "selected_indices", "=", "_indices", "\n", "if", "nn_ranks", "is", "not", "None", ":", "\n", "                ", "selected_ranks", "=", "nn_ranks", "[", "selected_indices", "]", "\n", "\n", "", "selected_dists", "=", "nn_distances", "[", "selected_indices", "]", "\n", "", "else", ":", "\n", "            ", "selected_indices", "=", "None", "\n", "selected_dists", "=", "None", "\n", "\n", "# if nn_rank is not None:", "\n", "#     rank_counts = torch.zeros((num_augments,), dtype=torch.long).scatter_add_(", "\n", "#         nn_rank[selected_indices], torch.ones_like(selected_indices)", "\n", "#     )", "\n", "# else:", "\n", "#     rank_counts = None", "\n", "\n", "", "return", "KnnModelOutput", "(", "\n", "tea_logits", "[", "selected_indices", "]", ",", "\n", "selected_indices", ",", "\n", "selected_dists", ",", "\n", "selected_ranks", ",", "\n", "max_filtered_ranks", ",", "\n", "min_filtered_ranks", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.MinimaxKnnHeadFast.__init__": [[294, 305], ["torch.nn.Module.__init__", "modeling.MinimaxKnnHeadFast.register_buffer"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "teacher_logits", ":", "torch", ".", "Tensor", ",", "\n", "student", ":", "PreTrainedModel", ",", "\n", "temperature", ":", "float", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "\"teacher_logits\"", ",", "teacher_logits", "[", ":", ",", "1", ":", "]", ")", "\n", "self", ".", "student", "=", "student", "\n", "# self.student = self._detach(student)", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.MinimaxKnnHeadFast._detach": [[306, 315], ["type", "type.", "type.load_state_dict", "type.parameters", "model.state_dict"], "methods", ["None"], ["", "def", "_detach", "(", "self", ",", "model", ":", "PreTrainedModel", ")", "->", "PreTrainedModel", ":", "\n", "        ", "model_class", "=", "type", "(", "model", ")", "\n", "detached_model", "=", "model_class", "(", "model", ".", "config", ")", "\n", "detached_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "\n", "for", "p", "in", "detached_model", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "return", "detached_model", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.modeling.MinimaxKnnHeadFast.forward": [[316, 379], ["dict", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss.sum", "modeling.KnnModelOutput", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "modeling.MinimaxKnnHeadFast.student", "nn.KLDivLoss.sum.nelement", "range", "torch.nn.KLDivLoss.", "torch_scatter.scatter_max", "float", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "_dists.isinf", "_dists.isinf"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "augment_rank", ":", "int", ",", "\n", "nn_mask", ",", "\n", "example_indices", ",", "\n", "input_ids", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "augmented_indices", "=", "None", ",", "\n", "nn_ranks", "=", "None", ",", "\n", ")", ":", "\n", "        ", "assert", "example_indices", "is", "not", "None", "\n", "\n", "inputs", "=", "dict", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "stu_output", "=", "self", ".", "student", "(", "**", "inputs", ")", "\n", "\n", "", "stu_logits", "=", "stu_output", ".", "logits", "\n", "tea_logits", "=", "self", ".", "teacher_logits", "[", "example_indices", "[", "nn_mask", "]", ",", "augmented_indices", ",", ":", "]", "\n", "\n", "loss_fct", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "\"none\"", ")", "\n", "distances", "=", "loss_fct", "(", "\n", "F", ".", "log_softmax", "(", "stu_logits", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "F", ".", "softmax", "(", "tea_logits", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n", "selected_ranks", "=", "None", "\n", "if", "distances", ".", "nelement", "(", ")", ">", "0", ":", "\n", "            ", "_dists", ",", "_indices", "=", "None", ",", "None", "\n", "\n", "for", "j", "in", "range", "(", "augment_rank", ")", ":", "\n", "                ", "_dists", ",", "_indices", "=", "scatter_max", "(", "distances", ",", "nn_mask", ")", "\n", "if", "j", ">", "0", ":", "\n", "                    ", "_indices", "=", "_indices", "[", "(", "_dists", "!=", "0", ")", "&", "~", "_dists", ".", "isinf", "(", ")", "]", "\n", "_dists", "=", "_dists", "[", "(", "_dists", "!=", "0", ")", "&", "~", "_dists", ".", "isinf", "(", ")", "]", "\n", "\n", "", "distances", "[", "_indices", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "", "selected_indices", "=", "_indices", "\n", "if", "nn_ranks", "is", "not", "None", ":", "\n", "                ", "selected_ranks", "=", "nn_ranks", "[", "selected_indices", "]", "\n", "", "", "else", ":", "\n", "            ", "selected_indices", "=", "None", "\n", "\n", "# if nn_rank is not None:", "\n", "#     rank_counts = torch.zeros((num_augments,), dtype=torch.long).scatter_add_(", "\n", "#         nn_rank[selected_indices], torch.ones_like(selected_indices)", "\n", "#     )", "\n", "# else:", "\n", "#     rank_counts = None", "\n", "\n", "", "return", "KnnModelOutput", "(", "\n", "tea_logits", "[", "selected_indices", "]", ",", "\n", "selected_indices", ",", "\n", "None", ",", "\n", "selected_ranks", ",", "\n", "None", ",", "\n", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.log_utils.set_global_logging_error": [[5, 7], ["log_utils.set_global_logging_level"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.log_utils.set_global_logging_level"], ["def", "set_global_logging_error", "(", "prefixes", "=", "None", ")", ":", "\n", "    ", "set_global_logging_level", "(", "logging", ".", "ERROR", ",", "prefixes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.log_utils.set_global_logging_warning": [[9, 11], ["log_utils.set_global_logging_level"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.log_utils.set_global_logging_level"], ["", "def", "set_global_logging_warning", "(", "prefixes", "=", "None", ")", ":", "\n", "    ", "set_global_logging_level", "(", "logging", ".", "WARNING", ",", "prefixes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.log_utils.set_global_logging_info": [[13, 15], ["log_utils.set_global_logging_level"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.log_utils.set_global_logging_level"], ["", "def", "set_global_logging_info", "(", "prefixes", "=", "None", ")", ":", "\n", "    ", "set_global_logging_level", "(", "logging", ".", "INFO", ",", "prefixes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.log_utils.set_global_logging_level": [[17, 37], ["re.compile", "re.match", "logging.getLogger().setLevel", "logging.getLogger", "logging.ERROR", "logging.WARNING", "logging.INFO"], "function", ["None"], ["", "def", "set_global_logging_level", "(", "level", "=", "logging", ".", "ERROR", ",", "prefixes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Taken from: https://github.com/huggingface/transformers/issues/3050#issuecomment-682167272\n    Override logging levels of different modules based on their name as a prefix.\n    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n\n    Args:\n        - level: desired level. e.g. logging.INFO. Optional. Default is logging.ERROR\n        - prefices: list of one or more str prefices to match (e.g. [\"transformers\", \"torch\"]). Optional.\n          Default is `[\"\"]` to match all active loggers.\n          The match is a case-sensitive `module_name.startswith(prefix)`\n    \"\"\"", "\n", "if", "prefixes", "is", "None", ":", "\n", "        ", "prefixes", "=", "[", "\"\"", "]", "\n", "\n", "", "prefix_re", "=", "re", ".", "compile", "(", "fr'^(?:{ \"|\".join(prefixes) })'", ")", "\n", "\n", "for", "name", "in", "logging", ".", "root", ".", "manager", ".", "loggerDict", ":", "\n", "        ", "if", "re", ".", "match", "(", "prefix_re", ",", "name", ")", ":", "\n", "            ", "logging", ".", "getLogger", "(", "name", ")", ".", "setLevel", "(", "level", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.__init__": [[72, 124], ["pytorch_lightning.LightningModule.__init__", "lightning_base.BaseTransformer.save_hyperparameters", "pathlib.Path", "transformers.AutoConfig.from_pretrained", "getattr", "transformers.AutoTokenizer.from_pretrained", "lightning_base.BaseTransformer.model_type.from_pretrained", "hasattr", "setattr", "getattr", "bool"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ":", "argparse", ".", "Namespace", ",", "\n", "num_labels", "=", "None", ",", "\n", "mode", "=", "\"base\"", ",", "\n", "config", "=", "None", ",", "\n", "tokenizer", "=", "None", ",", "\n", "model", "=", "None", ",", "\n", "**", "config_kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize a model, tokenizer and config.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "save_hyperparameters", "(", "hparams", ")", "\n", "self", ".", "train_loader", "=", "None", "\n", "self", ".", "step_count", "=", "0", "\n", "self", ".", "output_dir", "=", "Path", "(", "self", ".", "hparams", ".", "output_dir", ")", "\n", "cache_dir", "=", "self", ".", "hparams", ".", "cache_dir", "\n", "\n", "if", "config", "is", "None", ":", "\n", "            ", "self", ".", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "config_name", "if", "self", ".", "hparams", ".", "config_name", "else", "self", ".", "hparams", ".", "model_name_or_path", ",", "\n", "**", "(", "{", "\"num_labels\"", ":", "num_labels", "}", "if", "num_labels", "is", "not", "None", "else", "{", "}", ")", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "**", "config_kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "config", ":", "PretrainedConfig", "=", "config", "\n", "\n", "", "extra_model_params", "=", "(", "\"encoder_layerdrop\"", ",", "\"decoder_layerdrop\"", ",", "\"dropout\"", ",", "\"attention_dropout\"", ")", "\n", "for", "p", "in", "extra_model_params", ":", "\n", "            ", "if", "getattr", "(", "self", ".", "hparams", ",", "p", ",", "None", ")", ":", "\n", "                ", "assert", "hasattr", "(", "self", ".", "config", ",", "p", ")", ",", "f\"model config doesn't have a `{p}` attribute\"", "\n", "setattr", "(", "self", ".", "config", ",", "p", ",", "getattr", "(", "self", ".", "hparams", ",", "p", ")", ")", "\n", "\n", "", "", "if", "tokenizer", "is", "None", ":", "\n", "            ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "tokenizer_name", "if", "self", ".", "hparams", ".", "tokenizer_name", "else", "self", ".", "hparams", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer", ":", "PreTrainedTokenizer", "=", "tokenizer", "\n", "", "self", ".", "model_type", "=", "MODEL_MODES", "[", "mode", "]", "\n", "if", "model", "is", "None", ":", "\n", "            ", "self", ".", "model", "=", "self", ".", "model_type", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "self", ".", "hparams", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "self", ".", "config", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.load_hf_checkpoint": [[125, 127], ["lightning_base.BaseTransformer.model_type.from_pretrained"], "methods", ["None"], ["", "", "def", "load_hf_checkpoint", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "model", "=", "self", ".", "model_type", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.get_lr_scheduler": [[128, 147], ["lightning_base.BaseTransformer.total_steps", "dict", "get_schedule_func"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.total_steps"], ["", "def", "get_lr_scheduler", "(", "self", ")", ":", "\n", "        ", "get_schedule_func", "=", "arg_to_scheduler", "[", "self", ".", "hparams", ".", "lr_scheduler", "]", "\n", "\n", "total_steps", "=", "self", ".", "total_steps", "(", ")", "\n", "if", "self", ".", "hparams", ".", "warmup_ratio", ">", "0", ":", "\n", "            ", "warmup_steps", "=", "self", ".", "hparams", ".", "warmup_ratio", "*", "total_steps", "\n", "", "else", ":", "\n", "            ", "warmup_steps", "=", "self", ".", "hparams", ".", "warmup_steps", "\n", "\n", "", "sch_kwargs", "=", "dict", "(", "\n", "num_warmup_steps", "=", "warmup_steps", ",", "\n", ")", "\n", "\n", "if", "self", ".", "hparams", ".", "lr_scheduler", "!=", "\"constant\"", ":", "\n", "            ", "sch_kwargs", "[", "\"num_training_steps\"", "]", "=", "total_steps", "\n", "\n", "", "scheduler", "=", "get_schedule_func", "(", "self", ".", "opt", ",", "**", "sch_kwargs", ")", "\n", "scheduler", "=", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", ",", "\"frequency\"", ":", "1", "}", "\n", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.configure_optimizers": [[148, 165], ["lightning_base.BaseTransformer.get_trainable_parameters", "lightning_base.BaseTransformer.get_lr_scheduler", "transformers.optimization.Adafactor", "transformers.AdamW"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_trainable_parameters", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.get_lr_scheduler"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"", "\n", "optimizer_grouped_parameters", "=", "self", ".", "get_trainable_parameters", "(", ")", "\n", "if", "self", ".", "hparams", ".", "adafactor", ":", "\n", "            ", "optimizer", "=", "Adafactor", "(", "\n", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ",", "scale_parameter", "=", "False", ",", "relative_step", "=", "False", "\n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ",", "eps", "=", "self", ".", "hparams", ".", "adam_epsilon", "\n", ")", "\n", "", "self", ".", "opt", "=", "optimizer", "\n", "\n", "scheduler", "=", "self", ".", "get_lr_scheduler", "(", ")", "\n", "\n", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.get_trainable_parameters": [[166, 180], ["model.named_parameters", "model.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "get_trainable_parameters", "(", "self", ")", ":", "\n", "        ", "model", "=", "self", ".", "model", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "hparams", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "return", "optimizer_grouped_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.test_step": [[181, 183], ["lightning_base.BaseTransformer.validation_step"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.validation_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "return", "self", ".", "validation_step", "(", "batch", ",", "batch_nb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.test_epoch_end": [[184, 186], ["lightning_base.BaseTransformer.validation_end"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "self", ".", "validation_end", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.get_number_of_gpus": [[187, 192], ["torch.cuda.device_count"], "methods", ["None"], ["", "def", "get_number_of_gpus", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "hparams", ".", "gpus", "==", "-", "1", ":", "\n", "            ", "return", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "hparams", ".", "gpus", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.total_steps": [[193, 202], ["max", "len", "lightning_base.BaseTransformer.get_number_of_gpus"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.get_number_of_gpus"], ["", "", "def", "total_steps", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"The number of total training steps that will be run. Used for lr scheduler purposes.\"\"\"", "\n", "if", "self", ".", "train_loader", "is", "None", ":", "\n", "            ", "return", "0", "\n", "", "else", ":", "\n", "            ", "num_devices", "=", "max", "(", "1", ",", "self", ".", "get_number_of_gpus", "(", ")", ")", "\n", "effective_batch_size", "=", "self", ".", "hparams", ".", "train_batch_size", "*", "self", ".", "hparams", ".", "accumulate_grad_batches", "*", "num_devices", "\n", "dataset_size", "=", "len", "(", "self", ".", "train_loader", ".", "dataset", ")", "\n", "return", "(", "dataset_size", "/", "effective_batch_size", ")", "*", "self", ".", "hparams", ".", "max_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.setup": [[203, 206], ["lightning_base.BaseTransformer.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_dataloader"], ["", "", "def", "setup", "(", "self", ",", "mode", ")", ":", "\n", "        ", "if", "mode", "==", "\"fit\"", ":", "\n", "            ", "self", ".", "train_loader", "=", "self", ".", "get_dataloader", "(", "\"train\"", ",", "self", ".", "hparams", ".", "train_batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.get_dataloader": [[207, 209], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "get_dataloader", "(", "self", ",", "type_path", ",", "batch_size", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"You must implement this for your task\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.train_dataloader": [[210, 212], ["None"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.val_dataloader": [[213, 215], ["lightning_base.BaseTransformer.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_dataloader", "(", "\"dev\"", ",", "self", ".", "hparams", ".", "eval_batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.test_dataloader": [[216, 218], ["lightning_base.BaseTransformer.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_dataloader"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_dataloader", "(", "\"test\"", ",", "self", ".", "hparams", ".", "eval_batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer._feature_file": [[219, 226], ["os.path.join", "list().pop", "str", "list", "filter", "lightning_base.BaseTransformer.hparams.model_name_or_path.split"], "methods", ["None"], ["", "def", "_feature_file", "(", "self", ",", "mode", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "hparams", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "self", ".", "hparams", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "self", ".", "hparams", ".", "max_seq_length", ")", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.on_save_checkpoint": [[229, 238], ["lightning_base.BaseTransformer.output_dir.joinpath", "lightning_base.BaseTransformer.model.save_pretrained", "lightning_base.BaseTransformer.tokenizer.save_pretrained", "torch.save", "lr_scheduler.state_dict", "os.path.join"], "methods", ["None"], ["", "@", "pl", ".", "utilities", ".", "rank_zero_only", "\n", "def", "on_save_checkpoint", "(", "self", ",", "checkpoint", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "save_path", "=", "self", ".", "output_dir", ".", "joinpath", "(", "\"best_tfmr\"", ")", "\n", "self", ".", "model", ".", "config", ".", "save_step", "=", "self", ".", "step_count", "\n", "self", ".", "model", ".", "save_pretrained", "(", "save_path", ")", "\n", "self", ".", "tokenizer", ".", "save_pretrained", "(", "save_path", ")", "\n", "\n", "lr_scheduler", "=", "self", ".", "trainer", ".", "lr_schedulers", "[", "0", "]", "[", "\"scheduler\"", "]", "\n", "torch", ".", "save", "(", "lr_scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "\"scheduler.pt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.add_model_specific_args": [[239, 312], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder_layerdrop\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Encoder layer dropout probability (Optional). Goes into model.config\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_layerdrop\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Decoder layer dropout probability (Optional). Goes into model.config\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Dropout probability (Optional). Goes into model.config\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention_dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Attention dropout probability (Optional). Goes into model.config\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "3e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lr_scheduler\"", ",", "\n", "default", "=", "\"linear\"", ",", "\n", "choices", "=", "arg_to_scheduler_choices", ",", "\n", "metavar", "=", "arg_to_scheduler_metavar", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Learning rate scheduler\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_ratio\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Linear warmup over a ratio of train steps. Overrides `--warmup_steps`.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "default", "=", "6", ",", "type", "=", "int", ",", "help", "=", "\"kwarg passed to DataLoader\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "dest", "=", "\"max_epochs\"", ",", "default", "=", "3", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--adafactor\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--padding\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "choices", "=", "(", "\"longest\"", ",", "\"max_length\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pad_to_multiple_of\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"See https://developer.nvidia.com/blog/optimizing-gpu-performance-tensor-cores/\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.LoggingCallback.on_batch_end": [[316, 320], ["pl_module.logger.log_metrics", "enumerate", "lr_scheduler.get_last_lr"], "methods", ["None"], ["    ", "def", "on_batch_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "lr_scheduler", "=", "trainer", ".", "lr_schedulers", "[", "0", "]", "[", "\"scheduler\"", "]", "\n", "lrs", "=", "{", "f\"lr/group_{i}\"", ":", "lr", "for", "i", ",", "lr", "in", "enumerate", "(", "lr_scheduler", ".", "get_last_lr", "(", ")", ")", "}", "\n", "pl_module", ".", "logger", ".", "log_metrics", "(", "lrs", ",", "trainer", ".", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.LoggingCallback.on_validation_end": [[321, 334], ["pytorch_lightning.utilities.rank_zero_info", "sorted", "pytorch_lightning.utilities.rank_zero_info", "isinstance", "pytorch_lightning.utilities.rank_zero_info", "pytorch_lightning.utilities.rank_zero_info", "str", "cl.best_score.item"], "methods", ["None"], ["", "def", "on_validation_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "pl_module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "rank_zero_info", "(", "\"\\n***** Validation results *****\"", ")", "\n", "for", "cl", "in", "trainer", ".", "callbacks", ":", "\n", "            ", "if", "isinstance", "(", "cl", ",", "pl", ".", "callbacks", ".", "EarlyStopping", ")", ":", "\n", "                ", "rank_zero_info", "(", "f\"early_stop {cl.wait_count}/{cl.patience} best = {cl.best_score.item()}\"", ")", "\n", "break", "\n", "\n", "", "", "metrics", "=", "trainer", ".", "callback_metrics", "\n", "# Log results", "\n", "for", "key", "in", "sorted", "(", "metrics", ")", ":", "\n", "            ", "if", "key", "not", "in", "[", "\"log\"", ",", "\"progress_bar\"", "]", ":", "\n", "                ", "rank_zero_info", "(", "\"{} = {}\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "", "", "rank_zero_info", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.LoggingCallback.on_test_end": [[335, 353], ["getattr", "any", "os.path.join", "pytorch_lightning.utilities.rank_zero_info", "open", "sorted", "pytorch_lightning.utilities.rank_zero_info", "writer.write", "str", "str"], "methods", ["None"], ["", "def", "on_test_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "pl_module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "metrics", "=", "trainer", ".", "callback_metrics", "\n", "\n", "if", "getattr", "(", "pl_module", ".", "hparams", ",", "\"test_mode\"", ",", "False", ")", ":", "\n", "            ", "results_file_prefix", "=", "pl_module", ".", "hparams", ".", "test_mode", "\n", "", "else", ":", "\n", "            ", "results_file_prefix", "=", "\"dev\"", "\n", "\n", "", "if", "any", "(", "key", "not", "in", "(", "\"log\"", ",", "\"progress_bar\"", ")", "for", "key", "in", "metrics", ")", ":", "\n", "            ", "rank_zero_info", "(", "f\"\\n***** {results_file_prefix} results *****\"", ")", "\n", "\n", "# Log and save results to file", "\n", "", "output_test_results_file", "=", "os", ".", "path", ".", "join", "(", "pl_module", ".", "hparams", ".", "output_dir", ",", "f\"{results_file_prefix}_results.txt\"", ")", "\n", "with", "open", "(", "output_test_results_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "metrics", ")", ":", "\n", "                ", "if", "key", "not", "in", "[", "\"log\"", ",", "\"progress_bar\"", "]", ":", "\n", "                    ", "rank_zero_info", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.add_generic_args": [[355, 447], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "", "", "", "", "def", "add_generic_args", "(", "parser", ",", "root_dir", ")", "->", "None", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Overwrite the content of the output directory.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--n_tpu_cores\"", ",", "dest", "=", "\"tpu_cores\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gpus\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The number of GPUs allocated for this, it is by default -1 meaning all GPUs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--accelerator\"", ",", "\n", "default", "=", "None", ",", "\n", "choices", "=", "(", "\"dp\"", ",", "\"ddp\"", ",", "\"ddp2\"", ",", "\"ddp_cpu\"", ",", "\"ddp_spawn\"", ")", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The accelerator backend for multi-GPU/CPU environment\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "dest", "=", "\"gradient_clip_val\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run predictions on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_infer\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run inference on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_test\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run predictions on the test set if it includes labels.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "dest", "=", "\"accumulate_grad_batches\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_interval\"", ",", "\n", "dest", "=", "\"val_check_interval\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.25", ",", "\n", "help", "=", "\"Run an evaluation every X steps (int) or X times (float) within an epoch.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--log_interval\"", ",", "\n", "dest", "=", "\"log_every_n_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "10", ",", "\n", "help", "=", "\"Controls logging frequency during training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--flush_log_interval\"", ",", "\n", "dest", "=", "\"flush_logs_every_n_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "100", ",", "\n", "help", "=", "\"Controls log writing frequency during training\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--patience\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "5", ",", "\n", "help", "=", "\"Number of evaluation runs with no improvement after which training will be stopped (For early stopping).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--min_delta\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.0", ",", "\n", "help", "=", "\"An absolute change of less than `min_delta`, will count as no improvement (For early stopping).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--deterministic\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"enables cudnn.deterministic for reproducibility.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.generic_train": [[450, 496], ["pytorch_lightning.seed_everything", "pathlib.Path", "pathlib.Path.mkdir", "pytorch_lightning.Trainer.from_argparse_args", "pathlib.Path.exists", "shutil.rmtree", "pytorch_lightning.callbacks.ModelCheckpoint", "lightning_base.LoggingCallback", "pl.Trainer.from_argparse_args.fit"], "function", ["None"], ["", "def", "generic_train", "(", "\n", "model", ":", "BaseTransformer", ",", "\n", "args", ":", "argparse", ".", "Namespace", ",", "\n", "logger", "=", "True", ",", "# can pass WandbLogger() here", "\n", "extra_callbacks", "=", "None", ",", "\n", "checkpoint_callback", "=", "None", ",", "\n", "logging_callback", "=", "None", ",", "\n", "weights_summary", "=", "None", ",", "\n", "**", "extra_train_kwargs", ",", "\n", ")", ":", "\n", "    ", "pl", ".", "seed_everything", "(", "args", ".", "seed", ")", "\n", "\n", "extra_callbacks", "=", "extra_callbacks", "or", "[", "]", "\n", "\n", "# init model", "\n", "odir", "=", "Path", "(", "args", ".", "output_dir", ")", "\n", "if", "args", ".", "do_train", "and", "args", ".", "overwrite_output_dir", "and", "odir", ".", "exists", "(", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "odir", ")", "\n", "", "odir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# add custom checkpoints", "\n", "if", "checkpoint_callback", "is", "None", ":", "\n", "        ", "checkpoint_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "filepath", "=", "args", ".", "output_dir", ",", "prefix", "=", "\"checkpoint\"", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "1", "\n", ")", "\n", "", "if", "logging_callback", "is", "None", ":", "\n", "        ", "logging_callback", "=", "LoggingCallback", "(", ")", "\n", "\n", "", "train_params", "=", "extra_train_kwargs", "or", "{", "}", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "train_params", "[", "\"precision\"", "]", "=", "16", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "weights_summary", "=", "weights_summary", ",", "\n", "callbacks", "=", "[", "logging_callback", "]", "+", "extra_callbacks", ",", "\n", "logger", "=", "logger", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "**", "train_params", ",", "\n", ")", "\n", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ")", "\n", "\n", "", "return", "trainer", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUEBatch.select_subset": [[81, 88], ["isinstance", "getattr"], "methods", ["None"], ["def", "select_subset", "(", "self", ",", "attr", ":", "Union", "[", "str", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ",", "selected_indices", ")", "->", "Optional", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "if", "attr", "is", "not", "None", "and", "isinstance", "(", "attr", ",", "str", ")", ":", "\n", "            ", "val", "=", "getattr", "(", "self", ",", "attr", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "val", "=", "attr", "\n", "\n", "", "return", "val", "[", "selected_indices", "]", "if", "val", "is", "not", "None", "else", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUEBatch.get_minibatches": [[89, 92], ["run_glue.GLUEBatch", "enumerate"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_minibatches", "(", "cls", ",", "batch", ":", "Iterable", "[", "Tuple", "[", "Optional", "[", "torch", ".", "Tensor", "]", ",", "...", "]", "]", ")", "->", "Dict", "[", "int", ",", "\"GLUEBatch\"", "]", ":", "\n", "        ", "return", "{", "i", ":", "GLUEBatch", "(", "*", "minibatch", ")", "for", "i", ",", "minibatch", "in", "enumerate", "(", "batch", ")", "if", "minibatch", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.__init__": [[97, 180], ["lightning_base.BaseTransformer.__init__", "data.load_metric", "run_glue.GLUETransformer._reinitialize", "run_glue.GLUETransformer._is_distillation_on", "run_glue.GLUETransformer._is_minimax_on", "type", "argparse.Namespace", "os.path.exists", "logger.info", "HF_SEQUENCE_CLASSIFICATION[].reinitialize", "run_glue.GLUETransformer._is_teacher_cached", "run_glue.GLUETransformer._is_teacher_cached", "transformers.AutoConfig.from_pretrained", "transformers.AutoConfig.from_pretrained", "run_glue.GLUETransformer.model_type.from_pretrained", "data.cached_model_outputs", "modeling.KDHeadFast", "modeling.KDHead", "modeling.MinimaxKnnHeadFast", "modeling.MinimaxKnnHead", "transformers.AutoConfig.from_pretrained", "bool"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__init__", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.load_metric", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._reinitialize", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_distillation_on", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_minimax_on", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.HFSequenceClassificationMetadata.reinitialize", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_teacher_cached", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_teacher_cached", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached.cached_model_outputs"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "if", "type", "(", "hparams", ")", "==", "dict", ":", "\n", "            ", "hparams", "=", "Namespace", "(", "**", "hparams", ")", "\n", "", "hparams", ".", "glue_output_mode", "=", "glue_output_modes", "[", "hparams", ".", "task", "]", "\n", "num_labels", "=", "glue_tasks_num_labels", "[", "hparams", ".", "task", "]", "\n", "\n", "if", "hparams", ".", "config_name", ":", "\n", "            ", "num_labels_old", "=", "AutoConfig", ".", "from_pretrained", "(", "hparams", ".", "config_name", ")", ".", "num_labels", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "hparams", ".", "model_name_or_path", ")", ":", "\n", "            ", "num_labels_old", "=", "AutoConfig", ".", "from_pretrained", "(", "hparams", ".", "model_name_or_path", ")", ".", "num_labels", "\n", "", "else", ":", "\n", "            ", "num_labels_old", "=", "num_labels", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "num_labels_old", ",", "self", ".", "mode", ",", "return_dict", "=", "True", ")", "\n", "\n", "self", ".", "metric", "=", "load_metric", "(", "self", ".", "hparams", ".", "task", ")", "\n", "\n", "self", ".", "teacher_saved_output", "=", "None", "\n", "self", ".", "teacher", "=", "None", "\n", "if", "self", ".", "hparams", ".", "teacher_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "hparams", ".", "online_teacher", ":", "\n", "                ", "teacher_config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "teacher_name_or_path", ",", "\n", "**", "(", "{", "\"num_labels\"", ":", "num_labels", "}", "if", "num_labels", "is", "not", "None", "else", "{", "}", ")", ",", "\n", "cache_dir", "=", "self", ".", "hparams", ".", "cache_dir", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", "\n", "self", ".", "teacher", "=", "self", ".", "model_type", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "teacher_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "self", ".", "hparams", ".", "teacher_name_or_path", ")", ",", "\n", "config", "=", "teacher_config", ",", "\n", "cache_dir", "=", "self", ".", "hparams", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "teacher_saved_output", "=", "cached_model_outputs", "(", "\n", "self", ".", "hparams", ".", "teacher_name_or_path", ",", "\n", "self", ".", "hparams", ".", "task", ",", "\n", "self", ".", "hparams", ".", "data_dir", ",", "\n", "self", ".", "hparams", ".", "cache_batch_size", "or", "self", ".", "hparams", ".", "train_batch_size", ",", "\n", "self", ".", "hparams", ".", "max_seq_length", ",", "\n", "cache_dir", "=", "self", ".", "hparams", ".", "cache_dir", ",", "\n", "dataset_name", "=", "self", ".", "hparams", ".", "dataset_name", ",", "\n", "max_augment_length", "=", "self", ".", "hparams", ".", "max_aug_length", ",", "\n", "num_workers", "=", "self", ".", "hparams", ".", "num_workers", ",", "\n", ")", "\n", "\n", "", "", "if", "num_labels", "!=", "num_labels_old", ":", "\n", "            ", "self", ".", "config", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "model", ".", "num_labels", "=", "num_labels", "\n", "logger", ".", "info", "(", "\n", "f\"Classifier heads in model are reset because number of labels is different \"", "\n", "f\"in the pre-trained model from the task: {num_labels_old} != {num_labels}\"", "\n", ")", "\n", "HF_SEQUENCE_CLASSIFICATION", "[", "self", ".", "config", ".", "model_type", "]", ".", "reinitialize", "(", "self", ".", "config", ",", "self", ".", "model", ")", "\n", "\n", "", "self", ".", "_reinitialize", "(", ")", "\n", "\n", "if", "self", ".", "_is_distillation_on", "(", ")", ":", "\n", "            ", "if", "self", ".", "_is_teacher_cached", "(", ")", ":", "\n", "                ", "self", ".", "kd_head", "=", "KDHeadFast", "(", "self", ".", "teacher_saved_output", ".", "logits", ",", "self", ".", "hparams", ".", "temperature", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "kd_head", "=", "KDHead", "(", "self", ".", "teacher", ",", "self", ".", "hparams", ".", "temperature", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "kd_head", "=", "None", "\n", "\n", "", "if", "self", ".", "_is_minimax_on", "(", ")", ":", "\n", "            ", "if", "self", ".", "_is_teacher_cached", "(", ")", ":", "\n", "                ", "self", ".", "minimax_head", "=", "MinimaxKnnHeadFast", "(", "\n", "self", ".", "teacher_saved_output", ".", "logits", ",", "\n", "self", ".", "model", ",", "\n", "self", ".", "hparams", ".", "temperature", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "minimax_head", "=", "MinimaxKnnHead", "(", "\n", "self", ".", "teacher", ",", "\n", "self", ".", "model", ",", "\n", "self", ".", "hparams", ".", "temperature", ",", "\n", "self", ".", "hparams", ".", "min_distance", ",", "\n", "self", ".", "hparams", ".", "max_distance", ",", "\n", "self", ".", "hparams", ".", "maxim_func", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "minimax_head", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_teacher_cached": [[181, 183], ["None"], "methods", ["None"], ["", "", "def", "_is_teacher_cached", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "teacher_saved_output", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_distillation_on": [[184, 186], ["None"], "methods", ["None"], ["", "def", "_is_distillation_on", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "teacher", "is", "not", "None", "or", "self", ".", "teacher_saved_output", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_augmentation_on": [[187, 189], ["run_glue.GLUETransformer._is_distillation_on"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_distillation_on"], ["", "def", "_is_augmentation_on", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "_is_distillation_on", "(", ")", "and", "self", ".", "hparams", ".", "num_augments", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_minimax_on": [[190, 192], ["run_glue.GLUETransformer._is_augmentation_on"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_augmentation_on"], ["", "def", "_is_minimax_on", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "_is_augmentation_on", "(", ")", "and", "not", "self", ".", "hparams", ".", "naive_augment", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_naive_augment_on": [[193, 195], ["run_glue.GLUETransformer._is_augmentation_on"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_augmentation_on"], ["", "def", "_is_naive_augment_on", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "_is_augmentation_on", "(", ")", "and", "self", ".", "hparams", ".", "naive_augment", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.forward": [[196, 198], ["run_glue.GLUETransformer.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "**", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "**", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._reinitialize": [[199, 266], ["getattr", "getattr", "getattr.pooler.dense.weight.data.normal_", "getattr.pooler.dense.bias.data.zero_", "getattr.pooler.parameters", "ValueError", "layer.modules", "isinstance", "layer.modules", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "isinstance", "layer.modules", "module.bias.data.zero_", "module.weight.data.fill_", "module.weight.data.normal_", "isinstance", "run_glue.GLUETransformer.model.model._init_weights", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "param.data.normal_"], "methods", ["None"], ["", "def", "_reinitialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Taken from: https://github.com/asappresearch/revisit-bert-finetuning/blob/master/run_glue.py\n        \"\"\"", "\n", "if", "self", ".", "hparams", ".", "reinit_pooler", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_type", "in", "[", "\"bert\"", ",", "\"roberta\"", "]", ":", "\n", "                ", "encoder_temp", "=", "getattr", "(", "self", ".", "model", ",", "self", ".", "config", ".", "model_type", ")", "\n", "if", "encoder_temp", ".", "pooler", "is", "not", "None", ":", "\n", "                    ", "encoder_temp", ".", "pooler", ".", "dense", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "encoder_temp", ".", "config", ".", "initializer_range", ")", "\n", "encoder_temp", ".", "pooler", ".", "dense", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "for", "p", "in", "encoder_temp", ".", "pooler", ".", "parameters", "(", ")", ":", "\n", "                        ", "p", ".", "requires_grad", "=", "True", "\n", "", "", "", "elif", "self", ".", "config", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"bart\"", ",", "\"electra\"", "]", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{self.config.model_type} does not have a pooler at the end\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "if", "self", ".", "hparams", ".", "reinit_layers", ">", "0", ":", "\n", "            ", "if", "self", ".", "config", ".", "model_type", "in", "[", "\"bert\"", ",", "\"roberta\"", ",", "\"electra\"", "]", ":", "\n", "                ", "assert", "self", ".", "hparams", ".", "reinit_pooler", "or", "self", ".", "config", ".", "model_type", "==", "\"electra\"", "\n", "\n", "encoder_temp", "=", "getattr", "(", "self", ".", "model", ",", "self", ".", "config", ".", "model_type", ")", "\n", "for", "layer", "in", "encoder_temp", ".", "encoder", ".", "layer", "[", "-", "self", ".", "hparams", ".", "reinit_layers", ":", "]", ":", "\n", "                    ", "for", "module", "in", "layer", ".", "modules", "(", ")", ":", "\n", "                        ", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "                            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "encoder_temp", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "                            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "", "", "elif", "self", ".", "config", ".", "model_type", "==", "\"xlnet\"", ":", "\n", "                ", "from", "transformers", ".", "modeling_xlnet", "import", "XLNetLayerNorm", ",", "XLNetRelativeAttention", "\n", "\n", "for", "layer", "in", "self", ".", "model", ".", "transformer", ".", "layer", "[", "-", "self", ".", "hparams", ".", "reinit_layers", ":", "]", ":", "\n", "                    ", "for", "module", "in", "layer", ".", "modules", "(", ")", ":", "\n", "                        ", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "                            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "model", ".", "transformer", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetLayerNorm", ")", ":", "\n", "                            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "XLNetRelativeAttention", ")", ":", "\n", "                            ", "for", "param", "in", "[", "\n", "module", ".", "q", ",", "\n", "module", ".", "k", ",", "\n", "module", ".", "v", ",", "\n", "module", ".", "o", ",", "\n", "module", ".", "r", ",", "\n", "module", ".", "r_r_bias", ",", "\n", "module", ".", "r_s_bias", ",", "\n", "module", ".", "r_w_bias", ",", "\n", "module", ".", "seg_embed", ",", "\n", "]", ":", "\n", "                                ", "param", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "model", ".", "transformer", ".", "config", ".", "initializer_range", ")", "\n", "", "", "", "", "", "elif", "self", ".", "config", ".", "model_type", "==", "\"bart\"", ":", "\n", "                ", "for", "layer", "in", "self", ".", "model", ".", "model", ".", "decoder", ".", "layers", "[", "-", "self", ".", "hparams", ".", "reinit_layers", ":", "]", ":", "\n", "                    ", "for", "module", "in", "layer", ".", "modules", "(", ")", ":", "\n", "                        ", "self", ".", "model", ".", "model", ".", "_init_weights", "(", "module", ")", "\n", "\n", "", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_trainable_parameters": [[267, 277], ["super().get_trainable_parameters"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_trainable_parameters"], ["", "", "", "def", "get_trainable_parameters", "(", "self", ")", ":", "\n", "        ", "optimizer_grouped_parameters", "=", "super", "(", ")", ".", "get_trainable_parameters", "(", ")", "\n", "# if self.ref_logits_head is not None:", "\n", "#     optimizer_grouped_parameters.append(", "\n", "#         {", "\n", "#             \"params\": [p for n, p in self.ref_logits_head.named_parameters()],", "\n", "#             \"weight_decay\": self.hparams.weight_decay,", "\n", "#         }", "\n", "#     )", "\n", "return", "optimizer_grouped_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._add_distance_threshold_log": [[278, 297], ["run_glue.GLUETransformer.log", "filtered_ranks.nelement", "filtered_ranks.nelement", "run_glue.GLUETransformer.logger.experiment.add_histogram", "filtered_ranks.nelement"], "methods", ["None"], ["", "def", "_add_distance_threshold_log", "(", "\n", "self", ",", "threshold", ":", "int", ",", "filtered_ranks", ":", "Optional", "[", "torch", ".", "Tensor", "]", ",", "prefix", ":", "str", "\n", ")", "->", "Optional", "[", "int", "]", ":", "\n", "        ", "if", "threshold", ">", "0", "and", "filtered_ranks", "is", "not", "None", ":", "\n", "            ", "if", "filtered_ranks", ".", "nelement", "(", ")", ">", "0", ":", "\n", "                ", "self", ".", "logger", ".", "experiment", ".", "add_histogram", "(", "\n", "f\"minimax/{prefix}_filtered_ranks\"", ",", "\n", "filtered_ranks", ",", "\n", "self", ".", "global_step", ",", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "\n", "f\"minimax/num_{prefix}_filtered_neighbors\"", ",", "\n", "filtered_ranks", ".", "nelement", "(", ")", ",", "\n", "logger", "=", "True", ",", "\n", ")", "\n", "return", "filtered_ranks", ".", "nelement", "(", ")", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.training_step": [[298, 465], ["run_glue.GLUEBatch.get_minibatches", "run_glue.GLUEBatch.get_minibatches", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer.teacher.eval", "hf_utils.get_model_inputs", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer._is_minimax_on", "run_glue.GLUETransformer.", "run_glue.GLUETransformer._is_distillation_on", "hf_utils.get_model_inputs", "run_glue.GLUETransformer._is_teacher_cached", "run_glue.GLUETransformer._add_distance_threshold_log", "run_glue.GLUETransformer._add_distance_threshold_log", "lr_scheduler.get_last_lr", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer._is_teacher_cached", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer._is_minimax_on", "run_glue.GLUETransformer.minimax_head", "dict", "dict.pop", "run_glue.GLUETransformer.minimax_head", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer.", "run_glue.GLUETransformer._is_teacher_cached", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer.kd_head", "dict", "dict.pop", "run_glue.GLUETransformer.kd_head", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "run_glue.GLUETransformer.teacher", "run_glue.GLUETransformer.logger.experiment.add_histogram", "run_glue.GLUETransformer.logger.experiment.add_histogram", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer.kd_head", "run_glue.GLUETransformer.kd_head", "hf_utils.get_last_layer_hidden_states", "batch.augmented_ranks.nelement", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "minibatch.select_subset", "minibatch.select_subset", "minibatch.select_subset", "hf_utils.get_model_inputs.get"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUEBatch.get_minibatches", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUEBatch.get_minibatches", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_model_inputs", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_minimax_on", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_distillation_on", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_model_inputs", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_teacher_cached", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._add_distance_threshold_log", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._add_distance_threshold_log", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_teacher_cached", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_minimax_on", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_teacher_cached", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_last_layer_hidden_states", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUEBatch.select_subset", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUEBatch.select_subset", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUEBatch.select_subset"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "minibatches", "=", "GLUEBatch", ".", "get_minibatches", "(", "batch", ")", "\n", "\n", "# skip a batch", "\n", "if", "0", "not", "in", "minibatches", "and", "(", "self", ".", "_is_minimax_on", "(", ")", "and", "self", ".", "current_epoch", "<", "self", ".", "hparams", ".", "augment_start_epoch", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "teacher", "is", "not", "None", ":", "\n", "            ", "self", ".", "teacher", ".", "eval", "(", ")", "\n", "\n", "", "loss", "=", "0.0", "\n", "for", "aug_rank", ",", "minibatch", "in", "minibatches", ".", "items", "(", ")", ":", "\n", "            ", "inputs", "=", "hf_get_model_inputs", "(", "\n", "self", ".", "config", ".", "model_type", ",", "\n", "minibatch", ".", "input_ids", ",", "\n", "minibatch", ".", "token_type_ids", ",", "\n", "minibatch", ".", "attention_mask", ",", "\n", "minibatch", ".", "labels", ",", "\n", ")", "\n", "\n", "if", "aug_rank", "==", "0", ":", "\n", "                ", "output", "=", "self", "(", "**", "inputs", ")", "\n", "cls_loss", "=", "output", ".", "loss", "\n", "\n", "# for auxiliary samples that do not have labels", "\n", "if", "cls_loss", "is", "None", ":", "\n", "                    ", "cls_loss", "=", "0.0", "\n", "", "else", ":", "\n", "                    ", "self", ".", "log", "(", "\"train/cls_loss\"", ",", "cls_loss", ",", "logger", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "_is_distillation_on", "(", ")", ":", "\n", "                    ", "if", "self", ".", "_is_teacher_cached", "(", ")", ":", "\n", "                        ", "kd_loss", "=", "self", ".", "kd_head", "(", "\n", "output", ".", "logits", ",", "\n", "example_indices", "=", "minibatch", ".", "example_indices", ",", "\n", "augmented_indices", "=", "minibatch", ".", "augmented_indices", ",", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "teacher_inputs", "=", "dict", "(", "inputs", ")", "\n", "teacher_inputs", ".", "pop", "(", "\"labels\"", ",", "None", ")", "\n", "if", "\"token_type_ids\"", "not", "in", "inputs", ":", "\n", "                            ", "teacher_inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "None", "if", "self", ".", "teacher", ".", "config", ".", "model_type", "==", "\"xlm\"", "else", "minibatch", ".", "token_type_ids", "\n", ")", "\n", "\n", "", "kd_loss", ",", "_", "=", "self", ".", "kd_head", "(", "\n", "output", ".", "logits", ",", "\n", "**", "teacher_inputs", ",", "\n", ")", "\n", "", "self", ".", "log", "(", "\"train/kd_loss\"", ",", "kd_loss", ",", "logger", "=", "True", ")", "\n", "\n", "loss", "+=", "self", ".", "hparams", ".", "alpha_ce", "*", "kd_loss", "+", "self", ".", "hparams", ".", "alpha_true", "*", "cls_loss", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "cls_loss", "\n", "break", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "current_epoch", "<", "self", ".", "hparams", ".", "augment_start_epoch", ":", "\n", "                    ", "continue", "\n", "\n", "", "assert", "self", ".", "_is_minimax_on", "(", ")", "and", "minibatch", ".", "augmented_input_ids", "is", "not", "None", "\n", "\n", "augmented_inputs", "=", "hf_get_model_inputs", "(", "\n", "self", ".", "config", ".", "model_type", ",", "\n", "minibatch", ".", "augmented_input_ids", ",", "\n", "minibatch", ".", "augmented_token_types", ",", "\n", "minibatch", ".", "augmented_attention_mask", ",", "\n", ")", "\n", "\n", "if", "self", ".", "_is_teacher_cached", "(", ")", ":", "\n", "                    ", "minimax_output", "=", "self", ".", "minimax_head", "(", "\n", "aug_rank", ",", "\n", "minibatch", ".", "augmented_mask", ",", "\n", "minibatch", ".", "example_indices", ",", "\n", "nn_ranks", "=", "minibatch", ".", "augmented_ranks", ",", "\n", "augmented_indices", "=", "minibatch", ".", "augmented_indices", ",", "\n", "**", "augmented_inputs", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "teacher_inputs", "=", "dict", "(", "inputs", ")", "\n", "teacher_inputs", ".", "pop", "(", "\"labels\"", ",", "None", ")", "\n", "if", "\"token_type_ids\"", "not", "in", "inputs", ":", "\n", "                        ", "teacher_inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "None", "if", "self", ".", "teacher", ".", "config", ".", "model_type", "==", "\"xlm\"", "else", "minibatch", ".", "token_type_ids", "\n", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "teacher_output", "=", "self", ".", "teacher", "(", "\n", "**", "teacher_inputs", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", ")", "\n", "\n", "", "minimax_output", "=", "self", ".", "minimax_head", "(", "\n", "aug_rank", ",", "\n", "nn_mask", "=", "minibatch", ".", "augmented_mask", ",", "\n", "tea_orig_hidden_states", "=", "get_last_layer_hidden_states", "(", "self", ".", "teacher", ".", "config", ",", "teacher_output", ")", ",", "\n", "nn_ranks", "=", "minibatch", ".", "augmented_ranks", ",", "\n", "**", "augmented_inputs", ",", "\n", ")", "\n", "\n", "", "max_filtered_ranks", "=", "self", ".", "_add_distance_threshold_log", "(", "\n", "self", ".", "hparams", ".", "max_distance", ",", "minimax_output", ".", "max_filtered_ranks", ",", "\"max\"", "\n", ")", "\n", "min_filtered_ranks", "=", "self", ".", "_add_distance_threshold_log", "(", "\n", "self", ".", "hparams", ".", "min_distance", ",", "minimax_output", ".", "min_filtered_ranks", ",", "\"min\"", "\n", ")", "\n", "\n", "if", "max_filtered_ranks", "is", "not", "None", "or", "min_filtered_ranks", "is", "not", "None", ":", "\n", "                    ", "num_filtered_ranks", "=", "(", "max_filtered_ranks", "or", "0", ")", "+", "(", "min_filtered_ranks", "or", "0", ")", "\n", "self", ".", "log", "(", "\n", "\"minimax/num_filtered_neighbors\"", ",", "\n", "num_filtered_ranks", ",", "\n", "logger", "=", "True", ",", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"minimax/filtered_neighbors_percent\"", ",", "\n", "100.0", "*", "num_filtered_ranks", "/", "batch", ".", "augmented_ranks", ".", "nelement", "(", ")", ",", "\n", "logger", "=", "True", ",", "\n", ")", "\n", "\n", "", "if", "not", "minimax_output", ".", "is_empty", ":", "\n", "                    ", "if", "minimax_output", ".", "has_selected_ranks", ":", "\n", "                        ", "self", ".", "logger", ".", "experiment", ".", "add_histogram", "(", "\n", "\"minimax/selected_ranks\"", ",", "\n", "minimax_output", ".", "selected_ranks", ",", "\n", "self", ".", "global_step", ",", "\n", ")", "\n", "\n", "", "if", "minimax_output", ".", "has_selected_distances", ":", "\n", "                        ", "self", ".", "logger", ".", "experiment", ".", "add_histogram", "(", "\n", "\"minimax/selected_distances\"", ",", "\n", "minimax_output", ".", "selected_distances", ",", "\n", "self", ".", "global_step", ",", "\n", ")", "\n", "\n", "self", ".", "log", "(", "\n", "\"minimax/avg_selected_distances\"", ",", "\n", "torch", ".", "mean", "(", "minimax_output", ".", "selected_distances", ")", ",", "\n", "logger", "=", "True", ",", "\n", ")", "\n", "\n", "", "aug_output", "=", "self", "(", "\n", "input_ids", "=", "minibatch", ".", "select_subset", "(", "\"augmented_input_ids\"", ",", "minimax_output", ".", "selected_neighbors", ")", ",", "\n", "attention_mask", "=", "minibatch", ".", "select_subset", "(", "\n", "\"augmented_attention_mask\"", ",", "\n", "minimax_output", ".", "selected_neighbors", ",", "\n", ")", ",", "\n", "token_type_ids", "=", "minibatch", ".", "select_subset", "(", "\n", "augmented_inputs", ".", "get", "(", "\"token_type_ids\"", ",", "None", ")", ",", "\n", "minimax_output", ".", "selected_neighbors", ",", "\n", ")", ",", "\n", "labels", "=", "None", ",", "\n", ")", "\n", "\n", "if", "self", ".", "_is_teacher_cached", "(", ")", ":", "\n", "                        ", "loss_aug", "=", "self", ".", "kd_head", "(", "aug_output", ".", "logits", ",", "minimax_output", ".", "teacher_logits", ")", "\n", "", "else", ":", "\n", "                        ", "loss_aug", ",", "_", "=", "self", ".", "kd_head", "(", "aug_output", ".", "logits", ",", "minimax_output", ".", "teacher_logits", ")", "\n", "", "self", ".", "log", "(", "\"train/aug_loss\"", ",", "loss_aug", ",", "logger", "=", "True", ")", "\n", "loss", "+=", "self", ".", "hparams", ".", "alpha_aug", "*", "loss_aug", "\n", "\n", "", "", "", "if", "loss", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "\"train/loss\"", ",", "loss", ",", "prog_bar", "=", "False", ",", "logger", "=", "True", ")", "\n", "\n", "", "lr_scheduler", "=", "self", ".", "trainer", ".", "lr_schedulers", "[", "0", "]", "[", "\"scheduler\"", "]", "\n", "self", ".", "log", "(", "\"train/lr\"", ",", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "-", "1", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.total_steps": [[476, 487], ["run_glue.GLUETransformer._is_augmentation_on", "max", "super().total_steps", "run_glue.GLUETransformer.get_number_of_gpus", "len", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_augmentation_on", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.total_steps", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.BaseTransformer.get_number_of_gpus"], ["", "def", "total_steps", "(", "self", ")", "->", "int", ":", "\n", "        ", "if", "self", ".", "_is_augmentation_on", "(", ")", ":", "\n", "            ", "num_devices", "=", "max", "(", "1", ",", "self", ".", "get_number_of_gpus", "(", ")", ")", "\n", "effective_batch_size", "=", "self", ".", "hparams", ".", "train_batch_size", "*", "self", ".", "hparams", ".", "accumulate_grad_batches", "*", "num_devices", "\n", "effective_dataset_size", "=", "len", "(", "self", ".", "train_loader", ".", "dataset", ")", "/", "effective_batch_size", "\n", "effective_augmented_dataset_size", "=", "len", "(", "self", ".", "augmented_train_loader", ".", "dataset", ")", "/", "effective_batch_size", "\n", "return", "effective_dataset_size", "*", "self", ".", "hparams", ".", "augment_start_epoch", "+", "effective_augmented_dataset_size", "*", "(", "\n", "self", ".", "hparams", ".", "max_epochs", "-", "self", ".", "hparams", ".", "augment_start_epoch", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "total_steps", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.setup": [[488, 497], ["super().setup", "run_glue.GLUETransformer._is_augmentation_on", "data.GLUEv2Processor", "run_glue.GLUETransformer._filter_augments", "run_glue.GLUETransformer.get_dataloader", "data.GLUEv2Processor.get_train_examples"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.setup", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_augmentation_on", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._filter_augments", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_dataloader", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_train_examples"], ["", "", "def", "setup", "(", "self", ",", "mode", ")", ":", "\n", "        ", "super", "(", ")", ".", "setup", "(", "mode", ")", "\n", "if", "mode", "==", "\"fit\"", "and", "self", ".", "_is_augmentation_on", "(", ")", ":", "\n", "            ", "args", "=", "self", ".", "hparams", "\n", "\n", "processor", "=", "GLUEv2Processor", "(", "args", ".", "task", ",", "num_augments", "=", "-", "1", ")", "\n", "\n", "self", ".", "_filter_augments", "(", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", ")", "\n", "self", ".", "augmented_train_loader", "=", "self", ".", "get_dataloader", "(", "\"augmented_train\"", ",", "args", ".", "train_batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.train_dataloader": [[498, 503], ["super().train_dataloader", "run_glue.GLUETransformer._is_augmentation_on"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.train_dataloader", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_augmentation_on"], ["", "", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_is_augmentation_on", "(", ")", "and", "self", ".", "current_epoch", ">=", "self", ".", "hparams", ".", "augment_start_epoch", ":", "\n", "            ", "return", "self", ".", "augmented_train_loader", "\n", "\n", "", "return", "super", "(", ")", ".", "train_dataloader", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_dataloader": [[504, 562], ["data.GLUEv2Processor", "data.GLUEv2Processor.get_labels", "data.GLUEv2Dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "mode.endswith", "data.GLUEv2Processor.get_dev_examples", "data.GLUEv2Processor.get_test_examples", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "data.FeaturesCollatorWithPadding", "data.GLUEv2Processor.get_labelled_test_examples", "data.GLUEv2Processor.get_train_examples", "run_glue.GLUETransformer._is_teacher_cached", "run_glue.GLUETransformer._get_cached_allowed_indices_file", "run_glue.GLUETransformer._is_naive_augment_on", "run_glue.GLUETransformer._is_minimax_on"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labels", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_dev_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_test_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labelled_test_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_train_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_teacher_cached", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._get_cached_allowed_indices_file", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_naive_augment_on", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_minimax_on"], ["", "def", "get_dataloader", "(", "self", ",", "mode", ":", "str", ",", "batch_size", ":", "int", ",", "shuffle", ":", "bool", "=", "False", ")", "->", "DataLoader", ":", "\n", "        ", "\"Load datasets. Called after prepare data.\"", "\n", "\n", "# We test on dev set to compare to benchmarks without having to submit to GLUE server", "\n", "mode", "=", "\"dev\"", "if", "mode", "==", "\"test\"", "else", "mode", "\n", "if", "not", "mode", ".", "endswith", "(", "\"train\"", ")", ":", "\n", "            ", "self", ".", "hparams", ".", "test_mode", "=", "mode", "\n", "\n", "", "args", "=", "self", ".", "hparams", "\n", "\n", "processor", "=", "GLUEv2Processor", "(", "\n", "args", ".", "task", ",", "\n", "num_augments", "=", "-", "1", ",", "\n", ")", "\n", "self", ".", "labels", "=", "processor", ".", "get_labels", "(", ")", "\n", "\n", "if", "mode", "==", "\"dev\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"infer\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "mode", "==", "\"test2\"", ":", "\n", "            ", "examples", "=", "processor", ".", "get_labelled_test_examples", "(", "args", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "", "dataset", "=", "GLUEv2Dataset", "(", "\n", "examples", ",", "\n", "self", ".", "labels", ",", "\n", "args", ".", "glue_output_mode", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "self", ".", "tokenizer", ",", "\n", "args", ".", "max_aug_length", ",", "\n", "args", ".", "num_augments", "if", "mode", "==", "\"augmented_train\"", "else", "0", ",", "\n", "torch", ".", "load", "(", "self", ".", "_get_cached_allowed_indices_file", "(", ")", ")", "\n", "if", "mode", "==", "\"augmented_train\"", "and", "self", ".", "_is_teacher_cached", "(", ")", "\n", "else", "None", ",", "\n", "naive_augment", "=", "mode", "==", "\"augmented_train\"", "and", "self", ".", "_is_naive_augment_on", "(", ")", ",", "\n", "padding", "=", "self", ".", "hparams", ".", "padding", ",", "\n", ")", "\n", "\n", "dl_kwargs", "=", "{", "}", "\n", "# if is_ddp_enabled(self.hparams.distributed_backend, self.hparams.gpus):", "\n", "# dl_kwargs[\"sampler\"] = DistributedSampler(dataset, shuffle=shuffle, drop_last=mode != \"train\")", "\n", "# dl_kwargs[\"drop_last\"] = mode != \"train\"", "\n", "\n", "return", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collate_fn", "=", "FeaturesCollatorWithPadding", "(", "\n", "self", ".", "tokenizer", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "hparams", ".", "pad_to_multiple_of", ",", "\n", "group_features", "=", "mode", "==", "\"augmented_train\"", "and", "self", ".", "_is_minimax_on", "(", ")", ",", "\n", "num_augment_ranks", "=", "(", "self", ".", "hparams", ".", "num_augments", "+", "1", ")", "if", "mode", "==", "\"augmented_train\"", "else", "0", ",", "\n", ")", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "**", "dl_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.validation_step": [[564, 583], ["hf_utils.get_model_inputs", "run_glue.GLUETransformer.", "run_glue.GLUEBatch.get_minibatches", "hf_utils.get_model_inputs.get", "inputs[].detach().cpu().numpy", "tmp_eval_loss.detach().cpu", "inputs[].detach().cpu", "tmp_eval_loss.detach", "inputs[].detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_model_inputs", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUEBatch.get_minibatches"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "batch", "=", "GLUEBatch", ".", "get_minibatches", "(", "batch", ")", "[", "0", "]", "\n", "inputs", "=", "hf_get_model_inputs", "(", "\n", "self", ".", "config", ".", "model_type", ",", "batch", ".", "input_ids", ",", "batch", ".", "token_type_ids", ",", "batch", ".", "attention_mask", ",", "batch", ".", "labels", "\n", ")", "\n", "outputs", "=", "self", "(", "**", "inputs", ")", "\n", "\n", "preds", "=", "outputs", ".", "logits", "# .detach().cpu().numpy()", "\n", "\n", "if", "inputs", ".", "get", "(", "\"labels\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tmp_eval_loss", "=", "outputs", ".", "loss", "\n", "return", "{", "\n", "\"val_loss\"", ":", "tmp_eval_loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "\"pred\"", ":", "preds", ",", "\n", "\"target\"", ":", "out_label_ids", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "\"pred\"", ":", "preds", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._eval_end": [[584, 603], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all", "all", "torch.stack().mean().detach().cpu().item", "torch.stack().mean().detach().cpu().item", "torch.stack().mean().detach().cpu().item", "torch.stack().mean().detach().cpu().item", "torch.stack().mean().detach().cpu().item", "torch.stack().mean().detach().cpu().item", "torch.stack().mean().detach().cpu().item", "torch.stack().mean().detach().cpu().item", "torch.stack().mean().detach().cpu().item", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "numpy.concatenate", "run_glue.GLUETransformer.metric.compute", "preds.squeeze.squeeze.squeeze", "torch.stack().mean().detach().cpu", "torch.stack().mean().detach().cpu", "torch.stack().mean().detach().cpu", "torch.stack().mean().detach().cpu", "torch.stack().mean().detach().cpu", "torch.stack().mean().detach().cpu", "torch.stack().mean().detach().cpu", "torch.stack().mean().detach().cpu", "torch.stack().mean().detach().cpu", "preds.squeeze.squeeze.detach().cpu().numpy", "torch.stack().mean().detach", "torch.stack().mean().detach", "torch.stack().mean().detach", "torch.stack().mean().detach", "torch.stack().mean().detach", "torch.stack().mean().detach", "torch.stack().mean().detach", "torch.stack().mean().detach", "torch.stack().mean().detach", "preds.squeeze.squeeze.detach().cpu", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "preds.squeeze.squeeze.detach", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "", "def", "_eval_end", "(", "self", ",", "outputs", ")", "->", "tuple", ":", "\n", "        ", "preds", "=", "torch", ".", "cat", "(", "[", "x", "[", "\"pred\"", "]", "for", "x", "in", "outputs", "]", ",", "dim", "=", "0", ")", "\n", "\n", "val_loss_mean", "=", "None", "\n", "metrics", "=", "{", "}", "\n", "out_label_ids", "=", "None", "\n", "if", "all", "(", "\"val_loss\"", "in", "x", "for", "x", "in", "outputs", ")", ":", "\n", "            ", "val_loss_mean", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"val_loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "glue_output_mode", "==", "\"classification\"", ":", "\n", "            ", "preds", "=", "torch", ".", "argmax", "(", "preds", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "hparams", ".", "glue_output_mode", "==", "\"regression\"", ":", "\n", "            ", "preds", "=", "preds", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "all", "(", "\"target\"", "in", "x", "for", "x", "in", "outputs", ")", ":", "\n", "            ", "out_label_ids", "=", "np", ".", "concatenate", "(", "[", "x", "[", "\"target\"", "]", "for", "x", "in", "outputs", "]", ",", "axis", "=", "0", ")", "\n", "metrics", "=", "self", ".", "metric", ".", "compute", "(", "predictions", "=", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "references", "=", "out_label_ids", ")", "\n", "\n", "", "return", "val_loss_mean", ",", "metrics", ",", "preds", ",", "out_label_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.validation_epoch_end": [[604, 614], ["run_glue.GLUETransformer._eval_end", "run_glue.GLUETransformer.log", "next", "run_glue.GLUETransformer.log", "metrics.items", "iter", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer.log", "metrics.values"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._eval_end"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "val_loss", ",", "metrics", ",", "*", "_", "=", "self", ".", "_eval_end", "(", "outputs", ")", "\n", "self", ".", "log", "(", "\"valid/loss\"", ",", "val_loss", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ")", "\n", "\n", "val_metric", "=", "next", "(", "iter", "(", "metrics", ".", "values", "(", ")", ")", ")", "\n", "self", ".", "log", "(", "\"val_metric\"", ",", "val_metric", ",", "logger", "=", "True", ")", "\n", "\n", "for", "met_name", ",", "met_val", "in", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "log", "(", "f\"valid/{met_name}\"", ",", "met_val", ",", "prog_bar", "=", "False", ",", "logger", "=", "True", ")", "\n", "self", ".", "log", "(", "met_name", ",", "met_val", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.test_epoch_end": [[615, 643], ["run_glue.GLUETransformer._eval_end", "test_metrics.items", "run_glue.GLUETransformer._save_predictions", "next", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer.log", "run_glue.GLUETransformer.log", "torch.barrier", "torch.barrier", "torch.barrier", "torch.all_gather", "torch.all_gather", "torch.all_gather", "preds.detach().cpu().numpy", "iter", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.get_rank", "torch.get_rank", "torch.get_rank", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "range", "test_metrics.values", "range", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "preds.detach().cpu", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "preds.detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._eval_end", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._save_predictions"], ["", "", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "test_loss", ",", "test_metrics", ",", "preds", ",", "out_labels", "=", "self", ".", "_eval_end", "(", "outputs", ")", "\n", "\n", "if", "test_metrics", ":", "\n", "            ", "val_metric", "=", "next", "(", "iter", "(", "test_metrics", ".", "values", "(", ")", ")", ")", "\n", "self", ".", "log", "(", "\"test/metric\"", ",", "val_metric", ",", "logger", "=", "True", ")", "\n", "\n", "", "for", "met_name", ",", "met_val", "in", "test_metrics", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "log", "(", "f\"test/{met_name}\"", ",", "met_val", ",", "logger", "=", "True", ")", "\n", "\n", "", "if", "test_loss", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "\"test/loss\"", ",", "test_loss", ")", "\n", "\n", "", "if", "self", ".", "use_ddp", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "out_preds", "=", "[", "torch", ".", "zeros_like", "(", "preds", ")", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "dist", ".", "barrier", "(", ")", "\n", "dist", ".", "all_gather", "(", "out_preds", ",", "preds", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "all_preds", "=", "torch", ".", "empty", "(", "\n", "preds", ".", "shape", "[", "0", "]", "*", "dist", ".", "get_world_size", "(", ")", ",", "\n", "device", "=", "preds", ".", "device", ",", "\n", "dtype", "=", "preds", ".", "dtype", ",", "\n", ")", "\n", "for", "current_rank", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", ":", "\n", "                    ", "all_preds", "[", "current_rank", ":", ":", "dist", ".", "get_world_size", "(", ")", "]", "=", "out_preds", "[", "current_rank", "]", "\n", "", "preds", "=", "all_preds", "\n", "\n", "", "", "self", ".", "_save_predictions", "(", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# `val_loss` is the key returned by `self._eval_end()` but actually refers to `test_loss`", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._save_predictions": [[646, 670], ["os.path.join", "open", "writer.write", "enumerate", "getattr", "getattr", "writer.write", "writer.write", "writer.write", "float"], "methods", ["None"], ["", "def", "_save_predictions", "(", "self", ",", "preds", ")", ":", "\n", "        ", "task_name", "=", "self", ".", "hparams", ".", "task", "\n", "label_type", "=", "glue_submission_labels", "[", "task_name", "]", "\n", "\n", "output_suffix", "=", "\"\"", "\n", "if", "self", ".", "hparams", ".", "do_test", "and", "getattr", "(", "self", ".", "hparams", ",", "\"test_mode\"", ",", "\"\"", ")", "==", "\"test2\"", ":", "\n", "            ", "output_suffix", "=", "\"-test\"", "\n", "", "elif", "self", ".", "hparams", ".", "do_eval", "and", "getattr", "(", "self", ".", "hparams", ",", "\"test_mode\"", ",", "\"\"", ")", "==", "\"test\"", ":", "\n", "            ", "output_suffix", "=", "\"-dev\"", "\n", "\n", "", "output_test_results_file", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "hparams", ".", "output_dir", ",", "\n", "f\"{glue_submission_names[task_name]}{output_suffix}.tsv\"", ",", "\n", ")", "\n", "\n", "with", "open", "(", "output_test_results_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "\"index\\tprediction\\n\"", ")", "\n", "for", "i", ",", "pred", "in", "enumerate", "(", "preds", ")", ":", "\n", "                ", "if", "label_type", "==", "\"string\"", ":", "\n", "                    ", "writer", ".", "write", "(", "\"{}\\t{}\\n\"", ".", "format", "(", "i", ",", "self", ".", "labels", "[", "pred", "]", ")", ")", "\n", "", "elif", "label_type", "==", "\"float\"", ":", "\n", "                    ", "writer", ".", "write", "(", "\"{}\\t{.3f}\\n\"", ".", "format", "(", "i", ",", "float", "(", "pred", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "writer", ".", "write", "(", "\"{}\\t{}\\n\"", ".", "format", "(", "i", ",", "pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_progress_bar_dict": [[671, 675], ["super().get_progress_bar_dict", "super().get_progress_bar_dict.pop"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_progress_bar_dict"], ["", "", "", "", "def", "get_progress_bar_dict", "(", "self", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "str", "]", "]", ":", "\n", "        ", "items", "=", "super", "(", ")", ".", "get_progress_bar_dict", "(", ")", "\n", "items", ".", "pop", "(", "\"v_num\"", ",", "None", ")", "\n", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._get_cached_allowed_indices_file": [[676, 678], ["os.path.join"], "methods", ["None"], ["", "def", "_get_cached_allowed_indices_file", "(", "self", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "hparams", ".", "output_dir", ",", "f\".allowed_indices.bin\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._filter_augments": [[679, 756], ["run_glue.GLUETransformer._get_cached_allowed_indices_file", "os.path.exists", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.CosineSimilarity", "pytorch_lightning.utilities.rank_zero_info", "enumerate", "pytorch_lightning.utilities.rank_zero_info", "pytorch_lightning.utilities.rank_zero_info", "pytorch_lightning.utilities.rank_zero_info", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "run_glue.GLUETransformer._is_teacher_cached", "len", "len", "allowed_indices.append", "run_glue.GLUETransformer._is_minimax_on", "numpy.arange", "numpy.arange.tolist", "min", "torch.acos", "torch.acos", "torch.acos", "torch.acos", "torch.acos", "torch.acos", "torch.acos", "torch.acos", "torch.acos", "len", "len", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "len", "len", "torch.CosineSimilarity.", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "run_glue.GLUETransformer.teacher_saved_output.hidden_states[].reshape", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._get_cached_allowed_indices_file", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_teacher_cached", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer._is_minimax_on"], ["", "def", "_filter_augments", "(", "\n", "self", ",", "\n", "examples", ":", "List", "[", "AugmentedInputExample", "]", ",", "\n", ")", ":", "\n", "        ", "if", "not", "self", ".", "_is_teacher_cached", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "", "cache_file", "=", "self", ".", "_get_cached_allowed_indices_file", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_file", ")", ":", "\n", "            ", "return", "\n", "\n", "", "min_distance", "=", "self", ".", "hparams", ".", "min_distance", "\n", "max_distance", "=", "self", ".", "hparams", ".", "max_distance", "\n", "\n", "hidden_states", "=", "self", ".", "teacher_saved_output", ".", "hidden_states", "\n", "num_augmented_examples", "=", "0", "\n", "num_retained_augmented_examples", "=", "0", "\n", "allowed_indices", "=", "[", "]", "\n", "\n", "cos", "=", "nn", ".", "CosineSimilarity", "(", ")", "\n", "\n", "rank_zero_info", "(", "\"*** Filtering based on distance constraints\"", ")", "\n", "\n", "for", "i", ",", "ex", "in", "enumerate", "(", "examples", ")", ":", "\n", "            ", "num_augmented_examples", "+=", "len", "(", "ex", ".", "augmented_examples", ")", "\n", "n_augs", "=", "self", ".", "hparams", ".", "num_aug_candidates", "if", "self", ".", "_is_minimax_on", "(", ")", "else", "self", ".", "hparams", ".", "num_augments", "\n", "\n", "if", "self", ".", "hparams", ".", "preserve_order", ":", "\n", "# if self.hparams.start_rank < len(ex.augmented_examples):", "\n", "                ", "retained_indices", "=", "np", ".", "arange", "(", "\n", "min", "(", "n_augs", ",", "len", "(", "ex", ".", "augmented_examples", ")", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "distances", "=", "(", "\n", "torch", ".", "acos", "(", "\n", "torch", ".", "clamp", "(", "\n", "cos", "(", "\n", "self", ".", "teacher_saved_output", ".", "hidden_states", "[", "i", ",", "0", "]", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "\n", "hidden_states", "[", "i", ",", "1", ":", "len", "(", "ex", ".", "augmented_examples", ")", "+", "1", "]", ",", "\n", ")", ",", "\n", "-", "1.0", ",", "\n", "1.0", ",", "\n", ")", "\n", ")", "\n", "/", "np", ".", "pi", "\n", ")", "\n", "\n", "if", "min_distance", ">", "0", "and", "max_distance", ">", "0", ":", "\n", "                    ", "retained_indices", "=", "torch", ".", "nonzero", "(", "\n", "(", "distances", ">=", "min_distance", ")", "&", "(", "distances", "<=", "max_distance", ")", ",", "as_tuple", "=", "True", "\n", ")", "[", "0", "]", "\n", "", "elif", "min_distance", ">", "0", ":", "\n", "                    ", "retained_indices", "=", "torch", ".", "nonzero", "(", "distances", ">=", "min_distance", ",", "as_tuple", "=", "True", ")", "[", "0", "]", "\n", "", "elif", "max_distance", ">", "0", ":", "\n", "                    ", "retained_indices", "=", "torch", ".", "nonzero", "(", "(", "distances", "<=", "max_distance", ")", "&", "(", "distances", ">", "0", ")", ",", "as_tuple", "=", "True", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                    ", "retained_indices", "=", "torch", ".", "nonzero", "(", "distances", ">", "0", ",", "as_tuple", "=", "True", ")", "[", "0", "]", "\n", "\n", "", "if", "n_augs", "<", "retained_indices", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "retained_distances", "=", "distances", "[", "retained_indices", "]", "\n", "retained_indices", "=", "retained_indices", "[", "torch", ".", "topk", "(", "retained_distances", ",", "n_augs", ",", "largest", "=", "False", ")", "[", "1", "]", "]", "\n", "\n", "", "", "num_retained_augmented_examples", "+=", "len", "(", "retained_indices", ")", "\n", "allowed_indices", ".", "append", "(", "retained_indices", ".", "tolist", "(", ")", ")", "\n", "\n", "", "rank_zero_info", "(", "f\">>> original examples: {len(examples)}\"", ")", "\n", "rank_zero_info", "(", "\n", "f\">>> after augmentation: {num_augmented_examples} ({num_augmented_examples / len(examples):.2f})\"", "\n", ")", "\n", "rank_zero_info", "(", "\n", "f\">>> after distance constraints: {num_retained_augmented_examples} \"", "\n", "f\"(w.r.t. aug {num_retained_augmented_examples / num_augmented_examples:.2f} - \"", "\n", "f\"w.r.t. orig {num_retained_augmented_examples / len(examples):.2f})\"", "\n", ")", "\n", "\n", "torch", ".", "save", "(", "allowed_indices", ",", "cache_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.add_model_specific_args": [[757, 920], ["lightning_base.BaseTransformer.add_model_specific_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "        ", "BaseTransformer", ".", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Dataset name to be used in the name of the output directory.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The GLUE task to run\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--reinit_layers\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "\"re-initialize the last N Transformer blocks. reinit_pooler must be turned on.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--reinit_pooler\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"reinitialize the pooler\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_augments\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Number of augmentations per train samples used during training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_aug_candidates\"", ",", "\n", "default", "=", "4", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Number of candidates per train samples to select augmentation samples from\"", ",", "\n", ")", "\n", "# parser.add_argument(", "\n", "#     \"--start_rank\",", "\n", "#     default=0,", "\n", "#     type=int,", "\n", "#     help=\"Starting rank (from zero) for nearest neighbors \"", "\n", "#     \"(e.g., for second nearest neighbor, `start_rank` and `num_augments` should be set to 1)\",", "\n", "# )", "\n", "parser", ".", "add_argument", "(", "\n", "\"--augment_start_epoch\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"First epoch (starting from zero) in which augmented data incorporated into training. \"", "\n", "\"Earlier epochs are warm-up and run standard KD.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--minimax_update_interval\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Number of epochs that minimax ranking is frozen and gets updated after. 0=never updates\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_distance\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Maximum distance threshold to skip augmentation for too distant neighbors. \"", "\n", "\"The threshold's order of magnitude depends on the distance function.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--min_distance\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Minimum distance threshold to skip augmentation for too close neighbors. \"", "\n", "\"The threshold's order of magnitude depends on the distance function.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_aug_length\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Maximum length of augmented text sequence after tokenization. \"", "\n", "\"(0 = means follow `--max_seq_length`). Only when `num_augments` > 0\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--naive_augment\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Ignore minimax and naively include the whole augmented data in training. Only when `num_augments` > 0\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--preserve_order\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Preserves the order of augmented examples by skipping computing the distance in the teacher's space\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--maxim_func\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "(", "\"ce\"", ",", "\"l2\"", ")", ",", "\n", "default", "=", "\"ce\"", ",", "\n", "help", "=", "\"Maximization function for ranking augmented examples w.r.t. teacher output and student output\"", ",", "\n", ")", "\n", "\n", "# Distillation parameters (optional)", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the already fine-tuned teacher model. Only for distillation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--alpha_ce\"", ",", "\n", "default", "=", "0.5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Distillation loss linear weight. Only for distillation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--alpha_true\"", ",", "\n", "default", "=", "0.5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Classification loss linear weight. Only for distillation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--temperature\"", ",", "\n", "default", "=", "2.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Distillation temperature. Only for distillation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--alpha_aug\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Linear weight corresponding to cross-entropy loss of augmented samples between teacher and student. \"", "\n", "\"Only for distillation when `num_augments` > 0\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_batch_size\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for caching teacher output (default: `--train_batch_size`)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--online_teacher\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Whether to bypass offline caching of teacher output and acquire teacher outputs during training\"", ",", "\n", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue._get_default_output_dir": [[922, 1002], ["torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "pathlib.Path"], "function", ["None"], ["", "", "def", "_get_default_output_dir", "(", "args", ":", "Namespace", ")", "->", "str", ":", "\n", "    ", "arg_summary", "=", "f\"{args.task}_{Path(args.model_name_or_path).name}\"", "\n", "\n", "if", "args", ".", "dataset_name", ":", "\n", "        ", "arg_summary", "+=", "f\"_{args.dataset_name}\"", "\n", "\n", "", "if", "args", ".", "gpus", "<", "0", ":", "\n", "        ", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "        ", "n_gpus", "=", "args", ".", "gpus", "\n", "\n", "", "arg_summary", "+=", "f\"_ep{args.max_epochs}\"", "f\"_bsz{args.train_batch_size}x{n_gpus}\"", "\n", "\n", "if", "args", ".", "warmup_ratio", ">", "0", ":", "\n", "        ", "arg_summary", "+=", "f\"_wmr{args.warmup_ratio}\"", "\n", "", "else", ":", "\n", "        ", "arg_summary", "+=", "f\"_wm{args.warmup_steps}\"", "\n", "\n", "", "arg_summary", "+=", "(", "\n", "f\"_lr{args.learning_rate}\"", "\n", "f\"_acc{args.accumulate_grad_batches}\"", "\n", "f\"_seq{args.max_seq_length}\"", "\n", "f\"_val{args.val_check_interval}\"", "\n", "f\"_pat{args.patience}\"", "\n", "f\"_sd{args.seed}\"", "\n", "f\"_wdec{args.weight_decay}\"", "\n", ")", "\n", "\n", "if", "args", ".", "padding", "is", "not", "None", ":", "\n", "        ", "arg_summary", "+=", "f\"_pa{args.padding[:3]}\"", "\n", "", "if", "args", ".", "pad_to_multiple_of", "is", "not", "None", ":", "\n", "        ", "arg_summary", "+=", "f\"_pam{args.pad_to_multiple_of}\"", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "arg_summary", "+=", "\"_amp\"", "\n", "\n", "", "if", "args", ".", "reinit_pooler", ":", "\n", "        ", "arg_summary", "+=", "\"_rep\"", "\n", "\n", "", "if", "args", ".", "reinit_layers", ">", "0", ":", "\n", "        ", "arg_summary", "+=", "f\"_rel{args.reinit_layers}\"", "\n", "\n", "", "if", "args", ".", "deterministic", ":", "\n", "        ", "arg_summary", "+=", "\"_det\"", "\n", "\n", "", "if", "args", ".", "num_augments", ">", "0", ":", "\n", "        ", "arg_summary", "+=", "f\"_naug{args.num_augments}\"", "\n", "if", "not", "args", ".", "naive_augment", ":", "\n", "            ", "arg_summary", "+=", "f\"of{args.num_aug_candidates}\"", "\n", "# elif args.start_rank > 0:", "\n", "#     arg_summary += f\"st{args.start_rank}\"", "\n", "\n", "", "if", "args", ".", "maxim_func", "!=", "\"ce\"", ":", "\n", "            ", "arg_summary", "+=", "f\"_{args.maxim_func}\"", "\n", "\n", "", "if", "args", ".", "min_distance", ">", "0", ":", "\n", "            ", "arg_summary", "+=", "f\"_mind{args.min_distance}\"", "\n", "\n", "", "if", "args", ".", "max_distance", ">", "0", ":", "\n", "            ", "arg_summary", "+=", "f\"_maxd{args.max_distance}\"", "\n", "\n", "", "", "if", "args", ".", "teacher_name_or_path", "is", "not", "None", ":", "\n", "        ", "arg_summary", "+=", "f\"_tau{args.temperature}\"", "\n", "arg_summary", "+=", "f\"_ce{args.alpha_ce}\"", "\n", "arg_summary", "+=", "f\"_tru{args.alpha_true}\"", "\n", "\n", "if", "args", ".", "num_augments", ">", "0", ":", "\n", "            ", "arg_summary", "+=", "f\"_aug{args.alpha_aug}\"", "\n", "\n", "if", "args", ".", "augment_start_epoch", ">", "0", ":", "\n", "                ", "arg_summary", "+=", "f\"_augst{args.augment_start_epoch}\"", "\n", "\n", "", "if", "args", ".", "naive_augment", ":", "\n", "                ", "arg_summary", "+=", "f\"_naive\"", "\n", "if", "args", ".", "preserve_order", ":", "\n", "                    ", "arg_summary", "+=", "f\"_order\"", "\n", "\n", "", "", "", "arg_summary", "+=", "\"_distilled\"", "\n", "\n", "", "return", "arg_summary", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue._sanity_check": [[1004, 1018], ["None"], "function", ["None"], ["", "def", "_sanity_check", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "do_train", ":", "\n", "        ", "assert", "0.0", "<=", "args", ".", "warmup_ratio", "<=", "1.0", ",", "\"`--warmup_ratio` must be in [0, 1]\"", "\n", "\n", "if", "args", ".", "teacher_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "not", "args", ".", "naive_augment", "and", "args", ".", "num_augments", ">", "0", ":", "\n", "                ", "assert", "args", ".", "minimax_update_interval", ">=", "0", ",", "\"`--minimax_update_interval` must not be negative\"", "\n", "\n", "if", "args", ".", "min_distance", ">", "0", "and", "args", ".", "max_distance", ">", "0", ":", "\n", "                    ", "assert", "args", ".", "min_distance", "<=", "args", ".", "max_distance", ",", "\"`--min_distance` <= `--max_distance` must be true\"", "\n", "\n", "", "", "", "assert", "not", "(", "\n", "args", ".", "do_infer", "or", "args", ".", "do_test", "or", "args", ".", "do_eval", "\n", ")", ",", "\"`--do_infer`, `--do_test` and `--do_eval` cannot be done if training is enabled\"", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue._load_default_args": [[1020, 1058], ["hparams_path.exists", "logger.warning", "logger.info", "pathlib.Path", "hparams_path.open", "yaml.safe_load", "yaml.safe_load.get", "yaml.safe_load.get", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["None"], ["", "", "def", "_load_default_args", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "teacher_name_or_path", "is", "not", "None", "and", "args", ".", "num_augments", ">", "0", "and", "args", ".", "alpha_aug", "is", "None", ":", "\n", "        ", "args", ".", "alpha_aug", "=", "args", ".", "alpha_ce", "\n", "\n", "", "if", "args", ".", "naive_augment", "and", "args", ".", "preserve_order", ":", "\n", "        ", "if", "args", ".", "min_distance", ">", "0", "or", "args", ".", "max_distance", ">", "0", ":", "\n", "            ", "args", ".", "min_distance", "=", "0", "\n", "args", ".", "max_distance", "=", "0", "\n", "logger", ".", "warning", "(", "\"Distance thresholds are overwritten to zero because `--preserver_order` is activated\"", ")", "\n", "\n", "", "", "if", "not", "args", ".", "do_train", "and", "(", "args", ".", "do_infer", "or", "args", ".", "do_eval", "or", "args", ".", "do_test", ")", ":", "\n", "        ", "hparams_path", "=", "Path", "(", "args", ".", "model_name_or_path", ")", ".", "parent", "/", "\"hparams.yaml\"", "\n", "if", "hparams_path", ".", "exists", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"`hparams.yaml` found from which parameter values (max_seq_length, pad_to_multiple_of, and padding) will be loaded\"", "\n", ")", "\n", "\n", "with", "hparams_path", ".", "open", "(", "\"r\"", ")", "as", "hparams_file", ":", "\n", "                ", "train_hparams", "=", "yaml", ".", "safe_load", "(", "hparams_file", ")", "\n", "\n", "", "if", "args", ".", "max_seq_length", "==", "0", ":", "\n", "                ", "args", ".", "max_seq_length", "=", "train_hparams", ".", "get", "(", "\"max_seq_length\"", ",", "0", ")", "\n", "\n", "", "if", "args", ".", "pad_to_multiple_of", "is", "None", ":", "\n", "                ", "args", ".", "pad_to_multiple_of", "=", "train_hparams", ".", "get", "(", "\"pad_to_multiple_of\"", ",", "None", ")", "\n", "\n", "", "if", "args", ".", "padding", "is", "None", "and", "\"padding\"", "in", "train_hparams", ":", "\n", "                ", "args", ".", "padding", "=", "train_hparams", "[", "\"padding\"", "]", "\n", "\n", "", "", "", "if", "args", ".", "accelerator", "is", "None", ":", "\n", "        ", "if", "args", ".", "gpus", "==", "0", ":", "\n", "            ", "args", ".", "accelerator", "=", "\"ddp_cpu\"", "\n", "", "elif", "args", ".", "gpus", "==", "1", ":", "\n", "            ", "args", ".", "accelerator", "=", "\"dp\"", "\n", "", "elif", "args", ".", "gpus", "==", "-", "1", ":", "\n", "            ", "args", ".", "accelerator", "=", "\"ddp\"", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", "else", "\"dp\"", "\n", "", "else", ":", "\n", "            ", "args", ".", "accelerator", "=", "\"ddp\"", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.main": [[1060, 1150], ["run_glue._sanity_check", "run_glue._load_default_args", "run_glue.GLUETransformer", "pytorch_lightning.callbacks.ModelCheckpoint", "dict", "lightning_base.generic_train", "os.path.exists", "os.path.join", "extra_callbacks.append", "pytorch_lightning.loggers.TensorBoardLogger", "list", "os.makedirs", "run_glue._get_default_output_dir", "pytorch_lightning.callbacks.EarlyStopping", "sorted", "model.load_from_checkpoint.load_from_checkpoint", "lightning_base.generic_train.test", "lightning_base.generic_train.test", "lightning_base.generic_train.test", "glob.glob", "model.load_from_checkpoint.get_dataloader", "model.load_from_checkpoint.get_dataloader", "os.path.join"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue._sanity_check", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue._load_default_args", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.lightning_base.generic_train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue._get_default_output_dir", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_dataloader", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.cls.run_glue.GLUETransformer.get_dataloader"], ["", "", "", "def", "main", "(", "args", ":", "Namespace", ")", ":", "\n", "    ", "_sanity_check", "(", "args", ")", "\n", "_load_default_args", "(", "args", ")", "\n", "\n", "# If output_dir not provided, a folder will be generated in pwd", "\n", "if", "args", ".", "output_dir", "is", "None", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "            ", "args", ".", "output_dir", "=", "args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "            ", "args", ".", "output_dir", "=", "\"./results\"", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "# args.output_dir = os.path.join(", "\n", "#     \"./results\",", "\n", "#     f\"{args.task}_{time.strftime('%Y%m%d_%H%M%S')}\",", "\n", "# )", "\n", "\n", "", "", "if", "args", ".", "do_train", ":", "\n", "        ", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "_get_default_output_dir", "(", "args", ")", ")", "\n", "\n", "", "model", "=", "GLUETransformer", "(", "args", ")", "\n", "\n", "extra_callbacks", "=", "[", "]", "\n", "if", "args", ".", "do_train", "and", "args", ".", "patience", ">", "0", ":", "\n", "        ", "extra_callbacks", ".", "append", "(", "\n", "pl", ".", "callbacks", ".", "EarlyStopping", "(", "\n", "monitor", "=", "\"val_metric\"", ",", "\n", "min_delta", "=", "args", ".", "min_delta", ",", "\n", "patience", "=", "args", ".", "patience", ",", "\n", "verbose", "=", "False", ",", "\n", "mode", "=", "\"max\"", ",", "\n", ")", "\n", ")", "\n", "\n", "", "checkpoint_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "filepath", "=", "args", ".", "output_dir", ",", "\n", "prefix", "=", "\"checkpoint\"", ",", "\n", "monitor", "=", "\"val_metric\"", ",", "\n", "mode", "=", "\"max\"", ",", "\n", "save_top_k", "=", "1", ",", "\n", ")", "\n", "\n", "augmentation_on", "=", "args", ".", "teacher_name_or_path", "is", "not", "None", "and", "args", ".", "num_augments", ">", "0", "\n", "trainer_kwargs", "=", "dict", "(", "\n", "reload_dataloaders_every_epoch", "=", "augmentation_on", ",", "\n", "profiler", "=", "\"simple\"", ",", "\n", ")", "\n", "# if is_ddp_enabled(args.distributed_backend, args.gpus):", "\n", "#     trainer_kwargs[\"replace_sampler_ddp\"] = False", "\n", "\n", "logger", "=", "(", "\n", "pl_loggers", ".", "TensorBoardLogger", "(", "\n", "save_dir", "=", "args", ".", "output_dir", ",", "\n", "name", "=", "\"train_logs\"", ",", "\n", "default_hp_metric", "=", "False", ",", "\n", ")", "\n", "if", "args", ".", "do_train", "\n", "else", "False", "\n", ")", "\n", "\n", "trainer", "=", "generic_train", "(", "\n", "model", ",", "\n", "args", ",", "\n", "logger", ",", "\n", "extra_callbacks", ",", "\n", "checkpoint_callback", ",", "\n", "weights_summary", "=", "\"top\"", ",", "\n", "**", "trainer_kwargs", ",", "\n", ")", "\n", "\n", "# Optionally, predict on dev set and write to output_dir", "\n", "if", "args", ".", "do_eval", "or", "args", ".", "do_infer", "or", "args", ".", "do_test", ":", "\n", "        ", "checkpoints", "=", "list", "(", "\n", "sorted", "(", "\n", "glob", ".", "glob", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpointepoch=*.ckpt\"", ")", ",", "\n", "recursive", "=", "True", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "if", "checkpoints", ":", "\n", "            ", "model", "=", "model", ".", "load_from_checkpoint", "(", "checkpoints", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "args", ".", "do_eval", ":", "\n", "            ", "trainer", ".", "test", "(", "model", ")", "\n", "\n", "", "if", "args", ".", "do_infer", ":", "\n", "            ", "trainer", ".", "test", "(", "model", ",", "model", ".", "get_dataloader", "(", "\"infer\"", ",", "args", ".", "eval_batch_size", ")", ")", "\n", "\n", "", "if", "args", ".", "do_test", ":", "\n", "            ", "trainer", ".", "test", "(", "model", ",", "model", ".", "get_dataloader", "(", "\"test2\"", ",", "args", ".", "eval_batch_size", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached._Dataset.__init__": [[50, 61], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "examples", ":", "Union", "[", "List", "[", "InputExample", "]", ",", "List", "[", "AugmentedInputExample", "]", "]", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "max_length", ":", "int", ",", "\n", "max_augment_length", ":", "int", ",", "\n", ")", ":", "\n", "        ", "self", ".", "examples", "=", "examples", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_augment_length", "=", "max_augment_length", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached._Dataset.__len__": [[62, 64], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached._Dataset.__getitem__": [[65, 91], ["cached._Dataset.tokenizer", "hasattr", "utils.InputFeaturesV2", "cached._Dataset.tokenizer", "augmented_features.append", "transformers.InputFeatures"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", "->", "InputFeaturesV2", ":", "\n", "        ", "ex", "=", "self", ".", "examples", "[", "index", "]", "\n", "encoded_example", "=", "self", ".", "tokenizer", "(", "\n", "ex", ".", "text_a", ",", "\n", "ex", ".", "text_b", ",", "\n", "max_length", "=", "self", ".", "max_length", "if", "self", ".", "max_length", ">", "0", "else", "None", ",", "\n", "padding", "=", "\"longest\"", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", "\n", "augmented_features", "=", "[", "]", "\n", "if", "hasattr", "(", "ex", ",", "\"augmented_examples\"", ")", ":", "\n", "            ", "for", "aug_ex", "in", "ex", ".", "augmented_examples", ":", "\n", "                ", "encoded_aug", "=", "self", ".", "tokenizer", "(", "\n", "aug_ex", ".", "text_a", ",", "\n", "aug_ex", ".", "text_b", ",", "\n", "max_length", "=", "self", ".", "max_augment_length", "if", "self", ".", "max_augment_length", ">", "0", "else", "None", ",", "\n", "padding", "=", "\"longest\"", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", "augmented_features", ".", "append", "(", "InputFeatures", "(", "**", "encoded_aug", ")", ")", "\n", "\n", "", "", "return", "InputFeaturesV2", "(", "\n", "**", "encoded_example", ",", "\n", "label", "=", "None", ",", "\n", "augmented_features", "=", "augmented_features", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached._Collator.__call__": [[109, 138], ["cached._Collator.tokenizer.pad", "cached._Collator.keys", "enumerate", "flattened_features.append", "flattened_features.extend", "flattened_batch[].new_zeros", "cached._Collator.keys", "cached._asdict", "len", "cached._asdict", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached._asdict", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached._asdict"], ["def", "__call__", "(", "self", ",", "features", ":", "List", "[", "InputFeaturesV2", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "flattened_features", "=", "[", "]", "\n", "\n", "for", "f", "in", "features", ":", "\n", "            ", "flattened_features", ".", "append", "(", "_asdict", "(", "f", ")", ")", "\n", "flattened_features", ".", "extend", "(", "[", "_asdict", "(", "augf", ")", "for", "augf", "in", "f", ".", "augmented_features", "]", ")", "\n", "\n", "", "flattened_batch", "=", "self", ".", "tokenizer", ".", "pad", "(", "\n", "flattened_features", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "pad_to_multiple_of", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", ")", "\n", "\n", "max_length", "=", "flattened_batch", "[", "\"input_ids\"", "]", ".", "shape", "[", "-", "1", "]", "\n", "\n", "batch", "=", "{", "}", "\n", "for", "k", "in", "flattened_batch", ".", "keys", "(", ")", ":", "\n", "            ", "batch", "[", "k", "]", "=", "flattened_batch", "[", "k", "]", ".", "new_zeros", "(", "(", "len", "(", "features", ")", ",", "self", ".", "num_augments", "+", "1", ",", "max_length", ")", ")", "\n", "\n", "", "idx", "=", "0", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "num_augs", "=", "len", "(", "f", ".", "augmented_features", ")", "+", "1", "\n", "\n", "for", "k", "in", "flattened_batch", ".", "keys", "(", ")", ":", "\n", "                ", "batch", "[", "k", "]", "[", "i", ",", ":", "num_augs", ",", ":", "]", "=", "flattened_batch", "[", "k", "]", "[", "idx", ":", "idx", "+", "num_augs", ",", ":", "]", "\n", "", "idx", "+=", "num_augs", "\n", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached._asdict": [[94, 99], ["dataclasses.asdict().items", "dataclasses.asdict"], "function", ["None"], ["", "", "def", "_asdict", "(", "f", ":", "Union", "[", "InputFeaturesV2", ",", "InputFeatures", "]", ")", ":", "\n", "    ", "return", "{", "\n", "k", ":", "v", "\n", "for", "k", ",", "v", "in", "asdict", "(", "f", ")", ".", "items", "(", ")", "\n", "if", "k", "not", "in", "(", "\"augmented_features\"", ",", "\"example_index\"", ",", "\"augmented_indices\"", ",", "\"augmented_rank\"", ")", "and", "v", "is", "not", "None", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.cached.cached_model_outputs": [[140, 255], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "glue.GLUEv2Processor", "glue.GLUEv2Processor.get_train_examples", "max", "cached._Dataset", "kwargs.pop.mkdir", "numpy.memmap", "numpy.memmap", "cached.SavedModelOutput", "torch.cuda.current_device", "os.path.dirname", "pathlib.Path", "cached._Collator", "torch.utils.data.DataLoader", "transformers.AutoModelForSequenceClassification.from_pretrained", "torch.nn.DataParallel", "torch.nn.DataParallel.to", "numpy.memmap", "numpy.memmap", "tqdm.tqdm", "str", "str", "torch.from_numpy", "torch.from_numpy", "os.path.abspath", "len", "logits_file.exists", "hidden_states_file.exists", "str", "str", "torch.nn.DataParallel.eval", "model.logits.reshape().cpu().numpy", "hf_utils.get_last_layer_hidden_states", "hf_utils.get_last_layer_hidden_states.reshape().cpu().numpy", "numpy.array", "numpy.array", "bool", "len", "v.view().to", "torch.no_grad", "torch.nn.DataParallel.", "len", "len", "len", "len", "batch.items", "model.logits.reshape().cpu", "hf_utils.get_last_layer_hidden_states.reshape().cpu", "v.view", "model.logits.reshape", "hf_utils.get_last_layer_hidden_states.reshape"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_train_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.knnkd.hf_utils.get_last_layer_hidden_states"], ["", "", "def", "cached_model_outputs", "(", "\n", "model_name_or_path", ":", "str", ",", "\n", "task", ":", "str", ",", "\n", "data_dir", ":", "str", ",", "\n", "batch_size", ":", "int", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "return_tensor", ":", "bool", "=", "True", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "SavedModelOutput", ":", "\n", "    ", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "config_name", "=", "kwargs", ".", "pop", "(", "\"config_name\"", ",", "None", ")", "\n", "tokenizer_name", "=", "kwargs", ".", "pop", "(", "\"tokenizer_name\"", ",", "None", ")", "\n", "dataset_name", "=", "kwargs", ".", "pop", "(", "\"dataset_name\"", ",", "None", ")", "\n", "device", "=", "kwargs", ".", "pop", "(", "\"device\"", ",", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "num_workers", "=", "kwargs", ".", "pop", "(", "\"num_workers\"", ",", "8", ")", "\n", "output_dir", "=", "kwargs", ".", "pop", "(", "\"output_dir\"", ",", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "model_name_or_path", ")", ")", ")", "\n", "\n", "max_augment_length", "=", "kwargs", ".", "pop", "(", "\"max_augment_length\"", ",", "max_seq_length", ")", "\n", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "config_name", "or", "model_name_or_path", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", ")", "\n", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "tokenizer_name", "or", "model_name_or_path", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", ")", "\n", "\n", "processor", "=", "GLUEv2Processor", "(", "\n", "task", ",", "\n", "num_augments", "=", "-", "1", ",", "\n", ")", "\n", "\n", "examples", "=", "processor", ".", "get_train_examples", "(", "data_dir", ")", "\n", "num_augments", "=", "max", "(", "len", "(", "ex", ".", "augmented_examples", ")", "for", "ex", "in", "examples", ")", "\n", "dataset", "=", "_Dataset", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "max_augment_length", ",", "\n", ")", "\n", "\n", "num_labels", "=", "glue_tasks_num_labels", "[", "task", "]", "\n", "\n", "output_dir", "=", "Path", "(", "output_dir", ")", "/", "\".output_cache\"", "\n", "output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "dataset_prefix", "=", "f\"_{dataset_name}\"", "if", "dataset_name", "else", "\"\"", "\n", "aug_prefix", "=", "f\"_augseq{max_augment_length}\"", "if", "max_augment_length", "!=", "max_seq_length", "else", "\"\"", "\n", "prefix", "=", "f\"{config.model_type}_{task}{dataset_prefix}_seq{max_seq_length}{aug_prefix}_train\"", "\n", "\n", "logits_file", "=", "output_dir", "/", "f\"{prefix}_logits.npy\"", "\n", "hidden_states_file", "=", "output_dir", "/", "f\"{prefix}_hidden_states.npy\"", "\n", "\n", "if", "not", "logits_file", ".", "exists", "(", ")", "or", "not", "hidden_states_file", ".", "exists", "(", ")", ":", "\n", "        ", "collator", "=", "_Collator", "(", "tokenizer", ",", "num_augments", ")", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "collate_fn", "=", "collator", ",", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "True", "\n", ")", "\n", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", ")", "\n", "\n", "model", "=", "DataParallel", "(", "model", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "logits", "=", "np", ".", "memmap", "(", "\n", "str", "(", "logits_file", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ",", "\n", "mode", "=", "\"w+\"", ",", "\n", "shape", "=", "(", "len", "(", "dataset", ")", ",", "num_augments", "+", "1", ",", "num_labels", ")", ",", "\n", ")", "\n", "\n", "hidden_states", "=", "np", ".", "memmap", "(", "\n", "str", "(", "hidden_states_file", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ",", "\n", "mode", "=", "\"w+\"", ",", "\n", "shape", "=", "(", "len", "(", "dataset", ")", ",", "num_augments", "+", "1", ",", "config", ".", "hidden_size", ")", ",", "\n", ")", "\n", "\n", "idx", "=", "0", "\n", "for", "batch", "in", "tqdm", "(", "dataloader", ",", "total", "=", "len", "(", "dataloader", ")", ",", "desc", "=", "\"Caching model output\"", ")", ":", "\n", "            ", "bsz", "=", "batch", "[", "\"input_ids\"", "]", ".", "shape", "[", "0", "]", "\n", "batch", "=", "{", "k", ":", "v", ".", "view", "(", "-", "1", ",", "v", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "device", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "output", "=", "model", "(", "**", "batch", ")", "\n", "", "logits", "[", "idx", ":", "idx", "+", "bsz", ",", ":", ",", ":", "]", "=", "output", ".", "logits", ".", "reshape", "(", "bsz", ",", "-", "1", ",", "output", ".", "logits", ".", "shape", "[", "-", "1", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "last_hidden_state", "=", "get_last_layer_hidden_states", "(", "config", ",", "output", ")", "\n", "hidden_states", "[", "idx", ":", "idx", "+", "bsz", ",", ":", ",", ":", "]", "=", "(", "\n", "last_hidden_state", ".", "reshape", "(", "bsz", ",", "-", "1", ",", "last_hidden_state", ".", "shape", "[", "-", "1", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "\n", "idx", "+=", "bsz", "\n", "\n", "", "", "logits", "=", "np", ".", "memmap", "(", "\n", "str", "(", "logits_file", ")", ",", "mode", "=", "\"r\"", ",", "dtype", "=", "np", ".", "float32", ",", "shape", "=", "(", "len", "(", "dataset", ")", ",", "num_augments", "+", "1", ",", "num_labels", ")", "\n", ")", "\n", "\n", "hidden_states", "=", "np", ".", "memmap", "(", "\n", "str", "(", "hidden_states_file", ")", ",", "mode", "=", "\"r\"", ",", "dtype", "=", "np", ".", "float32", ",", "shape", "=", "(", "len", "(", "dataset", ")", ",", "num_augments", "+", "1", ",", "config", ".", "hidden_size", ")", "\n", ")", "\n", "\n", "if", "return_tensor", ":", "\n", "        ", "logits", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "logits", ")", ")", "\n", "hidden_states", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "hidden_states", ")", ")", "\n", "\n", "", "return", "SavedModelOutput", "(", "logits", ",", "hidden_states", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.collator.FeaturesCollatorWithPadding.__call__": [[53, 130], ["collections.defaultdict", "collections.defaultdict.items", "grouped_features[].append", "collator.FeaturesCollatorWithPadding.tokenizer.pad", "any", "any", "hasattr", "tuple", "collator.FeaturesCollatorWithPadding.tokenizer.pad", "torch.LongTensor", "torch.LongTensor", "any", "any", "torch.LongTensor", "collator.FeaturesCollatorWithPadding.get", "collator.FeaturesCollatorWithPadding.get", "collator.FeaturesCollatorWithPadding.get", "collator.FeaturesCollatorWithPadding.get", "collator.FeaturesCollatorWithPadding.get", "collator.FeaturesCollatorWithPadding.get", "collator._as_dict", "torch.LongTensor", "torch.LongTensor", "hasattr", "collator._as_dict", "hasattr", "enumerate", "range", "range", "hasattr", "hasattr", "len", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.collator._as_dict", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.collator._as_dict"], ["def", "__call__", "(", "\n", "self", ",", "features", ":", "Union", "[", "List", "[", "InputFeatures", "]", ",", "List", "[", "InputFeaturesV2", "]", "]", "\n", ")", "->", "List", "[", "Tuple", "[", "Optional", "[", "torch", ".", "Tensor", "]", ",", "...", "]", "]", ":", "\n", "\n", "        ", "grouped_features", "=", "defaultdict", "(", "list", ")", "\n", "for", "f", "in", "features", ":", "\n", "            ", "if", "self", ".", "group_features", "and", "hasattr", "(", "f", ",", "\"augmented_rank\"", ")", ":", "\n", "                ", "aug_rank", "=", "f", ".", "augmented_rank", "\n", "", "else", ":", "\n", "                ", "aug_rank", "=", "0", "\n", "\n", "", "grouped_features", "[", "aug_rank", "]", ".", "append", "(", "f", ")", "\n", "\n", "", "grouped_batch", "=", "[", "tuple", "(", ")", "]", "*", "(", "self", ".", "num_augment_ranks", "+", "1", ")", "\n", "\n", "for", "aug_rank", ",", "subfeatures", "in", "grouped_features", ".", "items", "(", ")", ":", "\n", "            ", "batch", "=", "self", ".", "tokenizer", ".", "pad", "(", "\n", "[", "\n", "_as_dict", "(", "f", ",", "[", "\"augmented_features\"", ",", "\"augmented_indices\"", ",", "\"example_index\"", ",", "\"augmented_rank\"", "]", ")", "\n", "for", "f", "in", "subfeatures", "\n", "]", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "pad_to_multiple_of", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", ")", "\n", "\n", "if", "\"label\"", "in", "batch", ":", "\n", "                ", "batch", "[", "\"labels\"", "]", "=", "batch", "[", "\"label\"", "]", "\n", "del", "batch", "[", "\"label\"", "]", "\n", "", "if", "\"label_ids\"", "in", "batch", ":", "\n", "                ", "batch", "[", "\"labels\"", "]", "=", "batch", "[", "\"label_ids\"", "]", "\n", "del", "batch", "[", "\"label_ids\"", "]", "\n", "\n", "", "augmented_batch", "=", "{", "}", "\n", "augmented_mask", "=", "None", "\n", "augmented_ranks", "=", "None", "\n", "if", "any", "(", "hasattr", "(", "f", ",", "\"augmented_features\"", ")", "and", "f", ".", "augmented_features", "for", "f", "in", "subfeatures", ")", ":", "\n", "                ", "augmented_batch", "=", "self", ".", "tokenizer", ".", "pad", "(", "\n", "[", "_as_dict", "(", "augf", ")", "for", "f", "in", "subfeatures", "for", "augf", "in", "f", ".", "augmented_features", "]", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "pad_to_multiple_of", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", ")", "\n", "augmented_mask", "=", "torch", ".", "LongTensor", "(", "\n", "[", "i", "for", "i", ",", "f", "in", "enumerate", "(", "subfeatures", ")", "for", "_", "in", "range", "(", "len", "(", "f", ".", "augmented_features", ")", ")", "]", "\n", ")", "\n", "augmented_ranks", "=", "torch", ".", "LongTensor", "(", "\n", "[", "r", "+", "1", "for", "f", "in", "subfeatures", "for", "r", "in", "range", "(", "len", "(", "f", ".", "augmented_features", ")", ")", "]", "\n", ")", "\n", "\n", "", "augmented_indices", "=", "None", "\n", "if", "self", ".", "group_features", ":", "\n", "                ", "if", "any", "(", "hasattr", "(", "f", ",", "\"augmented_indices\"", ")", "and", "f", ".", "augmented_indices", "is", "not", "None", "for", "f", "in", "subfeatures", ")", ":", "\n", "                    ", "augmented_indices", "=", "torch", ".", "LongTensor", "(", "[", "aug_idx", "for", "f", "in", "subfeatures", "for", "aug_idx", "in", "f", ".", "augmented_indices", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "any", "(", "hasattr", "(", "f", ",", "\"augmented_rank\"", ")", "and", "f", ".", "augmented_rank", "is", "not", "None", "for", "f", "in", "subfeatures", ")", ":", "\n", "                    ", "augmented_indices", "=", "torch", ".", "LongTensor", "(", "[", "f", ".", "augmented_rank", "for", "f", "in", "subfeatures", "]", ")", "\n", "\n", "", "", "example_indices", "=", "None", "\n", "if", "any", "(", "hasattr", "(", "f", ",", "\"example_index\"", ")", "and", "f", ".", "example_index", "is", "not", "None", "for", "f", "in", "subfeatures", ")", ":", "\n", "                ", "example_indices", "=", "torch", ".", "LongTensor", "(", "[", "f", ".", "example_index", "for", "f", "in", "subfeatures", "]", ")", "\n", "\n", "", "grouped_batch", "[", "aug_rank", "]", "=", "(", "\n", "batch", "[", "\"input_ids\"", "]", ",", "\n", "batch", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", ",", "\n", "batch", ".", "get", "(", "\"token_type_ids\"", ",", "None", ")", ",", "\n", "batch", ".", "get", "(", "\"labels\"", ",", "None", ")", ",", "\n", "augmented_batch", ".", "get", "(", "\"input_ids\"", ",", "None", ")", ",", "\n", "augmented_batch", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", ",", "\n", "augmented_batch", ".", "get", "(", "\"token_type_ids\"", ",", "None", ")", ",", "\n", "example_indices", ",", "\n", "augmented_indices", ",", "\n", "augmented_mask", ",", "\n", "augmented_ranks", ",", "\n", ")", "\n", "\n", "", "return", "grouped_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.collator._as_dict": [[17, 20], ["dataclasses.asdict().items", "dataclasses.asdict"], "function", ["None"], ["def", "_as_dict", "(", "obj", ",", "exclude_fields", ":", "Optional", "[", "Iterable", "[", "str", "]", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "exclude_fields", "=", "exclude_fields", "or", "[", "]", "\n", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "asdict", "(", "obj", ")", ".", "items", "(", ")", "if", "v", "is", "not", "None", "and", "k", "not", "in", "exclude_fields", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.collator.collate_tokens": [[132, 166], ["max", "values[].new().fill_", "enumerate", "max", "int", "collator.collate_tokens.copy_tensor"], "function", ["None"], ["", "", "def", "collate_tokens", "(", "\n", "values", ",", "\n", "pad_idx", ",", "\n", "eos_idx", "=", "None", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", "pad_to_length", "=", "None", ",", "\n", "pad_to_multiple", "=", "1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Copied from fairseq: https://github.com/pytorch/fairseq/blob/a48f235636557b8d3bc4922a6fa90f3a0fa57955/fairseq/data/data_utils.py#L34\n    Convert a list of 1d tensors into a padded 2d tensor.\n    \"\"\"", "\n", "size", "=", "max", "(", "v", ".", "size", "(", "0", ")", "for", "v", "in", "values", ")", "\n", "size", "=", "size", "if", "pad_to_length", "is", "None", "else", "max", "(", "size", ",", "pad_to_length", ")", "\n", "if", "pad_to_multiple", "!=", "1", "and", "size", "%", "pad_to_multiple", "!=", "0", ":", "\n", "        ", "size", "=", "int", "(", "(", "(", "size", "-", "0.1", ")", "//", "pad_to_multiple", "+", "1", ")", "*", "pad_to_multiple", ")", "\n", "", "res", "=", "values", "[", "0", "]", ".", "new", "(", "len", "(", "values", ")", ",", "size", ")", ".", "fill_", "(", "pad_idx", ")", "\n", "\n", "def", "copy_tensor", "(", "src", ",", "dst", ")", ":", "\n", "        ", "assert", "dst", ".", "numel", "(", ")", "==", "src", ".", "numel", "(", ")", "\n", "if", "move_eos_to_beginning", ":", "\n", "            ", "if", "eos_idx", "is", "None", ":", "\n", "# if no eos_idx is specified, then use the last token in src", "\n", "                ", "dst", "[", "0", "]", "=", "src", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "dst", "[", "0", "]", "=", "eos_idx", "\n", "", "dst", "[", "1", ":", "]", "=", "src", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "dst", ".", "copy_", "(", "src", ")", "\n", "\n", "", "", "for", "i", ",", "v", "in", "enumerate", "(", "values", ")", ":", "\n", "        ", "copy_tensor", "(", "v", ",", "res", "[", "i", "]", "[", "size", "-", "len", "(", "v", ")", ":", "]", "if", "left_pad", "else", "res", "[", "i", "]", "[", ":", "len", "(", "v", ")", "]", ")", "\n", "", "return", "res", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Dataset.__init__": [[39, 75], ["enumerate", "enumerate", "range", "min", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "examples", ":", "Union", "[", "List", "[", "InputExample", "]", ",", "List", "[", "AugmentedInputExample", "]", "]", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "output_mode", ":", "str", ",", "\n", "max_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizerBase", ",", "\n", "max_augment_length", ":", "int", "=", "0", ",", "\n", "num_augments", ":", "int", "=", "0", ",", "\n", "allowed_augment_indices", ":", "Optional", "[", "List", "[", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "naive_augment", ":", "bool", "=", "False", ",", "\n", "padding", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "examples", "=", "examples", "\n", "\n", "self", ".", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "self", ".", "label_map", "[", "-", "100", "]", "=", "-", "100", "\n", "self", ".", "output_mode", "=", "output_mode", "\n", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "self", ".", "max_augment_length", "=", "max_augment_length", "or", "max_length", "\n", "\n", "self", ".", "allowed_augment_indices", "=", "allowed_augment_indices", "\n", "if", "self", ".", "allowed_augment_indices", "is", "not", "None", ":", "\n", "            ", "self", ".", "flattened_augment_ranks", "=", "[", "\n", "(", "i", ",", "j", ")", "\n", "for", "i", ",", "indices", "in", "enumerate", "(", "self", ".", "allowed_augment_indices", ")", "\n", "for", "j", "in", "range", "(", "1", "+", "min", "(", "num_augments", ",", "len", "(", "indices", ")", ")", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "flattened_augment_ranks", "=", "None", "\n", "\n", "", "self", ".", "naive_augment", "=", "naive_augment", "\n", "self", ".", "padding", "=", "padding", "or", "\"max_length\"", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Dataset.label_from_example": [[76, 84], ["KeyError", "float"], "methods", ["None"], ["", "def", "label_from_example", "(", "self", ",", "example", ":", "InputExample", ")", "->", "Union", "[", "int", ",", "float", ",", "None", "]", ":", "\n", "        ", "if", "example", ".", "label", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "if", "self", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "return", "self", ".", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "self", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "return", "float", "(", "example", ".", "label", ")", "\n", "", "raise", "KeyError", "(", "self", ".", "output_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Dataset.__getitem__": [[85, 167], ["glue.GLUEv2Dataset.tokenizer", "glue.GLUEv2Dataset.tokenizer", "utils.InputFeaturesV2", "hasattr", "utils.InputFeaturesV2", "utils.InputFeaturesV2", "hasattr", "glue.GLUEv2Dataset.label_from_example", "transformers.InputFeatures", "glue.GLUEv2Dataset.label_from_example", "glue.GLUEv2Dataset.label_from_example", "glue.GLUEv2Dataset.tokenizer"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Dataset.label_from_example", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Dataset.label_from_example", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Dataset.label_from_example"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", "->", "Union", "[", "InputFeatures", ",", "InputFeaturesV2", "]", ":", "\n", "        ", "if", "self", ".", "flattened_augment_ranks", "is", "not", "None", ":", "\n", "            ", "ex_index", ",", "aug_rank", "=", "self", ".", "flattened_augment_ranks", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "ex_index", ",", "aug_rank", "=", "index", ",", "0", "\n", "", "example", "=", "self", ".", "examples", "[", "ex_index", "]", "\n", "\n", "if", "self", ".", "naive_augment", ":", "\n", "            ", "if", "hasattr", "(", "example", ",", "\"augmented_examples\"", ")", "and", "aug_rank", ">", "0", ":", "\n", "                ", "if", "self", ".", "allowed_augment_indices", "is", "not", "None", ":", "\n", "                    ", "aug_index", "=", "self", ".", "allowed_augment_indices", "[", "ex_index", "]", "[", "aug_rank", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "aug_index", "=", "aug_rank", "-", "1", "\n", "\n", "", "ex", "=", "example", ".", "augmented_examples", "[", "aug_index", "]", "\n", "aug_index", "+=", "1", "\n", "label", "=", "-", "100", "\n", "", "else", ":", "\n", "                ", "aug_index", "=", "0", "\n", "ex", "=", "example", "\n", "label", "=", "self", ".", "label_from_example", "(", "example", ")", "\n", "\n", "", "encoded_example", "=", "self", ".", "tokenizer", "(", "\n", "ex", ".", "text_a", ",", "\n", "ex", ".", "text_b", ",", "\n", "max_length", "=", "self", ".", "max_length", "if", "self", ".", "max_length", ">", "0", "else", "None", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", "\n", "return", "InputFeaturesV2", "(", "\n", "**", "encoded_example", ",", "\n", "label", "=", "label", ",", "\n", "example_index", "=", "ex_index", ",", "\n", "augmented_rank", "=", "aug_index", ",", "\n", ")", "\n", "\n", "", "encoded_example", "=", "self", ".", "tokenizer", "(", "\n", "example", ".", "text_a", ",", "\n", "example", ".", "text_b", ",", "\n", "max_length", "=", "self", ".", "max_length", "if", "self", ".", "max_length", ">", "0", "else", "None", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", "\n", "if", "hasattr", "(", "example", ",", "\"augmented_examples\"", ")", "and", "aug_rank", ">", "0", ":", "\n", "            ", "if", "self", ".", "allowed_augment_indices", "is", "not", "None", ":", "\n", "                ", "allowed_augmented_examples", "=", "[", "\n", "example", ".", "augmented_examples", "[", "j", "]", "for", "j", "in", "self", ".", "allowed_augment_indices", "[", "ex_index", "]", "\n", "]", "\n", "", "else", ":", "\n", "                ", "allowed_augmented_examples", "=", "example", ".", "augmented_examples", "\n", "\n", "", "augmented_features", "=", "[", "\n", "InputFeatures", "(", "\n", "**", "self", ".", "tokenizer", "(", "\n", "aug_ex", ".", "text_a", ",", "\n", "aug_ex", ".", "text_b", ",", "\n", "max_length", "=", "self", ".", "max_augment_length", "if", "self", ".", "max_augment_length", ">", "0", "else", "None", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", ")", "\n", "for", "aug_ex", "in", "allowed_augmented_examples", "\n", "]", "\n", "\n", "return", "InputFeaturesV2", "(", "\n", "**", "encoded_example", ",", "\n", "label", "=", "self", ".", "label_from_example", "(", "example", ")", ",", "\n", "example_index", "=", "ex_index", ",", "\n", "augmented_indices", "=", "self", ".", "allowed_augment_indices", "[", "ex_index", "]", "\n", "if", "self", ".", "allowed_augment_indices", "is", "not", "None", "\n", "else", "None", ",", "\n", "augmented_features", "=", "augmented_features", ",", "\n", "augmented_rank", "=", "aug_rank", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "InputFeaturesV2", "(", "\n", "**", "encoded_example", ",", "\n", "label", "=", "self", ".", "label_from_example", "(", "example", ")", ",", "\n", "example_index", "=", "ex_index", ",", "\n", "augmented_rank", "=", "aug_rank", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Dataset.__len__": [[169, 171], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "flattened_augment_ranks", "or", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.Sst5Processor.get_labels": [[195, 197], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.TrecProcessor.get_example_from_tensor_dict": [[200, 202], ["None"], "methods", ["None"], ["    ", "def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.TrecProcessor.get_train_examples": [[203, 206], ["glue.TrecProcessor._create_examples", "glue.TrecProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.TrecProcessor.get_dev_examples": [[207, 210], ["glue.TrecProcessor._create_examples", "glue.TrecProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.TrecProcessor.get_test_examples": [[211, 214], ["glue.TrecProcessor._create_examples", "glue.TrecProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.TrecProcessor.get_labels": [[215, 218], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"DESC\"", ",", "\"ENTY\"", ",", "\"ABBR\"", ",", "\"HUM\"", ",", "\"NUM\"", ",", "\"LOC\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.TrecProcessor._create_examples": [[219, 230], ["enumerate", "examples.append", "transformers.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ":", "str", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "f\"{set_type}-{line[0]}\"", "\n", "text_a", "=", "line", "[", "-", "1", "]", "\n", "label", "=", "None", "if", "set_type", "==", "\"test\"", "else", "line", "[", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.CrProcessor.get_example_from_tensor_dict": [[233, 235], ["None"], "methods", ["None"], ["    ", "def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.CrProcessor.get_train_examples": [[236, 239], ["glue.CrProcessor._create_examples", "glue.CrProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.CrProcessor.get_dev_examples": [[240, 243], ["glue.CrProcessor._create_examples", "glue.CrProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.CrProcessor.get_test_examples": [[244, 247], ["glue.CrProcessor._create_examples", "glue.CrProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.CrProcessor.get_labels": [[248, 251], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"negative\"", ",", "\"positive\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.CrProcessor._create_examples": [[252, 263], ["enumerate", "examples.append", "transformers.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ":", "str", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "f\"{set_type}-{i}\"", "\n", "text_a", "=", "line", "[", "0", "]", "\n", "label", "=", "None", "if", "set_type", "==", "\"test\"", "else", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.ImpProcessor.get_labels": [[266, 268], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.AGNewsProcessor.get_labels": [[271, 274], ["None"], "methods", ["None"], ["    ", "def", "get_labels", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"World\"", ",", "\"Sports\"", ",", "\"Business\"", ",", "\"Sci/Tech\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.__init__": [[340, 347], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "task_name", ":", "Optional", "[", "str", "]", ",", "num_augments", ":", "int", "=", "0", ")", ":", "\n", "        ", "self", ".", "task_name", "=", "task_name", "\n", "if", "task_name", ":", "\n", "            ", "self", ".", "hf_processor", "=", "glue_processors", "[", "self", ".", "task_name", "]", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hf_processor", "=", "None", "\n", "", "self", ".", "num_augments", "=", "num_augments", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_example_from_tensor_dict": [[348, 350], ["None"], "methods", ["None"], ["", "def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_train_examples": [[351, 358], ["pathlib.Path", "train_json_file.exists", "glue.GLUEv2Processor._create_examples", "glue.GLUEv2Processor.hf_processor.get_train_examples", "utils.read_jsonl", "str", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_train_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.utils.read_jsonl"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ":", "PathType", ")", ":", "\n", "        ", "data_dir", "=", "Path", "(", "data_dir", ")", "\n", "train_json_file", "=", "data_dir", "/", "\"train.jsonl\"", "\n", "if", "train_json_file", ".", "exists", "(", ")", ":", "\n", "            ", "return", "self", ".", "_create_examples", "(", "read_jsonl", "(", "str", "(", "train_json_file", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "hf_processor", ".", "get_train_examples", "(", "str", "(", "data_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_dev_examples": [[359, 366], ["pathlib.Path", "dev_json_file.exists", "glue.GLUEv2Processor._create_examples", "glue.GLUEv2Processor.hf_processor.get_dev_examples", "utils.read_jsonl", "str", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_dev_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.utils.read_jsonl"], ["", "", "def", "get_dev_examples", "(", "self", ",", "data_dir", ":", "PathType", ")", ":", "\n", "        ", "data_dir", "=", "Path", "(", "data_dir", ")", "\n", "dev_json_file", "=", "data_dir", "/", "\"dev.jsonl\"", "\n", "if", "dev_json_file", ".", "exists", "(", ")", ":", "\n", "            ", "return", "self", ".", "_create_examples", "(", "read_jsonl", "(", "str", "(", "dev_json_file", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "hf_processor", ".", "get_dev_examples", "(", "str", "(", "data_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_test_examples": [[367, 369], ["glue.GLUEv2Processor.hf_processor.get_test_examples", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_test_examples"], ["", "", "def", "get_test_examples", "(", "self", ",", "data_dir", ":", "PathType", ")", ":", "\n", "        ", "return", "self", ".", "hf_processor", ".", "get_test_examples", "(", "str", "(", "data_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labelled_test_examples": [[370, 374], ["pathlib.Path", "glue.GLUEv2Processor.hf_processor._create_examples", "glue.GLUEv2Processor.hf_processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["", "def", "get_labelled_test_examples", "(", "self", ",", "data_dir", ":", "PathType", ")", ":", "\n", "        ", "data_dir", "=", "Path", "(", "data_dir", ")", "\n", "return", "self", ".", "hf_processor", ".", "_create_examples", "(", "\n", "self", ".", "hf_processor", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.tsv\"", ")", ")", ",", "\"dev\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labels": [[376, 378], ["glue.GLUEv2Processor.hf_processor.get_labels"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labels"], ["", "def", "get_labels", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "self", ".", "hf_processor", ".", "get_labels", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor._create_examples": [[379, 410], ["line.get", "str", "examples.append", "line.get", "enumerate", "utils.AugmentedInputExample", "nn_line.get", "nn_line.get", "augmented_examples.append", "utils.InputExampleV2", "nn_line.get"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ":", "Iterable", "[", "Mapping", "[", "str", ",", "Any", "]", "]", ")", "->", "List", "[", "AugmentedInputExample", "]", ":", "\n", "        ", "\"\"\"Creates examples for the training, dev and test sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "text_a", "=", "line", "[", "\"text_a\"", "]", "\n", "text_b", "=", "line", ".", "get", "(", "\"text_b\"", ",", "None", ")", "\n", "guid", "=", "line", "[", "\"guid\"", "]", "\n", "label", "=", "str", "(", "line", ".", "get", "(", "\"label\"", ",", "-", "100", ")", ")", "\n", "\n", "augmented_examples", "=", "[", "]", "\n", "if", "self", ".", "num_augments", "!=", "0", "and", "\"augmented_samples\"", "in", "line", ":", "\n", "                ", "for", "k", ",", "nn_line", "in", "enumerate", "(", "line", "[", "\"augmented_samples\"", "]", ")", ":", "\n", "                    ", "if", "self", ".", "num_augments", ">=", "0", "and", "k", ">=", "self", ".", "num_augments", ":", "\n", "                        ", "break", "\n", "\n", "", "src", "=", "nn_line", ".", "get", "(", "\"src\"", ",", "None", ")", "\n", "src_label", "=", "nn_line", ".", "get", "(", "\"src_label\"", ",", "None", ")", "\n", "nn_guid", "=", "f\"{guid}|aux-{k + 1}\"", "\n", "augmented_examples", ".", "append", "(", "\n", "InputExampleV2", "(", "\n", "guid", "=", "nn_guid", ",", "\n", "text_a", "=", "nn_line", "[", "\"text_a\"", "]", ",", "\n", "text_b", "=", "nn_line", ".", "get", "(", "\"text_b\"", ",", "None", ")", ",", "\n", "src", "=", "src", ",", "\n", "src_label", "=", "src_label", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "examples", ".", "append", "(", "AugmentedInputExample", "(", "guid", ",", "text_a", ",", "text_b", ",", "label", ",", "augmented_examples", ")", ")", "\n", "\n", "", "return", "examples", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.load_metric": [[324, 336], ["datasets.load_metric", "task_name.replace.replace", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.load_metric"], ["def", "load_metric", "(", "task_name", ":", "str", ")", "->", "datasets", ".", "Metric", ":", "\n", "    ", "if", "task_name", "in", "(", "\"sst-5\"", ",", "\"ag_news\"", ",", "\"trec\"", ",", "\"cr\"", ",", "\"imp\"", ")", ":", "\n", "        ", "task_name", "=", "\"sst2\"", "\n", "", "elif", "task_name", "==", "\"mnli-mm\"", ":", "\n", "        ", "task_name", "=", "\"mnli_mismatched\"", "\n", "", "else", ":", "\n", "        ", "task_name", "=", "task_name", ".", "replace", "(", "\"-\"", ",", "\"\"", ")", "\n", "\n", "", "return", "datasets", ".", "load_metric", "(", "\n", "\"glue\"", ",", "\n", "task_name", ",", "\n", "experiment_id", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%d-%m-%Y_%H-%M-%S\"", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.utils.DataSubset.key": [[53, 59], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "key", "(", "self", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "subset", "is", "None", ":", "\n", "            ", "return", "self", ".", "name", "\n", "", "else", ":", "\n", "            ", "return", "f\"{self.name}/{self.subset}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.utils.DataSubset.out_prefix": [[60, 63], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "out_prefix", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "subset", "or", "self", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.utils.DataSubset.args": [[64, 70], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "args", "(", "self", ")", "->", "tuple", ":", "\n", "        ", "if", "self", ".", "subset", "is", "None", ":", "\n", "            ", "return", "(", "self", ".", "name", ",", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "name", ",", "self", ".", "subset", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.utils.DataSubset.of": [[71, 76], ["key.split", "cls", "len"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "of", "(", "cls", ",", "key", ":", "str", ",", "split", ":", "str", ")", ":", "\n", "        ", "sets", "=", "key", ".", "split", "(", "\"/\"", ")", "\n", "assert", "1", "<=", "len", "(", "sets", ")", "<=", "2", ",", "\"invalid key\"", "\n", "return", "cls", "(", "*", "sets", ",", "split", "=", "split", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.utils.read_jsonl": [[22, 26], ["open", "json.loads"], "function", ["None"], ["def", "read_jsonl", "(", "input_file", ":", "str", ")", "->", "List", "[", "Mapping", "[", "str", ",", "Any", "]", "]", ":", "\n", "    ", "\"\"\"Reads a Jsonl file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "        ", "return", "[", "json", ".", "loads", "(", "l", ")", "for", "l", "in", "f", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.read_reviews": [[34, 40], ["open", "line.strip.strip"], "function", ["None"], ["def", "read_reviews", "(", "data_path", ":", "str", ")", "->", "Iterable", "[", "str", "]", ":", "\n", "    ", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "reader", ":", "\n", "        ", "for", "line", "in", "reader", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ":", "\n", "                ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.split_reviews": [[42, 52], ["sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split"], "function", ["None"], ["", "", "", "", "def", "split_reviews", "(", "\n", "pos_reviews", ":", "List", "[", "str", "]", ",", "neg_reviews", ":", "List", "[", "str", "]", ",", "train_ratio", ":", "float", ",", "dev_ratio", ":", "float", "\n", ")", "->", "Tuple", "[", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ",", "...", "]", ":", "\n", "    ", "pos_train", ",", "pos_dev_test", "=", "train_test_split", "(", "pos_reviews", ",", "train_size", "=", "train_ratio", ",", "shuffle", "=", "True", ")", "\n", "neg_train", ",", "neg_dev_test", "=", "train_test_split", "(", "neg_reviews", ",", "train_size", "=", "train_ratio", ",", "shuffle", "=", "True", ")", "\n", "\n", "pos_dev", ",", "pos_test", "=", "train_test_split", "(", "pos_dev_test", ",", "train_size", "=", "dev_ratio", ",", "shuffle", "=", "True", ")", "\n", "neg_dev", ",", "neg_test", "=", "train_test_split", "(", "neg_dev_test", ",", "train_size", "=", "dev_ratio", ",", "shuffle", "=", "True", ")", "\n", "\n", "return", "(", "pos_train", ",", "neg_train", ")", ",", "(", "pos_dev", ",", "neg_dev", ")", ",", "(", "pos_test", ",", "neg_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.combine": [[54, 60], ["dataset.extend", "numpy.random.shuffle"], "function", ["None"], ["", "def", "combine", "(", "pos_data", ":", "List", "[", "str", "]", ",", "neg_data", ":", "List", "[", "str", "]", ")", "->", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ":", "\n", "    ", "dataset", "=", "[", "(", "review", ",", "\"positive\"", ")", "for", "review", "in", "pos_data", "]", "\n", "dataset", ".", "extend", "(", "[", "(", "review", ",", "\"negative\"", ")", "for", "review", "in", "neg_data", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "dataset", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.export_jsonl": [[62, 71], ["out_path.open", "enumerate", "writer.write", "str", "json.dumps"], "function", ["None"], ["", "def", "export_jsonl", "(", "dataset", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "out_path", ":", "Path", ")", ":", "\n", "    ", "with", "out_path", ".", "open", "(", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "for", "i", ",", "(", "text", ",", "label", ")", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "data", "=", "{", "\n", "\"guid\"", ":", "str", "(", "i", "+", "1", ")", ",", "\n", "\"text_a\"", ":", "text", ",", "\n", "\"label\"", ":", "label", ",", "\n", "}", "\n", "writer", ".", "write", "(", "json", ".", "dumps", "(", "data", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.export_tsv": [[73, 79], ["out_path.open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow"], "function", ["None"], ["", "", "", "def", "export_tsv", "(", "dataset", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ",", "out_path", ":", "Path", ")", ":", "\n", "    ", "with", "out_path", ".", "open", "(", "\"w\"", ",", "newline", "=", "\"\"", ")", "as", "out_file", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "out_file", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "writer", ".", "writerow", "(", "(", "\"sentence\"", ",", "\"label\"", ")", ")", "\n", "for", "text", ",", "label", "in", "dataset", ":", "\n", "            ", "writer", ".", "writerow", "(", "(", "text", ",", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.main": [[81, 137], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "list", "list", "logger.info", "output_dir.mkdir", "cr.split_reviews", "zip", "logger.info", "set", "set", "pathlib.Path", "logger.info", "cr.combine", "cr.export_tsv", "cr.read_reviews", "cr.read_reviews", "len", "len", "cr.export_jsonl", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.split_reviews", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.combine", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.export_tsv", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.read_reviews", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.cr.read_reviews", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.export_jsonl"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pos_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path of the positive review file.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--neg_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path of the negative review file.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path of the directory where the outputs will be saved.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_ratio\"", ",", "type", "=", "float", ",", "default", "=", "0.66", ",", "help", "=", "\"Split ratio between train and dev/test\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_ratio\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"Split ratio between dev and test\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "pos_reviews", "=", "list", "(", "set", "(", "read_reviews", "(", "args", ".", "pos_file", ")", ")", ")", "\n", "neg_reviews", "=", "list", "(", "set", "(", "read_reviews", "(", "args", ".", "neg_file", ")", ")", ")", "\n", "logger", ".", "info", "(", "f\"#pos {len(pos_reviews)} | #neg {len(neg_reviews)} -> {len(pos_reviews) + len(neg_reviews)}\"", ")", "\n", "\n", "if", "args", ".", "output_dir", "is", "None", ":", "\n", "        ", "args", ".", "output_dir", "=", "\".\"", "\n", "\n", "", "output_dir", "=", "Path", "(", "args", ".", "output_dir", ")", "/", "\"CR\"", "\n", "output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "split_data", "=", "split_reviews", "(", "pos_reviews", ",", "neg_reviews", ",", "args", ".", "train_ratio", ",", "args", ".", "dev_ratio", ")", "\n", "splits", "=", "(", "\"train\"", ",", "\"dev\"", ",", "\"test\"", ")", "\n", "\n", "for", "mode", ",", "data", "in", "zip", "(", "splits", ",", "split_data", ")", ":", "\n", "        ", "pos_data", ",", "neg_data", "=", "data", "\n", "total_size", "=", "len", "(", "pos_data", ")", "+", "len", "(", "neg_data", ")", "\n", "logger", ".", "info", "(", "\n", "f\"{mode}: #pos {len(pos_data)} ({100 * len(pos_data) / total_size:.1f}%) | \"", "\n", "f\"#neg {len(neg_data)} ({100 * len(neg_data) / total_size:.1f}%) -> {total_size}\"", "\n", ")", "\n", "dataset", "=", "combine", "(", "pos_data", ",", "neg_data", ")", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "export_jsonl", "(", "dataset", ",", "output_dir", "/", "f\"{mode}.jsonl\"", ")", "\n", "\n", "", "export_tsv", "(", "dataset", ",", "output_dir", "/", "f\"{mode}.tsv\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Done!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5._download": [[40, 48], ["logger.info", "os.path.join", "urllib.request.urlretrieve"], "function", ["None"], ["def", "_download", "(", "split", ":", "str", ",", "data_dir", ":", "str", ")", "->", "str", ":", "\n", "    ", "logger", ".", "info", "(", "f\"Downloading {split}...\"", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.txt\"", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "SPLIT_URLS", "[", "split", "]", ",", "\n", "output_file", ",", "\n", ")", "\n", "return", "output_file", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5._normalize": [[50, 52], ["text.replace().replace", "text.replace"], "function", ["None"], ["", "def", "_normalize", "(", "text", ":", "str", ")", "->", "str", ":", "\n", "    ", "return", "text", ".", "replace", "(", "\"-lrb-\"", ",", "\"(\"", ")", ".", "replace", "(", "\"-rrb-\"", ",", "\")\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5.read_original_file": [[54, 61], ["data_path.open", "line.index", "int", "line[].strip", "sst5._normalize"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5._normalize"], ["", "def", "read_original_file", "(", "data_path", ":", "Path", ")", "->", "Iterable", "[", "Tuple", "[", "str", ",", "int", "]", "]", ":", "\n", "    ", "with", "data_path", ".", "open", "(", "\"r\"", ")", "as", "reader", ":", "\n", "        ", "for", "line", "in", "reader", ":", "\n", "            ", "space_index", "=", "line", ".", "index", "(", "\" \"", ")", "\n", "label", "=", "int", "(", "line", "[", ":", "space_index", "]", ")", "\n", "text", "=", "line", "[", "space_index", "+", "1", ":", "]", ".", "strip", "(", ")", "\n", "yield", "_normalize", "(", "text", ")", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5.export_jsonl": [[63, 72], ["out_path.open", "enumerate", "sst5.read_original_file", "writer.write", "str", "json.dumps"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5.read_original_file"], ["", "", "", "def", "export_jsonl", "(", "data_path", ":", "Path", ",", "out_path", ":", "Path", ")", ":", "\n", "    ", "with", "out_path", ".", "open", "(", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "for", "i", ",", "(", "text", ",", "label", ")", "in", "enumerate", "(", "read_original_file", "(", "data_path", ")", ")", ":", "\n", "            ", "data", "=", "{", "\n", "\"guid\"", ":", "str", "(", "i", "+", "1", ")", ",", "\n", "\"text_a\"", ":", "text", ",", "\n", "\"label\"", ":", "label", ",", "\n", "}", "\n", "writer", ".", "write", "(", "json", ".", "dumps", "(", "data", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5.export_tsv": [[74, 80], ["out_path.open", "csv.writer", "csv.writer.writerow", "sst5.read_original_file", "csv.writer.writerow"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5.read_original_file"], ["", "", "", "def", "export_tsv", "(", "data_path", ":", "Path", ",", "out_path", ":", "Path", ")", ":", "\n", "    ", "with", "out_path", ".", "open", "(", "\"w\"", ",", "newline", "=", "\"\"", ")", "as", "out_file", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "out_file", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "writer", ".", "writerow", "(", "(", "\"sentence\"", ",", "\"label\"", ")", ")", "\n", "for", "text", ",", "label", "in", "read_original_file", "(", "data_path", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "(", "text", ",", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5.main": [[82, 110], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "pathlib.Path.mkdir", "original_dir.mkdir", "SPLIT_URLS.keys", "logger.info", "pathlib.Path", "pathlib.Path", "pathlib.Path", "sst5.export_tsv", "sst5._download", "sst5.export_jsonl", "str"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.export_tsv", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.sst5._download", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.export_jsonl"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path of the directory where the outputs will be saved.\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "output_dir", "is", "None", ":", "\n", "        ", "output_dir", "=", "Path", "(", "\"./SST-5\"", ")", "\n", "", "else", ":", "\n", "        ", "output_dir", "=", "Path", "(", "args", ".", "output_dir", ")", "\n", "", "output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "original_dir", "=", "output_dir", "/", "\"original\"", "\n", "original_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "for", "split", "in", "SPLIT_URLS", ".", "keys", "(", ")", ":", "\n", "        ", "original_file", "=", "Path", "(", "_download", "(", "split", ",", "str", "(", "original_dir", ")", ")", ")", "\n", "if", "split", "==", "\"train\"", ":", "\n", "            ", "export_jsonl", "(", "original_file", ",", "output_dir", "/", "f\"{split}.jsonl\"", ")", "\n", "", "export_tsv", "(", "original_file", ",", "output_dir", "/", "f\"{split}.tsv\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Done!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.read_data": [[31, 41], ["open", "csv.reader", "next", "enumerate", "len", "content.strip().strip", "content.strip"], "function", ["None"], ["def", "read_data", "(", "data_path", ":", "str", ")", "->", "Iterable", "[", "Tuple", "[", "int", ",", "str", ",", "int", "]", "]", ":", "\n", "    ", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "doublequote", "=", "True", ")", "\n", "next", "(", "reader", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "            ", "if", "len", "(", "row", ")", "<", "5", ":", "\n", "                ", "label", ",", "content", "=", "row", "[", "0", "]", ",", "row", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "label", ",", "content", "=", "row", "[", "1", "]", ",", "row", "[", "3", "]", "\n", "", "yield", "i", "+", "1", ",", "content", ".", "strip", "(", ")", ".", "strip", "(", "'\"'", ")", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.export_jsonl": [[43, 52], ["out_path.open", "writer.write", "str", "json.dumps"], "function", ["None"], ["", "", "", "def", "export_jsonl", "(", "dataset", ":", "List", "[", "Tuple", "[", "int", ",", "str", ",", "int", "]", "]", ",", "out_path", ":", "Path", ")", ":", "\n", "    ", "with", "out_path", ".", "open", "(", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "for", "id", ",", "text", ",", "label", "in", "dataset", ":", "\n", "            ", "data", "=", "{", "\n", "\"guid\"", ":", "str", "(", "id", ")", ",", "\n", "\"text_a\"", ":", "text", ",", "\n", "\"label\"", ":", "label", ",", "\n", "}", "\n", "writer", ".", "write", "(", "json", ".", "dumps", "(", "data", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.export_tsv": [[54, 60], ["out_path.open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow"], "function", ["None"], ["", "", "", "def", "export_tsv", "(", "dataset", ":", "List", "[", "Tuple", "[", "int", ",", "str", ",", "int", "]", "]", ",", "out_path", ":", "Path", ")", ":", "\n", "    ", "with", "out_path", ".", "open", "(", "\"w\"", ",", "newline", "=", "\"\"", ")", "as", "out_file", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "out_file", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "writer", ".", "writerow", "(", "(", "\"sentence\"", ",", "\"label\"", ")", ")", "\n", "for", "_", ",", "text", ",", "label", "in", "dataset", ":", "\n", "            ", "writer", ".", "writerow", "(", "(", "text", ",", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.main": [[62, 103], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "list", "logger.info", "output_dir.mkdir", "imp.export_tsv", "logger.info", "imp.read_data", "pathlib.Path", "imp.export_jsonl", "len"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.export_tsv", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.read_data", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.imp.export_jsonl"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path of the positive review file.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mode\"", ",", "\n", "default", "=", "None", ",", "\n", "required", "=", "True", ",", "\n", "choices", "=", "(", "\"train\"", ",", "\"test\"", ",", "\"dev\"", ")", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Split mode\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path of the directory where the outputs will be saved.\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "data", "=", "list", "(", "read_data", "(", "args", ".", "data_file", ")", ")", "\n", "logger", ".", "info", "(", "f\"#data {len(data)}\"", ")", "\n", "\n", "if", "args", ".", "output_dir", "is", "None", ":", "\n", "        ", "args", ".", "output_dir", "=", "\".\"", "\n", "\n", "", "output_dir", "=", "Path", "(", "args", ".", "output_dir", ")", "/", "\"IMP\"", "\n", "output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "args", ".", "mode", "==", "\"train\"", ":", "\n", "        ", "export_jsonl", "(", "data", ",", "output_dir", "/", "f\"{args.mode}.jsonl\"", ")", "\n", "\n", "", "export_tsv", "(", "data", ",", "output_dir", "/", "f\"{args.mode}.tsv\"", ")", "\n", "\n", "logger", ".", "info", "(", "\"Done!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf._prune": [[34, 43], ["ditem.items", "isinstance"], "function", ["None"], ["def", "_prune", "(", "ditem", ")", ":", "\n", "    ", "exp", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "ditem", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "in", "(", "\"guid\"", ",", "\"text_a\"", ",", "\"text_b\"", ")", ":", "\n", "            ", "exp", "[", "k", "]", "=", "v", "\n", "", "elif", "k", "==", "\"label\"", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "str", ")", "or", "v", ">=", "0", ":", "\n", "                ", "exp", "[", "k", "]", "=", "v", "\n", "", "", "", "return", "exp", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf._export_jsonl": [[45, 49], ["out_path.open", "range", "len", "writer.write", "json.dumps", "hf._prune"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf._prune"], ["", "def", "_export_jsonl", "(", "dataset", ",", "out_path", ":", "Path", ")", ":", "\n", "    ", "with", "out_path", ".", "open", "(", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "_prune", "(", "dataset", "[", "i", "]", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf._export_tsv": [[51, 58], ["out_path.open", "csv.writer", "csv.writer.writerow", "range", "len", "csv.writer.writerow", "dataset[].get"], "function", ["None"], ["", "", "", "def", "_export_tsv", "(", "dataset", ",", "has_two_cols", ":", "bool", ",", "out_path", ":", "Path", ")", ":", "\n", "    ", "header", "=", "(", "\"guid\"", ",", "\"label\"", ",", "\"text_a\"", ",", "\"text_b\"", ")", "if", "has_two_cols", "else", "(", "\"guid\"", ",", "\"label\"", ",", "\"text_a\"", ")", "\n", "with", "out_path", ".", "open", "(", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ",", "newline", "=", "\"\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "writer", ".", "writerow", "(", "header", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "dataset", "[", "i", "]", ".", "get", "(", "col", ",", "None", ")", "for", "col", "in", "header", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf.to_hf_dict": [[74, 93], ["dict", "LABEL_COLUMNS.get", "convert_fn", "str", "item.get"], "function", ["None"], ["def", "to_hf_dict", "(", "\n", "dataset_name", ":", "str", ",", "\n", "item", ":", "Mapping", "[", "str", ",", "Any", "]", ",", "\n", "idx", ":", "int", "=", "0", ",", "\n", "convert_fn", "=", "None", ",", "\n", ")", "->", "Mapping", "[", "str", ",", "Any", "]", ":", "\n", "    ", "item_dict", "=", "dict", "(", "\n", "guid", "=", "str", "(", "item", ".", "get", "(", "\"idx\"", ",", "idx", ")", "+", "1", ")", ",", "\n", "text_a", "=", "item", "[", "TEXT_COLUMNS", "[", "dataset_name", "]", "]", ",", "\n", ")", "\n", "\n", "label_col", "=", "LABEL_COLUMNS", ".", "get", "(", "dataset_name", ",", "\"label\"", ")", "\n", "if", "convert_fn", "is", "not", "None", ":", "\n", "        ", "label", "=", "convert_fn", "(", "item", "[", "label_col", "]", ")", "\n", "", "else", ":", "\n", "        ", "label", "=", "item", "[", "label_col", "]", "\n", "", "item_dict", "[", "\"label\"", "]", "=", "label", "\n", "\n", "return", "item_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf.main": [[95, 170], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logger.info", "datasets.load_dataset", "pathlib.Path", "pathlib.Path.mkdir", "logger.info", "dataset_fold.map.map", "parser.parse_args.dataset.split", "logger.warning", "dataset_fold.map.train_test_split", "hf._export_tsv", "hf._export_tsv", "hf._export_jsonl", "LABEL_COLUMNS.get", "hf.to_hf_dict", "getattr", "LABEL_TYPES.get", "SPLIT_NAMES.get", "SPLIT_NAMES.get"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf._export_tsv", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf._export_tsv", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf._export_jsonl", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.scripts.hf.to_hf_dict"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"dataset\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Name of dataset based on Huggingface's datasets package.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path of the directory where the outputs will be saved.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_format\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"jsonl\"", ",", "\n", "choices", "=", "(", "\"jsonl\"", ",", "\"tsv\"", ")", ",", "\n", "help", "=", "\"If provided, dataset would be split based on this size\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dev_split\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"If provided, train dataset would be split based on this size\"", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "logger", ".", "info", "(", "f\"loading dataset: '{args.dataset}'\"", ")", "\n", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\n", "*", "args", ".", "dataset", ".", "split", "(", "\"/\"", ")", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "output_dir", "=", "Path", "(", "args", ".", "output_dir", ")", "\n", "output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "SPLIT_NAMES", "=", "{", "\n", "\"validation\"", ":", "\"dev\"", "\n", "}", "\n", "\n", "for", "split", "in", "(", "\"train\"", ",", "\"validation\"", ",", "\"test\"", ")", ":", "\n", "        ", "if", "split", "not", "in", "dataset", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "split", "==", "\"validation\"", "and", "args", ".", "dev_split", ">", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Validation set ignored because it is taken from training set\"", ")", "\n", "continue", "\n", "\n", "", "dataset_fold", "=", "dataset", "[", "split", "]", "\n", "label_col", "=", "dataset_fold", ".", "features", "[", "LABEL_COLUMNS", ".", "get", "(", "args", ".", "dataset", ",", "\"label\"", ")", "]", "\n", "dataset_fold", "=", "dataset_fold", ".", "map", "(", "\n", "lambda", "ex", ",", "idx", ":", "to_hf_dict", "(", "args", ".", "dataset", ",", "ex", ",", "idx", ",", "convert_fn", "=", "getattr", "(", "label_col", ",", "LABEL_TYPES", ".", "get", "(", "args", ".", "dataset", ",", "\"\"", ")", ",", "None", ")", ")", ",", "\n", "with_indices", "=", "True", ",", "\n", ")", "\n", "\n", "if", "split", "==", "\"train\"", "and", "args", ".", "dev_split", ">", "0", ":", "\n", "            ", "split_dataset", "=", "dataset_fold", ".", "train_test_split", "(", "test_size", "=", "args", ".", "dev_split", ")", "\n", "dataset_fold", "=", "split_dataset", "[", "\"train\"", "]", "\n", "new_dataset", "=", "split_dataset", "[", "\"test\"", "]", "\n", "_export_tsv", "(", "new_dataset", ",", "False", ",", "output_dir", "/", "\"dev.tsv\"", ")", "\n", "\n", "", "if", "args", ".", "output_format", "==", "\"tsv\"", ":", "\n", "            ", "_export_tsv", "(", "dataset_fold", ",", "False", ",", "output_dir", "/", "f\"{SPLIT_NAMES.get(split, split)}.tsv\"", ")", "\n", "", "else", ":", "\n", "            ", "_export_jsonl", "(", "dataset_fold", ",", "output_dir", "/", "f\"{SPLIT_NAMES.get(split, split)}.jsonl\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Done!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.InputExample.__init__": [[124, 140], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ",", "rand_vec", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n        Args:\n          guid: Unique id for the example.\n          text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n          text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n          label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "rand_vec", "=", "rand_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MNLIDataset.__init__": [[145, 148], ["Combined_KD_bert.MNLIDataset._create_examples", "Combined_KD_bert.MNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MNLIDataset.__len__": [[148, 151], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MNLIDataset._read_tsv": [[152, 160], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MNLIDataset._create_examples": [[161, 188], ["enumerate", "int", "examples.append", "enumerate", "Combined_KD_bert.InputExample", "float", "float", "token.strip", "Combined_KD_bert.MNLIDataset._get_label", "Combined_KD_bert.MNLIDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "rand_vec", "=", "None", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MNLIDataset._get_label": [[189, 191], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'contradiction'", ",", "'neutral'", ",", "'entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MNLIDataset.__getitem__": [[192, 198], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.RTEDataset.__init__": [[203, 206], ["Combined_KD_bert.RTEDataset._create_examples", "Combined_KD_bert.RTEDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.RTEDataset.__len__": [[207, 210], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.RTEDataset._read_tsv": [[211, 219], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.RTEDataset._create_examples": [[220, 247], ["enumerate", "int", "examples.append", "enumerate", "Combined_KD_bert.InputExample", "float", "float", "token.strip", "Combined_KD_bert.RTEDataset._get_label", "Combined_KD_bert.RTEDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.RTEDataset._get_label": [[248, 250], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'entailment'", ",", "'not_entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.RTEDataset.__getitem__": [[251, 257], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QQPDataset.__init__": [[262, 265], ["Combined_KD_bert.QQPDataset._create_examples", "Combined_KD_bert.QQPDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QQPDataset.__len__": [[266, 269], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QQPDataset._read_tsv": [[270, 278], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QQPDataset._create_examples": [[279, 314], ["enumerate", "enumerate", "line[].strip", "line[].strip", "examples.append", "Combined_KD_bert.InputExample", "token.strip", "float", "float", "token.strip", "Combined_KD_bert.QQPDataset._get_label", "Combined_KD_bert.QQPDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"question1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"question2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "try", ":", "\n", "\n", "                ", "guid", "=", "i", "# int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", ".", "strip", "(", ")", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", ".", "strip", "(", ")", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "not", "text_a", "or", "not", "text_b", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "set_type", "==", "\"train\"", ":", "\n", "                    ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                    ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QQPDataset._get_label": [[315, 317], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QQPDataset.__getitem__": [[318, 324], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.WNLIDataset.__init__": [[329, 332], ["Combined_KD_bert.WNLIDataset._create_examples", "Combined_KD_bert.WNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.WNLIDataset.__len__": [[333, 336], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.WNLIDataset._read_tsv": [[337, 345], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.WNLIDataset._create_examples": [[346, 378], ["enumerate", "enumerate", "examples.append", "Combined_KD_bert.InputExample", "token.strip", "float", "float", "token.strip", "Combined_KD_bert.WNLIDataset._get_label", "Combined_KD_bert.WNLIDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "try", ":", "\n", "\n", "                ", "guid", "=", "i", "# int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                    ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                    ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.WNLIDataset._get_label": [[379, 381], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.WNLIDataset.__getitem__": [[382, 388], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.STSBDataset.__init__": [[393, 396], ["Combined_KD_bert.STSBDataset._create_examples", "Combined_KD_bert.STSBDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.STSBDataset.__len__": [[397, 400], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.STSBDataset._read_tsv": [[401, 409], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.STSBDataset._create_examples": [[410, 442], ["enumerate", "enumerate", "examples.append", "float", "float", "Combined_KD_bert.InputExample", "token.strip", "token.strip"], "methods", ["None"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "try", ":", "\n", "\n", "                ", "guid", "=", "i", "# int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                    ", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.STSBDataset._get_label": [[443, 445], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.STSBDataset.__getitem__": [[446, 452], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QNLIDataset.__init__": [[457, 460], ["Combined_KD_bert.QNLIDataset._create_examples", "Combined_KD_bert.QNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QNLIDataset.__len__": [[461, 464], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QNLIDataset._read_tsv": [[465, 473], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QNLIDataset._create_examples": [[474, 501], ["enumerate", "int", "examples.append", "enumerate", "Combined_KD_bert.InputExample", "float", "float", "token.strip", "Combined_KD_bert.QNLIDataset._get_label", "Combined_KD_bert.QNLIDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"question\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QNLIDataset._get_label": [[502, 504], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'entailment'", ",", "'not_entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.QNLIDataset.__getitem__": [[505, 511], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MRPCDataset.__init__": [[516, 519], ["Combined_KD_bert.MRPCDataset._create_examples", "Combined_KD_bert.MRPCDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MRPCDataset.__len__": [[520, 523], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MRPCDataset._read_tsv": [[524, 532], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MRPCDataset._create_examples": [[533, 560], ["enumerate", "int", "examples.append", "Combined_KD_bert.InputExample", "float", "float", "Combined_KD_bert.MRPCDataset._get_label", "Combined_KD_bert.MRPCDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "3", "\n", "sentence2_index", "=", "4", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "# for j, token in enumerate(line):", "\n", "#  if token.strip() == \"question\":", "\n", "#    sentence1_index = j", "\n", "#  elif token.strip() == \"sentence\":", "\n", "#    sentence2_index = j", "\n", "                ", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "0", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "0", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MRPCDataset._get_label": [[561, 563], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MRPCDataset.__getitem__": [[564, 570], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.SST2Dataset.__init__": [[575, 578], ["Combined_KD_bert.SST2Dataset._create_examples", "Combined_KD_bert.SST2Dataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.SST2Dataset.__len__": [[579, 582], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.SST2Dataset._read_tsv": [[583, 591], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.SST2Dataset._create_examples": [[592, 617], ["enumerate", "examples.append", "enumerate", "Combined_KD_bert.InputExample", "float", "float", "token.strip", "Combined_KD_bert.SST2Dataset._get_label", "Combined_KD_bert.SST2Dataset._get_label", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence\"", ":", "\n", "                        ", "sentence_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "i", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ",", "\n", "rand_vec", "=", "torch", ".", "normal", "(", "0", ",", "std_z", ",", "(", "1", ",", "128", ",", "256", ")", ")", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.SST2Dataset._get_label": [[618, 620], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.SST2Dataset.__getitem__": [[621, 627], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.ColaDataset.__init__": [[632, 635], ["Combined_KD_bert.ColaDataset._create_examples", "Combined_KD_bert.ColaDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.ColaDataset.__len__": [[636, 639], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.ColaDataset._read_tsv": [[640, 648], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.ColaDataset._create_examples": [[649, 666], ["enumerate", "examples.append", "Combined_KD_bert.InputExample", "float", "float", "Combined_KD_bert.ColaDataset._get_label", "Combined_KD_bert.ColaDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence_index", "=", "3", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "guid", "=", "i", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.ColaDataset._get_label": [[667, 669], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.ColaDataset.__getitem__": [[670, 676], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MateKD.__init__": [[783, 787], ["torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "args", ",", "config", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "LayerNorm_distilbert", "=", "nn", ".", "LayerNorm", "(", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dp_distilbert", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MateKD.train": [[788, 1153], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model.zero_grad", "generator.zero_grad", "tqdm.tqdm.trange", "Combined_KD_bert.set_seed", "logger.info", "max", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "generator.parameters", "generator.parameters", "amp.initialize", "amp.initialize", "amp.initialize", "len", "logger.info", "logger.info", "int", "tqdm.tqdm.trange", "tqdm.tqdm.trange", "model.train", "generator.train", "print", "enumerate", "Combined_KD_bert.create_collate_fn", "int", "int", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "tuple", "generator", "Combined_KD_bert.gumbel_softmax", "input_ids.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "model.distilbert.embeddings.LayerNorm", "model.distilbert.embeddings.dropout", "tqdm.tqdm.trange.close", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "print", "Combined_KD_bert.MateKD.evaluate", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "masked_permuted.unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "masked_permuted.unsqueeze", "amp.initialize.", "model.distilbert.embeddings.position_embeddings", "model", "transformers.AdamW.zero_grad", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "print", "epoch_iterator.close", "len", "len", "model.named_parameters", "model.named_parameters", "any", "Combined_KD_bert.MateKD.evaluate", "t.to", "amp.initialize.bert.embeddings.word_embeddings", "model.distilbert.embeddings.word_embeddings", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.cross_entropy.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.AdamW.zero_grad", "torch.optim.AdamW.zero_grad", "torch.optim.AdamW.zero_grad", "torch.optim.AdamW.step", "torch.optim.AdamW.step", "torch.optim.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.cross_entropy.item", "Combined_KD_bert.MateKD.evaluate", "Combined_KD_bert.MateKD.items", "transformers.get_linear_schedule_with_warmup.get_lr", "json.dumps", "os.path.join", "shutil.rmtree", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "len", "len", "any", "int", "Combined_KD_bert.MateKD.evaluate", "masked_permuted.unsqueeze", "masked_permuted.unsqueeze", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "generator.parameters", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.cross_entropy.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "torch.optim.AdamW.state_dict", "torch.optim.AdamW.state_dict", "torch.optim.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "Combined_KD_bert.MateKD.evaluate", "Combined_KD_bert.MateKD.evaluate", "amp.initialize.", "model", "model", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "model.parameters", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate"], ["", "def", "train", "(", "self", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "teacher_model", ",", "generator", ",", "tokenizer", ",", "phase", ")", ":", "\n", "\n", "        ", "args", "=", "self", ".", "args", "\n", "global", "BEST_ACCURACY", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_device_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "data", ".", "RandomSampler", "(", "\n", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "data", ".", "distributed", ".", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "data", ".", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "collate_fn", "=", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "128", ")", ")", "\n", "\n", "\n", "if", "phase", "==", "1", ":", "\n", "            ", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "                ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs_phase_1", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "                ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs_phase_1", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "                ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs_phase_2", "=", "args", ".", "max_steps", "//", "(", "\n", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "                ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs_phase_2", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "2138", ",", "# args.warmup_steps,", "\n", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "gen_optimizer", "=", "AdamW", "(", "generator", ".", "parameters", "(", ")", ",", "lr", "=", "5e-7", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "gen_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "gen_optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "gen_pre_optimizer", "=", "AdamW", "(", "generator", ".", "parameters", "(", ")", ",", "lr", "=", "5e-6", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "gen_pre_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "gen_pre_optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "                ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "generator", ",", "[", "gen_optimizer", ",", "gen_pre_optimizer", "]", "=", "amp", ".", "initialize", "(", "generator", ",", "\n", "[", "gen_optimizer", ",", "gen_pre_optimizer", "]", ",", "\n", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "teacher_model", "=", "amp", ".", "initialize", "(", "teacher_model", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "if", "phase", "==", "1", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Num Epochs in phase 1 = %d\"", ",", "args", ".", "num_train_epochs_phase_1", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Num Epochs in phase 2 = %d\"", ",", "args", ".", "num_train_epochs_phase_2", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_device_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "steps_train", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "max_met", "=", "-", "1", "\n", "max_met_step", "=", "-", "1", "\n", "model", ".", "zero_grad", "(", ")", "\n", "generator", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "\n", "n_generator_iter", "=", "10", "\n", "n_student_iter", "=", "100", "\n", "\n", "idx_pseudo", "=", "0", "\n", "n_repeat_batch", "=", "n_generator_iter", "+", "n_student_iter", "\n", "\n", "logger", ".", "info", "(", "\"  Pre-train Generator\"", ")", "\n", "\n", "if", "phase", "==", "1", ":", "\n", "            ", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs_phase_1", ")", ",", "desc", "=", "\"Epoch\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "temp", "=", "1", "\n", "", "else", ":", "\n", "            ", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs_phase_2", ")", ",", "desc", "=", "\"Epoch\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "\n", "\n", "", "for", "i", "in", "train_iterator", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "generator", ".", "train", "(", ")", "\n", "# If the phase is 1, then we need to increment the temperature after every (num_epochs_phase_1/max_temp) epochs", "\n", "# For e.g. num_epochs_phase_1 = 20, max_temp = 10, then we increment temperature value after every 2 epochs", "\n", "if", "phase", "==", "1", ":", "\n", "                ", "if", "i", "%", "int", "(", "args", ".", "num_train_epochs_phase_1", "/", "args", ".", "max_temperature", ")", "==", "0", "and", "i", ">", "0", ":", "\n", "                    ", "temp", "+=", "1", "\n", "print", "(", "f\"\\n\\ntemperature is {temp}\"", ")", "\n", "\n", "# Determine the metric based on task, then run evaluation and save model if better than current best result", "\n", "", "", "if", "args", ".", "task_name", "==", "'sts-b'", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'corr'", "]", "\n", "", "elif", "args", ".", "task_name", "==", "'cola'", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'mcc'", "]", "\n", "", "elif", "args", ".", "task_name", "==", "'mrpc'", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'f1'", "]", "\n", "", "elif", "args", ".", "task_name", "==", "'mnli'", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'mnli/acc'", "]", "\n", "", "else", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'acc'", "]", "\n", "", "print", "(", "\"Intermediate evaluate: \"", ",", "intermediate_res", ")", "\n", "if", "BEST_ACCURACY", "<", "intermediate_res", ":", "\n", "                ", "BEST_ACCURACY", "=", "intermediate_res", "\n", "torch", ".", "save", "(", "model", ",", "args", ".", "output_dir", "+", "\"/BestModel.pt\"", ")", "\n", "print", "(", "\"Best Model Saved!\"", ")", "\n", "\n", "", "epoch_iterator", "=", "train_dataloader", "\n", "# print(\"Intermediate evaluate: \", self.evaluate(eval_dataset, model, tokenizer))", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "                ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                    ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "\n", "", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "input_ids", "=", "batch", "[", "1", "]", "\n", "attention_mask", "=", "batch", "[", "2", "]", "\n", "labels", "=", "batch", "[", "3", "]", "\n", "token_type_ids", "=", "batch", "[", "7", "]", "\n", "input_ids_permuted", "=", "batch", "[", "4", "]", "\n", "masked_permuted", "=", "batch", "[", "5", "]", "\n", "\n", "# Generator training", "\n", "\n", "outputs", "=", "generator", "(", "input_ids", "=", "input_ids_permuted", ",", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ")", "\n", "\n", "prediction_scores", "=", "outputs", "[", "0", "]", "\n", "\n", "prediction_scores", "=", "gumbel_softmax", "(", "prediction_scores", ",", "1.0", ")", "\n", "\n", "teacher_inp", "=", "torch", ".", "matmul", "(", "prediction_scores", ",", "\n", "teacher_model", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "*", "masked_permuted", ".", "unsqueeze", "(", "\n", "-", "1", ")", "\n", "student_inp", "=", "torch", ".", "matmul", "(", "prediction_scores", ",", "\n", "model", ".", "distilbert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "*", "masked_permuted", ".", "unsqueeze", "(", "\n", "-", "1", ")", "\n", "\n", "teacher_inp", "=", "teacher_inp", "+", "(", "teacher_model", ".", "bert", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "*", "(", "\n", "1", "-", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", "\n", "student_inp", "=", "student_inp", "+", "(", "model", ".", "distilbert", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "*", "(", "\n", "1", "-", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", "\n", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "inputs_embeds", "=", "teacher_inp", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "\n", "0", "]", "\n", "\n", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "# (max_seq_length)", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "# (bs, max_seq_length)", "\n", "student_inp", "=", "student_inp", "+", "model", ".", "distilbert", ".", "embeddings", ".", "position_embeddings", "(", "position_ids", ")", "\n", "\n", "student_inp", "=", "model", ".", "distilbert", ".", "embeddings", ".", "LayerNorm", "(", "student_inp", ")", "# (bs, max_seq_length, dim)", "\n", "student_inp", "=", "model", ".", "distilbert", ".", "embeddings", ".", "dropout", "(", "student_inp", ")", "# (bs, max_seq_length, dim)", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "inputs_embeds", "=", "student_inp", ")", "[", "0", "]", "\n", "\n", "\n", "# Generator training loss", "\n", "if", "idx_pseudo", "%", "n_repeat_batch", "<", "n_generator_iter", ":", "\n", "\n", "                    ", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                        ", "loss", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", ")", "\n", "", "else", ":", "\n", "                        ", "loss", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", ")", "\n", "\n", "\n", "", "loss", "=", "-", "loss", "\n", "\n", "gen_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "gen_optimizer", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "gen_optimizer", ")", ",", "5", ")", "\n", "", "else", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "generator", ".", "parameters", "(", ")", ",", "5", ")", "\n", "\n", "", "gen_optimizer", ".", "step", "(", ")", "\n", "gen_scheduler", ".", "step", "(", ")", "\n", "\n", "# Student training", "\n", "\n", "", "elif", "idx_pseudo", "%", "n_repeat_batch", "<", "(", "n_generator_iter", "+", "n_student_iter", ")", ":", "\n", "\n", "                    ", "if", "phase", "==", "1", ":", "\n", "# In phase 1, student will only learn from teachers", "\n", "\n", "                        ", "loss_aug", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", "*", "(", "temp", "/", "args", ".", "max_temperature", ")", ")", "\n", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ")", "[", "0", "]", "\n", "\n", "loss_org", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", "*", "(", "temp", "/", "args", ".", "max_temperature", ")", ")", "\n", "loss_good", "=", "torch", ".", "mean", "(", "-", "torch", ".", "sum", "(", "F", ".", "log_softmax", "(", "student_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", "*", "labels", ",", "dim", "=", "-", "1", ")", ")", "\n", "loss", "=", "loss_good", "*", "(", "1", "/", "2", ")", "+", "(", "1", "/", "2", ")", "*", "loss_org", "\n", "\n", "", "else", ":", "\n", "# In phase 2, student will learn from golden label", "\n", "                        ", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ")", "[", "0", "]", "\n", "\n", "if", "args", ".", "task_name", "==", "'sts-b'", ":", "\n", "                            ", "loss", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "labels", ")", "\n", "", "else", ":", "\n", "                            ", "loss", "=", "F", ".", "cross_entropy", "(", "student_logits", ",", "torch", ".", "argmax", "(", "labels", ",", "dim", "=", "1", ")", ")", "\n", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "5", ")", "\n", "", "else", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "5", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "steps_train", "+=", "1", "\n", "\n", "", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logs", "=", "{", "}", "\n", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "\n", "if", "BEST_ACCURACY", "<", "value", ":", "\n", "                                ", "BEST_ACCURACY", "=", "value", "\n", "torch", ".", "save", "(", "model", ",", "args", ".", "output_dir", "+", "\"/BestModel.pt\"", ")", "\n", "print", "(", "\"Best Model Saved!\"", ")", "\n", "\n", "", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "tr_loss", "/", "steps_train", "if", "steps_train", ">", "0", "else", "0", "# (tr_loss - logging_loss) / args.logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "\n", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "acc_tasks", "=", "[", "'sst-2'", ",", "'rte'", ",", "'qnli'", ",", "'qqp'", ",", "'mrpc'", ",", "'wnli'", "]", "\n", "mnliacc_tasks", "=", "[", "'mnli'", "]", "\n", "mnlimmacc_tasks", "=", "[", "'mnli-mm'", "]", "\n", "mcc_tasks", "=", "[", "'cola'", "]", "\n", "accf1_tasks", "=", "[", "]", "# ['qqp', 'mrpc']", "\n", "corr_tasks", "=", "[", "'sts-b'", "]", "\n", "current_met", "=", "0", "\n", "\n", "if", "args", ".", "task_name", "in", "acc_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_acc\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mnliacc_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_mnli/acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mnli/acc\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_mnli/acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mnlimmacc_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mcc_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_mcc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mcc\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_mcc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "accf1_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_acc_and_f1\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_acc_and_f1\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_acc_and_f1\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "corr_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_corr\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_corr\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_corr\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "\n", "", "", "logs", "[", "\"eval_met_max\"", "]", "=", "max_met", "\n", "logs", "[", "\"eval_met_max_step\"", "]", "=", "max_met_step", "\n", "\n", "print", "(", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "global_step", "}", "}", ")", ")", "\n", "# Restore best model", "\n", "if", "current_met", "==", "max_met", ":", "\n", "                        ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"best\"", ")", "\n", "shutil", ".", "rmtree", "(", "output_dir", ",", "ignore_errors", "=", "True", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "idx_pseudo", "+=", "1", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                    ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.MateKD.evaluate": [[1154, 1231], ["zip", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "transformers.glue_compute_metrics", "results.update", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "torch.nn.DataParallel.eval", "torch.nn.DataParallel.eval", "tuple", "numpy.argmax", "numpy.argmax", "open", "logger.info", "sorted", "os.path.exists", "Combined_KD_bert.create_collate_fn", "isinstance", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.mean.mean().item", "torch.mean.mean().item", "torch.mean.mean().item", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "transformers.glue_compute_metrics.keys", "logger.info", "writer.write", "t.to", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy", "str", "logits.squeeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean.mean", "torch.mean.mean", "torch.mean.mean", "logits.detach().cpu", "labels.detach().cpu", "logits.detach().cpu", "labels.detach().cpu", "str", "logits.detach", "labels.detach", "logits.detach", "labels.detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn"], ["", "def", "evaluate", "(", "self", ",", "eval_dataset", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "        ", "args", "=", "self", ".", "args", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "# (\"mnli\", \"mnli-mm\") if args.task_name == \"mnli\" else (args.task_name,)", "\n", "eval_outputs_dirs", "=", "(", "\n", "args", ".", "output_dir", ",", ")", "# (args.output_dir, args.output_dir + \"-MM\") if args.task_name == \"mnli\" else (args.output_dir,)", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "# eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)", "\n", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_device_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "data", ".", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "data", ".", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "\n", "collate_fn", "=", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "128", ")", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "# for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "input_ids", "=", "batch", "[", "1", "]", "\n", "attention_mask", "=", "batch", "[", "2", "]", "\n", "labels", "=", "batch", "[", "3", "]", "\n", "token_type_ids", "=", "batch", "[", "7", "]", "\n", "\n", "logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ")", "[", "0", "]", "\n", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                        ", "tmp_eval_loss", "=", "F", ".", "mse_loss", "(", "logits", ".", "squeeze", "(", "-", "1", ")", ",", "labels", ")", "\n", "", "else", ":", "\n", "                        ", "log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "per_example_loss", "=", "-", "torch", ".", "sum", "(", "labels", "*", "log_probs", ",", "dim", "=", "-", "1", ")", "\n", "tmp_eval_loss", "=", "torch", ".", "mean", "(", "per_example_loss", ")", "\n", "\n", "", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                    ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                    ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "out_label_ids", "=", "np", ".", "argmax", "(", "out_label_ids", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "", "result", "=", "compute_metrics", "(", "eval_task", ",", "preds", ",", "out_label_ids", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.set_seed": [[73, 79], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.mask_tokens": [[678, 700], ["inputs.clone", "torch.full", "torch.full", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "ValueError", "tokenizer.get_special_tokens_mask", "torch.tensor", "torch.tensor", "torch.tensor", "inputs.clone.eq", "torch.full.masked_fill_", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool.float", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.full", "torch.full", "torch.full"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "mlm_probability", ")", ":", "\n", "    ", "if", "tokenizer", ".", "mask_token", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"", "\n", ")", "\n", "\n", "", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "mlm_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "\n", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "1.0", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "return", "inputs", ",", "labels", ",", "masked_indices", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.create_collate_fn": [[702, 732], ["tokenizer.batch_encode_plus", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "Combined_KD_bert.mask_tokens", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.clone"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.mask_tokens"], ["", "def", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "max_length", ")", ":", "\n", "    ", "def", "collate_fn", "(", "data", ")", ":", "\n", "        ", "text", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "[", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ")", "if", "example", ".", "text_b", "is", "not", "None", "else", "example", ".", "text_a", "for", "example", "in", "data", "]", ",", "\n", "max_length", "=", "max_length", ",", "truncation", "=", "True", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", ")", "\n", "\n", "input_ids", "=", "text", "[", "'input_ids'", "]", "\n", "\n", "token_type_ids", "=", "text", "[", "'token_type_ids'", "]", "\n", "attention_mask", "=", "text", "[", "'attention_mask'", "]", "\n", "\n", "guids", "=", "[", "example", ".", "guid", "for", "example", "in", "data", "]", "\n", "\n", "labels", "=", "[", "example", ".", "label", "for", "example", "in", "data", "]", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", ")", "\n", "token_type_ids", "=", "torch", ".", "tensor", "(", "token_type_ids", ")", "\n", "attention_mask", "=", "torch", ".", "tensor", "(", "attention_mask", ")", "\n", "\n", "input_ids_permuted", ",", "labels_permuted", ",", "mask_permuted", "=", "mask_tokens", "(", "input_ids", ".", "clone", "(", ")", ",", "tokenizer", ",", "args", ".", "p_value", ")", "\n", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ")", "\n", "\n", "guids", "=", "torch", ".", "tensor", "(", "guids", ")", "\n", "\n", "return", "guids", ",", "input_ids", ",", "attention_mask", ",", "labels", ",", "input_ids_permuted", ",", "mask_permuted", ",", "labels_permuted", ",", "token_type_ids", "\n", "\n", "", "return", "collate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.freeze_model": [[734, 737], ["model.parameters"], "function", ["None"], ["", "def", "freeze_model", "(", "model", ",", "freeze", ")", ":", "\n", "    ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "not", "freeze", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.sample_gumbel": [[742, 745], ["torch.rand", "torch.rand", "torch.rand", "torch.autograd.Variable", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], ["def", "sample_gumbel", "(", "shape", ",", "eps", "=", "1e-20", ")", ":", "\n", "    ", "U", "=", "torch", ".", "rand", "(", "shape", ",", "device", "=", "\"cuda\"", ")", "\n", "return", "-", "Variable", "(", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "eps", ")", "+", "eps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.gumbel_softmax_sample": [[747, 750], ["torch.softmax", "torch.log_softmax", "Combined_KD_bert.sample_gumbel", "logits.size"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.sample_gumbel"], ["", "def", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", ":", "\n", "    ", "y", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "+", "sample_gumbel", "(", "logits", ".", "size", "(", ")", ")", "\n", "return", "F", ".", "softmax", "(", "y", "/", "temperature", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.gumbel_softmax": [[752, 764], ["Combined_KD_bert.gumbel_softmax_sample", "gumbel_softmax_sample.size", "gumbel_softmax_sample.max", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "y_hard.view.scatter_", "y_hard.view.view", "ind.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax_sample"], ["", "def", "gumbel_softmax", "(", "logits", ",", "temperature", ")", ":", "\n", "    ", "\"\"\"\n    input: [*, n_class]\n    return: [*, n_class] an one-hot vector\n    \"\"\"", "\n", "y", "=", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", "\n", "shape", "=", "y", ".", "size", "(", ")", "\n", "_", ",", "ind", "=", "y", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "y_hard", "=", "torch", ".", "zeros_like", "(", "y", ")", ".", "view", "(", "-", "1", ",", "shape", "[", "-", "1", "]", ")", "\n", "y_hard", ".", "scatter_", "(", "1", ",", "ind", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "y_hard", "=", "y_hard", ".", "view", "(", "*", "shape", ")", "\n", "return", "(", "y_hard", "-", "y", ")", ".", "detach", "(", ")", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.divergence": [[772, 777], ["torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.log_softmax", "torch.softmax"], "function", ["None"], ["def", "divergence", "(", "student_logits", ",", "teacher_logits", ")", ":", "\n", "    ", "divergence", "=", "-", "torch", ".", "sum", "(", "\n", "F", ".", "log_softmax", "(", "student_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", "*", "F", ".", "softmax", "(", "teacher_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "dim", "=", "-", "1", ")", "# forward KL", "\n", "return", "torch", ".", "mean", "(", "divergence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD_bert.main": [[1233, 1449], ["transformers.HfArgumentParser", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.parse_args_into_dataclasses", "argparse.Namespace", "logging.basicConfig", "logger.warning", "Combined_KD_bert.set_seed", "argparse.Namespace.task_name.lower", "processor.get_labels", "len", "print", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.BertTokenizer.from_pretrained", "transformers.BertForMaskedLM.from_pretrained", "torch.load.to", "AutoModelForSequenceClassification.from_pretrained.to", "BertForMaskedLM.from_pretrained.to", "logger.info", "Combined_KD_bert.freeze_model", "AutoModelForSequenceClassification.from_pretrained.eval", "print", "sum", "print", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.device", "torch.device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "transformers.AutoConfig.from_pretrained", "transformers.AutoConfig.from_pretrained", "logger.info", "torch.Linear", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "Combined_KD_bert.MateKD", "print", "print", "print", "Combined_KD_bert.MateKD.train", "logger.info", "print", "print", "print", "print", "torch.load", "torch.load", "torch.load", "Combined_KD_bert.MateKD.train", "logger.info", "print", "vars", "vars", "vars", "vars", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "p.numel", "Combined_KD_bert.MNLIDataset", "Combined_KD_bert.MNLIDataset", "torch.load.parameters", "os.path.join", "os.path.join", "Combined_KD_bert.MNLIDataset", "Combined_KD_bert.MNLIDataset", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.join", "os.path.join", "Combined_KD_bert.SST2Dataset", "Combined_KD_bert.SST2Dataset", "os.path.join", "os.path.join", "Combined_KD_bert.RTEDataset", "Combined_KD_bert.RTEDataset", "os.path.join", "os.path.join", "Combined_KD_bert.QNLIDataset", "Combined_KD_bert.QNLIDataset", "os.path.join", "os.path.join", "Combined_KD_bert.QQPDataset", "Combined_KD_bert.QQPDataset", "os.path.join", "os.path.join", "Combined_KD_bert.MRPCDataset", "Combined_KD_bert.MRPCDataset", "os.path.join", "os.path.join", "Combined_KD_bert.ColaDataset", "Combined_KD_bert.ColaDataset", "os.path.join", "os.path.join", "Combined_KD_bert.WNLIDataset", "Combined_KD_bert.WNLIDataset", "os.path.join", "os.path.join", "Combined_KD_bert.STSBDataset", "Combined_KD_bert.STSBDataset", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labels", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.freeze_model", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataProcessingArguments", ",", "TrainingArguments", ")", ")", "\n", "\n", "# parser.add_argument(", "\n", "#\t\"--bert_pretrained_path\",", "\n", "#\ttype=str,", "\n", "#\trequired=True,", "\n", "#\thelp=\"The path corresponding to the pre-trained BERT model.\"", "\n", "# )", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--p_value\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.3", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Enable if you initialize student with an MNLI checkpoint for tasks such as RTE and STS-B.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_mnli_ckpt\"", ",", "\n", "type", "=", "bool", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Enable if you initialize student with an MNLI checkpoint for tasks such as RTE and STS-B.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_path\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The path corresponding to the teacher BERT model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs_phase_1\"", ",", "default", "=", "30.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs in phase 1.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs_phase_2\"", ",", "default", "=", "6.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs in phase 2.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_temperature\"", ",", "default", "=", "14", ",", "type", "=", "int", ",", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "\n", "model_args", ",", "dataprocessing_args", ",", "training_args", ",", "rest_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "vars", "(", "model_args", ")", ",", "**", "vars", "(", "dataprocessing_args", ")", ",", "**", "vars", "(", "training_args", ")", ",", "**", "vars", "(", "rest_args", ")", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "# args.n_gpu = 1", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "print", "(", "num_labels", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", ")", "\n", "\n", "# args.model_type = args.model_type.lower()", "\n", "if", "not", "args", ".", "use_mnli_ckpt", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "3", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "\n", "config", ".", "num_labels", "=", "3", "\n", "\n", "", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "# AutoModelForSequenceClassification.from_pretrained(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "if", "args", ".", "use_mnli_ckpt", ":", "\n", "        ", "config", ".", "num_labels", "=", "num_labels", "\n", "logger", ".", "info", "(", "'Reintializing model classifier layer...'", ")", "\n", "model", ".", "num_labels", "=", "num_labels", "\n", "model", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "#BertClassificationHead(config)", "\n", "\n", "", "teacher_config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "teacher_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "teacher_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "teacher_path", ",", "\n", ")", "\n", "teacher_model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "# AutoModelForSequenceClassification.from_pretrained(", "\n", "args", ".", "teacher_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "teacher_config", "\n", ")", "\n", "\n", "\n", "gen_bert_tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert_models/uncased_L-4_H-256_A-4'", ")", "#, cache_dir=\"downloaded\")", "\n", "generator", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "'bert_models/uncased_L-4_H-256_A-4'", ")", "#, cache_dir=\"downloaded\")", "\n", "# model = BertForSequenceClassification(config)", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "teacher_model", ".", "to", "(", "args", ".", "device", ")", "\n", "generator", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "freeze_model", "(", "teacher_model", ",", "True", ")", "\n", "teacher_model", ".", "eval", "(", ")", "\n", "\n", "print", "(", "model", ")", "\n", "model_total_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "print", "(", "\"Total trainable parameters:\"", ",", "model_total_params", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "training_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev_matched.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"mnli-mm\"", ":", "\n", "            ", "training_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev_mismatched.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"sst-2\"", ":", "\n", "            ", "training_set", "=", "SST2Dataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "SST2Dataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"rte\"", ":", "\n", "            ", "training_set", "=", "RTEDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "RTEDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"qnli\"", ":", "\n", "            ", "training_set", "=", "QNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "QNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"qqp\"", ":", "\n", "            ", "training_set", "=", "QQPDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "QQPDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"mrpc\"", ":", "\n", "            ", "training_set", "=", "MRPCDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MRPCDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"cola\"", ":", "\n", "            ", "training_set", "=", "ColaDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "ColaDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"wnli\"", ":", "\n", "            ", "training_set", "=", "WNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "WNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "            ", "training_set", "=", "STSBDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "STSBDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "\n", "", "mate_kd", "=", "MateKD", "(", "args", ",", "config", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "print", "(", "\"*\"", "+", "\" \"", "*", "39", "+", "\"Phase 1 of training\"", "+", "\" \"", "*", "40", "+", "\"*\"", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "global_step", ",", "tr_loss", "=", "mate_kd", ".", "train", "(", "training_set", ",", "eval_set", ",", "model", ",", "teacher_model", ",", "generator", ",", "teacher_tokenizer", ",", "phase", "=", "1", ")", "\n", "logger", ".", "info", "(", "\"  PHASE 1: global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "print", "(", "f\"Best result till end of phase 1 is: {BEST_ACCURACY}\"", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "print", "(", "\"*\"", "+", "\" \"", "*", "39", "+", "\"Phase 2 of training\"", "+", "\" \"", "*", "40", "+", "\"*\"", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "output_dir", "+", "\"/BestModel.pt\"", ")", "\n", "global_step", ",", "tr_loss", "=", "mate_kd", ".", "train", "(", "training_set", ",", "eval_set", ",", "model", ",", "teacher_model", ",", "generator", ",", "teacher_tokenizer", ",", "phase", "=", "2", ")", "\n", "logger", ".", "info", "(", "\"  PHASE 2: global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "print", "(", "f\"Best result till end of phase 2 is: {BEST_ACCURACY}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.InputExample.__init__": [[122, 138], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ",", "rand_vec", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n        Args:\n          guid: Unique id for the example.\n          text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n          text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n          label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "rand_vec", "=", "rand_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MNLIDataset.__init__": [[143, 146], ["Combined_KD.MNLIDataset._create_examples", "Combined_KD.MNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MNLIDataset.__len__": [[147, 150], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MNLIDataset._read_tsv": [[151, 159], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MNLIDataset._create_examples": [[160, 187], ["enumerate", "int", "examples.append", "enumerate", "Combined_KD.InputExample", "float", "float", "token.strip", "Combined_KD.MNLIDataset._get_label", "Combined_KD.MNLIDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "rand_vec", "=", "None", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MNLIDataset._get_label": [[188, 190], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'contradiction'", ",", "'neutral'", ",", "'entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MNLIDataset.__getitem__": [[191, 197], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.RTEDataset.__init__": [[202, 205], ["Combined_KD.RTEDataset._create_examples", "Combined_KD.RTEDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.RTEDataset.__len__": [[206, 209], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.RTEDataset._read_tsv": [[210, 218], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.RTEDataset._create_examples": [[219, 246], ["enumerate", "int", "examples.append", "enumerate", "Combined_KD.InputExample", "float", "float", "token.strip", "Combined_KD.RTEDataset._get_label", "Combined_KD.RTEDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.RTEDataset._get_label": [[247, 249], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'entailment'", ",", "'not_entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.RTEDataset.__getitem__": [[250, 256], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QQPDataset.__init__": [[261, 264], ["Combined_KD.QQPDataset._create_examples", "Combined_KD.QQPDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QQPDataset.__len__": [[265, 268], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QQPDataset._read_tsv": [[269, 277], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QQPDataset._create_examples": [[278, 313], ["enumerate", "enumerate", "line[].strip", "line[].strip", "examples.append", "Combined_KD.InputExample", "token.strip", "float", "float", "token.strip", "Combined_KD.QQPDataset._get_label", "Combined_KD.QQPDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"question1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"question2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "try", ":", "\n", "\n", "                ", "guid", "=", "i", "# int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", ".", "strip", "(", ")", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", ".", "strip", "(", ")", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "not", "text_a", "or", "not", "text_b", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "set_type", "==", "\"train\"", ":", "\n", "                    ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                    ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QQPDataset._get_label": [[314, 316], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QQPDataset.__getitem__": [[317, 323], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.WNLIDataset.__init__": [[328, 331], ["Combined_KD.WNLIDataset._create_examples", "Combined_KD.WNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.WNLIDataset.__len__": [[332, 335], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.WNLIDataset._read_tsv": [[336, 344], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.WNLIDataset._create_examples": [[345, 377], ["enumerate", "enumerate", "examples.append", "Combined_KD.InputExample", "token.strip", "float", "float", "token.strip", "Combined_KD.WNLIDataset._get_label", "Combined_KD.WNLIDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "try", ":", "\n", "\n", "                ", "guid", "=", "i", "# int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                    ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                    ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.WNLIDataset._get_label": [[378, 380], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.WNLIDataset.__getitem__": [[381, 387], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.STSBDataset.__init__": [[392, 395], ["Combined_KD.STSBDataset._create_examples", "Combined_KD.STSBDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.STSBDataset.__len__": [[396, 399], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.STSBDataset._read_tsv": [[400, 408], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.STSBDataset._create_examples": [[409, 441], ["enumerate", "enumerate", "examples.append", "float", "float", "Combined_KD.InputExample", "token.strip", "token.strip"], "methods", ["None"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "try", ":", "\n", "\n", "                ", "guid", "=", "i", "# int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                    ", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.STSBDataset._get_label": [[442, 444], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.STSBDataset.__getitem__": [[445, 451], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QNLIDataset.__init__": [[456, 459], ["Combined_KD.QNLIDataset._create_examples", "Combined_KD.QNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QNLIDataset.__len__": [[460, 463], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QNLIDataset._read_tsv": [[464, 472], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QNLIDataset._create_examples": [[473, 500], ["enumerate", "int", "examples.append", "enumerate", "Combined_KD.InputExample", "float", "float", "token.strip", "Combined_KD.QNLIDataset._get_label", "Combined_KD.QNLIDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"question\"", ":", "\n", "                        ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence\"", ":", "\n", "                        ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QNLIDataset._get_label": [[501, 503], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'entailment'", ",", "'not_entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.QNLIDataset.__getitem__": [[504, 510], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MRPCDataset.__init__": [[515, 518], ["Combined_KD.MRPCDataset._create_examples", "Combined_KD.MRPCDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MRPCDataset.__len__": [[519, 522], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MRPCDataset._read_tsv": [[523, 531], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MRPCDataset._create_examples": [[532, 559], ["enumerate", "int", "examples.append", "Combined_KD.InputExample", "float", "float", "Combined_KD.MRPCDataset._get_label", "Combined_KD.MRPCDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "3", "\n", "sentence2_index", "=", "4", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "# for j, token in enumerate(line):", "\n", "#  if token.strip() == \"question\":", "\n", "#    sentence1_index = j", "\n", "#  elif token.strip() == \"sentence\":", "\n", "#    sentence2_index = j", "\n", "                ", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "# tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "# tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "0", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "float", "(", "line", "[", "0", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MRPCDataset._get_label": [[560, 562], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MRPCDataset.__getitem__": [[563, 569], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.SST2Dataset.__init__": [[574, 577], ["Combined_KD.SST2Dataset._create_examples", "Combined_KD.SST2Dataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.SST2Dataset.__len__": [[578, 581], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.SST2Dataset._read_tsv": [[582, 590], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.SST2Dataset._create_examples": [[591, 616], ["enumerate", "examples.append", "enumerate", "Combined_KD.InputExample", "float", "float", "token.strip", "Combined_KD.SST2Dataset._get_label", "Combined_KD.SST2Dataset._get_label", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "                ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "                    ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence\"", ":", "\n", "                        ", "sentence_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "i", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ",", "\n", "rand_vec", "=", "torch", ".", "normal", "(", "0", ",", "std_z", ",", "(", "1", ",", "128", ",", "256", ")", ")", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.SST2Dataset._get_label": [[617, 619], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.SST2Dataset.__getitem__": [[620, 626], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.ColaDataset.__init__": [[631, 634], ["Combined_KD.ColaDataset._create_examples", "Combined_KD.ColaDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.ColaDataset.__len__": [[635, 638], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.ColaDataset._read_tsv": [[639, 647], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.ColaDataset._create_examples": [[648, 665], ["enumerate", "examples.append", "Combined_KD.InputExample", "float", "float", "Combined_KD.ColaDataset._get_label", "Combined_KD.ColaDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence_index", "=", "3", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "guid", "=", "i", "# \"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "                ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.ColaDataset._get_label": [[666, 668], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.ColaDataset.__getitem__": [[669, 675], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MateKD.__init__": [[782, 784], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MateKD.train": [[785, 1146], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model.zero_grad", "generator.zero_grad", "tqdm.tqdm.trange", "Combined_KD.set_seed", "logger.info", "max", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "generator.parameters", "generator.parameters", "amp.initialize", "amp.initialize", "amp.initialize", "len", "logger.info", "logger.info", "int", "tqdm.tqdm.trange", "tqdm.tqdm.trange", "model.train", "generator.train", "print", "enumerate", "Combined_KD.create_collate_fn", "int", "int", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "tuple", "generator", "Combined_KD.gumbel_softmax", "tqdm.tqdm.trange.close", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "print", "Combined_KD.MateKD.evaluate", "model.state_dict", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "masked_permuted.unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "masked_permuted.unsqueeze", "amp.initialize.", "model", "transformers.AdamW.zero_grad", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "print", "epoch_iterator.close", "len", "len", "model.named_parameters", "model.named_parameters", "any", "Combined_KD.MateKD.evaluate", "t.to", "amp.initialize.roberta.embeddings.word_embeddings", "model.roberta.embeddings.word_embeddings", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.cross_entropy.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.AdamW.zero_grad", "torch.optim.AdamW.zero_grad", "torch.optim.AdamW.zero_grad", "torch.optim.AdamW.step", "torch.optim.AdamW.step", "torch.optim.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.cross_entropy.item", "Combined_KD.MateKD.evaluate", "Combined_KD.MateKD.items", "transformers.get_linear_schedule_with_warmup.get_lr", "json.dumps", "os.path.join", "shutil.rmtree", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "len", "len", "any", "int", "Combined_KD.MateKD.evaluate", "masked_permuted.unsqueeze", "masked_permuted.unsqueeze", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "generator.parameters", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.cross_entropy.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "torch.optim.AdamW.state_dict", "torch.optim.AdamW.state_dict", "torch.optim.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "Combined_KD.MateKD.evaluate", "Combined_KD.MateKD.evaluate", "amp.initialize.", "model", "model", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "model.parameters", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "model.state_dict"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate"], ["", "def", "train", "(", "self", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "teacher_model", ",", "generator", ",", "tokenizer", ",", "phase", ")", ":", "\n", "\n", "        ", "args", "=", "self", ".", "args", "\n", "global", "BEST_ACCURACY", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_device_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "train_sampler", "=", "data", ".", "RandomSampler", "(", "\n", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "data", ".", "distributed", ".", "DistributedSampler", "(", "train_dataset", ")", "\n", "\n", "train_dataloader", "=", "data", ".", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "collate_fn", "=", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "128", ")", ")", "\n", "\n", "if", "phase", "==", "1", ":", "\n", "            ", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "                ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs_phase_1", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "                ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs_phase_1", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "                ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs_phase_2", "=", "args", ".", "max_steps", "//", "(", "\n", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "                ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs_phase_2", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "2138", ",", "# args.warmup_steps,", "\n", "num_training_steps", "=", "t_total", "\n", ")", "\n", "gen_optimizer", "=", "AdamW", "(", "generator", ".", "parameters", "(", ")", ",", "lr", "=", "5e-7", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "gen_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "gen_optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "gen_pre_optimizer", "=", "AdamW", "(", "generator", ".", "parameters", "(", ")", ",", "lr", "=", "5e-6", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "gen_pre_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "gen_pre_optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "                ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "generator", ",", "[", "gen_optimizer", ",", "gen_pre_optimizer", "]", "=", "amp", ".", "initialize", "(", "generator", ",", "\n", "[", "gen_optimizer", ",", "gen_pre_optimizer", "]", ",", "\n", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "teacher_model", "=", "amp", ".", "initialize", "(", "teacher_model", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "if", "phase", "==", "1", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Num Epochs in phase 1 = %d\"", ",", "args", ".", "num_train_epochs_phase_1", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Num Epochs in phase 2 = %d\"", ",", "args", ".", "num_train_epochs_phase_2", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_device_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "steps_train", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "max_met", "=", "-", "1", "\n", "max_met_step", "=", "-", "1", "\n", "model", ".", "zero_grad", "(", ")", "\n", "generator", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "\n", "n_generator_iter", "=", "10", "\n", "n_student_iter", "=", "100", "\n", "\n", "idx_pseudo", "=", "0", "\n", "n_repeat_batch", "=", "n_generator_iter", "+", "n_student_iter", "\n", "\n", "logger", ".", "info", "(", "\"  Pre-train Generator\"", ")", "\n", "\n", "if", "phase", "==", "1", ":", "\n", "            ", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs_phase_1", ")", ",", "desc", "=", "\"Epoch\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "temp", "=", "1", "\n", "", "else", ":", "\n", "            ", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs_phase_2", ")", ",", "desc", "=", "\"Epoch\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "\n", "\n", "", "for", "i", "in", "train_iterator", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "generator", ".", "train", "(", ")", "\n", "# If the phase is 1, then we need to increment the temperature after every (num_epochs_phase_1/max_temp) epochs", "\n", "# For e.g. num_epochs_phase_1 = 20, max_temp = 10, then we increment temperature value after every 2 epochs", "\n", "if", "phase", "==", "1", ":", "\n", "                ", "if", "i", "%", "int", "(", "args", ".", "num_train_epochs_phase_1", "/", "args", ".", "max_temperature", ")", "==", "0", "and", "i", ">", "0", ":", "\n", "                    ", "temp", "+=", "1", "\n", "print", "(", "f\"\\n\\ntemperature is {temp}\"", ")", "\n", "\n", "# Determine the metric based on task, then run evaluation and save model if better than current best result", "\n", "", "", "if", "args", ".", "task_name", "==", "'sts-b'", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'corr'", "]", "\n", "", "elif", "args", ".", "task_name", "==", "'cola'", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'mcc'", "]", "\n", "", "elif", "args", ".", "task_name", "==", "'mrpc'", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'f1'", "]", "\n", "", "elif", "args", ".", "task_name", "==", "'mnli'", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'mnli/acc'", "]", "\n", "", "else", ":", "\n", "                ", "intermediate_res", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "[", "'acc'", "]", "\n", "", "print", "(", "\"Intermediate evaluate: \"", ",", "intermediate_res", ")", "\n", "if", "BEST_ACCURACY", "<", "intermediate_res", ":", "\n", "                ", "BEST_ACCURACY", "=", "intermediate_res", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "args", ".", "output_dir", "+", "\"/BestModel.pt\"", ")", "\n", "print", "(", "\"Best Model Saved!\"", ")", "\n", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "# print(\"Intermediate evaluate: \", self.evaluate(eval_dataset, model, tokenizer))", "\n", "", "epoch_iterator", "=", "train_dataloader", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "                ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                    ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "\n", "", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "input_ids", "=", "batch", "[", "1", "]", "\n", "attention_mask", "=", "batch", "[", "2", "]", "\n", "labels", "=", "batch", "[", "3", "]", "\n", "token_type_ids", "=", "None", "# batch[5]", "\n", "input_ids_permuted", "=", "batch", "[", "4", "]", "\n", "masked_permuted", "=", "batch", "[", "5", "]", "\n", "\n", "# Generator training", "\n", "\n", "outputs", "=", "generator", "(", "input_ids", "=", "input_ids_permuted", ",", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ")", "\n", "\n", "prediction_scores", "=", "outputs", "[", "0", "]", "\n", "\n", "prediction_scores", "=", "gumbel_softmax", "(", "prediction_scores", ",", "1.0", ")", "\n", "\n", "teacher_inp", "=", "torch", ".", "matmul", "(", "prediction_scores", ",", "\n", "teacher_model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "*", "masked_permuted", ".", "unsqueeze", "(", "\n", "-", "1", ")", "\n", "student_inp", "=", "torch", ".", "matmul", "(", "prediction_scores", ",", "\n", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "*", "masked_permuted", ".", "unsqueeze", "(", "\n", "-", "1", ")", "\n", "\n", "teacher_inp", "=", "teacher_inp", "+", "(", "teacher_model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "*", "(", "\n", "1", "-", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", "\n", "student_inp", "=", "student_inp", "+", "(", "\n", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "*", "(", "1", "-", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", "\n", "\n", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "inputs_embeds", "=", "teacher_inp", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "\n", "0", "]", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "inputs_embeds", "=", "student_inp", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "\n", "\n", "# generator training loss", "\n", "if", "idx_pseudo", "%", "n_repeat_batch", "<", "n_generator_iter", ":", "\n", "\n", "                    ", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                        ", "loss", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", ")", "\n", "", "else", ":", "\n", "                        ", "loss", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", ")", "\n", "\n", "\n", "", "loss", "=", "-", "loss", "\n", "\n", "gen_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "gen_optimizer", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "gen_optimizer", ")", ",", "5", ")", "\n", "", "else", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "generator", ".", "parameters", "(", ")", ",", "5", ")", "\n", "\n", "", "gen_optimizer", ".", "step", "(", ")", "\n", "gen_scheduler", ".", "step", "(", ")", "\n", "\n", "# Student training", "\n", "\n", "", "elif", "idx_pseudo", "%", "n_repeat_batch", "<", "(", "n_generator_iter", "+", "n_student_iter", ")", ":", "\n", "\n", "\n", "# In phase 1, student will only learn from teacher", "\n", "                    ", "if", "phase", "==", "1", ":", "\n", "                        ", "loss_aug", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", "*", "(", "temp", "/", "args", ".", "max_temperature", ")", ")", "\n", "\n", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "loss_org", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", "*", "(", "temp", "/", "args", ".", "max_temperature", ")", ")", "\n", "loss", "=", "0.5", "*", "(", "loss_aug", "+", "loss_org", ")", "\n", "", "else", ":", "\n", "\n", "# In phase 2, student will learn from golden label", "\n", "                        ", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "\n", "if", "args", ".", "task_name", "==", "'sts-b'", ":", "\n", "                            ", "loss", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "labels", ")", "\n", "", "else", ":", "\n", "                            ", "loss", "=", "F", ".", "cross_entropy", "(", "student_logits", ",", "torch", ".", "argmax", "(", "labels", ",", "dim", "=", "1", ")", ")", "\n", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                        ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                            ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                        ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "5", ")", "\n", "", "else", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "5", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "steps_train", "+=", "1", "\n", "\n", "", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logs", "=", "{", "}", "\n", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "self", ".", "evaluate", "(", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "\n", "if", "BEST_ACCURACY", "<", "value", ":", "\n", "                                ", "BEST_ACCURACY", "=", "value", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "args", ".", "output_dir", "+", "\"/BestModel.pt\"", ")", "\n", "print", "(", "\"Best Model Saved!\"", ")", "\n", "\n", "", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "tr_loss", "/", "steps_train", "if", "steps_train", ">", "0", "else", "0", "# (tr_loss - logging_loss) / args.logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "\n", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "acc_tasks", "=", "[", "'sst-2'", ",", "'rte'", ",", "'qnli'", ",", "'qqp'", ",", "'mrpc'", ",", "'wnli'", "]", "\n", "mnliacc_tasks", "=", "[", "'mnli'", "]", "\n", "mnlimmacc_tasks", "=", "[", "'mnli-mm'", "]", "\n", "mcc_tasks", "=", "[", "'cola'", "]", "\n", "accf1_tasks", "=", "[", "]", "# ['qqp', 'mrpc']", "\n", "corr_tasks", "=", "[", "'sts-b'", "]", "\n", "current_met", "=", "0", "\n", "\n", "if", "args", ".", "task_name", "in", "acc_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_acc\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mnliacc_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_mnli/acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mnli/acc\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_mnli/acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mnlimmacc_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mcc_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_mcc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mcc\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_mcc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "accf1_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_acc_and_f1\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_acc_and_f1\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_acc_and_f1\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "corr_tasks", ":", "\n", "                        ", "current_met", "=", "logs", "[", "\"eval_corr\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_corr\"", "]", ":", "\n", "                            ", "max_met", "=", "logs", "[", "\"eval_corr\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "\n", "", "", "logs", "[", "\"eval_met_max\"", "]", "=", "max_met", "\n", "logs", "[", "\"eval_met_max_step\"", "]", "=", "max_met_step", "\n", "\n", "print", "(", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "global_step", "}", "}", ")", ")", "\n", "# Restore the best model", "\n", "if", "current_met", "==", "max_met", ":", "\n", "                        ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"best\"", ")", "\n", "shutil", ".", "rmtree", "(", "output_dir", ",", "ignore_errors", "=", "True", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "idx_pseudo", "+=", "1", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                    ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.MateKD.evaluate": [[1147, 1224], ["zip", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "transformers.glue_compute_metrics", "results.update", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "torch.nn.DataParallel.eval", "torch.nn.DataParallel.eval", "tuple", "numpy.argmax", "numpy.argmax", "open", "logger.info", "sorted", "os.path.exists", "Combined_KD.create_collate_fn", "isinstance", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.mean.mean().item", "torch.mean.mean().item", "torch.mean.mean().item", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "transformers.glue_compute_metrics.keys", "logger.info", "writer.write", "t.to", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy", "str", "logits.squeeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean.mean", "torch.mean.mean", "torch.mean.mean", "logits.detach().cpu", "labels.detach().cpu", "logits.detach().cpu", "labels.detach().cpu", "str", "logits.detach", "labels.detach", "logits.detach", "labels.detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn"], ["", "def", "evaluate", "(", "self", ",", "eval_dataset", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "        ", "args", "=", "self", ".", "args", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "# (\"mnli\", \"mnli-mm\") if args.task_name == \"mnli\" else (args.task_name,)", "\n", "eval_outputs_dirs", "=", "(", "\n", "args", ".", "output_dir", ",", ")", "# (args.output_dir, args.output_dir + \"-MM\") if args.task_name == \"mnli\" else (args.output_dir,)", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "# eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)", "\n", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_device_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "data", ".", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "data", ".", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "\n", "collate_fn", "=", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "128", ")", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "#for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "1", "]", ",", "\"attention_mask\"", ":", "batch", "[", "2", "]", "}", "\n", "labels", "=", "batch", "[", "3", "]", "\n", "inputs", "[", "\"token_type_ids\"", "]", "=", "None", "\n", "\n", "logits", "=", "model", "(", "**", "inputs", ")", "[", "0", "]", "\n", "\n", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                        ", "tmp_eval_loss", "=", "F", ".", "mse_loss", "(", "logits", ".", "squeeze", "(", "-", "1", ")", ",", "labels", ")", "\n", "", "else", ":", "\n", "                        ", "log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "per_example_loss", "=", "-", "torch", ".", "sum", "(", "labels", "*", "log_probs", ",", "dim", "=", "-", "1", ")", "\n", "tmp_eval_loss", "=", "torch", ".", "mean", "(", "per_example_loss", ")", "\n", "\n", "", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                    ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                    ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "out_label_ids", "=", "np", ".", "argmax", "(", "out_label_ids", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "", "result", "=", "compute_metrics", "(", "eval_task", ",", "preds", ",", "out_label_ids", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.set_seed": [[71, 77], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.mask_tokens": [[677, 699], ["inputs.clone", "torch.full", "torch.full", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "ValueError", "tokenizer.get_special_tokens_mask", "torch.tensor", "torch.tensor", "torch.tensor", "inputs.clone.eq", "torch.full.masked_fill_", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool.float", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.full", "torch.full", "torch.full"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "mlm_probability", ")", ":", "\n", "    ", "if", "tokenizer", ".", "mask_token", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"", "\n", ")", "\n", "\n", "", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "mlm_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "\n", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "1.0", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "return", "inputs", ",", "labels", ",", "masked_indices", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.create_collate_fn": [[701, 731], ["tokenizer.batch_encode_plus", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "Combined_KD.mask_tokens", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.clone"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.mask_tokens"], ["", "def", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "max_length", ")", ":", "\n", "    ", "def", "collate_fn", "(", "data", ")", ":", "\n", "        ", "text", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "[", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ")", "if", "example", ".", "text_b", "is", "not", "None", "else", "example", ".", "text_a", "for", "example", "in", "data", "]", ",", "\n", "max_length", "=", "max_length", ",", "truncation", "=", "True", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", ")", "\n", "\n", "input_ids", "=", "text", "[", "'input_ids'", "]", "\n", "\n", "# token_type_ids = text['token_type_ids']", "\n", "attention_mask", "=", "text", "[", "'attention_mask'", "]", "\n", "\n", "guids", "=", "[", "example", ".", "guid", "for", "example", "in", "data", "]", "\n", "\n", "labels", "=", "[", "example", ".", "label", "for", "example", "in", "data", "]", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", ")", "\n", "# token_type_ids = torch.tensor(token_type_ids)", "\n", "attention_mask", "=", "torch", ".", "tensor", "(", "attention_mask", ")", "\n", "\n", "input_ids_permuted", ",", "labels_permuted", ",", "mask_permuted", "=", "mask_tokens", "(", "input_ids", ".", "clone", "(", ")", ",", "tokenizer", ",", "args", ".", "p_value", ")", "\n", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ")", "\n", "\n", "guids", "=", "torch", ".", "tensor", "(", "guids", ")", "\n", "\n", "return", "guids", ",", "input_ids", ",", "attention_mask", ",", "labels", ",", "input_ids_permuted", ",", "mask_permuted", ",", "labels_permuted", "# , token_type_ids", "\n", "\n", "", "return", "collate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.freeze_model": [[733, 736], ["model.parameters"], "function", ["None"], ["", "def", "freeze_model", "(", "model", ",", "freeze", ")", ":", "\n", "    ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "not", "freeze", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.sample_gumbel": [[741, 744], ["torch.rand", "torch.rand", "torch.rand", "torch.autograd.Variable", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], ["def", "sample_gumbel", "(", "shape", ",", "eps", "=", "1e-20", ")", ":", "\n", "    ", "U", "=", "torch", ".", "rand", "(", "shape", ",", "device", "=", "\"cuda\"", ")", "\n", "return", "-", "Variable", "(", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "eps", ")", "+", "eps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.gumbel_softmax_sample": [[746, 749], ["torch.softmax", "torch.log_softmax", "Combined_KD.sample_gumbel", "logits.size"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.sample_gumbel"], ["", "def", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", ":", "\n", "    ", "y", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "+", "sample_gumbel", "(", "logits", ".", "size", "(", ")", ")", "\n", "return", "F", ".", "softmax", "(", "y", "/", "temperature", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.gumbel_softmax": [[751, 763], ["Combined_KD.gumbel_softmax_sample", "gumbel_softmax_sample.size", "gumbel_softmax_sample.max", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "y_hard.view.scatter_", "y_hard.view.view", "ind.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax_sample"], ["", "def", "gumbel_softmax", "(", "logits", ",", "temperature", ")", ":", "\n", "    ", "\"\"\"\n    input: [*, n_class]\n    return: [*, n_class] an one-hot vector\n    \"\"\"", "\n", "y", "=", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", "\n", "shape", "=", "y", ".", "size", "(", ")", "\n", "_", ",", "ind", "=", "y", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "y_hard", "=", "torch", ".", "zeros_like", "(", "y", ")", ".", "view", "(", "-", "1", ",", "shape", "[", "-", "1", "]", ")", "\n", "y_hard", ".", "scatter_", "(", "1", ",", "ind", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "y_hard", "=", "y_hard", ".", "view", "(", "*", "shape", ")", "\n", "return", "(", "y_hard", "-", "y", ")", ".", "detach", "(", ")", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.divergence": [[771, 776], ["torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.log_softmax", "torch.softmax"], "function", ["None"], ["def", "divergence", "(", "student_logits", ",", "teacher_logits", ")", ":", "\n", "    ", "divergence", "=", "-", "torch", ".", "sum", "(", "\n", "F", ".", "log_softmax", "(", "student_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", "*", "F", ".", "softmax", "(", "teacher_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "dim", "=", "-", "1", ")", "# forward KL", "\n", "return", "torch", ".", "mean", "(", "divergence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.Combined-KD.Combined_KD.main": [[1226, 1442], ["transformers.HfArgumentParser", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.parse_args_into_dataclasses", "argparse.Namespace", "logging.basicConfig", "logger.warning", "Combined_KD.set_seed", "argparse.Namespace.task_name.lower", "processor.get_labels", "len", "print", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.RobertaTokenizer.from_pretrained", "transformers.RobertaForMaskedLM.from_pretrained", "AutoModelForSequenceClassification.from_pretrained.to", "AutoModelForSequenceClassification.from_pretrained.to", "RobertaForMaskedLM.from_pretrained.to", "logger.info", "Combined_KD.freeze_model", "AutoModelForSequenceClassification.from_pretrained.eval", "print", "sum", "print", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.device", "torch.device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "transformers.AutoConfig.from_pretrained", "transformers.AutoConfig.from_pretrained", "logger.info", "transformers.modeling_roberta.RobertaClassificationHead", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "Combined_KD.MateKD", "print", "print", "print", "Combined_KD.MateKD.train", "logger.info", "print", "print", "print", "print", "AutoModelForSequenceClassification.from_pretrained.load_state_dict", "Combined_KD.MateKD.train", "logger.info", "print", "vars", "vars", "vars", "vars", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "p.numel", "Combined_KD.MNLIDataset", "Combined_KD.MNLIDataset", "torch.load", "torch.load", "torch.load", "AutoModelForSequenceClassification.from_pretrained.parameters", "os.path.join", "os.path.join", "Combined_KD.MNLIDataset", "Combined_KD.MNLIDataset", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.join", "os.path.join", "Combined_KD.SST2Dataset", "Combined_KD.SST2Dataset", "os.path.join", "os.path.join", "Combined_KD.RTEDataset", "Combined_KD.RTEDataset", "os.path.join", "os.path.join", "Combined_KD.QNLIDataset", "Combined_KD.QNLIDataset", "os.path.join", "os.path.join", "Combined_KD.QQPDataset", "Combined_KD.QQPDataset", "os.path.join", "os.path.join", "Combined_KD.MRPCDataset", "Combined_KD.MRPCDataset", "os.path.join", "os.path.join", "Combined_KD.ColaDataset", "Combined_KD.ColaDataset", "os.path.join", "os.path.join", "Combined_KD.WNLIDataset", "Combined_KD.WNLIDataset", "os.path.join", "os.path.join", "Combined_KD.STSBDataset", "Combined_KD.STSBDataset", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labels", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.freeze_model", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataProcessingArguments", ",", "TrainingArguments", ")", ")", "\n", "\n", "# parser.add_argument(", "\n", "#\t\"--bert_pretrained_path\",", "\n", "#\ttype=str,", "\n", "#\trequired=True,", "\n", "#\thelp=\"The path corresponding to the pre-trained BERT model.\"", "\n", "# )", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--p_value\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.3", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Enable if you initialize student with an MNLI checkpoint for tasks such as RTE and STS-B.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_mnli_ckpt\"", ",", "\n", "type", "=", "bool", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Enable if you initialize student with an MNLI checkpoint for tasks such as RTE and STS-B.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_path\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The path corresponding to the teacher BERT model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs_phase_1\"", ",", "default", "=", "10.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs in phase 1.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs_phase_2\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs in phase 2.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_temperature\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "\n", "model_args", ",", "dataprocessing_args", ",", "training_args", ",", "rest_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "vars", "(", "model_args", ")", ",", "**", "vars", "(", "dataprocessing_args", ")", ",", "**", "vars", "(", "training_args", ")", ",", "**", "vars", "(", "rest_args", ")", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "# args.n_gpu = 1", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "print", "(", "num_labels", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", ")", "\n", "\n", "# args.model_type = args.model_type.lower()", "\n", "if", "not", "args", ".", "use_mnli_ckpt", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "3", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "\n", "config", ".", "num_labels", "=", "3", "\n", "\n", "", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "# AutoModelForSequenceClassification.from_pretrained(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "if", "args", ".", "use_mnli_ckpt", ":", "\n", "        ", "config", ".", "num_labels", "=", "num_labels", "\n", "logger", ".", "info", "(", "'Reintializing model classifier layer...'", ")", "\n", "model", ".", "num_labels", "=", "num_labels", "\n", "model", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n", "", "teacher_config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "teacher_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "teacher_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "teacher_path", ",", "\n", ")", "\n", "teacher_model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "# AutoModelForSequenceClassification.from_pretrained(", "\n", "args", ".", "teacher_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "teacher_config", "\n", ")", "\n", "\n", "gen_bert_tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "'bert_models/distilroberta-base'", ")", "#, cache_dir=\"downloaded\")", "\n", "generator", "=", "RobertaForMaskedLM", ".", "from_pretrained", "(", "'bert_models/distilroberta-base'", ")", "#, cache_dir=\"downloaded\")", "\n", "\n", "# model = BertForSequenceClassification(config)", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "teacher_model", ".", "to", "(", "args", ".", "device", ")", "\n", "generator", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "freeze_model", "(", "teacher_model", ",", "True", ")", "\n", "teacher_model", ".", "eval", "(", ")", "\n", "\n", "print", "(", "model", ")", "\n", "model_total_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "print", "(", "\"Total trainable parameters:\"", ",", "model_total_params", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "training_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev_matched.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"mnli-mm\"", ":", "\n", "            ", "training_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev_mismatched.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"sst-2\"", ":", "\n", "            ", "training_set", "=", "SST2Dataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "SST2Dataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"rte\"", ":", "\n", "            ", "training_set", "=", "RTEDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "RTEDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"qnli\"", ":", "\n", "            ", "training_set", "=", "QNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "QNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"qqp\"", ":", "\n", "            ", "training_set", "=", "QQPDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "QQPDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"mrpc\"", ":", "\n", "            ", "training_set", "=", "MRPCDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MRPCDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"cola\"", ":", "\n", "            ", "training_set", "=", "ColaDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "ColaDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"wnli\"", ":", "\n", "            ", "training_set", "=", "WNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "WNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "            ", "training_set", "=", "STSBDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "STSBDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "\n", "", "mate_kd", "=", "MateKD", "(", "args", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "print", "(", "\"*\"", "+", "\" \"", "*", "39", "+", "\"Phase 1 of training\"", "+", "\" \"", "*", "40", "+", "\"*\"", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "global_step", ",", "tr_loss", "=", "mate_kd", ".", "train", "(", "training_set", ",", "eval_set", ",", "model", ",", "teacher_model", ",", "generator", ",", "tokenizer", ",", "phase", "=", "1", ")", "\n", "logger", ".", "info", "(", "\"  PHASE 1: global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "print", "(", "f\"Best result till end of phase 1 is: {BEST_ACCURACY}\"", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "print", "(", "\"*\"", "+", "\" \"", "*", "39", "+", "\"Phase 2 of training\"", "+", "\" \"", "*", "40", "+", "\"*\"", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "args", ".", "output_dir", "+", "\"/BestModel.pt\"", ")", ")", "\n", "global_step", ",", "tr_loss", "=", "mate_kd", ".", "train", "(", "training_set", ",", "eval_set", ",", "model", ",", "teacher_model", ",", "generator", ",", "tokenizer", ",", "phase", "=", "2", ")", "\n", "logger", ".", "info", "(", "\"  PHASE 2: global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "print", "(", "f\"Best result till end of phase 2 is: {BEST_ACCURACY}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.InputExample.__init__": [[118, 134], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ",", "rand_vec", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n        Args:\n          guid: Unique id for the example.\n          text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n          text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n          label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "rand_vec", "=", "rand_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MNLIDataset.__init__": [[138, 141], ["train_adversarial_student.MNLIDataset._create_examples", "train_adversarial_student.MNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MNLIDataset.__len__": [[142, 145], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MNLIDataset._read_tsv": [[146, 154], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MNLIDataset._create_examples": [[155, 182], ["enumerate", "int", "examples.append", "enumerate", "train_adversarial_student.InputExample", "float", "float", "token.strip", "train_adversarial_student.MNLIDataset._get_label", "train_adversarial_student.MNLIDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "rand_vec", "=", "None", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MNLIDataset._get_label": [[183, 185], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'contradiction'", ",", "'neutral'", ",", "'entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MNLIDataset.__getitem__": [[186, 192], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.RTEDataset.__init__": [[196, 199], ["train_adversarial_student.RTEDataset._create_examples", "train_adversarial_student.RTEDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.RTEDataset.__len__": [[200, 203], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.RTEDataset._read_tsv": [[204, 212], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.RTEDataset._create_examples": [[213, 240], ["enumerate", "int", "examples.append", "enumerate", "train_adversarial_student.InputExample", "float", "float", "token.strip", "train_adversarial_student.RTEDataset._get_label", "train_adversarial_student.RTEDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.RTEDataset._get_label": [[241, 243], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'entailment'", ",", "'not_entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.RTEDataset.__getitem__": [[244, 250], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QQPDataset.__init__": [[254, 257], ["train_adversarial_student.QQPDataset._create_examples", "train_adversarial_student.QQPDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QQPDataset.__len__": [[258, 261], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QQPDataset._read_tsv": [[262, 270], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QQPDataset._create_examples": [[271, 308], ["enumerate", "enumerate", "line[].strip", "line[].strip", "examples.append", "train_adversarial_student.InputExample", "token.strip", "float", "float", "token.strip", "train_adversarial_student.QQPDataset._get_label", "train_adversarial_student.QQPDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"question1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"question2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "\n", "", "try", ":", "\n", "\n", "             ", "guid", "=", "i", "#int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", ".", "strip", "(", ")", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", ".", "strip", "(", ")", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "not", "text_a", "or", "not", "text_b", ":", "\n", "               ", "continue", "\n", "\n", "", "if", "set_type", "==", "\"train\"", ":", "\n", "               ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "               ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "             ", "continue", "\n", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QQPDataset._get_label": [[309, 311], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QQPDataset.__getitem__": [[312, 318], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.WNLIDataset.__init__": [[322, 325], ["train_adversarial_student.WNLIDataset._create_examples", "train_adversarial_student.WNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.WNLIDataset.__len__": [[326, 329], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.WNLIDataset._read_tsv": [[330, 338], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.WNLIDataset._create_examples": [[339, 373], ["enumerate", "enumerate", "examples.append", "train_adversarial_student.InputExample", "token.strip", "float", "float", "token.strip", "train_adversarial_student.WNLIDataset._get_label", "train_adversarial_student.WNLIDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "\n", "", "try", ":", "\n", "\n", "             ", "guid", "=", "i", "#int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "               ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "               ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "             ", "continue", "\n", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.WNLIDataset._get_label": [[374, 376], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.WNLIDataset.__getitem__": [[377, 383], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.STSBDataset.__init__": [[386, 389], ["train_adversarial_student.STSBDataset._create_examples", "train_adversarial_student.STSBDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.STSBDataset.__len__": [[390, 393], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.STSBDataset._read_tsv": [[394, 402], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.STSBDataset._create_examples": [[403, 437], ["enumerate", "enumerate", "examples.append", "float", "float", "train_adversarial_student.InputExample", "token.strip", "token.strip"], "methods", ["None"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "\n", "", "try", ":", "\n", "\n", "             ", "guid", "=", "i", "#int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "               ", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "               ", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "             ", "continue", "\n", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.STSBDataset._get_label": [[438, 440], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.STSBDataset.__getitem__": [[441, 447], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QNLIDataset.__init__": [[450, 453], ["train_adversarial_student.QNLIDataset._create_examples", "train_adversarial_student.QNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QNLIDataset.__len__": [[454, 457], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QNLIDataset._read_tsv": [[458, 466], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QNLIDataset._create_examples": [[467, 494], ["enumerate", "int", "examples.append", "enumerate", "train_adversarial_student.InputExample", "float", "float", "token.strip", "train_adversarial_student.QNLIDataset._get_label", "train_adversarial_student.QNLIDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"question\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QNLIDataset._get_label": [[495, 497], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'entailment'", ",", "'not_entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.QNLIDataset.__getitem__": [[498, 504], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MRPCDataset.__init__": [[507, 510], ["train_adversarial_student.MRPCDataset._create_examples", "train_adversarial_student.MRPCDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MRPCDataset.__len__": [[511, 514], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MRPCDataset._read_tsv": [[515, 523], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MRPCDataset._create_examples": [[524, 551], ["enumerate", "int", "examples.append", "train_adversarial_student.InputExample", "float", "float", "train_adversarial_student.MRPCDataset._get_label", "train_adversarial_student.MRPCDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "3", "\n", "sentence2_index", "=", "4", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "#for j, token in enumerate(line):", "\n", "#  if token.strip() == \"question\":", "\n", "#    sentence1_index = j", "\n", "#  elif token.strip() == \"sentence\":", "\n", "#    sentence2_index = j", "\n", "            ", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "0", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "0", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MRPCDataset._get_label": [[552, 554], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.MRPCDataset.__getitem__": [[555, 561], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.SST2Dataset.__init__": [[564, 567], ["train_adversarial_student.SST2Dataset._create_examples", "train_adversarial_student.SST2Dataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.SST2Dataset.__len__": [[568, 571], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.SST2Dataset._read_tsv": [[572, 580], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.SST2Dataset._create_examples": [[581, 606], ["enumerate", "examples.append", "enumerate", "train_adversarial_student.InputExample", "float", "float", "token.strip", "train_adversarial_student.SST2Dataset._get_label", "train_adversarial_student.SST2Dataset._get_label", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence\"", ":", "\n", "                ", "sentence_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "i", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ",", "\n", "rand_vec", "=", "torch", ".", "normal", "(", "0", ",", "std_z", ",", "(", "1", ",", "128", ",", "256", ")", ")", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.SST2Dataset._get_label": [[607, 609], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.SST2Dataset.__getitem__": [[610, 616], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.ColaDataset.__init__": [[620, 623], ["train_adversarial_student.ColaDataset._create_examples", "train_adversarial_student.ColaDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.ColaDataset.__len__": [[624, 627], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.ColaDataset._read_tsv": [[628, 636], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.ColaDataset._create_examples": [[637, 654], ["enumerate", "examples.append", "train_adversarial_student.InputExample", "float", "float", "train_adversarial_student.ColaDataset._get_label", "train_adversarial_student.ColaDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence_index", "=", "3", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "guid", "=", "i", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.ColaDataset._get_label": [[655, 657], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.ColaDataset.__getitem__": [[658, 664], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.set_seed": [[69, 75], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.mask_tokens": [[666, 688], ["inputs.clone", "torch.full", "torch.full", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "ValueError", "tokenizer.get_special_tokens_mask", "torch.tensor", "torch.tensor", "torch.tensor", "inputs.clone.eq", "torch.full.masked_fill_", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool.float", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.full", "torch.full", "torch.full"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "mlm_probability", ")", ":", "\n", "    ", "if", "tokenizer", ".", "mask_token", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"", "\n", ")", "\n", "\n", "", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "mlm_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "\n", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "1.0", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "return", "inputs", ",", "labels", ",", "masked_indices", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.create_collate_fn": [[690, 719], ["tokenizer.batch_encode_plus", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "train_adversarial_student.mask_tokens", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.clone"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.mask_tokens"], ["", "def", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "max_length", ")", ":", "\n", "    ", "def", "collate_fn", "(", "data", ")", ":", "\n", "        ", "text", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "[", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ")", "if", "example", ".", "text_b", "is", "not", "None", "else", "example", ".", "text_a", "for", "example", "in", "data", "]", ",", "max_length", "=", "max_length", ",", "truncation", "=", "True", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", ")", "\n", "\n", "input_ids", "=", "text", "[", "'input_ids'", "]", "\n", "\n", "#token_type_ids = text['token_type_ids']", "\n", "attention_mask", "=", "text", "[", "'attention_mask'", "]", "\n", "\n", "guids", "=", "[", "example", ".", "guid", "for", "example", "in", "data", "]", "\n", "\n", "labels", "=", "[", "example", ".", "label", "for", "example", "in", "data", "]", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", ")", "\n", "#token_type_ids = torch.tensor(token_type_ids)", "\n", "attention_mask", "=", "torch", ".", "tensor", "(", "attention_mask", ")", "\n", "\n", "input_ids_permuted", ",", "labels_permuted", ",", "mask_permuted", "=", "mask_tokens", "(", "input_ids", ".", "clone", "(", ")", ",", "tokenizer", ",", "args", ".", "p_value", ")", "\n", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ")", "\n", "\n", "guids", "=", "torch", ".", "tensor", "(", "guids", ")", "\n", "\n", "return", "guids", ",", "input_ids", ",", "attention_mask", ",", "labels", ",", "input_ids_permuted", ",", "mask_permuted", ",", "labels_permuted", "#, token_type_ids", "\n", "\n", "", "return", "collate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.freeze_model": [[720, 723], ["model.parameters"], "function", ["None"], ["", "def", "freeze_model", "(", "model", ",", "freeze", ")", ":", "\n", "    ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "not", "freeze", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.sample_gumbel": [[726, 729], ["torch.rand", "torch.rand", "torch.rand", "torch.autograd.Variable", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], ["def", "sample_gumbel", "(", "shape", ",", "eps", "=", "1e-20", ")", ":", "\n", "    ", "U", "=", "torch", ".", "rand", "(", "shape", ",", "device", "=", "\"cuda\"", ")", "\n", "return", "-", "Variable", "(", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "eps", ")", "+", "eps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.gumbel_softmax_sample": [[730, 733], ["torch.softmax", "torch.log_softmax", "train_adversarial_student.sample_gumbel", "logits.size"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.sample_gumbel"], ["", "def", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", ":", "\n", "    ", "y", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "+", "sample_gumbel", "(", "logits", ".", "size", "(", ")", ")", "\n", "return", "F", ".", "softmax", "(", "y", "/", "temperature", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.gumbel_softmax": [[735, 747], ["train_adversarial_student.gumbel_softmax_sample", "gumbel_softmax_sample.size", "gumbel_softmax_sample.max", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "y_hard.view.scatter_", "y_hard.view.view", "ind.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax_sample"], ["", "def", "gumbel_softmax", "(", "logits", ",", "temperature", ")", ":", "\n", "    ", "\"\"\"\n    input: [*, n_class]\n    return: [*, n_class] an one-hot vector\n    \"\"\"", "\n", "y", "=", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", "\n", "shape", "=", "y", ".", "size", "(", ")", "\n", "_", ",", "ind", "=", "y", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "y_hard", "=", "torch", ".", "zeros_like", "(", "y", ")", ".", "view", "(", "-", "1", ",", "shape", "[", "-", "1", "]", ")", "\n", "y_hard", ".", "scatter_", "(", "1", ",", "ind", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "y_hard", "=", "y_hard", ".", "view", "(", "*", "shape", ")", "\n", "return", "(", "y_hard", "-", "y", ")", ".", "detach", "(", ")", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.divergence": [[751, 754], ["torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.log_softmax", "torch.softmax"], "function", ["None"], ["def", "divergence", "(", "student_logits", ",", "teacher_logits", ")", ":", "\n", "    ", "divergence", "=", "-", "torch", ".", "sum", "(", "F", ".", "log_softmax", "(", "student_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", "*", "F", ".", "softmax", "(", "teacher_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "# forward KL", "\n", "return", "torch", ".", "mean", "(", "divergence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.train": [[756, 1035], ["torch.utils.data.DataLoader", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model.zero_grad", "generator.zero_grad", "tqdm.trange", "train_adversarial_student.set_seed", "logger.info", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "generator.parameters", "generator.parameters", "amp.initialize", "amp.initialize", "amp.initialize", "len", "int", "tqdm.tqdm", "enumerate", "train_adversarial_student.create_collate_fn", "model.train", "generator.train", "tuple", "generator", "train_adversarial_student.gumbel_softmax", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.matmul", "torch.matmul", "torch.matmul", "masked_permuted.unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "masked_permuted.unsqueeze", "amp.initialize.", "model", "torch.mse_loss", "train_adversarial_student.divergence", "transformers.AdamW.zero_grad", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "print", "tqdm.tqdm.close", "len", "model.named_parameters", "model.named_parameters", "any", "t.to", "amp.initialize.roberta.embeddings.word_embeddings", "model.roberta.embeddings.word_embeddings", "divergence.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.zero_grad", "torch.optim.Adam.step", "transformers.get_linear_schedule_with_warmup.step", "divergence.item", "train_adversarial_student.evaluate", "evaluate.items", "transformers.get_linear_schedule_with_warmup.get_lr", "json.dumps", "os.path.join", "shutil.rmtree", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "torch.save", "torch.save", "logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "any", "masked_permuted.unsqueeze", "masked_permuted.unsqueeze", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "generator.parameters", "torch.mse_loss", "torch.mse_loss", "train_adversarial_student.divergence", "torch.mean", "torch.mean", "torch.mean", "divergence.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "torch.optim.Adam.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "amp.initialize.", "model", "student_logits.squeeze", "amp.initialize.", "model", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "model.parameters", "torch.sum", "torch.sum", "torch.sum", "torch.log_softmax"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.divergence", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.divergence"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "teacher_model", ",", "generator", ",", "tokenizer", ")", ":", "\n", "\n", "    ", "args", ".", "train_batch_size", "=", "args", ".", "per_device_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "train_sampler", "=", "data", ".", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "data", ".", "distributed", ".", "DistributedSampler", "(", "train_dataset", ")", "\n", "\n", "train_dataloader", "=", "data", ".", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "collate_fn", "=", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "128", ")", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "2138", ",", "#args.warmup_steps,", "\n", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "\n", "gen_optimizer", "=", "AdamW", "(", "generator", ".", "parameters", "(", ")", ",", "lr", "=", "5e-7", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "gen_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "gen_optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "\n", "gen_pre_optimizer", "=", "AdamW", "(", "generator", ".", "parameters", "(", ")", ",", "lr", "=", "5e-6", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "gen_pre_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "gen_pre_optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "generator", ",", "[", "gen_optimizer", ",", "gen_pre_optimizer", "]", "=", "amp", ".", "initialize", "(", "generator", ",", "[", "gen_optimizer", ",", "gen_pre_optimizer", "]", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "teacher_model", "=", "amp", ".", "initialize", "(", "teacher_model", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_device_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "steps_train", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "max_met", "=", "-", "1", "\n", "max_met_step", "=", "-", "1", "\n", "model", ".", "zero_grad", "(", ")", "\n", "generator", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "\n", "n_generator_iter", "=", "10", "\n", "n_student_iter", "=", "100", "\n", "\n", "idx_pseudo", "=", "0", "\n", "n_repeat_batch", "=", "n_generator_iter", "+", "n_student_iter", "\n", "\n", "logger", ".", "info", "(", "\"  Pre-train Generator\"", ")", "\n", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "generator", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "input_ids", "=", "batch", "[", "1", "]", "\n", "attention_mask", "=", "batch", "[", "2", "]", "\n", "labels", "=", "batch", "[", "3", "]", "\n", "token_type_ids", "=", "None", "#batch[5]", "\n", "input_ids_permuted", "=", "batch", "[", "4", "]", "\n", "masked_permuted", "=", "batch", "[", "5", "]", "\n", "# data augmentation", "\n", "outputs", "=", "generator", "(", "input_ids", "=", "input_ids_permuted", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "\n", "prediction_scores", "=", "outputs", "[", "0", "]", "\n", "\n", "prediction_scores", "=", "gumbel_softmax", "(", "prediction_scores", ",", "1.0", ")", "\n", "\n", "teacher_inp", "=", "torch", ".", "matmul", "(", "prediction_scores", ",", "teacher_model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "*", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", "\n", "student_inp", "=", "torch", ".", "matmul", "(", "prediction_scores", ",", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "*", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "teacher_inp", "=", "teacher_inp", "+", "(", "teacher_model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "*", "(", "1", "-", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", "\n", "student_inp", "=", "student_inp", "+", "(", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "*", "(", "1", "-", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", "\n", "\n", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "inputs_embeds", "=", "teacher_inp", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "inputs_embeds", "=", "student_inp", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "\n", "# generator training loss", "\n", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                ", "loss", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "divergence", "(", "student_logits", ",", "teacher_logits", ")", "\n", "\n", "\n", "", "if", "idx_pseudo", "%", "n_repeat_batch", "<", "n_generator_iter", ":", "\n", "                ", "loss", "=", "-", "loss", "\n", "\n", "gen_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                    ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "gen_optimizer", ")", "as", "scaled_loss", ":", "\n", "                        ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "gen_optimizer", ")", ",", "5", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "generator", ".", "parameters", "(", ")", ",", "5", ")", "\n", "\n", "", "gen_optimizer", ".", "step", "(", ")", "\n", "gen_scheduler", ".", "step", "(", ")", "\n", "\n", "", "elif", "idx_pseudo", "%", "n_repeat_batch", "<", "(", "n_generator_iter", "+", "n_student_iter", ")", ":", "\n", "\n", "                ", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                    ", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "loss_teach", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", ")", "\n", "loss_good", "=", "F", ".", "mse_loss", "(", "student_logits", ".", "squeeze", "(", "-", "1", ")", ",", "labels", ")", "\n", "", "else", ":", "\n", "                    ", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "loss_teach", "=", "divergence", "(", "student_logits", ",", "teacher_logits", ")", "\n", "loss_good", "=", "torch", ".", "mean", "(", "-", "torch", ".", "sum", "(", "F", ".", "log_softmax", "(", "student_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", "*", "labels", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "# loss in the paper", "\n", "", "loss", "=", "loss_good", "*", "(", "1", "/", "3", ")", "+", "(", "1", "/", "3", ")", "*", "loss", "+", "(", "1", "/", "3", ")", "*", "loss_teach", "\n", "# new loss", "\n", "#loss = loss_good * 0.5 + 0.5 * loss_teach", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                    ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                        ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "5", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "5", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "steps_train", "+=", "1", "\n", "\n", "\n", "", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                ", "logs", "=", "{", "}", "\n", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "results", "=", "evaluate", "(", "args", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "tr_loss", "/", "steps_train", "if", "steps_train", ">", "0", "else", "0", "#(tr_loss - logging_loss) / args.logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "\n", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "acc_tasks", "=", "[", "'sst-2'", ",", "'rte'", ",", "'qnli'", ",", "'qqp'", ",", "'mrpc'", ",", "'wnli'", "]", "\n", "mnliacc_tasks", "=", "[", "'mnli'", "]", "\n", "mnlimmacc_tasks", "=", "[", "'mnli-mm'", "]", "\n", "mcc_tasks", "=", "[", "'cola'", "]", "\n", "accf1_tasks", "=", "[", "]", "#['qqp', 'mrpc']", "\n", "corr_tasks", "=", "[", "'sts-b'", "]", "\n", "current_met", "=", "0", "\n", "\n", "if", "args", ".", "task_name", "in", "acc_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_acc\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mnliacc_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_mnli/acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mnli/acc\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_mnli/acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mnlimmacc_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mcc_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_mcc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mcc\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_mcc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "accf1_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_acc_and_f1\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_acc_and_f1\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_acc_and_f1\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "corr_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_corr\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_corr\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_corr\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "\n", "", "", "logs", "[", "\"eval_met_max\"", "]", "=", "max_met", "\n", "logs", "[", "\"eval_met_max_step\"", "]", "=", "max_met_step", "\n", "\n", "print", "(", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "global_step", "}", "}", ")", ")", "\n", "# restore best model", "\n", "if", "current_met", "==", "max_met", ":", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"best\"", ")", "\n", "shutil", ".", "rmtree", "(", "output_dir", ",", "ignore_errors", "=", "True", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "idx_pseudo", "+=", "1", "\n", "global_step", "+=", "1", "\n", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.evaluate": [[1037, 1114], ["zip", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "transformers.glue_compute_metrics", "results.update", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "numpy.argmax", "numpy.argmax", "open", "logger.info", "sorted", "os.path.exists", "train_adversarial_student.create_collate_fn", "isinstance", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.mean.mean().item", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "transformers.glue_compute_metrics.keys", "logger.info", "writer.write", "t.to", "torch.nn.DataParallel.", "torch.mse_loss", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.mean", "torch.mean", "torch.mean", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy", "str", "logits.squeeze", "torch.sum", "torch.sum", "torch.sum", "torch.mean.mean", "logits.detach().cpu", "labels.detach().cpu", "logits.detach().cpu", "labels.detach().cpu", "str", "logits.detach", "labels.detach", "logits.detach", "labels.detach"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn"], ["", "def", "evaluate", "(", "args", ",", "eval_dataset", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "#(\"mnli\", \"mnli-mm\") if args.task_name == \"mnli\" else (args.task_name,)", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", ")", "#(args.output_dir, args.output_dir + \"-MM\") if args.task_name == \"mnli\" else (args.output_dir,)", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "#eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)", "\n", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_device_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "data", ".", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "data", ".", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "128", ")", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "1", "]", ",", "\"attention_mask\"", ":", "batch", "[", "2", "]", "}", "\n", "labels", "=", "batch", "[", "3", "]", "\n", "inputs", "[", "\"token_type_ids\"", "]", "=", "None", "\n", "\n", "#if args.model_type != \"distilbert\":", "\n", "#    inputs[\"token_type_ids\"] = (", "\n", "#        batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None", "\n", "#    )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "logits", "=", "model", "(", "**", "inputs", ")", "[", "0", "]", "\n", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                    ", "tmp_eval_loss", "=", "F", ".", "mse_loss", "(", "logits", ".", "squeeze", "(", "-", "1", ")", ",", "labels", ")", "\n", "", "else", ":", "\n", "                    ", "log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "per_example_loss", "=", "-", "torch", ".", "sum", "(", "labels", "*", "log_probs", ",", "dim", "=", "-", "1", ")", "\n", "tmp_eval_loss", "=", "torch", ".", "mean", "(", "per_example_loss", ")", "\n", "\n", "", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "out_label_ids", "=", "np", ".", "argmax", "(", "out_label_ids", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "", "result", "=", "compute_metrics", "(", "eval_task", ",", "preds", ",", "out_label_ids", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student.main": [[1116, 1309], ["transformers.HfArgumentParser", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.parse_args_into_dataclasses", "argparse.Namespace", "logging.basicConfig", "logger.warning", "train_adversarial_student.set_seed", "argparse.Namespace.task_name.lower", "processor.get_labels", "len", "print", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.RobertaTokenizer.from_pretrained", "transformers.RobertaForMaskedLM.from_pretrained", "AutoModelForSequenceClassification.from_pretrained.to", "AutoModelForSequenceClassification.from_pretrained.to", "RobertaForMaskedLM.from_pretrained.to", "logger.info", "train_adversarial_student.freeze_model", "AutoModelForSequenceClassification.from_pretrained.eval", "print", "sum", "print", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.device", "torch.device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "transformers.AutoConfig.from_pretrained", "transformers.AutoConfig.from_pretrained", "logger.info", "transformers.modeling_roberta.RobertaClassificationHead", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "train_adversarial_student.train", "logger.info", "vars", "vars", "vars", "vars", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "p.numel", "train_adversarial_student.MNLIDataset", "train_adversarial_student.MNLIDataset", "AutoModelForSequenceClassification.from_pretrained.parameters", "os.path.join", "os.path.join", "train_adversarial_student.MNLIDataset", "train_adversarial_student.MNLIDataset", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.join", "os.path.join", "train_adversarial_student.SST2Dataset", "train_adversarial_student.SST2Dataset", "os.path.join", "os.path.join", "train_adversarial_student.RTEDataset", "train_adversarial_student.RTEDataset", "os.path.join", "os.path.join", "train_adversarial_student.QNLIDataset", "train_adversarial_student.QNLIDataset", "os.path.join", "os.path.join", "train_adversarial_student.QQPDataset", "train_adversarial_student.QQPDataset", "os.path.join", "os.path.join", "train_adversarial_student.MRPCDataset", "train_adversarial_student.MRPCDataset", "os.path.join", "os.path.join", "train_adversarial_student.ColaDataset", "train_adversarial_student.ColaDataset", "os.path.join", "os.path.join", "train_adversarial_student.WNLIDataset", "train_adversarial_student.WNLIDataset", "os.path.join", "os.path.join", "train_adversarial_student.STSBDataset", "train_adversarial_student.STSBDataset", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labels", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.freeze_model", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataProcessingArguments", ",", "TrainingArguments", ")", ")", "\n", "\n", "#parser.add_argument(", "\n", "#\t\"--bert_pretrained_path\",", "\n", "#\ttype=str,", "\n", "#\trequired=True,", "\n", "#\thelp=\"The path corresponding to the pre-trained BERT model.\"", "\n", "#)", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--p_value\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.3", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Enable if you initialize student with an MNLI checkpoint for tasks such as RTE and STS-B.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_mnli_ckpt\"", ",", "\n", "type", "=", "bool", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Enable if you initialize student with an MNLI checkpoint for tasks such as RTE and STS-B.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_path\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The path corresponding to the teacher BERT model.\"", "\n", ")", "\n", "\n", "model_args", ",", "dataprocessing_args", ",", "training_args", ",", "rest_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "vars", "(", "model_args", ")", ",", "**", "vars", "(", "dataprocessing_args", ")", ",", "**", "vars", "(", "training_args", ")", ",", "**", "vars", "(", "rest_args", ")", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "#args.n_gpu = 1", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "print", "(", "num_labels", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", ")", "\n", "\n", "#args.model_type = args.model_type.lower()", "\n", "if", "not", "args", ".", "use_mnli_ckpt", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "3", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "\n", "config", ".", "num_labels", "=", "3", "\n", "\n", "", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "#AutoModelForSequenceClassification.from_pretrained(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "if", "args", ".", "use_mnli_ckpt", ":", "\n", "        ", "config", ".", "num_labels", "=", "num_labels", "\n", "logger", ".", "info", "(", "'Reintializing model classifier layer...'", ")", "\n", "model", ".", "num_labels", "=", "num_labels", "\n", "model", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n", "\n", "", "teacher_config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "teacher_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "teacher_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "teacher_path", ",", "\n", ")", "\n", "teacher_model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "#AutoModelForSequenceClassification.from_pretrained(", "\n", "args", ".", "teacher_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "teacher_config", "\n", ")", "\n", "\n", "gen_bert_tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "'bert_models/distilroberta-base'", ")", "#, cache_dir=\"downloaded\")", "\n", "generator", "=", "RobertaForMaskedLM", ".", "from_pretrained", "(", "'bert_models/distilroberta-base'", ")", "#, cache_dir=\"downloaded\")", "\n", "\n", "#model = BertForSequenceClassification(config)", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "teacher_model", ".", "to", "(", "args", ".", "device", ")", "\n", "generator", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "freeze_model", "(", "teacher_model", ",", "True", ")", "\n", "teacher_model", ".", "eval", "(", ")", "\n", "\n", "print", "(", "model", ")", "\n", "model_total_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "print", "(", "\"Total trainable parameters:\"", ",", "model_total_params", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "training_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev_matched.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"mnli-mm\"", ":", "\n", "            ", "training_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev_mismatched.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"sst-2\"", ":", "\n", "            ", "training_set", "=", "SST2Dataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "SST2Dataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"rte\"", ":", "\n", "            ", "training_set", "=", "RTEDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "RTEDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"qnli\"", ":", "\n", "            ", "training_set", "=", "QNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "QNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"qqp\"", ":", "\n", "            ", "training_set", "=", "QQPDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "QQPDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"mrpc\"", ":", "\n", "            ", "training_set", "=", "MRPCDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MRPCDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"cola\"", ":", "\n", "            ", "training_set", "=", "ColaDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "ColaDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"wnli\"", ":", "\n", "            ", "training_set", "=", "WNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "WNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "            ", "training_set", "=", "STSBDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "STSBDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "training_set", ",", "eval_set", ",", "model", ",", "teacher_model", ",", "generator", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\"  global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.InputExample.__init__": [[119, 135], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ",", "rand_vec", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n        Args:\n          guid: Unique id for the example.\n          text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n          text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n          label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "rand_vec", "=", "rand_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MNLIDataset.__init__": [[139, 142], ["train_adversarial_student_bert.MNLIDataset._create_examples", "train_adversarial_student_bert.MNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MNLIDataset.__len__": [[143, 146], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MNLIDataset._read_tsv": [[147, 155], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MNLIDataset._create_examples": [[156, 183], ["enumerate", "int", "examples.append", "enumerate", "train_adversarial_student_bert.InputExample", "float", "float", "token.strip", "train_adversarial_student_bert.MNLIDataset._get_label", "train_adversarial_student_bert.MNLIDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "rand_vec", "=", "None", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MNLIDataset._get_label": [[184, 186], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'contradiction'", ",", "'entailment'", ",", "'neutral'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MNLIDataset.__getitem__": [[187, 193], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.RTEDataset.__init__": [[197, 200], ["train_adversarial_student_bert.RTEDataset._create_examples", "train_adversarial_student_bert.RTEDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.RTEDataset.__len__": [[201, 204], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.RTEDataset._read_tsv": [[205, 213], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.RTEDataset._create_examples": [[214, 241], ["enumerate", "int", "examples.append", "enumerate", "train_adversarial_student_bert.InputExample", "float", "float", "token.strip", "train_adversarial_student_bert.RTEDataset._get_label", "train_adversarial_student_bert.RTEDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.RTEDataset._get_label": [[242, 244], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'entailment'", ",", "'not_entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.RTEDataset.__getitem__": [[245, 251], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QQPDataset.__init__": [[255, 258], ["train_adversarial_student_bert.QQPDataset._create_examples", "train_adversarial_student_bert.QQPDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QQPDataset.__len__": [[259, 262], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QQPDataset._read_tsv": [[263, 271], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QQPDataset._create_examples": [[272, 309], ["enumerate", "enumerate", "line[].strip", "line[].strip", "examples.append", "train_adversarial_student_bert.InputExample", "token.strip", "float", "float", "token.strip", "train_adversarial_student_bert.QQPDataset._get_label", "train_adversarial_student_bert.QQPDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"question1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"question2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "\n", "", "try", ":", "\n", "\n", "             ", "guid", "=", "i", "#int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", ".", "strip", "(", ")", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", ".", "strip", "(", ")", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "not", "text_a", "or", "not", "text_b", ":", "\n", "               ", "continue", "\n", "\n", "", "if", "set_type", "==", "\"train\"", ":", "\n", "               ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "               ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "             ", "continue", "\n", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QQPDataset._get_label": [[310, 312], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QQPDataset.__getitem__": [[313, 319], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.WNLIDataset.__init__": [[323, 326], ["train_adversarial_student_bert.WNLIDataset._create_examples", "train_adversarial_student_bert.WNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.WNLIDataset.__len__": [[327, 330], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.WNLIDataset._read_tsv": [[331, 339], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.WNLIDataset._create_examples": [[340, 374], ["enumerate", "enumerate", "examples.append", "train_adversarial_student_bert.InputExample", "token.strip", "float", "float", "token.strip", "train_adversarial_student_bert.WNLIDataset._get_label", "train_adversarial_student_bert.WNLIDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "\n", "", "try", ":", "\n", "\n", "             ", "guid", "=", "i", "#int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "               ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "               ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "             ", "continue", "\n", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.WNLIDataset._get_label": [[375, 377], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.WNLIDataset.__getitem__": [[378, 384], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.STSBDataset.__init__": [[387, 390], ["train_adversarial_student_bert.STSBDataset._create_examples", "train_adversarial_student_bert.STSBDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.STSBDataset.__len__": [[391, 394], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.STSBDataset._read_tsv": [[395, 403], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.STSBDataset._create_examples": [[404, 438], ["enumerate", "enumerate", "examples.append", "float", "float", "train_adversarial_student_bert.InputExample", "token.strip", "token.strip"], "methods", ["None"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence1\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence2\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "\n", "", "try", ":", "\n", "\n", "             ", "guid", "=", "i", "#int(line[0]) #\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "               ", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "               ", "label", "=", "float", "(", "line", "[", "-", "1", "]", ")", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "except", ":", "\n", "             ", "continue", "\n", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.STSBDataset._get_label": [[439, 441], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.STSBDataset.__getitem__": [[442, 448], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QNLIDataset.__init__": [[451, 454], ["train_adversarial_student_bert.QNLIDataset._create_examples", "train_adversarial_student_bert.QNLIDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QNLIDataset.__len__": [[455, 458], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QNLIDataset._read_tsv": [[459, 467], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QNLIDataset._create_examples": [[468, 495], ["enumerate", "int", "examples.append", "enumerate", "train_adversarial_student_bert.InputExample", "float", "float", "token.strip", "train_adversarial_student_bert.QNLIDataset._get_label", "train_adversarial_student_bert.QNLIDataset._get_label", "token.strip"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "0", "\n", "sentence2_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"question\"", ":", "\n", "                ", "sentence1_index", "=", "j", "\n", "", "elif", "token", ".", "strip", "(", ")", "==", "\"sentence\"", ":", "\n", "                ", "sentence2_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QNLIDataset._get_label": [[496, 498], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'entailment'", ",", "'not_entailment'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.QNLIDataset.__getitem__": [[499, 505], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MRPCDataset.__init__": [[508, 511], ["train_adversarial_student_bert.MRPCDataset._create_examples", "train_adversarial_student_bert.MRPCDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MRPCDataset.__len__": [[512, 515], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MRPCDataset._read_tsv": [[516, 524], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MRPCDataset._create_examples": [[525, 552], ["enumerate", "int", "examples.append", "train_adversarial_student_bert.InputExample", "float", "float", "train_adversarial_student_bert.MRPCDataset._get_label", "train_adversarial_student_bert.MRPCDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence1_index", "=", "3", "\n", "sentence2_index", "=", "4", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "#for j, token in enumerate(line):", "\n", "#  if token.strip() == \"question\":", "\n", "#    sentence1_index = j", "\n", "#  elif token.strip() == \"sentence\":", "\n", "#    sentence2_index = j", "\n", "            ", "continue", "\n", "\n", "", "guid", "=", "int", "(", "line", "[", "0", "]", ")", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "text_a", "=", "line", "[", "sentence1_index", "]", "#tokenization.convert_to_unicode(line[sentence1_index])", "\n", "text_b", "=", "line", "[", "sentence2_index", "]", "#tokenization.convert_to_unicode(line[sentence2_index])", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "0", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "label", "=", "[", "float", "(", "line", "[", "0", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MRPCDataset._get_label": [[553, 555], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.MRPCDataset.__getitem__": [[556, 562], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.SST2Dataset.__init__": [[565, 568], ["train_adversarial_student_bert.SST2Dataset._create_examples", "train_adversarial_student_bert.SST2Dataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.SST2Dataset.__len__": [[569, 572], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.SST2Dataset._read_tsv": [[573, 581], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.SST2Dataset._create_examples": [[582, 607], ["enumerate", "examples.append", "enumerate", "train_adversarial_student_bert.InputExample", "float", "float", "token.strip", "train_adversarial_student_bert.SST2Dataset._get_label", "train_adversarial_student_bert.SST2Dataset._get_label", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence_index", "=", "0", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "if", "i", "==", "0", ":", "\n", "# Identify the sentence index", "\n", "            ", "for", "j", ",", "token", "in", "enumerate", "(", "line", ")", ":", "\n", "              ", "if", "token", ".", "strip", "(", ")", "==", "\"sentence\"", ":", "\n", "                ", "sentence_index", "=", "j", "\n", "", "", "continue", "\n", "\n", "", "guid", "=", "i", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "-", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ",", "\n", "rand_vec", "=", "torch", ".", "normal", "(", "0", ",", "std_z", ",", "(", "1", ",", "128", ",", "256", ")", ")", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.SST2Dataset._get_label": [[608, 610], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.SST2Dataset.__getitem__": [[611, 617], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__init__": [[621, 624], ["train_adversarial_student_bert.ColaDataset._create_examples", "train_adversarial_student_bert.ColaDataset._read_tsv"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv"], ["def", "__init__", "(", "self", ",", "data_path", ",", "set_type", ")", ":", "\n", "        ", "'Initialization'", "\n", "self", ".", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "data_path", ")", ",", "set_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__len__": [[625, 628], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'Denotes the total number of samples'", "\n", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._read_tsv": [[629, 637], ["tensorflow.gfile.Open", "csv.reader", "lines.append"], "methods", ["None"], ["", "def", "_read_tsv", "(", "self", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._create_examples": [[638, 655], ["enumerate", "examples.append", "train_adversarial_student_bert.InputExample", "float", "float", "train_adversarial_student_bert.ColaDataset._get_label", "train_adversarial_student_bert.ColaDataset._get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "sentence_index", "=", "3", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "          ", "guid", "=", "i", "#\"%s-%s\" % (set_type, tokenization.convert_to_unicode(line[0]))", "\n", "if", "set_type", "==", "\"train\"", ":", "\n", "            ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "text_a", "=", "line", "[", "sentence_index", "]", "\n", "label", "=", "[", "float", "(", "line", "[", "1", "]", "==", "l", ")", "for", "l", "in", "self", ".", "_get_label", "(", ")", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset._get_label": [[656, 658], ["None"], "methods", ["None"], ["", "def", "_get_label", "(", "self", ")", ":", "\n", "        ", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.ColaDataset.__getitem__": [[659, 665], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "'Generates one sample of data'", "\n", "# Select sample", "\n", "example", "=", "self", ".", "examples", "[", "index", "]", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed": [[70, 76], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.mask_tokens": [[667, 689], ["inputs.clone", "torch.full", "torch.full", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "ValueError", "tokenizer.get_special_tokens_mask", "torch.tensor", "torch.tensor", "torch.tensor", "inputs.clone.eq", "torch.full.masked_fill_", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool.float", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.full", "torch.full", "torch.full"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "mlm_probability", ")", ":", "\n", "    ", "if", "tokenizer", ".", "mask_token", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"", "\n", ")", "\n", "\n", "", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "mlm_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "\n", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "1.0", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "return", "inputs", ",", "labels", ",", "masked_indices", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn": [[691, 720], ["tokenizer.batch_encode_plus", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "train_adversarial_student_bert.mask_tokens", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.clone"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.mask_tokens"], ["", "def", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "max_length", ")", ":", "\n", "    ", "def", "collate_fn", "(", "data", ")", ":", "\n", "        ", "text", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "[", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ")", "if", "example", ".", "text_b", "is", "not", "None", "else", "example", ".", "text_a", "for", "example", "in", "data", "]", ",", "max_length", "=", "max_length", ",", "truncation", "=", "True", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", ")", "\n", "\n", "input_ids", "=", "text", "[", "'input_ids'", "]", "\n", "\n", "token_type_ids", "=", "text", "[", "'token_type_ids'", "]", "\n", "attention_mask", "=", "text", "[", "'attention_mask'", "]", "\n", "\n", "guids", "=", "[", "example", ".", "guid", "for", "example", "in", "data", "]", "\n", "\n", "labels", "=", "[", "example", ".", "label", "for", "example", "in", "data", "]", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", ")", "\n", "token_type_ids", "=", "torch", ".", "tensor", "(", "token_type_ids", ")", "\n", "attention_mask", "=", "torch", ".", "tensor", "(", "attention_mask", ")", "\n", "\n", "input_ids_permuted", ",", "labels_permuted", ",", "mask_permuted", "=", "mask_tokens", "(", "input_ids", ".", "clone", "(", ")", ",", "tokenizer", ",", "args", ".", "p_value", ")", "\n", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ")", "\n", "\n", "guids", "=", "torch", ".", "tensor", "(", "guids", ")", "\n", "\n", "return", "guids", ",", "input_ids", ",", "attention_mask", ",", "labels", ",", "input_ids_permuted", ",", "mask_permuted", ",", "labels_permuted", ",", "token_type_ids", "\n", "\n", "", "return", "collate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.freeze_model": [[721, 724], ["model.parameters"], "function", ["None"], ["", "def", "freeze_model", "(", "model", ",", "freeze", ")", ":", "\n", "    ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "not", "freeze", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.sample_gumbel": [[727, 730], ["torch.rand", "torch.rand", "torch.rand", "torch.autograd.Variable", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], ["def", "sample_gumbel", "(", "shape", ",", "eps", "=", "1e-20", ")", ":", "\n", "    ", "U", "=", "torch", ".", "rand", "(", "shape", ",", "device", "=", "\"cuda\"", ")", "\n", "return", "-", "Variable", "(", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "eps", ")", "+", "eps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax_sample": [[731, 734], ["torch.softmax", "torch.log_softmax", "train_adversarial_student_bert.sample_gumbel", "logits.size"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.sample_gumbel"], ["", "def", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", ":", "\n", "    ", "y", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "+", "sample_gumbel", "(", "logits", ".", "size", "(", ")", ")", "\n", "return", "F", ".", "softmax", "(", "y", "/", "temperature", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax": [[736, 748], ["train_adversarial_student_bert.gumbel_softmax_sample", "gumbel_softmax_sample.size", "gumbel_softmax_sample.max", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "y_hard.view.scatter_", "y_hard.view.view", "ind.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax_sample"], ["", "def", "gumbel_softmax", "(", "logits", ",", "temperature", ")", ":", "\n", "    ", "\"\"\"\n    input: [*, n_class]\n    return: [*, n_class] an one-hot vector\n    \"\"\"", "\n", "y", "=", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", "\n", "shape", "=", "y", ".", "size", "(", ")", "\n", "_", ",", "ind", "=", "y", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "y_hard", "=", "torch", ".", "zeros_like", "(", "y", ")", ".", "view", "(", "-", "1", ",", "shape", "[", "-", "1", "]", ")", "\n", "y_hard", ".", "scatter_", "(", "1", ",", "ind", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "y_hard", "=", "y_hard", ".", "view", "(", "*", "shape", ")", "\n", "return", "(", "y_hard", "-", "y", ")", ".", "detach", "(", ")", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.divergence": [[752, 755], ["torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.log_softmax", "torch.softmax"], "function", ["None"], ["def", "divergence", "(", "student_logits", ",", "teacher_logits", ")", ":", "\n", "    ", "divergence", "=", "-", "torch", ".", "sum", "(", "F", ".", "log_softmax", "(", "student_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", "*", "F", ".", "softmax", "(", "teacher_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "# forward KL", "\n", "return", "torch", ".", "mean", "(", "divergence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train": [[757, 1055], ["torch.utils.data.DataLoader", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model.zero_grad", "generator.zero_grad", "tqdm.trange", "train_adversarial_student_bert.set_seed", "logger.info", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "generator.parameters", "generator.parameters", "amp.initialize", "amp.initialize", "amp.initialize", "len", "int", "tqdm.tqdm", "enumerate", "train_adversarial_student_bert.create_collate_fn", "model.train", "generator.train", "tuple", "generator", "train_adversarial_student_bert.gumbel_softmax", "input_ids.size", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as", "model.distilbert.embeddings.LayerNorm", "model.distilbert.embeddings.dropout", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.matmul", "torch.matmul", "torch.matmul", "masked_permuted.unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "masked_permuted.unsqueeze", "amp.initialize.", "model.distilbert.embeddings.position_embeddings", "model", "torch.mse_loss", "train_adversarial_student_bert.divergence", "transformers.AdamW.zero_grad", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "print", "tqdm.tqdm.close", "len", "model.named_parameters", "model.named_parameters", "any", "t.to", "amp.initialize.bert.embeddings.word_embeddings", "model.distilbert.embeddings.word_embeddings", "position_ids.unsqueeze().expand_as.unsqueeze", "divergence.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.zero_grad", "torch.optim.Adam.step", "transformers.get_linear_schedule_with_warmup.step", "divergence.item", "train_adversarial_student_bert.evaluate", "evaluate.items", "transformers.get_linear_schedule_with_warmup.get_lr", "json.dumps", "os.path.join", "shutil.rmtree", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "torch.save", "torch.save", "logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "any", "masked_permuted.unsqueeze", "masked_permuted.unsqueeze", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "generator.parameters", "torch.mse_loss", "torch.mse_loss", "train_adversarial_student_bert.divergence", "torch.mean", "torch.mean", "torch.mean", "divergence.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "torch.optim.Adam.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "amp.initialize.", "model", "student_logits.squeeze", "amp.initialize.", "model", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "model.parameters", "torch.sum", "torch.sum", "torch.sum", "torch.log_softmax"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.gumbel_softmax", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.divergence", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.divergence"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "eval_dataset", ",", "model", ",", "teacher_model", ",", "generator", ",", "tokenizer", ")", ":", "\n", "\n", "    ", "args", ".", "train_batch_size", "=", "args", ".", "per_device_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "train_sampler", "=", "data", ".", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "data", ".", "distributed", ".", "DistributedSampler", "(", "train_dataset", ")", "\n", "\n", "# train_sampler = data.SequentialSampler(train_dataset)", "\n", "\n", "\n", "train_dataloader", "=", "data", ".", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "collate_fn", "=", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "128", ")", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "2138", ",", "#args.warmup_steps,", "\n", "num_training_steps", "=", "t_total", "\n", ")", "\n", "# scheduler = get_linear_schedule_with_warmup(", "\n", "#     optimizer, num_warmup_steps= args.warmup_steps,", "\n", "#     num_training_steps=t_total", "\n", "# )", "\n", "\n", "\n", "\n", "\n", "gen_optimizer", "=", "AdamW", "(", "generator", ".", "parameters", "(", ")", ",", "lr", "=", "5e-7", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "gen_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "gen_optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "\n", "gen_pre_optimizer", "=", "AdamW", "(", "generator", ".", "parameters", "(", ")", ",", "lr", "=", "5e-6", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "gen_pre_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "gen_pre_optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "generator", ",", "[", "gen_optimizer", ",", "gen_pre_optimizer", "]", "=", "amp", ".", "initialize", "(", "generator", ",", "[", "gen_optimizer", ",", "gen_pre_optimizer", "]", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "teacher_model", "=", "amp", ".", "initialize", "(", "teacher_model", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_device_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "steps_train", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "max_met", "=", "-", "1", "\n", "max_met_step", "=", "-", "1", "\n", "model", ".", "zero_grad", "(", ")", "\n", "generator", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "\n", "n_generator_iter", "=", "10", "\n", "n_student_iter", "=", "100", "\n", "\n", "idx_pseudo", "=", "0", "\n", "n_repeat_batch", "=", "n_generator_iter", "+", "n_student_iter", "\n", "\n", "logger", ".", "info", "(", "\"  Pre-train Generator\"", ")", "\n", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "generator", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "input_ids", "=", "batch", "[", "1", "]", "\n", "attention_mask", "=", "batch", "[", "2", "]", "\n", "labels", "=", "batch", "[", "3", "]", "\n", "token_type_ids", "=", "batch", "[", "7", "]", "\n", "input_ids_permuted", "=", "batch", "[", "4", "]", "\n", "masked_permuted", "=", "batch", "[", "5", "]", "\n", "#Date augmentation", "\n", "\n", "outputs", "=", "generator", "(", "input_ids", "=", "input_ids_permuted", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "\n", "prediction_scores", "=", "outputs", "[", "0", "]", "\n", "\n", "prediction_scores", "=", "gumbel_softmax", "(", "prediction_scores", ",", "1.0", ")", "\n", "\n", "teacher_inp", "=", "torch", ".", "matmul", "(", "prediction_scores", ",", "teacher_model", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "*", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", "\n", "student_inp", "=", "torch", ".", "matmul", "(", "prediction_scores", ",", "model", ".", "distilbert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "*", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "teacher_inp", "=", "teacher_inp", "+", "(", "teacher_model", ".", "bert", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "*", "(", "1", "-", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", "\n", "student_inp", "=", "student_inp", "+", "(", "model", ".", "distilbert", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "*", "(", "1", "-", "masked_permuted", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", "\n", "\n", "\n", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "inputs_embeds", "=", "teacher_inp", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "\n", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "# (max_seq_length)", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "# (bs, max_seq_length)", "\n", "student_inp", "=", "student_inp", "+", "model", ".", "distilbert", ".", "embeddings", ".", "position_embeddings", "(", "position_ids", ")", "\n", "\n", "student_inp", "=", "model", ".", "distilbert", ".", "embeddings", ".", "LayerNorm", "(", "student_inp", ")", "# (bs, max_seq_length, dim)", "\n", "student_inp", "=", "model", ".", "distilbert", ".", "embeddings", ".", "dropout", "(", "student_inp", ")", "# (bs, max_seq_length, dim)", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "inputs_embeds", "=", "student_inp", ")", "[", "0", "]", "\n", "\n", "# generator training loss", "\n", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                ", "loss", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "divergence", "(", "student_logits", ",", "teacher_logits", ")", "\n", "\n", "\n", "", "if", "idx_pseudo", "%", "n_repeat_batch", "<", "n_generator_iter", ":", "\n", "                ", "loss", "=", "-", "loss", "\n", "\n", "gen_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                    ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "gen_optimizer", ")", "as", "scaled_loss", ":", "\n", "                        ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "gen_optimizer", ")", ",", "5", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "generator", ".", "parameters", "(", ")", ",", "5", ")", "\n", "\n", "", "gen_optimizer", ".", "step", "(", ")", "\n", "gen_scheduler", ".", "step", "(", ")", "\n", "\n", "", "elif", "idx_pseudo", "%", "n_repeat_batch", "<", "(", "n_generator_iter", "+", "n_student_iter", ")", ":", "\n", "\n", "                ", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                    ", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ")", "[", "0", "]", "\n", "loss_teach", "=", "F", ".", "mse_loss", "(", "student_logits", ",", "teacher_logits", ")", "\n", "loss_good", "=", "F", ".", "mse_loss", "(", "student_logits", ".", "squeeze", "(", "-", "1", ")", ",", "labels", ")", "\n", "", "else", ":", "\n", "                    ", "teacher_logits", "=", "teacher_model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "[", "0", "]", "\n", "student_logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ")", "[", "0", "]", "\n", "loss_teach", "=", "divergence", "(", "student_logits", ",", "teacher_logits", ")", "\n", "loss_good", "=", "torch", ".", "mean", "(", "-", "torch", ".", "sum", "(", "F", ".", "log_softmax", "(", "student_logits", "/", "KL_temperature", ",", "dim", "=", "-", "1", ")", "*", "labels", ",", "dim", "=", "-", "1", ")", ")", "\n", "# loss in paper", "\n", "", "loss", "=", "loss_good", "*", "(", "1", "/", "3", ")", "+", "(", "1", "/", "3", ")", "*", "loss", "+", "(", "1", "/", "3", ")", "*", "loss_teach", "\n", "\n", "# new loss", "\n", "#loss = loss_good * 0.5 + 0.5 * loss_teach", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                    ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                        ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "5", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "5", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "steps_train", "+=", "1", "\n", "\n", "\n", "", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                ", "logs", "=", "{", "}", "\n", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "results", "=", "evaluate", "(", "args", ",", "eval_dataset", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "tr_loss", "/", "steps_train", "if", "steps_train", ">", "0", "else", "0", "#(tr_loss - logging_loss) / args.logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "\n", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "acc_tasks", "=", "[", "'sst-2'", ",", "'rte'", ",", "'qnli'", ",", "'qqp'", ",", "'mrpc'", ",", "'wnli'", "]", "\n", "mnliacc_tasks", "=", "[", "'mnli'", "]", "\n", "mnlimmacc_tasks", "=", "[", "'mnli-mm'", "]", "\n", "mcc_tasks", "=", "[", "'cola'", "]", "\n", "accf1_tasks", "=", "[", "]", "#['qqp', 'mrpc']", "\n", "corr_tasks", "=", "[", "'sts-b'", "]", "\n", "current_met", "=", "0", "\n", "\n", "if", "args", ".", "task_name", "in", "acc_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_acc\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mnliacc_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_mnli/acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mnli/acc\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_mnli/acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mnlimmacc_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_mnli-mm/acc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "mcc_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_mcc\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_mcc\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_mcc\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "accf1_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_acc_and_f1\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_acc_and_f1\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_acc_and_f1\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "", "", "elif", "args", ".", "task_name", "in", "corr_tasks", ":", "\n", "                    ", "current_met", "=", "logs", "[", "\"eval_corr\"", "]", "\n", "if", "max_met", "<=", "logs", "[", "\"eval_corr\"", "]", ":", "\n", "                        ", "max_met", "=", "logs", "[", "\"eval_corr\"", "]", "\n", "max_met_step", "=", "global_step", "\n", "\n", "", "", "logs", "[", "\"eval_met_max\"", "]", "=", "max_met", "\n", "logs", "[", "\"eval_met_max_step\"", "]", "=", "max_met_step", "\n", "\n", "print", "(", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "global_step", "}", "}", ")", ")", "\n", "# save best model", "\n", "if", "current_met", "==", "max_met", ":", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"best\"", ")", "\n", "shutil", ".", "rmtree", "(", "output_dir", ",", "ignore_errors", "=", "True", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "idx_pseudo", "+=", "1", "\n", "global_step", "+=", "1", "\n", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.evaluate": [[1057, 1135], ["zip", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "transformers.glue_compute_metrics", "results.update", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "numpy.argmax", "numpy.argmax", "open", "logger.info", "sorted", "os.path.exists", "train_adversarial_student_bert.create_collate_fn", "isinstance", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.mean.mean().item", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "transformers.glue_compute_metrics.keys", "logger.info", "writer.write", "t.to", "torch.nn.DataParallel.", "torch.mse_loss", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.mean", "torch.mean", "torch.mean", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy", "str", "logits.squeeze", "torch.sum", "torch.sum", "torch.sum", "torch.mean.mean", "logits.detach().cpu", "labels.detach().cpu", "logits.detach().cpu", "labels.detach().cpu", "str", "logits.detach", "labels.detach", "logits.detach", "labels.detach"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.create_collate_fn"], ["", "def", "evaluate", "(", "args", ",", "eval_dataset", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "#(\"mnli\", \"mnli-mm\") if args.task_name == \"mnli\" else (args.task_name,)", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", ")", "#(args.output_dir, args.output_dir + \"-MM\") if args.task_name == \"mnli\" else (args.output_dir,)", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "#eval_dataset = load_and_cache_examples(args, eval_task, tokenizer, evaluate=True)", "\n", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_device_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "data", ".", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "data", ".", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "create_collate_fn", "(", "args", ",", "tokenizer", ",", "128", ")", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "input_ids", "=", "batch", "[", "1", "]", "\n", "attention_mask", "=", "batch", "[", "2", "]", "\n", "labels", "=", "batch", "[", "3", "]", "\n", "token_type_ids", "=", "batch", "[", "7", "]", "\n", "\n", "#if args.model_type != \"distilbert\":", "\n", "#    inputs[\"token_type_ids\"] = (", "\n", "#        batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None", "\n", "#    )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "logits", "=", "model", "(", "attention_mask", "=", "attention_mask", ",", "input_ids", "=", "input_ids", ")", "[", "0", "]", "\n", "if", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "                    ", "tmp_eval_loss", "=", "F", ".", "mse_loss", "(", "logits", ".", "squeeze", "(", "-", "1", ")", ",", "labels", ")", "\n", "", "else", ":", "\n", "                    ", "log_probs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "per_example_loss", "=", "-", "torch", ".", "sum", "(", "labels", "*", "log_probs", ",", "dim", "=", "-", "1", ")", "\n", "tmp_eval_loss", "=", "torch", ".", "mean", "(", "per_example_loss", ")", "\n", "\n", "", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "out_label_ids", "=", "np", ".", "argmax", "(", "out_label_ids", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "", "result", "=", "compute_metrics", "(", "eval_task", ",", "preds", ",", "out_label_ids", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.main": [[1137, 1329], ["transformers.HfArgumentParser", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.add_argument", "transformers.HfArgumentParser.parse_args_into_dataclasses", "argparse.Namespace", "logging.basicConfig", "logger.warning", "train_adversarial_student_bert.set_seed", "argparse.Namespace.task_name.lower", "processor.get_labels", "len", "print", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.BertTokenizer.from_pretrained", "transformers.BertForMaskedLM.from_pretrained", "AutoModelForSequenceClassification.from_pretrained.to", "AutoModelForSequenceClassification.from_pretrained.to", "BertForMaskedLM.from_pretrained.to", "logger.info", "train_adversarial_student_bert.freeze_model", "AutoModelForSequenceClassification.from_pretrained.eval", "print", "sum", "print", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.device", "torch.device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "transformers.AutoConfig.from_pretrained", "transformers.AutoConfig.from_pretrained", "logger.info", "torch.Linear", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "train_adversarial_student_bert.train", "logger.info", "vars", "vars", "vars", "vars", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "p.numel", "train_adversarial_student_bert.MNLIDataset", "train_adversarial_student_bert.MNLIDataset", "AutoModelForSequenceClassification.from_pretrained.parameters", "os.path.join", "os.path.join", "train_adversarial_student_bert.MNLIDataset", "train_adversarial_student_bert.MNLIDataset", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.join", "os.path.join", "train_adversarial_student_bert.SST2Dataset", "train_adversarial_student_bert.SST2Dataset", "os.path.join", "os.path.join", "train_adversarial_student_bert.RTEDataset", "train_adversarial_student_bert.RTEDataset", "os.path.join", "os.path.join", "train_adversarial_student_bert.QNLIDataset", "train_adversarial_student_bert.QNLIDataset", "os.path.join", "os.path.join", "train_adversarial_student_bert.QQPDataset", "train_adversarial_student_bert.QQPDataset", "os.path.join", "os.path.join", "train_adversarial_student_bert.MRPCDataset", "train_adversarial_student_bert.MRPCDataset", "os.path.join", "os.path.join", "train_adversarial_student_bert.ColaDataset", "train_adversarial_student_bert.ColaDataset", "os.path.join", "os.path.join", "train_adversarial_student_bert.WNLIDataset", "train_adversarial_student_bert.WNLIDataset", "os.path.join", "os.path.join", "train_adversarial_student_bert.STSBDataset", "train_adversarial_student_bert.STSBDataset", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.set_seed", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.data.glue.GLUEv2Processor.get_labels", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.freeze_model", "home.repos.pwc.inspect_result.huawei-noah_kd-nlp.MATE-KD.train_adversarial_student_bert.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataProcessingArguments", ",", "TrainingArguments", ")", ")", "\n", "\n", "#parser.add_argument(", "\n", "#\t\"--bert_pretrained_path\",", "\n", "#\ttype=str,", "\n", "#\trequired=True,", "\n", "#\thelp=\"The path corresponding to the pre-trained BERT model.\"", "\n", "#)", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--p_value\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.3", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Enable if you initialize student with an MNLI checkpoint for tasks such as RTE and STS-B.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_mnli_ckpt\"", ",", "\n", "type", "=", "bool", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Enable if you initialize student with an MNLI checkpoint for tasks such as RTE and STS-B.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_path\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The path corresponding to the teacher BERT model.\"", "\n", ")", "\n", "\n", "model_args", ",", "dataprocessing_args", ",", "training_args", ",", "rest_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "vars", "(", "model_args", ")", ",", "**", "vars", "(", "dataprocessing_args", ")", ",", "**", "vars", "(", "training_args", ")", ",", "**", "vars", "(", "rest_args", ")", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "#args.n_gpu = 1", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "print", "(", "num_labels", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", ")", "\n", "\n", "#args.model_type = args.model_type.lower()", "\n", "if", "not", "args", ".", "use_mnli_ckpt", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "3", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "\n", "config", ".", "num_labels", "=", "3", "\n", "\n", "", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "#AutoModelForSequenceClassification.from_pretrained(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "if", "args", ".", "use_mnli_ckpt", ":", "\n", "        ", "config", ".", "num_labels", "=", "num_labels", "\n", "logger", ".", "info", "(", "'Reintializing model classifier layer...'", ")", "\n", "model", ".", "num_labels", "=", "num_labels", "\n", "model", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "#BertClassificationHead(config)", "\n", "\n", "\n", "", "teacher_config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "teacher_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", ")", "\n", "teacher_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "teacher_path", ",", "\n", ")", "\n", "teacher_model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "#AutoModelForSequenceClassification.from_pretrained(", "\n", "args", ".", "teacher_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "teacher_config", "\n", ")", "\n", "\n", "gen_bert_tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert_models/uncased_L-4_H-256_A-4'", ")", "#, cache_dir=\"downloaded\")", "\n", "generator", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "'bert_models/uncased_L-4_H-256_A-4'", ")", "#, cache_dir=\"downloaded\")", "\n", "\n", "#model = BertForSequenceClassification(config)", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "teacher_model", ".", "to", "(", "args", ".", "device", ")", "\n", "generator", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "freeze_model", "(", "teacher_model", ",", "True", ")", "\n", "teacher_model", ".", "eval", "(", ")", "\n", "\n", "print", "(", "model", ")", "\n", "model_total_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "print", "(", "\"Total trainable parameters:\"", ",", "model_total_params", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "training_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev_matched.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"mnli-mm\"", ":", "\n", "            ", "training_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev_mismatched.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"sst-2\"", ":", "\n", "            ", "training_set", "=", "SST2Dataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "SST2Dataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"rte\"", ":", "\n", "            ", "training_set", "=", "RTEDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "RTEDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"qnli\"", ":", "\n", "            ", "training_set", "=", "QNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "QNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"qqp\"", ":", "\n", "            ", "training_set", "=", "QQPDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "QQPDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"mrpc\"", ":", "\n", "            ", "training_set", "=", "MRPCDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "MRPCDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"cola\"", ":", "\n", "            ", "training_set", "=", "ColaDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "ColaDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"wnli\"", ":", "\n", "            ", "training_set", "=", "WNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "WNLIDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "elif", "args", ".", "task_name", "==", "\"sts-b\"", ":", "\n", "            ", "training_set", "=", "STSBDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"train.tsv\"", ")", ",", "\"train\"", ")", "\n", "eval_set", "=", "STSBDataset", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"dev.tsv\"", ")", ",", "\"test\"", ")", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "training_set", ",", "eval_set", ",", "model", ",", "teacher_model", ",", "generator", ",", "teacher_tokenizer", ")", "\n", "logger", ".", "info", "(", "\"  global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n"]]}