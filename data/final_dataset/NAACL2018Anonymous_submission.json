{"home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.None.config.Config.__init__": [[6, 127], ["os.path.join", "len", "len", "open", "enumerate", "open", "enumerate", "len", "len", "len", "len", "os.path.join", "os.path.join", "pickle.load", "pickle.load", "pickle.load", "open", "open", "open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "model_name", ",", "mode", "=", "\"QG\"", ")", ":", "\n", "\n", "        ", "assert", "mode", "in", "[", "\"QG\"", ",", "\"KBEMBED\"", "]", "\n", "\n", "self", ".", "CHECKPOINTS_PATH", "=", "os", ".", "path", ".", "join", "(", "\"./checkpoints/\"", "+", "model_name", ",", "model_name", ")", "\n", "\n", "# Triples:", "\n", "self", ".", "TRIPLELENGTH", "=", "3", "# (s,p,o) # make 4 to extend to quads", "\n", "self", ".", "ENTITIESLENGTH", "=", "2", "\n", "self", ".", "PREDICATESLENGTH", "=", "1", "\n", "self", ".", "USE_PRETRAINED_KB_EMBEDDINGS", "=", "False", "\n", "\n", "# knowledge base embeddings training params", "\n", "if", "mode", "==", "\"KBEMBED\"", ":", "\n", "\n", "            ", "self", ".", "KB_EMBED_VOCAB_PATH", "=", "'./data/kb_embeddings_data'", "\n", "\n", "# counting length of entity and properties vocab", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "KB_EMBED_VOCAB_PATH", ",", "\"entity2id.txt\"", ")", ")", "as", "f", ":", "\n", "                ", "for", "ec", ",", "l", "in", "enumerate", "(", "f", ")", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "KB_EMBED_VOCAB_PATH", ",", "\"relation2id.txt\"", ")", ")", "as", "f", ":", "\n", "                ", "for", "pc", ",", "l", "in", "enumerate", "(", "f", ")", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "self", ".", "ENTITIES_VOCAB", "=", "ec", "-", "1", "# Size of the encoding vocabulary  # -2  count of first line and remove of header", "\n", "self", ".", "PREDICATES_VOCAB", "=", "pc", "-", "1", "\n", "\n", "self", ".", "PICKLE_ENTITIES_VOCAB", "=", "len", "(", "data", ".", "entityvocab", ")", "# sizes of vocab to pickle (pick the first # and save) (practically the entities and predicates that only appear in simple questions)", "\n", "self", ".", "PICKLE_PREDICATES_VOCAB", "=", "len", "(", "data", ".", "propertyvocab", ")", "\n", "\n", "# KBEmbeddings TransE configurations", "\n", "self", ".", "L1_flag", "=", "True", "\n", "self", ".", "nbatches", "=", "50", "\n", "self", ".", "TRANSX_EPOCHS", "=", "10000", "\n", "self", ".", "margin", "=", "1.0", "\n", "\n", "self", ".", "ENTITIES_EMBEDDING_SIZE", "=", "100", "\n", "self", ".", "PREDICATES_EMBEDDING_SIZE", "=", "100", "\n", "\n", "self", ".", "LOG_FREQUENCY", "=", "20", "\n", "self", ".", "SAVE_FREQUENCY", "=", "300", "\n", "\n", "# MODE QUESTION GENERATION", "\n", "", "else", ":", "\n", "\n", "            ", "if", "self", ".", "USE_PRETRAINED_KB_EMBEDDINGS", ":", "\n", "\n", "                ", "self", ".", "PRETRAINED_ENTITIES_EMBEDDINGS_PATH", "=", "\"./checkpoints/transe/ent_embeddings.pkl\"", "\n", "self", ".", "PRETRAINED_PREDICATES_EMBEDDINGS_PATH", "=", "\"./checkpoints/transe/rel_embeddings.pkl\"", "\n", "# infer size from given pickle file", "\n", "self", ".", "ENTITIES_VOCAB", ",", "self", ".", "ENTITIES_EMBEDDING_SIZE", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "PRETRAINED_ENTITIES_EMBEDDINGS_PATH", ")", ")", ".", "shape", "\n", "self", ".", "PREDICATES_VOCAB", ",", "self", ".", "PREDICATES_EMBEDDING_SIZE", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "PRETRAINED_PREDICATES_EMBEDDINGS_PATH", ")", ")", ".", "shape", "\n", "self", ".", "TRAIN_KB_EMBEDDINGS", "=", "False", "# make preloaded embeddings fixed", "\n", "\n", "# for now has to be the same size as the triples embedding size", "\n", "# because all are being merged into one attention memory", "\n", "self", ".", "TYPES_RNN_HIDDEN_SIZE", "=", "self", ".", "ENTITIES_EMBEDDING_SIZE", "\n", "\n", "", "else", ":", "\n", "\n", "# define them manually", "\n", "                ", "self", ".", "ENTITIES_EMBEDDING_SIZE", "=", "200", "\n", "self", ".", "PREDICATES_EMBEDDING_SIZE", "=", "200", "\n", "self", ".", "ENTITIES_VOCAB", "=", "len", "(", "data", ".", "entityvocab", ")", "# Size of the encoding vocabulary", "\n", "self", ".", "PREDICATES_VOCAB", "=", "len", "(", "data", ".", "propertyvocab", ")", "\n", "self", ".", "TRAIN_KB_EMBEDDINGS", "=", "True", "\n", "# for now has to be the same size as the triples embedding size", "\n", "# because all are being merged into one attention memory", "\n", "self", ".", "TYPES_RNN_HIDDEN_SIZE", "=", "200", "\n", "\n", "", "self", ".", "TRIPLES_EMBEDDING_SIZE", "=", "self", ".", "ENTITIES_EMBEDDING_SIZE", "\n", "\n", "\n", "# Types: a.k.a Words", "\n", "self", ".", "USE_PRETRAINED_WORD_EMBEDDINGS", "=", "False", "\n", "self", ".", "NUMBER_OF_TEXTUAL_EVIDENCES", "=", "3", "# Subject type, Object Type, Predicate Type", "\n", "\n", "if", "self", ".", "USE_PRETRAINED_WORD_EMBEDDINGS", ":", "\n", "\n", "                ", "self", ".", "PRETRAINED_WORD_EMBEDDINGS_PATH", "=", "\"./data/wordembeddings/glove100d.pkl\"", "\n", "self", ".", "TYPES_ENCODER_VOCAB", ",", "self", ".", "TYPES_EMBEDDING_SIZE", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "PRETRAINED_WORD_EMBEDDINGS_PATH", ")", ")", ".", "shape", "\n", "self", ".", "TRAIN_WORD_EMBEDDINGS", "=", "True", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "TYPES_ENCODER_VOCAB", "=", "len", "(", "data", ".", "wordvocab", ")", "\n", "self", ".", "TYPES_EMBEDDING_SIZE", "=", "50", "\n", "\n", "# Decoder:", "\n", "", "self", ".", "NUM_LAYERS", "=", "1", "\n", "\n", "self", ".", "COUPLE_ENCODER_DECODER_WORD_EMBEDDINGS", "=", "True", "\n", "\n", "if", "self", ".", "COUPLE_ENCODER_DECODER_WORD_EMBEDDINGS", ":", "\n", "                ", "self", ".", "DECODER_EMBEDDING_SIZE", "=", "self", ".", "TYPES_EMBEDDING_SIZE", "\n", "self", ".", "DECODER_VOCAB_SIZE", "=", "self", ".", "TYPES_ENCODER_VOCAB", "\n", "", "else", ":", "\n", "                ", "self", ".", "DECODER_EMBEDDING_SIZE", "=", "50", "\n", "self", ".", "DECODER_VOCAB_SIZE", "=", "len", "(", "data", ".", "wordvocab", ")", "# Size of the decoding vocabulary", "\n", "\n", "\n", "", "self", ".", "DECODER_RNN_HIDDEN_SIZE", "=", "500", "\n", "\n", "# Attention:", "\n", "self", ".", "USE_ATTENTION", "=", "True", "\n", "self", ".", "ATTENTION_HIDDEN_SIZE", "=", "self", ".", "TRIPLES_EMBEDDING_SIZE", "\n", "\n", "# Inference", "\n", "self", ".", "DECODER_START_TOKEN_ID", "=", "2", "# numbers from the vocab file", "\n", "self", ".", "DECODER_END_TOKEN_ID", "=", "3", "# numbers from the vocab file", "\n", "self", ".", "MAX_DECODE_LENGTH", "=", "12", "# Arbitary number based on data analysis  # only used in inference time", "\n", "\n", "# Training Params", "\n", "self", ".", "BATCH_SIZE", "=", "500", "\n", "self", ".", "LR", "=", "0.001", "\n", "self", ".", "MAX_GRAD_NORM", "=", "0.1", "\n", "self", ".", "MAX_EPOCHS", "=", "250", "\n", "self", ".", "LOG_FREQUENCY", "=", "20", "\n", "self", ".", "SAVE_FREQUENCY", "=", "200", "# save per global step", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__init__": [[27, 38], ["print", "triples2seq.Triple2SeqModel.__create_placeholders", "triples2seq.Triple2SeqModel.__create_triple_encoder", "triples2seq.Triple2SeqModel.__create_decoder"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_placeholders", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_triple_encoder", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder"], ["def", "__init__", "(", "self", ",", "config", ",", "mode", "=", "'training'", ")", ":", "\n", "\n", "        ", "print", "(", "'Initializing new seq 2 seq model'", ")", "\n", "\n", "assert", "mode", "in", "[", "'training'", ",", "'evaluation'", ",", "'inference'", "]", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "__create_placeholders", "(", ")", "\n", "# self.__create_encoder()", "\n", "self", ".", "__create_triple_encoder", "(", ")", "\n", "self", ".", "__create_decoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__create_placeholders": [[39, 74], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.shape", "tensorflow.reduce_max"], "methods", ["None"], ["", "def", "__create_placeholders", "(", "self", ")", ":", "\n", "\n", "# encoder_inputs : size [batch_size, triples_size(normally 3)]", "\n", "        ", "self", ".", "encoder_entities_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "self", ".", "config", ".", "ENTITIESLENGTH", "]", ",", "name", "=", "\"encoder_entities_inputs\"", ")", "\n", "self", ".", "encoder_predicates_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "self", ".", "config", ".", "PREDICATESLENGTH", "]", ",", "name", "=", "\"encoder_predicates_inputs\"", ")", "\n", "self", ".", "encoder_predicates_direction", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"encoder_predicates_direction\"", ")", "\n", "\n", "self", ".", "batch_size", "=", "tf", ".", "shape", "(", "self", ".", "encoder_entities_inputs", ")", "[", "0", "]", "\n", "\n", "# Decoder placeholders:", "\n", "# these are the raw inputs to the decoder:", "\n", "self", ".", "decoder_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"decoder_inputs\"", ")", "\n", "self", ".", "decoder_inputs_length", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ",", "name", "=", "'decoder_inputs_length'", ")", "\n", "\n", "if", "self", ".", "mode", "==", "\"training\"", ":", "\n", "\n", "            ", "self", ".", "decoder_inputs_train", "=", "self", ".", "decoder_inputs", "\n", "\n", "# for training our targets are decoder inputs shifted by one (to ignore the <s> symbol)", "\n", "# as shown in figure https://www.tensorflow.org/images/basic_seq2seq.png", "\n", "self", ".", "decoder_targets_train", "=", "self", ".", "decoder_inputs", "[", ":", ",", "1", ":", "]", "\n", "\n", "# decoder_inputs_length_train: [batch_size x 1]", "\n", "self", ".", "decoder_inputs_length_train", "=", "self", ".", "decoder_inputs_length", "\n", "self", ".", "decoder_targets_length_train", "=", "self", ".", "decoder_inputs_length", "-", "1", "\n", "\n", "# calculating max_decoder_length", "\n", "self", ".", "decoder_max_length", "=", "tf", ".", "reduce_max", "(", "self", ".", "decoder_targets_length_train", ")", "\n", "\n", "", "elif", "self", ".", "mode", "==", "\"inference\"", ":", "\n", "# at inference time there's no decoder input so we set the Decode length to a maximum.", "\n", "            ", "self", ".", "decoder_max_length", "=", "self", ".", "config", ".", "MAX_DECODE_LENGTH", "\n", "\n", "# global step", "\n", "", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "'global_step'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__create_triple_encoder": [[75, 126], ["print", "time.time", "print", "tensorflow.variable_scope", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.concat", "tensorflow.concat", "pickle.load", "tensorflow.Variable", "pickle.load", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.unstack", "time.time", "open", "open", "triples2seq.Triple2SeqModel.__helper__initializer", "triples2seq.Triple2SeqModel.__helper__initializer"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__helper__initializer", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__helper__initializer"], ["", "def", "__create_triple_encoder", "(", "self", ")", ":", "\n", "        ", "print", "(", "'building encoder ...'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder'", ")", ":", "\n", "# Create Embeddings Weights", "\n", "\n", "            ", "if", "self", ".", "config", ".", "USE_PRETRAINED_KB_EMBEDDINGS", ":", "\n", "\n", "                ", "ent_kb_emb", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "config", ".", "PRETRAINED_ENTITIES_EMBEDDINGS_PATH", ")", ")", "\n", "self", ".", "encoder_entities_embeddings", "=", "tf", ".", "Variable", "(", "ent_kb_emb", ",", "name", "=", "\"entities_embeddings\"", ",", "trainable", "=", "self", ".", "config", ".", "TRAIN_KB_EMBEDDINGS", ")", "\n", "\n", "pred_kb_emb", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "config", ".", "PRETRAINED_PREDICATES_EMBEDDINGS_PATH", ")", ")", "\n", "self", ".", "encoder_predicates_embeddings", "=", "tf", ".", "Variable", "(", "pred_kb_emb", ",", "name", "=", "\"predicates_embeddings\"", ",", "\n", "trainable", "=", "self", ".", "config", ".", "TRAIN_KB_EMBEDDINGS", ")", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "self", ".", "encoder_entities_embeddings", "=", "tf", ".", "get_variable", "(", "\"entities_embeddings\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "ENTITIES_VOCAB", ",", "\n", "self", ".", "config", ".", "ENTITIES_EMBEDDING_SIZE", "]", ",", "\n", "initializer", "=", "self", ".", "__helper__initializer", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "self", ".", "encoder_predicates_embeddings", "=", "tf", ".", "get_variable", "(", "\"predicates_embeddings\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "PREDICATES_VOCAB", ",", "\n", "self", ".", "config", ".", "PREDICATES_EMBEDDING_SIZE", "]", ",", "\n", "initializer", "=", "self", ".", "__helper__initializer", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "# embedding the encoder inputs", "\n", "# encoder_inputs is of size [Batch size x 3]", "\n", "# encoder_inputs_embedded is of size [Batch size x 3 x TRIPLES_EMBEDDING_SIZE]", "\n", "", "self", ".", "encoder_entities_inputs_embedded", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "encoder_entities_embeddings", ",", "\n", "self", ".", "encoder_entities_inputs", ")", "\n", "self", ".", "encoder_predicates_inputs_embedded", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "encoder_predicates_embeddings", ",", "\n", "self", ".", "encoder_predicates_inputs", ")", "\n", "\n", "direction", "=", "tf", ".", "expand_dims", "(", "self", ".", "encoder_predicates_direction", ",", "axis", "=", "1", ")", "\n", "direction", "=", "tf", ".", "expand_dims", "(", "direction", ",", "axis", "=", "2", ")", "\n", "\n", "self", ".", "encoder_predicates_inputs_embedded", "=", "tf", ".", "multiply", "(", "self", ".", "encoder_predicates_inputs_embedded", ",", "direction", ")", "\n", "\n", "self", ".", "encoder_triples_inputs_embedded", "=", "tf", ".", "concat", "(", "\n", "(", "self", ".", "encoder_entities_inputs_embedded", ",", "self", ".", "encoder_predicates_inputs_embedded", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# Encode input triple into a vector", "\n", "# encoder_state: [batch_size, cell_output_size]", "\n", "self", ".", "encoder_triples_last_state", "=", "tf", ".", "concat", "(", "tf", ".", "unstack", "(", "self", ".", "encoder_triples_inputs_embedded", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "print", "(", "'Building encoder in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__build_single_rnn_cell": [[127, 138], ["tensorflow.nn.rnn_cell.GRUCell"], "methods", ["None"], ["", "def", "__build_single_rnn_cell", "(", "self", ",", "hidden_size", ")", ":", "\n", "\n", "        ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "hidden_size", ")", "\n", "\n", "# if self.use_dropout:", "\n", "#     cell = DropoutWrapper(cell, dtype=self.dtype,", "\n", "#                           output_keep_prob=self.keep_prob_placeholder, )", "\n", "# if self.use_residual:", "\n", "#     cell = ResidualWrapper(cell)", "\n", "\n", "return", "cell", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__create_decoder_cell": [[139, 149], ["tensorflow.nn.rnn_cell.GRUCell", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.python.layers.core.Dense", "tensorflow.python.layers.core.Dense."], "methods", ["None"], ["", "def", "__create_decoder_cell", "(", "self", ")", ":", "\n", "\n", "        ", "gru", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "\n", "\n", "self", ".", "decoder_cell_list", "=", "[", "gru", "]", "*", "self", ".", "config", ".", "NUM_LAYERS", "\n", "\n", "self", ".", "decoder_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "self", ".", "decoder_cell_list", ")", "\n", "\n", "decoder_hidden_state_reshape", "=", "Dense", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "# reshape last state of encoder to decoder hidden size", "\n", "self", ".", "decoder_initial_state", "=", "(", "decoder_hidden_state_reshape", "(", "self", ".", "encoder_triples_last_state", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__create_decoder_attention_cell": [[150, 191], ["tensorflow.contrib.seq2seq.BahdanauAttention", "triples2seq.Triple2SeqModel.__build_single_rnn_cell", "tensorflow.python.layers.core.Dense", "tensorflow.contrib.seq2seq.AttentionWrapper", "tensorflow.nn.rnn_cell.MultiRNNCell", "triples2seq.Triple2SeqModel.decoder_cell_list[].zero_state", "tensorflow.python.layers.core.Dense."], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__build_single_rnn_cell"], ["", "def", "__create_decoder_attention_cell", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        create decoder RNN with attention\n        :return:\n        \"\"\"", "\n", "\n", "self", ".", "attention_mechanism", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BahdanauAttention", "(", "\n", "num_units", "=", "self", ".", "config", ".", "TRIPLES_EMBEDDING_SIZE", ",", "# the depth of the Attention layer", "\n", "memory", "=", "self", ".", "encoder_triples_inputs_embedded", ",", "\n", "name", "=", "\"Attention\"", "\n", ")", "\n", "\n", "# create decoder cell:", "\n", "gru", "=", "self", ".", "__build_single_rnn_cell", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "\n", "self", ".", "decoder_cell_list", "=", "[", "gru", "]", "*", "self", ".", "config", ".", "NUM_LAYERS", "\n", "\n", "decoder_hidden_state_reshape", "=", "Dense", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "# reshape last state of encoder to decoder hidden size", "\n", "self", ".", "decoder_cell_list", "[", "-", "1", "]", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "AttentionWrapper", "(", "\n", "cell", "=", "self", ".", "decoder_cell_list", "[", "-", "1", "]", ",", "\n", "attention_layer_size", "=", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ",", "# the output hidden size of the last decoder", "\n", "attention_mechanism", "=", "self", ".", "attention_mechanism", ",", "\n", "initial_cell_state", "=", "decoder_hidden_state_reshape", "(", "self", ".", "encoder_triples_last_state", ")", ",", "\n", "alignment_history", "=", "False", ",", "\n", "name", "=", "\"Attention_Wrapper\"", "\n", ")", "\n", "\n", "self", ".", "decoder_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "self", ".", "decoder_cell_list", ")", "\n", "\n", "# To be compatible with AttentionWrapper, the encoder last state", "\n", "# of the top layer should be converted into the AttentionWrapperState form", "\n", "# We can easily do this by calling AttentionWrapper.zero_state", "\n", "\n", "# self.decoder_initial_state = self.encoder_last_state", "\n", "\n", "init_state", "=", "self", ".", "decoder_cell_list", "[", "-", "1", "]", ".", "zero_state", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "# a tuple because decode initial state has to take a tuple", "\n", "self", ".", "decoder_initial_state", "=", "(", "init_state", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__create_decoder": [[192, 286], ["print", "time.time", "print", "tensorflow.variable_scope", "tensorflow.python.layers.core.Dense", "tensorflow.python.layers.core.Dense", "tensorflow.get_variable", "triples2seq.Triple2SeqModel.__create_decoder_attention_cell", "tensorflow.nn.embedding_lookup", "tensorflow.contrib.seq2seq.TrainingHelper", "tensorflow.contrib.seq2seq.BasicDecoder", "tensorflow.contrib.seq2seq.dynamic_decode", "triples2seq.Triple2SeqModel.__create_loss", "triples2seq.Triple2SeqModel.__create_optimizer", "time.time", "triples2seq.Triple2SeqModel.__helper__initializer", "tensorflow.contrib.seq2seq.GreedyEmbeddingHelper", "print", "tensorflow.contrib.seq2seq.BasicDecoder", "tensorflow.contrib.seq2seq.dynamic_decode", "tensorflow.expand_dims", "tensorflow.ones", "tensorflow.nn.embedding_lookup"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder_attention_cell", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_loss", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_optimizer", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__helper__initializer"], ["", "def", "__create_decoder", "(", "self", ")", ":", "\n", "\n", "        ", "print", "(", "\"building decoder and attention ..\"", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'decoder'", ")", ":", "\n", "\n", "# input and output layers to the decoder", "\n", "            ", "decoder_input_layer", "=", "Dense", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "'decoder_input_projection'", ")", "\n", "decoder_output_layer", "=", "Dense", "(", "self", ".", "config", ".", "DECODER_VOCAB_SIZE", ",", "name", "=", "\"decoder_output_projection\"", ")", "\n", "\n", "# creating decoder embedding weights", "\n", "self", ".", "decoder_embeddings", "=", "tf", ".", "get_variable", "(", "\"decoder_embeddings\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "DECODER_VOCAB_SIZE", ",", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", "]", ",", "\n", "initializer", "=", "self", ".", "__helper__initializer", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "\n", "self", ".", "__create_decoder_attention_cell", "(", ")", "\n", "# self.__create_decoder_cell()", "\n", "\n", "######################################", "\n", "# Build the decoder in training mode #", "\n", "######################################", "\n", "if", "self", ".", "mode", "==", "'training'", ":", "\n", "\n", "# changing inputs to embeddings and then through the input projection", "\n", "# decoder_inputs_embedded: [batch_size, max_time_step + 1, embedding_size]", "\n", "                ", "self", ".", "decoder_inputs_embedded", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "decoder_embeddings", ",", "\n", "ids", "=", "self", ".", "decoder_inputs_train", ")", "\n", "\n", "# self.decoder_inputs_embedded = decoder_input_layer(self.decoder_inputs_embedded)", "\n", "\n", "# Helper to feed inputs to the training:", "\n", "\n", "self", ".", "training_helper", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "TrainingHelper", "(", "\n", "inputs", "=", "self", ".", "decoder_inputs_embedded", ",", "\n", "sequence_length", "=", "self", ".", "decoder_inputs_length_train", ",", "\n", "name", "=", "'training_helper'", ")", "\n", "\n", "# Build the decoder", "\n", "self", ".", "training_decoder", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BasicDecoder", "(", "\n", "cell", "=", "self", ".", "decoder_cell", ",", "\n", "helper", "=", "self", ".", "training_helper", ",", "\n", "initial_state", "=", "self", ".", "decoder_initial_state", ",", "\n", "output_layer", "=", "decoder_output_layer", ")", "\n", "\n", "# decoder outputs are of type tf.contrib.seq2seq.BasicDecoderOutput", "\n", "# has two fields `rnn_output` and `sample_id`", "\n", "\n", "self", ".", "decoder_outputs_train", ",", "self", ".", "decoder_last_state_train", ",", "self", ".", "decoder_outputs_length_decode_train", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "dynamic_decode", "(", "\n", "decoder", "=", "self", ".", "training_decoder", ",", "\n", "impute_finished", "=", "True", ",", "\n", "maximum_iterations", "=", "self", ".", "decoder_max_length", "\n", ")", "\n", "\n", "# In the training mode only create LOSS and Optimizer", "\n", "\n", "self", ".", "__create_loss", "(", ")", "\n", "self", ".", "__create_optimizer", "(", ")", "\n", "\n", "######################################", "\n", "# Build the decoder in sampling mode #", "\n", "######################################", "\n", "", "elif", "self", ".", "mode", "==", "'inference'", ":", "\n", "\n", "                ", "start_tokens", "=", "tf", ".", "ones", "(", "[", "self", ".", "batch_size", ",", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "*", "self", ".", "config", ".", "DECODER_START_TOKEN_ID", "\n", "end_token", "=", "self", ".", "config", ".", "DECODER_END_TOKEN_ID", "\n", "\n", "def", "decoder_inputs_embedder", "(", "inputs", ")", ":", "\n", "                    ", "return", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "decoder_embeddings", ",", "inputs", ")", "\n", "\n", "# end token is needed so the helper stop feeding new inputs again once the <end> mark is shown.", "\n", "# expected decoder output will be a set of <end> <end> <end> <end> words until the max sequence length is shown.", "\n", "", "decoder_helper", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "GreedyEmbeddingHelper", "(", "decoder_inputs_embedder", ",", "start_tokens", ",", "end_token", ")", "\n", "\n", "# Basic decoder performs greedy decoding at each time step", "\n", "print", "(", "\"Building Greedy Decoder ...\"", ")", "\n", "\n", "inference_decoder", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BasicDecoder", "(", "cell", "=", "self", ".", "decoder_cell", ",", "\n", "helper", "=", "decoder_helper", ",", "\n", "initial_state", "=", "self", ".", "decoder_initial_state", ",", "\n", "output_layer", "=", "decoder_output_layer", ")", "\n", "\n", "self", ".", "decoder_outputs_inference", ",", "self", ".", "decoder_last_state_inference", ",", "self", ".", "decoder_outputs_length_inference", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "dynamic_decode", "(", "\n", "decoder", "=", "inference_decoder", ",", "\n", "output_time_major", "=", "False", ",", "\n", "maximum_iterations", "=", "self", ".", "decoder_max_length", "\n", ")", "\n", "\n", "self", ".", "decoder_pred_inference", "=", "tf", ".", "expand_dims", "(", "self", ".", "decoder_outputs_inference", ".", "sample_id", ",", "-", "1", ")", "\n", "\n", "", "", "print", "(", "'Building decoder in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__create_loss": [[287, 308], ["print", "time.time", "tensorflow.identity", "tensorflow.argmax", "tensorflow.sequence_mask", "tensorflow.contrib.seq2seq.sequence_loss", "print", "time.time"], "methods", ["None"], ["", "def", "__create_loss", "(", "self", ")", ":", "\n", "\n", "        ", "print", "(", "'Creating loss...'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "self", ".", "decoder_logits", "=", "tf", ".", "identity", "(", "self", ".", "decoder_outputs_train", ".", "rnn_output", ",", "name", "=", "\"decoder_logits\"", ")", "\n", "self", ".", "decoder_pred", "=", "tf", ".", "argmax", "(", "self", ".", "decoder_logits", ",", "axis", "=", "-", "1", ",", "name", "=", "\"decoder_pred\"", ")", "\n", "\n", "# masking the sequence in order to calculate the error according to the calculated", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "self", ".", "decoder_inputs_length_train", ",", "maxlen", "=", "self", ".", "decoder_max_length", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "name", "=", "\"masks\"", ")", "\n", "\n", "# Control loss dimensions with `average_across_timesteps` and `average_across_batch`", "\n", "self", ".", "loss", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "sequence_loss", "(", "logits", "=", "self", ".", "decoder_logits", ",", "\n", "targets", "=", "self", ".", "decoder_targets_train", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "average_across_batch", "=", "False", ",", "\n", "weights", "=", "mask", ",", "\n", "name", "=", "\"batch_loss\"", ")", "\n", "\n", "print", "(", "'Building loss in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__create_optimizer": [[309, 333], ["print", "time.time", "tensorflow.train.exponential_decay", "tensorflow.train.RMSPropOptimizer", "tensorflow.trainable_variables", "tensorflow.gradients", "tensorflow.clip_by_global_norm", "triples2seq.Triple2SeqModel.opt.apply_gradients", "print", "zip", "time.time"], "methods", ["None"], ["", "def", "__create_optimizer", "(", "self", ")", ":", "\n", "        ", "print", "(", "'creating optimizer...'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "config", ".", "LR", ",", "self", ".", "global_step", ",", "200", ",", "0.97", ",", "staircase", "=", "True", ")", "\n", "self", ".", "opt", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "learning_rate", ")", "\n", "\n", "# learning_rate = tf.train.exponential_decay(self.config.LR, self.global_step, 100, 0.96, staircase=True)", "\n", "\n", "# self.opt = tf.train.RMSPropOptimizer(learning_rate=learning_rate)", "\n", "# self.opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)", "\n", "\n", "# normalize the gradients of a parameter vector when its L2 norm exceeds a certain threshold according to", "\n", "trainable_params", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "# calculate gradients of the loss given all the trainable parameters", "\n", "gradients", "=", "tf", ".", "gradients", "(", "self", ".", "loss", ",", "trainable_params", ")", "\n", "\n", "# Gradient clipping: new_gradients = gradients * threshold / l2_norm(gradients)", "\n", "clip_gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "self", ".", "config", ".", "MAX_GRAD_NORM", ")", "\n", "\n", "self", ".", "updates", "=", "self", ".", "opt", ".", "apply_gradients", "(", "zip", "(", "clip_gradients", ",", "trainable_params", ")", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "print", "(", "'Building optimizer in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.__helper__initializer": [[334, 338], ["math.sqrt", "tensorflow.random_uniform_initializer"], "methods", ["None"], ["", "def", "__helper__initializer", "(", "self", ")", ":", "\n", "        ", "sqrt3", "=", "math", ".", "sqrt", "(", "3", ")", "# Uniform(-sqrt(3), sqrt(3)) has variance=1.", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "sqrt3", ",", "sqrt3", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.train": [[340, 352], ["sess.run"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "sess", ",", "encoder_inputs", ",", "decoder_inputs", ",", "decoder_inputs_lengths", ",", "encoder_predicates_direction", ")", ":", "\n", "\n", "        ", "feed_dict", "=", "{", "\n", "self", ".", "encoder_entities_inputs", ":", "encoder_inputs", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "# pick up subjects and objects", "\n", "self", ".", "encoder_predicates_inputs", ":", "encoder_inputs", "[", ":", ",", "[", "1", "]", "]", ",", "# pick up predicates", "\n", "self", ".", "decoder_inputs", ":", "decoder_inputs", ",", "\n", "self", ".", "decoder_inputs_length", ":", "decoder_inputs_lengths", ",", "\n", "self", ".", "encoder_predicates_direction", ":", "encoder_predicates_direction", "\n", "}", "\n", "_", ",", "loss", "=", "sess", ".", "run", "(", "[", "self", ".", "updates", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.eval": [[353, 373], ["sess.run"], "methods", ["None"], ["", "def", "eval", "(", "self", ",", "sess", ",", "encoder_triples_inputs", ",", "decoder_inputs", ",", "decoder_inputs_lengths", ",", "encoder_predicates_direction", ")", ":", "\n", "        ", "\"\"\"\n        Run a evaluation step of the model feeding the given inputs\n        :param sess:\n        :param encoder_inputs:\n        :param decoder_inputs:\n        :param decoder_inputs_lengths:\n        :return:\n        \"\"\"", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "encoder_entities_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "# pick up subjects and objects", "\n", "self", ".", "encoder_predicates_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "1", "]", "]", ",", "# pick up predicates", "\n", "self", ".", "decoder_inputs", ":", "decoder_inputs", ",", "\n", "self", ".", "decoder_inputs_length", ":", "decoder_inputs_lengths", ",", "\n", "self", ".", "encoder_predicates_direction", ":", "encoder_predicates_direction", "\n", "}", "\n", "_", ",", "loss", "=", "sess", ".", "run", "(", "[", "self", ".", "updates", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.predict": [[374, 388], ["sess.run"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "sess", ",", "encoder_triples_inputs", ",", "encoder_predicates_direction", ")", ":", "\n", "        ", "\"\"\"\n        predict the output given an input\n        \"\"\"", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "encoder_entities_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "# pick up subjects and objects", "\n", "self", ".", "encoder_predicates_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "1", "]", "]", ",", "# pick up predicates", "\n", "self", ".", "encoder_predicates_direction", ":", "encoder_predicates_direction", "\n", "}", "\n", "\n", "output", "=", "sess", ".", "run", "(", "[", "self", ".", "decoder_pred_inference", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "return", "output", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.save": [[389, 395], ["tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.save"], ["", "def", "save", "(", "self", ",", "sess", ",", "path", ",", "var_list", "=", "None", ",", "global_step", "=", "None", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", ")", "\n", "path", "=", "saver", ".", "save", "(", "sess", ",", "save_path", "=", "path", ",", "global_step", "=", "global_step", ")", "\n", "print", "(", "\"model saved in %s\"", "%", "path", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.triples2seq.Triple2SeqModel.restore": [[396, 408], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.restore"], ["", "def", "restore", "(", "self", ",", "sess", ",", "path", ",", "var_list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        restore trained model from a specific path\n        :param sess:\n        :param path:\n        :param var_list: if None restore all list\n        :return:\n        \"\"\"", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "path", ")", "\n", "print", "(", "\"model restored from %s\"", "%", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__init__": [[35, 47], ["print", "tripletext2seq.TripleText2SeqModel.__create_placeholders", "tripletext2seq.TripleText2SeqModel.__create_encoder", "tripletext2seq.TripleText2SeqModel.__create_decoder"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_placeholders", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_encoder", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder"], ["def", "__init__", "(", "self", ",", "config", ",", "mode", "=", "'training'", ")", ":", "\n", "\n", "        ", "print", "(", "'Initializing new seq 2 seq model'", ")", "\n", "\n", "assert", "mode", "in", "[", "'training'", ",", "'evaluation'", ",", "'inference'", "]", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "__create_placeholders", "(", ")", "\n", "self", ".", "__create_encoder", "(", ")", "\n", "self", ".", "__create_decoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_placeholders": [[48, 110], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.shape", "tensorflow.reduce_max"], "methods", ["None"], ["", "def", "__create_placeholders", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Function to create placeholders for each\n        :return:\n        \"\"\"", "\n", "\n", "# Encoder Inputs", "\n", "#################", "\n", "\n", "# Input Triple", "\n", "###############", "\n", "\n", "# The input triple is given in the form of list of entities [sub,obj] and list of predicates [pred]", "\n", "# This design allows also inputting multiple triples at once since order matters [s1,s2,o1,o2] [p1,p2]", "\n", "self", ".", "encoder_entities_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "self", ".", "config", ".", "ENTITIESLENGTH", "]", ",", "name", "=", "\"encoder_entities_inputs\"", ")", "\n", "self", ".", "encoder_predicates_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "self", ".", "config", ".", "PREDICATESLENGTH", "]", ",", "name", "=", "\"encoder_predicates_inputs\"", ")", "\n", "self", ".", "encoder_predicates_direction", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"encoder_predicates_direction\"", ")", "\n", "\n", "# Input Sequences", "\n", "# textual evidences = input sequences", "\n", "######################################", "\n", "\n", "# input sequences with padding", "\n", "# :size =  NUMBER_OF_TEXTUAL_EVIDENCES x BATCHSIZE x input sequence max length", "\n", "self", ".", "encoder_text_inputs", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "self", ".", "config", ".", "NUMBER_OF_TEXTUAL_EVIDENCES", ",", "None", ",", "None", "]", ",", "name", "=", "'encoder_text_inputs'", ")", "\n", "# actual lengths of each input sequence", "\n", "# :size =  NUMBER_OF_TEXTUAL_EVIDENCES x 1", "\n", "# each batch has a fixed input sequence length", "\n", "self", ".", "encoder_text_inputs_length", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "self", ".", "config", ".", "NUMBER_OF_TEXTUAL_EVIDENCES", ",", "None", "]", ",", "name", "=", "'encoder_text_inputs_length'", ")", "\n", "\n", "self", ".", "batch_size", "=", "tf", ".", "shape", "(", "self", ".", "encoder_entities_inputs", ")", "[", "0", "]", "\n", "\n", "# Decoder placeholders:", "\n", "# these are the raw inputs to the decoder same as input sequences", "\n", "# output sequence with padding", "\n", "# :size =  BATCHSIZE x output sequence max length", "\n", "self", ".", "decoder_inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "\"decoder_inputs\"", ")", "\n", "# number indicating actual lengths of the output sequence", "\n", "# :size =  BATCHSIZE x 1", "\n", "self", ".", "decoder_inputs_length", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ",", "name", "=", "'decoder_inputs_length'", ")", "\n", "\n", "if", "self", ".", "mode", "==", "\"training\"", ":", "\n", "\n", "            ", "self", ".", "decoder_inputs_train", "=", "self", ".", "decoder_inputs", "\n", "\n", "# for training our targets are decoder inputs shifted by one (to ignore the <s> symbol)", "\n", "# as shown in figure https://www.tensorflow.org/images/basic_seq2seq.png", "\n", "self", ".", "decoder_targets_train", "=", "self", ".", "decoder_inputs", "[", ":", ",", "1", ":", "]", "\n", "\n", "# decoder_inputs_length_train: [batch_size x 1]", "\n", "self", ".", "decoder_inputs_length_train", "=", "self", ".", "decoder_inputs_length", "\n", "self", ".", "decoder_targets_length_train", "=", "self", ".", "decoder_inputs_length", "-", "1", "\n", "\n", "# calculating max_decoder_length", "\n", "self", ".", "decoder_max_length", "=", "tf", ".", "reduce_max", "(", "self", ".", "decoder_targets_length_train", ")", "\n", "\n", "", "elif", "self", ".", "mode", "==", "\"inference\"", ":", "\n", "# at inference time there's no decoder input so we set the Decode length to a maximum.", "\n", "            ", "self", ".", "decoder_max_length", "=", "self", ".", "config", ".", "MAX_DECODE_LENGTH", "\n", "\n", "# global step", "\n", "", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "'global_step'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__build_single_rnn_cell": [[111, 120], ["tensorflow.nn.rnn_cell.GRUCell"], "methods", ["None"], ["", "def", "__build_single_rnn_cell", "(", "self", ",", "hidden_size", ")", ":", "\n", "\n", "        ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "hidden_size", ")", "\n", "\n", "# if self.use_dropout:", "\n", "#     cell = DropoutWrapper(cell, dtype=self.dtype,", "\n", "#                           output_keep_prob=self.keep_prob_placeholder, )", "\n", "\n", "return", "cell", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_triple_encoder": [[121, 168], ["print", "time.time", "print", "tensorflow.variable_scope", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.concat", "tensorflow.concat", "pickle.load", "tensorflow.Variable", "pickle.load", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.unstack", "time.time", "open", "open", "tripletext2seq.TripleText2SeqModel.__helper__initializer", "tripletext2seq.TripleText2SeqModel.__helper__initializer"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__helper__initializer", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__helper__initializer"], ["", "def", "__create_triple_encoder", "(", "self", ")", ":", "\n", "        ", "print", "(", "'building Triples encoder ...'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder'", ")", ":", "\n", "# Create Embeddings Weights", "\n", "\n", "            ", "if", "self", ".", "config", ".", "USE_PRETRAINED_KB_EMBEDDINGS", ":", "\n", "\n", "                ", "ent_kb_emb", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "config", ".", "PRETRAINED_ENTITIES_EMBEDDINGS_PATH", ")", ")", "\n", "self", ".", "encoder_entities_embeddings", "=", "tf", ".", "Variable", "(", "ent_kb_emb", ",", "name", "=", "\"entities_embeddings\"", ",", "trainable", "=", "self", ".", "config", ".", "TRAIN_KB_EMBEDDINGS", ")", "\n", "\n", "pred_kb_emb", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "config", ".", "PRETRAINED_PREDICATES_EMBEDDINGS_PATH", ")", ")", "\n", "self", ".", "encoder_predicates_embeddings", "=", "tf", ".", "Variable", "(", "pred_kb_emb", ",", "name", "=", "\"predicates_embeddings\"", ",", "\n", "trainable", "=", "self", ".", "config", ".", "TRAIN_KB_EMBEDDINGS", ")", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "encoder_entities_embeddings", "=", "tf", ".", "get_variable", "(", "\"entities_embeddings\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "ENTITIES_VOCAB", ",", "self", ".", "config", ".", "ENTITIES_EMBEDDING_SIZE", "]", ",", "\n", "initializer", "=", "self", ".", "__helper__initializer", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "self", ".", "encoder_predicates_embeddings", "=", "tf", ".", "get_variable", "(", "\"predicates_embeddings\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "PREDICATES_VOCAB", ",", "\n", "self", ".", "config", ".", "PREDICATES_EMBEDDING_SIZE", "]", ",", "\n", "initializer", "=", "self", ".", "__helper__initializer", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "# embedding the encoder inputs", "\n", "# encoder_inputs is of size [Batch size x 3]", "\n", "# encoder_inputs_embedded is of size [Batch size x 3 x TRIPLES_EMBEDDING_SIZE]", "\n", "", "self", ".", "encoder_entities_inputs_embedded", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "encoder_entities_embeddings", ",", "self", ".", "encoder_entities_inputs", ")", "\n", "\n", "self", ".", "encoder_predicates_inputs_embedded", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "encoder_predicates_embeddings", ",", "self", ".", "encoder_predicates_inputs", ")", "\n", "\n", "direction", "=", "tf", ".", "expand_dims", "(", "self", ".", "encoder_predicates_direction", ",", "axis", "=", "1", ")", "\n", "direction", "=", "tf", ".", "expand_dims", "(", "direction", ",", "axis", "=", "2", ")", "\n", "\n", "self", ".", "encoder_predicates_inputs_embedded", "=", "tf", ".", "multiply", "(", "self", ".", "encoder_predicates_inputs_embedded", ",", "direction", ")", "\n", "\n", "self", ".", "encoder_triples_inputs_embedded", "=", "tf", ".", "concat", "(", "(", "self", ".", "encoder_entities_inputs_embedded", ",", "self", ".", "encoder_predicates_inputs_embedded", ")", ",", "axis", "=", "1", ")", "\n", "# Encode input triple into a vector", "\n", "# encoder_state: [batch_size, cell_output_size]", "\n", "self", ".", "encoder_triples_last_state", "=", "tf", ".", "concat", "(", "tf", ".", "unstack", "(", "self", ".", "encoder_triples_inputs_embedded", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "print", "(", "'Building encoder in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_seq_encoder": [[169, 260], ["print", "time.time", "print", "tensorflow.variable_scope", "tensorflow.nn.embedding_lookup", "tripletext2seq.TripleText2SeqModel.__build_single_rnn_cell", "pickle.load().astype", "tensorflow.Variable", "tensorflow.get_variable", "range", "range", "range", "range", "time.time", "tripletext2seq.TripleText2SeqModel.encoder_cell.append", "tensorflow.nn.dynamic_rnn", "tripletext2seq.TripleText2SeqModel.encoder_text_outputs.append", "tripletext2seq.TripleText2SeqModel.encoder_text_last_state.append", "tripletext2seq.TripleText2SeqModel.fwd_encoder_cell.append", "tripletext2seq.TripleText2SeqModel.bw_encoder_cell.append", "tensorflow.contrib.rnn.stack_bidirectional_dynamic_rnn", "tripletext2seq.TripleText2SeqModel.encoder_text_outputs.append", "tripletext2seq.TripleText2SeqModel.encoder_text_last_state.append", "pickle.load", "tripletext2seq.TripleText2SeqModel.__helper__initializer", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.squeeze", "tensorflow.concat", "tensorflow.squeeze", "open", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__build_single_rnn_cell", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__helper__initializer"], ["", "def", "__create_seq_encoder", "(", "self", ")", ":", "\n", "\n", "        ", "print", "(", "'Building Input Sequence Encoder ...'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder'", ")", ":", "\n", "\n", "###################", "\n", "# Word Embeddings #", "\n", "###################", "\n", "# Create Word Embeddings Weights", "\n", "            ", "if", "self", ".", "config", ".", "USE_PRETRAINED_WORD_EMBEDDINGS", ":", "\n", "\n", "                ", "word_emb", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "config", ".", "PRETRAINED_WORD_EMBEDDINGS_PATH", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "encoder_word_embeddings", "=", "tf", ".", "Variable", "(", "word_emb", ",", "name", "=", "\"encoder_word_embeddings\"", ",", "\n", "trainable", "=", "self", ".", "config", ".", "TRAIN_WORD_EMBEDDINGS", ")", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "encoder_word_embeddings", "=", "tf", ".", "get_variable", "(", "\"encoder_word_embeddings\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "DECODER_VOCAB_SIZE", ",", "\n", "self", ".", "config", ".", "INPUT_SEQ_EMBEDDING_SIZE", "]", ",", "\n", "initializer", "=", "self", ".", "__helper__initializer", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "# Embedding the encoder inputs", "\n", "# Encoder Input size = NUMBER_OF_TEXTUAL_EVIDENCES x BATCH x input_length", "\n", "# Embedded Input size =  NUMBER_OF_TEXTUAL_EVIDENCES x BATCH x input_length x word_embeddings_size", "\n", "", "self", ".", "encoder_text_inputs_embedded", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "encoder_word_embeddings", ",", "\n", "self", ".", "encoder_text_inputs", ")", "\n", "\n", "#######", "\n", "# RNN #", "\n", "#######", "\n", "\n", "# building a multilayer RNN for each Textual Evidence", "\n", "# Encode input sequences into context vectors:", "\n", "# encoder_outputs: [Num_text_evidence, batch_size, max_time_step, cell_output_size]", "\n", "# encoder_state: [Num_text_evidence, batch_size, cell_output_size]", "\n", "\n", "self", ".", "encoder_text_outputs", "=", "[", "]", "\n", "self", ".", "encoder_text_last_state", "=", "[", "]", "\n", "\n", "# If not bidirectional encoder", "\n", "self", ".", "encoder_cell", "=", "[", "]", "\n", "\n", "rnn", "=", "self", ".", "__build_single_rnn_cell", "(", "self", ".", "config", ".", "INPUT_SEQ_RNN_HIDDEN_SIZE", ")", "\n", "\n", "if", "\"bi\"", "not", "in", "self", ".", "config", ".", "ENCODER_RNN_CELL_TYPE", ":", "\n", "                    ", "for", "_", "in", "range", "(", "self", ".", "config", ".", "NUMBER_OF_TEXTUAL_EVIDENCES", ")", ":", "\n", "#rnn = self.__build_single_rnn_cell(self.config.INPUT_SEQ_RNN_HIDDEN_SIZE)", "\n", "                        ", "self", ".", "encoder_cell", ".", "append", "(", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "rnn", "]", "*", "self", ".", "config", ".", "NUM_LAYERS", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "config", ".", "NUMBER_OF_TEXTUAL_EVIDENCES", ")", ":", "\n", "\n", "                        ", "out", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "self", ".", "encoder_cell", "[", "i", "]", ",", "\n", "inputs", "=", "self", ".", "encoder_text_inputs_embedded", "[", "i", "]", ",", "\n", "sequence_length", "=", "self", ".", "encoder_text_inputs_length", "[", "i", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "self", ".", "encoder_text_outputs", ".", "append", "(", "out", ")", "\n", "self", ".", "encoder_text_last_state", ".", "append", "(", "tf", ".", "squeeze", "(", "state", ",", "axis", "=", "0", ")", ")", "\n", "\n", "# If bidirectional encoder", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "fwd_encoder_cell", "=", "[", "]", "\n", "self", ".", "bw_encoder_cell", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "config", ".", "NUMBER_OF_TEXTUAL_EVIDENCES", ")", ":", "\n", "# two rnn decoders for each layer for each input sequence\\", "\n", "#fwrnn = self.__build_single_rnn_cell(self.config.INPUT_SEQ_RNN_HIDDEN_SIZE)", "\n", "#bwrnn = self.__build_single_rnn_cell(self.config.INPUT_SEQ_RNN_HIDDEN_SIZE)", "\n", "\n", "                    ", "self", ".", "fwd_encoder_cell", ".", "append", "(", "[", "rnn", "]", "*", "self", ".", "config", ".", "NUM_LAYERS", ")", "\n", "self", ".", "bw_encoder_cell", ".", "append", "(", "[", "rnn", "]", "*", "self", ".", "config", ".", "NUM_LAYERS", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "config", ".", "NUMBER_OF_TEXTUAL_EVIDENCES", ")", ":", "\n", "\n", "                    ", "out", ",", "fwd_state", ",", "bk_state", "=", "tf", ".", "contrib", ".", "rnn", ".", "stack_bidirectional_dynamic_rnn", "(", "\n", "cells_fw", "=", "self", ".", "fwd_encoder_cell", "[", "i", "]", ",", "\n", "cells_bw", "=", "self", ".", "bw_encoder_cell", "[", "i", "]", ",", "\n", "inputs", "=", "self", ".", "encoder_text_inputs_embedded", "[", "i", "]", ",", "\n", "sequence_length", "=", "self", ".", "encoder_text_inputs_length", "[", "i", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "self", ".", "encoder_text_outputs", ".", "append", "(", "tf", ".", "concat", "(", "out", ",", "2", ")", ")", "\n", "self", ".", "encoder_text_last_state", ".", "append", "(", "tf", ".", "squeeze", "(", "tf", ".", "concat", "(", "[", "fwd_state", ",", "bk_state", "]", ",", "2", ")", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "", "", "print", "(", "'Building encoder in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_encoder": [[261, 270], ["tripletext2seq.TripleText2SeqModel.__create_triple_encoder", "tripletext2seq.TripleText2SeqModel.__create_seq_encoder", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_triple_encoder", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_seq_encoder"], ["", "def", "__create_encoder", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "__create_triple_encoder", "(", ")", "\n", "self", ".", "__create_seq_encoder", "(", ")", "\n", "\n", "# concatinating last state of the triple encoder with the last state of each text input being encoded", "\n", "last_states", "=", "[", "self", ".", "encoder_triples_last_state", "]", "+", "self", ".", "encoder_text_last_state", "\n", "\n", "self", ".", "encoder_last_state", "=", "tf", ".", "concat", "(", "last_states", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder_cell": [[271, 279], ["tensorflow.nn.rnn_cell.GRUCell", "tensorflow.python.layers.core.Dense", "tensorflow.python.layers.core.Dense."], "methods", ["None"], ["", "def", "__create_decoder_cell", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "decoder_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "\n", "\n", "# fully connected layer to change size of Encoder Last state to Decoder Hidden size", "\n", "decoder_hidden_state_reshape", "=", "Dense", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "\n", "\n", "self", ".", "decoder_initial_state", "=", "(", "decoder_hidden_state_reshape", "(", "self", ".", "encoder_last_state", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder_attention_cell_old": [[281, 325], ["tensorflow.concat", "tensorflow.contrib.seq2seq.BahdanauAttention", "tripletext2seq.TripleText2SeqModel.__build_single_rnn_cell", "tensorflow.python.layers.core.Dense", "tensorflow.contrib.seq2seq.AttentionWrapper", "tensorflow.nn.rnn_cell.MultiRNNCell", "tripletext2seq.TripleText2SeqModel.decoder_cell_list[].zero_state", "tensorflow.python.layers.core.Dense."], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__build_single_rnn_cell"], ["", "def", "__create_decoder_attention_cell_old", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        create decoder RNN with attention\n        :return:\n        \"\"\"", "\n", "\n", "memory", "=", "tf", ".", "concat", "(", "[", "self", ".", "encoder_triples_inputs_embedded", "]", "+", "self", ".", "encoder_text_outputs", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "attention_mechanism", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BahdanauAttention", "(", "\n", "num_units", "=", "self", ".", "config", ".", "TRIPLES_EMBEDDING_SIZE", ",", "# the depth of the Attention layer", "\n", "memory", "=", "memory", ",", "\n", "name", "=", "\"Attention\"", "\n", ")", "\n", "\n", "# create decoder cell:", "\n", "gru", "=", "self", ".", "__build_single_rnn_cell", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "\n", "self", ".", "decoder_cell_list", "=", "[", "gru", "]", "*", "self", ".", "config", ".", "NUM_LAYERS", "\n", "\n", "decoder_hidden_state_reshape", "=", "Dense", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "\n", "\n", "self", ".", "decoder_cell_list", "[", "-", "1", "]", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "AttentionWrapper", "(", "\n", "cell", "=", "self", ".", "decoder_cell_list", "[", "-", "1", "]", ",", "\n", "attention_layer_size", "=", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ",", "# the output hidden size of the last decoder", "\n", "attention_mechanism", "=", "self", ".", "attention_mechanism", ",", "\n", "initial_cell_state", "=", "decoder_hidden_state_reshape", "(", "self", ".", "encoder_last_state", ")", ",", "\n", "alignment_history", "=", "False", ",", "\n", "name", "=", "\"Attention_Wrapper\"", "\n", ")", "\n", "\n", "self", ".", "decoder_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "self", ".", "decoder_cell_list", ")", "\n", "\n", "# To be compatible with AttentionWrapper, the encoder last state", "\n", "# of the top layer should be converted into the AttentionWrapperState form", "\n", "# We can easily do this by calling AttentionWrapper.zero_state", "\n", "\n", "# self.decoder_initial_state = self.encoder_last_state", "\n", "\n", "init_state", "=", "self", ".", "decoder_cell_list", "[", "-", "1", "]", ".", "zero_state", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "# a tuple because decode initial state has to take a tuple", "\n", "self", ".", "decoder_initial_state", "=", "(", "init_state", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder_attention_cell": [[327, 383], ["tensorflow.contrib.seq2seq.BahdanauAttention", "tensorflow.concat", "tensorflow.contrib.seq2seq.BahdanauAttention", "tripletext2seq.TripleText2SeqModel.__build_single_rnn_cell", "tensorflow.python.layers.core.Dense", "tensorflow.contrib.seq2seq.AttentionWrapper", "tensorflow.nn.rnn_cell.MultiRNNCell", "tripletext2seq.TripleText2SeqModel.decoder_cell_list[].zero_state", "tensorflow.python.layers.core.Dense."], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__build_single_rnn_cell"], ["", "def", "__create_decoder_attention_cell", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        create decoder RNN with attention\n        :return:\n        \"\"\"", "\n", "\n", "triple_memory", "=", "self", ".", "encoder_triples_inputs_embedded", "\n", "\n", "self", ".", "triple_attention_mechanism", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BahdanauAttention", "(", "\n", "num_units", "=", "self", ".", "config", ".", "TRIPLES_EMBEDDING_SIZE", ",", "# the depth of the Attention layer", "\n", "memory", "=", "triple_memory", ",", "\n", "name", "=", "\"TripleAttention\"", "\n", ")", "\n", "\n", "context_memory", "=", "tf", ".", "concat", "(", "self", ".", "encoder_text_outputs", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "context_attention_mechanism", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BahdanauAttention", "(", "\n", "num_units", "=", "self", ".", "config", ".", "INPUT_SEQ_RNN_HIDDEN_SIZE", "if", "\"bi\"", "not", "in", "self", ".", "config", ".", "ENCODER_RNN_CELL_TYPE", "\n", "else", "self", ".", "config", ".", "INPUT_SEQ_RNN_HIDDEN_SIZE", "*", "2", ",", "# the depth of the Attention layer", "\n", "memory", "=", "context_memory", ",", "\n", "name", "=", "\"ContextAttention\"", "\n", ")", "\n", "\n", "# create decoder cell:", "\n", "gru", "=", "self", ".", "__build_single_rnn_cell", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "\n", "self", ".", "decoder_cell_list", "=", "[", "gru", "]", "*", "self", ".", "config", ".", "NUM_LAYERS", "\n", "\n", "decoder_hidden_state_reshape", "=", "Dense", "(", "self", ".", "config", ".", "DECODER_RNN_HIDDEN_SIZE", ")", "\n", "\n", "self", ".", "decoder_cell_list", "[", "-", "1", "]", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "AttentionWrapper", "(", "\n", "cell", "=", "self", ".", "decoder_cell_list", "[", "-", "1", "]", ",", "\n", "# the output hidden size of the last decoder", "\n", "attention_layer_size", "=", "[", "self", ".", "config", ".", "TRIPLES_EMBEDDING_SIZE", ",", "\n", "self", ".", "config", ".", "INPUT_SEQ_RNN_HIDDEN_SIZE", "if", "\"bi\"", "not", "in", "self", ".", "config", ".", "ENCODER_RNN_CELL_TYPE", "\n", "else", "self", ".", "config", ".", "INPUT_SEQ_RNN_HIDDEN_SIZE", "*", "2", "]", ",", "\n", "attention_mechanism", "=", "[", "self", ".", "triple_attention_mechanism", ",", "self", ".", "context_attention_mechanism", "]", ",", "\n", "initial_cell_state", "=", "decoder_hidden_state_reshape", "(", "self", ".", "encoder_last_state", ")", ",", "\n", "alignment_history", "=", "False", ",", "\n", "name", "=", "\"Attention_Wrapper\"", "\n", ")", "\n", "\n", "self", ".", "decoder_cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "self", ".", "decoder_cell_list", ")", "\n", "\n", "# To be compatible with AttentionWrapper, the encoder last state", "\n", "# of the top layer should be converted into the AttentionWrapperState form", "\n", "# We can easily do this by calling AttentionWrapper.zero_state", "\n", "\n", "# self.decoder_initial_state = self.encoder_last_state", "\n", "\n", "init_state", "=", "self", ".", "decoder_cell_list", "[", "-", "1", "]", ".", "zero_state", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "# a tuple because decode initial state has to take a tuple", "\n", "self", ".", "decoder_initial_state", "=", "(", "init_state", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder": [[384, 489], ["print", "time.time", "print", "tensorflow.variable_scope", "tensorflow.python.layers.core.Dense", "tripletext2seq.TripleText2SeqModel.__create_decoder_attention_cell", "tripletext2seq.TripleText2SeqModel.__create_decoder_cell", "tensorflow.nn.embedding_lookup", "tensorflow.contrib.seq2seq.TrainingHelper", "tensorflow.contrib.seq2seq.BasicDecoder", "tensorflow.contrib.seq2seq.dynamic_decode", "tripletext2seq.TripleText2SeqModel.__create_loss", "tripletext2seq.TripleText2SeqModel.__create_optimizer", "time.time", "pickle.load().astype", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.contrib.seq2seq.GreedyEmbeddingHelper", "print", "tensorflow.contrib.seq2seq.BasicDecoder", "tensorflow.contrib.seq2seq.dynamic_decode", "tensorflow.expand_dims", "tensorflow.ones", "tensorflow.nn.embedding_lookup", "pickle.load", "tripletext2seq.TripleText2SeqModel.__helper__initializer", "open"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder_attention_cell", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_decoder_cell", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_loss", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_optimizer", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__helper__initializer"], ["", "def", "__create_decoder", "(", "self", ")", ":", "\n", "\n", "        ", "print", "(", "\"building decoder and attention ..\"", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'decoder'", ")", ":", "\n", "\n", "# input and output layers to the decoder", "\n", "# decoder_input_layer = Dense(self.config.DECODER_RNN_HIDDEN_SIZE, dtype=tf.float32, name='decoder_input_projection')", "\n", "            ", "decoder_output_layer", "=", "Dense", "(", "self", ".", "config", ".", "DECODER_VOCAB_SIZE", ",", "name", "=", "\"decoder_output_projection\"", ")", "\n", "\n", "if", "self", ".", "config", ".", "COUPLE_ENCODER_DECODER_WORD_EMBEDDINGS", ":", "\n", "# connect encoder and decoder word embeddings", "\n", "                ", "self", ".", "decoder_embeddings", "=", "self", ".", "encoder_word_embeddings", "\n", "\n", "", "elif", "self", ".", "config", ".", "USE_PRETRAINED_WORD_EMBEDDINGS", ":", "\n", "\n", "                ", "word_emb", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "config", ".", "PRETRAINED_WORD_EMBEDDINGS_PATH", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "self", ".", "decoder_embeddings", "=", "tf", ".", "Variable", "(", "word_emb", ",", "name", "=", "\"decoder_embeddings\"", ",", "\n", "trainable", "=", "self", ".", "config", ".", "TRAIN_WORD_EMBEDDINGS", ")", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "decoder_embeddings", "=", "tf", ".", "get_variable", "(", "\"decoder_embeddings\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "DECODER_VOCAB_SIZE", ",", "self", ".", "config", ".", "DECODER_EMBEDDING_SIZE", "]", ",", "\n", "initializer", "=", "self", ".", "__helper__initializer", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "USE_ATTENTION", ":", "\n", "                ", "self", ".", "__create_decoder_attention_cell", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "__create_decoder_cell", "(", ")", "\n", "\n", "######################################", "\n", "# Build the decoder in training mode #", "\n", "######################################", "\n", "", "if", "self", ".", "mode", "==", "'training'", ":", "\n", "\n", "# changing inputs to embeddings and then through the input projection", "\n", "# decoder_inputs_embedded: [batch_size, max_time_step + 1, embedding_size]", "\n", "                ", "self", ".", "decoder_inputs_embedded", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "decoder_embeddings", ",", "\n", "ids", "=", "self", ".", "decoder_inputs_train", ")", "\n", "# self.decoder_inputs_embedded = decoder_input_layer(self.decoder_inputs_embedded)", "\n", "\n", "# Helper to feed inputs to the training:", "\n", "\n", "self", ".", "training_helper", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "TrainingHelper", "(", "\n", "inputs", "=", "self", ".", "decoder_inputs_embedded", ",", "\n", "sequence_length", "=", "self", ".", "decoder_inputs_length_train", ",", "\n", "name", "=", "'training_helper'", ")", "\n", "\n", "# Build the decoder", "\n", "self", ".", "training_decoder", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BasicDecoder", "(", "\n", "cell", "=", "self", ".", "decoder_cell", ",", "\n", "helper", "=", "self", ".", "training_helper", ",", "\n", "initial_state", "=", "self", ".", "decoder_initial_state", ",", "\n", "output_layer", "=", "decoder_output_layer", ")", "\n", "\n", "# decoder outputs are of type tf.contrib.seq2seq.BasicDecoderOutput", "\n", "# has two fields `rnn_output` and `sample_id`", "\n", "\n", "self", ".", "decoder_outputs_train", ",", "self", ".", "decoder_last_state_train", ",", "self", ".", "decoder_outputs_length_decode_train", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "dynamic_decode", "(", "\n", "decoder", "=", "self", ".", "training_decoder", ",", "\n", "impute_finished", "=", "True", ",", "\n", "maximum_iterations", "=", "self", ".", "decoder_max_length", "\n", ")", "\n", "\n", "# In the training mode only create LOSS and Optimizer", "\n", "\n", "self", ".", "__create_loss", "(", ")", "\n", "self", ".", "__create_optimizer", "(", ")", "\n", "\n", "######################################", "\n", "# Build the decoder in sampling mode #", "\n", "######################################", "\n", "", "elif", "self", ".", "mode", "==", "'inference'", ":", "\n", "\n", "                ", "start_tokens", "=", "tf", ".", "ones", "(", "[", "self", ".", "batch_size", ",", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "*", "self", ".", "config", ".", "DECODER_START_TOKEN_ID", "\n", "end_token", "=", "self", ".", "config", ".", "DECODER_END_TOKEN_ID", "\n", "\n", "def", "decoder_inputs_embedder", "(", "inputs", ")", ":", "\n", "# return decoder_input_layer(tf.nn.embedding_lookup(self.decoder_embeddings, inputs))", "\n", "                    ", "return", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "decoder_embeddings", ",", "inputs", ")", "\n", "\n", "# end token is needed so the helper stop feeding new inputs again once the <end> mark is shown.", "\n", "", "decoder_helper", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "GreedyEmbeddingHelper", "(", "decoder_inputs_embedder", ",", "start_tokens", ",", "end_token", ")", "\n", "\n", "# Basic decoder performs greedy decoding at each time step", "\n", "print", "(", "\"Building Greedy Decoder ...\"", ")", "\n", "\n", "inference_decoder", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "BasicDecoder", "(", "cell", "=", "self", ".", "decoder_cell", ",", "\n", "helper", "=", "decoder_helper", ",", "\n", "initial_state", "=", "self", ".", "decoder_initial_state", ",", "\n", "output_layer", "=", "decoder_output_layer", ")", "\n", "\n", "self", ".", "decoder_outputs_inference", ",", "self", ".", "decoder_last_state_inference", ",", "self", ".", "decoder_outputs_length_inference", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "dynamic_decode", "(", "\n", "decoder", "=", "inference_decoder", ",", "\n", "output_time_major", "=", "False", ",", "\n", "maximum_iterations", "=", "self", ".", "decoder_max_length", "\n", ")", "\n", "\n", "self", ".", "decoder_pred_inference", "=", "tf", ".", "expand_dims", "(", "self", ".", "decoder_outputs_inference", ".", "sample_id", ",", "-", "1", ")", "\n", "\n", "", "", "print", "(", "'Building decoder in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_loss": [[490, 511], ["print", "time.time", "tensorflow.identity", "tensorflow.argmax", "tensorflow.sequence_mask", "tensorflow.contrib.seq2seq.sequence_loss", "print", "time.time"], "methods", ["None"], ["", "def", "__create_loss", "(", "self", ")", ":", "\n", "\n", "        ", "print", "(", "'Creating loss...'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "self", ".", "decoder_logits", "=", "tf", ".", "identity", "(", "self", ".", "decoder_outputs_train", ".", "rnn_output", ",", "name", "=", "\"decoder_logits\"", ")", "\n", "self", ".", "decoder_pred", "=", "tf", ".", "argmax", "(", "self", ".", "decoder_logits", ",", "axis", "=", "-", "1", ",", "name", "=", "\"decoder_pred\"", ")", "\n", "\n", "# masking the sequence in order to calculate the error according to the calculated", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "self", ".", "decoder_inputs_length_train", ",", "maxlen", "=", "self", ".", "decoder_max_length", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "name", "=", "\"masks\"", ")", "\n", "\n", "# Control loss dimensions with `average_across_timesteps` and `average_across_batch`", "\n", "self", ".", "loss", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "sequence_loss", "(", "logits", "=", "self", ".", "decoder_logits", ",", "\n", "targets", "=", "self", ".", "decoder_targets_train", ",", "\n", "average_across_timesteps", "=", "False", ",", "\n", "average_across_batch", "=", "False", ",", "\n", "weights", "=", "mask", ",", "\n", "name", "=", "\"batch_loss\"", ")", "\n", "\n", "print", "(", "'Building loss in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__create_optimizer": [[512, 532], ["print", "time.time", "tensorflow.train.exponential_decay", "tensorflow.train.RMSPropOptimizer", "tensorflow.trainable_variables", "tensorflow.gradients", "tensorflow.clip_by_global_norm", "tripletext2seq.TripleText2SeqModel.opt.apply_gradients", "print", "zip", "time.time"], "methods", ["None"], ["", "def", "__create_optimizer", "(", "self", ")", ":", "\n", "        ", "print", "(", "'creating optimizer...'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "config", ".", "LR", ",", "self", ".", "global_step", ",", "200", ",", "0.97", ",", "staircase", "=", "True", ")", "\n", "self", ".", "opt", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "learning_rate", ")", "\n", "# self.opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)", "\n", "\n", "# normalize the gradients of a parameter vector when its L2 norm exceeds a certain threshold according to", "\n", "trainable_params", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "# calculate gradients of the loss given all the trainable parameters", "\n", "gradients", "=", "tf", ".", "gradients", "(", "self", ".", "loss", ",", "trainable_params", ")", "\n", "\n", "# Gradient clipping: new_gradients = gradients * threshold / l2_norm(gradients)", "\n", "clip_gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "self", ".", "config", ".", "MAX_GRAD_NORM", ")", "\n", "\n", "self", ".", "updates", "=", "self", ".", "opt", ".", "apply_gradients", "(", "zip", "(", "clip_gradients", ",", "trainable_params", ")", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "print", "(", "'Building optimizer in: '", ",", "time", ".", "time", "(", ")", "-", "start", ",", "' secs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.__helper__initializer": [[533, 537], ["math.sqrt", "tensorflow.random_uniform_initializer"], "methods", ["None"], ["", "def", "__helper__initializer", "(", "self", ")", ":", "\n", "        ", "sqrt3", "=", "math", ".", "sqrt", "(", "3", ")", "# Uniform(-sqrt(3), sqrt(3)) has variance=1.", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "sqrt3", ",", "sqrt3", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.train": [[538, 553], ["sess.run"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "sess", ",", "encoder_triples_inputs", ",", "encoder_text_inputs", ",", "encoder_text_inputs_length", ",", "decoder_inputs", ",", "decoder_inputs_lengths", ",", "encoder_predicates_direction", ")", ":", "\n", "\n", "        ", "feed_dict", "=", "{", "\n", "# self.encoder_triples_inputs: encoder_triples_inputs,", "\n", "self", ".", "encoder_entities_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "# pick up subjects and objects", "\n", "self", ".", "encoder_predicates_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "1", "]", "]", ",", "# pick up predicates", "\n", "self", ".", "encoder_text_inputs", ":", "encoder_text_inputs", ",", "\n", "self", ".", "encoder_text_inputs_length", ":", "encoder_text_inputs_length", ",", "\n", "self", ".", "decoder_inputs", ":", "decoder_inputs", ",", "\n", "self", ".", "decoder_inputs_length", ":", "decoder_inputs_lengths", ",", "\n", "self", ".", "encoder_predicates_direction", ":", "encoder_predicates_direction", "\n", "}", "\n", "_", ",", "loss", "=", "sess", ".", "run", "(", "[", "self", ".", "updates", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.eval": [[554, 578], ["sess.run"], "methods", ["None"], ["", "def", "eval", "(", "self", ",", "sess", ",", "encoder_triples_inputs", ",", "encoder_text_inputs", ",", "encoder_text_inputs_length", ",", "decoder_inputs", ",", "decoder_inputs_lengths", ",", "encoder_predicates_direction", ")", ":", "\n", "        ", "\"\"\"\n        Run a evaluation step of the model feeding the given inputs\n        :param sess:\n        :param encoder_inputs:\n        :param encoder_inputs_length:\n        :param decoder_inputs:\n        :param decoder_inputs_lengths:\n        :return:\n        \"\"\"", "\n", "\n", "feed_dict", "=", "{", "\n", "# self.encoder_triples_inputs: encoder_triples_inputs,", "\n", "self", ".", "encoder_entities_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "# pick up subjects and objects", "\n", "self", ".", "encoder_predicates_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "1", "]", "]", ",", "# pick up predicates", "\n", "self", ".", "encoder_text_inputs", ":", "encoder_text_inputs", ",", "\n", "self", ".", "encoder_text_inputs_length", ":", "encoder_text_inputs_length", ",", "\n", "self", ".", "decoder_inputs", ":", "decoder_inputs", ",", "\n", "self", ".", "decoder_inputs_length", ":", "decoder_inputs_lengths", ",", "\n", "self", ".", "encoder_predicates_direction", ":", "encoder_predicates_direction", "\n", "}", "\n", "_", ",", "loss", "=", "sess", ".", "run", "(", "[", "self", ".", "updates", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.predict": [[579, 596], ["sess.run"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "sess", ",", "encoder_triples_inputs", ",", "encoder_text_inputs", ",", "encoder_text_inputs_length", ",", "encoder_predicates_direction", ")", ":", "\n", "        ", "\"\"\"\n        predict the output given an input\n        \"\"\"", "\n", "\n", "feed_dict", "=", "{", "\n", "# self.encoder_triples_inputs: encoder_triples_inputs,", "\n", "self", ".", "encoder_entities_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "# pick up subjects and objects", "\n", "self", ".", "encoder_predicates_inputs", ":", "encoder_triples_inputs", "[", ":", ",", "[", "1", "]", "]", ",", "# pick up predicates", "\n", "self", ".", "encoder_text_inputs", ":", "encoder_text_inputs", ",", "\n", "self", ".", "encoder_text_inputs_length", ":", "encoder_text_inputs_length", ",", "\n", "self", ".", "encoder_predicates_direction", ":", "encoder_predicates_direction", "\n", "}", "\n", "\n", "output", "=", "sess", ".", "run", "(", "[", "self", ".", "decoder_pred_inference", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "return", "output", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.save": [[597, 603], ["tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.save"], ["", "def", "save", "(", "self", ",", "sess", ",", "path", ",", "var_list", "=", "None", ",", "global_step", "=", "None", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", ")", "\n", "path", "=", "saver", ".", "save", "(", "sess", ",", "save_path", "=", "path", ",", "global_step", "=", "global_step", ")", "\n", "print", "(", "\"model saved in %s\"", "%", "path", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.restore": [[604, 616], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.restore"], ["", "def", "restore", "(", "self", ",", "sess", ",", "path", ",", "var_list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        restore trained model from a specific path\n        :param sess:\n        :param path:\n        :param var_list: if None restore all list\n        :return:\n        \"\"\"", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "path", ")", "\n", "print", "(", "\"model restored from %s\"", "%", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.bleu.bleu.Bleu.__init__": [[15, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n", "=", "4", ")", ":", "\n", "# default compute Blue score up to 4", "\n", "        ", "self", ".", "_n", "=", "n", "\n", "self", ".", "_hypo_for_image", "=", "{", "}", "\n", "self", ".", "ref_for_image", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.bleu.bleu.Bleu.compute_score": [[21, 45], ["gts.keys", "bleu_scorer.BleuScorer.BleuScorer", "bleu_scorer.BleuScorer.BleuScorer.compute_score", "gts.keys", "res.keys", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider.Cider.compute_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "\n", "        ", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "self", ".", "_n", ")", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">=", "1", ")", "\n", "\n", "bleu_scorer", "+=", "(", "hypo", "[", "0", "]", ",", "ref", ")", "\n", "\n", "#score, scores = bleu_scorer.compute_score(option='shortest')", "\n", "", "score", ",", "scores", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ",", "verbose", "=", "1", ")", "\n", "#score, scores = bleu_scorer.compute_score(option='average', verbose=1)", "\n", "\n", "# return (bleu, bleu_info)", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.bleu.bleu.Bleu.method": [[46, 48], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"Bleu\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.rouge.rouge.Rouge.__init__": [[39, 42], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# vrama91: updated the value below based on discussion with Hovey", "\n", "        ", "self", ".", "beta", "=", "1.2", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.rouge.rouge.Rouge.calc_score": [[43, 74], ["candidate[].split", "max", "max", "len", "len", "reference.split", "rouge.my_lcs", "prec.append", "rec.append", "float", "float", "float", "len", "len"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.rouge.rouge.my_lcs"], ["", "def", "calc_score", "(", "self", ",", "candidate", ",", "refs", ")", ":", "\n", "        ", "\"\"\"\n        Compute ROUGE-L score given one candidate and references for an image\n        :param candidate: str : candidate sentence to be evaluated\n        :param refs: list of str : COCO reference sentences for the particular image to be evaluated\n        :returns score: int (ROUGE-L score for the candidate evaluated against references)\n        \"\"\"", "\n", "assert", "(", "len", "(", "candidate", ")", "==", "1", ")", "\n", "assert", "(", "len", "(", "refs", ")", ">", "0", ")", "\n", "prec", "=", "[", "]", "\n", "rec", "=", "[", "]", "\n", "\n", "# split into tokens", "\n", "token_c", "=", "candidate", "[", "0", "]", ".", "split", "(", "\" \"", ")", "\n", "\n", "for", "reference", "in", "refs", ":", "\n", "# split into tokens", "\n", "            ", "token_r", "=", "reference", ".", "split", "(", "\" \"", ")", "\n", "# compute the longest common subsequence", "\n", "lcs", "=", "my_lcs", "(", "token_r", ",", "token_c", ")", "\n", "prec", ".", "append", "(", "lcs", "/", "float", "(", "len", "(", "token_c", ")", ")", ")", "\n", "rec", ".", "append", "(", "lcs", "/", "float", "(", "len", "(", "token_r", ")", ")", ")", "\n", "\n", "", "prec_max", "=", "max", "(", "prec", ")", "\n", "rec_max", "=", "max", "(", "rec", ")", "\n", "\n", "if", "(", "prec_max", "!=", "0", "and", "rec_max", "!=", "0", ")", ":", "\n", "            ", "score", "=", "(", "(", "1", "+", "self", ".", "beta", "**", "2", ")", "*", "prec_max", "*", "rec_max", ")", "/", "float", "(", "rec_max", "+", "self", ".", "beta", "**", "2", "*", "prec_max", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "0.0", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.rouge.rouge.Rouge.compute_score": [[75, 101], ["gts.keys", "numpy.mean", "gts.keys", "res.keys", "score.append", "numpy.array", "numpy.array", "rouge.Rouge.calc_score", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.rouge.rouge.Rouge.calc_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "\"\"\"\n        Computes Rouge-L score given a set of reference and candidate sentences for the dataset\n        Invoked by evaluate_captions.py \n        :param hypo_for_image: dict : candidate / test sentences with \"image name\" key and \"tokenized sentences\" as values \n        :param ref_for_image: dict : reference MS-COCO sentences with \"image name\" key and \"tokenized sentences\" as values\n        :returns: average_score: float (mean ROUGE-L score computed by averaging scores for all the images)\n        \"\"\"", "\n", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "score", "=", "[", "]", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "score", ".", "append", "(", "self", ".", "calc_score", "(", "hypo", ",", "ref", ")", ")", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">", "0", ")", "\n", "\n", "", "average_score", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "score", ")", ")", "\n", "return", "average_score", ",", "np", ".", "array", "(", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.rouge.rouge.Rouge.method": [[102, 104], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"Rouge\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.rouge.rouge.my_lcs": [[11, 33], ["range", "len", "len", "range", "range", "len", "len", "range", "len", "max", "len", "len", "len"], "function", ["None"], ["def", "my_lcs", "(", "string", ",", "sub", ")", ":", "\n", "    ", "\"\"\"\n    Calculates longest common subsequence for a pair of tokenized strings\n    :param string : list of str : tokens from a string split using whitespace\n    :param sub : list of str : shorter string, also split using whitespace\n    :returns: length (list of int): length of the longest common subsequence between the two strings\n\n    Note: my_lcs only gives length of the longest common subsequence, not the actual LCS\n    \"\"\"", "\n", "if", "(", "len", "(", "string", ")", "<", "len", "(", "sub", ")", ")", ":", "\n", "        ", "sub", ",", "string", "=", "string", ",", "sub", "\n", "\n", "", "lengths", "=", "[", "[", "0", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sub", ")", "+", "1", ")", "]", "for", "j", "in", "range", "(", "0", ",", "len", "(", "string", ")", "+", "1", ")", "]", "\n", "\n", "for", "j", "in", "range", "(", "1", ",", "len", "(", "sub", ")", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "string", ")", "+", "1", ")", ":", "\n", "            ", "if", "(", "string", "[", "i", "-", "1", "]", "==", "sub", "[", "j", "-", "1", "]", ")", ":", "\n", "                ", "lengths", "[", "i", "]", "[", "j", "]", "=", "lengths", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "+", "1", "\n", "", "else", ":", "\n", "                ", "lengths", "[", "i", "]", "[", "j", "]", "=", "max", "(", "lengths", "[", "i", "-", "1", "]", "[", "j", "]", ",", "lengths", "[", "i", "]", "[", "j", "-", "1", "]", ")", "\n", "\n", "", "", "", "return", "lengths", "[", "len", "(", "string", ")", "]", "[", "len", "(", "sub", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.meteor.meteor.Meteor.__init__": [[17, 27], ["subprocess.Popen", "threading.Lock", "os.path.dirname", "os.path.abspath"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "meteor_cmd", "=", "[", "'java'", ",", "'-jar'", ",", "'-Xmx2G'", ",", "METEOR_JAR", ",", "'-'", ",", "'-'", ",", "'-stdio'", ",", "'-l'", ",", "'en'", ",", "'-norm'", "]", "\n", "self", ".", "meteor_p", "=", "subprocess", ".", "Popen", "(", "self", ".", "meteor_cmd", ",", "cwd", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "stdin", "=", "subprocess", ".", "PIPE", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ")", "\n", "# Used to guarantee thread safety", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.meteor.meteor.Meteor.compute_score": [[28, 47], ["gts.keys", "meteor.Meteor.lock.acquire", "meteor.Meteor.meteor_p.stdin.write", "range", "float", "meteor.Meteor.lock.release", "gts.keys", "res.keys", "meteor.Meteor._stat", "len", "scores.append", "meteor.Meteor.meteor_p.stdout.readline().strip", "len", "float", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.meteor.meteor.Meteor._stat"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "scores", "=", "[", "]", "\n", "\n", "eval_line", "=", "'EVAL'", "\n", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "for", "i", "in", "imgIds", ":", "\n", "            ", "assert", "(", "len", "(", "res", "[", "i", "]", ")", "==", "1", ")", "\n", "stat", "=", "self", ".", "_stat", "(", "res", "[", "i", "]", "[", "0", "]", ",", "gts", "[", "i", "]", ")", "\n", "eval_line", "+=", "' ||| {}'", ".", "format", "(", "stat", ")", "\n", "\n", "", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "eval_line", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "imgIds", ")", ")", ":", "\n", "            ", "scores", ".", "append", "(", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", ")", "\n", "", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.meteor.meteor.Meteor.method": [[48, 50], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"METEOR\"", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.meteor.meteor.Meteor._stat": [[51, 57], ["hypothesis_str.replace().replace.replace().replace.replace().replace", "meteor.Meteor.meteor_p.stdin.write", "meteor.Meteor.meteor_p.stdout.readline().strip", "hypothesis_str.replace().replace.replace().replace.replace", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["None"], ["", "def", "_stat", "(", "self", ",", "hypothesis_str", ",", "reference_list", ")", ":", "\n", "# SCORE ||| reference 1 words ||| reference n words ||| hypothesis words", "\n", "        ", "hypothesis_str", "=", "hypothesis_str", ".", "replace", "(", "'|||'", ",", "''", ")", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "score_line", "=", "' ||| '", ".", "join", "(", "(", "'SCORE'", ",", "' ||| '", ".", "join", "(", "reference_list", ")", ",", "hypothesis_str", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "score_line", ")", ")", "\n", "return", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.meteor.meteor.Meteor._score": [[58, 74], ["meteor.Meteor.lock.acquire", "hypothesis_str.replace().replace.replace().replace.replace().replace", "meteor.Meteor.meteor_p.stdin.write", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdin.write", "float", "float", "meteor.Meteor.lock.release", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdout.readline().strip", "hypothesis_str.replace().replace.replace().replace.replace", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["None"], ["", "def", "_score", "(", "self", ",", "hypothesis_str", ",", "reference_list", ")", ":", "\n", "        ", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "# SCORE ||| reference 1 words ||| reference n words ||| hypothesis words", "\n", "hypothesis_str", "=", "hypothesis_str", ".", "replace", "(", "'|||'", ",", "''", ")", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "score_line", "=", "' ||| '", ".", "join", "(", "(", "'SCORE'", ",", "' ||| '", ".", "join", "(", "reference_list", ")", ",", "hypothesis_str", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "score_line", ")", ")", "\n", "stats", "=", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "eval_line", "=", "'EVAL ||| {}'", ".", "format", "(", "stats", ")", "\n", "# EVAL ||| stats ", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "eval_line", ")", ")", "\n", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "# bug fix: there are two values returned by the jar file, one average, and one all, so do it twice", "\n", "# thanks for Andrej for pointing this out", "\n", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.meteor.meteor.Meteor.__del__": [[75, 81], ["meteor.Meteor.lock.acquire", "meteor.Meteor.meteor_p.stdin.close", "meteor.Meteor.meteor_p.kill", "meteor.Meteor.meteor_p.wait", "meteor.Meteor.lock.release"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "close", "(", ")", "\n", "self", ".", "meteor_p", ".", "kill", "(", ")", "\n", "self", ".", "meteor_p", ".", "wait", "(", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.tokenizer.ptbtokenizer.PTBTokenizer.tokenize": [[27, 69], ["os.path.dirname", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.close", "cmd.append", "subprocess.Popen", "token_lines.split", "os.remove", "zip", "os.path.abspath", "os.path.basename", "subprocess.Popen.communicate", "final_tokenized_captions_for_image[].append", "captions_for_image.items", "range", "c.replace", "len", "captions_for_image.items", "sentences.rstrip", "line.rstrip().split", "line.rstrip"], "methods", ["None"], ["def", "tokenize", "(", "self", ",", "captions_for_image", ")", ":", "\n", "        ", "cmd", "=", "[", "'java'", ",", "'-cp'", ",", "STANFORD_CORENLP_3_4_1_JAR", ",", "'edu.stanford.nlp.process.PTBTokenizer'", ",", "'-preserveLines'", ",", "'-lowerCase'", "]", "\n", "\n", "# ======================================================", "\n", "# prepare data for PTB Tokenizer", "\n", "# ======================================================", "\n", "final_tokenized_captions_for_image", "=", "{", "}", "\n", "image_id", "=", "[", "k", "for", "k", ",", "v", "in", "captions_for_image", ".", "items", "(", ")", "for", "_", "in", "range", "(", "len", "(", "v", ")", ")", "]", "\n", "sentences", "=", "'\\n'", ".", "join", "(", "[", "c", ".", "replace", "(", "'\\n'", ",", "' '", ")", "for", "k", ",", "v", "in", "captions_for_image", ".", "items", "(", ")", "for", "c", "in", "v", "]", ")", "\n", "\n", "# ======================================================", "\n", "# save sentences to temporary file", "\n", "# ======================================================", "\n", "path_to_jar_dirname", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "tmp_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ",", "dir", "=", "path_to_jar_dirname", ")", "\n", "tmp_file", ".", "write", "(", "sentences", ")", "\n", "tmp_file", ".", "close", "(", ")", "\n", "\n", "# ======================================================", "\n", "# tokenize sentence", "\n", "# ======================================================", "\n", "cmd", ".", "append", "(", "os", ".", "path", ".", "basename", "(", "tmp_file", ".", "name", ")", ")", "\n", "p_tokenizer", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "cwd", "=", "path_to_jar_dirname", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "token_lines", "=", "p_tokenizer", ".", "communicate", "(", "input", "=", "sentences", ".", "rstrip", "(", ")", ")", "[", "0", "]", "\n", "lines", "=", "token_lines", ".", "split", "(", "'\\n'", ")", "\n", "# remove temp file", "\n", "os", ".", "remove", "(", "tmp_file", ".", "name", ")", "\n", "\n", "# ======================================================", "\n", "# create dictionary for tokenized captions", "\n", "# ======================================================", "\n", "for", "k", ",", "line", "in", "zip", "(", "image_id", ",", "lines", ")", ":", "\n", "            ", "if", "not", "k", "in", "final_tokenized_captions_for_image", ":", "\n", "                ", "final_tokenized_captions_for_image", "[", "k", "]", "=", "[", "]", "\n", "", "tokenized_caption", "=", "' '", ".", "join", "(", "[", "w", "for", "w", "in", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "if", "w", "not", "in", "PUNCTUATIONS", "]", ")", "\n", "final_tokenized_captions_for_image", "[", "k", "]", ".", "append", "(", "tokenized_caption", ")", "\n", "\n", "", "return", "final_tokenized_captions_for_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.copy": [[51, 57], ["cider_scorer.CiderScorer", "copy.copy", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.copy"], ["def", "copy", "(", "self", ")", ":", "\n", "        ", "''' copy the refs.'''", "\n", "new", "=", "CiderScorer", "(", "n", "=", "self", ".", "n", ")", "\n", "new", ".", "ctest", "=", "copy", ".", "copy", "(", "self", ".", "ctest", ")", "\n", "new", ".", "crefs", "=", "copy", ".", "copy", "(", "self", ".", "crefs", ")", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.__init__": [[58, 67], ["collections.defaultdict", "cider_scorer.CiderScorer.cook_append"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.cook_append"], ["", "def", "__init__", "(", "self", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ")", ":", "\n", "        ", "''' singular instance '''", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "self", ".", "document_frequency", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "cook_append", "(", "test", ",", "refs", ")", "\n", "self", ".", "ref_len", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.cook_append": [[68, 77], ["cider_scorer.CiderScorer.crefs.append", "cider_scorer.cook_refs", "cider_scorer.CiderScorer.ctest.append", "cider_scorer.CiderScorer.ctest.append", "cider_scorer.cook_test"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.cook_refs", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.cook_test"], ["", "def", "cook_append", "(", "self", ",", "test", ",", "refs", ")", ":", "\n", "        ", "'''called by constructor and __iadd__ to avoid creating new instances.'''", "\n", "\n", "if", "refs", "is", "not", "None", ":", "\n", "            ", "self", ".", "crefs", ".", "append", "(", "cook_refs", "(", "refs", ")", ")", "\n", "if", "test", "is", "not", "None", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "cook_test", "(", "test", ")", ")", "## N.B.: -1", "\n", "", "else", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "None", ")", "# lens of crefs and ctest have to match", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.size": [[78, 81], ["len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "crefs", ")", "==", "len", "(", "self", ".", "ctest", ")", ",", "\"refs/test mismatch! %d<>%d\"", "%", "(", "len", "(", "self", ".", "crefs", ")", ",", "len", "(", "self", ".", "ctest", ")", ")", "\n", "return", "len", "(", "self", ".", "crefs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.__iadd__": [[82, 93], ["type", "cider_scorer.CiderScorer.cook_append", "cider_scorer.CiderScorer.ctest.extend", "cider_scorer.CiderScorer.crefs.extend"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.cook_append"], ["", "def", "__iadd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "'''add an instance (e.g., from another sentence).'''", "\n", "\n", "if", "type", "(", "other", ")", "is", "tuple", ":", "\n", "## avoid creating new CiderScorer instances", "\n", "            ", "self", ".", "cook_append", "(", "other", "[", "0", "]", ",", "other", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ctest", ".", "extend", "(", "other", ".", "ctest", ")", "\n", "self", ".", "crefs", ".", "extend", "(", "other", ".", "crefs", ")", "\n", "\n", "", "return", "self", "\n", "", "def", "compute_doc_freq", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.compute_doc_freq": [[93, 104], ["set", "ref.iteritems"], "methods", ["None"], ["", "def", "compute_doc_freq", "(", "self", ")", ":", "\n", "        ", "'''\n        Compute term frequency for reference data.\n        This will be used to compute idf (inverse document frequency later)\n        The term frequency is stored in the object\n        :return: None\n        '''", "\n", "for", "refs", "in", "self", ".", "crefs", ":", "\n", "# refs, k ref captions of one image", "\n", "            ", "for", "ngram", "in", "set", "(", "[", "ngram", "for", "ref", "in", "refs", "for", "(", "ngram", ",", "count", ")", "in", "ref", ".", "iteritems", "(", ")", "]", ")", ":", "\n", "                ", "self", ".", "document_frequency", "[", "ngram", "]", "+=", "1", "\n", "# maxcounts[ngram] = max(maxcounts.get(ngram,0), count)", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.compute_cider": [[106, 182], ["numpy.log", "zip", "cnts.iteritems", "float", "numpy.array", "range", "float", "cider_scorer.CiderScorer.compute_cider.counts2vec"], "methods", ["None"], ["", "", "", "def", "compute_cider", "(", "self", ")", ":", "\n", "        ", "def", "counts2vec", "(", "cnts", ")", ":", "\n", "            ", "\"\"\"\n            Function maps counts of ngram to vector of tfidf weights.\n            The function returns vec, an array of dictionary that store mapping of n-gram and tf-idf weights.\n            The n-th entry of array denotes length of n-grams.\n            :param cnts:\n            :return: vec (array of dict), norm (array of float), length (int)\n            \"\"\"", "\n", "vec", "=", "[", "defaultdict", "(", "float", ")", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "length", "=", "0", "\n", "norm", "=", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "for", "(", "ngram", ",", "term_freq", ")", "in", "cnts", ".", "iteritems", "(", ")", ":", "\n", "# give word count 1 if it doesn't appear in reference corpus", "\n", "                ", "df", "=", "np", ".", "log", "(", "max", "(", "1.0", ",", "self", ".", "document_frequency", "[", "ngram", "]", ")", ")", "\n", "# ngram index", "\n", "n", "=", "len", "(", "ngram", ")", "-", "1", "\n", "# tf (term_freq) * idf (precomputed idf) for n-grams", "\n", "vec", "[", "n", "]", "[", "ngram", "]", "=", "float", "(", "term_freq", ")", "*", "(", "self", ".", "ref_len", "-", "df", ")", "\n", "# compute norm for the vector.  the norm will be used for computing similarity", "\n", "norm", "[", "n", "]", "+=", "pow", "(", "vec", "[", "n", "]", "[", "ngram", "]", ",", "2", ")", "\n", "\n", "if", "n", "==", "1", ":", "\n", "                    ", "length", "+=", "term_freq", "\n", "", "", "norm", "=", "[", "np", ".", "sqrt", "(", "n", ")", "for", "n", "in", "norm", "]", "\n", "return", "vec", ",", "norm", ",", "length", "\n", "\n", "", "def", "sim", "(", "vec_hyp", ",", "vec_ref", ",", "norm_hyp", ",", "norm_ref", ",", "length_hyp", ",", "length_ref", ")", ":", "\n", "            ", "'''\n            Compute the cosine similarity of two vectors.\n            :param vec_hyp: array of dictionary for vector corresponding to hypothesis\n            :param vec_ref: array of dictionary for vector corresponding to reference\n            :param norm_hyp: array of float for vector corresponding to hypothesis\n            :param norm_ref: array of float for vector corresponding to reference\n            :param length_hyp: int containing length of hypothesis\n            :param length_ref: int containing length of reference\n            :return: array of score for each n-grams cosine similarity\n            '''", "\n", "delta", "=", "float", "(", "length_hyp", "-", "length_ref", ")", "\n", "# measure consine similarity", "\n", "val", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "# ngram", "\n", "                ", "for", "(", "ngram", ",", "count", ")", "in", "vec_hyp", "[", "n", "]", ".", "iteritems", "(", ")", ":", "\n", "# vrama91 : added clipping", "\n", "                    ", "val", "[", "n", "]", "+=", "min", "(", "vec_hyp", "[", "n", "]", "[", "ngram", "]", ",", "vec_ref", "[", "n", "]", "[", "ngram", "]", ")", "*", "vec_ref", "[", "n", "]", "[", "ngram", "]", "\n", "\n", "", "if", "(", "norm_hyp", "[", "n", "]", "!=", "0", ")", "and", "(", "norm_ref", "[", "n", "]", "!=", "0", ")", ":", "\n", "                    ", "val", "[", "n", "]", "/=", "(", "norm_hyp", "[", "n", "]", "*", "norm_ref", "[", "n", "]", ")", "\n", "\n", "", "assert", "(", "not", "math", ".", "isnan", "(", "val", "[", "n", "]", ")", ")", "\n", "# vrama91: added a length based gaussian penalty", "\n", "val", "[", "n", "]", "*=", "np", ".", "e", "**", "(", "-", "(", "delta", "**", "2", ")", "/", "(", "2", "*", "self", ".", "sigma", "**", "2", ")", ")", "\n", "", "return", "val", "\n", "\n", "# compute log reference length", "\n", "", "self", ".", "ref_len", "=", "np", ".", "log", "(", "float", "(", "len", "(", "self", ".", "crefs", ")", ")", ")", "\n", "\n", "scores", "=", "[", "]", "\n", "for", "test", ",", "refs", "in", "zip", "(", "self", ".", "ctest", ",", "self", ".", "crefs", ")", ":", "\n", "# compute vector for test captions", "\n", "            ", "vec", ",", "norm", ",", "length", "=", "counts2vec", "(", "test", ")", "\n", "# compute vector for ref captions", "\n", "score", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "ref", "in", "refs", ":", "\n", "                ", "vec_ref", ",", "norm_ref", ",", "length_ref", "=", "counts2vec", "(", "ref", ")", "\n", "score", "+=", "sim", "(", "vec", ",", "vec_ref", ",", "norm", ",", "norm_ref", ",", "length", ",", "length_ref", ")", "\n", "# change by vrama91 - mean of ngram scores, instead of sum", "\n", "", "score_avg", "=", "np", ".", "mean", "(", "score", ")", "\n", "# divide by number of references", "\n", "score_avg", "/=", "len", "(", "refs", ")", "\n", "# multiply score by 10", "\n", "score_avg", "*=", "10.0", "\n", "# append score of an image to the score list", "\n", "scores", ".", "append", "(", "score_avg", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.compute_score": [[183, 193], ["cider_scorer.CiderScorer.compute_doc_freq", "cider_scorer.CiderScorer.compute_cider", "len", "max", "numpy.mean", "numpy.array", "cider_scorer.CiderScorer.document_frequency.values", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.compute_doc_freq", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.CiderScorer.compute_cider"], ["", "def", "compute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "# compute idf", "\n", "        ", "self", ".", "compute_doc_freq", "(", ")", "\n", "# assert to check document frequency", "\n", "assert", "(", "len", "(", "self", ".", "ctest", ")", ">=", "max", "(", "self", ".", "document_frequency", ".", "values", "(", ")", ")", ")", "\n", "# compute cider score", "\n", "score", "=", "self", ".", "compute_cider", "(", ")", "\n", "# debug", "\n", "# print score", "\n", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "score", ")", ")", ",", "np", ".", "array", "(", "score", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.precook": [[11, 27], ["s.split", "collections.defaultdict", "xrange", "xrange", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.\n    :param s: string : sentence to be converted into ngrams\n    :param n: int    : number of ngrams for which representation is calculated\n    :return: term frequency vector for occuring ngrams\n    \"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "xrange", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "xrange", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.cook_refs": [[28, 37], ["cider_scorer.precook"], "function", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.precook"], ["", "def", "cook_refs", "(", "refs", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\n    :param refs: list of string : reference sentences for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (list of dict)\n    '''", "\n", "return", "[", "precook", "(", "ref", ",", "n", ")", "for", "ref", "in", "refs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.cook_test": [[38, 46], ["cider_scorer.precook"], "function", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider_scorer.precook"], ["", "def", "cook_test", "(", "test", ",", "n", "=", "4", ")", ":", "\n", "    ", "'''Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.\n    :param test: list of string : hypothesis sentence for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (dict)\n    '''", "\n", "return", "precook", "(", "test", ",", "n", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider.Cider.__init__": [[18, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ")", ":", "\n", "# set cider to sum over 1 to 4-grams", "\n", "        ", "self", ".", "_n", "=", "n", "\n", "# set the standard deviation parameter for gaussian penalty", "\n", "self", ".", "_sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider.Cider.compute_score": [[24, 52], ["gts.keys", "cider_scorer.CiderScorer.CiderScorer", "cider_scorer.CiderScorer.CiderScorer.compute_score", "gts.keys", "res.keys", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider.Cider.compute_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "\"\"\"\n        Main function to compute CIDEr score\n        :param  hypo_for_image (dict) : dictionary with key <image> and value <tokenized hypothesis / candidate sentence>\n                ref_for_image (dict)  : dictionary with key <image> and value <tokenized reference sentence>\n        :return: cider (float) : computed CIDEr score for the corpus \n        \"\"\"", "\n", "\n", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "cider_scorer", "=", "CiderScorer", "(", "n", "=", "self", ".", "_n", ",", "sigma", "=", "self", ".", "_sigma", ")", "\n", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">", "0", ")", "\n", "\n", "cider_scorer", "+=", "(", "hypo", "[", "0", "]", ",", "ref", ")", "\n", "\n", "", "(", "score", ",", "scores", ")", "=", "cider_scorer", ".", "compute_score", "(", ")", "\n", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.cider.cider.Cider.method": [[53, 55], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"CIDEr\"", "", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.SELECT.__init__": [[12, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mode", "=", "\"pred\"", ")", ":", "\n", "        ", "\"\"\"\n        :param mode: subtype, pred, or objtype\n               if pred : select objtype\n               if subtype of objtype: select pred\n        \"\"\"", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.SELECT.train": [[21, 30], ["dict", "dict", "zip", "zip"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "x", ",", "y", ",", "textual_evidence", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "train_x", "=", "x", "\n", "self", ".", "train_y", "=", "y", "\n", "\n", "if", "self", ".", "mode", "==", "\"pred\"", ":", "\n", "            ", "self", ".", "train_data", "=", "dict", "(", "zip", "(", "[", "i", "[", "2", "]", "for", "i", "in", "x", "]", ",", "y", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "train_data", "=", "dict", "(", "zip", "(", "[", "i", "[", "1", "]", "for", "i", "in", "x", "]", ",", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.SELECT.test": [[31, 47], ["y.append", "random.randint", "y.append", "len", "baselines.SELECT.train_data.values", "baselines.SELECT.train_data.values"], "methods", ["None"], ["", "", "def", "test", "(", "self", ",", "x", ",", "textual_evidence", "=", "None", ")", ":", "\n", "\n", "        ", "if", "self", ".", "mode", "==", "\"pred\"", ":", "\n", "            ", "x", "=", "[", "i", "[", "2", "]", "for", "i", "in", "x", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "[", "i", "[", "1", "]", "for", "i", "in", "x", "]", "\n", "\n", "", "y", "=", "[", "]", "\n", "for", "i", "in", "x", ":", "\n", "            ", "if", "i", "in", "self", ".", "train_data", ":", "\n", "                ", "y", ".", "append", "(", "self", ".", "train_data", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "r", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "train_data", ".", "values", "(", ")", ")", "-", "1", ")", "\n", "y", ".", "append", "(", "self", ".", "train_data", ".", "values", "(", ")", "[", "r", "]", ")", "\n", "\n", "", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.IR.__init__": [[50, 60], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "TEXT", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n\n        :param TEXT: boolean to determine doing IR over text or IR over KB embeddings\n        \"\"\"", "\n", "\n", "self", ".", "K", "=", "5", "\n", "self", ".", "RADIUS", "=", "0.4", "\n", "self", ".", "N_COMPONENTS", "=", "200", "\n", "self", ".", "TEXT", "=", "TEXT", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.IR.train": [[61, 88], ["print", "sklearn.feature_extraction.text.CountVectorizer().fit", "baselines.IR.count_vect.transform", "sklearn.feature_extraction.text.TfidfTransformer().fit", "baselines.IR.tf_transformer.transform", "sklearn.decomposition.TruncatedSVD().fit", "baselines.IR.svd.transform", "print", "sklearn.neighbors.NearestNeighbors", "baselines.IR.neigh.fit", "str", "sklearn.feature_extraction.text.CountVectorizer", "sklearn.feature_extraction.text.TfidfTransformer", "sklearn.decomposition.TruncatedSVD"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "x", ",", "y", ",", "textual_evidence", "=", "None", ")", ":", "\n", "\n", "        ", "if", "self", ".", "TEXT", ":", "\n", "            ", "x", "=", "textual_evidence", "\n", "\n", "x", "=", "[", "str", "(", "i", ")", "for", "i", "in", "x", "]", "# make sure every word is string", "\n", "\n", "", "self", ".", "train_x", "=", "x", "\n", "self", ".", "train_y", "=", "y", "\n", "\n", "# VECTORIZATION", "\n", "print", "(", "\"vectorization..\"", ")", "\n", "# X = np.concatenate([train['triples_prep'], test['triples_prep']])", "\n", "\n", "self", ".", "count_vect", "=", "CountVectorizer", "(", ")", ".", "fit", "(", "x", ")", "\n", "x", "=", "self", ".", "count_vect", ".", "transform", "(", "x", ")", "\n", "\n", "self", ".", "tf_transformer", "=", "TfidfTransformer", "(", ")", ".", "fit", "(", "x", ")", "\n", "x", "=", "self", ".", "tf_transformer", ".", "transform", "(", "x", ")", "\n", "\n", "self", ".", "svd", "=", "TruncatedSVD", "(", "n_components", "=", "self", ".", "N_COMPONENTS", ")", ".", "fit", "(", "x", ")", "\n", "x", "=", "self", ".", "svd", ".", "transform", "(", "x", ")", "\n", "\n", "# CLUSTERING", "\n", "print", "(", "\"clustering..\"", ")", "\n", "self", ".", "neigh", "=", "NearestNeighbors", "(", "self", ".", "K", ",", "self", ".", "RADIUS", ")", "\n", "self", ".", "neigh", ".", "fit", "(", "x", ")", "# clustering only training set", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.IR.test": [[89, 104], ["baselines.IR.count_vect.transform", "baselines.IR.tf_transformer.transform", "baselines.IR.svd.transform", "baselines.IR.neigh.kneighbors", "str"], "methods", ["None"], ["", "def", "test", "(", "self", ",", "x", ",", "textual_evidence", "=", "None", ")", ":", "\n", "\n", "        ", "if", "self", ".", "TEXT", ":", "\n", "            ", "x", "=", "textual_evidence", "\n", "\n", "", "x", "=", "[", "str", "(", "i", ")", "for", "i", "in", "x", "]", "# make sure every word is string", "\n", "\n", "x", "=", "self", ".", "count_vect", ".", "transform", "(", "x", ")", "\n", "x", "=", "self", ".", "tf_transformer", ".", "transform", "(", "x", ")", "\n", "x", "=", "self", ".", "svd", ".", "transform", "(", "x", ")", "\n", "\n", "dist", ",", "id", "=", "self", ".", "neigh", ".", "kneighbors", "(", "x", ",", "1", ")", "\n", "y", "=", "self", ".", "train_y", "[", "id", "[", "0", "]", "[", "0", "]", "]", "\n", "\n", "return", "[", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.RTransE.__init__": [[108, 115], ["pickle.load", "pickle.load", "open", "open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transe_entities_path", ",", "transe_predicates_path", ")", ":", "\n", "\n", "        ", "self", ".", "K", "=", "5", "\n", "self", ".", "RADIUS", "=", "0.4", "\n", "self", ".", "N_COMPONENTS", "=", "200", "\n", "self", ".", "Etranse", "=", "pickle", ".", "load", "(", "open", "(", "transe_entities_path", ")", ")", "\n", "self", ".", "Ptranse", "=", "pickle", ".", "load", "(", "open", "(", "transe_predicates_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.RTransE.train": [[116, 127], ["numpy.array", "print", "sklearn.neighbors.NearestNeighbors", "baselines.RTransE.neigh.fit", "numpy.concatenate"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "x", ",", "y", ",", "textual_evidence", "=", "None", ")", ":", "\n", "\n", "        ", "x", "=", "np", ".", "array", "(", "[", "np", ".", "concatenate", "(", "(", "self", ".", "Etranse", "[", "i", "[", "0", "]", "]", ",", "self", ".", "Ptranse", "[", "i", "[", "1", "]", "]", ",", "self", ".", "Etranse", "[", "i", "[", "2", "]", "]", ")", ")", "for", "i", "in", "x", "]", ")", "\n", "\n", "self", ".", "train_x", "=", "x", "\n", "self", ".", "train_y", "=", "y", "\n", "\n", "# CLUSTERING", "\n", "print", "(", "\"clustering..\"", ")", "\n", "self", ".", "neigh", "=", "NearestNeighbors", "(", "self", ".", "K", ",", "self", ".", "RADIUS", ")", "\n", "self", ".", "neigh", ".", "fit", "(", "x", ")", "# clustering only training set", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.baselines.baselines.RTransE.test": [[128, 136], ["numpy.array", "baselines.RTransE.neigh.kneighbors", "numpy.concatenate"], "methods", ["None"], ["", "def", "test", "(", "self", ",", "x", ",", "textual_evidence", "=", "None", ")", ":", "\n", "\n", "        ", "x", "=", "np", ".", "array", "(", "[", "np", ".", "concatenate", "(", "(", "self", ".", "Etranse", "[", "i", "[", "0", "]", "]", ",", "self", ".", "Ptranse", "[", "i", "[", "1", "]", "]", ",", "self", ".", "Etranse", "[", "i", "[", "2", "]", "]", ")", ")", "for", "i", "in", "x", "]", ")", "\n", "\n", "dist", ",", "id", "=", "self", ".", "neigh", ".", "kneighbors", "(", "x", ",", "1", ")", "\n", "y", "=", "self", ".", "train_y", "[", "id", "[", "0", "]", "[", "0", "]", "]", "\n", "\n", "return", "[", "y", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.Data.__init__": [[13, 50], ["numpy.random.seed", "data.Data.__init__.return_vocab"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "datapath", "=", "None", ",", "seed", "=", "3", ",", "remove_unk", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "remove_unk", "=", "remove_unk", "\n", "\n", "if", "datapath", "is", "None", ":", "\n", "            ", "datapath", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "\"./preprocessed\"", ")", "\n", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "# loading vocab", "\n", "def", "return_vocab", "(", "filename", ")", ":", "\n", "\n", "            ", "keys", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "open", "(", "filename", ")", ".", "readlines", "(", ")", "]", "\n", "values", "=", "range", "(", "0", ",", "len", "(", "keys", ")", ")", "\n", "return", "dict", "(", "zip", "(", "keys", ",", "values", ")", ")", "\n", "\n", "", "def", "return_inv_vocab", "(", "filename", ")", ":", "\n", "\n", "            ", "keys", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "open", "(", "filename", ")", ".", "readlines", "(", ")", "]", "\n", "values", "=", "range", "(", "0", ",", "len", "(", "keys", ")", ")", "\n", "return", "dict", "(", "zip", "(", "values", ",", "keys", ")", ")", "\n", "\n", "", "self", ".", "entityvocab", "=", "return_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"entity.vocab\"", ")", ")", "\n", "self", ".", "propertyvocab", "=", "return_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"property.vocab\"", ")", ")", "\n", "self", ".", "wordvocab", "=", "return_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"word.vocab\"", ")", ")", "\n", "\n", "self", ".", "inv_entityvocab", "=", "return_inv_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"entity.vocab\"", ")", ")", "\n", "self", ".", "inv_propertyvocab", "=", "return_inv_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"property.vocab\"", ")", ")", "\n", "self", ".", "inv_wordvocab", "=", "return_inv_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"word.vocab\"", ")", ")", "\n", "\n", "# loading data files names", "\n", "self", ".", "datafile", "=", "{", "\"train\"", ":", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"train.ids\"", ")", ",", "\n", "\"valid\"", ":", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"valid.ids\"", ")", ",", "\n", "\"test\"", ":", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"valid.ids\"", ")", "\n", "}", "\n", "\n", "self", ".", "data", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.Data.read_data": [[51, 85], ["pandas.read_csv", "pandas.read_csv.reset_index", "pandas.read_csv.iterrows", "pandas.read_csv.apply", "pandas.read_csv.apply", "pandas.read_csv.apply", "pandas.read_csv.apply", "pandas.read_csv.apply", "tmp[].append", "tmp[].append", "tmp[].append", "tmp[].append", "len", "len", "len", "len", "pandas.read_csv.apply", "int", "int", "int", "int", "[].split", "[].split", "[].split", "[].split", "str", "i[].split"], "methods", ["None"], ["", "def", "read_data", "(", "self", ",", "mode", ")", ":", "\n", "# modes = [\"train\", \"test\", \"valid\"]", "\n", "        ", "data", "=", "[", "]", "\n", "\n", "f", "=", "self", ".", "datafile", "[", "mode", "]", "\n", "x", "=", "pd", ".", "read_csv", "(", "f", ",", "names", "=", "[", "\"sub\"", ",", "\"pred\"", ",", "\"obj\"", ",", "\"question\"", ",", "\"subtype\"", ",", "\"objtype\"", ",", "\"dep\"", ",", "\"direction\"", ",", "\"placeholder_dict\"", "]", ")", "\n", "\n", "if", "self", ".", "remove_unk", ":", "\n", "            ", "unkdep", "=", "self", ".", "wordvocab", "[", "\"_UNK_DEP_\"", "]", "if", "\"_UNK_DEP_\"", "in", "self", ".", "wordvocab", "else", "None", "\n", "x", "=", "x", "[", "x", ".", "dep", "!=", "unkdep", "]", "\n", "x", "=", "x", "[", "x", ".", "apply", "(", "lambda", "i", ":", "str", "(", "self", ".", "wordvocab", "[", "\"_PLACEHOLDER_SUB_\"", "]", ")", "in", "i", "[", "'question'", "]", ".", "split", "(", ")", ",", "axis", "=", "1", ")", "]", "\n", "\n", "", "x", ".", "reset_index", "(", "inplace", "=", "True", ")", "\n", "\n", "tmp", "=", "[", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "]", "\n", "for", "l", "in", "x", ".", "iterrows", "(", ")", ":", "\n", "\n", "            ", "tmp", "[", "0", "]", ".", "append", "(", "[", "int", "(", "i", ")", "for", "i", "in", "l", "[", "1", "]", "[", "'question'", "]", ".", "split", "(", ")", "]", ")", "\n", "tmp", "[", "1", "]", ".", "append", "(", "[", "int", "(", "i", ")", "for", "i", "in", "l", "[", "1", "]", "[", "'subtype'", "]", ".", "split", "(", ")", "]", ")", "\n", "tmp", "[", "2", "]", ".", "append", "(", "[", "int", "(", "i", ")", "for", "i", "in", "l", "[", "1", "]", "[", "'objtype'", "]", ".", "split", "(", ")", "]", ")", "\n", "tmp", "[", "3", "]", ".", "append", "(", "[", "int", "(", "i", ")", "for", "i", "in", "l", "[", "1", "]", "[", "'dep'", "]", ".", "split", "(", ")", "]", ")", "\n", "\n", "", "x", "[", "'question'", "]", "=", "tmp", "[", "0", "]", "\n", "x", "[", "'subtype'", "]", "=", "tmp", "[", "1", "]", "\n", "x", "[", "'objtype'", "]", "=", "tmp", "[", "2", "]", "\n", "x", "[", "'dep'", "]", "=", "tmp", "[", "3", "]", "\n", "\n", "x", "[", "'question_length'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "len", "(", "l", "[", "'question'", "]", ")", ",", "axis", "=", "1", ")", "\n", "x", "[", "'subtype_length'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "len", "(", "l", "[", "'subtype'", "]", ")", ",", "axis", "=", "1", ")", "\n", "x", "[", "'objtype_length'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "len", "(", "l", "[", "'objtype'", "]", ")", ",", "axis", "=", "1", ")", "\n", "x", "[", "'dep_length'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "len", "(", "l", "[", "'dep'", "]", ")", ",", "axis", "=", "1", ")", "\n", "x", "[", "'triple'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "[", "l", "[", "'sub'", "]", ",", "l", "[", "'pred'", "]", ",", "l", "[", "'obj'", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.Data.datafeed": [[86, 107], ["data.Data.read_data", "data.Data.yield_datafeed", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.read_data", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.yield_datafeed"], ["", "def", "datafeed", "(", "self", ",", "mode", ",", "config", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n\n        :param mode: train, valid, test\n        :param config: config object\n        :param shot_percentage: float between 0 and 1 indicating the percentage of the training data taken into consideration\n        :param min_count: int indicating the minimum count of the predicates of the examples being taken in to consideration\n        :param shuffle: whether to shuffle the training data or not\n        :param kfold: a number between 1 and 10\n        :return:\n        \"\"\"", "\n", "\n", "x", "=", "self", ".", "read_data", "(", "mode", ")", "\n", "self", ".", "data", "[", "mode", "]", "=", "x", "\n", "\n", "dataids", "=", "x", ".", "index", "\n", "\n", "if", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "dataids", ")", "\n", "\n", "", "return", "self", ".", "yield_datafeed", "(", "mode", ",", "dataids", ",", "x", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.Data.yield_datafeed": [[109, 176], ["range", "enumerate", "max", "range", "data.Data.yield_datafeed.chunks"], "methods", ["None"], ["", "def", "yield_datafeed", "(", "self", ",", "mode", ",", "dataids", ",", "x", ",", "config", ")", ":", "\n", "        ", "\"\"\"\n        given a dataframe and selected ids and a mode yield data for experiments\n        :param mode:\n        :param dataids:\n        :param x:\n        :param config:\n        :return:\n        \"\"\"", "\n", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "\n", "            ", "for", "epoch", "in", "range", "(", "config", ".", "MAX_EPOCHS", ")", ":", "\n", "\n", "                ", "def", "chunks", "(", "l", ",", "n", ")", ":", "\n", "                    ", "\"\"\"Yield successive n-sized chunks from l.\"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "l", ")", ",", "n", ")", ":", "\n", "                        ", "yield", "l", "[", "i", ":", "i", "+", "n", "]", "\n", "\n", "", "", "for", "bn", ",", "batchids", "in", "enumerate", "(", "chunks", "(", "dataids", ",", "config", ".", "BATCH_SIZE", ")", ")", ":", "\n", "\n", "                    ", "batch", "=", "x", ".", "iloc", "[", "batchids", "]", "\n", "\n", "max_length", "=", "max", "(", "[", "batch", "[", "'subtype_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "batch", "[", "'objtype_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "batch", "[", "'dep_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "]", ")", "\n", "\n", "yield", "(", "\n", "np", ".", "array", "(", "[", "i", "for", "i", "in", "batch", "[", "'triple'", "]", ".", "values", "]", ")", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'subtype'", "]", ".", "values", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'subtype_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'objtype'", "]", ".", "values", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'objtype_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'dep'", "]", ".", "values", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'dep_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'question'", "]", ".", "values", ")", ",", "\n", "batch", "[", "'question_length'", "]", ".", "values", ",", "\n", "batch", "[", "'direction'", "]", ".", "values", ",", "\n", "{", "\"epoch\"", ":", "epoch", ",", "\"batch_id\"", ":", "bn", ",", "\"ids\"", ":", "batchids", ",", "\"placeholder_dict\"", ":", "[", "eval", "(", "i", ")", "for", "i", "in", "batch", "[", "\"placeholder_dict\"", "]", ".", "values", "]", "}", "# meta info", "\n", ")", "\n", "\n", "", "", "", "if", "mode", "==", "\"test\"", "or", "mode", "==", "\"valid\"", ":", "\n", "# in case of test of validation batch of size 1 and no shuffle", "\n", "# takes longer computation time but allows variable lengths", "\n", "\n", "            ", "for", "id", "in", "dataids", ":", "\n", "\n", "                ", "batch", "=", "x", ".", "iloc", "[", "[", "id", "]", "]", "\n", "\n", "max_length", "=", "max", "(", "[", "batch", "[", "'subtype_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "batch", "[", "'objtype_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "batch", "[", "'dep_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "]", ")", "\n", "\n", "yield", "(", "\n", "np", ".", "array", "(", "[", "i", "for", "i", "in", "batch", "[", "'triple'", "]", "]", ")", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'subtype'", "]", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'subtype_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'objtype'", "]", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'objtype_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'dep'", "]", ".", "values", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'dep_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'question'", "]", ".", "values", ")", ",", "\n", "batch", "[", "'question_length'", "]", ".", "values", ",", "\n", "batch", "[", "'direction'", "]", ".", "values", ",", "\n", "{", "\"ids\"", ":", "id", ",", "\"placeholder_dict\"", ":", "[", "eval", "(", "i", ")", "for", "i", "in", "batch", "[", "\"placeholder_dict\"", "]", ".", "values", "]", "}", "# meta info", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.Data.pad": [[178, 194], ["enumerate", "max", "numpy.ones", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "pad", "(", "self", ",", "x", ",", "pad_char", "=", "0", ",", "max_length", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        helper function to add padding to a batch\n        :param x: array of arrays of variable length\n        :return:  x with padding of max length\n        \"\"\"", "\n", "\n", "if", "max_length", "is", "None", ":", "\n", "            ", "max_length", "=", "max", "(", "[", "len", "(", "i", ")", "for", "i", "in", "x", "]", ")", "\n", "\n", "", "y", "=", "np", ".", "ones", "(", "[", "len", "(", "x", ")", ",", "max_length", "]", ")", "*", "pad_char", "\n", "\n", "for", "c", ",", "i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "y", "[", "c", ",", ":", "len", "(", "i", ")", "]", "=", "i", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.__init__": [[201, 243], ["numpy.random.seed", "data.FewShotsDataFeeder.__init__.return_vocab"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "datapath", "=", "None", ",", "seed", "=", "3", ",", "train_percent", "=", "0.7", ",", "test_percent", "=", "0.2", ",", "remove_unk", "=", "False", ")", ":", "\n", "\n", "        ", "assert", "0", "<", "train_percent", "+", "test_percent", "<=", "1", "\n", "\n", "self", ".", "train_percent", "=", "train_percent", "\n", "self", ".", "test_percent", "=", "test_percent", "\n", "self", ".", "valid_percent", "=", "1", "-", "(", "train_percent", "+", "test_percent", ")", "\n", "self", ".", "remove_unk", "=", "remove_unk", "\n", "\n", "if", "datapath", "is", "None", ":", "\n", "            ", "datapath", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "\"./preprocessed\"", ")", "\n", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "# loading vocab", "\n", "def", "return_vocab", "(", "filename", ")", ":", "\n", "\n", "            ", "keys", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "open", "(", "filename", ")", ".", "readlines", "(", ")", "]", "\n", "values", "=", "range", "(", "0", ",", "len", "(", "keys", ")", ")", "\n", "return", "dict", "(", "zip", "(", "keys", ",", "values", ")", ")", "\n", "\n", "", "def", "return_inv_vocab", "(", "filename", ")", ":", "\n", "\n", "            ", "keys", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "open", "(", "filename", ")", ".", "readlines", "(", ")", "]", "\n", "values", "=", "range", "(", "0", ",", "len", "(", "keys", ")", ")", "\n", "return", "dict", "(", "zip", "(", "values", ",", "keys", ")", ")", "\n", "\n", "", "self", ".", "entityvocab", "=", "return_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"entity.vocab\"", ")", ")", "\n", "self", ".", "propertyvocab", "=", "return_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"property.vocab\"", ")", ")", "\n", "self", ".", "wordvocab", "=", "return_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"word.vocab\"", ")", ")", "\n", "\n", "self", ".", "inv_entityvocab", "=", "return_inv_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"entity.vocab\"", ")", ")", "\n", "self", ".", "inv_propertyvocab", "=", "return_inv_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"property.vocab\"", ")", ")", "\n", "self", ".", "inv_wordvocab", "=", "return_inv_vocab", "(", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"word.vocab\"", ")", ")", "\n", "\n", "# loading data files names", "\n", "self", ".", "datafile", "=", "{", "\"train\"", ":", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"train.ids\"", ")", ",", "\n", "\"valid\"", ":", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"valid.ids\"", ")", ",", "\n", "\"test\"", ":", "os", ".", "path", ".", "join", "(", "datapath", ",", "\"valid.ids\"", ")", "\n", "}", "\n", "\n", "self", ".", "data", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.read_data": [[244, 280], ["pandas.concat", "pandas.concat.reset_index", "pandas.concat.iterrows", "pandas.concat.apply", "pandas.concat.apply", "pandas.concat.apply", "pandas.concat.apply", "pandas.concat.apply", "data.append", "tmp[].append", "tmp[].append", "tmp[].append", "tmp[].append", "pandas.read_csv", "len", "len", "len", "len", "pandas.concat.apply", "int", "int", "int", "int", "[].split", "[].split", "[].split", "[].split", "str", "i[].split"], "methods", ["None"], ["", "def", "read_data", "(", "self", ")", ":", "\n", "        ", "modes", "=", "[", "\"train\"", ",", "\"test\"", ",", "\"valid\"", "]", "\n", "data", "=", "[", "]", "\n", "for", "m", "in", "modes", ":", "\n", "            ", "f", "=", "self", ".", "datafile", "[", "m", "]", "\n", "data", ".", "append", "(", "pd", ".", "read_csv", "(", "f", ",", "names", "=", "[", "\"sub\"", ",", "\"pred\"", ",", "\"obj\"", ",", "\"question\"", ",", "\"subtype\"", ",", "\"objtype\"", ",", "\"dep\"", ",", "\"direction\"", ",", "\"placeholder_dict\"", "]", ")", ")", "\n", "\n", "", "x", "=", "pd", ".", "concat", "(", "data", ")", "\n", "\n", "if", "self", ".", "remove_unk", ":", "\n", "            ", "unkdep", "=", "self", ".", "wordvocab", "[", "\"_UNK_DEP_\"", "]", "if", "\"_UNK_DEP_\"", "in", "self", ".", "wordvocab", "else", "None", "\n", "x", "=", "x", "[", "x", ".", "dep", "!=", "unkdep", "]", "\n", "x", "=", "x", "[", "x", ".", "apply", "(", "lambda", "i", ":", "str", "(", "self", ".", "wordvocab", "[", "\"_PLACEHOLDER_SUB_\"", "]", ")", "in", "i", "[", "'question'", "]", ".", "split", "(", ")", ",", "axis", "=", "1", ")", "]", "\n", "\n", "", "x", ".", "reset_index", "(", "inplace", "=", "True", ")", "\n", "\n", "tmp", "=", "[", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "]", "\n", "for", "l", "in", "x", ".", "iterrows", "(", ")", ":", "\n", "\n", "            ", "tmp", "[", "0", "]", ".", "append", "(", "[", "int", "(", "i", ")", "for", "i", "in", "l", "[", "1", "]", "[", "'question'", "]", ".", "split", "(", ")", "]", ")", "\n", "tmp", "[", "1", "]", ".", "append", "(", "[", "int", "(", "i", ")", "for", "i", "in", "l", "[", "1", "]", "[", "'subtype'", "]", ".", "split", "(", ")", "]", ")", "\n", "tmp", "[", "2", "]", ".", "append", "(", "[", "int", "(", "i", ")", "for", "i", "in", "l", "[", "1", "]", "[", "'objtype'", "]", ".", "split", "(", ")", "]", ")", "\n", "tmp", "[", "3", "]", ".", "append", "(", "[", "int", "(", "i", ")", "for", "i", "in", "l", "[", "1", "]", "[", "'dep'", "]", ".", "split", "(", ")", "]", ")", "\n", "\n", "", "x", "[", "'question'", "]", "=", "tmp", "[", "0", "]", "\n", "x", "[", "'subtype'", "]", "=", "tmp", "[", "1", "]", "\n", "x", "[", "'objtype'", "]", "=", "tmp", "[", "2", "]", "\n", "x", "[", "'dep'", "]", "=", "tmp", "[", "3", "]", "\n", "\n", "x", "[", "'question_length'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "len", "(", "l", "[", "'question'", "]", ")", ",", "axis", "=", "1", ")", "\n", "x", "[", "'subtype_length'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "len", "(", "l", "[", "'subtype'", "]", ")", ",", "axis", "=", "1", ")", "\n", "x", "[", "'objtype_length'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "len", "(", "l", "[", "'objtype'", "]", ")", ",", "axis", "=", "1", ")", "\n", "x", "[", "'dep_length'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "len", "(", "l", "[", "'dep'", "]", ")", ",", "axis", "=", "1", ")", "\n", "x", "[", "'triple'", "]", "=", "x", ".", "apply", "(", "lambda", "l", ":", "[", "l", "[", "'sub'", "]", ",", "l", "[", "'pred'", "]", ",", "l", "[", "'obj'", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.filter_data": [[281, 308], ["x.groupby().filter.groupby().filter.groupby().filter", "numpy.array", "x.groupby().filter.groupby().filter.groupby", "ids.values", "x.groupby().filter.groupby().filter.groupby", "int", "numpy.append", "ids.values", "len", "math.ceil", "int", "int", "numpy.append", "ids.values", "math.ceil", "int", "int", "numpy.append", "math.ceil", "len", "math.ceil", "math.ceil", "math.ceil", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "filter_data", "(", "self", ",", "x", ",", "mode", ",", "shot_percentage", ",", "min_count", ")", ":", "\n", "\n", "# removing predicates with less than min_count examples in the labeled set", "\n", "        ", "x", "=", "x", ".", "groupby", "(", "\"pred\"", ")", ".", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">=", "min_count", ")", "\n", "ids", "=", "x", ".", "groupby", "(", "\"pred\"", ")", ".", "indices", "\n", "\n", "keep_ids", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "for", "v", "in", "ids", ".", "values", "(", ")", ":", "\n", "                ", "start", "=", "0", "\n", "end", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "v", ")", "*", "shot_percentage", "*", "self", ".", "train_percent", ")", ")", "\n", "keep_ids", "=", "np", ".", "append", "(", "keep_ids", ",", "v", "[", "start", ":", "end", "]", ")", "\n", "\n", "", "", "elif", "mode", "==", "\"test\"", ":", "\n", "            ", "for", "v", "in", "ids", ".", "values", "(", ")", ":", "\n", "                ", "start", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "v", ")", "*", "shot_percentage", "*", "self", ".", "train_percent", ")", ")", "\n", "end", "=", "int", "(", "start", "+", "math", ".", "ceil", "(", "len", "(", "v", ")", "*", "self", ".", "test_percent", ")", ")", "\n", "keep_ids", "=", "np", ".", "append", "(", "keep_ids", ",", "v", "[", "start", ":", "end", "]", ")", "\n", "\n", "", "", "elif", "mode", "==", "\"valid\"", ":", "\n", "\n", "            ", "for", "v", "in", "ids", ".", "values", "(", ")", ":", "\n", "                ", "start", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "v", ")", "*", "shot_percentage", "*", "self", ".", "train_percent", ")", "+", "math", ".", "ceil", "(", "len", "(", "v", ")", "*", "self", ".", "test_percent", ")", ")", "\n", "end", "=", "int", "(", "start", "+", "math", ".", "ceil", "(", "len", "(", "v", ")", "*", "self", ".", "valid_percent", ")", ")", "\n", "keep_ids", "=", "np", ".", "append", "(", "keep_ids", ",", "v", "[", "start", ":", "end", "]", ")", "\n", "\n", "", "", "return", "keep_ids", ",", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.datafeed": [[309, 331], ["data.FewShotsDataFeeder.read_data", "data.FewShotsDataFeeder.filter_data", "data.FewShotsDataFeeder.yield_datafeed", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.read_data", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.ZeroShotsDataFeeder.filter_data", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.yield_datafeed"], ["", "def", "datafeed", "(", "self", ",", "mode", ",", "config", ",", "shot_percentage", "=", "1", ",", "min_count", "=", "10", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n\n        :param mode: train, valid, test\n        :param config: config object\n        :param shot_percentage: float between 0 and 1 indicating the percentage of the training data taken into consideration\n        :param min_count: int indicating the minimum count of the predicates of the examples being taken in to consideration\n        :param shuffle: whether to shuffle the training data or not\n        :param kfold: a number between 1 and 10\n        :return:\n        \"\"\"", "\n", "\n", "x", "=", "self", ".", "read_data", "(", ")", "\n", "self", ".", "data", "[", "mode", "]", "=", "x", "\n", "\n", "dataids", ",", "x", "=", "self", ".", "filter_data", "(", "x", ",", "mode", ",", "shot_percentage", ",", "min_count", ")", "\n", "dataids", "=", "[", "i", "for", "i", "in", "dataids", "if", "i", "in", "x", ".", "index", "]", "\n", "\n", "if", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "dataids", ")", "\n", "\n", "", "return", "self", ".", "yield_datafeed", "(", "mode", ",", "dataids", ",", "x", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.yield_datafeed": [[333, 400], ["range", "enumerate", "max", "range", "data.FewShotsDataFeeder.yield_datafeed.chunks"], "methods", ["None"], ["", "def", "yield_datafeed", "(", "self", ",", "mode", ",", "dataids", ",", "x", ",", "config", ")", ":", "\n", "        ", "\"\"\"\n        given a dataframe and selected ids and a mode yield data for experiments\n        :param mode:\n        :param dataids:\n        :param x:\n        :param config:\n        :return:\n        \"\"\"", "\n", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "\n", "            ", "for", "epoch", "in", "range", "(", "config", ".", "MAX_EPOCHS", ")", ":", "\n", "\n", "                ", "def", "chunks", "(", "l", ",", "n", ")", ":", "\n", "                    ", "\"\"\"Yield successive n-sized chunks from l.\"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "l", ")", ",", "n", ")", ":", "\n", "                        ", "yield", "l", "[", "i", ":", "i", "+", "n", "]", "\n", "\n", "", "", "for", "bn", ",", "batchids", "in", "enumerate", "(", "chunks", "(", "dataids", ",", "config", ".", "BATCH_SIZE", ")", ")", ":", "\n", "\n", "                    ", "batch", "=", "x", ".", "iloc", "[", "batchids", "]", "\n", "\n", "max_length", "=", "max", "(", "[", "batch", "[", "'subtype_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "batch", "[", "'objtype_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "batch", "[", "'dep_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "]", ")", "\n", "\n", "yield", "(", "\n", "np", ".", "array", "(", "[", "i", "for", "i", "in", "batch", "[", "'triple'", "]", ".", "values", "]", ")", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'subtype'", "]", ".", "values", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'subtype_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'objtype'", "]", ".", "values", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'objtype_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'dep'", "]", ".", "values", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'dep_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'question'", "]", ".", "values", ")", ",", "\n", "batch", "[", "'question_length'", "]", ".", "values", ",", "\n", "batch", "[", "'direction'", "]", ".", "values", ",", "\n", "{", "\"epoch\"", ":", "epoch", ",", "\"batch_id\"", ":", "bn", ",", "\"ids\"", ":", "batchids", ",", "\"placeholder_dict\"", ":", "[", "eval", "(", "i", ")", "for", "i", "in", "batch", "[", "\"placeholder_dict\"", "]", ".", "values", "]", "}", "# meta info", "\n", ")", "\n", "\n", "", "", "", "if", "mode", "==", "\"test\"", "or", "mode", "==", "\"valid\"", ":", "\n", "# in case of test of validation batch of size 1 and no shuffle", "\n", "# takes longer computation time but allows variable lengths", "\n", "\n", "            ", "for", "id", "in", "dataids", ":", "\n", "\n", "                ", "batch", "=", "x", ".", "iloc", "[", "[", "id", "]", "]", "\n", "\n", "max_length", "=", "max", "(", "[", "batch", "[", "'subtype_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "batch", "[", "'objtype_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "batch", "[", "'dep_length'", "]", ".", "values", ".", "max", "(", ")", ",", "\n", "]", ")", "\n", "\n", "yield", "(", "\n", "np", ".", "array", "(", "[", "i", "for", "i", "in", "batch", "[", "'triple'", "]", "]", ")", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'subtype'", "]", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'subtype_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'objtype'", "]", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'objtype_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'dep'", "]", ".", "values", ",", "max_length", "=", "max_length", ")", ",", "\n", "batch", "[", "'dep_length'", "]", ".", "values", ",", "\n", "self", ".", "pad", "(", "batch", "[", "'question'", "]", ".", "values", ")", ",", "\n", "batch", "[", "'question_length'", "]", ".", "values", ",", "\n", "batch", "[", "'direction'", "]", ".", "values", ",", "\n", "{", "\"ids\"", ":", "id", ",", "\"placeholder_dict\"", ":", "[", "eval", "(", "i", ")", "for", "i", "in", "batch", "[", "\"placeholder_dict\"", "]", ".", "values", "]", "}", "# meta info", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.pad": [[402, 418], ["enumerate", "max", "numpy.ones", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "pad", "(", "self", ",", "x", ",", "pad_char", "=", "0", ",", "max_length", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        helper function to add padding to a batch\n        :param x: array of arrays of variable length\n        :return:  x with padding of max length\n        \"\"\"", "\n", "\n", "if", "max_length", "is", "None", ":", "\n", "            ", "max_length", "=", "max", "(", "[", "len", "(", "i", ")", "for", "i", "in", "x", "]", ")", "\n", "\n", "", "y", "=", "np", ".", "ones", "(", "[", "len", "(", "x", ")", ",", "max_length", "]", ")", "*", "pad_char", "\n", "\n", "for", "c", ",", "i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "y", "[", "c", ",", ":", "len", "(", "i", ")", "]", "=", "i", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.ZeroShotsDataFeeder.filter_data": [[422, 473], ["x.groupby().filter.groupby().filter.apply", "x.groupby().filter.groupby().filter.groupby().filter", "sorted", "numpy.array", "x.groupby().filter.groupby().filter.groupby", "sorted.items", "enumerate", "str", "x.groupby().filter.groupby().filter.groupby", "enumerate", "len", "len", "range", "numpy.append", "enumerate", "int", "range", "numpy.append", "math.ceil", "range", "int", "range", "numpy.append", "int", "math.ceil", "range", "int", "math.ceil", "int", "math.ceil", "math.ceil"], "methods", ["None"], ["    ", "def", "filter_data", "(", "self", ",", "x", ",", "mode", ",", "criteria", "=", "\"pred\"", ",", "min_count", "=", "10", ",", "kfold", "=", "10", ",", "cv", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n\n        :param x:\n        :param mode:\n        :param criteria:\n        :param min_count:\n        :param kfold:\n        :param cv:\n        :return:\n        \"\"\"", "\n", "\n", "# removing predicates with less than min_count examples in the labeled set", "\n", "criteria_hash", "=", "criteria", "+", "\"_hash\"", "\n", "x", "[", "criteria_hash", "]", "=", "x", ".", "apply", "(", "lambda", "a", ":", "str", "(", "a", "[", "criteria", "]", ")", ",", "axis", "=", "1", ")", "# make criteria hashable", "\n", "x", "=", "x", ".", "groupby", "(", "criteria_hash", ")", ".", "filter", "(", "lambda", "i", ":", "len", "(", "i", ")", ">=", "min_count", ")", "\n", "ids", "=", "x", ".", "groupby", "(", "criteria_hash", ")", ".", "indices", "\n", "ids", "=", "sorted", "(", "ids", ".", "items", "(", ")", ",", "key", "=", "lambda", "a", ":", "len", "(", "a", "[", "1", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "keep_ids", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "\n", "            ", "start", "=", "cv", "\n", "pos", "=", "[", "(", "i", "+", "start", ")", "%", "kfold", "for", "i", "in", "range", "(", "int", "(", "math", ".", "ceil", "(", "kfold", "*", "self", ".", "train_percent", ")", ")", ")", "]", "\n", "\n", "for", "c", ",", "i", "in", "enumerate", "(", "ids", ")", ":", "\n", "                ", "if", "c", "%", "kfold", "in", "pos", ":", "\n", "                    ", "keep_ids", "=", "np", ".", "append", "(", "keep_ids", ",", "i", "[", "1", "]", ")", "\n", "\n", "", "", "", "elif", "mode", "==", "\"test\"", ":", "\n", "\n", "            ", "start", "=", "cv", "\n", "start", "=", "[", "(", "i", "+", "start", "+", "1", ")", "%", "kfold", "for", "i", "in", "range", "(", "int", "(", "math", ".", "ceil", "(", "kfold", "*", "self", ".", "train_percent", ")", ")", ")", "]", "[", "-", "1", "]", "\n", "pos", "=", "[", "(", "i", "+", "start", ")", "%", "kfold", "for", "i", "in", "range", "(", "int", "(", "math", ".", "ceil", "(", "kfold", "*", "self", ".", "test_percent", ")", ")", ")", "]", "\n", "\n", "for", "c", ",", "i", "in", "enumerate", "(", "ids", ")", ":", "\n", "                ", "if", "c", "%", "kfold", "in", "pos", ":", "\n", "                    ", "keep_ids", "=", "np", ".", "append", "(", "keep_ids", ",", "i", "[", "1", "]", ")", "\n", "\n", "", "", "", "elif", "mode", "==", "\"valid\"", ":", "\n", "\n", "            ", "start", "=", "cv", "\n", "start", "=", "[", "(", "i", "+", "start", "+", "1", ")", "%", "kfold", "for", "i", "in", "range", "(", "int", "(", "math", ".", "ceil", "(", "kfold", "*", "(", "self", ".", "train_percent", "+", "self", ".", "test_percent", ")", ")", ")", ")", "]", "[", "-", "1", "]", "\n", "pos", "=", "[", "(", "i", "+", "start", ")", "%", "kfold", "for", "i", "in", "range", "(", "int", "(", "math", ".", "ceil", "(", "kfold", "*", "self", ".", "valid_percent", ")", ")", ")", "]", "\n", "\n", "for", "c", ",", "i", "in", "enumerate", "(", "ids", ")", ":", "\n", "                ", "if", "c", "%", "kfold", "in", "pos", ":", "\n", "                    ", "keep_ids", "=", "np", ".", "append", "(", "keep_ids", ",", "i", "[", "1", "]", ")", "\n", "\n", "", "", "", "return", "keep_ids", ",", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.ZeroShotsDataFeeder.datafeed": [[474, 497], ["data.ZeroShotsDataFeeder.read_data", "data.ZeroShotsDataFeeder.filter_data", "data.ZeroShotsDataFeeder.yield_datafeed", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.read_data", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.ZeroShotsDataFeeder.filter_data", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.data.data.FewShotsDataFeeder.yield_datafeed"], ["", "def", "datafeed", "(", "self", ",", "mode", ",", "config", ",", "criteria", "=", "\"pred\"", ",", "min_count", "=", "10", ",", "shuffle", "=", "True", ",", "kfold", "=", "10", ",", "cv", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n\n        :param mode: train, valid, test\n        :param config: config object\n        :param criteria: the column label to do zero shot on \"pred\" \"subtype\" \"objtype\"\n        :param shot_percentage: float between 0 and 1 indicating the percentage of the training data taken into consideration\n        :param min_count: int indicating the minimum count of the predicates of the examples being taken in to consideration\n        :param shuffle: whether to shuffle the training data or not\n        :param kfold:\n        :param cv:\n        :return:\n        \"\"\"", "\n", "\n", "x", "=", "self", ".", "read_data", "(", ")", "\n", "\n", "dataids", ",", "x", "=", "self", ".", "filter_data", "(", "x", ",", "mode", ",", "criteria", ",", "min_count", ",", "kfold", ",", "cv", ")", "\n", "dataids", "=", "[", "i", "for", "i", "in", "dataids", "if", "i", "in", "x", ".", "index", "]", "\n", "\n", "if", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "dataids", ")", "\n", "\n", "", "return", "self", ".", "yield_datafeed", "(", "mode", ",", "dataids", ",", "x", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.__init__": [[11, 54], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.name_scope", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.name_scope", "tensorflow.reduce_sum", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.contrib.layers.xavier_initializer", "abs", "abs", "tensorflow.maximum"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "\n", "        ", "self", ".", "config", "=", "config", "\n", "\n", "entity_total", "=", "config", ".", "ENTITIES_VOCAB", "\n", "size", "=", "config", ".", "ENTITIES_EMBEDDING_SIZE", "\n", "\n", "relation_total", "=", "config", ".", "PREDICATES_VOCAB", "\n", "\n", "margin", "=", "config", ".", "margin", "\n", "\n", "self", ".", "ent_embeddings", "=", "tf", ".", "get_variable", "(", "name", "=", "\"ent_embedding\"", ",", "shape", "=", "[", "entity_total", ",", "size", "]", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", "uniform", "=", "False", ")", ")", "\n", "self", ".", "rel_embeddings", "=", "tf", ".", "get_variable", "(", "name", "=", "\"rel_embedding\"", ",", "shape", "=", "[", "relation_total", ",", "size", "]", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", "uniform", "=", "False", ")", ")", "\n", "\n", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "'global_step'", ")", "\n", "\n", "self", ".", "pos_h", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "self", ".", "pos_t", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "self", ".", "pos_r", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "\n", "self", ".", "neg_h", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "self", ".", "neg_t", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "self", ".", "neg_r", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"embedding\"", ")", ":", "\n", "            ", "pos_h_e", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "ent_embeddings", ",", "self", ".", "pos_h", ")", "\n", "pos_t_e", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "ent_embeddings", ",", "self", ".", "pos_t", ")", "\n", "pos_r_e", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "rel_embeddings", ",", "self", ".", "pos_r", ")", "\n", "neg_h_e", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "ent_embeddings", ",", "self", ".", "neg_h", ")", "\n", "neg_t_e", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "ent_embeddings", ",", "self", ".", "neg_t", ")", "\n", "neg_r_e", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "rel_embeddings", ",", "self", ".", "neg_r", ")", "\n", "\n", "", "if", "config", ".", "L1_flag", ":", "\n", "            ", "pos", "=", "tf", ".", "reduce_sum", "(", "abs", "(", "pos_h_e", "+", "pos_r_e", "-", "pos_t_e", ")", ",", "1", ",", "keep_dims", "=", "True", ")", "\n", "neg", "=", "tf", ".", "reduce_sum", "(", "abs", "(", "neg_h_e", "+", "neg_r_e", "-", "neg_t_e", ")", ",", "1", ",", "keep_dims", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "pos", "=", "tf", ".", "reduce_sum", "(", "(", "pos_h_e", "+", "pos_r_e", "-", "pos_t_e", ")", "**", "2", ",", "1", ",", "keep_dims", "=", "True", ")", "\n", "neg", "=", "tf", ".", "reduce_sum", "(", "(", "neg_h_e", "+", "neg_r_e", "-", "neg_t_e", ")", "**", "2", ",", "1", ",", "keep_dims", "=", "True", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"output\"", ")", ":", "\n", "            ", "self", ".", "loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "maximum", "(", "pos", "-", "neg", "+", "margin", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.save": [[56, 62], ["tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.save"], ["", "", "def", "save", "(", "self", ",", "sess", ",", "var_list", "=", "None", ",", "global_step", "=", "None", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", ")", "\n", "path", "=", "saver", ".", "save", "(", "sess", ",", "save_path", "=", "self", ".", "config", ".", "CHECKPOINTS_PATH", ",", "global_step", "=", "global_step", ")", "\n", "print", "(", "\"model saved in %s\"", "%", "path", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.restore": [[63, 77], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print", "tensorflow.train.latest_checkpoint", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.restore"], ["", "def", "restore", "(", "self", ",", "sess", ",", "path", "=", "None", ",", "var_list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        restore trained model from a specific path\n        :param sess:\n        :param path:\n        :param var_list: if None restore all list\n        :return:\n        \"\"\"", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", ")", "\n", "if", "path", "is", "None", ":", "\n", "            ", "path", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "os", ".", "path", ".", "dirname", "(", "self", ".", "config", ".", "CHECKPOINTS_PATH", ")", ")", "\n", "", "saver", ".", "restore", "(", "sess", ",", "path", ")", "\n", "print", "(", "\"model restored from %s\"", "%", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.kbembeddings.transe.TransEModel.pickle_embeddings": [[78, 101], ["os.path.join", "os.path.join", "print", "pickle.dump", "pickle.dump", "os.path.dirname", "transe.TransEModel.ent_embeddings.eval", "open", "transe.TransEModel.rel_embeddings.eval", "open", "transe.TransEModel.ent_embeddings.eval", "transe.TransEModel.rel_embeddings.eval"], "methods", ["home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.eval", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.eval", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.eval", "home.repos.pwc.inspect_result.NAACL2018Anonymous_submission.models.tripletext2seq.TripleText2SeqModel.eval"], ["", "def", "pickle_embeddings", "(", "self", ",", "sess", ",", "path", "=", "None", ",", "ent_file_name", "=", "\"ent_embeddings.pkl\"", ",", "rel_file_name", "=", "\"rel_embeddings.pkl\"", ",", "top_entities", "=", "None", ",", "top_predicates", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :param sess: current tf session\n        :param path: path of the folder to save embeddings files in\n                     embeddings files are saved under the names\n        :param all: A\n        :return:\n        \"\"\"", "\n", "\n", "if", "path", "is", "None", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "dirname", "(", "self", ".", "config", ".", "CHECKPOINTS_PATH", ")", "\n", "\n", "", "entpath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "ent_file_name", ")", "\n", "relpath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "rel_file_name", ")", "\n", "# save generated entity embeddings and relation embeddings into a pickle file", "\n", "\n", "print", "(", "\"dumping embeddings into pickle files in %s\"", "%", "path", ")", "\n", "\n", "ent_pickle", "=", "self", ".", "ent_embeddings", ".", "eval", "(", "sess", ")", "if", "top_entities", "is", "None", "else", "self", ".", "ent_embeddings", ".", "eval", "(", "sess", ")", "[", ":", "top_entities", "]", "\n", "pickle", ".", "dump", "(", "ent_pickle", ",", "open", "(", "entpath", ",", "\"w\"", ")", ")", "\n", "rel_pickle", "=", "self", ".", "rel_embeddings", ".", "eval", "(", "sess", ")", "if", "top_predicates", "is", "None", "else", "self", ".", "rel_embeddings", ".", "eval", "(", "sess", ")", "[", ":", "top_predicates", "]", "\n", "pickle", ".", "dump", "(", "rel_pickle", ",", "open", "(", "relpath", ",", "\"w\"", ")", ")", "\n", "\n"]]}