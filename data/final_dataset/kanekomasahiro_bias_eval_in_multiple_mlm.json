{"home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.parse_args": [[16, 28], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--lang'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "choices", "=", "[", "'en'", ",", "'de'", ",", "'ja'", ",", "'ar'", ",", "'es'", ",", "'pt'", ",", "'ru'", ",", "'id'", ",", "'zh'", "]", ",", "\n", "help", "=", "'Path to evaluation dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'--method'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "choices", "=", "[", "'aula'", ",", "'aul'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--corpus'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "choices", "=", "[", "'ted'", ",", "'news'", "]", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.load_tokenizer_and_model": [[30, 64], ["transformers.AutoModelForMaskedLM.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "model.eval.eval", "torch.cuda.is_available", "model.eval.to"], "function", ["None"], ["", "def", "load_tokenizer_and_model", "(", "args", ")", ":", "\n", "    ", "'''\n    Load tokenizer and model to evaluate.\n    '''", "\n", "if", "args", ".", "lang", "==", "'de'", ":", "\n", "        ", "model_name", "=", "'deepset/gbert-base'", "\n", "", "elif", "args", ".", "lang", "==", "'ja'", ":", "\n", "        ", "model_name", "=", "'cl-tohoku/bert-base-japanese-whole-word-masking'", "\n", "", "elif", "args", ".", "lang", "==", "'ar'", ":", "\n", "        ", "model_name", "=", "'aubmindlab/bert-base-arabertv02'", "\n", "", "elif", "args", ".", "lang", "==", "'es'", ":", "\n", "        ", "model_name", "=", "'dccuchile/bert-base-spanish-wwm-uncased'", "\n", "", "elif", "args", ".", "lang", "==", "'pt'", ":", "\n", "        ", "model_name", "=", "'neuralmind/bert-base-portuguese-cased'", "\n", "", "elif", "args", ".", "lang", "==", "'ru'", ":", "\n", "        ", "model_name", "=", "'blinoff/roberta-base-russian-v0'", "\n", "", "elif", "args", ".", "lang", "==", "'id'", ":", "\n", "        ", "model_name", "=", "'cahya/bert-base-indonesian-1.5G'", "\n", "", "elif", "args", ".", "lang", "==", "'zh'", ":", "\n", "        ", "model_name", "=", "'hfl/chinese-bert-wwm-ext'", "\n", "", "elif", "args", ".", "lang", "==", "'multi-xlm'", ":", "\n", "        ", "model_name", "=", "'xlm-mlm-100-1280'", "\n", "", "elif", "args", ".", "lang", "==", "'multi-bert'", ":", "\n", "        ", "model_name", "=", "'bert-base-multilingual-uncased'", "\n", "", "model", "=", "AutoModelForMaskedLM", ".", "from_pretrained", "(", "model_name", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "output_attentions", "=", "True", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "to", "(", "'cuda'", ")", "\n", "\n", "", "return", "tokenizer", ",", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.calculate_aul": [[66, 88], ["model", "model.logits.squeeze", "log_softmax", "token_ids.view().detach.view().detach", "torch.mean", "torch.mean.item", "torch.mean().detach().cpu().numpy", "log_softmax.gather", "torch.mean", "torch.mean", "torch.mean", "token_ids.view().detach.view", "torch.cat", "token_log_probs.squeeze", "torch.mean().detach().cpu", "torch.mean().detach", "torch.mean"], "function", ["None"], ["", "def", "calculate_aul", "(", "model", ",", "token_ids", ",", "log_softmax", ",", "attention", ")", ":", "\n", "    ", "'''\n    Given token ids of a sequence, return the averaged log probability of\n    unmasked sequence (AULA or AUL).\n    '''", "\n", "output", "=", "model", "(", "token_ids", ")", "\n", "logits", "=", "output", ".", "logits", ".", "squeeze", "(", "0", ")", "\n", "log_probs", "=", "log_softmax", "(", "logits", ")", "\n", "token_ids", "=", "token_ids", ".", "view", "(", "-", "1", ",", "1", ")", ".", "detach", "(", ")", "\n", "token_log_probs", "=", "log_probs", ".", "gather", "(", "1", ",", "token_ids", ")", "[", "1", ":", "-", "1", "]", "\n", "if", "attention", ":", "\n", "        ", "attentions", "=", "torch", ".", "mean", "(", "torch", ".", "cat", "(", "output", ".", "attentions", ",", "0", ")", ",", "0", ")", "\n", "averaged_attentions", "=", "torch", ".", "mean", "(", "attentions", ",", "0", ")", "\n", "averaged_token_attentions", "=", "torch", ".", "mean", "(", "averaged_attentions", ",", "0", ")", "\n", "token_log_probs", "=", "token_log_probs", ".", "squeeze", "(", "1", ")", "*", "averaged_token_attentions", "[", "1", ":", "-", "1", "]", "\n", "", "sentence_log_prob", "=", "torch", ".", "mean", "(", "token_log_probs", ")", "\n", "score", "=", "sentence_log_prob", ".", "item", "(", ")", "\n", "\n", "hidden_states", "=", "output", ".", "hidden_states", "[", "-", "1", "]", "[", ":", ",", "1", ":", "-", "1", "]", "\n", "hidden_state", "=", "torch", ".", "mean", "(", "hidden_states", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "score", ",", "hidden_state", "\n", "\n"]], "home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.cos_sim": [[90, 92], ["numpy.dot", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "cos_sim", "(", "v1", ",", "v2", ")", ":", "\n", "    ", "return", "np", ".", "dot", "(", "v1", ",", "v2", ")", "/", "(", "np", ".", "linalg", ".", "norm", "(", "v1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "v2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.main": [[94, 145], ["eval.load_tokenizer_and_model", "torch.cuda.is_available", "torch.nn.LogSoftmax", "pickle.load", "pickle.load", "numpy.array", "female_scores.reshape.reshape", "numpy.array", "male_scores.reshape.reshape", "numpy.concatenate", "numpy.concatenate", "eval.cos_sim", "print", "torch.set_default_tensor_type", "open", "open", "numpy.sum", "numpy.sum", "round", "torch.no_grad", "eval.calculate_aul", "female_scores.reshape.append", "np.concatenate.append", "torch.no_grad", "eval.calculate_aul", "male_scores.reshape.append", "np.concatenate.append"], "function", ["home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.load_tokenizer_and_model", "home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.cos_sim", "home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.calculate_aul", "home.repos.pwc.inspect_result.kanekomasahiro_bias_eval_in_multiple_mlm.None.eval.calculate_aul"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "'''\n    Evaluate the bias in masked language models.\n    '''", "\n", "tokenizer", ",", "model", "=", "load_tokenizer_and_model", "(", "args", ")", "\n", "total_score", "=", "0", "\n", "stereo_score", "=", "0", "\n", "corpus", "=", "args", ".", "corpus", "\n", "lang", "=", "args", ".", "lang", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "set_default_tensor_type", "(", "'torch.cuda.FloatTensor'", ")", "\n", "\n", "", "mask_id", "=", "tokenizer", ".", "mask_token_id", "\n", "log_softmax", "=", "torch", ".", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "\n", "female_inputs", "=", "pickle", ".", "load", "(", "open", "(", "f'parallel_data/{corpus}/{lang}_f.bin'", ",", "'rb'", ")", ")", "\n", "male_inputs", "=", "pickle", ".", "load", "(", "open", "(", "f'parallel_data/{corpus}/{lang}_m.bin'", ",", "'rb'", ")", ")", "\n", "\n", "attention", "=", "True", "if", "args", ".", "method", "==", "'aula'", "else", "False", "\n", "\n", "female_scores", "=", "[", "]", "\n", "male_scores", "=", "[", "]", "\n", "female_embes", "=", "[", "]", "\n", "male_embes", "=", "[", "]", "\n", "\n", "for", "female_tokens", "in", "female_inputs", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "female_score", ",", "female_hidden_state", "=", "calculate_aul", "(", "model", ",", "female_tokens", ",", "log_softmax", ",", "attention", ")", "\n", "female_scores", ".", "append", "(", "female_score", ")", "\n", "female_embes", ".", "append", "(", "female_hidden_state", ")", "\n", "\n", "", "", "for", "male_tokens", "in", "male_inputs", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "male_score", ",", "male_hidden_state", "=", "calculate_aul", "(", "model", ",", "male_tokens", ",", "log_softmax", ",", "attention", ")", "\n", "male_scores", ".", "append", "(", "male_score", ")", "\n", "male_embes", ".", "append", "(", "male_hidden_state", ")", "\n", "\n", "", "", "female_scores", "=", "np", ".", "array", "(", "female_scores", ")", "\n", "female_scores", "=", "female_scores", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "male_scores", "=", "np", ".", "array", "(", "male_scores", ")", "\n", "male_scores", "=", "male_scores", ".", "reshape", "(", "[", "1", ",", "-", "1", "]", ")", "\n", "bias_scores", "=", "male_scores", ">", "female_scores", "\n", "\n", "female_embes", "=", "np", ".", "concatenate", "(", "female_embes", ")", "\n", "male_embes", "=", "np", ".", "concatenate", "(", "male_embes", ")", "\n", "weights", "=", "cos_sim", "(", "female_embes", ",", "male_embes", ".", "T", ")", "\n", "\n", "weighted_bias_scores", "=", "bias_scores", "*", "weights", "\n", "bias_score", "=", "np", ".", "sum", "(", "weighted_bias_scores", ")", "/", "np", ".", "sum", "(", "weights", ")", "\n", "print", "(", "'bias score (emb):'", ",", "round", "(", "bias_score", "*", "100", ",", "2", ")", ")", "\n", "\n"]]}