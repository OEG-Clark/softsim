{"home.repos.pwc.inspect_result.lsrock1_nlp_search.None.transforms.build_transforms": [[4, 14], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.ToPILImage", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["def", "build_transforms", "(", "cfg", ")", ":", "\n", "    ", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "\n", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToPILImage", "(", ")", ",", "\n", "transforms", ".", "Resize", "(", "cfg", ".", "DATA", ".", "GLOBAL_SIZE", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", ""]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.train_dist.train_model_on_dataset": [[22, 132], ["torch.init_process_group", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "dataset.CityFlowNLDataset", "model.MyModel().cuda", "torch.nn.parallel.DistributedDataParallel", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "scheduler.WarmupMultiStepLR", "loss.LabelSmoothingLoss", "loss.LabelSmoothingLoss", "torch.utils.data.DistributedSampler", "torch.utils.data.DataLoader", "range", "transforms.build_transforms", "len", "torch.nn.parallel.DistributedDataParallel.load_state_dict", "torch.optim.Adam.load_state_dict", "scheduler.WarmupMultiStepLR.step", "torch.utils.data.DistributedSampler.set_epoch", "enumerate", "scheduler.WarmupMultiStepLR.step", "model.MyModel", "torch.nn.parallel.DistributedDataParallel.parameters", "len", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "nl.cuda.cuda", "label.cuda.cuda", "act_map.cuda.cuda", "frame.cuda.cuda", "color_label.cuda.cuda", "type_label.cuda.cuda", "nl_color_label.cuda.cuda", "nl_type_label.cuda.cuda", "torch.nn.parallel.DistributedDataParallel.", "loss.reduce_sum().item", "max", "torch.optim.Adam.zero_grad", "loss_total.backward", "torch.optim.Adam.step", "loss.item", "loss_color.item", "loss_type.item", "loss_nl_color.item", "loss_nl_type.item", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "len", "loss.sigmoid_focal_loss", "loss.LabelSmoothingLoss.", "loss.LabelSmoothingLoss.", "loss.LabelSmoothingLoss.", "loss.LabelSmoothingLoss.", "print", "os.path.exists", "os.mkdir", "torch.nn.parallel.DistributedDataParallel.state_dict", "torch.optim.Adam.state_dict", "len", "loss.reduce_sum", "float", "output.sigmoid", "label.cuda.sum", "color.argmax", "ca.sum().item", "ca.numel", "types.argmax", "ta.sum().item", "ta.numel", "len", "label.cuda.new_tensor", "ca.sum", "ta.sum", "len", "recall.item", "label.cuda.sum"], "function", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.transforms.build_transforms", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.sigmoid_focal_loss", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.reduce_sum"], ["def", "train_model_on_dataset", "(", "rank", ",", "cfg", ")", ":", "\n", "    ", "dist_rank", "=", "rank", "\n", "# print(dist_rank)", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ",", "rank", "=", "dist_rank", ",", "\n", "world_size", "=", "cfg", ".", "num_gpu", ",", "\n", "init_method", "=", "\"env://\"", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "rank", ")", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "dataset", "=", "CityFlowNLDataset", "(", "cfg", ",", "build_transforms", "(", "cfg", ")", ")", "\n", "\n", "model", "=", "MyModel", "(", "cfg", ",", "len", "(", "dataset", ".", "nl", ")", ",", "dataset", ".", "nl", ".", "word_to_idx", "[", "'<PAD>'", "]", ",", "norm_layer", "=", "nn", ".", "SyncBatchNorm", ",", "num_colors", "=", "len", "(", "CityFlowNLDataset", ".", "colors", ")", ",", "num_types", "=", "len", "(", "CityFlowNLDataset", ".", "vehicle_type", ")", "-", "2", ")", ".", "cuda", "(", ")", "\n", "model", "=", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "rank", "]", ",", "\n", "output_device", "=", "rank", ",", "\n", "broadcast_buffers", "=", "cfg", ".", "num_gpu", ">", "1", ",", "find_unused_parameters", "=", "False", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "params", "=", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "cfg", ".", "TRAIN", ".", "LR", ".", "BASE_LR", ",", "weight_decay", "=", "0.00003", ")", "\n", "lr_scheduler", "=", "WarmupMultiStepLR", "(", "optimizer", ",", "\n", "milestones", "=", "cfg", ".", "TRAIN", ".", "STEPS", ",", "\n", "gamma", "=", "cfg", ".", "TRAIN", ".", "LR", ".", "WEIGHT_DECAY", ",", "\n", "warmup_factor", "=", "cfg", ".", "TRAIN", ".", "WARMUP_FACTOR", ",", "\n", "warmup_iters", "=", "cfg", ".", "TRAIN", ".", "WARMUP_EPOCH", ")", "\n", "color_loss", "=", "LabelSmoothingLoss", "(", "len", "(", "dataset", ".", "colors", ")", ",", "0.1", ")", "\n", "vehicle_loss", "=", "LabelSmoothingLoss", "(", "len", "(", "dataset", ".", "vehicle_type", ")", "-", "2", ",", "0.1", ")", "\n", "if", "cfg", ".", "resume_epoch", ">", "0", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "f'save/{cfg.resume_epoch}.pth'", ")", ")", "\n", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "f'save/{cfg.resume_epoch}_optim.pth'", ")", ")", "\n", "lr_scheduler", ".", "last_epoch", "=", "cfg", ".", "resume_epoch", "\n", "lr_scheduler", ".", "step", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "            ", "print", "(", "f'resume from {cfg.resume_epoch} pth file, starting {cfg.resume_epoch+1} epoch'", ")", "\n", "", "cfg", ".", "resume_epoch", "+=", "1", "\n", "\n", "# loader = DataLoader(dataset, batch_size=cfg.TRAIN.BATCH_SIZE, shuffle=True, num_workers=cfg.TRAIN.NUM_WORKERS)", "\n", "", "train_sampler", "=", "DistributedSampler", "(", "dataset", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "//", "cfg", ".", "num_gpu", ",", "\n", "num_workers", "=", "cfg", ".", "TRAIN", ".", "NUM_WORKERS", "//", "cfg", ".", "num_gpu", ",", "# shuffle=True,", "\n", "sampler", "=", "train_sampler", ",", "pin_memory", "=", "True", ")", "\n", "for", "epoch", "in", "range", "(", "cfg", ".", "resume_epoch", ",", "cfg", ".", "TRAIN", ".", "EPOCH", ")", ":", "\n", "        ", "losses", "=", "0.", "\n", "losses_color", "=", "0.", "\n", "losses_types", "=", "0.", "\n", "losses_nl_color", "=", "0.", "\n", "losses_nl_types", "=", "0.", "\n", "precs", "=", "0.", "\n", "train_sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "for", "idx", ",", "(", "nl", ",", "frame", ",", "label", ",", "act_map", ",", "color_label", ",", "type_label", ",", "nl_color_label", ",", "nl_type_label", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "# print(nl.shape)", "\n", "# print(global_img.shape)", "\n", "# print(local_img.shape)", "\n", "            ", "nl", "=", "nl", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "label", "=", "label", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "act_map", "=", "act_map", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "# global_img, local_img = global_img.cuda(), local_img.cuda()", "\n", "# nl = nl.transpose(1, 0)", "\n", "frame", "=", "frame", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "color_label", "=", "color_label", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "type_label", "=", "type_label", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "nl_color_label", "=", "nl_color_label", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "nl_type_label", "=", "nl_type_label", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "output", ",", "color", ",", "types", ",", "nl_color", ",", "nl_types", "=", "model", "(", "nl", ",", "frame", ",", "act_map", ")", "\n", "\n", "# loss = sampling_loss(output, label, ratio=5)", "\n", "# loss = F.binary_cross_entropy_with_logits(output, label)", "\n", "total_num_pos", "=", "reduce_sum", "(", "label", ".", "new_tensor", "(", "[", "label", ".", "sum", "(", ")", "]", ")", ")", ".", "item", "(", ")", "\n", "num_pos_avg_per_gpu", "=", "max", "(", "total_num_pos", "/", "float", "(", "cfg", ".", "num_gpu", ")", ",", "1.0", ")", "\n", "\n", "loss", "=", "sigmoid_focal_loss", "(", "output", ",", "label", ",", "reduction", "=", "'sum'", ")", "/", "num_pos_avg_per_gpu", "\n", "loss_color", "=", "color_loss", "(", "color", ",", "color_label", ")", "*", "cfg", ".", "TRAIN", ".", "ALPHA_COLOR", "\n", "loss_type", "=", "vehicle_loss", "(", "types", ",", "type_label", ")", "*", "cfg", ".", "TRAIN", ".", "ALPHA_TYPE", "\n", "loss_nl_color", "=", "color_loss", "(", "nl_color", ",", "nl_color_label", ")", "*", "cfg", ".", "TRAIN", ".", "ALPHA_NL_COLOR", "\n", "loss_nl_type", "=", "vehicle_loss", "(", "nl_types", ",", "nl_type_label", ")", "*", "cfg", ".", "TRAIN", ".", "ALPHA_NL_TYPE", "\n", "loss_total", "=", "loss", "+", "loss_color", "+", "loss_type", "+", "loss_nl_color", "+", "loss_nl_type", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss_total", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "losses", "+=", "loss", ".", "item", "(", ")", "\n", "losses_color", "+=", "loss_color", ".", "item", "(", ")", "\n", "losses_types", "+=", "loss_type", ".", "item", "(", ")", "\n", "losses_nl_color", "+=", "loss_nl_color", ".", "item", "(", ")", "\n", "losses_nl_types", "+=", "loss_nl_type", ".", "item", "(", ")", "\n", "# precs += recall.item()", "\n", "\n", "if", "rank", "==", "0", "and", "idx", "%", "cfg", ".", "TRAIN", ".", "PRINT_FREQ", "==", "0", ":", "\n", "                ", "pred", "=", "(", "output", ".", "sigmoid", "(", ")", ">", "0.5", ")", "\n", "# print((pred == label).sum())", "\n", "pred", "=", "(", "pred", "==", "label", ")", "\n", "recall", "=", "(", "pred", "*", "label", ")", ".", "sum", "(", ")", "/", "label", ".", "sum", "(", ")", "\n", "ca", "=", "(", "color", ".", "argmax", "(", "dim", "=", "1", ")", "==", "color_label", ")", "\n", "ca", "=", "ca", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "ca", ".", "numel", "(", ")", "\n", "ta", "=", "(", "types", ".", "argmax", "(", "dim", "=", "1", ")", "==", "type_label", ")", "\n", "ta", "=", "ta", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "ta", ".", "numel", "(", ")", "\n", "# accu = pred.sum().item() / pred.numel()", "\n", "lr", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "print", "(", "f'epoch: {epoch},'", ",", "\n", "f'lr: {lr}, step: {idx}/{len(loader)},'", ",", "\n", "f'loss: {losses / (idx + 1):.4f},'", ",", "\n", "f'loss color: {losses_color / (idx + 1):.4f},'", ",", "\n", "f'loss type: {losses_types / (idx + 1):.4f},'", ",", "\n", "f'loss nl color: {losses_nl_color / (idx + 1):.4f},'", ",", "\n", "f'loss nl type: {losses_nl_types / (idx + 1):.4f},'", ",", "\n", "f'recall: {recall.item():.4f}, c_accu: {ca:.4f}, t_accu: {ta:.4f}'", ")", "\n", "", "", "lr_scheduler", ".", "step", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "'save'", ")", ":", "\n", "                ", "os", ".", "mkdir", "(", "'save'", ")", "\n", "", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "f'save/{epoch}.pth'", ")", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "f'save/{epoch}_optim.pth'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.NL.__init__": [[26, 42], ["nltk.stem.PorterStemmer", "set", "transformers.ElectraTokenizerFast.from_pretrained", "os.path.exists", "nltk.corpus.stopwords.words", "os.path.join", "dataset.NL.__build_dict", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__build_dict"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "tracks", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "tracks", "=", "tracks", "\n", "self", ".", "s", "=", "PorterStemmer", "(", ")", "\n", "self", ".", "stop_words", "=", "set", "(", "stopwords", ".", "words", "(", "'english'", ")", ")", "\n", "self", ".", "tokenizer", "=", "ElectraTokenizerFast", ".", "from_pretrained", "(", "'google/electra-small-discriminator'", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_count.pkl'", ")", ")", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_count.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "words_count", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_to_idx.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "word_to_idx", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'special_case.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "special_case", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "words_count", ",", "self", ".", "word_to_idx", "=", "self", ".", "__build_dict", "(", "self", ".", "tracks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.NL.__len__": [[43, 45], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "word_to_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.NL.__build_dict": [[46, 101], ["collections.defaultdict", "dataset.NL.special_case.update", "print", "dict", "collections.defaultdict.items", "dict", "ec.replace", "zip", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "[].split", "dataset.NL.do_clean", "collections.defaultdict.keys", "range", "os.path.join", "os.path.join", "os.path.join", "len", "len", "len", "word.replace", "n.lower", "word.replace"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.do_clean"], ["", "def", "__build_dict", "(", "self", ",", "tracks", ")", ":", "\n", "        ", "word_count", "=", "defaultdict", "(", "int", ")", "\n", "\n", "word_count", "[", "'<SOS>'", "]", "+=", "1", "\n", "word_count", "[", "'<EOS>'", "]", "+=", "1", "\n", "word_count", "[", "'<PAD>'", "]", "+=", "1", "\n", "word_count", "[", "'<UNK>'", "]", "+=", "1", "\n", "max_length", "=", "0", "\n", "\n", "# special case handling", "\n", "except_case", "=", "[", "'dark-red'", ",", "'dark-blue'", ",", "'dark-colored'", "]", "\n", "hand_case", "=", "{", "\n", "'hatckback'", ":", "'hatchback'", "\n", "}", "\n", "self", ".", "special_case", "=", "{", "}", "\n", "for", "t", "in", "tracks", ":", "\n", "            ", "for", "n", "in", "t", "[", "'nl'", "]", ":", "\n", "                ", "for", "word", "in", "n", ".", "lower", "(", ")", "[", ":", "-", "1", "]", ".", "split", "(", ")", ":", "\n", "                    ", "if", "'-'", "in", "word", "and", "word", "not", "in", "except_case", "and", "word", "not", "in", "self", ".", "special_case", ":", "\n", "                        ", "self", ".", "special_case", "[", "word", ".", "replace", "(", "'-'", ",", "' '", ")", "]", "=", "word", ".", "replace", "(", "'-'", ",", "''", ")", "\n", "\n", "", "", "", "", "for", "ec", "in", "except_case", ":", "\n", "            ", "self", ".", "special_case", "[", "ec", "]", "=", "ec", ".", "replace", "(", "'-'", ",", "' '", ")", "\n", "", "self", ".", "special_case", ".", "update", "(", "hand_case", ")", "\n", "\n", "# self.special_case = special_case", "\n", "\n", "for", "t", "in", "tracks", ":", "\n", "            ", "for", "n", "in", "t", "[", "'nl'", "]", ":", "\n", "                ", "cleaned_sentence", "=", "self", ".", "do_clean", "(", "n", ")", "\n", "if", "len", "(", "cleaned_sentence", ")", ">", "max_length", ":", "\n", "                    ", "max_length", "=", "len", "(", "cleaned_sentence", ")", "\n", "", "for", "w", "in", "cleaned_sentence", ":", "\n", "# for l in n.replace('.', '').split():", "\n", "                    ", "word_count", "[", "w", "]", "+=", "1", "\n", "", "", "", "print", "(", "'max: '", ",", "max_length", ")", "\n", "new_dict", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "word_count", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", ">=", "self", ".", "cfg", ".", "DATA", ".", "MIN_COUNT", "or", "k", "in", "[", "'<SOS>'", ",", "'<EOS>'", ",", "'<PAD>'", ",", "'<UNK>'", "]", ":", "\n", "                ", "new_dict", "[", "k", "]", "=", "v", "\n", "\n", "", "", "word_count", "=", "new_dict", "\n", "\n", "word_to_idx", "=", "dict", "(", "zip", "(", "word_count", ".", "keys", "(", ")", ",", "range", "(", "len", "(", "word_count", ")", ")", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_count.pkl'", ")", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "word_count", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_to_idx.pkl'", ")", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "word_to_idx", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'special_case.pkl'", ")", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "special_case", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "return", "word_count", ",", "word_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.NL.do_clean": [[102, 112], ["nl.replace.replace.lower", "dataset.NL.special_case.items", "nl[].replace().split", "nl.replace.replace.replace", "nl[].replace"], "methods", ["None"], ["", "def", "do_clean", "(", "self", ",", "nl", ")", ":", "\n", "        ", "nl", "=", "nl", ".", "lower", "(", ")", "\n", "for", "sc", ",", "replaced", "in", "self", ".", "special_case", ".", "items", "(", ")", ":", "\n", "            ", "if", "sc", "in", "nl", ":", "\n", "                ", "nl", "=", "nl", ".", "replace", "(", "sc", ",", "replaced", ")", "\n", "\n", "", "", "nl", "=", "nl", "[", ":", "-", "1", "]", ".", "replace", "(", "'-'", ",", "''", ")", ".", "split", "(", ")", "\n", "# nl = [self.s.stem(w) for w in nl]", "\n", "# nl = [w for w in nl if w not in self.stop_words]", "\n", "return", "nl", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.NL.sentence_to_index": [[113, 121], ["dataset.NL.do_clean", "dataset.NL.tokenizer.encode", "dataset.NL.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.do_clean"], ["", "def", "sentence_to_index", "(", "self", ",", "nl", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "nl", "=", "self", ".", "do_clean", "(", "nl", ")", "\n", "str_input", "=", "' '", ".", "join", "(", "nl", ")", "\n", "if", "is_train", ":", "\n", "            ", "idxs", "=", "self", ".", "tokenizer", ".", "encode", "(", "str_input", ",", "padding", "=", "'max_length'", ",", "truncation", "=", "True", ",", "max_length", "=", "30", ")", "\n", "", "else", ":", "\n", "            ", "idxs", "=", "self", ".", "tokenizer", ".", "encode", "(", "str_input", ")", "\n", "", "return", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.__init__": [[127, 184], ["data_cfg.clone", "list", "list", "list", "dataset.NL", "dict", "collections.defaultdict", "enumerate", "print", "open", "json.load", "json.load.keys", "json.load.values", "enumerate", "os.path.join", "dataset.CityFlowNLDataset.type_replacer", "dataset.CityFlowNLDataset.color_replacer", "dataset.CityFlowNLDataset.color_type_per_frame[].add", "range", "range", "os.path.exists", "dataset.CityFlowNLDataset.list_of_crops.append", "dataset.CityFlowNLDataset.color_type_item[].append", "len", "os.path.join", "len", "len"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.type_replacer", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.color_replacer"], ["def", "__init__", "(", "self", ",", "data_cfg", ",", "transforms", ")", ":", "\n", "        ", "\"\"\"\n        Dataset for training.\n        :param data_cfg: CfgNode for CityFlow NL.\n        \"\"\"", "\n", "self", ".", "data_cfg", "=", "data_cfg", ".", "clone", "(", ")", "\n", "# self.vehicle_type = ['bus', 'pickup','sedan', 'suv', 'van', 'wagon', 'cargo', 'mpv', 'hatchback', 'coup','truck', 'minivan']", "\n", "# self.colors = ['silver', 'red', 'white', 'brown', 'gold','black', 'gray', 'blue', 'purple', 'yellow', 'orange', 'green']", "\n", "with", "open", "(", "self", ".", "data_cfg", ".", "DATA", ".", "JSON_PATH", ")", "as", "f", ":", "\n", "            ", "tracks", "=", "json", ".", "load", "(", "f", ")", "\n", "", "self", ".", "list_of_uuids", "=", "list", "(", "tracks", ".", "keys", "(", ")", ")", "\n", "self", ".", "list_of_tracks", "=", "list", "(", "tracks", ".", "values", "(", ")", ")", "\n", "self", ".", "list_of_crops", "=", "list", "(", ")", "\n", "self", ".", "nl", "=", "NL", "(", "data_cfg", ",", "self", ".", "list_of_tracks", ")", "\n", "self", ".", "color_type_item", "=", "dict", "(", "[", "[", "(", "c", ",", "t", ")", ",", "[", "]", "]", "for", "c", "in", "range", "(", "len", "(", "CityFlowNLDataset", ".", "colors", ")", ")", "for", "t", "in", "range", "(", "len", "(", "CityFlowNLDataset", ".", "vehicle_type", ")", "-", "2", ")", "]", ")", "\n", "# self.color_type_list = [[[] for _ in range(len(CityFlowNLDataset.vehicle_type)-2)] for _ in range(len(CityFlowNLDataset.colors))]", "\n", "self", ".", "color_type_per_frame", "=", "defaultdict", "(", "set", ")", "\n", "# self.type_per_frame = defaultdict(set)", "\n", "# if os.path.exists(os.path.join(self.data_cfg.DATA.DICT_PATH, 'list_of_crops.pkl')):", "\n", "#     with open(os.path.join(self.data_cfg.DATA.DICT_PATH, 'list_of_crops.pkl'), 'rb') as handle:", "\n", "#         self.list_of_crops = pickle.load(handle)", "\n", "#     # self.list_of_crops = ", "\n", "# else:", "\n", "for", "track_idx", ",", "track", "in", "enumerate", "(", "self", ".", "list_of_tracks", ")", ":", "\n", "# print(track_idx, '/', len(self.list_of_tracks))", "\n", "            ", "for", "frame_idx", ",", "frame", "in", "enumerate", "(", "track", "[", "\"frames\"", "]", ")", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_cfg", ".", "DATA", ".", "CITYFLOW_PATH", ",", "frame", ")", ")", ":", "\n", "# print(os.path.join(self.data_cfg.DATA.CITYFLOW_PATH, frame))", "\n", "# print('not exists', os.path.join(self.data_cfg.DATA.CITYFLOW_PATH, frame))", "\n", "                    ", "continue", "\n", "", "frame_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_cfg", ".", "DATA", ".", "CITYFLOW_PATH", ",", "frame", ")", "\n", "#nl_idx = int(random.uniform(0, 3))", "\n", "nl", "=", "track", "[", "\"nl\"", "]", "#[nl_idx]", "\n", "box", "=", "track", "[", "\"boxes\"", "]", "[", "frame_idx", "]", "\n", "# crop = {\"frame\": frame_path, \"nl\": nl, \"box\": box}", "\n", "# self.list_of_crops.append(crop)", "\n", "# expand nls", "\n", "nl", ",", "vehicle_type", "=", "CityFlowNLDataset", ".", "type_replacer", "(", "nl", ")", "\n", "if", "vehicle_type", "==", "-", "1", ":", "\n", "                    ", "continue", "\n", "", "nl", ",", "vehicle_color", "=", "CityFlowNLDataset", ".", "color_replacer", "(", "nl", ")", "\n", "if", "vehicle_color", "==", "-", "1", ":", "\n", "                    ", "continue", "\n", "# print(len(nl))", "\n", "# print(nl)", "\n", "", "self", ".", "color_type_per_frame", "[", "frame_path", "]", ".", "add", "(", "(", "vehicle_color", ",", "vehicle_type", ")", ")", "\n", "# self.type_per_frame[frame_path].add(vehicle_type)", "\n", "for", "n", "in", "nl", ":", "\n", "                    ", "crop", "=", "{", "\"frame\"", ":", "frame_path", ",", "\"nl\"", ":", "n", ",", "\"box\"", ":", "box", ",", "\"color\"", ":", "vehicle_color", ",", "\"type\"", ":", "vehicle_type", "}", "\n", "self", ".", "list_of_crops", ".", "append", "(", "crop", ")", "\n", "self", ".", "color_type_item", "[", "(", "vehicle_color", ",", "vehicle_type", ")", "]", ".", "append", "(", "\n", "len", "(", "self", ".", "list_of_crops", ")", "-", "1", "\n", ")", "\n", "# with open(os.path.join(self.data_cfg.DATA.DICT_PATH, 'list_of_crops.pkl'), 'wb') as handle:", "\n", "#     pickle.dump(self.list_of_crops, handle, protocol=pickle.HIGHEST_PROTOCOL)", "\n", "", "", "", "self", ".", "transforms", "=", "transforms", "\n", "print", "(", "'data loading end'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.__len__": [[185, 187], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "list_of_crops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.color_replacer": [[188, 237], ["n.lower", "color_replace.items", "new_nls.append", "sorted", "len", "collections.Counter", "collections.Counter.most_common", "zip", "cls.colors.index", "nl.replace.replace.find", "len", "colors_in_nls.append", "replace_list.append", "replace_list.append", "set", "cls.colors.index", "len", "nl.replace.replace.replace", "sorted.append", "new_nls.append", "new_nls.append", "n.replace"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "color_replacer", "(", "cls", ",", "nls", ")", ":", "\n", "# cleaning noise in nl", "\n", "        ", "color_replace", "=", "{", "\n", "'reddish'", ":", "'red'", ",", "\n", "'maroon'", ":", "'red'", ",", "'whit '", ":", "'white '", ",", "'golden'", ":", "'gold'", ",", "'grey'", ":", "'gray'", ",", "'lightgray'", ":", "'gray'", "\n", "}", "\n", "\n", "colors_in_nls", "=", "[", "]", "\n", "replace_list", "=", "[", "]", "\n", "nls", "=", "[", "n", ".", "lower", "(", ")", "for", "n", "in", "nls", "]", "\n", "new_nls", "=", "[", "]", "\n", "for", "nl", "in", "nls", ":", "\n", "            ", "for", "k", ",", "v", "in", "color_replace", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "nl", ":", "\n", "                    ", "nl", "=", "nl", ".", "replace", "(", "k", ",", "v", ")", "\n", "", "", "new_nls", ".", "append", "(", "nl", ")", "\n", "", "nls", "=", "new_nls", "\n", "for", "nl", "in", "nls", ":", "\n", "# n = n.lower()", "\n", "            ", "colors_in_nl", "=", "[", "]", "\n", "\n", "for", "c", "in", "cls", ".", "colors", ":", "\n", "                ", "index", "=", "nl", ".", "find", "(", "c", ")", "\n", "if", "index", "!=", "-", "1", ":", "\n", "# colors_in_nls.add(c)", "\n", "                    ", "colors_in_nl", ".", "append", "(", "(", "c", ",", "index", ")", ")", "\n", "", "", "colors_in_nl", "=", "sorted", "(", "colors_in_nl", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "if", "len", "(", "colors_in_nl", ")", ">", "0", ":", "\n", "                ", "colors_in_nls", ".", "append", "(", "colors_in_nl", "[", "0", "]", "[", "0", "]", ")", "\n", "replace_list", ".", "append", "(", "colors_in_nl", "[", "0", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "replace_list", ".", "append", "(", "None", ")", "\n", "\n", "", "", "if", "len", "(", "set", "(", "colors_in_nls", ")", ")", ">", "1", ":", "\n", "            ", "counters", "=", "Counter", "(", "colors_in_nls", ")", "\n", "# nls = [t.lower() for t in track['nl']]", "\n", "k", "=", "counters", ".", "most_common", "(", "1", ")", "\n", "representer_color", "=", "k", "[", "0", "]", "[", "0", "]", "\n", "new_nls", "=", "[", "]", "\n", "for", "c", ",", "n", "in", "zip", "(", "replace_list", ",", "nls", ")", ":", "\n", "                ", "if", "c", "!=", "None", ":", "\n", "                    ", "new_nls", ".", "append", "(", "n", ".", "replace", "(", "c", ",", "representer_color", ")", ")", "\n", "", "else", ":", "\n", "                    ", "new_nls", ".", "append", "(", "n", ")", "\n", "", "", "return", "new_nls", ",", "cls", ".", "colors", ".", "index", "(", "representer_color", ")", "\n", "", "elif", "len", "(", "colors_in_nls", ")", "==", "0", ":", "\n", "            ", "return", "nls", ",", "-", "1", "\n", "", "return", "nls", ",", "cls", ".", "colors", ".", "index", "(", "colors_in_nls", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.type_replacer": [[238, 290], ["n.lower", "type_replace.items", "new_nls.append", "sorted", "len", "collections.Counter", "collections.Counter.most_common", "zip", "cls.vehicle_type.index", "nl.replace.replace.find", "len", "types_in_nls.append", "replace_list.append", "replace_list.append", "set", "cls.vehicle_type.index", "len", "nl.replace.replace.replace", "sorted.append", "new_nls.append", "new_nls.append", "n.replace"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "type_replacer", "(", "cls", ",", "nls", ")", ":", "\n", "# cleaning noise in nl", "\n", "        ", "type_replace", "=", "{", "'hatckback'", ":", "'hatchback'", "}", "\n", "types_in_nls", "=", "[", "]", "\n", "replace_list", "=", "[", "]", "\n", "nls", "=", "[", "n", ".", "lower", "(", ")", "for", "n", "in", "nls", "]", "\n", "new_nls", "=", "[", "]", "\n", "for", "nl", "in", "nls", ":", "\n", "            ", "for", "k", ",", "v", "in", "type_replace", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "nl", ":", "\n", "                    ", "nl", "=", "nl", ".", "replace", "(", "k", ",", "v", ")", "\n", "# else:", "\n", "#     new_nls.append(nl)", "\n", "", "", "new_nls", ".", "append", "(", "nl", ")", "\n", "", "nls", "=", "new_nls", "\n", "for", "nl", "in", "nls", ":", "\n", "            ", "types_in_nl", "=", "[", "]", "\n", "\n", "for", "c", "in", "cls", ".", "vehicle_type", ":", "\n", "                ", "index", "=", "nl", ".", "find", "(", "c", ")", "\n", "if", "index", "!=", "-", "1", ":", "\n", "# colors_in_nls.add(c)", "\n", "                    ", "types_in_nl", ".", "append", "(", "(", "c", ",", "index", ")", ")", "\n", "", "", "types_in_nl", "=", "sorted", "(", "types_in_nl", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "\n", "if", "len", "(", "types_in_nl", ")", ">", "0", ":", "\n", "                ", "first_type", "=", "types_in_nl", "[", "0", "]", "[", "0", "]", "\n", "if", "first_type", "==", "'truck'", ":", "\n", "                    ", "first_type", "=", "'pickup'", "\n", "", "elif", "first_type", "==", "'minivan'", ":", "\n", "                    ", "first_type", "=", "'van'", "\n", "", "types_in_nls", ".", "append", "(", "first_type", ")", "\n", "replace_list", ".", "append", "(", "first_type", ")", "\n", "", "else", ":", "\n", "                ", "replace_list", ".", "append", "(", "None", ")", "\n", "\n", "", "", "if", "len", "(", "set", "(", "types_in_nls", ")", ")", ">", "1", ":", "\n", "            ", "counters", "=", "Counter", "(", "types_in_nls", ")", "\n", "# nls = [t.lower() for t in track['nl']]", "\n", "k", "=", "counters", ".", "most_common", "(", "1", ")", "\n", "representer_color", "=", "k", "[", "0", "]", "[", "0", "]", "\n", "new_nls", "=", "[", "]", "\n", "for", "c", ",", "n", "in", "zip", "(", "replace_list", ",", "nls", ")", ":", "\n", "                ", "if", "c", "!=", "None", ":", "\n", "                    ", "new_nls", ".", "append", "(", "n", ".", "replace", "(", "c", ",", "representer_color", ")", ")", "\n", "", "else", ":", "\n", "                    ", "new_nls", ".", "append", "(", "n", ")", "\n", "", "", "return", "new_nls", ",", "cls", ".", "vehicle_type", ".", "index", "(", "representer_color", ")", "\n", "", "elif", "len", "(", "types_in_nls", ")", "==", "0", ":", "\n", "            ", "return", "nls", ",", "-", "1", "\n", "", "return", "nls", ",", "cls", ".", "vehicle_type", ".", "index", "(", "types_in_nls", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.bbox_aug": [[291, 330], ["int", "int", "random.randint", "random.randint", "max", "max", "albumentations.Compose", "albumentations.Compose", "min", "min", "albumentations.Compose", "albumentations.Compose", "albumentations.Crop", "albumentations.Crop", "albumentations.HorizontalFlip", "albumentations.HorizontalFlip", "albumentations.Resize", "albumentations.Resize", "albumentations.transforms.ToTensor", "albumentations.transforms.ToTensor", "albumentations.BboxParams", "albumentations.BboxParams", "albumentations.HorizontalFlip", "albumentations.HorizontalFlip", "albumentations.Resize", "albumentations.Resize", "albumentations.transforms.ToTensor", "albumentations.transforms.ToTensor", "albumentations.BboxParams", "albumentations.BboxParams"], "methods", ["None"], ["", "def", "bbox_aug", "(", "self", ",", "img", ",", "bbox", ",", "h", ",", "w", ")", ":", "\n", "        ", "resized_h", "=", "int", "(", "h", "*", "0.8", ")", "\n", "resized_w", "=", "int", "(", "w", "*", "0.8", ")", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "bbox", "[", "0", "]", ",", "bbox", "[", "1", "]", ",", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ",", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", "\n", "first", "=", "[", "max", "(", "xmax", "-", "resized_w", ",", "0", ")", ",", "max", "(", "ymax", "-", "resized_h", ",", "0", ")", "]", "\n", "second", "=", "[", "min", "(", "xmin", "+", "resized_w", ",", "w", ")", "-", "resized_w", ",", "min", "(", "ymin", "+", "resized_h", ",", "h", ")", "-", "resized_h", "]", "\n", "if", "first", "[", "0", "]", ">", "second", "[", "0", "]", "or", "first", "[", "1", "]", ">", "second", "[", "1", "]", ":", "\n", "            ", "tf", "=", "A", ".", "Compose", "(", "\n", "[", "\n", "A", ".", "HorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "A", ".", "Resize", "(", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "0", "]", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "1", "]", ")", ",", "\n", "AP", ".", "transforms", ".", "ToTensor", "(", "normalize", "=", "{", "\n", "'mean'", ":", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "'std'", ":", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "}", ")", "\n", "]", ",", "\n", "bbox_params", "=", "A", ".", "BboxParams", "(", "format", "=", "'coco'", ",", "label_fields", "=", "[", "'class_labels'", "]", ")", ",", "\n", ")", "(", "image", "=", "img", ",", "bboxes", "=", "[", "bbox", "]", ",", "class_labels", "=", "[", "0", "]", ")", "\n", "# print(tf['bboxes'])", "\n", "return", "tf", "[", "'image'", "]", ",", "tf", "[", "'bboxes'", "]", "[", "0", "]", "\n", "# return img, bbox", "\n", "", "x", "=", "random", ".", "randint", "(", "first", "[", "0", "]", ",", "second", "[", "0", "]", ")", "\n", "y", "=", "random", ".", "randint", "(", "first", "[", "1", "]", ",", "second", "[", "1", "]", ")", "\n", "\n", "# print(bbox)", "\n", "tf", "=", "A", ".", "Compose", "(", "\n", "[", "\n", "A", ".", "Crop", "(", "x_min", "=", "x", ",", "y_min", "=", "y", ",", "x_max", "=", "x", "+", "resized_w", ",", "y_max", "=", "y", "+", "resized_h", ",", "p", "=", "0.5", ")", ",", "\n", "A", ".", "HorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "A", ".", "Resize", "(", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "0", "]", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "1", "]", ")", ",", "\n", "AP", ".", "transforms", ".", "ToTensor", "(", "normalize", "=", "{", "\n", "'mean'", ":", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "'std'", ":", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "}", ")", "\n", "]", ",", "\n", "bbox_params", "=", "A", ".", "BboxParams", "(", "format", "=", "'coco'", ",", "label_fields", "=", "[", "'class_labels'", "]", ")", ",", "\n", ")", "(", "image", "=", "img", ",", "bboxes", "=", "[", "bbox", "]", ",", "class_labels", "=", "[", "0", "]", ")", "\n", "# print(tf['bboxes'])", "\n", "return", "tf", "[", "'image'", "]", ",", "tf", "[", "'bboxes'", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.__getitem__": [[331, 374], ["cv2.imread", "dataset.CityFlowNLDataset.bbox_aug", "torch.zeros", "dataset.CityFlowNLDataset.nl.sentence_to_index", "int", "int", "int", "int", "random.random", "dataset.CityFlowNLDataset.color_type_item.items", "random.choice", "dataset.CityFlowNLDataset.nl.sentence_to_index", "torch.zeros", "torch.tensor", "list", "torch.tensor", "selected_items.append", "itertools.chain"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLInferenceDataset.bbox_aug", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.sentence_to_index", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.sentence_to_index"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Get pairs of NL and cropped frame.\n        \"\"\"", "\n", "dp", "=", "self", ".", "list_of_crops", "[", "index", "]", "\n", "frame", "=", "cv2", ".", "imread", "(", "dp", "[", "\"frame\"", "]", ")", "\n", "h", ",", "w", ",", "_", "=", "frame", ".", "shape", "\n", "box", "=", "dp", "[", "\"box\"", "]", "\n", "frame", ",", "box", "=", "self", ".", "bbox_aug", "(", "frame", ",", "box", ",", "h", ",", "w", ")", "\n", "color", ",", "typ", "=", "dp", "[", "'color'", "]", ",", "dp", "[", "'type'", "]", "\n", "\n", "ymin", ",", "ymax", "=", "box", "[", "1", "]", ",", "box", "[", "1", "]", "+", "box", "[", "3", "]", "\n", "xmin", ",", "xmax", "=", "box", "[", "0", "]", ",", "box", "[", "0", "]", "+", "box", "[", "2", "]", "\n", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "int", "(", "xmin", "//", "16", ")", ",", "int", "(", "xmax", "//", "16", ")", ",", "int", "(", "ymin", "//", "16", ")", ",", "int", "(", "ymax", "//", "16", ")", "\n", "\n", "label", "=", "torch", ".", "zeros", "(", "[", "1", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "0", "]", "//", "16", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "1", "]", "//", "16", "]", ")", "\n", "# rectangle version", "\n", "label", "[", ":", ",", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", "=", "1", "\n", "\n", "if", "random", ".", "random", "(", ")", ">=", "0.8", ":", "# and len(self.color_type_list[color][typ]) > 1:", "\n", "# different type same color", "\n", "            ", "selected_items", "=", "[", "]", "\n", "for", "combination", ",", "l", "in", "self", ".", "color_type_item", ".", "items", "(", ")", ":", "\n", "                ", "if", "combination", "not", "in", "self", ".", "color_type_per_frame", "[", "dp", "[", "\"frame\"", "]", "]", "and", "(", "combination", "[", "0", "]", "==", "color", "or", "combination", "[", "1", "]", "==", "typ", ")", ":", "\n", "# print(f\"{color}, {typ}\", ' ', combination)", "\n", "                    ", "selected_items", ".", "append", "(", "l", ")", "\n", "# dtsc = [self.color_type_list[color][t] for t in range(len(self.color_type_list[color])) if t not in self.color_type_per_frame[dp['frame']][color] and len(self.color_type_list[color][t]) > 1]", "\n", "# same type different color", "\n", "# stdc = [self.color_type_list[c][typ] for c in range(len(self.color_type_list)) if typ not in self.color_type_per_frame[dp['frame']][c] and len(self.color_type_list[c][typ]) > 1]", "\n", "", "", "new_dp_idx", "=", "random", ".", "choice", "(", "list", "(", "itertools", ".", "chain", "(", "*", "selected_items", ")", ")", ")", "\n", "\n", "dp", "=", "self", ".", "list_of_crops", "[", "new_dp_idx", "]", "\n", "nl", "=", "dp", "[", "\"nl\"", "]", "#[int(random.uniform(0, 3))]", "\n", "nl", "=", "self", ".", "nl", ".", "sentence_to_index", "(", "nl", ")", "\n", "label_", "=", "torch", ".", "zeros", "(", "[", "1", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "0", "]", "//", "16", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "1", "]", "//", "16", "]", ")", "\n", "\n", "return", "torch", ".", "tensor", "(", "nl", ")", ",", "frame", ",", "label_", ",", "label", ",", "color", ",", "typ", ",", "dp", "[", "'color'", "]", ",", "dp", "[", "'type'", "]", "\n", "\n", "", "nl", "=", "dp", "[", "\"nl\"", "]", "#[0][int(random.uniform(0, 3))]", "\n", "# print(nl)", "\n", "nl", "=", "self", ".", "nl", ".", "sentence_to_index", "(", "nl", ")", "\n", "\n", "return", "torch", ".", "tensor", "(", "nl", ")", ",", "frame", ",", "label", ",", "label", ",", "color", ",", "typ", ",", "color", ",", "typ", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLInferenceDataset.__init__": [[377, 388], ["list", "list", "dataset.NL", "open", "json.load", "json.load.keys", "json.load.values"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_cfg", ",", "transforms", ",", "num_frames", "=", "None", ")", ":", "\n", "        ", "\"\"\"Dataset for evaluation. Loading tracks instead of frames.\"\"\"", "\n", "self", ".", "data_cfg", "=", "data_cfg", "\n", "with", "open", "(", "self", ".", "data_cfg", ".", "DATA", ".", "EVAL_TRACKS_JSON_PATH", ")", "as", "f", ":", "\n", "            ", "tracks", "=", "json", ".", "load", "(", "f", ")", "\n", "", "self", ".", "list_of_uuids", "=", "list", "(", "tracks", ".", "keys", "(", ")", ")", "\n", "self", ".", "list_of_tracks", "=", "list", "(", "tracks", ".", "values", "(", ")", ")", "\n", "self", ".", "transforms", "=", "transforms", "\n", "self", ".", "nl", "=", "NL", "(", "data_cfg", ",", "self", ".", "list_of_tracks", ")", "\n", "self", ".", "load_frame", "=", "True", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLInferenceDataset.__len__": [[389, 391], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "list_of_uuids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLInferenceDataset.bbox_aug": [[392, 405], ["albumentations.Compose", "albumentations.Compose", "albumentations.Resize", "albumentations.Resize", "albumentations.transforms.ToTensor", "albumentations.transforms.ToTensor", "albumentations.BboxParams", "albumentations.BboxParams"], "methods", ["None"], ["", "def", "bbox_aug", "(", "self", ",", "img", ",", "bbox", ")", ":", "\n", "        ", "tf", "=", "A", ".", "Compose", "(", "\n", "[", "\n", "A", ".", "Resize", "(", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "0", "]", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "1", "]", ")", ",", "\n", "AP", ".", "transforms", ".", "ToTensor", "(", "normalize", "=", "{", "\n", "'mean'", ":", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "'std'", ":", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "}", ")", "\n", "]", ",", "\n", "bbox_params", "=", "A", ".", "BboxParams", "(", "format", "=", "'coco'", ",", "label_fields", "=", "[", "'class_labels'", "]", ")", ",", "\n", ")", "(", "image", "=", "img", ",", "bboxes", "=", "[", "bbox", "]", ",", "class_labels", "=", "[", "0", "]", ")", "\n", "# print(tf['bboxes'])", "\n", "return", "tf", "[", "'image'", "]", ",", "tf", "[", "'bboxes'", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLInferenceDataset.__getitem__": [[406, 467], ["enumerate", "torch.stack", "zip", "os.path.join", "paths.append", "boxes.append", "rois.append", "torch.zeros", "labels.append", "numpy.array", "numpy.array", "torch.stack", "os.path.isfile", "cv2.imread", "dataset.CityFlowNLInferenceDataset.bbox_aug", "torch.stack.append", "torch.stack.append", "int", "int", "int", "int", "len", "cv2.imread", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLInferenceDataset.bbox_aug"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        :return: a dictionary for each track:\n        id: uuid for the track\n        frames, boxes, nl are untouched from the input json file.\n        crops: A Tensor of cropped images from the track of shape\n            [length, 3, crop_w, crop_h].\n        \"\"\"", "\n", "id", "=", "self", ".", "list_of_uuids", "[", "index", "]", "\n", "dp", "=", "self", ".", "list_of_tracks", "[", "index", "]", "\n", "# nl = dp['nl']", "\n", "# nl = self.nl.sentence_to_index(nl)", "\n", "# dp = {\"id\": self.list_of_uuids[index]}", "\n", "# dp.update(self.list_of_tracks[index])", "\n", "frames", "=", "[", "]", "\n", "boxes", "=", "[", "]", "\n", "paths", "=", "[", "]", "\n", "rois", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "idx", ",", "(", "frame_path", ",", "box", ")", "in", "enumerate", "(", "zip", "(", "dp", "[", "\"frames\"", "]", ",", "dp", "[", "\"boxes\"", "]", ")", ")", ":", "\n", "            ", "if", "self", ".", "num_frames", "!=", "None", "and", "len", "(", "frames", ")", "==", "self", ".", "num_frames", ":", "\n", "                ", "break", "\n", "", "frame_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_cfg", ".", "DATA", ".", "CITYFLOW_PATH", ",", "frame_path", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "frame_path", ")", ":", "\n", "                ", "continue", "\n", "", "paths", ".", "append", "(", "frame_path", ")", "\n", "\n", "if", "self", ".", "load_frame", ":", "\n", "                ", "frame", "=", "cv2", ".", "imread", "(", "frame_path", ")", "\n", "h", ",", "w", ",", "_", "=", "frame", ".", "shape", "\n", "frame", ",", "box_resized", "=", "self", ".", "bbox_aug", "(", "frame", ",", "box", ")", "\n", "frames", ".", "append", "(", "frame", ")", "\n", "", "else", ":", "\n", "                ", "if", "idx", "==", "0", ":", "\n", "                    ", "frame", "=", "cv2", ".", "imread", "(", "frame_path", ")", "\n", "h", ",", "w", ",", "_", "=", "frame", ".", "shape", "\n", "", "frames", ".", "append", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "# boxes.append(box)", "\n", "\n", "", "ymin", ",", "ymax", "=", "box", "[", "1", "]", ",", "box", "[", "1", "]", "+", "box", "[", "3", "]", "\n", "xmin", ",", "xmax", "=", "box", "[", "0", "]", ",", "box", "[", "0", "]", "+", "box", "[", "2", "]", "\n", "# frame = self.transforms[0](frame)", "\n", "boxes", ".", "append", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ")", "\n", "h_ratio", "=", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "0", "]", "/", "h", "\n", "w_ratio", "=", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "1", "]", "/", "w", "\n", "ymin", ",", "ymax", "=", "int", "(", "ymin", "*", "h_ratio", "//", "16", ")", ",", "int", "(", "ymax", "*", "h_ratio", "//", "16", ")", "\n", "xmin", ",", "xmax", "=", "int", "(", "xmin", "*", "w_ratio", "//", "16", ")", ",", "int", "(", "xmax", "*", "w_ratio", "//", "16", ")", "\n", "rois", ".", "append", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ")", "\n", "label", "=", "torch", ".", "zeros", "(", "[", "1", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "0", "]", "//", "16", ",", "self", ".", "data_cfg", ".", "DATA", ".", "GLOBAL_SIZE", "[", "1", "]", "//", "16", "]", ")", "\n", "# rectangle version", "\n", "label", "[", ":", ",", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", "=", "1", "\n", "labels", ".", "append", "(", "label", ")", "\n", "# box = dp[\"boxes\"][frame_idx]", "\n", "# crop = frame[box[1]:box[1] + box[3], box[0]: box[0] + box[2], :]", "\n", "# crop = cv2.resize(crop, dsize=self.data_cfg.CROP_SIZE)", "\n", "# crop = torch.from_numpy(crop).permute([2, 0, 1]).to(", "\n", "# dtype=torch.float32)", "\n", "# cropped_frames.append(crop)", "\n", "# dp[\"crops\"] = torch.stack(cropped_frames, dim=0)", "\n", "", "frames", "=", "torch", ".", "stack", "(", "frames", ",", "dim", "=", "0", ")", "\n", "return", "id", ",", "frames", ",", "np", ".", "array", "(", "boxes", ")", ",", "paths", ",", "np", ".", "array", "(", "rois", ")", ",", "torch", ".", "stack", "(", "labels", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.query": [[469, 475], ["list", "list", "open", "json.load", "json.load.keys", "json.load.values"], "function", ["None"], ["", "", "def", "query", "(", "data_cfg", ")", ":", "\n", "    ", "with", "open", "(", "data_cfg", ".", "DATA", ".", "EVAL_QUERIES_JSON_PATH", ")", "as", "f", ":", "\n", "        ", "tracks", "=", "json", ".", "load", "(", "f", ")", "\n", "", "uuids", "=", "list", "(", "tracks", ".", "keys", "(", ")", ")", "\n", "nls", "=", "list", "(", "tracks", ".", "values", "(", ")", ")", "\n", "return", "uuids", ",", "nls", "", "", ""]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.test_dist.main": [[26, 47], ["configs.get_default_config", "dataset.CityFlowNLInferenceDataset", "torch.utils.data.DataLoader", "dataset.query", "os.path.exists", "os.mkdir", "test_dist.extract_cache_features", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.spawn", "transforms.build_transforms", "shutil.rmtree"], "function", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.configs.get_default_config", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.query", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.test_dist.extract_cache_features", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.transforms.build_transforms"], ["def", "main", "(", ")", ":", "\n", "    ", "epoch", "=", "9", "\n", "test_batch_size", "=", "64", "\n", "scene_threshold", "=", "0.", "\n", "total_threshold", "=", "0.2", "\n", "num_of_vehicles", "=", "64", "\n", "\n", "cfg", "=", "get_default_config", "(", ")", "\n", "dataset", "=", "CityFlowNLInferenceDataset", "(", "cfg", ",", "build_transforms", "(", "cfg", ")", ",", "num_of_vehicles", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "num_workers", "=", "8", ")", "\n", "uuids", ",", "nls", "=", "query", "(", "cfg", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "'results'", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "'results'", ")", "\n", "", "os", ".", "mkdir", "(", "'results'", ")", "\n", "extract_cache_features", "(", "cfg", ",", "epoch", ",", "loader", ",", "dataset", ",", "test_batch_size", ",", "uuids", ",", "nls", ")", "\n", "cfg", ".", "num_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "cfg", ".", "resume_epoch", "=", "0", "\n", "mp", ".", "spawn", "(", "test", ",", "args", "=", "(", "cfg", ",", "loader", ",", "dataset", ",", "epoch", ",", "uuids", ",", "nls", ",", "scene_threshold", ",", "total_threshold", ")", ",", "\n", "nprocs", "=", "cfg", ".", "num_gpu", ",", "join", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.test_dist.extract_cache_features": [[49, 112], ["os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "model.MyModel().cuda", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load.items", "MyModel().cuda.load_state_dict", "MyModel().cuda.eval", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "print", "zip", "model.MyModel", "tqdm.tqdm", "frames.squeeze().cuda.squeeze().cuda", "labels.squeeze().cuda.squeeze().cuda", "enumerate", "dataset.CityFlowNLDataset.type_replacer", "dataset.CityFlowNLDataset.color_replacer", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "len", "k.replace", "zip", "MyModel().cuda.", "torch.softmax().cpu", "torch.softmax().cpu", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "model.rnn.unsqueeze", "MyModel().cuda.rnn", "nls_list.append", "len", "frames.squeeze().cuda.squeeze", "labels.squeeze().cuda.squeeze", "frames.squeeze().cuda.split", "labels.squeeze().cuda.split", "len", "torch.softmax", "torch.softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "cache[].mean", "cache[].mean", "dataset.nl.sentence_to_index"], "function", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.type_replacer", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.dataset.CityFlowNLDataset.color_replacer", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.sentence_to_index"], ["", "def", "extract_cache_features", "(", "cfg", ",", "epoch", ",", "loader", ",", "dataset", ",", "test_batch_size", ",", "uuids", ",", "nls", ")", ":", "\n", "# extract img fts first to save time", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'cache'", ")", ":", "\n", "# shutil.rmtree('cache')", "\n", "        ", "os", ".", "mkdir", "(", "'cache'", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "f'cache/{epoch}'", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "f'cache/{epoch}'", ")", "\n", "model", "=", "MyModel", "(", "cfg", ",", "len", "(", "dataset", ".", "nl", ")", ",", "dataset", ".", "nl", ".", "word_to_idx", "[", "'<PAD>'", "]", ",", "nn", ".", "BatchNorm2d", ",", "num_colors", "=", "len", "(", "CityFlowNLDataset", ".", "colors", ")", ",", "num_types", "=", "len", "(", "CityFlowNLDataset", ".", "vehicle_type", ")", "-", "2", ")", ".", "cuda", "(", ")", "\n", "saved_dict", "=", "torch", ".", "load", "(", "f'save/{epoch}.pth'", ")", "\n", "\n", "n", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "saved_dict", ".", "items", "(", ")", ":", "\n", "            ", "n", "[", "k", ".", "replace", "(", "'module.'", ",", "''", ")", "]", "=", "v", "\n", "\n", "", "model", ".", "load_state_dict", "(", "n", ",", "False", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "idx", ",", "(", "id", ",", "frames", ",", "_", ",", "_", ",", "_", ",", "labels", ")", "in", "enumerate", "(", "tqdm", "(", "loader", ")", ")", ":", "\n", "                ", "frames", "=", "frames", ".", "squeeze", "(", "0", ")", ".", "cuda", "(", ")", "\n", "labels", "=", "labels", ".", "squeeze", "(", "0", ")", ".", "cuda", "(", ")", "\n", "# b = frames.shape[0]", "\n", "# cache = []", "\n", "\n", "# version 3", "\n", "# if b <= test_batch_size:", "\n", "#     cache = model.cnn(frames)", "\n", "#     torch.save(cache, f'cache/{epoch}/{idx}_0.pth')", "\n", "# else:", "\n", "#     cache = []", "\n", "for", "i", ",", "(", "f", ",", "l", ")", "in", "enumerate", "(", "zip", "(", "frames", ".", "split", "(", "test_batch_size", ")", ",", "labels", ".", "split", "(", "test_batch_size", ")", ")", ")", ":", "\n", "                    ", "cache", "=", "model", "(", "None", ",", "f", ",", "l", ")", "\n", "img_ft", "=", "cache", "[", "0", "]", "\n", "color", "=", "F", ".", "softmax", "(", "cache", "[", "1", "]", ".", "mean", "(", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", ".", "cpu", "(", ")", "#.numpy()", "\n", "typ", "=", "F", ".", "softmax", "(", "cache", "[", "2", "]", ".", "mean", "(", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", ".", "cpu", "(", ")", "#.numpy()", "\n", "# color = np.argmax(color)", "\n", "# typ = np.argmax(typ)", "\n", "\n", "cache", "=", "[", "img_ft", ",", "color", ",", "typ", "]", "\n", "torch", ".", "save", "(", "cache", ",", "f'cache/{epoch}/{idx}_{i}.pth'", ")", "\n", "break", "\n", "\n", "", "", "print", "(", "'saving language features..'", ")", "\n", "for", "uuid", ",", "query_nl", "in", "zip", "(", "uuids", ",", "nls", ")", ":", "\n", "                ", "nls_list", "=", "[", "]", "\n", "query_nl", ",", "vehicle_type", "=", "CityFlowNLDataset", ".", "type_replacer", "(", "query_nl", ")", "\n", "query_nl", ",", "vehicle_color", "=", "CityFlowNLDataset", ".", "color_replacer", "(", "query_nl", ")", "\n", "# max_len = max([len(dataset.nl.do_clean(nl)) for nl in query_nl])", "\n", "for", "nl", "in", "query_nl", ":", "\n", "                    ", "nl", "=", "torch", ".", "tensor", "(", "dataset", ".", "nl", ".", "sentence_to_index", "(", "nl", ",", "is_train", "=", "False", ")", ")", ".", "cuda", "(", ")", "\n", "# nls.append(nl.unsqueeze(0).transpose(1, 0))", "\n", "nl", "=", "nl", ".", "unsqueeze", "(", "0", ")", "#.transpose(1, 0)", "\n", "# bs, len, dim", "\n", "nl", "=", "model", ".", "rnn", "(", "nl", ")", "\n", "nls_list", ".", "append", "(", "nl", ")", "\n", "", "saved_nls", "=", "{", "\n", "'nls'", ":", "nls_list", ",", "\n", "'type'", ":", "vehicle_type", ",", "'color'", ":", "vehicle_color", "\n", "}", "\n", "torch", ".", "save", "(", "saved_nls", ",", "f'cache/{epoch}/{uuid}.pth'", ")", "\n", "# model = model.cpu()", "\n", "", "", "del", "model", ",", "saved_dict", ",", "n", ",", "nls_list", ",", "img_ft", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.test_dist.test": [[114, 250], ["torch.init_process_group", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "model.MyModel().cuda", "torch.nn.parallel.DistributedDataParallel", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.nn.parallel.DistributedDataParallel.load_state_dict", "torch.nn.parallel.DistributedDataParallel.eval", "print", "enumerate", "len", "zip", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "enumerate", "model.MyModel", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "open", "json.dump", "len", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "boxes.squeeze().numpy.squeeze().numpy", "rois.squeeze().numpy.squeeze().numpy", "frames.squeeze.squeeze", "labels.cuda.squeeze", "labels.cuda.cuda", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.nn.parallel.DistributedDataParallel.", "torch.nn.parallel.DistributedDataParallel.", "torch.nn.parallel.DistributedDataParallel.", "activation_aggregation.cpu().numpy", "utils.compute_probability_of_activations", "uuids_per_nl.append", "prob_per_nl.append", "len", "len", "cache_nl[].expand().cuda", "cache_nl[].expand().cuda", "cache_nl[].expand().cuda", "len", "boxes.squeeze().numpy.squeeze", "rois.squeeze().numpy.squeeze", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "activation_aggregation.cpu", "cache_nl[].expand", "cache_nl[].expand", "cache_nl[].expand"], "function", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.utils.compute_probability_of_activations"], ["", "", "def", "test", "(", "rank", ",", "cfg", ",", "loader", ",", "dataset", ",", "epoch", ",", "uuids", ",", "nls", ",", "scene_threshold", ",", "total_threshold", ")", ":", "\n", "    ", "dataset", ".", "load_frame", "=", "False", "\n", "dist", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ",", "rank", "=", "rank", ",", "\n", "world_size", "=", "cfg", ".", "num_gpu", ",", "\n", "init_method", "=", "\"env://\"", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "rank", ")", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "model", "=", "MyModel", "(", "cfg", ",", "len", "(", "dataset", ".", "nl", ")", ",", "dataset", ".", "nl", ".", "word_to_idx", "[", "'<PAD>'", "]", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "num_colors", "=", "len", "(", "CityFlowNLDataset", ".", "colors", ")", ",", "num_types", "=", "len", "(", "CityFlowNLDataset", ".", "vehicle_type", ")", "-", "2", ")", ".", "cuda", "(", ")", "\n", "model", "=", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "rank", "]", ",", "\n", "output_device", "=", "rank", ",", "\n", "broadcast_buffers", "=", "cfg", ".", "num_gpu", ">", "1", ",", "find_unused_parameters", "=", "False", ")", "\n", "saved_dict", "=", "torch", ".", "load", "(", "f'save/{epoch}.pth'", ",", "map_location", "=", "torch", ".", "device", "(", "f'cuda:{rank}'", ")", ")", "\n", "model", ".", "load_state_dict", "(", "saved_dict", ",", "True", ")", "\n", "model", ".", "eval", "(", ")", "\n", "final_results", "=", "{", "}", "\n", "\n", "a", "=", "len", "(", "nls", ")", "//", "cfg", ".", "num_gpu", "\n", "start", "=", "a", "*", "rank", "\n", "end", "=", "None", "if", "(", "rank", "+", "1", ")", "==", "cfg", ".", "num_gpu", "else", "a", "*", "(", "rank", "+", "1", ")", "\n", "end_str", "=", "'end'", "if", "end", "==", "None", "else", "end", "\n", "print", "(", "f'process number: {rank}, {start}:{end_str}'", ")", "\n", "for", "nlidx", ",", "(", "uuid", ",", "query_nl", ")", "in", "enumerate", "(", "zip", "(", "uuids", "[", "start", ":", "end", "]", ",", "nls", "[", "start", ":", "end", "]", ")", ")", ":", "\n", "        ", "nlidx", "=", "nlidx", "+", "start", "\n", "print", "(", "f'{nlidx} / {len(nls)}'", ")", "\n", "cache_nl", "=", "torch", ".", "load", "(", "f'cache/{epoch}/{uuid}.pth'", ",", "map_location", "=", "torch", ".", "device", "(", "f'cuda:{rank}'", ")", ")", "\n", "cache_nl", ",", "vehicle_type", ",", "vehicle_color", "=", "cache_nl", "[", "'nls'", "]", ",", "cache_nl", "[", "'type'", "]", ",", "cache_nl", "[", "'color'", "]", "\n", "# nls = []", "\n", "# for nl in query_nl:", "\n", "#     nl = torch.tensor(dataset.nl.sentence_to_index(nl, is_train=False)).cuda()", "\n", "#     nls.append(nl.unsqueeze(0).transpose(1, 0))", "\n", "uuids_per_nl", "=", "[", "]", "\n", "prob_per_nl", "=", "[", "]", "\n", "for", "idx", ",", "(", "id", ",", "frames", ",", "boxes", ",", "paths", ",", "rois", ",", "labels", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "# print(f'{nlidx}_{idx}')", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "boxes", "=", "boxes", ".", "squeeze", "(", "0", ")", ".", "numpy", "(", ")", "\n", "rois", "=", "rois", ".", "squeeze", "(", "0", ")", ".", "numpy", "(", ")", "\n", "# print(rois)", "\n", "frames", "=", "frames", ".", "squeeze", "(", "0", ")", "\n", "# print(frames.shape)", "\n", "# b = frames.shape[0]", "\n", "labels", "=", "labels", ".", "squeeze", "(", "0", ")", "\n", "labels", "=", "labels", ".", "cuda", "(", ")", "\n", "\n", "cache", "=", "torch", ".", "load", "(", "f'cache/{epoch}/{idx}_0.pth'", ",", "map_location", "=", "torch", ".", "device", "(", "f'cuda:{rank}'", ")", ")", "\n", "# print(cache)", "\n", "frame", ",", "cs", ",", "vs", "=", "cache", "\n", "# if vehicle_type != -1 and vs != vehicle_type:", "\n", "#     continue", "\n", "# if vehicle_color != -1 and cs != vehicle_color:", "\n", "#     continue", "\n", "# print(frame.device)", "\n", "# results = []", "\n", "\n", "nl1", "=", "cache_nl", "[", "0", "]", "\n", "nl2", "=", "cache_nl", "[", "1", "]", "\n", "nl3", "=", "cache_nl", "[", "2", "]", "\n", "\n", "bs", "=", "frame", ".", "shape", "[", "0", "]", "\n", "# cache = cache[:num_of_vehicles]", "\n", "# print(cache.shape)", "\n", "if", "nl1", ".", "shape", "[", "0", "]", "!=", "bs", ":", "\n", "                    ", "nl1", "=", "cache_nl", "[", "0", "]", ".", "expand", "(", "bs", ",", "-", "1", ",", "-", "1", ")", ".", "cuda", "(", ")", "\n", "nl2", "=", "cache_nl", "[", "1", "]", ".", "expand", "(", "bs", ",", "-", "1", ",", "-", "1", ")", ".", "cuda", "(", ")", "\n", "nl3", "=", "cache_nl", "[", "2", "]", ".", "expand", "(", "bs", ",", "-", "1", ",", "-", "1", ")", ".", "cuda", "(", ")", "\n", "\n", "", "am1", "=", "model", "(", "nl1", ",", "frame", ",", "labels", ")", "\n", "am2", "=", "model", "(", "nl2", ",", "frame", ",", "labels", ")", "\n", "am3", "=", "model", "(", "nl3", ",", "frame", ",", "labels", ")", "\n", "# am1, c1, v1 = model(nl1, frame, labels)", "\n", "# am2, c2, v2 = model(nl2, frame, labels)", "\n", "# am3, c3, v3 = model(nl3, frame, labels)", "\n", "activation_aggregation", "=", "(", "am1", "+", "am2", "+", "am3", ")", "/", "3", "\n", "# c_aggregation = (c1 + c2 + c3) / 3", "\n", "# v_aggregation = (v1 + v2 + v3) / 3", "\n", "# activation_aggregation = model(nl1, frame) +\\", "\n", "#     model(nl2, frame) +\\", "\n", "#     model(nl3, frame)", "\n", "# activation_aggregation = activation_aggregation / 3", "\n", "# results.append(activation_aggregation)", "\n", "# cs.append(c_aggregation)", "\n", "# vs.append(v_aggregation)", "\n", "\n", "results", "=", "activation_aggregation", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# cs = c_aggregation.mean(dim=0).cpu().numpy()", "\n", "# vs = v_aggregation.mean(dim=0).cpu().numpy()", "\n", "\n", "# version 1", "\n", "# cache = torch.load(f'cache/{epoch}/{idx}.pth')", "\n", "# results = []", "\n", "# for batch_idx in range(cache.shape[0]):", "\n", "#     output = model(cache_nl[0], cache[batch_idx:batch_idx+1]).sigmoid()", "\n", "#     results.append(output.squeeze(0).cpu().detach().numpy())", "\n", "\n", "prob", "=", "compute_probability_of_activations", "(", "results", ",", "rois", ",", "scene_threshold", ")", "\n", "\n", "# if vehicle_type != -1 and np.argmax(vs) != vehicle_type:", "\n", "#     prob = 0.", "\n", "# if vehicle_color != -1 and np.argmax(cs) != vehicle_color:", "\n", "#     prob = 0.", "\n", "\n", "###### visualization", "\n", "# if not os.path.exists('results/' + query_nl[0]):", "\n", "#     os.mkdir('results/' + query_nl[0])", "\n", "\n", "# # cs = np.argmax(cs)", "\n", "# cs = cs.item()", "\n", "# vs = vs.item()", "\n", "# cs = CityFlowNLDataset.colors[cs]", "\n", "# # vs = np.argmax(vs)", "\n", "# vs = CityFlowNLDataset.vehicle_type[vs]", "\n", "# if prob > total_threshold:", "\n", "\n", "#     print(f'color: {cs}, type: {vs}')", "\n", "#     save_img(np.squeeze(results[0], axis=0) * 255, cv2.imread(paths[0][0]), boxes[0], f\"results/{query_nl[0]}/{idx}_{prob}.png\")", "\n", "\n", "###### end visualization", "\n", "\n", "\n", "# for submission", "\n", "uuids_per_nl", ".", "append", "(", "id", "[", "0", "]", ")", "\n", "prob_per_nl", ".", "append", "(", "prob", ")", "\n", "", "", "final_results", "[", "'uuids_order'", "]", "=", "uuids_per_nl", "\n", "final_results", "[", "uuid", "]", "=", "prob_per_nl", "\n", "\n", "# uuids_per_nl = np.array(uuids_per_nl)", "\n", "# # print(uuids_per_nl.shape)", "\n", "# prob_per_nl = np.array(prob_per_nl)", "\n", "# prob_per_nl_arg = (-prob_per_nl).argsort(axis=0)", "\n", "# sorted_uuids_per_nl = uuids_per_nl[prob_per_nl_arg]", "\n", "# # print(prob_per_nl[prob_per_nl_arg])", "\n", "# final_results[uuid] = sorted_uuids_per_nl.tolist()", "\n", "# print(len(final_results.keys()))", "\n", "\n", "with", "open", "(", "f'results/submit_{epoch}_{start}_{end_str}.json'", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "final_results", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.scheduler.WarmupMultiStepLR.__init__": [[6, 34], ["super().__init__", "ValueError", "ValueError", "list", "sorted"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "milestones", ",", "\n", "gamma", "=", "0.1", ",", "\n", "warmup_factor", "=", "1.0", "/", "3", ",", "\n", "warmup_iters", "=", "500", ",", "\n", "warmup_method", "=", "\"linear\"", ",", "\n", "last_epoch", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "if", "not", "list", "(", "milestones", ")", "==", "sorted", "(", "milestones", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Milestones should be a list of\"", "\" increasing integers. Got {}\"", ",", "\n", "milestones", ",", "\n", ")", "\n", "\n", "", "if", "warmup_method", "not", "in", "(", "\"constant\"", ",", "\"linear\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Only 'constant' or 'linear' warmup_method accepted\"", "\n", "\"got {}\"", ".", "format", "(", "warmup_method", ")", "\n", ")", "\n", "\n", "", "self", ".", "milestones", "=", "milestones", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iters", "=", "warmup_iters", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", "WarmupMultiStepLR", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.scheduler.WarmupMultiStepLR.get_lr": [[35, 49], ["bisect.bisect_right"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "warmup_factor", "=", "1", "\n", "if", "self", ".", "last_epoch", "<", "self", ".", "warmup_iters", ":", "\n", "            ", "if", "self", ".", "warmup_method", "==", "\"constant\"", ":", "\n", "                ", "warmup_factor", "=", "self", ".", "warmup_factor", "\n", "", "elif", "self", ".", "warmup_method", "==", "\"linear\"", ":", "\n", "                ", "alpha", "=", "self", ".", "last_epoch", "/", "self", ".", "warmup_iters", "\n", "warmup_factor", "=", "self", ".", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "\n", "", "", "return", "[", "\n", "base_lr", "\n", "*", "warmup_factor", "\n", "*", "self", ".", "gamma", "**", "bisect_right", "(", "self", ".", "milestones", ",", "self", ".", "last_epoch", ")", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "\n", "]", ""]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.LabelSmoothingLoss.__init__": [[8, 14], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "classes", ",", "smoothing", "=", "0.0", ",", "dim", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "LabelSmoothingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "confidence", "=", "1.0", "-", "smoothing", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "self", ".", "cls", "=", "classes", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.LabelSmoothingLoss.forward": [[15, 23], ["pred.log_softmax.log_softmax.log_softmax", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.fill_", "torch.zeros_like.fill_", "torch.zeros_like.fill_", "torch.zeros_like.scatter_", "torch.zeros_like.scatter_", "torch.zeros_like.scatter_", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "target.data.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pred", ",", "target", ")", ":", "\n", "        ", "pred", "=", "pred", ".", "log_softmax", "(", "dim", "=", "self", ".", "dim", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# true_dist = pred.data.clone()", "\n", "            ", "true_dist", "=", "torch", ".", "zeros_like", "(", "pred", ")", "\n", "true_dist", ".", "fill_", "(", "self", ".", "smoothing", "/", "(", "self", ".", "cls", "-", "1", ")", ")", "\n", "true_dist", ".", "scatter_", "(", "1", ",", "target", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "", "return", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "-", "true_dist", "*", "pred", ",", "dim", "=", "self", ".", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.TripletLoss.__init__": [[48, 53], ["torch.nn.Module.__init__", "torch.nn.MarginRankingLoss().cuda", "torch.nn.MarginRankingLoss().cuda", "torch.nn.MarginRankingLoss().cuda", "torch.nn.MarginRankingLoss", "torch.nn.MarginRankingLoss", "torch.nn.MarginRankingLoss"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin", ",", "normalize_feature", "=", "False", ")", ":", "\n", "        ", "super", "(", "TripletLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "normalize_feature", "=", "normalize_feature", "\n", "self", ".", "margin_loss", "=", "nn", ".", "MarginRankingLoss", "(", "margin", "=", "margin", ")", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.TripletLoss.forward": [[54, 66], ["loss.euclidean_dist", "loss._batch_hard", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "loss.TripletLoss.TripletLoss.margin_loss", "torch.ones_like.size", "torch.ones_like.size", "torch.ones_like.size", "label_nl.unsqueeze", "label_img.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.euclidean_dist", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss._batch_hard"], ["", "def", "forward", "(", "self", ",", "nl", ",", "img", ",", "label_nl", ",", "label_img", ")", ":", "\n", "# nl = F.normalize(nl, dim=1)", "\n", "# img = F.normalize(img, dim=1)", "\n", "        ", "mat_dist", "=", "euclidean_dist", "(", "nl", ",", "img", ")", "\n", "mat_sim", "=", "(", "label_nl", ".", "unsqueeze", "(", "1", ")", "==", "label_img", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "\n", "dist_ap", ",", "dist_an", "=", "_batch_hard", "(", "mat_dist", ",", "mat_sim", ")", "\n", "\n", "y", "=", "torch", ".", "ones_like", "(", "dist_ap", ")", "\n", "loss", "=", "self", ".", "margin_loss", "(", "dist_an", ",", "dist_ap", ",", "y", ")", "\n", "prec", "=", "(", "dist_an", ".", "data", ">", "dist_ap", ".", "data", ")", ".", "sum", "(", ")", "*", "1.", "/", "y", ".", "size", "(", "0", ")", "\n", "return", "loss", ",", "prec", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.euclidean_dist": [[25, 33], ["torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand().t", "torch.pow().sum().expand().t", "torch.pow().sum().expand().t", "dist.clamp().sqrt.addmm_", "dist.clamp().sqrt.clamp().sqrt", "x.size", "y.size", "y.t", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "dist.clamp().sqrt.clamp", "torch.pow", "torch.pow", "torch.pow", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow"], "function", ["None"], ["", "", "def", "euclidean_dist", "(", "x", ",", "y", ")", ":", "\n", "    ", "m", ",", "n", "=", "x", ".", "size", "(", "0", ")", ",", "y", ".", "size", "(", "0", ")", "\n", "xx", "=", "torch", ".", "pow", "(", "x", ",", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "expand", "(", "m", ",", "n", ")", "\n", "yy", "=", "torch", ".", "pow", "(", "y", ",", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "expand", "(", "n", ",", "m", ")", ".", "t", "(", ")", "\n", "dist", "=", "xx", "+", "yy", "\n", "dist", ".", "addmm_", "(", "1", ",", "-", "2", ",", "x", ",", "y", ".", "t", "(", ")", ")", "\n", "dist", "=", "dist", ".", "clamp", "(", "min", "=", "1e-12", ")", ".", "sqrt", "(", ")", "# for numerical stability", "\n", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss._batch_hard": [[35, 45], ["torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort"], "function", ["None"], ["", "def", "_batch_hard", "(", "mat_distance", ",", "mat_similarity", ",", "indice", "=", "False", ")", ":", "\n", "    ", "sorted_mat_distance", ",", "positive_indices", "=", "torch", ".", "sort", "(", "mat_distance", "+", "(", "-", "9999999.", ")", "*", "(", "1", "-", "mat_similarity", ")", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "hard_p", "=", "sorted_mat_distance", "[", ":", ",", "0", "]", "\n", "hard_p_indice", "=", "positive_indices", "[", ":", ",", "0", "]", "\n", "sorted_mat_distance", ",", "negative_indices", "=", "torch", ".", "sort", "(", "mat_distance", "+", "(", "9999999.", ")", "*", "(", "mat_similarity", ")", ",", "dim", "=", "1", ",", "descending", "=", "False", ")", "\n", "hard_n", "=", "sorted_mat_distance", "[", ":", ",", "0", "]", "\n", "hard_n_indice", "=", "negative_indices", "[", ":", ",", "0", "]", "\n", "if", "(", "indice", ")", ":", "\n", "        ", "return", "hard_p", ",", "hard_n", ",", "hard_p_indice", ",", "hard_n_indice", "\n", "", "return", "hard_p", ",", "hard_n", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.reduce_sum": [[68, 72], ["tensor.clone.clone", "torch.all_reduce"], "function", ["None"], ["", "", "def", "reduce_sum", "(", "tensor", ")", ":", "\n", "    ", "tensor", "=", "tensor", ".", "clone", "(", ")", "\n", "dist", ".", "all_reduce", "(", "tensor", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.sigmoid_focal_loss": [[74, 115], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.binary_cross_entropy_with_logits", "loss.sum.mean", "loss.sum.sum"], "function", ["None"], ["", "def", "sigmoid_focal_loss", "(", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "\n", "targets", ":", "torch", ".", "Tensor", ",", "\n", "alpha", ":", "float", "=", "-", "1", ",", "\n", "gamma", ":", "float", "=", "2", ",", "\n", "reduction", ":", "str", "=", "\"none\"", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.\n    Args:\n        inputs: A float tensor of arbitrary shape.\n                The predictions for each example.\n        targets: A float tensor with the same shape as inputs. Stores the binary\n                 classification label for each element in inputs\n                (0 for the negative class and 1 for the positive class).\n        alpha: (optional) Weighting factor in range (0,1) to balance\n                positive vs negative examples. Default = -1 (no weighting).\n        gamma: Exponent of the modulating factor (1 - p_t) to\n               balance easy vs hard examples.\n        reduction: 'none' | 'mean' | 'sum'\n                 'none': No reduction will be applied to the output.\n                 'mean': The output will be averaged.\n                 'sum': The output will be summed.\n    Returns:\n        Loss tensor with the reduction option applied.\n    \"\"\"", "\n", "p", "=", "torch", ".", "sigmoid", "(", "inputs", ")", "\n", "ce_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "inputs", ",", "targets", ",", "reduction", "=", "\"none\"", ")", "\n", "p_t", "=", "p", "*", "targets", "+", "(", "1", "-", "p", ")", "*", "(", "1", "-", "targets", ")", "\n", "loss", "=", "ce_loss", "*", "(", "(", "1", "-", "p_t", ")", "**", "gamma", ")", "\n", "\n", "if", "alpha", ">=", "0", ":", "\n", "        ", "alpha_t", "=", "alpha", "*", "targets", "+", "(", "1", "-", "alpha", ")", "*", "(", "1", "-", "targets", ")", "\n", "loss", "=", "alpha_t", "*", "loss", "\n", "\n", "", "if", "reduction", "==", "\"mean\"", ":", "\n", "        ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "", "elif", "reduction", "==", "\"sum\"", ":", "\n", "        ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.loss.sampling_loss": [[117, 129], ["labels.flatten.sum().item", "int", "predicted.flatten.flatten", "labels.flatten.flatten", "torch.binary_cross_entropy_with_logits", "loss_all[].topk", "loss_all[].sum", "topk_loss_neg.sum", "labels.flatten.sum"], "function", ["None"], ["", "def", "sampling_loss", "(", "predicted", ",", "labels", ",", "ratio", "=", "3", ")", ":", "\n", "    ", "num_of_pos", "=", "labels", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_of_neg", "=", "int", "(", "num_of_pos", "*", "ratio", ")", "\n", "predicted", "=", "predicted", ".", "flatten", "(", "start_dim", "=", "1", ")", "\n", "labels", "=", "labels", ".", "flatten", "(", "start_dim", "=", "1", ")", "\n", "\n", "loss_all", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "predicted", ",", "labels", ",", "reduction", "=", "'none'", ")", "\n", "\n", "topk_loss_neg", ",", "_", "=", "loss_all", "[", "labels", "==", "0", "]", ".", "topk", "(", "num_of_neg", ")", "\n", "loss_pos", "=", "loss_all", "[", "labels", "==", "1", "]", ".", "sum", "(", ")", "\n", "loss_neg", "=", "topk_loss_neg", ".", "sum", "(", ")", "\n", "return", "(", "loss_pos", "+", "loss_neg", ")", "/", "(", "num_of_pos", "+", "num_of_neg", ")", "", "", ""]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.PositionalEncoding2D.__init__": [[11, 26], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "int", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.sin().transpose().unsqueeze().repeat", "torch.sin().transpose().unsqueeze().repeat", "torch.sin().transpose().unsqueeze().repeat", "torch.sin().transpose().unsqueeze().repeat", "torch.cos().transpose().unsqueeze().repeat", "torch.cos().transpose().unsqueeze().repeat", "torch.cos().transpose().unsqueeze().repeat", "torch.cos().transpose().unsqueeze().repeat", "torch.sin().transpose().unsqueeze().repeat", "torch.sin().transpose().unsqueeze().repeat", "torch.sin().transpose().unsqueeze().repeat", "torch.sin().transpose().unsqueeze().repeat", "torch.cos().transpose().unsqueeze().repeat", "torch.cos().transpose().unsqueeze().repeat", "torch.cos().transpose().unsqueeze().repeat", "torch.cos().transpose().unsqueeze().repeat", "model.PositionalEncoding2D.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.sin().transpose().unsqueeze", "torch.sin().transpose().unsqueeze", "torch.sin().transpose().unsqueeze", "torch.sin().transpose().unsqueeze", "torch.cos().transpose().unsqueeze", "torch.cos().transpose().unsqueeze", "torch.cos().transpose().unsqueeze", "torch.cos().transpose().unsqueeze", "torch.sin().transpose().unsqueeze", "torch.sin().transpose().unsqueeze", "torch.sin().transpose().unsqueeze", "torch.sin().transpose().unsqueeze", "torch.cos().transpose().unsqueeze", "torch.cos().transpose().unsqueeze", "torch.cos().transpose().unsqueeze", "torch.cos().transpose().unsqueeze", "math.log", "torch.sin().transpose", "torch.sin().transpose", "torch.sin().transpose", "torch.sin().transpose", "torch.cos().transpose", "torch.cos().transpose", "torch.cos().transpose", "torch.cos().transpose", "torch.sin().transpose", "torch.sin().transpose", "torch.sin().transpose", "torch.sin().transpose", "torch.cos().transpose", "torch.cos().transpose", "torch.cos().transpose", "torch.cos().transpose", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "height_max", ",", "width_max", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding2D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "pe", "=", "torch", ".", "zeros", "(", "d_model", ",", "height_max", ",", "width_max", ")", "\n", "# Each dimension use half of d_model", "\n", "d_model", "=", "int", "(", "d_model", "/", "2", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0.", ",", "d_model", ",", "2", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pos_w", "=", "torch", ".", "arange", "(", "0.", ",", "width_max", ")", ".", "unsqueeze", "(", "1", ")", "\n", "pos_h", "=", "torch", ".", "arange", "(", "0.", ",", "height_max", ")", ".", "unsqueeze", "(", "1", ")", "\n", "pe", "[", "0", ":", "d_model", ":", "2", ",", ":", ",", ":", "]", "=", "torch", ".", "sin", "(", "pos_w", "*", "div_term", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "height_max", ",", "1", ")", "\n", "pe", "[", "1", ":", "d_model", ":", "2", ",", ":", ",", ":", "]", "=", "torch", ".", "cos", "(", "pos_w", "*", "div_term", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "height_max", ",", "1", ")", "\n", "pe", "[", "d_model", ":", ":", "2", ",", ":", ",", ":", "]", "=", "torch", ".", "sin", "(", "pos_h", "*", "div_term", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "width_max", ")", "\n", "pe", "[", "d_model", "+", "1", ":", ":", "2", ",", ":", ",", ":", "]", "=", "torch", ".", "cos", "(", "pos_h", "*", "div_term", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "width_max", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.PositionalEncoding2D.forward": [[27, 30], ["model.PositionalEncoding2D.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "pe", "[", ":", ",", ":", "x", ".", "shape", "[", "2", "]", ",", ":", "x", ".", "shape", "[", "3", "]", "]", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.PositionalEncoding.__init__": [[34, 45], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze().transpose.unsqueeze().transpose.unsqueeze().transpose", "model.PositionalEncoding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "pe.unsqueeze().transpose.unsqueeze().transpose.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "dropout", "=", "0.1", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ")", ".", "float", "(", ")", "*", "(", "-", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.PositionalEncoding.forward": [[46, 49], ["model.PositionalEncoding.dropout", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "pe", "[", ":", "x", ".", "size", "(", "0", ")", ",", ":", "]", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.TextModel.__init__": [[52, 58], ["torch.nn.Module.__init__", "transformers.ElectraModel.from_pretrained", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "num_words", ",", "padding_idx", ",", "num_colors", ",", "num_types", ")", ":", "\n", "        ", "super", "(", "TextModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "ElectraModel", ".", "from_pretrained", "(", "\"google/electra-small-discriminator\"", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "256", ",", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", ")", "\n", "self", ".", "color", "=", "nn", ".", "Linear", "(", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", ",", "num_colors", ")", "\n", "self", ".", "typ", "=", "nn", ".", "Linear", "(", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", ",", "num_types", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.TextModel.forward": [[59, 70], ["model.TextModel.fc", "model.TextModel.model", "model.TextModel.model", "model.TextModel.color", "model.TextModel.typ", "mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "mask", "=", "(", "x", "!=", "0", ")", "\n", "x", "=", "self", ".", "model", "(", "x", ",", "attention_mask", "=", "mask", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "model", "(", "x", ")", "[", "0", "]", "\n", "", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "# bs, seq_len, emb = x.shape", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "x", ",", "self", ".", "color", "(", "x", "[", ":", ",", "0", "]", ")", ",", "self", ".", "typ", "(", "x", "[", ":", ",", "0", "]", ")", ",", "mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.RNN.__init__": [[73, 88], ["torch.nn.Module.__init__", "model.PositionalEncoding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "model.RNN.init_weights", "torch.nn.TransformerEncoderLayer", "torch.nn.TransformerEncoderLayer"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.RNN.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "num_words", ",", "padding_idx", ",", "num_colors", ",", "num_types", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "pos_encoder", "=", "PositionalEncoding", "(", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", ",", "max_len", "=", "30", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "num_words", ",", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "TransformerEncoder", "(", "\n", "nn", ".", "TransformerEncoderLayer", "(", "d_model", "=", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", ",", "nhead", "=", "8", ")", ",", "\n", "num_layers", "=", "cfg", ".", "MODEL", ".", "RNN", ".", "LAYERS", "\n", ")", "\n", "self", ".", "src_mask", "=", "None", "\n", "self", ".", "hidden_size", "=", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", "\n", "self", ".", "color", "=", "nn", ".", "Linear", "(", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", ",", "num_colors", ")", "\n", "self", ".", "typ", "=", "nn", ".", "Linear", "(", "cfg", ".", "MODEL", ".", "RNN", ".", "HIDDEN", ",", "num_types", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.RNN.init_weights": [[89, 92], ["model.RNN.embedding.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.RNN._generate_square_subsequent_mask": [[93, 97], ["mask.float().masked_fill().masked_fill.float().masked_fill().masked_fill.float().masked_fill().masked_fill", "float", "mask.float().masked_fill().masked_fill.float().masked_fill().masked_fill.float().masked_fill", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.float().masked_fill().masked_fill.float().masked_fill().masked_fill.float"], "methods", ["None"], ["", "def", "_generate_square_subsequent_mask", "(", "self", ",", "sz", ")", ":", "\n", "        ", "mask", "=", "(", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "sz", ",", "sz", ")", ")", "==", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "mask", "=", "mask", ".", "float", "(", ")", ".", "masked_fill", "(", "mask", "==", "0", ",", "float", "(", "'-inf'", ")", ")", ".", "masked_fill", "(", "mask", "==", "1", ",", "float", "(", "0.0", ")", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.RNN.make_pad_mask": [[98, 101], ["None"], "methods", ["None"], ["", "def", "make_pad_mask", "(", "self", ",", "idx", ")", ":", "\n", "# len, bs to bs, len", "\n", "        ", "return", "(", "idx", "==", "self", ".", "padding_idx", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.RNN.forward": [[102, 117], ["model.RNN.make_pad_mask", "model.RNN.pos_encoder", "model.RNN.rnn", "model.RNN.permute", "model.RNN._generate_square_subsequent_mask().to", "model.RNN.embedding", "math.sqrt", "model.RNN.mean", "model.RNN.src_mask.size", "len", "model.RNN.permute", "model.RNN.color", "model.RNN.typ", "model.RNN._generate_square_subsequent_mask", "len"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.RNN.make_pad_mask", "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.RNN._generate_square_subsequent_mask"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "src_mask", "is", "None", "or", "self", ".", "src_mask", ".", "size", "(", "0", ")", "!=", "len", "(", "x", ")", ":", "\n", "            ", "device", "=", "x", ".", "device", "\n", "mask", "=", "self", ".", "_generate_square_subsequent_mask", "(", "len", "(", "x", ")", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "src_mask", "=", "mask", "\n", "", "mask", "=", "self", ".", "make_pad_mask", "(", "x", ")", "\n", "# print(mask)", "\n", "x", "=", "self", ".", "embedding", "(", "x", ")", "*", "math", ".", "sqrt", "(", "self", ".", "hidden_size", ")", "\n", "x", "=", "self", ".", "pos_encoder", "(", "x", ")", "\n", "x", "=", "self", ".", "rnn", "(", "x", ",", "self", ".", "src_mask", ",", "src_key_padding_mask", "=", "mask", ")", "\n", "length", ",", "bs", ",", "emb", "=", "x", ".", "shape", "\n", "if", "self", ".", "training", ":", "\n", "            ", "v", "=", "x", ".", "mean", "(", "dim", "=", "0", ")", "\n", "return", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ",", "self", ".", "color", "(", "v", ")", ",", "self", ".", "typ", "(", "v", ")", "\n", "", "return", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.CNN.__init__": [[120, 136], ["torch.nn.Module.__init__", "torchvision.resnet50", "torch.nn.Sequential", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "norm_layer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "# self.global_embedding = models.vgg16(pretrained=True).features", "\n", "self", ".", "global_embedding", "=", "models", ".", "resnet50", "(", "pretrained", "=", "True", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "global_embedding", ".", "layer4", "[", "0", "]", ".", "conv2", ".", "stride", "=", "1", "\n", "self", ".", "global_embedding", ".", "layer4", "[", "0", "]", ".", "downsample", "[", "0", "]", ".", "stride", "=", "1", "\n", "self", ".", "global_embedding", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "global_embedding", ".", "conv1", ",", "\n", "self", ".", "global_embedding", ".", "bn1", ",", "\n", "self", ".", "global_embedding", ".", "relu", ",", "\n", "self", ".", "global_embedding", ".", "maxpool", ",", "\n", "self", ".", "global_embedding", ".", "layer1", ",", "\n", "self", ".", "global_embedding", ".", "layer2", ",", "\n", "self", ".", "global_embedding", ".", "layer3", ",", "\n", "self", ".", "global_embedding", ".", "layer4", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.CNN.forward": [[138, 140], ["model.CNN.global_embedding"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "global_img", ")", ":", "\n", "        ", "return", "self", ".", "global_embedding", "(", "global_img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.SELayer.__init__": [[143, 151], ["torch.nn.Module.__init__", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "reduction", "=", "16", ")", ":", "\n", "        ", "super", "(", "SELayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "channel", ",", "channel", "//", "reduction", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "channel", "//", "reduction", ",", "channel", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.SELayer.forward": [[153, 164], ["x.size", "model.SELayer.fc().unsqueeze().unsqueeze", "x.mean.split", "x.mean", "mask.sum", "model.SELayer.fc().unsqueeze", "model.SELayer.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "b", ",", "t", ",", "c", "=", "x", ".", "size", "(", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "y", "=", "(", "x", "*", "mask", ")", ".", "sum", "(", "dim", "=", "1", ")", "/", "mask", ".", "sum", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "x", ".", "mean", "(", "dim", "=", "1", ")", "\n", "# y = self.avg_pool(x).view(b, c)", "\n", "", "y", "=", "self", ".", "fc", "(", "y", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "y", "\n", "w", ",", "b", "=", "y", ".", "split", "(", "y", ".", "shape", "[", "1", "]", "//", "2", ",", "dim", "=", "1", ")", "\n", "return", "w", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.MyModel.__init__": [[167, 201], ["torch.nn.Module.__init__", "model.TextModel", "model.CNN", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "model.SELayer", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "model.PositionalEncoding2D", "torch.nn.Conv2d", "torch.nn.Conv2d", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Linear", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "norm_layer", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "num_words", ",", "padding_idx", ",", "norm_layer", ",", "num_colors", ",", "num_types", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "==", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "self", ".", "rnn", "=", "TextModel", "(", "cfg", ",", "num_words", ",", "padding_idx", ",", "num_colors", ",", "num_types", ")", "\n", "self", ".", "cnn", "=", "CNN", "(", "cfg", ",", "norm_layer", ")", "\n", "self", ".", "a", "=", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "self", ".", "b", "=", "nn", ".", "Conv2d", "(", "2048", ",", "2048", ",", "1", ")", "\n", "self", ".", "c", "=", "nn", ".", "Linear", "(", "2048", ",", "2048", ")", "\n", "self", ".", "d", "=", "nn", ".", "Conv2d", "(", "2048", ",", "2048", ",", "1", ")", "\n", "\n", "self", ".", "e", "=", "nn", ".", "Conv2d", "(", "2048", ",", "512", ",", "1", ")", "\n", "self", ".", "f", "=", "nn", ".", "Conv2d", "(", "2048", ",", "2048", ",", "1", ")", "\n", "\n", "self", ".", "se", "=", "SELayer", "(", "2048", ")", "\n", "self", ".", "out", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "2048", ",", "1024", ",", "3", ",", "padding", "=", "1", ")", ",", "norm_layer", "(", "1024", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "1024", ",", "512", ",", "3", ",", "padding", "=", "1", ")", ",", "norm_layer", "(", "512", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "256", ",", "3", ",", "padding", "=", "1", ")", ",", "norm_layer", "(", "256", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "1", ",", "3", ",", "padding", "=", "1", ")", ")", "\n", "\n", "if", "norm_layer", "==", "nn", ".", "BatchNorm2d", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm1d", "\n", "\n", "", "self", ".", "color", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2048", ",", "1024", ")", ",", "norm_layer", "(", "1024", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "num_colors", ")", "\n", ")", "\n", "self", ".", "types", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2048", ",", "1024", ")", ",", "norm_layer", "(", "1024", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "num_types", ")", "\n", ")", "\n", "\n", "self", ".", "pos", "=", "PositionalEncoding2D", "(", "2048", ",", "24", ",", "24", ")", "# 24, 24", "\n", "# self.attn = nn.ModuleList([", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.model.MyModel.forward": [[205, 277], ["model.MyModel.pos", "model.MyModel.b", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model.MyModel.e().reshape", "torch.softmax.permute().contiguous().bmm", "torch.softmax", "torch.softmax", "model.MyModel.f().reshape", "img_value.bmm().reshape.bmm().reshape.bmm().reshape", "model.MyModel.rnn", "model.MyModel.cnn", "model.MyModel.a", "model.MyModel.reshape", "model.MyModel.c().permute", "torch.bmm.reshape", "torch.bmm.reshape", "model.MyModel.d().reshape().permute", "model.MyModel.se", "model.MyModel.se", "model.MyModel.out", "model.MyModel.sigmoid", "model.MyModel.out", "model.MyModel.color", "model.MyModel.types", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "model.MyModel.cnn", "model.MyModel.color", "model.MyModel.types", "model.MyModel.e", "torch.softmax.permute().contiguous", "model.MyModel.f", "img_value.bmm().reshape.bmm().reshape.bmm", "model.MyModel.c", "model.MyModel.d().reshape", "torch.softmax.permute", "activation_map.sum", "activation_map.sum", "torch.softmax.permute", "model.MyModel.d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "nl", ",", "global_img", ",", "activation_map", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "nl", ",", "nl_color", ",", "nl_types", ",", "mask", "=", "self", ".", "rnn", "(", "nl", ")", "\n", "img_ft", "=", "self", ".", "cnn", "(", "global_img", ")", "\n", "img_org", "=", "img_ft", "\n", "", "else", ":", "\n", "# caching", "\n", "            ", "if", "not", "torch", ".", "is_tensor", "(", "nl", ")", ":", "\n", "                ", "img_ft", "=", "self", ".", "cnn", "(", "global_img", ")", "\n", "vectors", "=", "(", "img_ft", "*", "activation_map", ")", ".", "sum", "(", "dim", "=", "(", "2", ",", "3", ")", ")", "/", "(", "activation_map", ".", "sum", "(", "dim", "=", "(", "2", ",", "3", ")", ")", "+", "1e-7", ")", "\n", "color", "=", "self", ".", "color", "(", "vectors", ")", "\n", "types", "=", "self", ".", "types", "(", "vectors", ")", "\n", "return", "img_ft", ",", "color", ",", "types", "\n", "", "img_ft", "=", "global_img", "\n", "# img_org = img_ft", "\n", "", "img_ft", "=", "self", ".", "pos", "(", "img_ft", ")", "\n", "# nl = nl.mean(dim=1)", "\n", "# bs, emb = nl.shape", "\n", "img_ft_b", "=", "self", ".", "b", "(", "img_ft", ")", "\n", "bs", ",", "c", ",", "h", ",", "w", "=", "img_ft_b", ".", "shape", "\n", "# bs, t, hw", "\n", "relation", "=", "torch", ".", "bmm", "(", "self", ".", "a", "(", "nl", ")", ",", "img_ft_b", ".", "reshape", "(", "bs", ",", "c", ",", "-", "1", ")", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "relation", "=", "relation", "*", "mask", "\n", "\n", "", "weights", "=", "F", ".", "softmax", "(", "relation", ",", "dim", "=", "1", ")", "\n", "weighted_img_ft", "=", "torch", ".", "bmm", "(", "self", ".", "c", "(", "nl", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ",", "weights", ")", "\n", "img_ft", "=", "weighted_img_ft", ".", "reshape", "(", "bs", ",", "c", ",", "h", ",", "w", ")", "+", "img_ft", "\n", "\n", "weights", "=", "F", ".", "softmax", "(", "relation", ",", "dim", "=", "2", ")", "\n", "weighted_nl_ft", "=", "torch", ".", "bmm", "(", "weights", ",", "self", ".", "d", "(", "img_ft", ")", ".", "reshape", "(", "bs", ",", "c", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "nl", "=", "weighted_nl_ft", "+", "nl", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "weights", "=", "self", ".", "se", "(", "nl", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "weights", "=", "self", ".", "se", "(", "nl", ")", "\n", "# nl = nl * se.unsqueeze(dim=1)", "\n", "# nl = nl.mean(dim=1).unsqueeze(-1).unsqueeze(-1)", "\n", "", "img_ft", "=", "img_ft", "*", "weights", "\n", "\n", "# ===== self attention =====", "\n", "# img_ft = self.pos(img_ft)", "\n", "img_key", "=", "self", ".", "e", "(", "img_ft", ")", ".", "reshape", "(", "bs", ",", "512", ",", "-", "1", ")", "\n", "# bs, hw, hw", "\n", "img_key", "=", "img_key", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ".", "bmm", "(", "img_key", ")", "\n", "img_key", "=", "F", ".", "softmax", "(", "img_key", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# bs, c, hw", "\n", "img_value", "=", "self", ".", "f", "(", "img_ft", ")", ".", "reshape", "(", "bs", ",", "c", ",", "-", "1", ")", "\n", "# bs, c, h, w", "\n", "img_value", "=", "img_value", ".", "bmm", "(", "img_key", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "reshape", "(", "bs", ",", "c", ",", "h", ",", "w", ")", "\n", "img_ft", "=", "img_ft", "+", "img_value", "\n", "# img_ft = self.g(img_ft)", "\n", "# ===== end self attention =====", "\n", "\n", "# nl = nl.reshape(nl.shape[0], -1, 1, 1)", "\n", "# last = img_ft + nl", "\n", "# nl = nl.expand(-1, -1, img_ft.shape[2], img_ft.shape[3])", "\n", "# last = torch.cat([img_ft, nl], dim=1)", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "pred_map", "=", "self", ".", "out", "(", "img_ft", ")", "\n", "# vectors = (img_org * activation_map).sum(dim=(2, 3)) / (activation_map.sum(dim=(2, 3))+ 1e-7)", "\n", "# color = self.color(vectors)", "\n", "# types = self.types(vectors)", "\n", "return", "pred_map", ".", "sigmoid", "(", ")", "#, color, types", "\n", "", "else", ":", "\n", "            ", "pred_map", "=", "self", ".", "out", "(", "img_ft", ")", "\n", "vectors", "=", "(", "img_org", "*", "activation_map", ")", ".", "sum", "(", "dim", "=", "(", "2", ",", "3", ")", ")", "/", "(", "activation_map", ".", "sum", "(", "dim", "=", "(", "2", ",", "3", ")", ")", "+", "1e-7", ")", "\n", "color", "=", "self", ".", "color", "(", "vectors", ")", "\n", "types", "=", "self", ".", "types", "(", "vectors", ")", "\n", "return", "pred_map", ",", "color", ",", "types", ",", "nl_color", ",", "nl_types", "", "", "", "", ""]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__init__": [[13, 28], ["nltk.stem.PorterStemmer", "set", "transformers.ElectraTokenizerFast.from_pretrained", "os.path.exists", "nltk.corpus.stopwords.words", "os.path.join", "analyz.NL.__build_dict", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__build_dict"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "tracks", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "tracks", "=", "tracks", "\n", "self", ".", "s", "=", "PorterStemmer", "(", ")", "\n", "self", ".", "stop_words", "=", "set", "(", "stopwords", ".", "words", "(", "'english'", ")", ")", "\n", "self", ".", "tokenizer", "=", "ElectraTokenizerFast", ".", "from_pretrained", "(", "'google/electra-small-discriminator'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_count.pkl'", ")", ")", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_count.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "words_count", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_to_idx.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "word_to_idx", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'special_case.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "special_case", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "words_count", ",", "self", ".", "word_to_idx", "=", "self", ".", "__build_dict", "(", "self", ".", "tracks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "word_to_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.__build_dict": [[32, 87], ["collections.defaultdict", "analyz.NL.special_case.update", "print", "dict", "collections.defaultdict.items", "dict", "ec.replace", "zip", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "[].split", "analyz.NL.do_clean", "collections.defaultdict.keys", "range", "os.path.join", "os.path.join", "os.path.join", "len", "len", "len", "word.replace", "n.lower", "word.replace"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.do_clean"], ["", "def", "__build_dict", "(", "self", ",", "tracks", ")", ":", "\n", "        ", "word_count", "=", "defaultdict", "(", "int", ")", "\n", "\n", "word_count", "[", "'<SOS>'", "]", "+=", "1", "\n", "word_count", "[", "'<EOS>'", "]", "+=", "1", "\n", "word_count", "[", "'<PAD>'", "]", "+=", "1", "\n", "word_count", "[", "'<UNK>'", "]", "+=", "1", "\n", "max_length", "=", "0", "\n", "\n", "# special case handling", "\n", "except_case", "=", "[", "'dark-red'", ",", "'dark-blue'", ",", "'dark-colored'", "]", "\n", "hand_case", "=", "{", "\n", "'hatckback'", ":", "'hatchback'", "\n", "}", "\n", "self", ".", "special_case", "=", "{", "}", "\n", "for", "t", "in", "tracks", ":", "\n", "            ", "for", "n", "in", "t", "[", "'nl'", "]", ":", "\n", "                ", "for", "word", "in", "n", ".", "lower", "(", ")", "[", ":", "-", "1", "]", ".", "split", "(", ")", ":", "\n", "                    ", "if", "'-'", "in", "word", "and", "word", "not", "in", "except_case", "and", "word", "not", "in", "self", ".", "special_case", ":", "\n", "                        ", "self", ".", "special_case", "[", "word", ".", "replace", "(", "'-'", ",", "' '", ")", "]", "=", "word", ".", "replace", "(", "'-'", ",", "''", ")", "\n", "\n", "", "", "", "", "for", "ec", "in", "except_case", ":", "\n", "            ", "self", ".", "special_case", "[", "ec", "]", "=", "ec", ".", "replace", "(", "'-'", ",", "' '", ")", "\n", "", "self", ".", "special_case", ".", "update", "(", "hand_case", ")", "\n", "\n", "# self.special_case = special_case", "\n", "\n", "for", "t", "in", "tracks", ":", "\n", "            ", "for", "n", "in", "t", "[", "'nl'", "]", ":", "\n", "                ", "cleaned_sentence", "=", "self", ".", "do_clean", "(", "n", ")", "\n", "if", "len", "(", "cleaned_sentence", ")", ">", "max_length", ":", "\n", "                    ", "max_length", "=", "len", "(", "cleaned_sentence", ")", "\n", "", "for", "w", "in", "cleaned_sentence", ":", "\n", "# for l in n.replace('.', '').split():", "\n", "                    ", "word_count", "[", "w", "]", "+=", "1", "\n", "", "", "", "print", "(", "'max: '", ",", "max_length", ")", "\n", "new_dict", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "word_count", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", ">=", "self", ".", "cfg", ".", "DATA", ".", "MIN_COUNT", "or", "k", "in", "[", "'<SOS>'", ",", "'<EOS>'", ",", "'<PAD>'", ",", "'<UNK>'", "]", ":", "\n", "                ", "new_dict", "[", "k", "]", "=", "v", "\n", "\n", "", "", "word_count", "=", "new_dict", "\n", "\n", "word_to_idx", "=", "dict", "(", "zip", "(", "word_count", ".", "keys", "(", ")", ",", "range", "(", "len", "(", "word_count", ")", ")", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_count.pkl'", ")", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "word_count", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'word_to_idx.pkl'", ")", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "word_to_idx", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "cfg", ".", "DATA", ".", "DICT_PATH", ",", "'special_case.pkl'", ")", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "special_case", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "return", "word_count", ",", "word_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.do_clean": [[88, 98], ["nl.replace.replace.lower", "analyz.NL.special_case.items", "nl[].replace().split", "nl.replace.replace.replace", "nl[].replace"], "methods", ["None"], ["", "def", "do_clean", "(", "self", ",", "nl", ")", ":", "\n", "        ", "nl", "=", "nl", ".", "lower", "(", ")", "\n", "for", "sc", ",", "replaced", "in", "self", ".", "special_case", ".", "items", "(", ")", ":", "\n", "            ", "if", "sc", "in", "nl", ":", "\n", "                ", "nl", "=", "nl", ".", "replace", "(", "sc", ",", "replaced", ")", "\n", "\n", "", "", "nl", "=", "nl", "[", ":", "-", "1", "]", ".", "replace", "(", "'-'", ",", "''", ")", ".", "split", "(", ")", "\n", "# nl = [self.s.stem(w) for w in nl]", "\n", "# nl = [w for w in nl if w not in self.stop_words]", "\n", "return", "nl", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.sentence_to_index": [[99, 113], ["analyz.NL.do_clean", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.analyz.NL.do_clean"], ["", "def", "sentence_to_index", "(", "self", ",", "nl", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "nl", "=", "self", ".", "do_clean", "(", "nl", ")", "\n", "\n", "idxs", "=", "[", "self", ".", "word_to_idx", "[", "n", "]", "if", "n", "in", "self", ".", "word_to_idx", "else", "self", ".", "word_to_idx", "[", "'<UNK>'", "]", "for", "n", "in", "nl", "]", "\n", "\n", "if", "is_train", ":", "\n", "            ", "if", "len", "(", "idxs", ")", ">", "self", ".", "cfg", ".", "DATA", ".", "MAX_SENTENCE", ":", "\n", "                ", "idxs", "=", "idxs", "[", ":", "self", ".", "cfg", ".", "DATA", ".", "MAX_SENTENCE", "]", "\n", "idxs", "=", "[", "self", ".", "word_to_idx", "[", "'<SOS>'", "]", "]", "+", "idxs", "+", "[", "self", ".", "word_to_idx", "[", "'<EOS>'", "]", "]", "\n", "", "else", ":", "\n", "                ", "idxs", "=", "[", "self", ".", "word_to_idx", "[", "'<SOS>'", "]", "]", "+", "idxs", "+", "[", "self", ".", "word_to_idx", "[", "'<EOS>'", "]", "]", "+", "[", "self", ".", "word_to_idx", "[", "'<PAD>'", "]", "for", "_", "in", "range", "(", "self", ".", "cfg", ".", "DATA", ".", "MAX_SENTENCE", "-", "len", "(", "idxs", ")", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "idxs", "=", "[", "self", ".", "word_to_idx", "[", "'<SOS>'", "]", "]", "+", "idxs", "+", "[", "self", ".", "word_to_idx", "[", "'<EOS>'", "]", "]", "\n", "", "return", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.utils.compute_probability_of_activation": [[7, 16], ["result[].sum"], "function", ["None"], ["def", "compute_probability_of_activation", "(", "result", ",", "roi", ",", "threshold", ")", ":", "\n", "    ", "'''\n    results: numpy array of shape (h, w)\n    roi: numpy array of shape (4) (xyxy)\n    '''", "\n", "# roi = [b.item() for b in roi]", "\n", "result", "=", "(", "result", ">", "threshold", ")", "*", "result", "\n", "activation_ratio", "=", "result", "[", ":", ",", "roi", "[", "1", "]", ":", "roi", "[", "3", "]", ",", "roi", "[", "0", "]", ":", "roi", "[", "2", "]", "]", ".", "sum", "(", ")", "/", "(", "(", "roi", "[", "3", "]", "-", "roi", "[", "1", "]", ")", "*", "(", "roi", "[", "2", "]", "-", "roi", "[", "0", "]", ")", ")", "\n", "return", "activation_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.utils.compute_probability_of_point": [[18, 26], ["result[].item"], "function", ["None"], ["", "def", "compute_probability_of_point", "(", "result", ",", "roi", ",", "threshold", ")", ":", "\n", "    ", "'''\n    results: numpy array of shape (h, w)\n    roi: numpy array of shape (4) (xyxy)\n    '''", "\n", "# print(result.shape)", "\n", "# print(result[:, (roi[1] + roi[3])//2, (roi[0] + roi[2])//2].shape)", "\n", "return", "result", "[", ":", ",", "(", "roi", "[", "1", "]", "+", "roi", "[", "3", "]", ")", "//", "2", ",", "(", "roi", "[", "0", "]", "+", "roi", "[", "2", "]", ")", "//", "2", "]", ".", "item", "(", ")", "# > threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.utils.compute_probability_of_activations": [[28, 35], ["len", "zip", "utils.compute_probability_of_activation"], "function", ["home.repos.pwc.inspect_result.lsrock1_nlp_search.None.utils.compute_probability_of_activation"], ["", "def", "compute_probability_of_activations", "(", "results", ",", "rois", ",", "threshold", ")", ":", "\n", "    ", "total_length", "=", "len", "(", "results", ")", "\n", "bool_results", "=", "0", "\n", "for", "result", ",", "roi", "in", "zip", "(", "results", ",", "rois", ")", ":", "\n", "        ", "activation_ratio", "=", "compute_probability_of_activation", "(", "result", ",", "roi", ",", "threshold", ")", "\n", "bool_results", "+=", "activation_ratio", "# > threshold", "\n", "", "return", "bool_results", "/", "total_length", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.utils.save_img": [[37, 60], ["cv2.applyColorMap", "cv2.resize", "tuple", "cv2.rectangle", "numpy.concatenate", "cv2.imwrite", "print", "numpy.uint8", "numpy.float32", "numpy.max", "np.concatenate.astype", "numpy.float32", "int"], "function", ["None"], ["", "def", "save_img", "(", "activation", ",", "image", ",", "box", ",", "path", ")", ":", "\n", "    ", "'''\n    activation: numpy array 0~255\n    '''", "\n", "heatmap", "=", "cv2", ".", "applyColorMap", "(", "np", ".", "uint8", "(", "activation", ")", ",", "cv2", ".", "COLORMAP_JET", ")", "\n", "# draw box to heatmap", "\n", "heatmap", "=", "np", ".", "float32", "(", "heatmap", ")", "/", "255", "\n", "heatmap", "=", "cv2", ".", "resize", "(", "heatmap", ",", "(", "image", ".", "shape", "[", "1", "]", ",", "image", ".", "shape", "[", "0", "]", ")", ")", "\n", "# img = cv2.resize(img, (384, 384))#(heatmap.shape[1], heatmap.shape[0]))", "\n", "\n", "cam", "=", "heatmap", "+", "np", ".", "float32", "(", "image", ")", "/", "255", "\n", "cam", "=", "cam", "/", "np", ".", "max", "(", "cam", ")", "\n", "\n", "# h_ratio = img.shape[0] / o.shape[0]", "\n", "# w_ratio = img.shape[1] / o.shape[1]", "\n", "# xyxy", "\n", "# box = [b.item() for b in boxes[i]]", "\n", "box", "=", "tuple", "(", "[", "int", "(", "b", ")", "for", "b", "in", "box", "]", ")", "\n", "cv2", ".", "rectangle", "(", "cam", ",", "box", "[", ":", "2", "]", ",", "box", "[", "2", ":", "]", ",", "(", "255", ",", "255", ",", "0", ")", ",", "2", ")", "\n", "cam", "=", "cam", "*", "255", "\n", "cam", "=", "np", ".", "concatenate", "(", "[", "cam", ",", "image", "]", ",", "axis", "=", "1", ")", "\n", "cv2", ".", "imwrite", "(", "path", ",", "cam", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "print", "(", "'saved: '", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.utils.stableMatching": [[62, 128], ["numpy.transpose().tolist", "list", "range", "numpy.transpose", "list.pop", "herPreferences.index", "herPreferences.index", "list.pop", "list.insert"], "function", ["None"], ["", "def", "stableMatching", "(", "matrix", ")", ":", "\n", "# Initially, all n men are unmarried", "\n", "    ", "num_nl", ",", "num_img", "=", "matrix", ".", "shape", "\n", "menPreferences", "=", "(", "-", "matrix", ")", ".", "argsort", "(", "axis", "=", "1", ")", ".", "tolist", "(", ")", "\n", "womenPreferences", "=", "np", ".", "transpose", "(", "(", "-", "matrix", ")", ".", "argsort", "(", "axis", "=", "0", ")", ")", ".", "tolist", "(", ")", "\n", "unmarriedMen", "=", "list", "(", "range", "(", "num_nl", ")", ")", "\n", "# None of the men has a spouse yet, we denote this by the value None", "\n", "manSpouse", "=", "[", "None", "]", "*", "num_nl", "\n", "# None of the women has a spouse yet, we denote this by the value None", "\n", "womanSpouse", "=", "[", "None", "]", "*", "num_img", "\n", "# Each man made 0 proposals, which means that ", "\n", "# his next proposal will be to the woman number 0 in his list", "\n", "nextManChoice", "=", "[", "0", "]", "*", "num_nl", "\n", "\n", "# While there exists at least one unmarried man:", "\n", "while", "unmarriedMen", ":", "\n", "# Pick an arbitrary unmarried man", "\n", "        ", "he", "=", "unmarriedMen", "[", "0", "]", "\n", "# Store his ranking in this variable for convenience", "\n", "hisPreferences", "=", "menPreferences", "[", "he", "]", "\n", "# Find a woman to propose to", "\n", "she", "=", "hisPreferences", "[", "nextManChoice", "[", "he", "]", "]", "\n", "# Store her ranking in this variable for convenience", "\n", "herPreferences", "=", "womenPreferences", "[", "she", "]", "\n", "# Find the present husband of the selected woman (it might be None)", "\n", "currentHusband", "=", "womanSpouse", "[", "she", "]", "\n", "\n", "\n", "# Now \"he\" proposes to \"she\". ", "\n", "# Decide whether \"she\" accepts, and update the following fields", "\n", "# 1. manSpouse", "\n", "# 2. womanSpouse", "\n", "# 3. unmarriedMen", "\n", "# 4. nextManChoice", "\n", "if", "currentHusband", "==", "None", ":", "\n", "#No Husband case", "\n", "#\"She\" accepts any proposal", "\n", "            ", "womanSpouse", "[", "she", "]", "=", "he", "\n", "manSpouse", "[", "he", "]", "=", "she", "\n", "#\"His\" nextchoice is the next woman", "\n", "#in the hisPreferences list", "\n", "nextManChoice", "[", "he", "]", "=", "nextManChoice", "[", "he", "]", "+", "1", "\n", "#Delete \"him\" from the ", "\n", "#Unmarried list", "\n", "unmarriedMen", ".", "pop", "(", "0", ")", "\n", "", "else", ":", "\n", "#Husband exists", "\n", "#Check the preferences of the ", "\n", "#current husband and that of the proposed man's", "\n", "            ", "currentIndex", "=", "herPreferences", ".", "index", "(", "currentHusband", ")", "\n", "hisIndex", "=", "herPreferences", ".", "index", "(", "he", ")", "\n", "#Accept the proposal if ", "\n", "#\"he\" has higher preference in the herPreference list", "\n", "if", "currentIndex", ">", "hisIndex", ":", "\n", "#New stable match is found for \"her\"", "\n", "                ", "womanSpouse", "[", "she", "]", "=", "he", "\n", "manSpouse", "[", "he", "]", "=", "she", "\n", "nextManChoice", "[", "he", "]", "=", "nextManChoice", "[", "he", "]", "+", "1", "\n", "#Pop the newly wed husband", "\n", "unmarriedMen", ".", "pop", "(", "0", ")", "\n", "#Now the previous husband is unmarried add", "\n", "#him to the unmarried list", "\n", "unmarriedMen", ".", "insert", "(", "0", ",", "currentHusband", ")", "\n", "", "else", ":", "\n", "                ", "nextManChoice", "[", "he", "]", "=", "nextManChoice", "[", "he", "]", "+", "1", "\n", "", "", "", "return", "manSpouse", "", "", ""]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.configs.get_default_config": [[72, 74], ["_C.clone"], "function", ["None"], ["def", "get_default_config", "(", ")", ":", "\n", "    ", "return", "_C", ".", "clone", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.lsrock1_nlp_search.None.sm.stableMatching": [[31, 97], ["numpy.transpose().tolist", "list", "range", "numpy.transpose", "list.pop", "herPreferences.index", "herPreferences.index", "list.pop", "list.insert"], "function", ["None"], ["def", "stableMatching", "(", "matrix", ")", ":", "\n", "# Initially, all n men are unmarried", "\n", "    ", "num_nl", ",", "num_img", "=", "matrix", ".", "shape", "\n", "menPreferences", "=", "(", "-", "matrix", ")", ".", "argsort", "(", "axis", "=", "1", ")", ".", "tolist", "(", ")", "\n", "womenPreferences", "=", "np", ".", "transpose", "(", "(", "-", "matrix", ")", ".", "argsort", "(", "axis", "=", "0", ")", ")", ".", "tolist", "(", ")", "\n", "unmarriedMen", "=", "list", "(", "range", "(", "num_nl", ")", ")", "\n", "# None of the men has a spouse yet, we denote this by the value None", "\n", "manSpouse", "=", "[", "None", "]", "*", "num_nl", "\n", "# None of the women has a spouse yet, we denote this by the value None", "\n", "womanSpouse", "=", "[", "None", "]", "*", "num_img", "\n", "# Each man made 0 proposals, which means that ", "\n", "# his next proposal will be to the woman number 0 in his list", "\n", "nextManChoice", "=", "[", "0", "]", "*", "num_nl", "\n", "\n", "# While there exists at least one unmarried man:", "\n", "while", "unmarriedMen", ":", "\n", "# Pick an arbitrary unmarried man", "\n", "        ", "he", "=", "unmarriedMen", "[", "0", "]", "\n", "# Store his ranking in this variable for convenience", "\n", "hisPreferences", "=", "menPreferences", "[", "he", "]", "\n", "# Find a woman to propose to", "\n", "she", "=", "hisPreferences", "[", "nextManChoice", "[", "he", "]", "]", "\n", "# Store her ranking in this variable for convenience", "\n", "herPreferences", "=", "womenPreferences", "[", "she", "]", "\n", "# Find the present husband of the selected woman (it might be None)", "\n", "currentHusband", "=", "womanSpouse", "[", "she", "]", "\n", "\n", "\n", "# Now \"he\" proposes to \"she\". ", "\n", "# Decide whether \"she\" accepts, and update the following fields", "\n", "# 1. manSpouse", "\n", "# 2. womanSpouse", "\n", "# 3. unmarriedMen", "\n", "# 4. nextManChoice", "\n", "if", "currentHusband", "==", "None", ":", "\n", "#No Husband case", "\n", "#\"She\" accepts any proposal", "\n", "            ", "womanSpouse", "[", "she", "]", "=", "he", "\n", "manSpouse", "[", "he", "]", "=", "she", "\n", "#\"His\" nextchoice is the next woman", "\n", "#in the hisPreferences list", "\n", "nextManChoice", "[", "he", "]", "=", "nextManChoice", "[", "he", "]", "+", "1", "\n", "#Delete \"him\" from the ", "\n", "#Unmarried list", "\n", "unmarriedMen", ".", "pop", "(", "0", ")", "\n", "", "else", ":", "\n", "#Husband exists", "\n", "#Check the preferences of the ", "\n", "#current husband and that of the proposed man's", "\n", "            ", "currentIndex", "=", "herPreferences", ".", "index", "(", "currentHusband", ")", "\n", "hisIndex", "=", "herPreferences", ".", "index", "(", "he", ")", "\n", "#Accept the proposal if ", "\n", "#\"he\" has higher preference in the herPreference list", "\n", "if", "currentIndex", ">", "hisIndex", ":", "\n", "#New stable match is found for \"her\"", "\n", "                ", "womanSpouse", "[", "she", "]", "=", "he", "\n", "manSpouse", "[", "he", "]", "=", "she", "\n", "nextManChoice", "[", "he", "]", "=", "nextManChoice", "[", "he", "]", "+", "1", "\n", "#Pop the newly wed husband", "\n", "unmarriedMen", ".", "pop", "(", "0", ")", "\n", "#Now the previous husband is unmarried add", "\n", "#him to the unmarried list", "\n", "unmarriedMen", ".", "insert", "(", "0", ",", "currentHusband", ")", "\n", "", "else", ":", "\n", "                ", "nextManChoice", "[", "he", "]", "=", "nextManChoice", "[", "he", "]", "+", "1", "\n", "", "", "", "return", "manSpouse", "\n", "\n"]]}