{"home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.None.main.dyn_batch_with_padding": [[19, 22], ["max", "len", "len"], "function", ["None"], ["def", "dyn_batch_with_padding", "(", "new", ",", "i", ",", "sofar", ")", ":", "\n", "    ", "prev_max_len", "=", "sofar", "/", "(", "i", "-", "1", ")", "if", "i", ">", "1", "else", "0", "\n", "return", "max", "(", "len", "(", "new", ".", "src", ")", ",", "len", "(", "new", ".", "tgt", ")", ",", "prev_max_len", ")", "*", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.None.main.dyn_batch_without_padding": [[24, 26], ["max", "len", "len"], "function", ["None"], ["", "def", "dyn_batch_without_padding", "(", "new", ",", "i", ",", "sofar", ")", ":", "\n", "    ", "return", "sofar", "+", "max", "(", "len", "(", "new", ".", "src", ")", ",", "len", "(", "new", ".", "tgt", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.None.main.parse_args": [[28, 135], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.None.main.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a Transformer / FastTransformer.'", ")", "\n", "\n", "# added by lemon", "\n", "msg", "=", "'source embedding size, default 620'", "\n", "parser", ".", "add_argument", "(", "'--embdim'", ",", "nargs", "=", "1", ",", "type", "=", "int", ",", "help", "=", "msg", ")", "\n", "msg", "=", "'source, target hidden size, default 1000'", "\n", "parser", ".", "add_argument", "(", "'--hidden'", ",", "nargs", "=", "4", ",", "type", "=", "int", ",", "help", "=", "msg", ")", "\n", "msg", "=", "'max epoch'", "\n", "parser", ".", "add_argument", "(", "'--maxepoch'", ",", "type", "=", "int", ",", "help", "=", "msg", ")", "\n", "msg", "=", "'decay'", "\n", "parser", ".", "add_argument", "(", "'--decay'", ",", "type", "=", "float", ",", "help", "=", "msg", ")", "\n", "msg", "=", "'test_corpus'", "\n", "parser", ".", "add_argument", "(", "'--test_corpus'", ",", "type", "=", "str", ",", "help", "=", "msg", ")", "\n", "msg", "=", "'init source vocab'", "\n", "parser", ".", "add_argument", "(", "'--init_src_vocab'", ",", "type", "=", "str", ",", "help", "=", "msg", ")", "\n", "msg", "=", "'patience for early stop'", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "int", ",", "help", "=", "msg", ")", "\n", "parser", ".", "add_argument", "(", "'--k'", ",", "type", "=", "int", ",", "help", "=", "msg", ")", "\n", "\n", "# dataset settings", "\n", "parser", ".", "add_argument", "(", "'--corpus_prex'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--lang'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "\"the suffix of the corpus, translation language\"", ")", "\n", "parser", ".", "add_argument", "(", "'--valid'", ",", "type", "=", "str", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--writetrans'", ",", "type", "=", "str", ",", "help", "=", "'write translations for to a file'", ")", "\n", "parser", ".", "add_argument", "(", "'--ref'", ",", "type", "=", "str", ",", "help", "=", "'references, word unit'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--vocab'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_size'", ",", "type", "=", "int", ",", "default", "=", "40000", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--load_vocab'", ",", "action", "=", "'store_true'", ",", "help", "=", "'load a pre-computed vocabulary'", ")", "\n", "# parser.add_argument('--load_corpus', action='store_true', default=False, help='load a pre-processed corpus')", "\n", "# parser.add_argument('--save_corpus', action='store_true', default=False, help='save a pre-processed corpus')", "\n", "parser", ".", "add_argument", "(", "'--max_len'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'limit the train set sentences to this many tokens'", ")", "\n", "# parser.add_argument('--max_train_data', type=int, default=None,", "\n", "#                     help='limit the train set sentences to this many sentences')", "\n", "parser", ".", "add_argument", "(", "'--pool'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'shuffle batches in the pool'", ")", "\n", "\n", "# model name", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'[time]'", ",", "help", "=", "'prefix to denote the model, nothing or [time]'", ")", "\n", "\n", "# network settings", "\n", "parser", ".", "add_argument", "(", "'--share_embed'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'share embeddings and linear out weight'", ")", "\n", "parser", ".", "add_argument", "(", "'--share_vocab'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'share vocabulary between src and target'", ")", "\n", "\n", "# parser.add_argument('--ffw_block', type=str, default=\"residual\", choices=['residual', 'highway', 'nonresidual'])", "\n", "\n", "# parser.add_argument('--posi_kv', action='store_true', default=False,", "\n", "#                     help='incorporate positional information in key/value')", "\n", "\n", "# parser.add_argument('--params', type=str, default='user', choices=['user', 'small', 'middle', 'big'],", "\n", "#                     help='Defines the dimension size of the parameter')", "\n", "# parser.add_argument('--n_layers', type=int, default=5, help='number of layers')", "\n", "# parser.add_argument('--n_heads', type=int, default=2, help='number of heads')", "\n", "# parser.add_argument('--d_model', type=int, default=278, help='dimention size for hidden states')", "\n", "# parser.add_argument('--d_hidden', type=int, default=507, help='dimention size for FFN')", "\n", "\n", "# parser.add_argument('--initnn', default='standard', help='parameter init')", "\n", "\n", "# running setting", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "\n", "choices", "=", "[", "'train'", ",", "'test'", ",", "\n", "'distill'", "]", ")", "# distill : take a trained AR model and decode a training set", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "19920206", ",", "help", "=", "'seed for randomness'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--keep_cpts'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'save n checkpoints, when 1 save best model only'", ")", "\n", "\n", "# training", "\n", "parser", ".", "add_argument", "(", "'--eval_every'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'validate every * step'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_every'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'save model every * step (5000)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "help", "=", "'# of tokens processed per batch'", ")", "\n", "parser", ".", "add_argument", "(", "'--delay'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'gradiant accumulation for delayed update for large batch'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "default", "=", "'Adadelta'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "help", "=", "'maximum steps to linearly anneal the learning rate'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--maximum_steps'", ",", "type", "=", "int", ",", "default", "=", "5000000", ",", "help", "=", "'maximum steps you take to train a model'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_ratio'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'dropout ratio'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_drop_ratio'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'dropout ratio only for inputs'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--grad_clip'", ",", "type", "=", "float", ",", "default", "=", "-", "1.0", ",", "help", "=", "'gradient clipping'", ")", "\n", "parser", ".", "add_argument", "(", "'--smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'label smoothing'", ")", "\n", "\n", "# decoding", "\n", "parser", ".", "add_argument", "(", "'--length_ratio'", ",", "type", "=", "float", ",", "default", "=", "2", ",", "help", "=", "'maximum lengths of decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--beam_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'beam-size used in Beamsearch, default using greedy decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "0.6", ",", "help", "=", "'length normalization weights'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'test src file'", ")", "\n", "\n", "# model saving/reloading, output translations", "\n", "parser", ".", "add_argument", "(", "'--load_from'", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "help", "=", "'load from 1.modelname, 2.lastnumber, 3.number'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'when resume, need other things besides parameters'", ")", "\n", "# save path", "\n", "parser", ".", "add_argument", "(", "'--main_path'", ",", "type", "=", "str", ",", "default", "=", "\"./\"", ")", "\n", "parser", ".", "add_argument", "(", "'--model_path'", ",", "type", "=", "str", ",", "default", "=", "\"models\"", ")", "\n", "parser", ".", "add_argument", "(", "'--decoding_path'", ",", "type", "=", "str", ",", "default", "=", "\"decoding\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.None.main.set_seeds": [[137, 142], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seeds", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.None.main.curtime": [[144, 146], ["time.strftime", "time.localtime"], "function", ["None"], ["", "def", "curtime", "(", ")", ":", "\n", "    ", "return", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "time", ".", "localtime", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.None.main.override": [[148, 152], ["None"], "function", ["None"], ["", "def", "override", "(", "args", ",", "load_dict", ",", "except_name", ")", ":", "\n", "    ", "for", "k", "in", "args", ".", "__dict__", ":", "\n", "        ", "if", "k", "not", "in", "except_name", ":", "\n", "            ", "args", ".", "__dict__", "[", "k", "]", "=", "load_dict", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.beam.Beam.__init__": [[7, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "self", ".", "beam_size", "=", "beam_size", "\n", "\n", "self", ".", "candidates", "=", "[", "]", "\n", "self", ".", "scores", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.beam.Beam.step": [[13, 32], ["prob.new_tensor", "score.view().topk", "itertools.zip_longest", "prob.new_tensor.unsqueeze().expand_as", "prob.size", "nbest_score.tolist", "beam_ix.tolist", "token_ix.tolist", "f_done", "score.view", "prob.size", "done_list.append", "remain_list.append", "beam.Beam.candidates.append", "beam.Beam.scores.append", "prob.new_tensor.unsqueeze"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "prob", ",", "prev_beam", ",", "f_done", ")", ":", "\n", "        ", "pre_score", "=", "prob", ".", "new_tensor", "(", "prev_beam", ".", "scores", ")", "\n", "score", "=", "prob", "+", "pre_score", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "prob", ")", "\n", "nbest_score", ",", "nbest_ix", "=", "score", ".", "view", "(", "-", "1", ")", ".", "topk", "(", "self", ".", "beam_size", ",", "largest", "=", "False", ")", "\n", "beam_ix", "=", "nbest_ix", "/", "prob", ".", "size", "(", "1", ")", "\n", "token_ix", "=", "nbest_ix", "-", "beam_ix", "*", "prob", ".", "size", "(", "1", ")", "\n", "\n", "done_list", ",", "remain_list", "=", "[", "]", ",", "[", "]", "\n", "prev_candidates", "=", "prev_beam", ".", "candidates", "\n", "for", "b_score", ",", "b_ix", ",", "t_ix", "in", "itertools", ".", "zip_longest", "(", "nbest_score", ".", "tolist", "(", ")", ",", "beam_ix", ".", "tolist", "(", ")", ",", "token_ix", ".", "tolist", "(", ")", ")", ":", "\n", "            ", "candidate", "=", "prev_candidates", "[", "b_ix", "]", "+", "[", "t_ix", "]", "\n", "\n", "if", "f_done", "(", "candidate", ")", ":", "\n", "                ", "done_list", ".", "append", "(", "[", "candidate", ",", "b_score", "]", ")", "\n", "", "else", ":", "\n", "                ", "remain_list", ".", "append", "(", "b_ix", ")", "\n", "self", ".", "candidates", ".", "append", "(", "candidate", ")", "\n", "self", ".", "scores", ".", "append", "(", "b_score", ")", "\n", "", "", "return", "done_list", ",", "remain_list", "", "", "", ""]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.search.greedy_search": [[5, 40], ["src.size", "model.encoding", "torch.LongTensor().fill_().to", "torch.ones_like().squeeze", "model.tgt_emb().squeeze", "src_mask.squeeze().transpose.squeeze().transpose", "torch.zeros", "torch.LongTensor().fill_().to", "range", "src.size", "model.decoder.step", "model.generator.forward", "model.generator.forward.max", "model.tgt_emb().squeeze", "torch.cat", "torch.zeros.all", "src.size", "src.size", "torch.LongTensor().fill_", "torch.ones_like", "model.tgt_emb", "src_mask.squeeze().transpose.squeeze", "torch.LongTensor().fill_", "model.tgt_emb", "max_index.unsqueeze", "torch.LongTensor", "torch.LongTensor", "max_index.unsqueeze"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.encoding", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.beam.Beam.step", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.forward"], ["def", "greedy_search", "(", "args", ",", "model", ",", "src", ",", "src_mask", ",", "bosid", ",", "eosid", ")", ":", "\n", "    ", "time_dim", "=", "1", "\n", "B", ",", "L", "=", "src", ".", "size", "(", ")", "\n", "\n", "max_len", "=", "src", ".", "size", "(", "time_dim", ")", "*", "args", ".", "length_ratio", "if", "args", ".", "length_ratio", "else", "src", ".", "size", "(", "time_dim", ")", "*", "2", "\n", "min_len", "=", "src", ".", "size", "(", "time_dim", ")", "/", "2", "\n", "\n", "annots", ",", "initial_state", ",", "mapped_keys", "=", "model", ".", "encoding", "(", "src", ")", "\n", "last_words", "=", "torch", ".", "LongTensor", "(", "B", ",", "1", ")", ".", "fill_", "(", "bosid", ")", ".", "to", "(", "src", ".", "device", ")", "\n", "mask", "=", "torch", ".", "ones_like", "(", "last_words", ")", ".", "squeeze", "(", "time_dim", ")", "\n", "last_words_emb", "=", "model", ".", "tgt_emb", "(", "last_words", ")", ".", "squeeze", "(", "time_dim", ")", "\n", "src_mask", "=", "src_mask", ".", "squeeze", "(", "time_dim", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "# print(mask.size(), last_words_emb.size(), src_mask.size())", "\n", "\n", "eos_yet", "=", "torch", ".", "zeros", "(", "B", ",", "device", "=", "src", ".", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "outs", "=", "torch", ".", "LongTensor", "(", "B", ",", "1", ")", ".", "fill_", "(", "eosid", ")", ".", "to", "(", "src", ".", "device", ")", "\n", "\n", "next_state", "=", "initial_state", "\n", "for", "k", "in", "range", "(", "max_len", ")", ":", "\n", "        ", "next_state", ",", "context", "=", "model", ".", "decoder", ".", "step", "(", "last_words_emb", ",", "mask", ",", "next_state", ",", "mapped_keys", ",", "annots", ",", "src_mask", ")", "\n", "log_probs", "=", "model", ".", "generator", ".", "forward", "(", "last_words_emb", ",", "next_state", ",", "context", ")", "\n", "if", "k", "<", "min_len", ":", "\n", "            ", "log_probs", "[", ":", ",", "eosid", "]", "=", "-", "np", ".", "inf", "\n", "", "max_value", ",", "max_index", "=", "log_probs", ".", "max", "(", "-", "1", ")", "\n", "last_words_emb", "=", "model", ".", "tgt_emb", "(", "max_index", ".", "unsqueeze", "(", "time_dim", ")", ")", ".", "squeeze", "(", "time_dim", ")", "\n", "\n", "outs", "=", "torch", ".", "cat", "(", "[", "outs", ",", "max_index", ".", "unsqueeze", "(", "1", ")", "]", ",", "-", "1", ")", "\n", "\n", "eos_yet", "=", "eos_yet", "|", "(", "max_index", "==", "eosid", ")", "\n", "if", "eos_yet", ".", "all", "(", ")", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "outs", "[", ":", ",", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.search.beam_search": [[43, 107], ["model.encoding", "search.beam.Beam", "key_mask.index_select.transpose", "range", "enumerate", "hidden.index_select.new_tensor", "torch.sort", "sort_ix.tolist", "src.new_tensor", "src.size", "src.size", "src.new_tensor", "model.tgt_emb", "model.tgt_emb.new_ones", "model.decoder.step", "model.generator", "search.beam.Beam", "search.beam.Beam.step", "hyp_list.extend", "len", "src.new_tensor", "values.index_select.index_select", "keys.index_select.index_select", "key_mask.index_select.index_select", "hidden.index_select.index_select", "zip", "src.new_tensor.append", "list", "log_prob[].clone", "len", "map", "float", "float", "score[].item", "hyp[].index", "len"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.encoding", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.beam.Beam.step", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.beam.Beam.step"], ["", "def", "beam_search", "(", "args", ",", "model", ",", "src", ",", "key_mask", ",", "bos_id", ",", "eos_id", ")", ":", "\n", "    ", "time_dim", "=", "1", "\n", "\n", "max_len", "=", "src", ".", "size", "(", "time_dim", ")", "*", "3", "\n", "min_len", "=", "src", ".", "size", "(", "time_dim", ")", "/", "2", "\n", "\n", "values", ",", "hidden", ",", "keys", "=", "model", ".", "encoding", "(", "src", ")", "\n", "\n", "prev_beam", "=", "Beam", "(", "args", ".", "beam_size", ")", "\n", "prev_beam", ".", "candidates", "=", "[", "[", "bos_id", "]", "]", "\n", "prev_beam", ".", "scores", "=", "[", "0", "]", "\n", "f_done", "=", "(", "lambda", "x", ":", "x", "[", "-", "1", "]", "==", "eos_id", ")", "\n", "\n", "valid_size", "=", "args", ".", "beam_size", "\n", "\n", "hyp_list", "=", "[", "]", "\n", "key_mask", "=", "key_mask", ".", "transpose", "(", "1", ",", "0", ")", "\n", "for", "k", "in", "range", "(", "max_len", ")", ":", "\n", "        ", "candidates", "=", "prev_beam", ".", "candidates", "\n", "input", "=", "src", ".", "new_tensor", "(", "list", "(", "map", "(", "lambda", "cand", ":", "cand", "[", "-", "1", "]", ",", "candidates", ")", ")", ")", "\n", "input", "=", "model", ".", "tgt_emb", "(", "input", ")", "\n", "mask", "=", "input", ".", "new_ones", "(", "input", ".", "shape", "[", "0", "]", ")", "\n", "hidden", ",", "context", "=", "model", ".", "decoder", ".", "step", "(", "input", ",", "mask", ",", "hidden", ",", "keys", ",", "values", ",", "key_mask", ")", "\n", "\n", "log_prob", "=", "model", ".", "generator", "(", "input", ",", "hidden", ",", "context", ")", "\n", "\n", "if", "k", "<", "min_len", ":", "\n", "            ", "log_prob", "[", ":", ",", "eos_id", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "", "if", "k", "==", "max_len", "-", "1", ":", "\n", "            ", "eos_prob", "=", "log_prob", "[", ":", ",", "eos_id", "]", ".", "clone", "(", ")", "\n", "log_prob", "[", ":", ",", ":", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "log_prob", "[", ":", ",", "eos_id", "]", "=", "eos_prob", "\n", "", "next_beam", "=", "Beam", "(", "valid_size", ")", "\n", "done_list", ",", "remain_list", "=", "next_beam", ".", "step", "(", "-", "log_prob", ",", "prev_beam", ",", "f_done", ")", "\n", "hyp_list", ".", "extend", "(", "done_list", ")", "\n", "valid_size", "-=", "len", "(", "done_list", ")", "\n", "\n", "if", "valid_size", "==", "0", ":", "\n", "            ", "break", "\n", "\n", "", "beam_remain_ix", "=", "src", ".", "new_tensor", "(", "remain_list", ")", "\n", "values", "=", "values", ".", "index_select", "(", "1", ",", "beam_remain_ix", ")", "# select batch dim", "\n", "keys", "=", "keys", ".", "index_select", "(", "1", ",", "beam_remain_ix", ")", "\n", "key_mask", "=", "key_mask", ".", "index_select", "(", "1", ",", "beam_remain_ix", ")", "\n", "hidden", "=", "hidden", ".", "index_select", "(", "0", ",", "beam_remain_ix", ")", "# hidden is 2-dim tensor", "\n", "prev_beam", "=", "next_beam", "\n", "\n", "", "score_list", "=", "[", "hyp", "[", "1", "]", "for", "hyp", "in", "hyp_list", "]", "\n", "hyp_list", "=", "[", "hyp", "[", "0", "]", "[", "1", ":", "hyp", "[", "0", "]", ".", "index", "(", "eos_id", ")", "]", "if", "eos_id", "in", "hyp", "[", "0", "]", "else", "hyp", "[", "0", "]", "[", "1", ":", "]", "for", "hyp", "in", "hyp_list", "]", "\n", "\n", "for", "k", ",", "(", "hyp", ",", "score", ")", "in", "enumerate", "(", "zip", "(", "hyp_list", ",", "score_list", ")", ")", ":", "\n", "        ", "if", "len", "(", "hyp", ")", ">", "0", ":", "\n", "            ", "lp", "=", "(", "5", "+", "len", "(", "hyp", ")", ")", "/", "(", "5", "+", "1", ")", "\n", "lp", "=", "lp", "**", "args", ".", "alpha", "# length norm", "\n", "score_list", "[", "k", "]", "=", "score_list", "[", "k", "]", "/", "lp", "\n", "\n", "", "", "score", "=", "hidden", ".", "new_tensor", "(", "score_list", ")", "\n", "sort_score", ",", "sort_ix", "=", "torch", ".", "sort", "(", "score", ")", "\n", "output", "=", "[", "]", "\n", "for", "ix", "in", "sort_ix", ".", "tolist", "(", ")", ":", "\n", "        ", "output", ".", "append", "(", "(", "hyp_list", "[", "ix", "]", ",", "score", "[", "ix", "]", ".", "item", "(", ")", ")", ")", "\n", "# add batch dim", "\n", "", "output", "=", "src", ".", "new_tensor", "(", "[", "output", "[", "0", "]", "[", "0", "]", "]", ")", "\n", "return", "output", "", "", ""]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.end_of_chunk": [[19, 32], ["None"], "function", ["None"], ["", "def", "end_of_chunk", "(", "prev_tag", ",", "tag", ",", "prev_type", ",", "type_", ")", ":", "\n", "# check if a chunk ended between the previous and current word", "\n", "# arguments: previous and current chunk tags, previous and current types", "\n", "    ", "chunk_end", "=", "False", "\n", "if", "prev_tag", "==", "'e'", "or", "prev_tag", "==", "'s'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'b'", "and", "tag", "==", "'b'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'b'", "and", "tag", "==", "'s'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'b'", "and", "tag", "==", "'O'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'m'", "and", "tag", "==", "'b'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'m'", "and", "tag", "==", "'s'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "==", "'m'", "and", "tag", "==", "'O'", ":", "chunk_end", "=", "True", "\n", "if", "prev_tag", "!=", "'O'", "and", "prev_type", "!=", "type_", ":", "chunk_end", "=", "True", "\n", "return", "chunk_end", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.start_of_chunk": [[34, 47], ["None"], "function", ["None"], ["", "def", "start_of_chunk", "(", "prev_tag", ",", "tag", ",", "prev_type", ",", "type_", ")", ":", "\n", "# check if a chunk started between the previous and current word", "\n", "# arguments: previous and current chunk tags, previous and current types", "\n", "    ", "chunk_start", "=", "False", "\n", "if", "tag", "==", "'b'", "or", "tag", "==", "'s'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'e'", "and", "tag", "==", "'e'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'e'", "and", "tag", "==", "'m'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'s'", "and", "tag", "==", "'e'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'s'", "and", "tag", "==", "'m'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'O'", "and", "tag", "==", "'e'", ":", "chunk_start", "=", "True", "\n", "if", "prev_tag", "==", "'O'", "and", "tag", "==", "'m'", ":", "chunk_start", "=", "True", "\n", "if", "tag", "!=", "'O'", "and", "prev_type", "!=", "type_", ":", "chunk_start", "=", "True", "\n", "return", "chunk_start", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.parse_tag": [[48, 55], ["len", "paireval.FormatError"], "function", ["None"], ["", "def", "parse_tag", "(", "t", ")", ":", "\n", "    ", "if", "t", "==", "'O'", ":", "\n", "        ", "return", "(", "'O'", ",", "'O'", ")", "\n", "", "if", "len", "(", "t", ")", "==", "2", ":", "\n", "        ", "return", "t", "[", "0", "]", ",", "t", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "raise", "FormatError", "(", "'unexpected tags when pasing: '", ",", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.detect_chunks": [[57, 94], ["collections.defaultdict", "range", "len", "paireval.parse_tag", "paireval.parse_tag", "paireval.end_of_chunk", "paireval.end_of_chunk", "paireval.start_of_chunk", "paireval.start_of_chunk"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.parse_tag", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.parse_tag", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.end_of_chunk", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.end_of_chunk", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.start_of_chunk", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.start_of_chunk"], ["", "", "def", "detect_chunks", "(", "labels_predicted", ",", "labels_true", ")", ":", "\n", "# calculate correct chunks of labels_predicted", "\n", "    ", "t_correct_chunk", "=", "defaultdict", "(", "int", ")", "\n", "in_correct", "=", "False", "# currently processed chunks is correct until now", "\n", "last_correct", "=", "'O'", "# previous chunk tag in corpus", "\n", "last_correct_type", "=", "''", "# type of previously identified chunk tag", "\n", "last_guessed", "=", "'O'", "# previously identified chunk tag", "\n", "last_guessed_type", "=", "''", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "labels_predicted", ")", ")", ":", "\n", "        ", "label_predicted", "=", "labels_predicted", "[", "i", "]", "\n", "label_true", "=", "labels_true", "[", "i", "]", "\n", "\n", "guessed_type", ",", "guessed", "=", "parse_tag", "(", "label_predicted", ")", "\n", "correct_type", ",", "correct", "=", "parse_tag", "(", "label_true", ")", "\n", "end_correct", "=", "end_of_chunk", "(", "last_correct", ",", "correct", ",", "last_correct_type", ",", "correct_type", ")", "\n", "end_guessed", "=", "end_of_chunk", "(", "last_guessed", ",", "guessed", ",", "last_guessed_type", ",", "guessed_type", ")", "\n", "start_correct", "=", "start_of_chunk", "(", "last_correct", ",", "correct", ",", "last_correct_type", ",", "correct_type", ")", "\n", "start_guessed", "=", "start_of_chunk", "(", "last_guessed", ",", "guessed", ",", "last_guessed_type", ",", "guessed_type", ")", "\n", "\n", "if", "in_correct", ":", "\n", "            ", "if", "(", "end_correct", "and", "end_guessed", "and", "last_guessed_type", "==", "last_correct_type", ")", ":", "\n", "                ", "in_correct", "=", "False", "\n", "t_correct_chunk", "[", "last_correct_type", "]", "+=", "1", "\n", "", "elif", "(", "end_correct", "!=", "end_guessed", "or", "guessed_type", "!=", "correct_type", ")", ":", "\n", "                ", "in_correct", "=", "False", "\n", "\n", "", "", "if", "start_correct", "and", "start_guessed", "and", "guessed_type", "==", "correct_type", ":", "\n", "            ", "in_correct", "=", "True", "\n", "\n", "", "last_guessed", "=", "guessed", "\n", "last_correct", "=", "correct", "\n", "last_guessed_type", "=", "guessed_type", "\n", "last_correct_type", "=", "correct_type", "\n", "", "if", "in_correct", ":", "\n", "        ", "t_correct_chunk", "[", "last_correct_type", "]", "+=", "1", "\n", "", "return", "(", "t_correct_chunk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.count_t_and_v": [[96, 108], ["paireval.parse_tag", "paireval.start_of_chunk"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.parse_tag", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.start_of_chunk"], ["", "def", "count_t_and_v", "(", "labels", ")", ":", "\n", "    ", "num_t", ",", "num_v", "=", "0", ",", "0", "\n", "last_label", "=", "'O'", "# previously identified chunk tag", "\n", "last_label_type", "=", "''", "\n", "for", "i", "in", "labels", ":", "\n", "        ", "label_type", ",", "label", "=", "parse_tag", "(", "i", ")", "\n", "if", "start_of_chunk", "(", "last_label", ",", "label", ",", "last_label_type", ",", "label_type", ")", ":", "\n", "            ", "if", "label_type", "==", "'v'", ":", "num_v", "+=", "1", "\n", "if", "label_type", "==", "'t'", ":", "num_t", "+=", "1", "\n", "", "last_label", "=", "label", "\n", "last_label_type", "=", "label_type", "\n", "", "return", "num_t", ",", "num_v", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.evaluate": [[109, 139], ["range", "len", "len", "paireval.count_t_and_v", "paireval.count_t_and_v", "max", "max", "paireval.detect_chunks"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.count_t_and_v", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.count_t_and_v", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.detect_chunks"], ["", "def", "evaluate", "(", "sents", ")", ":", "\n", "    ", "token_counter", "=", "0", "\n", "true_pair", ",", "pred_pair", ",", "pair_hit", "=", "0", ",", "0", ",", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "sents", ")", ")", ":", "\n", "        ", "token_counter", "+=", "len", "(", "sents", "[", "i", "]", "[", "0", "]", ")", "\n", "_", ",", "labels_true", ",", "labels_pred", "=", "sents", "[", "i", "]", "\n", "num_t", ",", "num_v", "=", "count_t_and_v", "(", "labels_true", ")", "\n", "num_t_pred", ",", "num_v_pred", "=", "count_t_and_v", "(", "labels_pred", ")", "\n", "true_pair", "+=", "max", "(", "num_t", ",", "num_v", ")", "\n", "pred_pair", "+=", "max", "(", "num_t_pred", ",", "num_v_pred", ")", "\n", "correct_chunk", "=", "detect_chunks", "(", "labels_pred", ",", "labels_true", ")", "\n", "if", "num_t", "==", "1", "and", "num_v", "==", "1", ":", "\n", "            ", "if", "correct_chunk", "[", "'t'", "]", "==", "1", "and", "correct_chunk", "[", "'v'", "]", "==", "1", ":", "\n", "                ", "pair_hit", "+=", "1", "\n", "", "", "elif", "num_t", ">", "1", "and", "num_v", ">", "1", ":", "\n", "            ", "pair_hit", "+=", "correct_chunk", "[", "'t'", "]", "if", "correct_chunk", "[", "'t'", "]", "<", "correct_chunk", "[", "'v'", "]", "else", "correct_chunk", "[", "'v'", "]", "\n", "", "elif", "num_t", ">", "1", "and", "num_v", "==", "1", ":", "\n", "            ", "pair_hit", "+=", "correct_chunk", "[", "'t'", "]", "if", "correct_chunk", "[", "'v'", "]", "==", "1", "else", "0", "\n", "", "elif", "num_t", "==", "1", "and", "num_v", ">", "1", ":", "\n", "            ", "pair_hit", "+=", "correct_chunk", "[", "'v'", "]", "if", "correct_chunk", "[", "'t'", "]", "==", "1", "else", "0", "\n", "", "elif", "num_t", "==", "0", "and", "num_v", "==", "0", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "assert", "(", "False", ")", "\n", "\n", "", "", "recall", "=", "0.0", "if", "true_pair", "==", "0", "else", "(", "1.0", "*", "pair_hit", "/", "true_pair", ")", "\n", "precision", "=", "0.0", "if", "pred_pair", "==", "0", "else", "(", "1.0", "*", "pair_hit", "/", "pred_pair", ")", "\n", "f_1", "=", "0.0", "if", "(", "precision", "+", "recall", ")", "==", "0.0", "else", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "return", "token_counter", ",", "precision", ",", "recall", ",", "f_1", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Self_Neural_Attention.__init__": [[56, 60], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__init__"], ["def", "__init__", "(", "self", ",", "dim_value", ",", "dim_atten", ")", ":", "\n", "        ", "super", "(", "Self_Neural_Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "map_values", "=", "nn", ".", "Linear", "(", "dim_value", ",", "dim_atten", ",", "bias", "=", "False", ")", "\n", "self", ".", "pre_alpha", "=", "nn", ".", "Linear", "(", "dim_atten", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Self_Neural_Attention.__call__": [[61, 72], ["dl4nmt.Self_Neural_Attention.map_values", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "dl4nmt.Self_Neural_Attention.pre_alpha().squeeze", "dl4nmt.Self_Neural_Attention.masked_fill_", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "dl4nmt.Self_Neural_Attention.pre_alpha", "float", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.nn.functional.softmax.unsqueeze"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "values", ",", "mask", ")", ":", "\n", "# B, T, H", "\n", "        ", "time_dim", "=", "1", "\n", "mapped_values", "=", "self", ".", "map_values", "(", "values", ")", "# B, T, H", "\n", "\n", "act", "=", "torch", ".", "tanh", "(", "mapped_values", ")", "\n", "e", "=", "self", ".", "pre_alpha", "(", "act", ")", ".", "squeeze", "(", "-", "1", ")", "# B, T", "\n", "e", ".", "masked_fill_", "(", "mask", "==", "0", ",", "-", "float", "(", "'inf'", ")", ")", "# B, T", "\n", "alpha", "=", "F", ".", "softmax", "(", "e", ",", "dim", "=", "time_dim", ")", "# T, B", "\n", "output", "=", "torch", ".", "bmm", "(", "alpha", ".", "unsqueeze", "(", "1", ")", ",", "values", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "output", ",", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.LSTMEncoder.__init__": [[76, 81], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__init__"], ["def", "__init__", "(", "self", ",", "sedim", ",", "shdim", ")", ":", "\n", "        ", "super", "(", "LSTMEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sedim", "=", "sedim", "\n", "self", ".", "shdim", "=", "shdim", "\n", "self", ".", "bi_cell", "=", "nn", ".", "LSTM", "(", "sedim", ",", "shdim", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.LSTMEncoder.forward": [[82, 87], ["dl4nmt.LSTMEncoder.bi_cell"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "states", ",", "_", "=", "self", ".", "bi_cell", "(", "x", ")", "\n", "\n", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor.__init__": [[89, 112], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__init__"], ["    ", "def", "__init__", "(", "self", ",", "shdim", ",", "thdim", ",", "tgt_vocab_size", ",", "tgt_field", ")", ":", "\n", "        ", "super", "(", "Extractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# padid", "\n", "self", ".", "tgt_field", "=", "tgt_field", "\n", "self", ".", "tag_to_ix", "=", "tgt_field", ".", "vocab", ".", "stoi", "\n", "# tags", "\n", "self", ".", "START_TAG", "=", "tgt_field", ".", "init_token", "\n", "self", ".", "STOP_TAG", "=", "tgt_field", ".", "eos_token", "\n", "\n", "# active layer", "\n", "activation", "=", "nn", ".", "Linear", "(", "shdim", ",", "thdim", ")", "\n", "\n", "# proj", "\n", "hidden2tag", "=", "nn", ".", "Linear", "(", "thdim", ",", "tgt_vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "# Matrix of transition parameters.", "\n", "self", ".", "transitions", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "tgt_vocab_size", ",", "tgt_vocab_size", ")", ")", "\n", "\n", "self", ".", "tgt_vocab_size", "=", "tgt_vocab_size", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "hidden2tag", "=", "hidden2tag", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor.constrain_transition": [[113, 136], ["None"], "methods", ["None"], ["", "def", "constrain_transition", "(", "self", ")", ":", "\n", "        ", "TS", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'ts'", "]", "\n", "VS", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'vs'", "]", "\n", "VB", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'vb'", "]", "\n", "VE", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'ve'", "]", "\n", "TB", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'tb'", "]", "\n", "TE", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'te'", "]", "\n", "VM", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'vm'", "]", "\n", "TM", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'tm'", "]", "\n", "O", "=", "self", ".", "tgt_field", ".", "vocab", ".", "stoi", "[", "'O'", "]", "\n", "# These two statements enforce the constraint that we never transfer", "\n", "# to the start tag and we never transfer from the stop tag", "\n", "self", ".", "transitions", ".", "data", "[", "self", ".", "tag_to_ix", "[", "self", ".", "START_TAG", "]", ",", ":", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", ":", ",", "self", ".", "tag_to_ix", "[", "self", ".", "STOP_TAG", "]", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "TB", ",", "TS", ",", "VM", ",", "VS", ",", "VB", ",", "VE", "]", ",", "TB", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "TB", ",", "TS", ",", "VB", ",", "VM", ",", "VE", ",", "VS", "]", ",", "TM", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "TE", ",", "TB", ",", "TM", ",", "TS", "]", ",", "TE", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "TS", ",", "TB", ",", "TM", ",", "TE", ",", "VM", ",", "VE", "]", ",", "TS", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "TS", ",", "TB", ",", "TM", ",", "TE", ",", "VS", "]", ",", "VB", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "TB", ",", "TM", ",", "TE", ",", "TS", ",", "VB", ",", "VS", "]", ",", "VM", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "VE", ",", "VB", ",", "VM", ",", "VS", "]", ",", "VE", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "TM", ",", "TE", ",", "VS", ",", "VB", ",", "VM", ",", "VE", "]", ",", "VS", "]", "=", "-", "1000", "\n", "self", ".", "transitions", ".", "data", "[", "[", "TM", ",", "TE", ",", "VM", ",", "VE", "]", ",", "O", "]", "=", "-", "1000", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor._forward_alg": [[137, 169], ["feats.size", "feats.new_zeros().fill_", "enumerate", "dl4nmt.log_sum_exp", "masks[].view().expand().bool", "range", "terminal_var.view", "feats.new_zeros", "feat[].view().expand", "dl4nmt.Extractor.transitions[].view", "alphas_t.append", "forward_var.masked_fill", "torch.cat().transpose().view().masked_fill", "torch.cat().transpose().view().masked_fill", "torch.cat().transpose().view().masked_fill", "torch.cat().transpose().view().masked_fill", "range", "masks[].view().expand", "dl4nmt.log_sum_exp", "feat[].view", "torch.cat().transpose().view", "torch.cat().transpose().view", "torch.cat().transpose().view", "torch.cat().transpose().view", "masks[].view", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.log_sum_exp", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.log_sum_exp"], ["", "def", "_forward_alg", "(", "self", ",", "feats", ",", "masks", ")", ":", "\n", "        ", "'''\n        :param feats: L, B\n        :return:\n        '''", "\n", "L", ",", "B", ",", "tagset_size", "=", "feats", ".", "size", "(", ")", "\n", "# Do the forward algorithm to compute the partition function", "\n", "init_alphas", "=", "feats", ".", "new_zeros", "(", "(", "1", ",", "B", ",", "tagset_size", ")", ")", ".", "fill_", "(", "-", "10000.", ")", "\n", "\n", "# START_TAG has all of the score.", "\n", "init_alphas", "[", "0", ",", "range", "(", "B", ")", ",", "self", ".", "tag_to_ix", "[", "self", ".", "START_TAG", "]", "]", "=", "0.", "\n", "\n", "# Wrap in a variable so that we will get automatic backprop", "\n", "forward_var", "=", "init_alphas", "\n", "\n", "# Iterate through the sentence", "\n", "for", "idx", ",", "feat", "in", "enumerate", "(", "feats", ")", ":", "\n", "            ", "mask", "=", "masks", "[", "idx", "]", ".", "view", "(", "B", ",", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "tagset_size", ")", ".", "bool", "(", ")", "\n", "alphas_t", "=", "[", "]", "# The forward tensors at this timestep", "\n", "for", "next_tag", "in", "range", "(", "tagset_size", ")", ":", "\n", "                ", "emit_score", "=", "feat", "[", "range", "(", "B", ")", ",", "next_tag", "]", ".", "view", "(", "B", ",", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "tagset_size", ")", "\n", "trans_score", "=", "self", ".", "transitions", "[", "next_tag", "]", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "next_tag_var", "=", "forward_var", "+", "trans_score", "+", "emit_score", "\n", "alphas_t", ".", "append", "(", "log_sum_exp", "(", "next_tag_var", ")", ")", "\n", "\n", "", "forward_var", "=", "forward_var", ".", "masked_fill", "(", "mask", ",", "0.", ")", "+", "torch", ".", "cat", "(", "alphas_t", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "view", "(", "1", ",", "B", ",", "-", "1", ")", ".", "masked_fill", "(", "~", "mask", ",", "0.", ")", "\n", "\n", "", "terminal_var", "=", "forward_var", "+", "self", ".", "transitions", "[", "self", ".", "tag_to_ix", "[", "self", ".", "STOP_TAG", "]", "]", "\n", "alpha", "=", "log_sum_exp", "(", "terminal_var", ".", "view", "(", "1", ",", "B", ",", "-", "1", ")", ")", "\n", "\n", "return", "alpha", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor._score_sentence": [[170, 190], ["feats.size", "feats.new_zeros", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "masks[].bool", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().cuda.view", "torch.tensor().cuda.view", "range", "range", "masks.sum", "range", "range", "range", "range"], "methods", ["None"], ["", "def", "_score_sentence", "(", "self", ",", "feats", ",", "tags", ",", "masks", ")", ":", "\n", "        ", "'''\n        :param feats: L, B, tag_size\n        :param tags: L, B\n        :return:\n        '''", "\n", "L", ",", "B", ",", "tagset_size", "=", "feats", ".", "size", "(", ")", "\n", "# Gives the score of a provided tag sequence", "\n", "score", "=", "feats", ".", "new_zeros", "(", "B", ")", "\n", "start_tensor", "=", "torch", ".", "tensor", "(", "[", "self", ".", "tag_to_ix", "[", "self", ".", "START_TAG", "]", "for", "i", "in", "range", "(", "B", ")", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", "\n", "tags", "=", "torch", ".", "cat", "(", "[", "start_tensor", ".", "view", "(", "B", ",", "1", ")", ",", "tags", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "for", "i", ",", "feat", "in", "enumerate", "(", "feats", ")", ":", "\n", "            ", "mask", "=", "masks", "[", "i", "]", ".", "bool", "(", ")", "\n", "score", "=", "score", "+", "(", "self", ".", "transitions", "[", "tags", "[", "range", "(", "B", ")", ",", "i", "+", "1", "]", ",", "tags", "[", "range", "(", "B", ")", ",", "i", "]", "]", "+", "feat", "[", "range", "(", "B", ")", ",", "tags", "[", "range", "(", "B", ")", ",", "i", "+", "1", "]", "]", ")", ".", "masked_fill", "(", "~", "mask", ",", "0", ")", "\n", "\n", "", "score", "=", "score", "+", "self", ".", "transitions", "[", "self", ".", "tag_to_ix", "[", "self", ".", "STOP_TAG", "]", ",", "tags", "[", "range", "(", "B", ")", ",", "masks", ".", "sum", "(", "0", ")", "]", "]", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor._viterbi_decode": [[191, 235], ["feats.size", "feats.new_zeros().fill_", "argmax().item", "reversed", "best_path.pop", "best_path.reverse", "range", "backpointers.append", "best_path.append", "feats.new_zeros", "argmax().item", "bptrs_t.append", "viterbivars_t.append", "dl4nmt.argmax", "[].view", "dl4nmt.argmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.data.NormalField.reverse", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.argmax", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.argmax"], ["", "def", "_viterbi_decode", "(", "self", ",", "feats", ")", ":", "\n", "        ", "backpointers", "=", "[", "]", "\n", "L", ",", "tagset_size", "=", "feats", ".", "size", "(", ")", "\n", "# Initialize the viterbi variables in log space", "\n", "init_vvars", "=", "feats", ".", "new_zeros", "(", "(", "1", ",", "tagset_size", ")", ")", ".", "fill_", "(", "-", "10000.", ")", "\n", "# init_vvars = torch.full((1, tagset_size), -10000.)", "\n", "init_vvars", "[", "0", "]", "[", "self", ".", "tag_to_ix", "[", "self", ".", "START_TAG", "]", "]", "=", "0", "\n", "\n", "# forward_var at step i holds the viterbi variables for step i-1", "\n", "forward_var", "=", "init_vvars", "\n", "for", "feat", "in", "feats", ":", "\n", "            ", "bptrs_t", "=", "[", "]", "# holds the backpointers for this step", "\n", "viterbivars_t", "=", "[", "]", "# holds the viterbi variables for this step", "\n", "\n", "for", "next_tag", "in", "range", "(", "tagset_size", ")", ":", "\n", "# next_tag_var[i] holds the viterbi variable for tag i at the", "\n", "# previous step, plus the score of transitioning", "\n", "# from tag i to next_tag.", "\n", "# We don't include the emission scores here because the max", "\n", "# does not depend on them (we add them in below)", "\n", "                ", "next_tag_var", "=", "forward_var", "+", "self", ".", "transitions", "[", "next_tag", "]", "\n", "best_tag_id", "=", "argmax", "(", "next_tag_var", ")", ".", "item", "(", ")", "\n", "bptrs_t", ".", "append", "(", "best_tag_id", ")", "\n", "viterbivars_t", ".", "append", "(", "next_tag_var", "[", "0", "]", "[", "best_tag_id", "]", ".", "view", "(", "1", ")", ")", "\n", "# Now add in the emission scores, and assign forward_var to the set", "\n", "# of viterbi variables we just computed", "\n", "", "forward_var", "=", "(", "torch", ".", "cat", "(", "viterbivars_t", ")", "+", "feat", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "backpointers", ".", "append", "(", "bptrs_t", ")", "\n", "\n", "# Transition to STOP_TAG", "\n", "", "terminal_var", "=", "forward_var", "+", "self", ".", "transitions", "[", "self", ".", "tag_to_ix", "[", "self", ".", "STOP_TAG", "]", "]", "\n", "best_tag_id", "=", "argmax", "(", "terminal_var", ")", ".", "item", "(", ")", "\n", "path_score", "=", "terminal_var", "[", "0", "]", "[", "best_tag_id", "]", "\n", "\n", "# Follow the back pointers to decode the best path.", "\n", "best_path", "=", "[", "best_tag_id", "]", "\n", "for", "bptrs_t", "in", "reversed", "(", "backpointers", ")", ":", "\n", "            ", "best_tag_id", "=", "bptrs_t", "[", "best_tag_id", "]", "\n", "best_path", ".", "append", "(", "best_tag_id", ")", "\n", "# Pop off the start tag (we dont want to return that to the caller)", "\n", "", "start", "=", "best_path", ".", "pop", "(", ")", "\n", "assert", "start", "==", "self", ".", "tag_to_ix", "[", "self", ".", "START_TAG", "]", "# Sanity check", "\n", "best_path", ".", "reverse", "(", ")", "\n", "return", "path_score", ",", "best_path", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor.forward": [[247, 256], ["mask.transpose.transpose.size", "mask.transpose.transpose.transpose", "efeats.transpose.transpose.transpose", "dl4nmt.Extractor._forward_alg", "dl4nmt.Extractor._score_sentence"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor._forward_alg", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor._score_sentence"], ["", "def", "forward", "(", "self", ",", "efeats", ",", "mask", ",", "tgt", ")", ":", "\n", "        ", "B", ",", "L", "=", "mask", ".", "size", "(", ")", "\n", "mask", "=", "mask", ".", "transpose", "(", "1", ",", "0", ")", "# L, B", "\n", "efeats", "=", "efeats", ".", "transpose", "(", "1", ",", "0", ")", "# transfer to (L,B,tag_size) from (B,L, tag_size)", "\n", "\n", "forward_score", "=", "self", ".", "_forward_alg", "(", "efeats", ",", "mask", ")", "\n", "gold_score", "=", "self", ".", "_score_sentence", "(", "efeats", ",", "tgt", ",", "mask", ")", "\n", "loss", "=", "(", "forward_score", "-", "gold_score", ")", ".", "sum", "(", ")", "/", "B", "\n", "return", "loss", "\n", "", "def", "get_feature", "(", "self", ",", "src_annots", ")", ":", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor.get_feature": [[256, 260], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "dl4nmt.Extractor.hidden2tag", "dl4nmt.Extractor.activation"], "methods", ["None"], ["", "def", "get_feature", "(", "self", ",", "src_annots", ")", ":", "\n", "        ", "feature", "=", "torch", ".", "tanh", "(", "self", ".", "activation", "(", "src_annots", ")", ")", "\n", "feats", "=", "self", ".", "hidden2tag", "(", "feature", ")", "\n", "return", "feats", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor.decoding": [[281, 300], ["masks.size", "range", "dl4nmt.Extractor._viterbi_decode", "scores.append", "tag_seqs.append", "score.item", "masks.sum"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor._viterbi_decode"], ["", "def", "decoding", "(", "self", ",", "feats", ",", "masks", ")", ":", "\n", "        ", "\"\"\"\n        :param src_annots:  [batch, length, shdim]\n        :param masks: [batch, length]\n        :return:\n        \"\"\"", "\n", "B", ",", "L", "=", "masks", ".", "size", "(", ")", "\n", "# # encoding the source", "\n", "# feature = torch.tanh(self.activation(src_annots))", "\n", "# feats = self.hidden2tag(feature)", "\n", "\n", "scores", "=", "[", "]", "\n", "tag_seqs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "B", ")", ":", "\n", "            ", "feat", "=", "feats", "[", "i", ",", ":", "masks", ".", "sum", "(", "1", ")", "[", "i", "]", "]", "\n", "score", ",", "tag_seq", "=", "self", ".", "_viterbi_decode", "(", "feat", ")", "\n", "scores", ".", "append", "(", "score", ".", "item", "(", ")", ")", "\n", "tag_seqs", ".", "append", "(", "tag_seq", ")", "\n", "", "return", "scores", ",", "tag_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.__init__": [[302, 318], ["torch.Module.__init__", "dl4nmt.Self_Neural_Attention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.NLLLoss", "torch.NLLLoss"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__init__"], ["    ", "def", "__init__", "(", "self", ",", "shdim", ",", "thdim", ",", "ahdim", ",", "tag_vocab_size", ")", ":", "\n", "        ", "super", "(", "Classify", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Self-attention", "\n", "attention", "=", "Self_Neural_Attention", "(", "shdim", ",", "thdim", ")", "\n", "\n", "# active layer", "\n", "activation", "=", "nn", ".", "Linear", "(", "shdim", ",", "ahdim", ")", "\n", "\n", "# proj", "\n", "proj", "=", "nn", ".", "Linear", "(", "ahdim", ",", "tag_vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "attention", "=", "attention", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "proj", "=", "proj", "\n", "self", ".", "nll_loss", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.loss": [[319, 324], ["dl4nmt.Classify.nll_loss", "probs.contiguous().view", "truth.contiguous().view", "probs.size", "probs.contiguous", "truth.contiguous"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "probs", ",", "truth", ")", ":", "\n", "        ", "loss", "=", "self", ".", "nll_loss", "(", "probs", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "probs", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "truth", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.pred_tag": [[325, 331], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "dl4nmt.Classify.proj", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "dl4nmt.Classify.activation"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.argmax", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.argmax", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.argmax", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.argmax"], ["", "def", "pred_tag", "(", "self", ",", "context", ")", ":", "\n", "# context, _ = self.attention(src_annots, src_mask)", "\n", "        ", "feature", "=", "torch", ".", "tanh", "(", "self", ".", "activation", "(", "context", ")", ")", "\n", "probs", "=", "self", ".", "proj", "(", "feature", ")", "\n", "idx", "=", "torch", ".", "argmax", "(", "probs", ",", "dim", "=", "-", "1", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.get_feature": [[332, 337], ["dl4nmt.Classify.attention"], "methods", ["None"], ["", "def", "get_feature", "(", "self", ",", "src_annots", ",", "src_mask", ")", ":", "\n", "# attention", "\n", "        ", "context", ",", "alpha", "=", "self", ".", "attention", "(", "src_annots", ",", "src_mask", ")", "# [batch, shdim]", "\n", "# _, alpha = self.attention(src_annots, src_mask)  # [batch, shdim]", "\n", "return", "context", ",", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.forward": [[338, 348], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "dl4nmt.Classify.proj", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "dl4nmt.Classify.loss", "dl4nmt.Classify.activation"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.loss"], ["", "def", "forward", "(", "self", ",", "context", ",", "tag", ")", ":", "\n", "        ", "feature", "=", "torch", ".", "tanh", "(", "self", ".", "activation", "(", "context", ")", ")", "\n", "\n", "feats", "=", "self", ".", "proj", "(", "feature", ")", "# [batch, thdim]", "\n", "\n", "log_probs", "=", "F", ".", "log_softmax", "(", "feats", ",", "dim", "=", "-", "1", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "log_probs", ",", "tag", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.__init__": [[350, 398], ["torch.Module.__init__", "pytorch_transformers.BertModel.from_pretrained", "torch.Dropout", "torch.Dropout", "dl4nmt.LSTMEncoder", "dl4nmt.Classify", "dl4nmt.Extractor", "dl4nmt.Extractor.constrain_transition"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__init__", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor.constrain_transition"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "tgt_field", ")", ":", "\n", "        ", "super", "(", "Classify_Extractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "sedim", "=", "args", ".", "embdim", "[", "0", "]", "\n", "\n", "# hidden layer dim", "\n", "shdim", ",", "cthdim", ",", "cahdim", ",", "ethdim", "=", "args", ".", "hidden", "\n", "\n", "# vocab size", "\n", "# src_vocab_size = args.src_vocab", "\n", "tgt_vocab_size", "=", "args", ".", "tgt_vocab", "\n", "# tag_vocab_size = args.tag_vocab", "\n", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-chinese'", ",", "output_hidden_states", "=", "True", ",", "output_attentions", "=", "False", ")", "\n", "# self.bert.cuda()", "\n", "# bert_dim = 768", "\n", "\n", "# self.bert2enc = nn.Linear(bert_dim, sedim)", "\n", "# self.bert.eval()", "\n", "sedim", "=", "768", "\n", "\n", "# padid", "\n", "# self.srcpadid = srcpadid", "\n", "self", ".", "tgt_field", "=", "tgt_field", "\n", "self", ".", "tag_to_ix", "=", "tgt_field", ".", "vocab", ".", "stoi", "\n", "# tags", "\n", "self", ".", "START_TAG", "=", "tgt_field", ".", "init_token", "\n", "self", ".", "STOP_TAG", "=", "tgt_field", ".", "eos_token", "\n", "\n", "# dropout", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "args", ".", "drop_ratio", ")", "\n", "self", ".", "tgt_vocab_size", "=", "tgt_vocab_size", "\n", "\n", "# Bi-directional LSTM encoder", "\n", "encoder", "=", "LSTMEncoder", "(", "sedim", ",", "shdim", ")", "\n", "\n", "# Classifier", "\n", "classifier", "=", "Classify", "(", "shdim", "*", "2", "+", "tgt_vocab_size", ",", "cthdim", ",", "cahdim", ",", "2", ")", "\n", "\n", "# Extractor", "\n", "extractor", "=", "Extractor", "(", "shdim", "*", "2", "+", "1", ",", "ethdim", ",", "tgt_vocab_size", ",", "tgt_field", ")", "\n", "extractor", ".", "constrain_transition", "(", ")", "\n", "\n", "# self.src_emb = src_emb", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "classifier", "=", "classifier", "\n", "self", ".", "extractor", "=", "extractor", "\n", "self", ".", "k", "=", "args", ".", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.bert_emb": [[399, 409], ["dl4nmt.Classify_Extractor.bert"], "methods", ["None"], ["", "def", "bert_emb", "(", "self", ",", "src", ",", "mask", ")", ":", "\n", "# with torch.no_grad():", "\n", "        ", "if", "True", ":", "\n", "            ", "output", "=", "self", ".", "bert", "(", "src", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "mask", ")", "[", "2", "]", "\n", "#     encoded_layers, _ = self.bert(src, token_type_ids=None, attention_mask=mask)", "\n", "# use [CLS] for sentence embedding", "\n", "#h = encoded_layers[-1][:, 0]", "\n", "# B T H", "\n", "last_h", "=", "output", "[", "-", "1", "]", "\n", "", "return", "last_h", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.bert_encoding": [[410, 429], ["dl4nmt.Classify_Extractor.bert_emb", "dl4nmt.Classify_Extractor.drop", "src_mask.sum", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "dl4nmt.Classify_Extractor.encoder", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "dl4nmt.Classify_Extractor.drop"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.bert_emb"], ["", "def", "bert_encoding", "(", "self", ",", "src", ",", "src_mask", ")", ":", "\n", "# batch_first = True", "\n", "        ", "bert_embed", "=", "self", ".", "bert_emb", "(", "src", ",", "src_mask", ")", "\n", "bert_embed", "=", "self", ".", "drop", "(", "bert_embed", ")", "\n", "\n", "length", "=", "src_mask", ".", "sum", "(", "-", "1", ")", "\n", "\n", "sorted_len", ",", "ix", "=", "torch", ".", "sort", "(", "length", ",", "descending", "=", "True", ")", "\n", "sorted_bert_embed", "=", "bert_embed", "[", "ix", "]", "\n", "\n", "packed_sorted_bert_embed", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "sorted_bert_embed", ",", "sorted_len", ",", "True", ")", "\n", "packed_annotations", "=", "self", ".", "encoder", "(", "packed_sorted_bert_embed", ")", "\n", "annotations", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "packed_annotations", ",", "True", ")", "\n", "\n", "_", ",", "recovered_ix", "=", "torch", ".", "sort", "(", "ix", ",", "descending", "=", "False", ")", "\n", "annotations", "=", "annotations", "[", "recovered_ix", "]", "\n", "\n", "annotations", "=", "self", ".", "drop", "(", "annotations", ")", "\n", "return", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.encoding": [[430, 466], ["torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "dl4nmt.Classify_Extractor.src_emb", "dl4nmt.Classify_Extractor.drop", "torch.nn.utils.rnn.PackedSequence", "torch.nn.utils.rnn.PackedSequence", "dl4nmt.Classify_Extractor.encoder", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "dl4nmt.Classify_Extractor.drop"], "methods", ["None"], ["", "def", "encoding", "(", "self", ",", "src", ")", ":", "\n", "        ", "\"\"\"\n        :param src: (B, T)\n        :return: annotations (B, T, 2*shdim);\n        \"\"\"", "\n", "batch_first", "=", "True", "\n", "\n", "seq_lens", "=", "(", "src", "!=", "self", ".", "srcpadid", ")", ".", "sum", "(", "1", ")", "# B, 1", "\n", "\n", "sorted_seq_lens", ",", "indices", "=", "torch", ".", "sort", "(", "seq_lens", ",", "descending", "=", "True", ")", "\n", "_", ",", "desorted_indices", "=", "torch", ".", "sort", "(", "indices", ",", "descending", "=", "False", ")", "\n", "\n", "if", "batch_first", ":", "\n", "            ", "src", "=", "src", "[", "indices", "]", "\n", "", "else", ":", "\n", "            ", "src", "=", "src", "[", ":", ",", "indices", "]", "\n", "\n", "", "packed_inputs", "=", "pack", "(", "src", ",", "sorted_seq_lens", ",", "batch_first", "=", "batch_first", ")", "\n", "\n", "idx", "=", "packed_inputs", ".", "data", "\n", "src_embedding", "=", "self", ".", "src_emb", "(", "idx", ")", "\n", "src_embedding", "=", "self", ".", "drop", "(", "src_embedding", ")", "\n", "\n", "src_embedding", "=", "PackedSequence", "(", "src_embedding", ",", "packed_inputs", ".", "batch_sizes", ")", "\n", "\n", "annotations", "=", "self", ".", "encoder", "(", "src_embedding", ")", "\n", "unpacked_inputs", ",", "_", "=", "unpack", "(", "annotations", ",", "batch_first", "=", "batch_first", ")", "\n", "\n", "if", "batch_first", ":", "\n", "            ", "annotations", "=", "unpacked_inputs", "[", "desorted_indices", "]", "\n", "", "else", ":", "\n", "            ", "annotations", "=", "unpacked_inputs", "[", ":", ",", "desorted_indices", "]", "\n", "\n", "", "annotations", "=", "self", ".", "drop", "(", "annotations", ")", "\n", "\n", "return", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.simile_classify": [[467, 486], ["dl4nmt.Classify_Extractor.bert_encoding", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "dl4nmt.Classify_Extractor.classifier.pred_tag", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dl4nmt.Classify_Extractor.classifier.get_feature", "alpha.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dl4nmt.Classify_Extractor.extractor.get_feature", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.bert_encoding", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.pred_tag", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.get_feature", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.get_feature"], ["", "def", "simile_classify", "(", "self", ",", "src", ",", "src_mask", ")", ":", "\n", "        ", "annotations", "=", "self", ".", "bert_encoding", "(", "src", ",", "src_mask", ")", "\n", "K", "=", "self", ".", "k", "\n", "efeats", "=", "torch", ".", "zeros", "(", "[", "annotations", ".", "shape", "[", "0", "]", ",", "annotations", ".", "shape", "[", "1", "]", ",", "self", ".", "tgt_vocab_size", "]", ")", ".", "cuda", "(", ")", "\n", "# cfeats = torch.zeros([annotations.shape[0],annotations.shape[1],self.tgt_vocab_size])", "\n", "kcontext", "=", "None", "\n", "for", "i", "in", "range", "(", "K", ")", ":", "\n", "            ", "cla_annot", "=", "torch", ".", "cat", "(", "[", "annotations", ",", "efeats", "]", ",", "dim", "=", "-", "1", ")", "\n", "context", ",", "alpha", "=", "self", ".", "classifier", ".", "get_feature", "(", "cla_annot", ",", "src_mask", ")", "\n", "cfeats", "=", "alpha", ".", "unsqueeze", "(", "-", "1", ")", "\n", "ext_annot", "=", "torch", ".", "cat", "(", "[", "annotations", ",", "cfeats", "]", ",", "dim", "=", "-", "1", ")", "\n", "efeats", "=", "self", ".", "extractor", ".", "get_feature", "(", "ext_annot", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "kcontext", "=", "context", "\n", "", "else", ":", "\n", "                ", "kcontext", "+=", "context", "\n", "", "", "tags", "=", "self", ".", "classifier", ".", "pred_tag", "(", "kcontext", ")", "\n", "\n", "return", "tags", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.component_extraction": [[487, 506], ["dl4nmt.Classify_Extractor.bert_encoding", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "dl4nmt.Classify_Extractor.extractor.decoding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dl4nmt.Classify_Extractor.classifier.get_feature", "alpha.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dl4nmt.Classify_Extractor.extractor.get_feature", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.bert_encoding", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Extractor.decoding", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.get_feature", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.get_feature"], ["", "def", "component_extraction", "(", "self", ",", "src", ",", "src_mask", ")", ":", "\n", "        ", "annotations", "=", "self", ".", "bert_encoding", "(", "src", ",", "src_mask", ")", "\n", "efeats", "=", "torch", ".", "zeros", "(", "[", "annotations", ".", "shape", "[", "0", "]", ",", "annotations", ".", "shape", "[", "1", "]", ",", "self", ".", "tgt_vocab_size", "]", ")", ".", "cuda", "(", ")", "\n", "# cfeats = torch.zeros([annotations.shape[0],annotations.shape[1],self.tgt_vocab_size])", "\n", "kefeats", "=", "None", "\n", "K", "=", "self", ".", "k", "\n", "for", "i", "in", "range", "(", "K", ")", ":", "\n", "            ", "cla_annot", "=", "torch", ".", "cat", "(", "[", "annotations", ",", "efeats", "]", ",", "dim", "=", "-", "1", ")", "\n", "context", ",", "alpha", "=", "self", ".", "classifier", ".", "get_feature", "(", "cla_annot", ",", "src_mask", ")", "\n", "cfeats", "=", "alpha", ".", "unsqueeze", "(", "-", "1", ")", "\n", "ext_annot", "=", "torch", ".", "cat", "(", "[", "annotations", ",", "cfeats", "]", ",", "dim", "=", "-", "1", ")", "\n", "efeats", "=", "self", ".", "extractor", ".", "get_feature", "(", "ext_annot", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "kefeats", "=", "efeats", "\n", "", "else", ":", "\n", "                ", "kefeats", "+=", "efeats", "\n", "", "", "scores", ",", "tag_seqs", "=", "self", ".", "extractor", ".", "decoding", "(", "kefeats", ",", "src_mask", ")", "\n", "\n", "return", "scores", ",", "tag_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.forward": [[507, 542], ["dl4nmt.Classify_Extractor.bert_encoding", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "dl4nmt.Classify_Extractor.classifier", "dl4nmt.Classify_Extractor.extractor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dl4nmt.Classify_Extractor.classifier.get_feature", "alpha.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dl4nmt.Classify_Extractor.extractor.get_feature", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.bert_encoding", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.get_feature", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify.get_feature"], ["", "def", "forward", "(", "self", ",", "src", ",", "src_mask", ",", "tgt", ",", "tag", ")", ":", "\n", "        ", "\"\"\"\n        :param src: [batch, length]\n        :param src_mask: [batch, length]\n        :param tgt: [batch, length]\n        :param tag: [batch,tag]\n        :return:\n        \"\"\"", "\n", "# encoding the source", "\n", "annotations", "=", "self", ".", "bert_encoding", "(", "src", ",", "src_mask", ")", "\n", "K", "=", "self", ".", "k", "\n", "efeats", "=", "torch", ".", "zeros", "(", "[", "annotations", ".", "shape", "[", "0", "]", ",", "annotations", ".", "shape", "[", "1", "]", ",", "self", ".", "tgt_vocab_size", "]", ")", ".", "cuda", "(", ")", "\n", "# cfeats = torch.zeros([annotations.shape[0],annotations.shape[1],self.tgt_vocab_size])", "\n", "kcontext", "=", "None", "\n", "kefeats", "=", "None", "\n", "for", "i", "in", "range", "(", "K", ")", ":", "\n", "            ", "cla_annot", "=", "torch", ".", "cat", "(", "[", "annotations", ",", "efeats", "]", ",", "dim", "=", "-", "1", ")", "\n", "context", ",", "alpha", "=", "self", ".", "classifier", ".", "get_feature", "(", "cla_annot", ",", "src_mask", ")", "\n", "cfeats", "=", "alpha", ".", "unsqueeze", "(", "-", "1", ")", "\n", "ext_annot", "=", "torch", ".", "cat", "(", "[", "annotations", ",", "cfeats", "]", ",", "dim", "=", "-", "1", ")", "\n", "efeats", "=", "self", ".", "extractor", ".", "get_feature", "(", "ext_annot", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "kcontext", "=", "context", "\n", "kefeats", "=", "efeats", "\n", "", "else", ":", "\n", "                ", "kcontext", "+=", "context", "\n", "kefeats", "+=", "efeats", "\n", "\n", "", "", "cla_loss", "=", "self", ".", "classifier", "(", "kcontext", ",", "tag", ")", "\n", "\n", "ext_loss", "=", "self", ".", "extractor", "(", "kefeats", ",", "src_mask", ",", "tgt", ")", "\n", "\n", "loss", "=", "0.2", "*", "cla_loss", "+", "0.8", "*", "ext_loss", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.print_params": [[23, 26], ["print", "print", "sum", "sum", "numpy.prod", "numpy.prod", "list", "model.parameters", "list", "model.encoder.parameters", "p.size", "p.size"], "function", ["None"], ["def", "print_params", "(", "model", ")", ":", "\n", "    ", "print", "(", "'total_params'", ",", "sum", "(", "[", "np", ".", "prod", "(", "list", "(", "p", ".", "size", "(", ")", ")", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", ")", "\n", "print", "(", "'enc parameters:'", ",", "sum", "(", "[", "np", ".", "prod", "(", "list", "(", "p", ".", "size", "(", ")", ")", ")", "for", "p", "in", "model", ".", "encoder", ".", "parameters", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.prepare_src": [[27, 32], ["data.dim"], "function", ["None"], ["", "def", "prepare_src", "(", "data", ",", "padid", ")", ":", "\n", "    ", "assert", "data", ".", "dim", "(", ")", "==", "2", "\n", "mask", "=", "(", "data", "!=", "padid", ")", "\n", "\n", "return", "data", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.prepare_tgt": [[33, 37], ["data.dim"], "function", ["None"], ["", "def", "prepare_tgt", "(", "data", ")", ":", "\n", "    ", "assert", "data", ".", "dim", "(", ")", "==", "2", "\n", "data", "=", "data", "[", ":", ",", "1", ":", "-", "1", "]", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.argmax": [[38, 42], ["torch.max", "torch.max"], "function", ["None"], ["", "def", "argmax", "(", "vec", ")", ":", "\n", "# return the argmax as a python int", "\n", "    ", "_", ",", "idx", "=", "torch", ".", "max", "(", "vec", ",", "dim", "=", "-", "1", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.log_sum_exp": [[44, 52], ["vec.size", "max_score.view().expand", "torch.log", "torch.log", "max_score.view", "torch.sum", "torch.sum", "range", "dl4nmt.argmax", "torch.exp", "torch.exp"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.argmax"], ["", "def", "log_sum_exp", "(", "vec", ")", ":", "\n", "    ", "_", ",", "B", ",", "tgt_size", "=", "vec", ".", "size", "(", ")", "\n", "max_score", "=", "vec", "[", "0", ",", "range", "(", "B", ")", ",", "argmax", "(", "vec", ")", "]", "\n", "\n", "max_score_broadcast", "=", "max_score", ".", "view", "(", "B", ",", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "tgt_size", ")", "\n", "\n", "return", "max_score", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "vec", "-", "max_score_broadcast", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.train": [[543, 839], ["pytorch_transformers.BertTokenizer.from_pretrained", "dl4nmt.Classify_Extractor", "torch.cuda.is_available", "torch.cuda.is_available", "dl4nmt.print_params", "print", "time.time", "range", "print", "print", "dl4nmt.Classify_Extractor", "Classify_Extractor.cuda", "print", "torch.load", "torch.load", "print", "Classify_Extractor.load_state_dict", "dl4nmt.Classify_Extractor", "Classify_Extractor.cuda", "print", "torch.load", "torch.load", "print", "Classify_Extractor.load_state_dict", "Classify_Extractor.cuda", "pytorch_transformers.AdamW", "pytorch_transformers.WarmupLinearSchedule", "torch.optim.Adadelta", "torch.optim.Adadelta", "print", "Classify_Extractor.load_state_dict", "train_iter.init_epoch", "enumerate", "print", "print", "torch.no_grad", "torch.no_grad", "test.init_epoch", "Classify_Extractor.eval", "Classify_Extractor.eval", "enumerate", "model.paireval.evaluate", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "print", "print", "Classify_Extractor.parameters", "torch.optim.Adadelta.load_state_dict", "print", "print", "print", "Classify_Extractor.train", "time.time", "max", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().byte().cuda", "torch.tensor().byte().cuda", "dl4nmt.prepare_tgt", "Classify_Extractor.", "loss.item.backward", "time.time", "loss.item.item", "print", "print", "print", "time.strftime", "time.time", "time.time", "max", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().byte().cuda", "torch.tensor().byte().cuda", "dl4nmt.prepare_tgt", "test_batch.tag.squeeze", "dl4nmt.Classify_Extractor.component_extraction", "dl4nmt.Classify_Extractor.simile_classify", "cy_true.extend", "cy_pred.extend", "zip", "print", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "padded_sents.append", "torch.tensor().byte().cuda.append", "torch.optim.Adadelta.step", "pytorch_transformers.WarmupLinearSchedule.step", "torch.optim.Adadelta.zero_grad", "torch.no_grad", "torch.no_grad", "dev.init_epoch", "Classify_Extractor.eval", "enumerate", "model.paireval.evaluate", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "print", "print", "time.localtime", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "padded_sents.append", "torch.tensor().byte().cuda.append", "dev_batch.tag.squeeze.tolist", "model.simile_classify.tolist", "sen[].tolist", "tags[].tolist", "len", "torch.tensor().long", "torch.tensor().long", "torch.tensor().byte", "torch.tensor().byte", "time.time", "max", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().byte().cuda", "torch.tensor().byte().cuda", "dl4nmt.prepare_tgt", "dev_batch.tag.squeeze", "dl4nmt.Classify_Extractor.component_extraction", "dl4nmt.Classify_Extractor.simile_classify", "cy_true.extend", "cy_pred.extend", "zip", "print", "print", "torch.save", "torch.save", "print", "torch.save", "torch.save", "len", "torch.tensor().long", "torch.tensor().long", "torch.tensor().byte", "torch.tensor().byte", "sents.append", "Classify_Extractor.named_parameters", "Classify_Extractor.named_parameters", "any", "len", "torch.tensor().long().cuda.size", "prepare_tgt.size", "BertTokenizer.from_pretrained.convert_tokens_to_ids", "padded_sents.append", "torch.tensor().byte().cuda.append", "dev_batch.tag.squeeze.tolist", "model.simile_classify.tolist", "sen[].tolist", "tags[].tolist", "Classify_Extractor.state_dict", "torch.optim.Adadelta.state_dict", "Classify_Extractor.state_dict", "torch.optim.Adadelta.state_dict", "len", "sents.append", "time.time", "any", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.tensor().long", "torch.tensor().long", "torch.tensor().byte", "torch.tensor().byte", "sents.append", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "time.time", "len", "len", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.print_params", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.load_state_dict", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.load_state_dict", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.load_state_dict", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.init_epoch", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.init_epoch", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.evaluate", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.load_state_dict", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.train", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.prepare_tgt", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.prepare_tgt", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.component_extraction", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.simile_classify", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.beam.Beam.step", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.search.beam.Beam.step", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.init_epoch", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.paireval.evaluate", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.prepare_tgt", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.component_extraction", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.model.dl4nmt.Classify_Extractor.simile_classify", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.state_dict", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.state_dict", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.state_dict", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.state_dict"], ["", "", "def", "train", "(", "args", ",", "train_iter", ",", "dev", ",", "test", ",", "src_field", ",", "tgt_field", ",", "tag_field", ",", "checkpoint", ")", ":", "\n", "# srcpadid = src_field.vocab.stoi['<pad>']", "\n", "    ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-chinese'", ")", "\n", "\n", "model", "=", "Classify_Extractor", "(", "args", ",", "tgt_field", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print_params", "(", "model", ")", "\n", "\n", "decay", "=", "args", ".", "decay", "\n", "\n", "if", "args", ".", "optimizer", "==", "'bert'", ":", "\n", "        ", "weight_decay", "=", "0.0", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "opt", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "lr", ",", "eps", "=", "1e-8", ")", "\n", "totalnum", "=", "0", "\n", "for", "i", "in", "train_iter", ":", "\n", "            ", "totalnum", "+=", "1", "\n", "#print(args.lr)", "\n", "#print(args.maximum_steps)", "\n", "#exit()", "\n", "", "t_total", "=", "totalnum", "//", "decay", "*", "args", ".", "maximum_steps", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "opt", ",", "warmup_steps", "=", "0", ",", "t_total", "=", "t_total", ")", "\n", "", "else", ":", "\n", "        ", "opt", "=", "torch", ".", "optim", ".", "Adadelta", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "\n", "", "best_e", "=", "0.0", "\n", "best_c", "=", "0.0", "\n", "best_epoch_for_c", "=", "0", "\n", "best_epoch_for_e", "=", "0", "\n", "offset", "=", "0.0", "\n", "pre_epoch", "=", "0", "\n", "patience_c", "=", "0", "\n", "patience_e", "=", "0", "\n", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "print", "(", "'model.load_state_dict(checkpoint[model])'", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "if", "args", ".", "resume", ":", "\n", "            ", "opt", ".", "load_state_dict", "(", "checkpoint", "[", "'optim'", "]", ")", "\n", "\n", "best_f", "=", "checkpoint", "[", "'f'", "]", "\n", "offset", "=", "checkpoint", "[", "'iters'", "]", "\n", "pre_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "\n", "print", "(", "'*************************************'", ")", "\n", "print", "(", "'resume from {} epoch {} iters and best_f {}'", ".", "format", "(", "pre_epoch", ",", "offset", ",", "best_f", ")", ")", "\n", "print", "(", "'*************************************'", ")", "\n", "\n", "", "", "print", "(", "\"**************start training****************\"", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "maxepoch", ")", ":", "\n", "        ", "train_iter", ".", "init_epoch", "(", ")", "\n", "epoch", "+=", "pre_epoch", "\n", "\n", "for", "iters", ",", "train_batch", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "            ", "iters", "+=", "offset", "\n", "model", ".", "train", "(", ")", "\n", "# model.zero_grad()", "\n", "# model.constrain_transition()", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "batch_src", "=", "train_batch", ".", "src", "\n", "#print(batch_src)", "\n", "#exit()", "\n", "src", "=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "s", ")", "for", "s", "in", "batch_src", "]", "\n", "maxlen", "=", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "batch_src", "]", ")", "\n", "\n", "src_mask", "=", "[", "]", "\n", "padded_sents", "=", "[", "]", "\n", "for", "s", "in", "src", ":", "\n", "                ", "new_s", "=", "s", "+", "[", "0", "]", "*", "(", "maxlen", "-", "len", "(", "s", ")", ")", "\n", "padded_sents", ".", "append", "(", "new_s", ")", "\n", "mask", "=", "[", "1", "]", "*", "len", "(", "s", ")", "+", "[", "0", "]", "*", "(", "maxlen", "-", "len", "(", "s", ")", ")", "\n", "src_mask", ".", "append", "(", "mask", ")", "\n", "# B T", "\n", "", "src", "=", "torch", ".", "tensor", "(", "padded_sents", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "# B T", "\n", "src_mask", "=", "torch", ".", "tensor", "(", "src_mask", ")", ".", "byte", "(", ")", ".", "cuda", "(", ")", "\n", "# src, src_mask = prepare_src(train_batch.src, srcpadid)", "\n", "tgt", "=", "prepare_tgt", "(", "train_batch", ".", "tgt", ")", "\n", "tag", "=", "train_batch", ".", "tag", "\n", "\n", "loss", "=", "model", "(", "src", ",", "src_mask", ",", "tgt", ",", "tag", ")", "\n", "\n", "# \"update parameters\"", "\n", "\n", "\n", "if", "decay", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "decay", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "# if args.grad_clip:", "\n", "#     torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)", "\n", "\n", "if", "(", "iters", "+", "1", ")", "%", "decay", "==", "0", ":", "\n", "                ", "opt", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "\n", "# opt.step()", "\n", "\n", "", "t2", "=", "time", ".", "time", "(", ")", "\n", "\n", "loss", "=", "loss", ".", "item", "(", ")", "\n", "\n", "print", "(", "\"epoch:{} iters:{} src:({},{}) tgt:({},{}) \"", "\n", "\"loss:{:.2f} t:{:.2f}\"", ".", "format", "(", "epoch", "+", "1", ",", "iters", "+", "1", ",", "*", "src", ".", "size", "(", ")", ",", "\n", "*", "tgt", ".", "size", "(", ")", ",", "loss", ",", "t2", "-", "t1", ")", ")", "\n", "\n", "# if torch.cuda.is_available():", "\n", "#     torch.cuda.empty_cache()", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "1", "==", "0", ":", "\n", "            ", "print", "(", "\"=============validate model==============\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "dev", ".", "init_epoch", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "# model.constrain_transition()", "\n", "sents", "=", "[", "]", "\n", "cy_true", "=", "[", "]", "\n", "cy_pred", "=", "[", "]", "\n", "for", "j", ",", "dev_batch", "in", "enumerate", "(", "dev", ")", ":", "\n", "                    ", "t1", "=", "time", ".", "time", "(", ")", "\n", "# src, src_mask = prepare_src(dev_batch.src, srcpadid)", "\n", "batch_src", "=", "dev_batch", ".", "src", "\n", "src", "=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "s", ")", "for", "s", "in", "batch_src", "]", "\n", "maxlen", "=", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "batch_src", "]", ")", "\n", "\n", "src_mask", "=", "[", "]", "\n", "padded_sents", "=", "[", "]", "\n", "for", "s", "in", "src", ":", "\n", "                        ", "new_s", "=", "s", "+", "[", "0", "]", "*", "(", "maxlen", "-", "len", "(", "s", ")", ")", "\n", "padded_sents", ".", "append", "(", "new_s", ")", "\n", "mask", "=", "[", "1", "]", "*", "len", "(", "s", ")", "+", "[", "0", "]", "*", "(", "maxlen", "-", "len", "(", "s", ")", ")", "\n", "src_mask", ".", "append", "(", "mask", ")", "\n", "# B T", "\n", "", "src", "=", "torch", ".", "tensor", "(", "padded_sents", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "# B T", "\n", "src_mask", "=", "torch", ".", "tensor", "(", "src_mask", ")", ".", "byte", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "tgt", "=", "prepare_tgt", "(", "dev_batch", ".", "tgt", ")", "\n", "tag", "=", "dev_batch", ".", "tag", ".", "squeeze", "(", "-", "1", ")", "\n", "_", ",", "pre_tag", "=", "model", ".", "component_extraction", "(", "src", ",", "src_mask", ")", "\n", "pre_ctag", "=", "model", ".", "simile_classify", "(", "src", ",", "src_mask", ")", "\n", "cy_true", ".", "extend", "(", "tag", ".", "tolist", "(", ")", ")", "\n", "cy_pred", ".", "extend", "(", "pre_ctag", ".", "tolist", "(", ")", ")", "\n", "\n", "for", "sen", ",", "tags", ",", "p_tags", ",", "c_tags", "in", "zip", "(", "src", ",", "tgt", ",", "pre_tag", ",", "tag", ")", ":", "\n", "                        ", "sen", "=", "sen", "[", ":", "len", "(", "p_tags", ")", "]", ".", "tolist", "(", ")", "\n", "tags", "=", "tags", "[", ":", "len", "(", "p_tags", ")", "]", ".", "tolist", "(", ")", "\n", "if", "c_tags", "==", "1", ":", "\n", "                            ", "sents", ".", "append", "(", "[", "sen", ",", "[", "tgt_field", ".", "vocab", ".", "itos", "[", "t", "]", "for", "t", "in", "tags", "]", ",", "\n", "[", "tgt_field", ".", "vocab", ".", "itos", "[", "t", "]", "for", "t", "in", "p_tags", "]", "]", ")", "\n", "", "", "print", "(", "'dev iters: {}, t:{}'", ".", "format", "(", "j", ",", "time", ".", "time", "(", ")", "-", "t1", ")", ")", "\n", "\n", "", "_", ",", "eprecision", ",", "erecall", ",", "ef1", "=", "evaluate", "(", "sents", ")", "\n", "\n", "cprecision", "=", "precision_score", "(", "cy_true", ",", "cy_pred", ")", "\n", "crecall", "=", "recall_score", "(", "cy_true", ",", "cy_pred", ")", "\n", "cf1", "=", "f1_score", "(", "cy_true", ",", "cy_pred", ")", "\n", "\n", "print", "(", "'epoch: {} classify--> precision: {} recall: {} f1: {} best:{}'", ".", "format", "(", "epoch", "+", "1", ",", "cprecision", ",", "\n", "crecall", ",", "cf1", ",", "best_c", ")", ")", "\n", "print", "(", "'extractor--> precision: {} recall: {} f1: {} best: {}'", ".", "format", "(", "eprecision", ",", "erecall", ",", "\n", "ef1", ",", "best_e", ")", ")", "\n", "\n", "if", "cf1", ">", "best_c", ":", "\n", "                    ", "best_c", "=", "cf1", "\n", "best_epoch_for_c", "=", "epoch", "+", "1", "\n", "\n", "print", "(", "'save best classifier model at epoch={}'", ".", "format", "(", "epoch", "+", "1", ")", ")", "\n", "checkpoint", "=", "{", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optim'", ":", "opt", ".", "state_dict", "(", ")", ",", "\n", "'args'", ":", "args", "}", "\n", "torch", ".", "save", "(", "checkpoint", ",", "'{}/{}.classify.best.pt'", ".", "format", "(", "args", ".", "model_path", ",", "args", ".", "model", ")", ")", "\n", "patience_c", "=", "0", "\n", "", "else", ":", "\n", "                    ", "patience_c", "+=", "1", "\n", "\n", "", "if", "ef1", ">", "best_e", ":", "\n", "                    ", "best_e", "=", "ef1", "\n", "best_epoch_for_e", "=", "epoch", "+", "1", "\n", "\n", "print", "(", "'save best extractor model at epoch={}'", ".", "format", "(", "epoch", "+", "1", ")", ")", "\n", "checkpoint", "=", "{", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optim'", ":", "opt", ".", "state_dict", "(", ")", ",", "\n", "'args'", ":", "args", "\n", "}", "\n", "torch", ".", "save", "(", "checkpoint", ",", "'{}/{}.extractor.best.pt'", ".", "format", "(", "args", ".", "model_path", ",", "args", ".", "model", ")", ")", "\n", "patience_e", "=", "0", "\n", "", "else", ":", "\n", "                    ", "patience_e", "+=", "1", "\n", "\n", "", "", "", "if", "patience_c", ">", "args", ".", "patience", "and", "patience_e", ">", "args", ".", "patience", ":", "\n", "            ", "print", "(", "\"early stop at {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "break", "\n", "\n", "", "if", "args", ".", "decay", ":", "\n", "            ", "opt", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "opt", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "*", "args", ".", "decay", "\n", "\n", "", "", "print", "(", "'*******Done********{}'", ".", "format", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "time", ".", "localtime", "(", ")", ")", ")", ")", "\n", "minutes", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "//", "60", "\n", "if", "minutes", "<", "60", ":", "\n", "        ", "print", "(", "'best_c:{}, best_e:{} best_epoch_c:{}, best_epoch_e:{}, time:{} mins'", ".", "format", "(", "best_c", ",", "best_e", ",", "\n", "best_epoch_for_c", ",", "best_epoch_for_e", ",", "\n", "minutes", ")", ")", "\n", "", "else", ":", "\n", "        ", "hours", "=", "minutes", "/", "60", "\n", "print", "(", "'best_c:{}, best_e:{} best_epoch_c:{}, best_epoch_e:{}, time:{:.1f} hours'", ".", "format", "(", "best_c", ",", "best_e", ",", "\n", "best_epoch_for_c", ",", "best_epoch_for_e", ",", "\n", "hours", ")", ")", "\n", "\n", "\n", "", "print", "(", "'*******Testing************'", ")", "\n", "model1", "=", "Classify_Extractor", "(", "args", ",", "tgt_field", ")", "\n", "model1", ".", "cuda", "(", ")", "\n", "load_from", "=", "'{}/{}.classify.best.pt'", ".", "format", "(", "args", ".", "model_path", ",", "args", ".", "model", ")", "\n", "print", "(", "'load the best model {}'", ".", "format", "(", "load_from", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "load_from", ",", "map_location", "=", "'cpu'", ")", "\n", "print", "(", "'load parameters'", ")", "\n", "model1", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "\n", "model2", "=", "Classify_Extractor", "(", "args", ",", "tgt_field", ")", "\n", "model2", ".", "cuda", "(", ")", "\n", "load_from", "=", "'{}/{}.extractor.best.pt'", ".", "format", "(", "args", ".", "model_path", ",", "args", ".", "model", ")", "\n", "print", "(", "'load the best model {}'", ".", "format", "(", "load_from", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "load_from", ",", "map_location", "=", "'cpu'", ")", "\n", "print", "(", "'load parameters'", ")", "\n", "model2", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "test", ".", "init_epoch", "(", ")", "\n", "model1", ".", "eval", "(", ")", "\n", "model2", ".", "eval", "(", ")", "\n", "sents", "=", "[", "]", "\n", "cy_true", "=", "[", "]", "\n", "cy_pred", "=", "[", "]", "\n", "for", "j", ",", "test_batch", "in", "enumerate", "(", "test", ")", ":", "\n", "            ", "t1", "=", "time", ".", "time", "(", ")", "\n", "# src, src_mask = prepare_src(test_batch.src, srcpadid)", "\n", "batch_src", "=", "test_batch", ".", "src", "\n", "src", "=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "s", ")", "for", "s", "in", "batch_src", "]", "\n", "maxlen", "=", "max", "(", "[", "len", "(", "s", ")", "for", "s", "in", "batch_src", "]", ")", "\n", "\n", "src_mask", "=", "[", "]", "\n", "padded_sents", "=", "[", "]", "\n", "for", "s", "in", "src", ":", "\n", "                ", "new_s", "=", "s", "+", "[", "0", "]", "*", "(", "maxlen", "-", "len", "(", "s", ")", ")", "\n", "padded_sents", ".", "append", "(", "new_s", ")", "\n", "mask", "=", "[", "1", "]", "*", "len", "(", "s", ")", "+", "[", "0", "]", "*", "(", "maxlen", "-", "len", "(", "s", ")", ")", "\n", "src_mask", ".", "append", "(", "mask", ")", "\n", "# B T", "\n", "", "src", "=", "torch", ".", "tensor", "(", "padded_sents", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "# B T", "\n", "src_mask", "=", "torch", ".", "tensor", "(", "src_mask", ")", ".", "byte", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "tgt", "=", "prepare_tgt", "(", "test_batch", ".", "tgt", ")", "\n", "tag", "=", "test_batch", ".", "tag", ".", "squeeze", "(", "-", "1", ")", "\n", "_", ",", "pre_tag", "=", "model2", ".", "component_extraction", "(", "src", ",", "src_mask", ")", "\n", "pre_ctag", "=", "model1", ".", "simile_classify", "(", "src", ",", "src_mask", ")", "\n", "cy_true", ".", "extend", "(", "tag", ".", "tolist", "(", ")", ")", "\n", "cy_pred", ".", "extend", "(", "pre_ctag", ".", "tolist", "(", ")", ")", "\n", "\n", "# for sen, tags, p_tags in zip(src, tgt, pre_tag):", "\n", "#     sen = sen[:len(p_tags)].tolist()", "\n", "#     tags = tags[:len(p_tags)].tolist()", "\n", "#     sents.append([sen, [tgt_field.vocab.itos[t] for t in tags],", "\n", "#                  [tgt_field.vocab.itos[t] for t in p_tags]])", "\n", "for", "sen", ",", "tags", ",", "p_tags", ",", "c_tags", "in", "zip", "(", "src", ",", "tgt", ",", "pre_tag", ",", "pre_ctag", ")", ":", "\n", "                ", "sen", "=", "sen", "[", ":", "len", "(", "p_tags", ")", "]", ".", "tolist", "(", ")", "\n", "tags", "=", "tags", "[", ":", "len", "(", "p_tags", ")", "]", ".", "tolist", "(", ")", "\n", "if", "c_tags", "==", "1", ":", "\n", "                    ", "sents", ".", "append", "(", "[", "sen", ",", "[", "tgt_field", ".", "vocab", ".", "itos", "[", "t", "]", "for", "t", "in", "tags", "]", ",", "\n", "[", "tgt_field", ".", "vocab", ".", "itos", "[", "t", "]", "for", "t", "in", "p_tags", "]", "]", ")", "\n", "", "elif", "c_tags", "==", "0", ":", "\n", "                    ", "sents", ".", "append", "(", "[", "sen", ",", "[", "tgt_field", ".", "vocab", ".", "itos", "[", "t", "]", "for", "t", "in", "tags", "]", ",", "\n", "[", "'O'", "for", "t", "in", "p_tags", "]", "]", ")", "\n", "\n", "", "", "print", "(", "'test iters: {}, t:{}'", ".", "format", "(", "j", ",", "time", ".", "time", "(", ")", "-", "t1", ")", ")", "\n", "\n", "", "_", ",", "eprecision", ",", "erecall", ",", "ef1", "=", "evaluate", "(", "sents", ")", "\n", "\n", "cprecision", "=", "precision_score", "(", "cy_true", ",", "cy_pred", ")", "\n", "crecall", "=", "recall_score", "(", "cy_true", ",", "cy_pred", ")", "\n", "cf1", "=", "f1_score", "(", "cy_true", ",", "cy_pred", ")", "\n", "\n", "print", "(", "'Testing classify--> precision: {} recall: {} f1: {}'", ".", "format", "(", "cprecision", ",", "crecall", ",", "cf1", ")", ")", "\n", "print", "(", "'extractor--> precision: {} recall: {} f1: {}'", ".", "format", "(", "eprecision", ",", "erecall", ",", "ef1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.ori_dataset.NormalField.reverse": [[19, 49], ["batch.tolist.tolist.t_", "torch.cuda.device_of", "batch.tolist.tolist.tolist", "ori_dataset.NormalField.reverse.trim"], "methods", ["None"], ["    ", "def", "reverse", "(", "self", ",", "batch", ",", "unbpe", "=", "True", ",", "returen_token", "=", "False", ")", ":", "\n", "        ", "if", "not", "self", ".", "batch_first", ":", "\n", "            ", "batch", ".", "t_", "(", ")", "\n", "\n", "", "with", "torch", ".", "cuda", ".", "device_of", "(", "batch", ")", ":", "\n", "            ", "batch", "=", "batch", ".", "tolist", "(", ")", "\n", "\n", "", "batch", "=", "[", "[", "self", ".", "vocab", ".", "itos", "[", "ind", "]", "for", "ind", "in", "ex", "]", "for", "ex", "in", "batch", "]", "# denumericalize", "\n", "\n", "def", "trim", "(", "s", ",", "t", ")", ":", "\n", "            ", "sentence", "=", "[", "]", "\n", "for", "w", "in", "s", ":", "\n", "                ", "if", "w", "==", "t", ":", "\n", "                    ", "break", "\n", "", "sentence", ".", "append", "(", "w", ")", "\n", "", "return", "sentence", "\n", "\n", "", "batch", "=", "[", "trim", "(", "ex", ",", "self", ".", "eos_token", ")", "for", "ex", "in", "batch", "]", "# trim past frst eos", "\n", "\n", "def", "filter_special", "(", "tok", ")", ":", "\n", "            ", "return", "tok", "not", "in", "(", "self", ".", "init_token", ",", "self", ".", "pad_token", ")", "\n", "\n", "", "if", "unbpe", ":", "\n", "            ", "batch", "=", "[", "\" \"", ".", "join", "(", "filter", "(", "filter_special", ",", "ex", ")", ")", ".", "replace", "(", "\"@@ \"", ",", "\"\"", ")", "for", "ex", "in", "batch", "]", "\n", "", "else", ":", "\n", "            ", "batch", "=", "[", "\" \"", ".", "join", "(", "filter", "(", "filter_special", ",", "ex", ")", ")", "for", "ex", "in", "batch", "]", "\n", "\n", "", "if", "returen_token", ":", "\n", "            ", "batch", "=", "[", "ex", ".", "split", "(", ")", "for", "ex", "in", "batch", "]", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.ori_dataset.TranslationDataset.sort_key": [[54, 57], ["torchtext.data.interleave_keys", "len", "len"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "sort_key", "(", "ex", ")", ":", "\n", "        ", "return", "data", ".", "interleave_keys", "(", "len", "(", "ex", ".", "src", ")", ",", "len", "(", "ex", ".", "trg", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.ori_dataset.TranslationDataset.__init__": [[58, 82], ["tuple", "torchtext.data.Dataset.__init__", "isinstance", "open", "open", "zip", "os.path.expanduser", "src_line.strip", "trg_line.strip", "examples.append", "torchtext.data.Example.fromlist"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__init__"], ["", "def", "__init__", "(", "self", ",", "path", ",", "exts", ",", "fields", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Create a TranslationDataset given paths and fields.\n        Arguments:\n            path: Common prefix of paths to the data files for both languages.\n            exts: A tuple containing the extension to path for each language.\n            fields: A tuple containing the fields that will be used for data\n                in each language.\n            Remaining keyword arguments: Passed to the constructor of\n                data.Dataset.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "fields", "[", "0", "]", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "fields", "=", "[", "(", "'src'", ",", "fields", "[", "0", "]", ")", ",", "(", "'trg'", ",", "fields", "[", "1", "]", ")", "]", "\n", "\n", "", "src_path", ",", "trg_path", "=", "tuple", "(", "os", ".", "path", ".", "expanduser", "(", "path", "+", "x", ")", "for", "x", "in", "exts", ")", "\n", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "src_path", ")", "as", "src_file", ",", "open", "(", "trg_path", ")", "as", "trg_file", ":", "\n", "            ", "for", "src_line", ",", "trg_line", "in", "zip", "(", "src_file", ",", "trg_file", ")", ":", "\n", "                ", "src_line", ",", "trg_line", "=", "src_line", ".", "strip", "(", ")", ",", "trg_line", ".", "strip", "(", ")", "\n", "if", "src_line", "!=", "''", "and", "trg_line", "!=", "''", ":", "\n", "                    ", "examples", ".", "append", "(", "data", ".", "Example", ".", "fromlist", "(", "\n", "[", "src_line", ",", "trg_line", "]", ",", "fields", ")", ")", "\n", "\n", "", "", "", "super", "(", "TranslationDataset", ",", "self", ")", ".", "__init__", "(", "examples", ",", "fields", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.ori_dataset.TranslationDataset.splits": [[83, 108], ["tuple", "cls", "cls", "cls", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "splits", "(", "cls", ",", "path", ",", "exts", ",", "fields", ",", "root", "=", "'.data'", ",", "\n", "train", "=", "'train'", ",", "validation", "=", "'val'", ",", "test", "=", "'test'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Create dataset objects for splits of a TranslationDataset.\n        Arguments:\n            root: Root dataset storage directory. Default is '.data'.\n            exts: A tuple containing the extension to path for each language.\n            fields: A tuple containing the fields that will be used for data\n                in each language.\n            train: The prefix of the train data. Default: 'train'.\n            validation: The prefix of the validation data. Default: 'val'.\n            test: The prefix of the test data. Default: 'test'.\n            Remaining keyword arguments: Passed to the splits method of\n                Dataset.\n        \"\"\"", "\n", "# path = cls.download(root)", "\n", "\n", "train_data", "=", "None", "if", "train", "is", "None", "else", "cls", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "train", ")", ",", "exts", ",", "fields", ",", "**", "kwargs", ")", "\n", "val_data", "=", "None", "if", "validation", "is", "None", "else", "cls", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "validation", ")", ",", "exts", ",", "fields", ",", "**", "kwargs", ")", "\n", "test_data", "=", "None", "if", "test", "is", "None", "else", "cls", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "test", ")", ",", "exts", ",", "fields", ",", "**", "kwargs", ")", "\n", "return", "tuple", "(", "d", "for", "d", "in", "(", "train_data", ",", "val_data", ",", "test_data", ")", "\n", "if", "d", "is", "not", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.ori_dataset.ParallelDataset.__init__": [[113, 141], ["torchtext.datasets.TranslationDataset.__init__", "len", "tuple", "len", "len", "isinstance", "range", "os.path.exists", "torch.load", "newfields.append", "os.path.expanduser", "contextlib.ExitStack", "enumerate", "torch.save", "len", "stack.enter_context", "zip", "open", "line.strip", "any", "torch.load.append", "torchtext.data.Example.fromlist"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__init__"], ["def", "__init__", "(", "self", ",", "path", "=", "None", ",", "exts", "=", "None", ",", "fields", "=", "None", ",", "\n", "load_dataset", "=", "False", ",", "save_dataset", "=", "False", ",", "prefix", "=", "''", ",", "examples", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "examples", "is", "None", ":", "\n", "            ", "assert", "len", "(", "exts", ")", "==", "len", "(", "fields", ")", ",", "'N parallel dataset must match'", "\n", "self", ".", "N", "=", "len", "(", "fields", ")", "\n", "\n", "if", "not", "isinstance", "(", "fields", "[", "0", "]", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "                ", "newfields", "=", "[", "(", "'src'", ",", "fields", "[", "0", "]", ")", ",", "(", "'trg'", ",", "fields", "[", "1", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "exts", ")", "-", "2", ")", ":", "\n", "                    ", "newfields", ".", "append", "(", "(", "'extra_{}'", ".", "format", "(", "i", ")", ",", "fields", "[", "2", "+", "i", "]", ")", ")", "\n", "", "self", ".", "fields", "=", "newfields", "\n", "\n", "", "paths", "=", "tuple", "(", "os", ".", "path", ".", "expanduser", "(", "path", "+", "'.'", "+", "x", ")", "for", "x", "in", "exts", ")", "\n", "if", "load_dataset", "and", "(", "os", ".", "path", ".", "exists", "(", "path", "+", "'.processed.{}.pt'", ".", "format", "(", "prefix", ")", ")", ")", ":", "\n", "                ", "examples", "=", "torch", ".", "load", "(", "path", "+", "'.processed.{}.pt'", ".", "format", "(", "prefix", ")", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "[", "]", "\n", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "                    ", "files", "=", "[", "stack", ".", "enter_context", "(", "open", "(", "fname", ",", "'r'", ",", "errors", "=", "'ignore'", ")", ")", "for", "fname", "in", "paths", "]", "\n", "for", "i", ",", "lines", "in", "enumerate", "(", "zip", "(", "*", "files", ")", ")", ":", "\n", "                        ", "lines", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "lines", "]", "\n", "if", "not", "any", "(", "line", "==", "''", "for", "line", "in", "lines", ")", ":", "\n", "                            ", "examples", ".", "append", "(", "data", ".", "Example", ".", "fromlist", "(", "lines", ",", "fields", ")", ")", "\n", "", "", "", "if", "load_dataset", ":", "\n", "                    ", "torch", ".", "save", "(", "examples", ",", "path", "+", "'.processed.{}.pt'", ".", "format", "(", "prefix", ")", ")", "\n", "\n", "", "", "", "super", "(", "datasets", ".", "TranslationDataset", ",", "self", ")", ".", "__init__", "(", "examples", ",", "fields", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.data.NormalField._getattr": [[16, 19], ["getattr"], "methods", ["None"], ["    ", "def", "_getattr", "(", "self", ",", "dataset", ",", "attr", ")", ":", "\n", "            ", "for", "x", "in", "dataset", ":", "\n", "                ", "yield", "getattr", "(", "x", ",", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.data.NormalField.build_vocab": [[20, 50], ["collections.Counter", "list", "torchtext.data.NormalField.vocab_cls", "collections.OrderedDict.fromkeys", "torchtext.data.NormalField._getattr", "collections.Counter.update", "collections.Counter.update", "itertools.chain.from_iterable"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.data.NormalField._getattr"], ["", "", "def", "build_vocab", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Construct the Vocab object for this field from one or more datasets.\n\n        Arguments:\n            Positional arguments: Dataset objects or other iterable data\n                sources from which to construct the Vocab object that\n                represents the set of possible values for this field. If\n                a Dataset object is provided, all columns corresponding\n                to this field are used; individual columns can also be\n                provided directly.\n            Remaining keyword arguments: Passed to the constructor of Vocab.\n        \"\"\"", "\n", "counter", "=", "Counter", "(", ")", "\n", "sources", "=", "[", "]", "\n", "for", "arg", "in", "args", ":", "\n", "            ", "sources", "+=", "[", "self", ".", "_getattr", "(", "arg", ",", "name", ")", "for", "name", ",", "field", "in", "\n", "arg", ".", "fields", "if", "field", "is", "self", "]", "\n", "", "for", "data", "in", "sources", ":", "\n", "            ", "for", "x", "in", "data", ":", "\n", "                ", "if", "not", "self", ".", "sequential", ":", "\n", "                    ", "x", "=", "[", "x", "]", "\n", "", "try", ":", "\n", "                    ", "counter", ".", "update", "(", "x", ")", "\n", "", "except", "TypeError", ":", "\n", "                    ", "counter", ".", "update", "(", "chain", ".", "from_iterable", "(", "x", ")", ")", "\n", "", "", "", "specials", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "\n", "tok", "for", "tok", "in", "[", "self", ".", "unk_token", ",", "self", ".", "pad_token", ",", "self", ".", "init_token", ",", "\n", "self", ".", "eos_token", "]", "\n", "if", "tok", "is", "not", "None", ")", ")", "\n", "self", ".", "vocab", "=", "self", ".", "vocab_cls", "(", "counter", ",", "specials", "=", "specials", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.data.NormalField.reverse": [[51, 81], ["batch.tolist.tolist.t_", "torch.cuda.device_of", "batch.tolist.tolist.tolist", "torchtext.data.NormalField.reverse.trim"], "methods", ["None"], ["", "def", "reverse", "(", "self", ",", "batch", ",", "unbpe", "=", "True", ",", "returen_token", "=", "False", ")", ":", "\n", "        ", "if", "not", "self", ".", "batch_first", ":", "\n", "            ", "batch", ".", "t_", "(", ")", "\n", "\n", "", "with", "torch", ".", "cuda", ".", "device_of", "(", "batch", ")", ":", "\n", "            ", "batch", "=", "batch", ".", "tolist", "(", ")", "\n", "\n", "", "batch", "=", "[", "[", "self", ".", "vocab", ".", "itos", "[", "ind", "]", "for", "ind", "in", "ex", "]", "for", "ex", "in", "batch", "]", "# denumericalize", "\n", "\n", "def", "trim", "(", "s", ",", "t", ")", ":", "\n", "            ", "sentence", "=", "[", "]", "\n", "for", "w", "in", "s", ":", "\n", "                ", "if", "w", "==", "t", ":", "\n", "                    ", "break", "\n", "", "sentence", ".", "append", "(", "w", ")", "\n", "", "return", "sentence", "\n", "\n", "", "batch", "=", "[", "trim", "(", "ex", ",", "self", ".", "eos_token", ")", "for", "ex", "in", "batch", "]", "# trim past frst eos", "\n", "\n", "def", "filter_special", "(", "tok", ")", ":", "\n", "            ", "return", "tok", "not", "in", "(", "self", ".", "init_token", ",", "self", ".", "pad_token", ")", "\n", "\n", "", "if", "unbpe", ":", "\n", "            ", "batch", "=", "[", "\" \"", ".", "join", "(", "filter", "(", "filter_special", ",", "ex", ")", ")", ".", "replace", "(", "\"@@ \"", ",", "\"\"", ")", "for", "ex", "in", "batch", "]", "\n", "", "else", ":", "\n", "            ", "batch", "=", "[", "\" \"", ".", "join", "(", "filter", "(", "filter_special", ",", "ex", ")", ")", "for", "ex", "in", "batch", "]", "\n", "\n", "", "if", "returen_token", ":", "\n", "            ", "batch", "=", "[", "ex", ".", "split", "(", ")", "for", "ex", "in", "batch", "]", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.data.ParallelDataset.__init__": [[86, 97], ["len", "tuple", "len", "len", "isinstance", "range", "newfields.append", "os.path.expanduser", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "path", "=", "None", ",", "exts", "=", "None", ",", "fields", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "assert", "len", "(", "exts", ")", "==", "len", "(", "fields", ")", ",", "'N parallel dataset must match'", "\n", "self", ".", "N", "=", "len", "(", "fields", ")", "\n", "\n", "if", "not", "isinstance", "(", "fields", "[", "0", "]", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "newfields", "=", "[", "(", "'src'", ",", "fields", "[", "0", "]", ")", ",", "(", "'tgt'", ",", "fields", "[", "1", "]", ")", ",", "(", "'tag'", ",", "fields", "[", "2", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "exts", ")", "-", "3", ")", ":", "\n", "                ", "newfields", ".", "append", "(", "(", "'extra_{}'", ".", "format", "(", "i", ")", ",", "fields", "[", "3", "+", "i", "]", ")", ")", "\n", "", "self", ".", "fields", "=", "newfields", "\n", "", "self", ".", "paths", "=", "tuple", "(", "os", ".", "path", ".", "expanduser", "(", "path", "+", "'.'", "+", "x", ")", "for", "x", "in", "exts", ")", "\n", "self", ".", "max_len", "=", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.data.ParallelDataset.__iter__": [[98, 109], ["contextlib.ExitStack", "enumerate", "stack.enter_context", "zip", "open", "line.strip", "any", "torchtext.data.Example.fromlist", "len", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "            ", "files", "=", "[", "stack", ".", "enter_context", "(", "open", "(", "fname", ",", "'r'", ",", "errors", "=", "'ignore'", ")", ")", "for", "fname", "in", "self", ".", "paths", "]", "\n", "for", "i", ",", "lines", "in", "enumerate", "(", "zip", "(", "*", "files", ")", ")", ":", "\n", "                ", "lines", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "lines", "]", "\n", "if", "not", "any", "(", "line", "==", "''", "for", "line", "in", "lines", ")", ":", "\n", "                    ", "example", "=", "Example", ".", "fromlist", "(", "lines", ",", "self", ".", "fields", ")", "\n", "if", "self", ".", "max_len", "is", "None", ":", "\n", "                        ", "yield", "example", "\n", "", "elif", "len", "(", "example", ".", "src", ")", "<=", "self", ".", "max_len", "and", "len", "(", "example", ".", "tgt", ")", "<=", "self", ".", "max_len", ":", "\n", "                        ", "yield", "example", "\n", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.__init__": [[50, 86], ["dict", "torchtext.data.utils.RandomShuffler", "type", "logger.warning", "torchtext.data.interleave_keys", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ",", "sort_key", "=", "None", ",", "device", "=", "None", ",", "\n", "batch_size_fn", "=", "None", ",", "train", "=", "True", ",", "\n", "repeat", "=", "False", ",", "shuffle", "=", "None", ",", "sort", "=", "None", ",", "\n", "sort_within_batch", "=", "None", ",", "poolnum", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "fields", "=", "dict", "(", "dataset", ".", "fields", ")", "\n", "self", ".", "batch_size", ",", "self", ".", "train", ",", "self", ".", "dataset", "=", "batch_size", ",", "train", ",", "dataset", "\n", "self", ".", "poolnum", "=", "poolnum", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "iterations", "=", "0", "\n", "self", ".", "repeat", "=", "repeat", "\n", "self", ".", "shuffle", "=", "train", "if", "shuffle", "is", "None", "else", "shuffle", "\n", "self", ".", "sort", "=", "not", "train", "if", "sort", "is", "None", "else", "sort", "\n", "\n", "if", "sort_within_batch", "is", "None", ":", "\n", "            ", "self", ".", "sort_within_batch", "=", "self", ".", "sort", "\n", "", "else", ":", "\n", "            ", "self", ".", "sort_within_batch", "=", "sort_within_batch", "\n", "\n", "", "if", "sort_key", "is", "None", ":", "\n", "            ", "self", ".", "sort_key", "=", "lambda", "ex", ":", "interleave_keys", "(", "len", "(", "ex", ".", "src", ")", ",", "len", "(", "ex", ".", "tgt", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "sort_key", "=", "sort_key", "\n", "\n", "", "if", "type", "(", "device", ")", "==", "int", ":", "\n", "            ", "logger", ".", "warning", "(", "\"The `device` argument should be set by using `torch.device`\"", "+", "\n", "\" or passing a string as an argument. This behavior will be\"", "+", "\n", "\" deprecated soon and currently defaults to cpu.\"", ")", "\n", "device", "=", "None", "\n", "", "self", ".", "device", "=", "device", "\n", "self", ".", "random_shuffler", "=", "RandomShuffler", "(", ")", "\n", "\n", "# For state loading/saving only", "\n", "self", ".", "_iterations_this_epoch", "=", "0", "\n", "self", ".", "_random_state_this_epoch", "=", "None", "\n", "self", ".", "_restored_from_state", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.data": [[87, 99], ["None"], "methods", ["None"], ["", "def", "data", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the examples in the dataset in order, sorted, or shuffled.\"\"\"", "\n", "# if self.sort:", "\n", "#     xs = sorted(self.dataset, key=self.sort_key)", "\n", "# elif self.shuffle:", "\n", "#     xs = [self.dataset[i] for i in self.random_shuffler(range(len(self.dataset)))]", "\n", "# else:", "\n", "\n", "# files ->shuffle -> tmp files", "\n", "\n", "xs", "=", "self", ".", "dataset", "\n", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.init_epoch": [[100, 117], ["lazy_iterator.Iterator.create_batches"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.BucketIterator.create_batches"], ["", "def", "init_epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the batch generator for a new epoch.\"\"\"", "\n", "\n", "if", "self", ".", "_restored_from_state", ":", "\n", "            ", "self", ".", "random_shuffler", ".", "random_state", "=", "self", ".", "_random_state_this_epoch", "\n", "", "else", ":", "\n", "            ", "self", ".", "_random_state_this_epoch", "=", "self", ".", "random_shuffler", ".", "random_state", "\n", "\n", "", "self", ".", "create_batches", "(", ")", "\n", "\n", "if", "self", ".", "_restored_from_state", ":", "\n", "            ", "self", ".", "_restored_from_state", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "_iterations_this_epoch", "=", "0", "\n", "\n", "", "if", "not", "self", ".", "repeat", ":", "\n", "            ", "self", ".", "iterations", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.create_batches": [[118, 120], ["lazy_iterator.batch", "lazy_iterator.Iterator.data"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.batch", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.data"], ["", "", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "self", ".", "batches", "=", "batch", "(", "self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "self", ".", "batch_size_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.epoch": [[121, 124], ["math.floor", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "epoch", "(", "self", ")", ":", "\n", "        ", "return", "math", ".", "floor", "(", "self", ".", "iterations", "/", "len", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.__len__": [[125, 129], ["math.ceil", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_size_fn", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "return", "math", ".", "ceil", "(", "len", "(", "self", ".", "dataset", ")", "/", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.__iter__": [[130, 150], ["lazy_iterator.Iterator.init_epoch", "enumerate", "lazy_iterator.Batch", "minibatch.reverse", "minibatch.sort"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.init_epoch", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.data.NormalField.reverse"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "self", ".", "init_epoch", "(", ")", "\n", "for", "idx", ",", "minibatch", "in", "enumerate", "(", "self", ".", "batches", ")", ":", "\n", "# fast-forward if loaded from state", "\n", "                ", "if", "self", ".", "_iterations_this_epoch", ">", "idx", ":", "\n", "                    ", "continue", "\n", "", "self", ".", "iterations", "+=", "1", "\n", "self", ".", "_iterations_this_epoch", "+=", "1", "\n", "if", "self", ".", "sort_within_batch", ":", "\n", "# NOTE: `rnn.pack_padded_sequence` requires that a minibatch", "\n", "# be sorted by decreasing order, which requires reversing", "\n", "# relative to typical sort keys", "\n", "                    ", "if", "self", ".", "sort", ":", "\n", "                        ", "minibatch", ".", "reverse", "(", ")", "\n", "", "else", ":", "\n", "                        ", "minibatch", ".", "sort", "(", "key", "=", "self", ".", "sort_key", ",", "reverse", "=", "True", ")", "\n", "", "", "yield", "Batch", "(", "minibatch", ",", "self", ".", "dataset", ",", "self", ".", "device", ",", "self", ".", "fields", ")", "\n", "", "if", "not", "self", ".", "repeat", ":", "\n", "                ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.state_dict": [[151, 156], ["None"], "methods", ["None"], ["", "", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"iterations\"", ":", "self", ".", "iterations", ",", "\n", "\"iterations_this_epoch\"", ":", "self", ".", "_iterations_this_epoch", ",", "\n", "\"random_state_this_epoch\"", ":", "self", ".", "_random_state_this_epoch", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.load_state_dict": [[157, 162], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "iterations", "=", "state_dict", "[", "\"iterations\"", "]", "\n", "self", ".", "_iterations_this_epoch", "=", "state_dict", "[", "\"iterations_this_epoch\"", "]", "\n", "self", ".", "_random_state_this_epoch", "=", "state_dict", "[", "\"random_state_this_epoch\"", "]", "\n", "self", ".", "_restored_from_state", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.BucketIterator.create_batches": [[171, 181], ["lazy_iterator.batch", "lazy_iterator.pool", "lazy_iterator.BucketIterator.data", "lazy_iterator.BucketIterator.data"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.batch", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.pool", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.data", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Iterator.data"], ["def", "create_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "sort", ":", "\n", "            ", "self", ".", "batches", "=", "batch", "(", "self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "batch_size_fn", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "batches", "=", "pool", "(", "self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "sort_key", ",", "self", ".", "batch_size_fn", ",", "\n", "random_shuffler", "=", "self", ".", "random_shuffler", ",", "\n", "shuffle", "=", "self", ".", "shuffle", ",", "\n", "sort_within_batch", "=", "self", ".", "sort_within_batch", ",", "poolnum", "=", "self", ".", "poolnum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__init__": [[246, 266], ["len", "fields.keys", "fields.items", "fields.items", "fields.items", "getattr", "setattr", "setattr", "field.process"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", "=", "None", ",", "dataset", "=", "None", ",", "device", "=", "None", ",", "fields", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a Batch from a list of examples.\"\"\"", "\n", "if", "data", "is", "not", "None", ":", "\n", "            ", "self", ".", "batch_size", "=", "len", "(", "data", ")", "\n", "\n", "# self.dataset = dataset", "\n", "# self.fields = dataset.fields.keys()  # copy field names", "\n", "self", ".", "fields", "=", "fields", ".", "keys", "(", ")", "\n", "self", ".", "input_fields", "=", "[", "k", "for", "k", ",", "v", "in", "fields", ".", "items", "(", ")", "if", "\n", "v", "is", "not", "None", "and", "not", "v", ".", "is_target", "]", "\n", "self", ".", "target_fields", "=", "[", "k", "for", "k", ",", "v", "in", "fields", ".", "items", "(", ")", "if", "\n", "v", "is", "not", "None", "and", "v", ".", "is_target", "]", "\n", "\n", "for", "(", "name", ",", "field", ")", "in", "fields", ".", "items", "(", ")", ":", "\n", "                ", "if", "field", "is", "not", "None", ":", "\n", "                    ", "batch", "=", "[", "getattr", "(", "x", ",", "name", ")", "for", "x", "in", "data", "]", "\n", "if", "name", "!=", "'src'", ":", "\n", "                        ", "setattr", "(", "self", ",", "name", ",", "field", ".", "process", "(", "batch", ",", "device", "=", "device", ")", ")", "\n", "", "else", ":", "\n", "                        ", "setattr", "(", "self", ",", "name", ",", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.fromvars": [[267, 277], ["cls", "dataset.fields.keys", "kwargs.items", "setattr"], "methods", ["None"], ["", "", "", "", "", "@", "classmethod", "\n", "def", "fromvars", "(", "cls", ",", "dataset", ",", "batch_size", ",", "train", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Create a Batch directly from a number of Variables.\"\"\"", "\n", "batch", "=", "cls", "(", ")", "\n", "batch", ".", "batch_size", "=", "batch_size", "\n", "batch", ".", "dataset", "=", "dataset", "\n", "batch", ".", "fields", "=", "dataset", ".", "fields", ".", "keys", "(", ")", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "batch", ",", "k", ",", "v", ")", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__repr__": [[278, 280], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__str__": [[281, 296], ["filter", "torch.typename", "torch.typename", "hasattr", "isinstance", "lazy_iterator.Batch.dataset.name.upper", "lazy_iterator._short_str", "hasattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator._short_str"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "__dict__", ":", "\n", "            ", "return", "'Empty {} instance'", ".", "format", "(", "torch", ".", "typename", "(", "self", ")", ")", "\n", "\n", "", "fields_to_index", "=", "filter", "(", "lambda", "field", ":", "field", "is", "not", "None", ",", "self", ".", "fields", ")", "\n", "var_strs", "=", "'\\n'", ".", "join", "(", "[", "'\\t[.'", "+", "name", "+", "']'", "+", "\":\"", "+", "_short_str", "(", "getattr", "(", "self", ",", "name", ")", ")", "\n", "for", "name", "in", "fields_to_index", "if", "hasattr", "(", "self", ",", "name", ")", "]", ")", "\n", "\n", "data_str", "=", "(", "' from {}'", ".", "format", "(", "self", ".", "dataset", ".", "name", ".", "upper", "(", ")", ")", "\n", "if", "hasattr", "(", "self", ".", "dataset", ",", "'name'", ")", "and", "\n", "isinstance", "(", "self", ".", "dataset", ".", "name", ",", "str", ")", "else", "''", ")", "\n", "\n", "strt", "=", "'[{} of size {}{}]\\n{}'", ".", "format", "(", "torch", ".", "typename", "(", "self", ")", ",", "\n", "self", ".", "batch_size", ",", "data_str", ",", "var_strs", ")", "\n", "return", "'\\n'", "+", "strt", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__len__": [[297, 299], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch._get_field_values": [[300, 307], ["len", "len", "getattr", "tuple", "getattr"], "methods", ["None"], ["", "def", "_get_field_values", "(", "self", ",", "fields", ")", ":", "\n", "        ", "if", "len", "(", "fields", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "elif", "len", "(", "fields", ")", "==", "1", ":", "\n", "            ", "return", "getattr", "(", "self", ",", "fields", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "tuple", "(", "getattr", "(", "self", ",", "f", ")", "for", "f", "in", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch.__iter__": [[308, 311], ["lazy_iterator.Batch._get_field_values", "lazy_iterator.Batch._get_field_values"], "methods", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch._get_field_values", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.Batch._get_field_values"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "yield", "self", ".", "_get_field_values", "(", "self", ".", "input_fields", ")", "\n", "yield", "self", ".", "_get_field_values", "(", "self", ".", "target_fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.batch": [[183, 200], ["minibatch.append", "lazy_iterator.batch.batch_size_fn"], "function", ["None"], ["", "", "", "def", "batch", "(", "data", ",", "batch_size", ",", "batch_size_fn", "=", "None", ")", ":", "\n", "    ", "\"\"\"Yield elements from data in chunks of batch_size.\"\"\"", "\n", "if", "batch_size_fn", "is", "None", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "return", "count", "\n", "", "", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "for", "ex", "in", "data", ":", "\n", "        ", "minibatch", ".", "append", "(", "ex", ")", "\n", "size_so_far", "=", "batch_size_fn", "(", "ex", ",", "len", "(", "minibatch", ")", ",", "size_so_far", ")", "\n", "if", "size_so_far", "==", "batch_size", ":", "\n", "            ", "yield", "minibatch", "\n", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "", "elif", "size_so_far", ">", "batch_size", ":", "\n", "            ", "yield", "minibatch", "[", ":", "-", "1", "]", "\n", "minibatch", ",", "size_so_far", "=", "minibatch", "[", "-", "1", ":", "]", ",", "batch_size_fn", "(", "ex", ",", "1", ",", "0", ")", "\n", "", "", "if", "minibatch", ":", "\n", "        ", "yield", "minibatch", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.pool": [[202, 228], ["lazy_iterator.batch", "list", "random_shuffler", "lazy_iterator.batch", "lazy_iterator.batch", "sorted"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.batch", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.batch", "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator.batch"], ["", "", "def", "pool", "(", "data", ",", "batch_size", ",", "key", ",", "batch_size_fn", "=", "lambda", "new", ",", "count", ",", "sofar", ":", "count", ",", "\n", "random_shuffler", "=", "None", ",", "shuffle", "=", "False", ",", "sort_within_batch", "=", "False", ",", "poolnum", "=", "100", ")", ":", "\n", "    ", "\"\"\"Sort within buckets, then batch, then shuffle batches.\n\n    Partitions data into chunks of size 100*batch_size, sorts examples within\n    each chunk using sort_key, then batch these examples and shuffle the\n    batches.\n    \"\"\"", "\n", "if", "random_shuffler", "is", "None", ":", "\n", "        ", "random_shuffler", "=", "random", ".", "shuffle", "\n", "\n", "", "for", "p", "in", "batch", "(", "data", ",", "batch_size", "*", "poolnum", ",", "batch_size_fn", ")", ":", "\n", "        ", "if", "shuffle", ":", "\n", "            ", "p", "=", "random_shuffler", "(", "p", ")", "\n", "", "p_batch", "=", "batch", "(", "sorted", "(", "p", ",", "key", "=", "key", ")", ",", "batch_size", ",", "batch_size_fn", ")", "if", "sort_within_batch", "else", "batch", "(", "p", ",", "batch_size", ",", "batch_size_fn", ")", "\n", "\n", "# if shuffle:", "\n", "#     for b in random_shuffler(list(p_batch)):", "\n", "#         yield b", "\n", "# else:", "\n", "for", "b", "in", "list", "(", "p_batch", ")", ":", "\n", "# print(len(b))", "\n", "# exit()", "\n", "            ", "yield", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator._short_str": [[313, 333], ["torch.is_tensor", "hasattr", "torch.typename", "getattr", "isinstance", "str", "getattr.get_device", "str", "str", "getattr.size", "tuple", "lazy_iterator._short_str"], "function", ["home.repos.pwc.inspect_result.DeepLearnXMU_Cyclic.data.lazy_iterator._short_str"], ["", "", "def", "_short_str", "(", "tensor", ")", ":", "\n", "# unwrap variable to tensor", "\n", "    ", "if", "not", "torch", ".", "is_tensor", "(", "tensor", ")", ":", "\n", "# (1) unpack variable", "\n", "        ", "if", "hasattr", "(", "tensor", ",", "'data'", ")", ":", "\n", "            ", "tensor", "=", "getattr", "(", "tensor", ",", "'data'", ")", "\n", "# (2) handle include_lengths", "\n", "", "elif", "isinstance", "(", "tensor", ",", "tuple", ")", ":", "\n", "            ", "return", "str", "(", "tuple", "(", "_short_str", "(", "t", ")", "for", "t", "in", "tensor", ")", ")", "\n", "# (3) fallback to default str", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "tensor", ")", "\n", "\n", "# copied from torch _tensor_str", "\n", "", "", "size_str", "=", "'x'", ".", "join", "(", "str", "(", "size", ")", "for", "size", "in", "tensor", ".", "size", "(", ")", ")", "\n", "device_str", "=", "''", "if", "not", "tensor", ".", "is_cuda", "else", "' (GPU {})'", ".", "format", "(", "tensor", ".", "get_device", "(", ")", ")", "\n", "strt", "=", "'[{} of size {}{}]'", ".", "format", "(", "torch", ".", "typename", "(", "tensor", ")", ",", "\n", "size_str", ",", "device_str", ")", "\n", "return", "strt", "\n", "\n"]]}