{"home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.InputFeatures.__init__": [[75, 79], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.Feature.__init__": [[82, 99], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "seq_a", ",", "label", ",", "label_str", ",", "target_label", ",", "target_label_str", ")", ":", "\n", "        ", "self", ".", "label", "=", "label", "\n", "self", ".", "seq", "=", "seq_a", "\n", "self", ".", "final_adverse", "=", "seq_a", "\n", "self", ".", "query", "=", "0", "\n", "self", ".", "change", "=", "0", "\n", "self", ".", "success", "=", "0", "\n", "self", ".", "sim", "=", "0.0", "\n", "self", ".", "changes", "=", "[", "]", "\n", "\n", "self", ".", "label_str", "=", "label_str", "\n", "self", ".", "target_label", "=", "target_label", "\n", "self", ".", "target_label_str", "=", "target_label_str", "\n", "self", ".", "adv_label", "=", "label", "\n", "self", ".", "adv_label_str", "=", "label_str", "\n", "self", ".", "pred_label", "=", "label", "\n", "self", ".", "pred_label_str", "=", "label_str", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.get_sim_embed": [[57, 70], ["numpy.load", "open", "line.split", "len", "len"], "function", ["None"], ["def", "get_sim_embed", "(", "embed_path", ",", "sim_path", ")", ":", "\n", "    ", "id2word", "=", "{", "}", "\n", "word2id", "=", "{", "}", "\n", "\n", "with", "open", "(", "embed_path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "ifile", ":", "\n", "        ", "for", "line", "in", "ifile", ":", "\n", "            ", "word", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "word", "not", "in", "id2word", ":", "\n", "                ", "id2word", "[", "len", "(", "id2word", ")", "]", "=", "word", "\n", "word2id", "[", "word", "]", "=", "len", "(", "id2word", ")", "-", "1", "\n", "\n", "", "", "", "cos_sim", "=", "np", ".", "load", "(", "sim_path", ")", "\n", "return", "cos_sim", ",", "word2id", ",", "id2word", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc._tokenize": [[101, 116], ["seq.replace.replace", "seq.replace.split", "keys.append", "len", "len"], "function", ["None"], ["", "", "def", "_tokenize", "(", "seq", ",", "tokenizer", ")", ":", "\n", "    ", "seq", "=", "seq", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "\n", "words", "=", "seq", ".", "split", "(", "' '", ")", "\n", "\n", "sub_words", "=", "[", "]", "\n", "keys", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "word", "in", "words", ":", "\n", "        ", "sub", "=", "[", "word", "]", "\n", "sub_words", "+=", "sub", "\n", "keys", ".", "append", "(", "[", "index", ",", "index", "+", "len", "(", "sub", ")", "]", ")", "\n", "index", "+=", "len", "(", "sub", ")", "\n", "\n", "", "return", "words", ",", "sub_words", ",", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc._special_char_axml": [[117, 123], ["enumerate", "text.replace.replace", "text.replace.replace"], "function", ["None"], ["", "def", "_special_char_axml", "(", "texts", ")", ":", "\n", "    ", "for", "i", ",", "text", "in", "enumerate", "(", "texts", ")", ":", "\n", "        ", "text", "=", "text", ".", "replace", "(", "'[SEP]'", ",", "'/SEP/'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'[UNK]'", ",", "'/UNK/'", ")", "\n", "texts", "[", "i", "]", "=", "text", "\n", "", "return", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc._get_masked": [[124, 131], ["len", "range", "masked_words.append"], "function", ["None"], ["", "def", "_get_masked", "(", "words", ")", ":", "\n", "    ", "len_text", "=", "len", "(", "words", ")", "\n", "masked_words", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len_text", "-", "1", ")", ":", "\n", "        ", "masked_words", ".", "append", "(", "words", "[", "0", ":", "i", "]", "+", "[", "'[UNK]'", "]", "+", "words", "[", "i", "+", "1", ":", "]", ")", "\n", "# list of words", "\n", "", "return", "masked_words", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.get_important_scores": [[133, 154], ["adv_xmtc._get_masked", "tgt_model.predict", "torch.cat", "torch.cat", "torch.sigmoid", "torch.sigmoid", "adv_xmtc._special_char_axml", "range", "len"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc._get_masked", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel.predict", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc._special_char_axml"], ["", "def", "get_important_scores", "(", "words", ",", "tgt_model", ",", "target_label", ",", "orig_label", ",", "orig_probs", ",", "attack_type", ",", "tgt_type", ",", "batch_size", ",", "max_length", ")", ":", "\n", "\n", "    ", "masked_words", "=", "_get_masked", "(", "words", ")", "\n", "# list of text of masked words", "\n", "texts", "=", "[", "' '", ".", "join", "(", "words", ")", "for", "words", "in", "masked_words", "]", "\n", "\n", "if", "tgt_type", "==", "'axml'", ":", "\n", "        ", "texts", "=", "_special_char_axml", "(", "texts", ")", "\n", "", "_", ",", "leave_1_probs", "=", "tgt_model", ".", "predict", "(", "texts", ",", "[", "orig_label", "for", "i", "in", "range", "(", "len", "(", "texts", ")", ")", "]", ",", "max_length", ")", "\n", "leave_1_probs", "=", "torch", ".", "cat", "(", "leave_1_probs", ",", "dim", "=", "0", ")", "# words, num-label", "\n", "leave_1_probs", "=", "torch", ".", "sigmoid", "(", "leave_1_probs", ")", "\n", "\n", "orig_prob", "=", "orig_probs", "[", "target_label", "]", "\n", "\n", "if", "attack_type", "==", "'A_pos'", ":", "\n", "        ", "import_scores", "=", "(", "(", "orig_prob", "-", "leave_1_probs", "[", ":", ",", "target_label", "]", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "if", "attack_type", "==", "'A_neg'", ":", "\n", "        ", "import_scores", "=", "(", "leave_1_probs", "[", ":", ",", "target_label", "]", "-", "orig_prob", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "import_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.get_substitues": [[156, 176], ["substitutes.size", "zip", "get_bpe_substitues.append", "adv_xmtc.get_bpe_substitues", "tokenizer._convert_id_to_token", "int"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.get_bpe_substitues", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_id_to_token"], ["", "def", "get_substitues", "(", "substitutes", ",", "tokenizer", ",", "mlm_model", ",", "use_bpe", ",", "substitutes_score", "=", "None", ",", "threshold", "=", "3.0", ")", ":", "\n", "# substitues L,k", "\n", "# from this matrix to recover a word", "\n", "    ", "words", "=", "[", "]", "\n", "sub_len", ",", "k", "=", "substitutes", ".", "size", "(", ")", "# sub-len, k", "\n", "\n", "if", "sub_len", "==", "0", ":", "\n", "        ", "return", "words", "\n", "\n", "", "elif", "sub_len", "==", "1", ":", "\n", "        ", "for", "(", "i", ",", "j", ")", "in", "zip", "(", "substitutes", "[", "0", "]", ",", "substitutes_score", "[", "0", "]", ")", ":", "\n", "            ", "if", "threshold", "!=", "0", "and", "j", "<", "threshold", ":", "\n", "                ", "break", "\n", "", "words", ".", "append", "(", "tokenizer", ".", "_convert_id_to_token", "(", "int", "(", "i", ")", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "use_bpe", "==", "1", ":", "\n", "            ", "words", "=", "get_bpe_substitues", "(", "substitutes", ",", "tokenizer", ",", "mlm_model", ")", "\n", "", "else", ":", "\n", "            ", "return", "words", "\n", "", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.get_bpe_substitues": [[178, 217], ["range", "torch.CrossEntropyLoss", "torch.tensor", "torch.tensor", "all_substitutes[].to", "all_substitutes[].to.size", "nn.CrossEntropyLoss.", "torch.exp", "torch.exp", "torch.sort", "torch.sort", "substitutes.size", "mlm_model", "word_predictions.view", "all_substitutes[].to.view", "torch.mean", "torch.mean", "tokenizer.convert_tokens_to_string", "final_words.append", "len", "torch.exp.view", "tokenizer._convert_id_to_token", "int", "int", "lev_i.append", "int"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_id_to_token"], ["", "def", "get_bpe_substitues", "(", "substitutes", ",", "tokenizer", ",", "mlm_model", ")", ":", "\n", "# substitutes L, k", "\n", "\n", "    ", "substitutes", "=", "substitutes", "[", "0", ":", "12", ",", "0", ":", "4", "]", "# maximum BPE candidates", "\n", "\n", "# find all possible candidates", "\n", "\n", "all_substitutes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "substitutes", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "if", "len", "(", "all_substitutes", ")", "==", "0", ":", "\n", "            ", "lev_i", "=", "substitutes", "[", "i", "]", "\n", "all_substitutes", "=", "[", "[", "int", "(", "c", ")", "]", "for", "c", "in", "lev_i", "]", "\n", "", "else", ":", "\n", "            ", "lev_i", "=", "[", "]", "\n", "for", "all_sub", "in", "all_substitutes", ":", "\n", "                ", "for", "j", "in", "substitutes", "[", "i", "]", ":", "\n", "                    ", "lev_i", ".", "append", "(", "all_sub", "+", "[", "int", "(", "j", ")", "]", ")", "\n", "", "", "all_substitutes", "=", "lev_i", "\n", "\n", "# all substitutes  list of list of token-id (all candidates)", "\n", "", "", "c_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "word_list", "=", "[", "]", "\n", "# all_substitutes = all_substitutes[:24]", "\n", "all_substitutes", "=", "torch", ".", "tensor", "(", "all_substitutes", ")", "# [ N, L ]", "\n", "all_substitutes", "=", "all_substitutes", "[", ":", "24", "]", ".", "to", "(", "'cuda'", ")", "\n", "# print(substitutes.size(), all_substitutes.size())", "\n", "N", ",", "L", "=", "all_substitutes", ".", "size", "(", ")", "\n", "word_predictions", "=", "mlm_model", "(", "all_substitutes", ")", "[", "0", "]", "# N L vocab-size", "\n", "ppl", "=", "c_loss", "(", "word_predictions", ".", "view", "(", "N", "*", "L", ",", "-", "1", ")", ",", "\n", "all_substitutes", ".", "view", "(", "-", "1", ")", ")", "# [ N*L ]", "\n", "ppl", "=", "torch", ".", "exp", "(", "torch", ".", "mean", "(", "ppl", ".", "view", "(", "N", ",", "L", ")", ",", "dim", "=", "-", "1", ")", ")", "# N", "\n", "_", ",", "word_list", "=", "torch", ".", "sort", "(", "ppl", ")", "\n", "word_list", "=", "[", "all_substitutes", "[", "i", "]", "for", "i", "in", "word_list", "]", "\n", "final_words", "=", "[", "]", "\n", "for", "word", "in", "word_list", ":", "\n", "        ", "tokens", "=", "[", "tokenizer", ".", "_convert_id_to_token", "(", "int", "(", "i", ")", ")", "for", "i", "in", "word", "]", "\n", "text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "tokens", ")", "\n", "final_words", ".", "append", "(", "text", ")", "\n", "", "return", "final_words", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.attack": [[219, 376], ["adv_xmtc._tokenize", "tgt_model.predict", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sort", "torch.sort", "pred_label.squeeze().tolist.squeeze().tolist", "torch.tensor", "torch.tensor", "[].squeeze", "torch.topk", "torch.topk", "adv_xmtc.get_important_scores", "int", "sorted", "copy.deepcopy", "tgt_model.tokenizer.convert_tokens_to_string", "torch.sort", "torch.sort", "adv_label.squeeze().tolist.squeeze().tolist", "print", "len", "enumerate", "adv_xmtc.get_substitues", "torch.sigmoid", "torch.sigmoid", "pred_label.squeeze().tolist.squeeze", "print", "tokenizer_mlm.convert_tokens_to_ids", "int", "tgt_model.tokenizer.convert_tokens_to_string", "tgt_model.predict", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.topk", "torch.topk", "feature.changes.append", "adv_label.squeeze().tolist.squeeze", "mlm_model", "feature.changes.append", "torch.sort", "torch.sort", "adv_label.squeeze().tolist.squeeze().tolist", "torch.tensor.to", "len", "len", "len", "adv_xmtc._special_char_axml", "torch.sigmoid", "torch.sigmoid", "adv_label.squeeze().tolist.squeeze"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._tokenize", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel.predict", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.get_important_scores", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.get_substitues", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel.predict", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc._special_char_axml"], ["", "def", "attack", "(", "feature", ",", "tgt_model", ",", "mlm_model", ",", "tokenizer_mlm", ",", "k", ",", "label_rev_map", ",", "attack_type", ",", "tgt_type", ",", "change_threshold", ",", "batch_size", ",", "max_length", "=", "512", ",", "cos_mat", "=", "None", ",", "w2i", "=", "{", "}", ",", "i2w", "=", "{", "}", ",", "use_bpe", "=", "1", ",", "threshold_pred_score", "=", "0.3", ",", "top", "=", "5", ")", ":", "\n", "# MLM-process", "\n", "    ", "words", ",", "sub_words", ",", "keys", "=", "_tokenize", "(", "feature", ".", "seq", ",", "tokenizer_mlm", ")", "\n", "\n", "\n", "_", ",", "logits", "=", "tgt_model", ".", "predict", "(", "[", "feature", ".", "seq", "]", ",", "[", "feature", ".", "label", "]", ",", "max_length", ")", "\n", "logits", "=", "logits", "[", "0", "]", "\n", "\n", "orig_probs", "=", "torch", ".", "sigmoid", "(", "logits", ")", ".", "squeeze", "(", ")", "\n", "_", ",", "pred_label", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "pred_label", "=", "pred_label", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "\n", "target_label", "=", "feature", ".", "target_label", "\n", "if", "attack_type", "==", "'A_pos'", ":", "\n", "        ", "invalid_attack", "=", "target_label", "not", "in", "feature", ".", "label", "or", "target_label", "not", "in", "pred_label", "[", ":", "top", "]", "\n", "", "elif", "attack_type", "==", "'A_neg'", ":", "\n", "        ", "invalid_attack", "=", "target_label", "in", "feature", ".", "label", "or", "target_label", "in", "pred_label", "[", ":", "top", "]", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Unrecognized attack type'", ")", "\n", "feature", ".", "success", "=", "-", "1", "\n", "return", "feature", "\n", "\n", "\n", "", "if", "invalid_attack", ":", "\n", "        ", "print", "(", "'invalid attack'", ")", "\n", "feature", ".", "success", "=", "-", "1", "\n", "return", "feature", "\n", "\n", "", "feature", ".", "pred_label", "=", "pred_label", "[", ":", "10", "]", "\n", "feature", ".", "pred_label_str", "=", "[", "label_rev_map", "[", "label", "]", "for", "label", "in", "feature", ".", "pred_label", "]", "\n", "\n", "feature", ".", "adv_label", "=", "pred_label", "[", ":", "10", "]", "\n", "feature", ".", "adv_label_str", "=", "[", "label_rev_map", "[", "label", "]", "for", "label", "in", "feature", ".", "pred_label", "]", "\n", "\n", "sub_words", "=", "[", "'[CLS]'", "]", "+", "sub_words", "[", ":", "max_length", "-", "2", "]", "+", "[", "'[SEP]'", "]", "\n", "input_ids_", "=", "torch", ".", "tensor", "(", "[", "tokenizer_mlm", ".", "convert_tokens_to_ids", "(", "sub_words", ")", "]", ")", "\n", "word_predictions", "=", "mlm_model", "(", "input_ids_", ".", "to", "(", "'cuda'", ")", ")", "[", "0", "]", ".", "squeeze", "(", ")", "# seq-len(sub) vocab", "\n", "word_pred_scores_all", ",", "word_predictions", "=", "torch", ".", "topk", "(", "\n", "word_predictions", ",", "k", ",", "-", "1", ")", "# seq-len k", "\n", "\n", "word_predictions", "=", "word_predictions", "[", "1", ":", "len", "(", "sub_words", ")", "+", "1", ",", ":", "]", "\n", "word_pred_scores_all", "=", "word_pred_scores_all", "[", "1", ":", "len", "(", "sub_words", ")", "+", "1", ",", ":", "]", "\n", "\n", "\n", "important_scores", "=", "get_important_scores", "(", "words", ",", "tgt_model", ",", "target_label", ",", "feature", ".", "label", ",", "orig_probs", ",", "\n", "attack_type", ",", "tgt_type", ",", "batch_size", ",", "max_length", ")", "\n", "\n", "feature", ".", "query", "+=", "int", "(", "len", "(", "words", ")", ")", "\n", "list_of_index", "=", "sorted", "(", "enumerate", "(", "important_scores", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "final_words", "=", "copy", ".", "deepcopy", "(", "words", ")", "\n", "\n", "for", "top_index", "in", "list_of_index", ":", "\n", "        ", "if", "feature", ".", "change", ">", "int", "(", "change_threshold", "*", "(", "len", "(", "words", ")", ")", ")", ":", "\n", "            ", "feature", ".", "success", "=", "1", "# exceed", "\n", "return", "feature", "\n", "\n", "", "tgt_word", "=", "words", "[", "top_index", "[", "0", "]", "]", "\n", "if", "tgt_word", "in", "filter_words", ":", "\n", "            ", "continue", "\n", "", "if", "keys", "[", "top_index", "[", "0", "]", "]", "[", "0", "]", ">", "max_length", "-", "2", ":", "\n", "            ", "continue", "\n", "\n", "", "substitutes", "=", "word_predictions", "[", "keys", "[", "top_index", "[", "0", "]", "]", "\n", "[", "0", "]", ":", "keys", "[", "top_index", "[", "0", "]", "]", "[", "1", "]", "]", "\n", "word_pred_scores", "=", "word_pred_scores_all", "[", "keys", "[", "top_index", "[", "0", "]", "]", "\n", "[", "0", "]", ":", "keys", "[", "top_index", "[", "0", "]", "]", "[", "1", "]", "]", "\n", "\n", "substitutes", "=", "get_substitues", "(", "\n", "substitutes", ",", "tokenizer_mlm", ",", "mlm_model", ",", "use_bpe", ",", "word_pred_scores", ",", "threshold_pred_score", ")", "\n", "\n", "most_gap", "=", "0.0", "\n", "candidate", "=", "None", "\n", "\n", "for", "substitute_", "in", "substitutes", ":", "\n", "            ", "substitute", "=", "substitute_", "\n", "\n", "if", "substitute", "==", "tgt_word", ":", "\n", "                ", "continue", "# filter out original word", "\n", "", "if", "'##'", "in", "substitute", ":", "\n", "                ", "continue", "# filter out sub-word", "\n", "\n", "", "if", "substitute", "in", "filter_words", ":", "\n", "                ", "continue", "\n", "", "if", "substitute", "in", "w2i", "and", "tgt_word", "in", "w2i", ":", "\n", "                ", "if", "cos_mat", "[", "w2i", "[", "substitute", "]", "]", "[", "w2i", "[", "tgt_word", "]", "]", "<", "0.4", ":", "\n", "                    ", "continue", "\n", "", "", "temp_replace", "=", "final_words", "\n", "temp_replace", "[", "top_index", "[", "0", "]", "]", "=", "substitute", "\n", "temp_text", "=", "tgt_model", ".", "tokenizer", ".", "convert_tokens_to_string", "(", "temp_replace", ")", "\n", "\n", "if", "tgt_type", "==", "'axml'", ":", "\n", "                ", "temp_text", "=", "_special_char_axml", "(", "[", "temp_text", "]", ")", "[", "0", "]", "\n", "", "_", ",", "temp_logits", "=", "tgt_model", ".", "predict", "(", "[", "temp_text", "]", ",", "[", "feature", ".", "label", "]", ",", "max_length", ")", "\n", "temp_logits", "=", "temp_logits", "[", "0", "]", "\n", "\n", "feature", ".", "query", "+=", "1", "\n", "temp_prob", "=", "torch", ".", "sigmoid", "(", "temp_logits", ")", ".", "squeeze", "(", ")", "\n", "_", ",", "temp_label", "=", "torch", ".", "topk", "(", "temp_prob", ",", "top", ")", "\n", "\n", "if", "attack_type", "==", "'A_pos'", ":", "\n", "                ", "terminate_condition", "=", "target_label", "not", "in", "temp_label", "\n", "", "if", "attack_type", "==", "'A_neg'", ":", "\n", "                ", "terminate_condition", "=", "target_label", "in", "temp_label", "\n", "\n", "", "if", "terminate_condition", ":", "\n", "                ", "feature", ".", "change", "+=", "1", "\n", "final_words", "[", "top_index", "[", "0", "]", "]", "=", "substitute", "\n", "feature", ".", "changes", ".", "append", "(", "\n", "[", "keys", "[", "top_index", "[", "0", "]", "]", "[", "0", "]", ",", "substitute", ",", "tgt_word", "]", ")", "\n", "feature", ".", "final_adverse", "=", "temp_text", "\n", "feature", ".", "success", "=", "4", "\n", "\n", "_", ",", "adv_label", "=", "torch", ".", "sort", "(", "temp_prob", ",", "descending", "=", "True", ")", "\n", "adv_label", "=", "adv_label", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "feature", ".", "adv_label", "=", "adv_label", "[", ":", "10", "]", "\n", "feature", ".", "adv_label_str", "=", "[", "label_rev_map", "[", "label", "]", "for", "label", "in", "feature", ".", "adv_label", "]", "\n", "\n", "return", "feature", "\n", "\n", "", "else", ":", "\n", "                ", "if", "attack_type", "==", "'A_both'", "or", "attack_type", "==", "'A_neg'", ":", "\n", "                    ", "gap_pos", "=", "0", "\n", "gap_neg", "=", "temp_prob", "[", "target_label", "]", "-", "orig_probs", "[", "target_label", "]", "\n", "\n", "", "if", "attack_type", "==", "'A_pos'", ":", "\n", "                    ", "gap_pos", "=", "orig_probs", "[", "target_label", "]", "-", "temp_prob", "[", "target_label", "]", "\n", "gap_neg", "=", "0", "\n", "\n", "", "gap", "=", "gap_pos", "+", "gap_neg", "\n", "\n", "if", "gap", ">", "most_gap", ":", "\n", "                    ", "most_gap", "=", "gap", "\n", "candidate", "=", "substitute", "\n", "\n", "", "", "", "if", "most_gap", ">", "0", ":", "\n", "            ", "feature", ".", "change", "+=", "1", "\n", "feature", ".", "changes", ".", "append", "(", "\n", "[", "keys", "[", "top_index", "[", "0", "]", "]", "[", "0", "]", ",", "candidate", ",", "tgt_word", "]", ")", "\n", "# current_prob = current_prob - most_gap", "\n", "final_words", "[", "top_index", "[", "0", "]", "]", "=", "candidate", "\n", "\n", "", "", "feature", ".", "final_adverse", "=", "(", "tgt_model", ".", "tokenizer", ".", "convert_tokens_to_string", "(", "final_words", ")", ")", "\n", "\n", "\n", "_", ",", "adv_label", "=", "torch", ".", "sort", "(", "temp_prob", ",", "descending", "=", "True", ")", "\n", "adv_label", "=", "adv_label", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "feature", ".", "adv_label", "=", "adv_label", "[", ":", "10", "]", "\n", "feature", ".", "adv_label_str", "=", "[", "label_rev_map", "[", "label", "]", "for", "label", "in", "feature", ".", "adv_label", "]", "\n", "feature", ".", "success", "=", "2", "\n", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.evaluate": [[378, 464], ["float", "float", "print", "USE", "len", "super().__init__", "hub.Module", "tf.ConfigProto", "tf.Session", "adv_xmtc..build_graph", "adv_xmtc..sess.run", "tf.placeholder", "tf.placeholder", "tf.nn.l2_normalize", "tf.nn.l2_normalize", "tf.reduce_sum", "tf.clip_by_value", "adv_xmtc..sess.run", "feat.seq.split", "float", "adv_xmtc..embed", "adv_xmtc..embed", "tf.multiply", "tf.acos", "s.lower", "s.lower", "USE.semantic_sim", "tf.global_variables_initializer", "tf.tables_initializer"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["", "def", "evaluate", "(", "features", ")", ":", "# mohamm: read it and change it for multilabel", "\n", "    ", "do_use", "=", "1", "\n", "use", "=", "None", "\n", "sim_thres", "=", "0", "\n", "# evaluate with USE", "\n", "\n", "if", "do_use", "==", "1", ":", "\n", "        ", "cache_path", "=", "'https://tfhub.dev/google/universal-sentence-encoder-large/3'", "\n", "import", "tensorflow", "as", "tf", "\n", "import", "tensorflow_hub", "as", "hub", "\n", "\n", "class", "USE", "(", "object", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "cache_path", ")", ":", "\n", "                ", "super", "(", "USE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embed", "=", "hub", ".", "Module", "(", "cache_path", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "self", ".", "build_graph", "(", ")", "\n", "self", ".", "sess", ".", "run", "(", "\n", "[", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "tables_initializer", "(", ")", "]", ")", "\n", "\n", "", "def", "build_graph", "(", "self", ")", ":", "\n", "                ", "self", ".", "sts_input1", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ")", ")", "\n", "self", ".", "sts_input2", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ")", ")", "\n", "\n", "sts_encode1", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "\n", "self", ".", "embed", "(", "self", ".", "sts_input1", ")", ",", "axis", "=", "1", ")", "\n", "sts_encode2", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "\n", "self", ".", "embed", "(", "self", ".", "sts_input2", ")", ",", "axis", "=", "1", ")", "\n", "self", ".", "cosine_similarities", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "sts_encode1", ",", "sts_encode2", ")", ",", "axis", "=", "1", ")", "\n", "clip_cosine_similarities", "=", "tf", ".", "clip_by_value", "(", "\n", "self", ".", "cosine_similarities", ",", "-", "1.0", ",", "1.0", ")", "\n", "self", ".", "sim_scores", "=", "1.0", "-", "tf", ".", "acos", "(", "clip_cosine_similarities", ")", "\n", "\n", "", "def", "semantic_sim", "(", "self", ",", "sents1", ",", "sents2", ")", ":", "\n", "                ", "sents1", "=", "[", "s", ".", "lower", "(", ")", "for", "s", "in", "sents1", "]", "\n", "sents2", "=", "[", "s", ".", "lower", "(", ")", "for", "s", "in", "sents2", "]", "\n", "scores", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "sim_scores", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "sts_input1", ":", "sents1", ",", "\n", "self", ".", "sts_input2", ":", "sents2", ",", "\n", "}", ")", "\n", "return", "scores", "[", "0", "]", "\n", "\n", "", "", "use", "=", "USE", "(", "cache_path", ")", "\n", "\n", "", "acc", "=", "0", "\n", "origin_success", "=", "0", "\n", "total", "=", "0", "\n", "total_q", "=", "0", "\n", "total_change", "=", "0", "\n", "total_word", "=", "0", "\n", "\n", "for", "feat", "in", "features", ":", "\n", "        ", "if", "feat", ".", "success", "!=", "2", ":", "\n", "            ", "total", "+=", "1", "\n", "total_change", "+=", "feat", ".", "change", "\n", "total_word", "+=", "len", "(", "feat", ".", "seq", ".", "split", "(", "' '", ")", ")", "\n", "\n", "if", "do_use", "==", "1", ":", "\n", "                    ", "sim", "=", "float", "(", "use", ".", "semantic_sim", "(", "[", "feat", ".", "seq", "]", ",", "[", "feat", ".", "final_adverse", "]", ")", ")", "\n", "feat", ".", "sim", "=", "sim", "\n", "\n", "", "if", "feat", ".", "success", ">", "2", ":", "\n", "                ", "acc", "+=", "1", "\n", "\n", "if", "feat", ".", "success", "==", "3", ":", "\n", "                    ", "origin_success", "+=", "1", "\n", "\n", "", "", "", "", "suc", "=", "float", "(", "acc", "/", "total", ")", "\n", "\n", "change_rate", "=", "float", "(", "total_change", "/", "total_word", ")", "\n", "\n", "origin_acc", "=", "1", "-", "origin_success", "/", "total", "\n", "after_atk", "=", "1", "-", "suc", "\n", "\n", "print", "(", "'acc/aft-atk-acc {:.6f}/ {:.6f}, change-rate {:.4f}'", ".", "format", "(", "\n", "origin_acc", ",", "after_atk", ",", "change_rate", ")", ")", "\n", "\n", "eval_results", "=", "{", "'origin_acc'", ":", "origin_acc", ",", "'after_atk'", ":", "after_atk", ",", "'change_rate'", ":", "change_rate", "}", "\n", "\n", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.dump_features": [[466, 495], ["outputs.append", "json.dump", "print", "list", "list", "outputs.append", "open", "map", "map", "len", "feature.seq.split"], "function", ["None"], ["", "def", "dump_features", "(", "features", ",", "output", ",", "origin_acc", ",", "after_atk", ",", "change_rate", ")", ":", "\n", "    ", "outputs", "=", "[", "]", "\n", "\n", "for", "feature", "in", "features", ":", "\n", "        ", "changes", "=", "[", "]", "\n", "list", "(", "map", "(", "changes", ".", "extend", ",", "feature", ".", "changes", ")", ")", "\n", "changes", "=", "list", "(", "map", "(", "str", ",", "changes", ")", ")", "\n", "changes", "=", "\", \"", ".", "join", "(", "changes", ")", "\n", "outputs", ".", "append", "(", "{", "'true label'", ":", "', '", ".", "join", "(", "feature", ".", "label_str", ")", ",", "\n", "'pred label'", ":", "', '", ".", "join", "(", "feature", ".", "pred_label_str", ")", ",", "\n", "'adv label'", ":", "', '", ".", "join", "(", "feature", ".", "adv_label_str", ")", ",", "\n", "'target label'", ":", "feature", ".", "target_label_str", ",", "\n", "'success'", ":", "feature", ".", "success", ",", "\n", "'sim'", ":", "feature", ".", "sim", ",", "\n", "'change'", ":", "feature", ".", "change", ",", "\n", "'num_word'", ":", "len", "(", "feature", ".", "seq", ".", "split", "(", "' '", ")", ")", ",", "\n", "'query'", ":", "feature", ".", "query", ",", "\n", "'changes'", ":", "changes", ",", "\n", "'seq_a'", ":", "feature", ".", "seq", ",", "\n", "'adv'", ":", "feature", ".", "final_adverse", "\n", "}", ")", "\n", "", "outputs", ".", "append", "(", "{", "'original acc'", ":", "origin_acc", ",", "\n", "'attack acc'", ":", "after_atk", ",", "\n", "'change_rate'", ":", "change_rate", "\n", "}", ")", "\n", "output_json", "=", "output", "\n", "json", ".", "dump", "(", "outputs", ",", "open", "(", "output_json", ",", "'w'", ")", ",", "indent", "=", "2", ")", "\n", "\n", "print", "(", "'finished dump'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.run_attack": [[497, 608], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.task_name.lower", "str", "str", "str", "print", "transformers.BertTokenizer.from_pretrained", "transformers.BertConfig.from_pretrained", "transformers.BertForMaskedLM.from_pretrained", "BertForMaskedLM.from_pretrained.to", "processor.get_labels", "processor.get_dev_examples", "print", "print", "print", "adv_xmtc.evaluate", "ValueError", "utils.AplcXlnetModel", "utils.AttentionXmlModel", "os.path.dirname", "adv_xmtc.get_sim_embed", "os.path.exists", "os.makedirs", "torch.no_grad", "torch.no_grad", "enumerate", "adv_xmtc.dump_features", "enumerate", "label_map.items", "os.path.dirname", "os.path.dirname", "str", "adv_xmtc.Feature", "adv_xmtc.attack", "features_output.append", "print", "adv_xmtc.evaluate", "label.append", "adv_xmtc.dump_features", "print"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor.get_labels", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor.get_dev_examples", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.evaluate", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.get_sim_embed", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.dump_features", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.attack", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.evaluate", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.None.adv_xmtc.dump_features"], ["", "def", "run_attack", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlm_path\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt_path\"", ",", "type", "=", "str", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--output_path\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_sim_mat\"", ",", "type", "=", "int", ",", "\n", "help", "=", "'whether use cosine_similarity to filter out atonyms'", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_bpe\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "default", "=", "48", ",", "help", "=", "'number of candidates'", ")", "\n", "parser", ".", "add_argument", "(", "\"--threshold_pred_score\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--pos_label\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--top\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"threshold for prediction\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_name\"", ",", "type", "=", "str", ",", "default", "=", "\"dev.csv\"", ",", "help", "=", "\"name of the evaluation file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--attack_type\"", ",", "type", "=", "str", ",", "help", "=", "\"it can be A_both, A_pos, or A_neg\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--change_threshold\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"determines the rate of allowed changes. The lower, the less changes.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt_type\"", ",", "type", "=", "str", ",", "help", "=", "\"type of attacked classifier (axml or aplc)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pos_samples\"", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"number of tageted samples for A_pos\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "mlm_path", "=", "str", "(", "args", ".", "mlm_path", ")", "\n", "tgt_path", "=", "str", "(", "args", ".", "tgt_path", ")", "\n", "output_path", "=", "str", "(", "args", ".", "output_path", ")", "\n", "use_bpe", "=", "args", ".", "use_bpe", "\n", "k", "=", "args", ".", "k", "\n", "max_seq_length", "=", "args", ".", "max_seq_length", "\n", "threshold_pred_score", "=", "args", ".", "threshold_pred_score", "\n", "top", "=", "args", ".", "top", "\n", "attack_type", "=", "args", ".", "attack_type", "\n", "change_threshold", "=", "args", ".", "change_threshold", "\n", "tgt_type", "=", "args", ".", "tgt_type", "\n", "data_dir", "=", "args", ".", "data_dir", "\n", "pos_samples", "=", "args", ".", "pos_samples", "\n", "dev_name", "=", "args", ".", "dev_name", "\n", "\n", "if", "tgt_type", "not", "in", "TGT_MODEL_TYPES", ":", "\n", "        ", "raise", "ValueError", "(", "F'Unknown model type: {tgt_type}'", ")", "\n", "\n", "", "print", "(", "'start process'", ")", "\n", "\n", "tokenizer_mlm", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "mlm_path", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "config_atk", "=", "BertConfig", ".", "from_pretrained", "(", "mlm_path", ")", "\n", "mlm_model", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "mlm_path", ",", "config", "=", "config_atk", ")", "\n", "mlm_model", ".", "to", "(", "'cuda'", ")", "\n", "\n", "tgt_model", "=", "AplcXlnetModel", "(", "tgt_path", ")", "if", "tgt_type", "==", "'aplc'", "else", "AttentionXmlModel", "(", "tgt_path", ")", "\n", "\n", "processor", "=", "processors", "[", "task_name", "]", "(", ")", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", "os", ".", "path", ".", "dirname", "(", "data_dir", ")", ")", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "label_rev_map", "=", "{", "i", ":", "label", "for", "label", ",", "i", "in", "label_map", ".", "items", "(", ")", "}", "\n", "\n", "\n", "examples", "=", "processor", ".", "get_dev_examples", "(", "data_dir", ",", "dev_name", "=", "dev_name", ")", "\n", "\n", "print", "(", "'loading sim-embed'", ")", "\n", "\n", "if", "args", ".", "use_sim_mat", "==", "1", ":", "\n", "        ", "cos_mat", ",", "w2i", ",", "i2w", "=", "get_sim_embed", "(", "\n", "'data_defense/counter-fitted-vectors.txt'", ",", "'data_defense/cos_sim_counter_fitting.npy'", ")", "\n", "", "else", ":", "\n", "        ", "cos_mat", ",", "w2i", ",", "i2w", "=", "None", ",", "{", "}", ",", "{", "}", "\n", "\n", "", "print", "(", "'finish get-sim-embed'", ")", "\n", "features_output", "=", "[", "]", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "dirname", "(", "output_path", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "output_path", ")", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "index", ",", "example", "in", "enumerate", "(", "examples", ")", ":", "\n", "\n", "            ", "label", "=", "[", "]", "\n", "for", "item", "in", "example", ".", "label", ":", "\n", "                ", "try", ":", "\n", "                    ", "label", ".", "append", "(", "label_map", "[", "item", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                    ", "print", "(", "F'label \"{item}\" not found'", ")", "\n", "", "", "target_label_str", "=", "str", "(", "example", ".", "target_label", ")", "\n", "target_label", "=", "label_map", "[", "target_label_str", "]", "\n", "feat", "=", "Feature", "(", "example", ".", "text_a", ",", "label", ",", "example", ".", "label", ",", "target_label", ",", "target_label_str", ")", "\n", "\n", "feat", "=", "attack", "(", "feat", ",", "tgt_model", ",", "mlm_model", ",", "tokenizer_mlm", ",", "k", ",", "label_rev_map", ",", "attack_type", ",", "tgt_type", ",", "change_threshold", ",", "batch_size", "=", "32", ",", "max_length", "=", "max_seq_length", ",", "cos_mat", "=", "cos_mat", ",", "w2i", "=", "w2i", ",", "i2w", "=", "i2w", ",", "use_bpe", "=", "use_bpe", ",", "threshold_pred_score", "=", "threshold_pred_score", ",", "top", "=", "top", ")", "\n", "\n", "if", "feat", ".", "success", ">", "-", "1", ":", "\n", "                ", "features_output", ".", "append", "(", "feat", ")", "\n", "", "if", "(", "index", "+", "1", ")", "%", "5", "==", "0", ":", "\n", "                ", "print", "(", "F'Running evalution for {index+1} samples'", ")", "\n", "eval_results", "=", "evaluate", "(", "features_output", ")", "\n", "if", "features_output", "!=", "[", "]", ":", "\n", "                    ", "dump_features", "(", "features_output", ",", "output_path", ",", "**", "eval_results", ")", "\n", "", "", "if", "index", "+", "1", "==", "pos_samples", "and", "attack_type", "==", "'A_pos'", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "print", "(", "F'Running final evalution'", ")", "\n", "eval_results", "=", "evaluate", "(", "features_output", ")", "\n", "if", "features_output", "!=", "[", "]", ":", "\n", "        ", "dump_features", "(", "features_output", ",", "output_path", ",", "**", "eval_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.data_utils.A_pos_sample_selector": [[15, 63], ["zip", "pandas.DataFrame", "enumerate", "pandas.DataFrame", "test_data.iterrows", "selected_data.keys", "selected_freqs.append", "numpy.unique().tolist", "selected_labels.extend", "len", "copy.deepcopy", "selected_data[].append", "selected_data_bins.append.sample", "str", "str", "os.path.join", "selected_data_bins.append.to_csv", "pandas.DataFrame", "data[].split", "numpy.unique", "selected_data_bins.append.append", "numpy.where", "numpy.array", "len"], "function", ["None"], ["def", "A_pos_sample_selector", "(", "test_data", ",", "labels_all", ",", "labels_freq_dict", ",", "labels_freq", ",", "pred_labels", ",", "data_path", ",", "bin_size", "=", "50", ")", ":", "\n", "\n", "\n", "# selecting samples which are classifed correctly for each frequency and each label", "\n", "    ", "selected_data", "=", "{", "freq", ":", "pd", ".", "DataFrame", "(", "[", "]", ",", "columns", "=", "[", "'id'", ",", "'text'", ",", "'label'", ",", "'target_label'", "]", ")", "for", "freq", "in", "labels_freq", "}", "\n", "for", "pred", ",", "data", "in", "zip", "(", "pred_labels", ",", "test_data", ".", "iterrows", "(", ")", ")", ":", "\n", "        ", "data", "=", "data", "[", "1", "]", "\n", "true_labels_index", "=", "[", "np", ".", "where", "(", "label", "==", "labels_all", ")", "[", "0", "]", "[", "0", "]", "for", "label", "in", "data", "[", "'label'", "]", ".", "split", "(", "','", ")", "if", "label", "in", "labels_all", "]", "\n", "\n", "selected_labels", "=", "[", "labels_all", "[", "label", "]", "for", "label", "in", "pred", "if", "label", "in", "true_labels_index", "]", "\n", "\n", "for", "target_label", "in", "selected_labels", ":", "\n", "            ", "data", "[", "'target_label'", "]", "=", "target_label", "\n", "freq", "=", "labels_freq_dict", "[", "target_label", "]", "\n", "data_copy", "=", "copy", ".", "deepcopy", "(", "data", ")", "\n", "selected_data", "[", "freq", "]", "=", "selected_data", "[", "freq", "]", ".", "append", "(", "data_copy", ")", "\n", "\n", "\n", "\n", "# split frequencies into different bins and write them", "\n", "", "", "selected_freqs", "=", "[", "]", "\n", "selected_labels", "=", "[", "]", "\n", "selected_data_bins", "=", "pd", ".", "DataFrame", "(", "[", "]", ",", "columns", "=", "[", "'id'", ",", "'text'", ",", "'label'", ",", "'target_label'", "]", ")", "\n", "selected_labels_bins", "=", "{", "}", "# store selected labels for each bin (will be used in A_neg_sample_selector)", "\n", "\n", "for", "i", ",", "freq", "in", "enumerate", "(", "selected_data", ".", "keys", "(", ")", ")", ":", "\n", "        ", "selected_freqs", ".", "append", "(", "freq", ")", "\n", "target_labels", "=", "np", ".", "unique", "(", "np", ".", "array", "(", "selected_data", "[", "freq", "]", "[", "'target_label'", "]", ")", ")", ".", "tolist", "(", ")", "\n", "selected_labels", ".", "extend", "(", "target_labels", ")", "\n", "selected_labels_len", "=", "len", "(", "selected_labels", ")", "\n", "if", "selected_labels_len", ">=", "bin_size", "or", "i", "==", "len", "(", "selected_data", ")", "-", "1", ":", "\n", "            ", "for", "f", "in", "selected_freqs", ":", "\n", "                ", "selected_data_bins", "=", "selected_data_bins", ".", "append", "(", "selected_data", "[", "f", "]", ")", "\n", "", "selected_data_bins", "=", "selected_data_bins", ".", "sample", "(", "frac", "=", "1", ")", "# random shuffling", "\n", "start_freq", "=", "str", "(", "selected_freqs", "[", "0", "]", ")", "\n", "end_freq", "=", "str", "(", "selected_freqs", "[", "-", "1", "]", ")", "\n", "write_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "F'freq_{start_freq}_{end_freq}_pos.csv'", ")", "\n", "selected_data_bins", ".", "to_csv", "(", "write_path", ",", "index", "=", "False", ")", "\n", "\n", "bin_key", "=", "F'{start_freq}_{end_freq}'", "\n", "selected_labels_bins", "[", "bin_key", "]", "=", "selected_labels", "\n", "\n", "selected_freqs", "=", "[", "]", "\n", "selected_labels", "=", "[", "]", "\n", "selected_data_bins", "=", "pd", ".", "DataFrame", "(", "[", "]", ",", "columns", "=", "[", "'id'", ",", "'text'", ",", "'label'", ",", "'target_label'", "]", ")", "\n", "\n", "\n", "", "", "return", "selected_labels_bins", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.data_utils.A_neg_sample_selector": [[68, 97], ["labels_sp.keys", "selected_data.keys", "pandas.DataFrame", "labels_sp.keys", "len", "numpy.arange", "numpy.random.shuffle", "zip", "os.path.join", "selected_data[].to_csv", "len", "test_data.iterrows", "list", "copy.deepcopy", "selected_data[].append", "len", "int", "data[].split", "numpy.where", "numpy.random.randint", "numpy.where", "len"], "function", ["None"], ["", "def", "A_neg_sample_selector", "(", "test_data", ",", "labels_all", ",", "labels_sp", ",", "labels_freq", ",", "pred_labels", ",", "data_path", ",", "max_samples", "=", "10", ")", ":", "\n", "\n", "    ", "selected_data", "=", "{", "freq", ":", "pd", ".", "DataFrame", "(", "[", "]", ",", "columns", "=", "[", "'id'", ",", "'text'", ",", "'label'", ",", "'target_label'", "]", ")", "for", "freq", "in", "labels_sp", ".", "keys", "(", ")", "}", "\n", "for", "freq", "in", "labels_sp", ".", "keys", "(", ")", ":", "\n", "        ", "if", "len", "(", "labels_sp", "[", "freq", "]", ")", ">", "0", ":", "\n", "            ", "random_idx", "=", "np", ".", "arange", "(", "len", "(", "test_data", ")", ")", "# random shuffling", "\n", "np", ".", "random", ".", "shuffle", "(", "random_idx", ")", "\n", "pred_labels", "=", "pred_labels", "[", "random_idx", ",", ":", "]", "\n", "test_data", "=", "test_data", ".", "loc", "[", "random_idx", ",", ":", "]", "\n", "for", "pred", ",", "data", "in", "zip", "(", "pred_labels", ",", "test_data", ".", "iterrows", "(", ")", ")", ":", "\n", "                ", "data", "=", "data", "[", "1", "]", "\n", "\n", "target_labels_list", "=", "list", "(", "labels_sp", "[", "freq", "]", ")", "\n", "# target label is selected randomly from the specified frequency", "\n", "target_label", "=", "target_labels_list", "[", "int", "(", "np", ".", "random", ".", "randint", "(", "len", "(", "labels_sp", "[", "freq", "]", ")", ",", "size", "=", "1", ")", ")", "]", "\n", "true_labels_index", "=", "[", "np", ".", "where", "(", "label", "==", "labels_all", ")", "[", "0", "]", "[", "0", "]", "for", "label", "in", "data", "[", "'label'", "]", ".", "split", "(", "','", ")", "if", "label", "in", "labels_all", "]", "\n", "target_label_index", "=", "np", ".", "where", "(", "target_label", "==", "labels_all", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "if", "target_label_index", "not", "in", "true_labels_index", "and", "target_label_index", "not", "in", "pred", ":", "\n", "                    ", "data", "[", "'target_label'", "]", "=", "target_label", "\n", "data_copy", "=", "copy", ".", "deepcopy", "(", "data", ")", "\n", "selected_data", "[", "freq", "]", "=", "selected_data", "[", "freq", "]", ".", "append", "(", "data_copy", ")", "\n", "", "if", "len", "(", "selected_data", "[", "freq", "]", ")", ">=", "max_samples", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "", "for", "freq", "in", "selected_data", ".", "keys", "(", ")", ":", "\n", "        ", "if", "not", "selected_data", "[", "freq", "]", ".", "empty", ":", "\n", "            ", "write_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "F'freq_{freq}_neg.csv'", ")", "\n", "selected_data", "[", "freq", "]", ".", "to_csv", "(", "write_path", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.data_utils.main": [[99, 171], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "os.path.join", "os.path.join", "numpy.array", "print", "pandas.read_csv", "numpy.array", "pd.read_csv.iterrows", "numpy.unique", "dict", "numpy.unique", "numpy.setdiff1d", "print", "pandas.read_csv().dropna().reset_index", "list", "list", "enumerate", "print", "model.predict", "torch.cat", "print", "data_utils.A_pos_sample_selector", "print", "data_utils.A_neg_sample_selector", "os.path.exists", "os.makedirs", "os.path.dirname", "os.path.dirname", "os.path.dirname", "open", "f.read().split", "row[].split", "labels_unique.extend", "zip", "numpy.array", "sample_labels_index.extend", "aplc_scripts.AplcXlnetModel", "axml_scripts.AttentionXmlModel", "list", "pandas.read_csv().dropna", "f.read", "dict.keys", "row[].split.split", "pandas.read_csv", "range", "numpy.where", "len"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel.predict", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.data_utils.A_pos_sample_selector", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.data_utils.A_neg_sample_selector"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--pos_label'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "'number of positive labels (for APLC_XLNet)'", ")", "\n", "parser", ".", "add_argument", "(", "'--top'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'determines number of predicted labels'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_neg_samples'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'maximum number of targeted samples for each label in A_neg'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_seq_length'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'500 for axml and 512 for aplc'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "type", "=", "str", ",", "help", "=", "'data path to store the selected samples for each bin'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--model_type'", ",", "type", "=", "str", ",", "help", "=", "'aplc or axml'", ")", "\n", "parser", ".", "add_argument", "(", "'--bin_size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'minimum number of labels per bin'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "pos_label", "=", "args", ".", "pos_label", "\n", "top", "=", "args", ".", "top", "\n", "max_neg_samples", "=", "args", ".", "max_neg_samples", "\n", "data_path", "=", "args", ".", "data_path", "\n", "model_path", "=", "args", ".", "model_path", "\n", "model_type", "=", "args", ".", "model_type", "\n", "max_seq_length", "=", "args", ".", "max_seq_length", "\n", "bin_size", "=", "args", ".", "bin_size", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "data_path", ")", "\n", "\n", "", "label_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "data_path", ")", ",", "'labels.txt'", ")", "\n", "train_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "data_path", ")", ",", "'train.csv'", ")", "\n", "dev_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "data_path", ")", ",", "'dev.csv'", ")", "\n", "\n", "with", "open", "(", "label_path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "labels", "=", "f", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "# computing the frequency of labels", "\n", "print", "(", "'computing the frequency of labels'", ")", "\n", "train_data", "=", "pd", ".", "read_csv", "(", "train_path", ")", "\n", "labels_unique", "=", "[", "]", "\n", "labels_freq", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "i", ",", "row", "in", "train_data", ".", "iterrows", "(", ")", ":", "\n", "        ", "sample_labels", "=", "row", "[", "'label'", "]", ".", "split", "(", "','", ")", "\n", "labels_unique", ".", "extend", "(", "sample_labels", ")", "\n", "\n", "", "labels_unique", ",", "labels_freq", "=", "np", ".", "unique", "(", "labels_unique", ",", "return_counts", "=", "True", ")", "\n", "labels_freq_dict", "=", "dict", "(", "zip", "(", "labels_unique", ",", "labels_freq", ")", ")", "\n", "labels_freq", "=", "np", ".", "unique", "(", "labels_freq", ")", "\n", "\n", "diff_labels", "=", "np", ".", "setdiff1d", "(", "labels", ",", "np", ".", "array", "(", "list", "(", "labels_freq_dict", ".", "keys", "(", ")", ")", ")", ")", "# set labels with zero frequency", "\n", "for", "label", "in", "diff_labels", ":", "\n", "        ", "labels_freq_dict", "[", "label", "]", "=", "0", "\n", "\n", "\n", "# selecting all samples for prediction", "\n", "", "print", "(", "'selecting all samples for prediction'", ")", "\n", "test_data", "=", "pd", ".", "read_csv", "(", "dev_path", ")", ".", "dropna", "(", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "selected_texts", "=", "list", "(", "test_data", "[", "'text'", "]", ")", "\n", "selected_labels", "=", "list", "(", "test_data", "[", "'label'", "]", ")", "\n", "\n", "for", "i", ",", "sample_labels", "in", "enumerate", "(", "selected_labels", ")", ":", "\n", "        ", "sample_labels_index", "=", "[", "np", ".", "where", "(", "labels", "==", "label", ")", "[", "0", "]", "[", "0", "]", "if", "label", "in", "labels", "else", "\n", "labels", ".", "size", "for", "label", "in", "sample_labels", ".", "split", "(", "','", ")", "]", "\n", "sample_labels_index", ".", "extend", "(", "[", "sample_labels_index", "[", "0", "]", "for", "i", "in", "range", "(", "pos_label", "-", "len", "(", "sample_labels_index", ")", ")", "]", ")", "\n", "selected_labels", "[", "i", "]", "=", "sample_labels_index", "\n", "\n", "", "print", "(", "'evaluating all the test samples'", ")", "\n", "model", "=", "AplcXlnetModel", "(", "model_path", ")", "if", "model_type", "==", "'aplc'", "else", "AttentionXmlModel", "(", "model_path", ",", "data_path", ")", "\n", "_", ",", "pred_labels", "=", "model", ".", "predict", "(", "selected_texts", ",", "selected_labels", ",", "max_seq_length", ",", "return_logits", "=", "False", ",", "top", "=", "top", ",", "batch_size", "=", "12", ",", "ver", "=", "True", ")", "\n", "pred_labels", "=", "torch", ".", "cat", "(", "pred_labels", ",", "dim", "=", "0", ")", "\n", "\n", "print", "(", "'selecting samples for A_pos'", ")", "\n", "selected_labels_pos", "=", "A_pos_sample_selector", "(", "test_data", ",", "labels", ",", "labels_freq_dict", ",", "labels_freq", ",", "pred_labels", ",", "data_path", ",", "bin_size", ")", "\n", "print", "(", "'selecting samples for A_neg'", ")", "\n", "A_neg_sample_selector", "(", "test_data", ",", "labels", ",", "selected_labels_pos", ",", "labels_freq", ",", "pred_labels", ",", "data_path", ",", "max_neg_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.plot_results.result_extractor": [[8, 53], ["dict", "dict", "dict", "dict", "os.path.join", "sorted", "sorted", "sorted", "sorted", "int", "open", "json.load", "dict.items", "dict.items", "dict.items", "dict.items", "print", "len", "len", "f.split"], "function", ["None"], ["def", "result_extractor", "(", "files", ",", "results_path", ")", ":", "\n", "    ", "acc", "=", "{", "}", "\n", "change", "=", "{", "}", "\n", "sim", "=", "{", "}", "\n", "acc_sim", "=", "{", "}", "\n", "change_hit_dict", "=", "{", "}", "\n", "for", "f", "in", "files", ":", "\n", "        ", "try", ":", "\n", "            ", "freq", "=", "int", "(", "f", ".", "split", "(", "'_'", ")", "[", "2", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "print", "(", "'value error'", ")", "\n", "continue", "\n", "", "f_path", "=", "os", ".", "path", ".", "join", "(", "results_path", ",", "f", ")", "\n", "with", "open", "(", "f_path", ",", "'r'", ")", "as", "f_t", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f_t", ")", "\n", "", "sim_avg", "=", "0", "\n", "hit", "=", "0", "\n", "hit_sim", "=", "0", "\n", "change_hit", "=", "0", "\n", "num_word_hit", "=", "0", "\n", "for", "res", "in", "data", "[", ":", "-", "1", "]", ":", "\n", "            ", "if", "res", "[", "'change'", "]", "/", "res", "[", "'num_word'", "]", "<=", "0.1", ":", "# compute metrics for change rate less than 0.1", "\n", "                ", "if", "res", "[", "'success'", "]", "==", "4", ":", "\n", "                    ", "change_hit", "+=", "res", "[", "'change'", "]", "\n", "num_word_hit", "+=", "res", "[", "'num_word'", "]", "\n", "sim_avg", "=", "res", "[", "'sim'", "]", "+", "sim_avg", "\n", "hit", "+=", "1", "\n", "if", "res", "[", "'sim'", "]", ">", "0.8", ":", "\n", "                        ", "hit_sim", "+=", "1", "\n", "\n", "", "", "", "", "sim", "[", "freq", "]", "=", "sim_avg", "/", "hit", "\n", "acc", "[", "freq", "]", "=", "(", "hit", "/", "len", "(", "data", "[", ":", "-", "1", "]", ")", ")", "*", "100.0", "\n", "acc_sim", "[", "freq", "]", "=", "(", "hit_sim", "/", "len", "(", "data", "[", ":", "-", "1", "]", ")", ")", "*", "100.0", "\n", "\n", "change_hit_dict", "[", "freq", "]", "=", "(", "change_hit", "/", "num_word_hit", ")", "*", "100.0", "\n", "\n", "", "acc", "=", "dict", "(", "sorted", "(", "acc", ".", "items", "(", ")", ")", ")", "\n", "# change = dict(sorted(change.items()))", "\n", "change", "=", "1", "\n", "acc_sim", "=", "dict", "(", "sorted", "(", "acc_sim", ".", "items", "(", ")", ")", ")", "\n", "sim", "=", "dict", "(", "sorted", "(", "sim", ".", "items", "(", ")", ")", ")", "\n", "\n", "change_hit_dict", "=", "dict", "(", "sorted", "(", "change_hit_dict", ".", "items", "(", ")", ")", ")", "\n", "\n", "return", "acc", ",", "change", ",", "change_hit_dict", ",", "acc_sim", ",", "sim", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.plot_results.main": [[57, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.listdir", "plot_results.result_extractor", "matplotlib.plot", "matplotlib.xscale", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.show", "list", "list", "pos_normal_acc_sim.keys", "pos_normal_acc_sim.values"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.results_all.result_extractor"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--result_path'", ",", "type", "=", "str", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "results_path_normal", "=", "args", ".", "result_path", "\n", "\n", "files_normal", "=", "os", ".", "listdir", "(", "results_path_normal", ")", "\n", "\n", "pos_normal_files", "=", "[", "f", "for", "f", "in", "files_normal", "if", "'pos'", "in", "f", "]", "\n", "\n", "pos_normal_acc", ",", "pos_normal_change", ",", "pos_normal_change_hit", ",", "pos_normal_acc_sim", ",", "pos_normal_sim", "=", "result_extractor", "(", "pos_normal_files", ",", "results_path_normal", ")", "\n", "\n", "\n", "\n", "plt", ".", "plot", "(", "list", "(", "pos_normal_acc_sim", ".", "keys", "(", ")", ")", ",", "list", "(", "pos_normal_acc_sim", ".", "values", "(", ")", ")", ",", "linewidth", "=", "2.0", ")", "\n", "plt", ".", "xscale", "(", "'log'", ")", "\n", "plt", ".", "xlabel", "(", "'Frequency'", ")", "\n", "plt", ".", "ylabel", "(", "'Success rate'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.results_all.result_extractor": [[8, 38], ["os.path.join", "enumerate", "open", "json.load"], "function", ["None"], ["def", "result_extractor", "(", "files", ",", "results_path", ",", "num_samples_per_file", ")", ":", "\n", "\n", "    ", "sim_avg", ",", "sim_avg_hit", ",", "total_change", ",", "total_word", ",", "hit", ",", "hit_sim", ",", "num_samples_total", ",", "num_samples_hit_sim", "=", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "\n", "for", "f", "in", "files", ":", "\n", "        ", "f_path", "=", "os", ".", "path", ".", "join", "(", "results_path", ",", "f", ")", "\n", "with", "open", "(", "f_path", ",", "'r'", ")", "as", "f_t", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f_t", ")", "\n", "\n", "", "for", "idx", ",", "res", "in", "enumerate", "(", "data", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "num_samples_total", "+=", "1", "\n", "if", "res", "[", "'change'", "]", "/", "res", "[", "'num_word'", "]", "<", "0.1", ":", "# compute metrics for change rate less than 0.1", "\n", "                ", "if", "res", "[", "'success'", "]", "==", "4", ":", "\n", "                    ", "sim_avg", "=", "res", "[", "'sim'", "]", "+", "sim_avg", "\n", "hit", "+=", "1", "\n", "total_change", "+=", "res", "[", "'change'", "]", "\n", "total_word", "+=", "res", "[", "'num_word'", "]", "\n", "if", "res", "[", "'sim'", "]", ">", "0.8", ":", "\n", "                        ", "hit_sim", "+=", "1", "\n", "sim_avg_hit", "=", "res", "[", "'sim'", "]", "+", "sim_avg_hit", "\n", "num_samples_hit_sim", "+=", "1", "\n", "", "", "", "if", "idx", "==", "num_samples_per_file", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "sim", "=", "sim_avg", "/", "num_samples_total", "\n", "# sim_08 = sim_avg_hit / num_samples_hit_sim", "\n", "acc", "=", "(", "hit", "/", "num_samples_total", ")", "*", "100.0", "\n", "acc_sim_08", "=", "(", "hit_sim", "/", "num_samples_total", ")", "*", "100.0", "\n", "change", "=", "(", "total_change", "/", "total_word", ")", "*", "100.0", "\n", "\n", "return", "acc", ",", "acc_sim_08", ",", "sim", ",", "change", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.results_all.main": [[42, 63], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.listdir", "results_all.result_extractor", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.utils.results_all.result_extractor"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--result_path'", ",", "type", "=", "str", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "results_path_normal", "=", "args", ".", "result_path", "\n", "\n", "num_samples_per_file", "=", "1000", "\n", "\n", "files_normal", "=", "os", ".", "listdir", "(", "results_path_normal", ")", "\n", "\n", "pos_normal_files", "=", "[", "f", "for", "f", "in", "files_normal", "if", "'pos'", "in", "f", "]", "\n", "\n", "acc", ",", "acc_sim_08", ",", "sim", ",", "change", "=", "result_extractor", "(", "pos_normal_files", ",", "results_path_normal", ",", "num_samples_per_file", ")", "\n", "\n", "print", "(", "F'Average success rate: {acc}'", ")", "\n", "print", "(", "F'Average success rate (when sim>0.8): {acc_sim_08}'", ")", "\n", "print", "(", "F'Average similarity: {sim}'", ")", "\n", "# print(F'Average similarity (when sim>0.8): {sim_08}')", "\n", "print", "(", "F'Average change rate: {change}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.axml_data_preprocess.preprocess": [[7, 28], ["enumerate", "pandas.DataFrame", "pd.DataFrame.to_csv", "open", "f.read().split", "open", "f.read().split", "zip", "new_data.append", "label.split", "f.read", "f.read"], "function", ["None"], ["def", "preprocess", "(", "data_path", ",", "label_path", ",", "write_path", ")", ":", "\n", "    ", "with", "open", "(", "data_path", ")", "as", "f", ":", "\n", "        ", "data", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "data", "=", "data", "[", ":", "-", "1", "]", "\n", "\n", "with", "open", "(", "label_path", ")", "as", "f", ":", "\n", "        ", "labels", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "labels", "=", "labels", "[", ":", "-", "1", "]", "\n", "\n", "\n", "new_data", "=", "[", "]", "\n", "for", "i", ",", "(", "sample", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "data", ",", "labels", ")", ")", ":", "\n", "        ", "if", "sample", "==", "''", ":", "\n", "            ", "continue", "\n", "# data_csv = data_csv.append(pd.DataFrame({'id': [i], 'text': sample, 'label':label}))", "\n", "", "label", "=", "','", ".", "join", "(", "label", ".", "split", "(", "' '", ")", ")", "\n", "new_data", ".", "append", "(", "[", "i", ",", "sample", ",", "label", "]", ")", "\n", "\n", "", "data_csv", "=", "pd", ".", "DataFrame", "(", "new_data", ",", "columns", "=", "[", "'id'", ",", "'text'", ",", "'label'", "]", ")", "\n", "\n", "data_csv", ".", "to_csv", "(", "write_path", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer.__init__": [[17, 19], ["predict_axml.AxmlTokenizer._get_vocab"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer._get_vocab"], ["    ", "def", "__init__", "(", "self", ",", "data_path", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "self", ".", "_get_vocab", "(", "data_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer._get_vocab": [[20, 24], ["os.path.join", "enumerate", "numpy.load"], "methods", ["None"], ["", "def", "_get_vocab", "(", "self", ",", "data_path", ")", ":", "\n", "        ", "vocab_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "'vocab.npy'", ")", "\n", "vocab", "=", "{", "word", ":", "idx", "for", "idx", ",", "word", "in", "enumerate", "(", "np", ".", "load", "(", "vocab_path", ",", "allow_pickle", "=", "True", ")", ")", "}", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer.tokenize": [[25, 29], ["token.lower", "nltk.tokenize.word_tokenize", "len", "re.sub"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "sentence", ":", "str", ",", "sep", "=", "'/SEP/'", ",", "unknown", "=", "'/UNK/'", ")", ":", "\n", "# We added a /SEP/ symbol between titles and descriptions such as Amazon datasets.", "\n", "        ", "return", "[", "token", ".", "lower", "(", ")", "if", "token", "!=", "sep", "and", "token", "!=", "unknown", "else", "token", "for", "token", "in", "word_tokenize", "(", "sentence", ")", "\n", "if", "len", "(", "re", ".", "sub", "(", "r'[^\\w]'", ",", "''", ",", "token", ")", ")", ">", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer._truncate_text": [[31, 37], ["numpy.asarray", "list", "len"], "methods", ["None"], ["", "def", "_truncate_text", "(", "self", ",", "texts", ",", "max_len", "=", "500", ",", "padding_idx", "=", "0", ",", "unknown_idx", "=", "1", ")", ":", "\n", "        ", "if", "max_len", "is", "None", ":", "\n", "            ", "return", "texts", "\n", "", "texts", "=", "np", ".", "asarray", "(", "[", "list", "(", "x", "[", ":", "max_len", "]", ")", "+", "[", "padding_idx", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "for", "x", "in", "texts", "]", ")", "\n", "texts", "[", "(", "texts", "==", "padding_idx", ")", ".", "all", "(", "axis", "=", "1", ")", ",", "0", "]", "=", "unknown_idx", "\n", "return", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer.convert_to_binary": [[39, 45], ["numpy.asarray", "predict_axml.AxmlTokenizer._truncate_text", "vocab.get"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer._truncate_text"], ["", "def", "convert_to_binary", "(", "self", ",", "texts", ",", "max_len", "=", "None", ",", "pad", "=", "'<PAD>'", ",", "unknown", "=", "'<UNK>'", ")", ":", "\n", "        ", "vocab", "=", "self", ".", "vocab", "\n", "texts", "=", "np", ".", "asarray", "(", "[", "[", "vocab", ".", "get", "(", "word", ",", "vocab", "[", "unknown", "]", ")", "for", "word", "in", "row", "]", "\n", "for", "row", "in", "texts", "]", ")", "\n", "\n", "return", "self", ".", "_truncate_text", "(", "texts", ",", "max_len", ",", "vocab", "[", "pad", "]", ",", "vocab", "[", "unknown", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer.convert_tokens_to_string": [[47, 50], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "out_string", "=", "' '", ".", "join", "(", "tokens", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AttentionXmlModel.__init__": [[55, 60], ["yaml.load", "torch.DataParallel", "torch.DataParallel", "predict_axml.AttentionXmlModel._load_model", "predict_axml.AxmlTokenizer", "pathlib.Path", "models.AttentionRNN().cuda", "os.path.join", "os.path.join", "models.AttentionRNN"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AttentionXmlModel._load_model"], ["    ", "def", "__init__", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "self", ".", "cnfg_args", "=", "yaml", ".", "load", "(", "Path", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "'confg_axml.yaml'", ")", ")", ")", "\n", "self", ".", "model", "=", "nn", ".", "DataParallel", "(", "AttentionRNN", "(", "**", "self", ".", "cnfg_args", ")", ".", "cuda", "(", ")", ")", "\n", "self", ".", "_load_model", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "'AttentionXML'", ")", ")", "\n", "self", ".", "tokenizer", "=", "AxmlTokenizer", "(", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AttentionXmlModel._load_model": [[62, 64], ["predict_axml.AttentionXmlModel.model.module.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["None"], ["", "def", "_load_model", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "self", ".", "model", ".", "module", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AttentionXmlModel._predict_step": [[66, 75], ["predict_axml.AttentionXmlModel.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "predict_axml.AttentionXmlModel.model", "predict_axml.AttentionXmlModel.cpu", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "predict_axml.AttentionXmlModel.cpu"], "methods", ["None"], ["", "def", "_predict_step", "(", "self", ",", "data_x", ":", "torch", ".", "Tensor", ",", "return_logits", ",", "top", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "self", ".", "model", "(", "data_x", ")", "\n", "if", "not", "return_logits", ":", "\n", "                ", "preds", "=", "torch", ".", "topk", "(", "scores", ".", "cpu", "(", ")", ",", "top", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "                ", "preds", "=", "scores", ".", "cpu", "(", ")", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AttentionXmlModel.predict": [[77, 86], ["predict_axml.AttentionXmlModel.tokenizer.convert_to_binary", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "predict_axml.AttentionXmlModel.append", "models.MultiLabelDataset", "predict_axml.AttentionXmlModel._predict_step", "predict_axml.AttentionXmlModel.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AxmlTokenizer.convert_to_binary", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.axml_scripts.predict_axml.AttentionXmlModel._predict_step", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "", "def", "predict", "(", "self", ",", "list_seq", ":", "list", ",", "labels", ":", "list", ",", "max_length", ":", "int", ",", "return_logits", "=", "True", ",", "top", "=", "5", ",", "batch_size", "=", "12", ")", ":", "# labels !!!!!!!", "\n", "        ", "texts", "=", "[", "]", "\n", "for", "seq", "in", "list_seq", ":", "\n", "            ", "texts", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "seq", ")", ")", "\n", "", "texts", "=", "self", ".", "tokenizer", ".", "convert_to_binary", "(", "texts", ",", "max_length", ")", "\n", "test_loader", "=", "DataLoader", "(", "MultiLabelDataset", "(", "texts", ")", ",", "batch_size", ",", "num_workers", "=", "4", ")", "\n", "preds", "=", "[", "self", ".", "_predict_step", "(", "data_x", ",", "return_logits", ",", "top", ")", "for", "data_x", "in", "test_loader", "]", "\n", "loss", "=", "1", "# TODO: compute loss", "\n", "return", "loss", ",", "preds", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.networks.Network.__init__": [[21, 25], ["torch.Module.__init__", "modules.Embedding"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "emb_size", ",", "vocab_size", "=", "None", ",", "emb_init", "=", "None", ",", "emb_trainable", "=", "True", ",", "padding_idx", "=", "0", ",", "emb_dropout", "=", "0.2", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Network", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb", "=", "Embedding", "(", "vocab_size", ",", "emb_size", ",", "emb_init", ",", "emb_trainable", ",", "padding_idx", ",", "emb_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.networks.Network.forward": [[26, 28], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.networks.AttentionRNN.__init__": [[34, 39], ["networks.Network.__init__", "modules.LSTMEncoder", "modules.MLAttention", "modules.MLLinear"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "labels_num", ",", "emb_size", ",", "hidden_size", ",", "layers_num", ",", "linear_size", ",", "dropout", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "AttentionRNN", ",", "self", ")", ".", "__init__", "(", "emb_size", ",", "**", "kwargs", ")", "\n", "self", ".", "lstm", "=", "LSTMEncoder", "(", "emb_size", ",", "hidden_size", ",", "layers_num", ",", "dropout", ")", "\n", "self", ".", "attention", "=", "MLAttention", "(", "labels_num", ",", "hidden_size", "*", "2", ")", "\n", "self", ".", "linear", "=", "MLLinear", "(", "[", "hidden_size", "*", "2", "]", "+", "linear_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.networks.AttentionRNN.forward": [[40, 45], ["networks.AttentionRNN.emb", "networks.AttentionRNN.lstm", "networks.AttentionRNN.attention", "networks.AttentionRNN.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "emb_out", ",", "lengths", ",", "masks", "=", "self", ".", "emb", "(", "inputs", ",", "**", "kwargs", ")", "\n", "rnn_out", "=", "self", ".", "lstm", "(", "emb_out", ",", "lengths", ")", "# N, L, hidden_size * 2", "\n", "attn_out", "=", "self", ".", "attention", "(", "rnn_out", ",", "masks", ")", "# N, labels_num, hidden_size * 2", "\n", "return", "self", ".", "linear", "(", "attn_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.networks.FastAttentionRNN.__init__": [[51, 56], ["networks.Network.__init__", "modules.LSTMEncoder", "modules.FastMLAttention", "modules.MLLinear"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "labels_num", ",", "emb_size", ",", "hidden_size", ",", "layers_num", ",", "linear_size", ",", "dropout", ",", "parallel_attn", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "FastAttentionRNN", ",", "self", ")", ".", "__init__", "(", "emb_size", ",", "**", "kwargs", ")", "\n", "self", ".", "lstm", "=", "LSTMEncoder", "(", "emb_size", ",", "hidden_size", ",", "layers_num", ",", "dropout", ")", "\n", "self", ".", "attention", "=", "FastMLAttention", "(", "labels_num", ",", "hidden_size", "*", "2", ",", "parallel_attn", ")", "\n", "self", ".", "linear", "=", "MLLinear", "(", "[", "hidden_size", "*", "2", "]", "+", "linear_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.networks.FastAttentionRNN.forward": [[57, 62], ["networks.FastAttentionRNN.emb", "networks.FastAttentionRNN.lstm", "networks.FastAttentionRNN.attention", "networks.FastAttentionRNN.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "candidates", ",", "attn_weights", ":", "nn", ".", "Module", ",", "**", "kwargs", ")", ":", "\n", "        ", "emb_out", ",", "lengths", ",", "masks", "=", "self", ".", "emb", "(", "inputs", ",", "**", "kwargs", ")", "\n", "rnn_out", "=", "self", ".", "lstm", "(", "emb_out", ",", "lengths", ")", "# N, L, hidden_size * 2", "\n", "attn_out", "=", "self", ".", "attention", "(", "rnn_out", ",", "masks", ",", "candidates", ",", "attn_weights", ")", "# N, sampled_size, hidden_size * 2", "\n", "return", "self", ".", "linear", "(", "attn_out", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.Embedding.__init__": [[22, 35], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", "=", "None", ",", "emb_size", "=", "None", ",", "emb_init", "=", "None", ",", "emb_trainable", "=", "True", ",", "padding_idx", "=", "0", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "Embedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "emb_init", "is", "not", "None", ":", "\n", "            ", "if", "vocab_size", "is", "not", "None", ":", "\n", "                ", "assert", "vocab_size", "==", "emb_init", ".", "shape", "[", "0", "]", "\n", "", "if", "emb_size", "is", "not", "None", ":", "\n", "                ", "assert", "emb_size", "==", "emb_init", ".", "shape", "[", "1", "]", "\n", "", "vocab_size", ",", "emb_size", "=", "emb_init", ".", "shape", "\n", "", "self", ".", "emb", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "emb_size", ",", "padding_idx", "=", "padding_idx", ",", "sparse", "=", "True", ",", "\n", "_weight", "=", "torch", ".", "from_numpy", "(", "emb_init", ")", ".", "float", "(", ")", "if", "emb_init", "is", "not", "None", "else", "None", ")", "\n", "self", ".", "emb", ".", "weight", ".", "requires_grad", "=", "emb_trainable", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.Embedding.forward": [[36, 40], ["modules.Embedding.dropout", "modules.Embedding.emb", "lengths.max", "lengths.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "emb_out", "=", "self", ".", "dropout", "(", "self", ".", "emb", "(", "inputs", ")", ")", "\n", "lengths", ",", "masks", "=", "(", "inputs", "!=", "self", ".", "padding_idx", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ",", "inputs", "!=", "self", ".", "padding_idx", "\n", "return", "emb_out", "[", ":", ",", ":", "lengths", ".", "max", "(", ")", "]", ",", "lengths", ",", "masks", "[", ":", ",", ":", "lengths", ".", "max", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.LSTMEncoder.__init__": [[46, 51], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "layers_num", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "LSTMEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", ",", "hidden_size", ",", "layers_num", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "self", ".", "init_state", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "2", "*", "2", "*", "layers_num", ",", "1", ",", "hidden_size", ")", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.LSTMEncoder.forward": [[52, 61], ["modules.LSTMEncoder.lstm.flatten_parameters", "modules.LSTMEncoder.init_state.repeat", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "modules.LSTMEncoder.dropout", "inputs.size", "modules.LSTMEncoder.lstm", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "modules.LSTMEncoder.size", "modules.LSTMEncoder.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "lengths", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "init_state", "=", "self", ".", "init_state", ".", "repeat", "(", "[", "1", ",", "inputs", ".", "size", "(", "0", ")", ",", "1", "]", ")", "\n", "cell_init", ",", "hidden_init", "=", "init_state", "[", ":", "init_state", ".", "size", "(", "0", ")", "//", "2", "]", ",", "init_state", "[", "init_state", ".", "size", "(", "0", ")", "//", "2", ":", "]", "\n", "idx", "=", "torch", ".", "argsort", "(", "lengths", ",", "descending", "=", "True", ")", "\n", "packed_inputs", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "inputs", "[", "idx", "]", ",", "lengths", "[", "idx", "]", ",", "batch_first", "=", "True", ")", "\n", "outputs", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "\n", "self", ".", "lstm", "(", "packed_inputs", ",", "(", "hidden_init", ",", "cell_init", ")", ")", "[", "0", "]", ",", "batch_first", "=", "True", ")", "\n", "return", "self", ".", "dropout", "(", "outputs", "[", "torch", ".", "argsort", "(", "idx", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.MLAttention.__init__": [[67, 71], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "labels_num", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "MLAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "labels_num", ",", "bias", "=", "False", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "attention", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.MLAttention.forward": [[72, 77], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "modules.MLAttention.attention().transpose().masked_fill", "torch.softmax", "torch.softmax", "torch.softmax", "modules.MLAttention.attention().transpose", "modules.MLAttention.attention"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "masks", ")", ":", "\n", "        ", "masks", "=", "torch", ".", "unsqueeze", "(", "masks", ",", "1", ")", "# N, 1, L", "\n", "attention", "=", "self", ".", "attention", "(", "inputs", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "masked_fill", "(", "~", "masks", ",", "-", "np", ".", "inf", ")", "# N, labels_num, L", "\n", "attention", "=", "F", ".", "softmax", "(", "attention", ",", "-", "1", ")", "\n", "return", "attention", "@", "inputs", "# N, labels_num, hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.AttentionWeights.__init__": [[83, 99], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "list", "len", "sum", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "numpy.cumsum", "range", "len", "len", "torch.Embedding().cuda", "torch.Embedding().cuda", "torch.Embedding().cuda", "emb.weight.data.uniform_", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "len", "enumerate", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "labels_num", ",", "hidden_size", ",", "device_ids", "=", "None", ")", ":", "\n", "        ", "super", "(", "AttentionWeights", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "device_ids", "is", "None", ":", "\n", "            ", "device_ids", "=", "list", "(", "range", "(", "1", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "\n", "# device_ids = list(range(0, torch.cuda.device_count()))", "\n", "", "assert", "labels_num", ">=", "len", "(", "device_ids", ")", "\n", "group_size", ",", "plus_num", "=", "labels_num", "//", "len", "(", "device_ids", ")", ",", "labels_num", "%", "len", "(", "device_ids", ")", "\n", "self", ".", "group", "=", "[", "group_size", "+", "1", "]", "*", "plus_num", "+", "[", "group_size", "]", "*", "(", "len", "(", "device_ids", ")", "-", "plus_num", ")", "\n", "assert", "sum", "(", "self", ".", "group", ")", "==", "labels_num", "\n", "self", ".", "emb", "=", "nn", ".", "ModuleList", "(", "nn", ".", "Embedding", "(", "size", ",", "hidden_size", ",", "sparse", "=", "True", ")", ".", "cuda", "(", "device_ids", "[", "i", "]", ")", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "self", ".", "group", ")", ")", "\n", "std", "=", "(", "6.0", "/", "(", "labels_num", "+", "hidden_size", ")", ")", "**", "0.5", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "emb", "in", "self", ".", "emb", ":", "\n", "                ", "emb", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "std", ",", "std", ")", "\n", "", "", "self", ".", "group_offset", ",", "self", ".", "hidden_size", "=", "np", ".", "cumsum", "(", "[", "0", "]", "+", "self", ".", "group", ")", ",", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.AttentionWeights.forward": [[100, 107], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "zip", "emb().to", "inputs.size", "emb"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "outputs", "=", "torch", ".", "zeros", "(", "*", "inputs", ".", "size", "(", ")", ",", "self", ".", "hidden_size", ",", "device", "=", "inputs", ".", "device", ")", "\n", "for", "left", ",", "right", ",", "emb", "in", "zip", "(", "self", ".", "group_offset", "[", ":", "-", "1", "]", ",", "self", ".", "group_offset", "[", "1", ":", "]", ",", "self", ".", "emb", ")", ":", "\n", "            ", "index", "=", "(", "left", "<=", "inputs", ")", "&", "(", "inputs", "<", "right", ")", "\n", "group_inputs", "=", "(", "inputs", "[", "index", "]", "-", "left", ")", ".", "to", "(", "emb", ".", "weight", ".", "device", ")", "\n", "outputs", "[", "index", "]", "=", "emb", "(", "group_inputs", ")", ".", "to", "(", "inputs", ".", "device", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.FastMLAttention.__init__": [[113, 118], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "labels_num", ",", "hidden_size", ",", "parallel_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", "FastMLAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "parallel_attn", ":", "\n", "            ", "self", ".", "attention", "=", "nn", ".", "Embedding", "(", "labels_num", "+", "1", ",", "hidden_size", ",", "sparse", "=", "True", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "attention", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.FastMLAttention.forward": [[119, 126], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "inputs.transpose", "torch.softmax", "torch.softmax", "torch.softmax", "hasattr", "modules.FastMLAttention.attention", "attn_weights"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ",", "masks", ",", "candidates", ",", "attn_weights", ":", "nn", ".", "Module", ")", ":", "\n", "        ", "masks", "=", "torch", ".", "unsqueeze", "(", "masks", ",", "1", ")", "# N, 1, L", "\n", "attn_inputs", "=", "inputs", ".", "transpose", "(", "1", ",", "2", ")", "# N, hidden, L", "\n", "attn_weights", "=", "self", ".", "attention", "(", "candidates", ")", "if", "hasattr", "(", "self", ",", "'attention'", ")", "else", "attn_weights", "(", "candidates", ")", "\n", "attention", "=", "(", "attn_weights", "@", "attn_inputs", ")", ".", "masked_fill", "(", "~", "masks", ",", "-", "np", ".", "inf", ")", "# N, sampled_size, L", "\n", "attention", "=", "F", ".", "softmax", "(", "attention", ",", "-", "1", ")", "# N, sampled_size, L", "\n", "return", "attention", "@", "inputs", "# N, sampled_size, hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.MLLinear.__init__": [[132, 140], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Linear", "torch.Linear", "torch.Linear", "zip"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "linear_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "MLLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "ModuleList", "(", "nn", ".", "Linear", "(", "in_s", ",", "out_s", ")", "\n", "for", "in_s", ",", "out_s", "in", "zip", "(", "linear_size", "[", ":", "-", "1", "]", ",", "linear_size", "[", "1", ":", "]", ")", ")", "\n", "for", "linear", "in", "self", ".", "linear", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "linear", ".", "weight", ")", "\n", "", "self", ".", "output", "=", "nn", ".", "Linear", "(", "linear_size", "[", "-", "1", "]", ",", "output_size", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "output", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modules.MLLinear.forward": [[141, 146], ["torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.relu", "torch.relu", "torch.relu", "modules.MLLinear.output", "linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "linear_out", "=", "inputs", "\n", "for", "linear", "in", "self", ".", "linear", ":", "\n", "            ", "linear_out", "=", "F", ".", "relu", "(", "linear", "(", "linear_out", ")", ")", "\n", "", "return", "torch", ".", "squeeze", "(", "self", ".", "output", "(", "linear_out", ")", ",", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.dataset.MultiLabelDataset.__init__": [[29, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_x", ":", "TDataX", ",", "data_y", ":", "TDataY", "=", "None", ",", "training", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_x", ",", "self", ".", "data_y", ",", "self", ".", "training", "=", "data_x", ",", "data_y", ",", "training", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.dataset.MultiLabelDataset.__getitem__": [[32, 39], ["dataset.MultiLabelDataset.data_y[].toarray().squeeze().astype", "dataset.MultiLabelDataset.data_y[].toarray().squeeze", "dataset.MultiLabelDataset.data_y[].toarray"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "data_x", "=", "self", ".", "data_x", "[", "item", "]", "\n", "if", "self", ".", "training", "and", "self", ".", "data_y", "is", "not", "None", ":", "\n", "            ", "data_y", "=", "self", ".", "data_y", "[", "item", "]", ".", "toarray", "(", ")", ".", "squeeze", "(", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "data_x", ",", "data_y", "\n", "", "else", ":", "\n", "            ", "return", "data_x", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.dataset.MultiLabelDataset.__len__": [[40, 42], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.dataset.XMLDataset.__init__": [[48, 65], ["dataset.MultiLabelDataset.__init__", "numpy.concatenate", "numpy.ones_like", "max", "tqdm.tqdm.tqdm", "numpy.concatenate", "zip", "len", "len", "zip"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "data_x", ":", "TDataX", ",", "data_y", ":", "TDataY", "=", "None", ",", "training", "=", "True", ",", "\n", "labels_num", "=", "None", ",", "candidates", ":", "TCandidate", "=", "None", ",", "candidates_num", "=", "None", ",", "\n", "groups", ":", "TGroup", "=", "None", ",", "group_labels", ":", "TGroupLabel", "=", "None", ",", "group_scores", ":", "TGroupScore", "=", "None", ")", ":", "\n", "        ", "super", "(", "XMLDataset", ",", "self", ")", ".", "__init__", "(", "data_x", ",", "data_y", ",", "training", ")", "\n", "self", ".", "labels_num", ",", "self", ".", "candidates", ",", "self", ".", "candidates_num", "=", "labels_num", ",", "candidates", ",", "candidates_num", "\n", "self", ".", "groups", ",", "self", ".", "group_labels", ",", "self", ".", "group_scores", "=", "groups", ",", "group_labels", ",", "group_scores", "\n", "if", "self", ".", "candidates", "is", "None", ":", "\n", "            ", "self", ".", "candidates", "=", "[", "np", ".", "concatenate", "(", "[", "self", ".", "groups", "[", "g", "]", "for", "g", "in", "group_labels", "]", ")", "\n", "for", "group_labels", "in", "tqdm", "(", "self", ".", "group_labels", ",", "leave", "=", "False", ",", "desc", "=", "'Candidates'", ")", "]", "\n", "if", "self", ".", "group_scores", "is", "not", "None", ":", "\n", "                ", "self", ".", "candidates_scores", "=", "[", "np", ".", "concatenate", "(", "[", "[", "s", "]", "*", "len", "(", "self", ".", "groups", "[", "g", "]", ")", "\n", "for", "g", ",", "s", "in", "zip", "(", "group_labels", ",", "group_scores", ")", "]", ")", "\n", "for", "group_labels", ",", "group_scores", "in", "zip", "(", "self", ".", "group_labels", ",", "self", ".", "group_scores", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "candidates_scores", "=", "[", "np", ".", "ones_like", "(", "candidates", ")", "for", "candidates", "in", "self", ".", "candidates", "]", "\n", "", "if", "self", ".", "candidates_num", "is", "None", ":", "\n", "            ", "self", ".", "candidates_num", "=", "self", ".", "group_labels", ".", "shape", "[", "1", "]", "*", "max", "(", "len", "(", "g", ")", "for", "g", "in", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.dataset.XMLDataset.__getitem__": [[66, 83], ["numpy.asarray", "dataset.XMLDataset.data_y[].toarray().squeeze().astype", "numpy.asarray", "len", "numpy.random.randint", "numpy.concatenate", "len", "numpy.concatenate", "numpy.concatenate", "len", "numpy.random.choice", "dataset.XMLDataset.data_y[].toarray().squeeze", "len", "dataset.XMLDataset.data_y[].toarray", "len", "len"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "data_x", ",", "candidates", "=", "self", ".", "data_x", "[", "item", "]", ",", "np", ".", "asarray", "(", "self", ".", "candidates", "[", "item", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "if", "self", ".", "training", "and", "self", ".", "data_y", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "candidates", ")", "<", "self", ".", "candidates_num", ":", "\n", "                ", "sample", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "labels_num", ",", "size", "=", "self", ".", "candidates_num", "-", "len", "(", "candidates", ")", ")", "\n", "candidates", "=", "np", ".", "concatenate", "(", "[", "candidates", ",", "sample", "]", ")", "\n", "", "elif", "len", "(", "candidates", ")", ">", "self", ".", "candidates_num", ":", "\n", "                ", "candidates", "=", "np", ".", "random", ".", "choice", "(", "candidates", ",", "self", ".", "candidates_num", ",", "replace", "=", "False", ")", "\n", "", "data_y", "=", "self", ".", "data_y", "[", "item", ",", "candidates", "]", ".", "toarray", "(", ")", ".", "squeeze", "(", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "(", "data_x", ",", "candidates", ")", ",", "data_y", "\n", "", "else", ":", "\n", "            ", "scores", "=", "self", ".", "candidates_scores", "[", "item", "]", "\n", "if", "len", "(", "candidates", ")", "<", "self", ".", "candidates_num", ":", "\n", "                ", "scores", "=", "np", ".", "concatenate", "(", "[", "scores", ",", "[", "-", "np", ".", "inf", "]", "*", "(", "self", ".", "candidates_num", "-", "len", "(", "candidates", ")", ")", "]", ")", "\n", "candidates", "=", "np", ".", "concatenate", "(", "[", "candidates", ",", "[", "self", ".", "labels_num", "]", "*", "(", "self", ".", "candidates_num", "-", "len", "(", "candidates", ")", ")", "]", ")", "\n", "", "scores", "=", "np", ".", "asarray", "(", "scores", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "return", "data_x", ",", "candidates", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.dataset.XMLDataset.__len__": [[84, 86], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer.__init__": [[64, 87], ["tokenization_utils.PreTrainedTokenizer.__init__", "spm.SentencePieceProcessor", "tokenization_xlnet.XLNetTokenizer.sp_model.Load", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "max_len", "=", "None", ",", "\n", "do_lower_case", "=", "False", ",", "remove_space", "=", "True", ",", "keep_accents", "=", "False", ",", "\n", "bos_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "unk_token", "=", "\"<unk>\"", ",", "sep_token", "=", "\"<sep>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "cls_token", "=", "\"<cls>\"", ",", "mask_token", "=", "\"<mask>\"", ",", "\n", "additional_special_tokens", "=", "[", "\"<eop>\"", ",", "\"<eod>\"", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLNetTokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "additional_special_tokens", "=", "\n", "additional_special_tokens", ",", "**", "kwargs", ")", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", ")", "\n", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "remove_space", "=", "remove_space", "\n", "self", ".", "keep_accents", "=", "keep_accents", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer.vocab_size": [[88, 91], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sp_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer.__getstate__": [[92, 96], ["tokenization_xlnet.XLNetTokenizer.__dict__.copy"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "state", "[", "\"sp_model\"", "]", "=", "None", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer.__setstate__": [[97, 106], ["spm.SentencePieceProcessor", "tokenization_xlnet.XLNetTokenizer.sp_model.Load", "logger.warning"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "d", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", ")", "\n", "", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "self", ".", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer.preprocess_text": [[107, 124], ["outputs.lower.lower.replace().replace", "isinstance", "outputs.lower.lower.decode", "unicodedata.normalize", "outputs.lower.lower.lower", "inputs.strip().split", "outputs.lower.lower.replace", "inputs.strip", "unicodedata.combining"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "preprocess_text", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "remove_space", ":", "\n", "            ", "outputs", "=", "' '", ".", "join", "(", "inputs", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "inputs", "\n", "", "outputs", "=", "outputs", ".", "replace", "(", "\"``\"", ",", "'\"'", ")", ".", "replace", "(", "\"''\"", ",", "'\"'", ")", "\n", "\n", "if", "six", ".", "PY2", "and", "isinstance", "(", "outputs", ",", "str", ")", ":", "\n", "            ", "outputs", "=", "outputs", ".", "decode", "(", "'utf-8'", ")", "\n", "\n", "", "if", "not", "self", ".", "keep_accents", ":", "\n", "            ", "outputs", "=", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "outputs", ")", "\n", "outputs", "=", "''", ".", "join", "(", "[", "c", "for", "c", "in", "outputs", "if", "not", "unicodedata", ".", "combining", "(", "c", ")", "]", ")", "\n", "", "if", "self", ".", "do_lower_case", ":", "\n", "            ", "outputs", "=", "outputs", ".", "lower", "(", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer._tokenize": [[125, 163], ["tokenization_xlnet.XLNetTokenizer.preprocess_text", "isinstance", "text.encode.encode.encode", "tokenization_xlnet.XLNetTokenizer.sp_model.EncodeAsPieces", "tokenization_xlnet.XLNetTokenizer.sp_model.SampleEncodeAsPieces", "piece[].isdigit", "tokenization_xlnet.XLNetTokenizer.sp_model.EncodeAsPieces", "tokenization_xlnet.XLNetTokenizer.append", "new_pieces.extend", "new_pieces.append", "isinstance", "ret_pieces.append", "len", "piece[].replace", "piece.decode.decode.decode", "len"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer.preprocess_text", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "return_unicode", "=", "True", ",", "sample", "=", "False", ")", ":", "\n", "        ", "\"\"\" Tokenize a string.\n            return_unicode is used only for py2\n        \"\"\"", "\n", "text", "=", "self", ".", "preprocess_text", "(", "text", ")", "\n", "# note(zhiliny): in some systems, sentencepiece only accepts str for py2", "\n", "if", "six", ".", "PY2", "and", "isinstance", "(", "text", ",", "unicode", ")", ":", "\n", "            ", "text", "=", "text", ".", "encode", "(", "'utf-8'", ")", "\n", "\n", "", "if", "not", "sample", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "SampleEncodeAsPieces", "(", "text", ",", "64", ",", "0.1", ")", "\n", "", "new_pieces", "=", "[", "]", "\n", "for", "piece", "in", "pieces", ":", "\n", "            ", "if", "len", "(", "piece", ")", ">", "1", "and", "piece", "[", "-", "1", "]", "==", "','", "and", "piece", "[", "-", "2", "]", ".", "isdigit", "(", ")", ":", "\n", "                ", "cur_pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "\n", "piece", "[", ":", "-", "1", "]", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "''", ")", ")", "\n", "if", "piece", "[", "0", "]", "!=", "SPIECE_UNDERLINE", "and", "cur_pieces", "[", "0", "]", "[", "0", "]", "==", "SPIECE_UNDERLINE", ":", "\n", "                    ", "if", "len", "(", "cur_pieces", "[", "0", "]", ")", "==", "1", ":", "\n", "                        ", "cur_pieces", "=", "cur_pieces", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                        ", "cur_pieces", "[", "0", "]", "=", "cur_pieces", "[", "0", "]", "[", "1", ":", "]", "\n", "", "", "cur_pieces", ".", "append", "(", "piece", "[", "-", "1", "]", ")", "\n", "new_pieces", ".", "extend", "(", "cur_pieces", ")", "\n", "", "else", ":", "\n", "                ", "new_pieces", ".", "append", "(", "piece", ")", "\n", "\n", "# note(zhiliny): convert back to unicode for py2", "\n", "", "", "if", "six", ".", "PY2", "and", "return_unicode", ":", "\n", "            ", "ret_pieces", "=", "[", "]", "\n", "for", "piece", "in", "new_pieces", ":", "\n", "                ", "if", "isinstance", "(", "piece", ",", "str", ")", ":", "\n", "                    ", "piece", "=", "piece", ".", "decode", "(", "'utf-8'", ")", "\n", "", "ret_pieces", ".", "append", "(", "piece", ")", "\n", "", "new_pieces", "=", "ret_pieces", "\n", "\n", "", "return", "new_pieces", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer._convert_token_to_id": [[164, 167], ["tokenization_xlnet.XLNetTokenizer.sp_model.PieceToId"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "sp_model", ".", "PieceToId", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer._convert_id_to_token": [[168, 174], ["tokenization_xlnet.XLNetTokenizer.sp_model.IdToPiece", "isinstance", "token.decode.decode.decode"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ",", "return_unicode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "token", "=", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", ")", "\n", "if", "six", ".", "PY2", "and", "return_unicode", "and", "isinstance", "(", "token", ",", "str", ")", ":", "\n", "            ", "token", "=", "token", ".", "decode", "(", "'utf-8'", ")", "\n", "", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_string": [[175, 180], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"", "\n", "# out_string = ''.join(tokens).replace(SPIECE_UNDERLINE, ' ').strip()", "\n", "out_string", "=", "' '", ".", "join", "(", "tokens", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_xlnet.XLNetTokenizer.save_vocabulary": [[181, 194], ["os.path.join", "os.path.isdir", "logger.error", "os.path.abspath", "os.path.abspath", "shutil.copyfile"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n            to a directory.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "out_vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "\n", "if", "os", ".", "path", ".", "abspath", "(", "self", ".", "vocab_file", ")", "!=", "os", ".", "path", ".", "abspath", "(", "out_vocab_file", ")", ":", "\n", "            ", "copyfile", "(", "self", ".", "vocab_file", ",", "out_vocab_file", ")", "\n", "\n", "", "return", "(", "out_vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetConfig.__init__": [[246, 324], ["modeling_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "32000", ",", "\n", "d_model", "=", "1024", ",", "\n", "n_layer", "=", "24", ",", "\n", "n_head", "=", "16", ",", "\n", "d_inner", "=", "4096", ",", "\n", "ff_activation", "=", "\"gelu\"", ",", "\n", "untie_r", "=", "True", ",", "\n", "attn_type", "=", "\"bi\"", ",", "\n", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "\n", "dropout", "=", "0.1", ",", "\n", "mem_len", "=", "None", ",", "\n", "reuse_len", "=", "None", ",", "\n", "bi_data", "=", "False", ",", "\n", "clamp_len", "=", "-", "1", ",", "\n", "same_length", "=", "False", ",", "\n", "\n", "finetuning_task", "=", "None", ",", "\n", "num_labels", "=", "2", ",", "\n", "summary_type", "=", "'last'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "'tanh'", ",", "\n", "summary_last_dropout", "=", "0.1", ",", "\n", "start_n_top", "=", "5", ",", "\n", "end_n_top", "=", "5", ",", "\n", "adaptive_cutoff", "=", "[", "10", ",", "100", "]", ",", "\n", "div_value", "=", "2", ",", "\n", "last_hidden_size", "=", "768", ",", "\n", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs XLNetConfig.\n        \"\"\"", "\n", "super", "(", "XLNetConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "n_token", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "assert", "d_model", "%", "n_head", "==", "0", "\n", "self", ".", "d_head", "=", "d_model", "//", "n_head", "\n", "self", ".", "ff_activation", "=", "ff_activation", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "reuse_len", "=", "reuse_len", "\n", "self", ".", "bi_data", "=", "bi_data", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "\n", "self", ".", "finetuning_task", "=", "finetuning_task", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_last_dropout", "=", "summary_last_dropout", "\n", "self", ".", "start_n_top", "=", "start_n_top", "\n", "self", ".", "end_n_top", "=", "end_n_top", "\n", "self", ".", "adaptive_cutoff", "=", "adaptive_cutoff", "\n", "self", ".", "div_value", "=", "div_value", "\n", "self", ".", "last_hidden_size", "=", "last_hidden_size", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetConfig.max_position_embeddings": [[326, 329], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetConfig.vocab_size": [[334, 337], ["None"], "methods", ["None"], ["", "@", "vocab_size", ".", "setter", "\n", "def", "vocab_size", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "n_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetConfig.hidden_size": [[338, 341], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetConfig.num_attention_heads": [[342, 345], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetConfig.num_hidden_layers": [[346, 349], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.__init__": [[371, 398], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "XLNetLayerNorm", "torch.nn.Dropout", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetRelativeAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "if", "config", ".", "d_model", "%", "config", ".", "n_head", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "d_model", ",", "config", ".", "n_head", ")", ")", "\n", "\n", "", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "scale", "=", "1", "/", "(", "config", ".", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "q", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "k", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "o", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_s_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "seg_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "2", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.prune_heads": [[399, 401], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.rel_shift": [[402, 414], ["torch.index_select.reshape", "torch.index_select.reshape", "torch.index_select", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rel_shift", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"perform relative shift to form the relative attention score.\"\"\"", "\n", "x_size", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "1", "]", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "x", "=", "x", "[", "1", ":", ",", "...", "]", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", "-", "1", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "# x = x[:, 0:klen, :, :]", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "1", ",", "torch", ".", "arange", "(", "klen", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.rel_attn_core": [[415, 453], ["torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_shift", "torch.nn.functional.softmax", "modeling_xlnet.XLNetRelativeAttention.dropout", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.rel_shift"], ["", "def", "rel_attn_core", "(", "self", ",", "q_head", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "None", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Core relative positional attention operations.\"\"\"", "\n", "\n", "# content based attention score", "\n", "ac", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "q_head", "+", "self", ".", "r_w_bias", ",", "k_head_h", ")", "\n", "\n", "# position based attention score", "\n", "bd", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "q_head", "+", "self", ".", "r_r_bias", ",", "k_head_r", ")", "\n", "bd", "=", "self", ".", "rel_shift", "(", "bd", ",", "klen", "=", "ac", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# segment based attention score", "\n", "if", "seg_mat", "is", "None", ":", "\n", "            ", "ef", "=", "0", "\n", "", "else", ":", "\n", "            ", "ef", "=", "torch", ".", "einsum", "(", "'ibnd,snd->ibns'", ",", "q_head", "+", "self", ".", "r_s_bias", ",", "self", ".", "seg_embed", ")", "\n", "ef", "=", "torch", ".", "einsum", "(", "'ijbs,ibns->ijbn'", ",", "seg_mat", ",", "ef", ")", "\n", "\n", "# merge attention scores and perform masking", "\n", "", "attn_score", "=", "(", "ac", "+", "bd", "+", "ef", ")", "*", "self", ".", "scale", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask", "\n", "            ", "attn_score", "=", "attn_score", "-", "1e30", "*", "attn_mask", "\n", "\n", "# attention probability", "\n", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropout", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "# attention output", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "attn_prob", ",", "v_head_h", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "attn_vec", ",", "attn_prob", "\n", "\n", "", "return", "attn_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.post_attention": [[454, 465], ["torch.einsum", "modeling_xlnet.XLNetRelativeAttention.dropout", "modeling_xlnet.XLNetRelativeAttention.layer_norm"], "methods", ["None"], ["", "def", "post_attention", "(", "self", ",", "h", ",", "attn_vec", ",", "residual", "=", "True", ")", ":", "\n", "        ", "\"\"\"Post-attention processing.\"\"\"", "\n", "# post-attention projection (back to `d_model`)", "\n", "attn_out", "=", "torch", ".", "einsum", "(", "'ibnd,hnd->ibh'", ",", "attn_vec", ",", "self", ".", "o", ")", "\n", "\n", "attn_out", "=", "self", ".", "dropout", "(", "attn_out", ")", "\n", "if", "residual", ":", "\n", "            ", "attn_out", "=", "attn_out", "+", "h", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "attn_out", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.forward": [[466, 558], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.cat", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.cat", "mems.dim", "mems.dim"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetRelativeAttention.rel_attn_core"], ["", "def", "forward", "(", "self", ",", "h", ",", "g", ",", "\n", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "\n", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "###### Two-stream attention with relative positional encoding.", "\n", "# content based attention score", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content-based key head", "\n", "", "k_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "\n", "# content-based value head", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# position-based key head", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "##### h-stream", "\n", "# content-stream query head", "\n", "q_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec_h", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec_h", ",", "attn_prob_h", "=", "attn_vec_h", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec_h", ")", "\n", "\n", "##### g-stream", "\n", "# query-stream query head", "\n", "q_head_g", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "g", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "                ", "q_head_g", "=", "torch", ".", "einsum", "(", "'mbnd,mlb->lbnd'", ",", "q_head_g", ",", "target_mapping", ")", "\n", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "", "attn_vec_g", "=", "torch", ".", "einsum", "(", "'lbnd,mlb->mbnd'", ",", "attn_vec_g", ",", "target_mapping", ")", "\n", "", "else", ":", "\n", "                ", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "# post processing", "\n", "", "", "output_g", "=", "self", ".", "post_attention", "(", "g", ",", "attn_vec_g", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_prob", "=", "attn_prob_h", ",", "attn_prob_g", "\n", "\n", "", "", "else", ":", "\n", "###### Multi-head attention with relative positional encoding", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content heads", "\n", "", "q_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "k_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# positional heads", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec", ",", "attn_prob", "=", "attn_vec", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec", ")", "\n", "output_g", "=", "None", "\n", "\n", "", "outputs", "=", "(", "output_h", ",", "output_g", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn_prob", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetFeedForward.__init__": [[560, 571], ["torch.nn.Module.__init__", "XLNetLayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "layer_1", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_inner", ")", "\n", "self", ".", "layer_2", "=", "nn", ".", "Linear", "(", "config", ".", "d_inner", ",", "config", ".", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "if", "isinstance", "(", "config", ".", "ff_activation", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "ff_activation", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "activation_function", "=", "ACT2FN", "[", "config", ".", "ff_activation", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation_function", "=", "config", ".", "ff_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetFeedForward.forward": [[572, 581], ["modeling_xlnet.XLNetFeedForward.layer_1", "modeling_xlnet.XLNetFeedForward.activation_function", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_2", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "inp", "\n", "output", "=", "self", ".", "layer_1", "(", "output", ")", "\n", "output", "=", "self", ".", "activation_function", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_2", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "inp", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetLayer.__init__": [[583, 588], ["torch.nn.Module.__init__", "modeling_xlnet.XLNetRelativeAttention", "modeling_xlnet.XLNetFeedForward", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rel_attn", "=", "XLNetRelativeAttention", "(", "config", ")", "\n", "self", ".", "ff", "=", "XLNetFeedForward", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetLayer.forward": [[589, 603], ["modeling_xlnet.XLNetLayer.rel_attn", "modeling_xlnet.XLNetLayer.ff", "modeling_xlnet.XLNetLayer.ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output_h", ",", "output_g", ",", "\n", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "rel_attn", "(", "output_h", ",", "output_g", ",", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", "=", "mems", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "output_g", "is", "not", "None", ":", "\n", "            ", "output_g", "=", "self", ".", "ff", "(", "output_g", ")", "\n", "", "output_h", "=", "self", ".", "ff", "(", "output_h", ")", "\n", "\n", "outputs", "=", "(", "output_h", ",", "output_g", ")", "+", "outputs", "[", "2", ":", "]", "# Add again attentions if there are there", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetPreTrainedModel.__init__": [[614, 616], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLNetPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetPreTrainedModel.init_weights": [[617, 636], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "isinstance", "param.data.normal_", "module.mask_emb.data.normal_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "XLNetRelativeAttention", ")", ":", "\n", "            ", "for", "param", "in", "[", "module", ".", "q", ",", "module", ".", "k", ",", "module", ".", "v", ",", "module", ".", "o", ",", "module", ".", "r", ",", "\n", "module", ".", "r_r_bias", ",", "module", ".", "r_s_bias", ",", "module", ".", "r_w_bias", ",", "\n", "module", ".", "seg_embed", "]", ":", "\n", "                ", "param", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetModel", ")", ":", "\n", "                ", "module", ".", "mask_emb", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.__init__": [[738, 758], ["modeling_xlnet.XLNetPreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.ModuleList", "torch.nn.Dropout", "modeling_xlnet.XLNetModel.apply", "torch.Tensor", "modeling_xlnet.XLNetLayer", "range"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "reuse_len", "=", "config", ".", "reuse_len", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "bi_data", "=", "config", ".", "bi_data", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", "(", "config", ".", "n_token", ",", "config", ".", "d_model", ")", "\n", "self", ".", "mask_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "config", ".", "d_model", ")", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "XLNetLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel._resize_token_embeddings": [[759, 762], ["modeling_xlnet.XLNetModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "word_embedding", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "word_embedding", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "word_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel._prune_heads": [[763, 765], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.create_mask": [[766, 795], ["torch.ones", "torch.triu", "torch.zeros", "torch.cat", "torch.cat.to", "torch.tril", "torch.cat", "next", "modeling_xlnet.XLNetModel.parameters"], "methods", ["None"], ["", "def", "create_mask", "(", "self", ",", "qlen", ",", "mlen", ")", ":", "\n", "        ", "\"\"\"\n        Creates causal attention mask. Float mask where 1.0 indicates masked, 0.0 indicates not-masked.\n\n        Args:\n            qlen: TODO Lysandre didn't fill\n            mlen: TODO Lysandre didn't fill\n\n        ::\n\n                  same_length=False:      same_length=True:\n                  <mlen > <  qlen >       <mlen > <  qlen >\n               ^ [0 0 0 0 0 1 1 1 1]     [0 0 0 0 0 1 1 1 1]\n                 [0 0 0 0 0 0 1 1 1]     [1 0 0 0 0 0 1 1 1]\n            qlen [0 0 0 0 0 0 0 1 1]     [1 1 0 0 0 0 0 1 1]\n                 [0 0 0 0 0 0 0 0 1]     [1 1 1 0 0 0 0 0 1]\n               v [0 0 0 0 0 0 0 0 0]     [1 1 1 1 0 0 0 0 0]\n\n        \"\"\"", "\n", "attn_mask", "=", "torch", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ")", "\n", "mask_up", "=", "torch", ".", "triu", "(", "attn_mask", ",", "diagonal", "=", "1", ")", "\n", "attn_mask_pad", "=", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "attn_mask_pad", ",", "mask_up", "]", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_lo", "=", "torch", ".", "tril", "(", "attn_mask", ",", "diagonal", "=", "-", "1", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "ret", "[", ":", ",", ":", "qlen", "]", "+", "mask_lo", ",", "ret", "[", ":", ",", "qlen", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "ret", "=", "ret", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.cache_mem": [[796, 810], ["new_mem.detach", "torch.cat"], "methods", ["None"], ["", "def", "cache_mem", "(", "self", ",", "curr_out", ",", "prev_mem", ")", ":", "\n", "        ", "\"\"\"cache hidden states into memory.\"\"\"", "\n", "if", "self", ".", "mem_len", "is", "None", "or", "self", ".", "mem_len", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "reuse_len", "is", "not", "None", "and", "self", ".", "reuse_len", ">", "0", ":", "\n", "                ", "curr_out", "=", "curr_out", "[", ":", "self", ".", "reuse_len", "]", "\n", "\n", "", "if", "prev_mem", "is", "None", ":", "\n", "                ", "new_mem", "=", "curr_out", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "", "else", ":", "\n", "                ", "new_mem", "=", "torch", ".", "cat", "(", "[", "prev_mem", ",", "curr_out", "]", ",", "dim", "=", "0", ")", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "\n", "", "", "return", "new_mem", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.positional_embedding": [[811, 821], ["torch.einsum", "torch.cat", "pos_emb.expand.expand.expand", "torch.sin", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "positional_embedding", "(", "pos_seq", ",", "inv_freq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "einsum", "(", "'i,d->id'", ",", "pos_seq", ",", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "sinusoid_inp", ")", ",", "torch", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "pos_emb", "=", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "pos_emb", "=", "pos_emb", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.relative_positional_encoding": [[822, 860], ["torch.arange", "modeling_xlnet.XLNetModel.to", "torch.pow", "torch.arange", "torch.arange", "torch.cat", "torch.arange", "modeling_xlnet.XLNetModel.positional_embedding", "next", "ValueError", "fwd_pos_seq.clamp.clamp.clamp", "bwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "fwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.parameters"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.positional_embedding"], ["", "def", "relative_positional_encoding", "(", "self", ",", "qlen", ",", "klen", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "\"\"\"create relative positional encoding.\"\"\"", "\n", "freq_seq", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "d_model", ",", "2.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "inv_freq", "=", "1", "/", "torch", ".", "pow", "(", "10000", ",", "(", "freq_seq", "/", "self", ".", "d_model", ")", ")", "\n", "\n", "if", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "# beg, end = klen - 1, -qlen", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "qlen", "\n", "", "elif", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "# beg, end = klen - 1, -1", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown `attn_type` {}.'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "", "if", "self", ".", "bi_data", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bwd_pos_seq", "=", "torch", ".", "arange", "(", "-", "beg", ",", "-", "end", ",", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "bwd_pos_seq", "=", "bwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "\n", "", "if", "bsz", "is", "not", "None", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "", "else", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ")", "\n", "\n", "", "pos_emb", "=", "torch", ".", "cat", "(", "[", "fwd_pos_emb", ",", "bwd_pos_emb", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", ")", "\n", "\n", "", "pos_emb", "=", "pos_emb", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.forward": [[861, 1004], ["input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_xlnet.XLNetModel.word_embedding", "modeling_xlnet.XLNetModel.dropout", "modeling_xlnet.XLNetModel.relative_positional_encoding", "modeling_xlnet.XLNetModel.dropout", "enumerate", "modeling_xlnet.XLNetModel.dropout", "token_type_ids.transpose().contiguous", "input_mask.transpose().contiguous", "attention_mask.transpose().contiguous", "perm_mask.permute().contiguous", "target_mapping.permute().contiguous", "next", "next", "modeling_xlnet.XLNetModel.create_mask", "torch.zeros().to", "torch.cat", "torch.cat", "modeling_xlnet.XLNetModel.mask_emb.expand", "modeling_xlnet.XLNetModel.dropout", "torch.zeros", "torch.cat", "torch.nn.functional.one_hot().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "layer_module", "tuple.append", "modeling_xlnet.XLNetModel.permute().contiguous", "tuple", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "modeling_xlnet.XLNetModel.parameters", "modeling_xlnet.XLNetModel.parameters", "ValueError", "torch.eye().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "len", "tuple.append", "tuple.append", "tuple", "tuple", "token_type_ids.transpose", "input_mask.transpose", "attention_mask.transpose", "perm_mask.permute", "target_mapping.permute", "torch.zeros", "torch.zeros().to", "torch.nn.functional.one_hot", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.cache_mem", "modeling_xlnet.XLNetModel.permute", "t.permute().contiguous", "torch.eye", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "h.permute().contiguous", "hs.permute().contiguous", "torch.zeros", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.parameters", "t.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "h.permute", "hs.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.relative_positional_encoding", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.create_mask", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel.cache_mem"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# the original code for XLNet uses shapes [len, bsz] with the batch dimension at the end", "\n", "# but we want a unified interface in the library with the batch size on the first dimension", "\n", "# so we move here the first dimension (batch) to the end", "\n", "        ", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "token_type_ids", "=", "token_type_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "input_mask", "=", "input_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "attention_mask", "=", "attention_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "perm_mask", "=", "perm_mask", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "perm_mask", "is", "not", "None", "else", "None", "\n", "target_mapping", "=", "target_mapping", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "target_mapping", "is", "not", "None", "else", "None", "\n", "\n", "qlen", ",", "bsz", "=", "input_ids", ".", "shape", "[", "0", "]", ",", "input_ids", ".", "shape", "[", "1", "]", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "shape", "[", "0", "]", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "dtype_float", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "##### Attention mask", "\n", "# causal attention mask", "\n", "if", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "            ", "attn_mask", "=", "self", ".", "create_mask", "(", "qlen", ",", "mlen", ")", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported attention type: {}'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "# data mask: input mask & perm mask", "\n", "", "assert", "input_mask", "is", "None", "or", "attention_mask", "is", "None", ",", "\"You can only use one of input_mask (uses 1 for padding) \"", "\n", "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"", "\n", "if", "input_mask", "is", "None", "and", "attention_mask", "is", "not", "None", ":", "\n", "            ", "input_mask", "=", "1.0", "-", "attention_mask", "\n", "", "if", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "+", "perm_mask", "\n", "", "elif", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "\n", "", "elif", "input_mask", "is", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "perm_mask", "\n", "", "else", ":", "\n", "            ", "data_mask", "=", "None", "\n", "\n", "", "if", "data_mask", "is", "not", "None", ":", "\n", "# all mems can be attended to", "\n", "            ", "mems_mask", "=", "torch", ".", "zeros", "(", "[", "data_mask", ".", "shape", "[", "0", "]", ",", "mlen", ",", "bsz", "]", ")", ".", "to", "(", "data_mask", ")", "\n", "data_mask", "=", "torch", ".", "cat", "(", "[", "mems_mask", ",", "data_mask", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "None", ":", "\n", "                ", "attn_mask", "=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "                ", "attn_mask", "+=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "(", "attn_mask", ">", "0", ")", ".", "to", "(", "dtype_float", ")", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "non_tgt_mask", "=", "-", "torch", ".", "eye", "(", "qlen", ")", ".", "to", "(", "attn_mask", ")", "\n", "non_tgt_mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", ".", "to", "(", "attn_mask", ")", ",", "non_tgt_mask", "]", ",", "dim", "=", "-", "1", ")", "\n", "non_tgt_mask", "=", "(", "(", "attn_mask", "+", "non_tgt_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ">", "0", ")", ".", "to", "(", "attn_mask", ")", "\n", "", "else", ":", "\n", "            ", "non_tgt_mask", "=", "None", "\n", "\n", "##### Word embeddings and prepare h & g hidden states", "\n", "", "word_emb_k", "=", "self", ".", "word_embedding", "(", "input_ids", ")", "\n", "output_h", "=", "self", ".", "dropout", "(", "word_emb_k", ")", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "            ", "word_emb_q", "=", "self", ".", "mask_emb", ".", "expand", "(", "target_mapping", ".", "shape", "[", "0", "]", ",", "bsz", ",", "-", "1", ")", "\n", "# else:  # We removed the inp_q input which was same as target mapping", "\n", "#     inp_q_ext = inp_q[:, :, None]", "\n", "#     word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k", "\n", "output_g", "=", "self", ".", "dropout", "(", "word_emb_q", ")", "\n", "", "else", ":", "\n", "            ", "output_g", "=", "None", "\n", "\n", "##### Segment embedding", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "# Convert `token_type_ids` to one-hot `seg_mat`", "\n", "            ", "mem_pad", "=", "torch", ".", "zeros", "(", "[", "mlen", ",", "bsz", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "cat_ids", "=", "torch", ".", "cat", "(", "[", "mem_pad", ",", "token_type_ids", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# `1` indicates not in the same segment [qlen x klen x bsz]", "\n", "seg_mat", "=", "(", "token_type_ids", "[", ":", ",", "None", "]", "!=", "cat_ids", "[", "None", ",", ":", "]", ")", ".", "long", "(", ")", "\n", "seg_mat", "=", "F", ".", "one_hot", "(", "seg_mat", ",", "num_classes", "=", "2", ")", ".", "to", "(", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "seg_mat", "=", "None", "\n", "\n", "##### Positional encoding", "\n", "", "pos_emb", "=", "self", ".", "relative_positional_encoding", "(", "qlen", ",", "klen", ",", "bsz", "=", "bsz", ")", "\n", "pos_emb", "=", "self", ".", "dropout", "(", "pos_emb", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "new_mems", "=", "(", ")", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "[", "None", "]", "*", "len", "(", "self", ".", "layer", ")", "\n", "\n", "", "attentions", "=", "[", "]", "\n", "hidden_states", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "# cache new mems", "\n", "            ", "new_mems", "=", "new_mems", "+", "(", "self", ".", "cache_mem", "(", "output_h", ",", "mems", "[", "i", "]", ")", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "outputs", "=", "layer_module", "(", "output_h", ",", "output_g", ",", "attn_mask_h", "=", "non_tgt_mask", ",", "attn_mask_g", "=", "attn_mask", ",", "\n", "r", "=", "pos_emb", ",", "seg_mat", "=", "seg_mat", ",", "mems", "=", "mems", "[", "i", "]", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "# Add last hidden state", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "output", "=", "self", ".", "dropout", "(", "output_g", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "# Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)", "\n", "outputs", "=", "(", "output", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ",", "new_mems", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "if", "output_g", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "h", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", "for", "h", "in", "hs", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "hs", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "attentions", "=", "tuple", "(", "t", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "\n", "", "return", "outputs", "# outputs, new_mems, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetLMHeadModel.__init__": [[1050, 1060], ["modeling_xlnet.XLNetPreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetLMHeadModel.apply", "modeling_xlnet.XLNetLMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetLMHeadModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "lm_loss", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "n_token", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetLMHeadModel.tie_weights": [[1061, 1065], ["modeling_xlnet.XLNetLMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_loss", ",", "self", ".", "transformer", ".", "word_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetLMHeadModel.forward": [[1066, 1086], ["modeling_xlnet.XLNetLMHeadModel.transformer", "modeling_xlnet.XLNetLMHeadModel.lm_loss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetLMHeadModel.view", "labels.view", "modeling_xlnet.XLNetLMHeadModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "labels", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "perm_mask", "=", "perm_mask", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "logits", "=", "self", ".", "lm_loss", "(", "transformer_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Flatten the tokens", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, mems, (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetForMultiLabelSequenceClassification.__init__": [[1129, 1141], ["modeling_xlnet.XLNetPreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.SequenceSummary", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss", "modeling_xlnet.XLNetForMultiLabelSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "reweighting_factors", ")", ":", "\n", "        ", "super", "(", "XLNetForMultiLabelSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "self", ".", "AdaptiveMultiLabel", "=", "AdaptiveBCEWithLogitsLoss", "(", "config", ".", "last_hidden_size", ",", "config", ".", "num_labels", ",", "\n", "config", ".", "adaptive_cutoff", ",", "config", ".", "div_value", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n", "self", ".", "reweighting_factors", "=", "reweighting_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetForMultiLabelSequenceClassification.forward": [[1142, 1159], ["modeling_xlnet.XLNetForMultiLabelSequenceClassification.transformer", "modeling_xlnet.XLNetForMultiLabelSequenceClassification.sequence_summary", "modeling_xlnet.XLNetForMultiLabelSequenceClassification.AdaptiveMultiLabel", "modeling_xlnet.XLNetForMultiLabelSequenceClassification.AdaptiveMultiLabel.predict", "modeling_xlnet.XLNetForMultiLabelSequenceClassification.detach"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel.predict"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "labels", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "xlnet_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "perm_mask", "=", "perm_mask", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "output", "=", "xlnet_outputs", "[", "0", "]", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "# mohamm: output is the last hidden layer (output) of the model. So its size is batch_size*last_hidden_size (768 by default)", "\n", "loss", "=", "self", ".", "AdaptiveMultiLabel", "(", "output", ",", "labels", ",", "self", ".", "reweighting_factors", ")", "\n", "\n", "output", "=", "self", ".", "AdaptiveMultiLabel", ".", "predict", "(", "output", ".", "detach", "(", ")", ")", "\n", "\n", "outputs", "=", "(", "loss", ",", "output", ")", "\n", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.build_tf_xlnet_to_pytorch_map": [[57, 126], ["hasattr", "tf_to_pt_map.update", "enumerate", "tf_to_pt_map.update", "hasattr", "tf_to_pt_map.update", "hasattr", "hasattr", "r_r_list.append", "r_w_list.append", "r_s_list.append", "seg_embed_list.append"], "function", ["None"], ["def", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", "=", "None", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        I use a map to keep the PyTorch model as\n        identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "'transformer'", ")", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "'lm_loss'", ")", ":", "\n", "# We will load also the output bias", "\n", "            ", "tf_to_pt_map", "[", "'model/lm_loss/bias'", "]", "=", "model", ".", "lm_loss", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "'sequence_summary'", ")", "and", "'model/sequnece_summary/summary/kernel'", "in", "tf_weights", ":", "\n", "# We will load also the sequence summary", "\n", "            ", "tf_to_pt_map", "[", "'model/sequnece_summary/summary/kernel'", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "weight", "\n", "tf_to_pt_map", "[", "'model/sequnece_summary/summary/bias'", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "'logits_proj'", ")", "and", "config", ".", "finetuning_task", "is", "not", "None", "and", "'model/regression_{}/logit/kernel'", ".", "format", "(", "config", ".", "finetuning_task", ")", "in", "tf_weights", ":", "\n", "            ", "tf_to_pt_map", "[", "'model/regression_{}/logit/kernel'", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "weight", "\n", "tf_to_pt_map", "[", "'model/regression_{}/logit/bias'", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "bias", "\n", "\n", "# Now load the rest of the transformer", "\n", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings and output", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "'model/transformer/word_embedding/lookup_table'", ":", "model", ".", "word_embedding", ".", "weight", ",", "\n", "'model/transformer/mask_emb/mask_emb'", ":", "model", ".", "mask_emb", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layer", ")", ":", "\n", "        ", "layer_str", "=", "\"model/transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "rel_attn", ".", "o", ",", "\n", "layer_str", "+", "\"rel_attn/q/kernel\"", ":", "b", ".", "rel_attn", ".", "q", ",", "\n", "layer_str", "+", "\"rel_attn/k/kernel\"", ":", "b", ".", "rel_attn", ".", "k", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "rel_attn", ".", "r", ",", "\n", "layer_str", "+", "\"rel_attn/v/kernel\"", ":", "b", ".", "rel_attn", ".", "v", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "ff", ".", "layer_1", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "ff", ".", "layer_1", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "ff", ".", "layer_2", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "ff", ".", "layer_2", ".", "bias", ",", "\n", "}", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "r_s_list", "=", "[", "]", "\n", "seg_embed_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layer", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_w_bias", ")", "\n", "r_s_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_s_bias", ")", "\n", "seg_embed_list", ".", "append", "(", "b", ".", "rel_attn", ".", "seg_embed", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "r_s_list", "=", "[", "model", ".", "r_s_bias", "]", "\n", "seg_embed_list", "=", "[", "model", ".", "seg_embed", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\n", "'model/transformer/r_r_bias'", ":", "r_r_list", ",", "\n", "'model/transformer/r_w_bias'", ":", "r_w_list", ",", "\n", "'model/transformer/r_s_bias'", ":", "r_s_list", ",", "\n", "'model/transformer/seg_embed'", ":", "seg_embed_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.load_tf_weights_in_xlnet": [[127, 185], ["tf.train.list_variables", "modeling_xlnet.build_tf_xlnet_to_pytorch_map", "build_tf_xlnet_to_pytorch_map.items", "logger.info", "logger.info", "tf.train.load_variable", "logger.info", "isinstance", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "logger.error", "logger.info", "logger.info", "np.transpose", "enumerate", "logger.info", "torch.from_numpy", "len", "logger.info", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.build_tf_xlnet_to_pytorch_map"], ["", "def", "load_tf_weights_in_xlnet", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "# Load weights from TF model", "\n", "", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", ")", "\n", "\n", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Importing {}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "name", "not", "in", "tf_weights", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} not in tf pre-trained weights, skipping\"", ".", "format", "(", "name", ")", ")", "\n", "continue", "\n", "", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "'kernel'", "in", "name", "and", "(", "'ff'", "in", "name", "or", "'summary'", "in", "name", "or", "'logit'", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Transposing\"", ")", "\n", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "isinstance", "(", "pointer", ",", "list", ")", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam'", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam_1'", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "', '", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.gelu": [[187, 194], ["torch.tanh", "math.sqrt", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function.\n        XLNet is using OpenAI GPT's gelu (not exactly the same as BERT)\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.swish": [[196, 198], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.url_to_filename": [[49, 65], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.encode"], ["def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.filename_to_url": [[67, 91], ["os.path.join", "isinstance", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.cached_path": [[93, 121], ["urlparse", "isinstance", "str", "isinstance", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.split_s3_path": [[123, 134], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.s3_request": [[136, 153], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.s3_etag": [[155, 162], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.s3_get": [[164, 170], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.http_get": [[172, 182], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["None"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.get_from_cache": [[184, 260], ["url.startswith", "file_utils.url_to_filename", "os.path.join", "isinstance", "str", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "response.headers.get.decode", "fnmatch.filter", "list", "os.path.exists", "isinstance", "requests.head", "os.path.exists", "os.listdir", "filter", "os.path.join", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "requests.head.headers.get", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dumps", "meta_file.write", "isinstance", "unicode", "s.endswith"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.url_to_filename", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.s3_etag", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.s3_get", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.http_get"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "not", "isinstance", "(", "cache_dir", ",", "str", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "EnvironmentError", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "etag", "is", "not", "None", ":", "\n", "        ", "etag", "=", "etag", ".", "decode", "(", "'utf-8'", ")", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n", "# try to get the last downloaded one", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "'.*'", ")", "\n", "matching_files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "s", ".", "endswith", "(", "'.json'", ")", ",", "matching_files", ")", ")", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ")", "as", "meta_file", ":", "\n", "                ", "output_string", "=", "json", ".", "dumps", "(", "meta", ")", "\n", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "output_string", ",", "str", ")", ":", "\n", "                    ", "output_string", "=", "unicode", "(", "output_string", ",", "'utf-8'", ")", "# The beauty of python 2", "\n", "", "meta_file", ".", "write", "(", "output_string", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.bos_token": [[98, 101], ["None"], "methods", ["None"], ["", "@", "bos_token", ".", "setter", "\n", "def", "bos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.eos_token": [[102, 105], ["None"], "methods", ["None"], ["", "@", "eos_token", ".", "setter", "\n", "def", "eos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_eos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.unk_token": [[106, 109], ["None"], "methods", ["None"], ["", "@", "unk_token", ".", "setter", "\n", "def", "unk_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_unk_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.sep_token": [[110, 113], ["None"], "methods", ["None"], ["", "@", "sep_token", ".", "setter", "\n", "def", "sep_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_sep_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.pad_token": [[114, 117], ["None"], "methods", ["None"], ["", "@", "pad_token", ".", "setter", "\n", "def", "pad_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_pad_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.cls_token": [[118, 121], ["None"], "methods", ["None"], ["", "@", "cls_token", ".", "setter", "\n", "def", "cls_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_cls_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.mask_token": [[122, 125], ["None"], "methods", ["None"], ["", "@", "mask_token", ".", "setter", "\n", "def", "mask_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_mask_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.additional_special_tokens": [[126, 129], ["None"], "methods", ["None"], ["", "@", "additional_special_tokens", ".", "setter", "\n", "def", "additional_special_tokens", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_additional_special_tokens", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.__init__": [[130, 147], ["kwargs.items", "int", "setattr"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "max_len", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "None", "\n", "self", ".", "_eos_token", "=", "None", "\n", "self", ".", "_unk_token", "=", "None", "\n", "self", ".", "_sep_token", "=", "None", "\n", "self", ".", "_pad_token", "=", "None", "\n", "self", ".", "_cls_token", "=", "None", "\n", "self", ".", "_mask_token", "=", "None", "\n", "self", ".", "_additional_special_tokens", "=", "[", "]", "\n", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "self", ".", "added_tokens_encoder", "=", "{", "}", "\n", "self", ".", "added_tokens_decoder", "=", "{", "}", "\n", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.from_pretrained": [[149, 152], ["cls._from_pretrained"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._from_pretrained"], ["", "", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "cls", ".", "_from_pretrained", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._from_pretrained": [[154, 253], ["list", "vocab_files.items", "resolved_vocab_files.pop", "resolved_vocab_files.pop", "resolved_vocab_files.items", "cls", "cls.max_model_input_sizes.keys", "cls.pretrained_vocab_files_map.items", "cls.pretrained_vocab_files_map.items", "vocab_files.items", "json.load", "json.load.items", "json.load", "cls.added_tokens_encoder.update", "cls.added_tokens_decoder.update", "os.path.join", "logger.info", "logger.info", "isinstance", "min", "io.open", "io.open", "file_utils.cached_path", "logger.error", "logger.error", "kwargs.get", "json.load.items", "int", "str", "vocab_files.keys"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "_from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedTokenizer from pre-trained vocabulary files.\n        Download and cache the vocabulary files if needed.\n        \"\"\"", "\n", "s3_models", "=", "list", "(", "cls", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "vocab_files", "=", "{", "}", "\n", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "            ", "for", "file_id", ",", "map_list", "in", "cls", ".", "pretrained_vocab_files_map", ".", "items", "(", ")", ":", "\n", "                ", "vocab_files", "[", "file_id", "]", "=", "map_list", "[", "pretrained_model_name_or_path", "]", "\n", "", "", "else", ":", "# mohamm", "\n", "            ", "for", "file_id", ",", "_", "in", "cls", ".", "pretrained_vocab_files_map", ".", "items", "(", ")", ":", "\n", "                ", "vocab_files", "[", "file_id", "]", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "'spiece.model'", ")", "\n", "# else:", "\n", "#     logger.info(", "\n", "#         \"Model name '{}' not found in model shortcut name list ({}). \"", "\n", "#         \"Assuming '{}' is a path or url to a directory containing tokenizer files.\".format(", "\n", "#             pretrained_model_name_or_path, ', '.join(s3_models),", "\n", "#             pretrained_model_name_or_path))", "\n", "#     all_vocab_files_names = {'added_tokens_file': ADDED_TOKENS_FILE,", "\n", "#                              'special_tokens_map_file': SPECIAL_TOKENS_MAP_FILE}", "\n", "#     all_vocab_files_names.update(cls.vocab_files_names)", "\n", "#     for file_id, file_name in all_vocab_files_names.items():", "\n", "#         if os.path.isdir(pretrained_model_name_or_path):", "\n", "#             full_file_name = os.path.join(pretrained_model_name_or_path, file_name)", "\n", "#         else:", "\n", "#             full_file_name = pretrained_model_name_or_path", "\n", "#         if not os.path.exists(full_file_name):", "\n", "#             logger.info(\"Didn't find file {}. We won't load it.\".format(full_file_name))", "\n", "#             full_file_name = None", "\n", "#         vocab_files[file_id] = full_file_name", "\n", "#     if all(full_file_name is None for full_file_name in vocab_files.values()):", "\n", "#         logger.error(", "\n", "#             \"Model name '{}' was not found in model name list ({}). \"", "\n", "#             \"We assumed '{}' was a path or url but couldn't find tokenizer files\"", "\n", "#             \"at this path or url.\".format(", "\n", "#                 pretrained_model_name_or_path, ', '.join(s3_models),", "\n", "#                 pretrained_model_name_or_path, ))", "\n", "#         return None", "\n", "\n", "# Get files from url, cache, or disk depending on the case", "\n", "", "", "try", ":", "\n", "            ", "resolved_vocab_files", "=", "{", "}", "\n", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "                ", "if", "file_path", "is", "None", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "None", "\n", "", "else", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "cached_path", "(", "file_path", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "                ", "logger", ".", "error", "(", "\"Couldn't reach server to download vocabulary.\"", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", "str", "(", "vocab_files", ".", "keys", "(", ")", ")", ")", ")", "\n", "", "return", "None", "\n", "\n", "", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "file_path", "==", "resolved_vocab_files", "[", "file_id", "]", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {} from cache at {}\"", ".", "format", "(", "\n", "file_path", ",", "resolved_vocab_files", "[", "file_id", "]", ")", ")", "\n", "\n", "# Set max length if needed", "\n", "", "", "if", "pretrained_model_name_or_path", "in", "cls", ".", "max_model_input_sizes", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer", "\n", "# wont index sequences longer than the number of positional embeddings", "\n", "            ", "max_len", "=", "cls", ".", "max_model_input_sizes", "[", "pretrained_model_name_or_path", "]", "\n", "if", "max_len", "is", "not", "None", "and", "isinstance", "(", "max_len", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "\n", "# Merge resolved_vocab_files arguments in kwargs.", "\n", "", "", "added_tokens_file", "=", "resolved_vocab_files", ".", "pop", "(", "'added_tokens_file'", ",", "None", ")", "\n", "special_tokens_map_file", "=", "resolved_vocab_files", ".", "pop", "(", "'special_tokens_map_file'", ",", "None", ")", "\n", "for", "args_name", ",", "file_path", "in", "resolved_vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "args_name", "not", "in", "kwargs", ":", "\n", "                ", "kwargs", "[", "args_name", "]", "=", "file_path", "\n", "", "", "if", "special_tokens_map_file", "is", "not", "None", ":", "\n", "            ", "special_tokens_map", "=", "json", ".", "load", "(", "open", "(", "special_tokens_map_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "for", "key", ",", "value", "in", "special_tokens_map", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "kwargs", ":", "\n", "                    ", "kwargs", "[", "key", "]", "=", "value", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "", "", "tokenizer", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "# Add supplementary tokens.", "\n", "if", "added_tokens_file", "is", "not", "None", ":", "\n", "            ", "added_tok_encoder", "=", "json", ".", "load", "(", "open", "(", "added_tokens_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "tokenizer", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "tokenizer", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.save_pretrained": [[255, 280], ["os.path.join", "os.path.join", "tokenization_utils.PreTrainedTokenizer.save_vocabulary", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "f.write", "json.dumps", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.save_vocabulary"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary files (with added tokens) and the\n            special-tokens-to-class-attributes-mapping to a directory, so that it\n            can be re-loaded using the `from_pretrained(save_directory)` class method.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Saving directory ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "\n", "", "special_tokens_map_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "SPECIAL_TOKENS_MAP_FILE", ")", "\n", "added_tokens_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "ADDED_TOKENS_FILE", ")", "\n", "\n", "with", "open", "(", "special_tokens_map_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "special_tokens_map", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "with", "open", "(", "added_tokens_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "if", "self", ".", "added_tokens_encoder", ":", "\n", "                ", "out_str", "=", "json", ".", "dumps", "(", "self", ".", "added_tokens_decoder", ",", "ensure_ascii", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "out_str", "=", "u\"{}\"", "\n", "", "f", ".", "write", "(", "out_str", ")", "\n", "\n", "", "vocab_files", "=", "self", ".", "save_vocabulary", "(", "save_directory", ")", "\n", "\n", "return", "vocab_files", "+", "(", "special_tokens_map_file", ",", "added_tokens_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.save_vocabulary": [[282, 290], ["None"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary to a directory. This method doesn't save added tokens\n            and special token mappings.\n            \n            Please use `save_pretrained()` to save the full Tokenizer state so that it can be\n            reloaded using the `from_pretrained(save_directory)` class method.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.vocab_size": [[292, 294], ["None"], "methods", ["None"], ["", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.__len__": [[296, 298], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "+", "len", "(", "self", ".", "added_tokens_encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.add_tokens": [[300, 324], ["dict", "tokenization_utils.PreTrainedTokenizer.added_tokens_encoder.update", "tokenization_utils.PreTrainedTokenizer.added_tokens_decoder.update", "len", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "to_add_tokens.append", "logger.info", "dict.items", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "add_tokens", "(", "self", ",", "new_tokens", ")", ":", "\n", "        ", "\"\"\" Add a list of new tokens to the tokenizer class. If the new tokens are not in the\n            vocabulary, they are added to the added_tokens_encoder with indices starting from\n            the last index of the current vocabulary.\n\n            Returns:\n                Number of tokens added to the vocabulary which can be used to correspondingly\n                    increase the size of the associated model embedding matrices.\n        \"\"\"", "\n", "if", "not", "new_tokens", ":", "\n", "            ", "return", "0", "\n", "\n", "", "to_add_tokens", "=", "[", "]", "\n", "for", "token", "in", "new_tokens", ":", "\n", "            ", "if", "self", ".", "convert_tokens_to_ids", "(", "token", ")", "==", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "unk_token", ")", ":", "\n", "                ", "to_add_tokens", ".", "append", "(", "token", ")", "\n", "logger", ".", "info", "(", "\"Adding %s to the vocabulary\"", ",", "token", ")", "\n", "\n", "", "", "added_tok_encoder", "=", "dict", "(", "(", "tok", ",", "len", "(", "self", ")", "+", "i", ")", "for", "i", ",", "tok", "in", "enumerate", "(", "to_add_tokens", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "self", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "return", "len", "(", "to_add_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.add_special_tokens": [[326, 344], ["tokenization_utils.PreTrainedTokenizer.add_tokens", "special_tokens_dict.items", "special_tokens_dict.values", "logger.info", "setattr"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.add_tokens"], ["", "def", "add_special_tokens", "(", "self", ",", "special_tokens_dict", ")", ":", "\n", "        ", "\"\"\" Add a dictionnary of special tokens (eos, pad, cls...) to the encoder and link them\n            to class attributes. If the special tokens are not in the vocabulary, they are added\n            to it and indexed starting from the last index of the current vocabulary.\n\n            Returns:\n                Number of tokens added to the vocabulary which can be used to correspondingly\n                    increase the size of the associated model embedding matrices.\n        \"\"\"", "\n", "if", "not", "special_tokens_dict", ":", "\n", "            ", "return", "0", "\n", "\n", "", "added_special_tokens", "=", "self", ".", "add_tokens", "(", "special_tokens_dict", ".", "values", "(", ")", ")", "\n", "for", "key", ",", "value", "in", "special_tokens_dict", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Assigning %s to the %s key of the tokenizer\"", ",", "value", ",", "key", ")", "\n", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n", "", "return", "added_special_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.tokenize": [[346, 366], ["tokenization_utils.PreTrainedTokenizer.tokenize.split_on_tokens"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n\n            Take care of added tokens.\n        \"\"\"", "\n", "def", "split_on_tokens", "(", "tok_list", ",", "text", ")", ":", "\n", "            ", "if", "not", "text", ":", "\n", "                ", "return", "[", "]", "\n", "", "if", "not", "tok_list", ":", "\n", "                ", "return", "self", ".", "_tokenize", "(", "text", ",", "**", "kwargs", ")", "\n", "", "tok", "=", "tok_list", "[", "0", "]", "\n", "split_text", "=", "text", ".", "split", "(", "tok", ")", "\n", "return", "sum", "(", "(", "split_on_tokens", "(", "tok_list", "[", "1", ":", "]", ",", "sub_text", ".", "strip", "(", ")", ")", "+", "[", "tok", "]", "for", "sub_text", "in", "split_text", ")", ",", "[", "]", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "added_tokens", "=", "list", "(", "self", ".", "added_tokens_encoder", ".", "keys", "(", ")", ")", "+", "self", ".", "all_special_tokens", "\n", "tokenized_text", "=", "split_on_tokens", "(", "added_tokens", ",", "text", ")", "\n", "return", "tokenized_text", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._tokenize": [[367, 375], ["None"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n\n            Don't take care of added tokens.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids": [[376, 391], ["isinstance", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "ids.append", "len", "logger.warning", "isinstance", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "len"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a single token or a sequence of tokens (str/unicode) in a integer id\n            (resp.) a sequence of ids, using the vocabulary.\n        \"\"\"", "\n", "if", "isinstance", "(", "tokens", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "tokens", ",", "unicode", ")", ")", ":", "\n", "            ", "return", "self", ".", "_convert_token_to_id_with_added_voc", "(", "tokens", ")", "\n", "\n", "", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "_convert_token_to_id_with_added_voc", "(", "token", ")", ")", "\n", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Token indices sequence length is longer than the specified maximum sequence length \"", "\n", "\"for this model ({} > {}). Running this sequence through the model will result in \"", "\n", "\"indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc": [[392, 396], ["tokenization_utils.PreTrainedTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_token_to_id"], ["", "def", "_convert_token_to_id_with_added_voc", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "added_tokens_encoder", ":", "\n", "            ", "return", "self", ".", "added_tokens_encoder", "[", "token", "]", "\n", "", "return", "self", ".", "_convert_token_to_id", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_token_to_id": [[397, 399], ["None"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.encode": [[401, 406], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "tokenization_utils.PreTrainedTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.tokenize"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of ids (integer), using the tokenizer and vocabulary.\n            same as self.convert_tokens_to_ids(self.tokenize(text)).\n        \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenize", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens": [[408, 429], ["isinstance", "tokenization_utils.PreTrainedTokenizer._convert_id_to_token", "tokens.append", "tokens.append", "tokenization_utils.PreTrainedTokenizer._convert_id_to_token"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_id_to_token", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_id_to_token"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\" Converts a single index or a sequence of indices (integers) in a token \"\n            (resp.) a sequence of tokens (str/unicode), using the vocabulary and added tokens.\n\n            Args:\n                skip_special_tokens: Don't decode special tokens (self.all_special_tokens). Default: False\n        \"\"\"", "\n", "if", "isinstance", "(", "ids", ",", "int", ")", ":", "\n", "            ", "if", "ids", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "return", "self", ".", "added_tokens_decoder", "[", "ids", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_convert_id_to_token", "(", "ids", ")", "\n", "", "", "tokens", "=", "[", "]", "\n", "for", "index", "in", "ids", ":", "\n", "            ", "if", "index", "in", "self", ".", "all_special_ids", "and", "skip_special_tokens", ":", "\n", "                ", "continue", "\n", "", "if", "index", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "added_tokens_decoder", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "_convert_id_to_token", "(", "index", ")", ")", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer._convert_id_to_token": [[430, 432], ["None"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string": [[433, 439], ["tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string.\n            The most simple way to do it is ' '.join(self.convert_ids_to_tokens(token_ids))\n            but we often want to remove sub-word tokenization artifacts at the same time.\n        \"\"\"", "\n", "return", "' '", ".", "join", "(", "self", ".", "convert_ids_to_tokens", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.decode": [[440, 449], ["tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string", "tokenization_utils.clean_up_tokenization"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.clean_up_tokenization"], ["", "def", "decode", "(", "self", ",", "token_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of ids (integer) in a string, using the tokenizer and vocabulary\n            with options to remove special tokens and clean up tokenization spaces.\n        \"\"\"", "\n", "filtered_tokens", "=", "self", ".", "convert_ids_to_tokens", "(", "token_ids", ",", "skip_special_tokens", "=", "skip_special_tokens", ")", "\n", "text", "=", "self", ".", "convert_tokens_to_string", "(", "filtered_tokens", ")", "\n", "if", "clean_up_tokenization_spaces", ":", "\n", "            ", "text", "=", "clean_up_tokenization", "(", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.special_tokens_map": [[450, 461], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "special_tokens_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" A dictionary mapping special token class attribute (cls_token, unk_token...) to their\n            values ('<unk>', '<cls>'...)\n        \"\"\"", "\n", "set_attr", "=", "{", "}", "\n", "for", "attr", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "            ", "attr_value", "=", "getattr", "(", "self", ",", "\"_\"", "+", "attr", ")", "\n", "if", "attr_value", ":", "\n", "                ", "set_attr", "[", "attr", "]", "=", "attr_value", "\n", "", "", "return", "set_attr", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.all_special_tokens": [[462, 473], ["set_attr.values", "list", "set", "isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_special_tokens", "(", "self", ")", ":", "\n", "        ", "\"\"\" List all the special tokens ('<unk>', '<cls>'...) mapped to class attributes\n            (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "[", "]", "\n", "set_attr", "=", "self", ".", "special_tokens_map", "\n", "for", "attr_value", "in", "set_attr", ".", "values", "(", ")", ":", "\n", "            ", "all_toks", "=", "all_toks", "+", "(", "attr_value", "if", "isinstance", "(", "attr_value", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "attr_value", "]", ")", "\n", "", "all_toks", "=", "list", "(", "set", "(", "all_toks", ")", ")", "\n", "return", "all_toks", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.all_special_ids": [[474, 482], ["list", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "all_special_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\" List the vocabulary indices of the special tokens ('<unk>', '<cls>'...) mapped to\n            class attributes (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "self", ".", "all_special_tokens", "\n", "all_ids", "=", "list", "(", "self", ".", "convert_tokens_to_ids", "(", "t", ")", "for", "t", "in", "all_toks", ")", "\n", "return", "all_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.clean_up_tokenization": [[485, 490], ["out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace"], "function", ["None"], ["", "", "def", "clean_up_tokenization", "(", "out_string", ")", ":", "\n", "    ", "out_string", "=", "out_string", ".", "replace", "(", "' .'", ",", "'.'", ")", ".", "replace", "(", "' ?'", ",", "'?'", ")", ".", "replace", "(", "' !'", ",", "'!'", ")", ".", "replace", "(", "' ,'", ",", "','", "\n", ")", ".", "replace", "(", "\" ' \"", ",", "\"'\"", ")", ".", "replace", "(", "\" n't\"", ",", "\"n't\"", ")", ".", "replace", "(", "\" 'm\"", ",", "\"'m\"", ")", ".", "replace", "(", "\" do not\"", ",", "\" don't\"", "\n", ")", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", ".", "replace", "(", "\" 've\"", ",", "\"'ve\"", ")", ".", "replace", "(", "\" 're\"", ",", "\"'re\"", ")", "\n", "return", "out_string", "\n", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.__init__": [[62, 68], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "finetuning_task", "=", "kwargs", ".", "pop", "(", "'finetuning_task'", ",", "None", ")", "\n", "self", ".", "num_labels", "=", "kwargs", ".", "pop", "(", "'num_labels'", ",", "2", ")", "\n", "self", ".", "output_attentions", "=", "kwargs", ".", "pop", "(", "'output_attentions'", ",", "False", ")", "\n", "self", ".", "output_hidden_states", "=", "kwargs", ".", "pop", "(", "'output_hidden_states'", ",", "False", ")", "\n", "self", ".", "torchscript", "=", "kwargs", ".", "pop", "(", "'torchscript'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.save_pretrained": [[69, 79], ["os.path.isdir", "os.path.join", "modeling_utils.PretrainedConfig.to_json_file"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.to_json_file"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a configuration object to a directory, so that it\n            can be re-loaded using the `from_pretrained(save_directory)` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "CONFIG_NAME", ")", "\n", "\n", "self", ".", "to_json_file", "(", "output_config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.from_pretrained": [[80, 152], ["kwargs.pop", "cls.from_json_file", "kwargs.items", "logger.info", "os.path.isdir", "file_utils.cached_path", "logger.info", "logger.info", "hasattr", "kwargs.pop", "os.path.join", "setattr", "to_remove.append", "logger.error", "logger.error", "cls.pretrained_config_archive_map.keys"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a PretrainedConfig from a pre-trained model configuration.\n\n        Params:\n            **pretrained_model_name_or_path**: either:\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache\n                    or download and cache if not already stored in cache (e.g. 'bert-base-uncased').\n                - a path to a `directory` containing a configuration file saved\n                    using the `save_pretrained(save_directory)` method.\n                - a path or url to a saved configuration `file`.\n            **cache_dir**: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n            **kwargs**: (`optional`) dict:\n                Dictionnary of key, values to update the configuration object after loading.\n                Can be used to override selected configuration parameters.\n\n        Examples::\n\n            >>> config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            >>> config = BertConfig.from_pretrained('./test/saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            >>> config = BertConfig.from_pretrained('./test/saved_model/my_configuration.json')\n            >>> config = BertConfig.from_pretrained('bert-base-uncased', output_attention=True)\n            >>> assert config.output_attention == True\n\n        \"\"\"", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "\n", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "            ", "config_file", "=", "cls", ".", "pretrained_config_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "", "else", ":", "\n", "            ", "config_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Couldn't reach server at '{}' to download pretrained model configuration file.\"", ".", "format", "(", "\n", "config_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_config_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "config_file", ")", ")", "\n", "", "return", "None", "\n", "", "if", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "\n", "# Load config", "\n", "", "config", "=", "cls", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "\n", "# Update config with kwargs if needed", "\n", "to_remove", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "key", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "to_remove", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "to_remove", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Model config %s\"", ",", "config", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.from_dict": [[153, 160], ["cls", "json_object.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "cls", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.from_json_file": [[161, 167], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.__eq__": [[168, 170], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.__repr__": [[171, 173], ["str", "modeling_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.to_dict": [[174, 178], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.to_json_string": [[179, 182], ["json.dumps", "modeling_utils.PretrainedConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.to_json_file": [[183, 187], ["io.open", "writer.write", "modeling_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PretrainedConfig.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.__init__": [[199, 210], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel._get_resized_embeddings": [[211, 244], ["old_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.to", "modeling_utils.PreTrainedModel.init_weights", "min"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetPreTrainedModel.init_weights"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Module from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``torch.nn.Embeddings``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "", "old_num_tokens", ",", "old_embedding_dim", "=", "old_embeddings", ".", "weight", ".", "size", "(", ")", "\n", "if", "old_num_tokens", "==", "new_num_tokens", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "# Build new embeddings", "\n", "", "new_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_tokens", ",", "old_embedding_dim", ")", "\n", "new_embeddings", ".", "to", "(", "old_embeddings", ".", "weight", ".", "device", ")", "\n", "\n", "# initialize all new embeddings (in particular added tokens)", "\n", "self", ".", "init_weights", "(", "new_embeddings", ")", "\n", "\n", "# Copy word embeddings from the previous weights", "\n", "num_tokens_to_copy", "=", "min", "(", "old_num_tokens", ",", "new_num_tokens", ")", "\n", "new_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "=", "old_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "\n", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel._tie_or_clone_weights": [[245, 252], ["torch.nn.Parameter", "second_module.weight.clone"], "methods", ["None"], ["", "def", "_tie_or_clone_weights", "(", "self", ",", "first_module", ",", "second_module", ")", ":", "\n", "        ", "\"\"\" Tie or clone module weights depending of weither we are using TorchScript or not\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "            ", "first_module", ".", "weight", "=", "nn", ".", "Parameter", "(", "second_module", ".", "weight", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "first_module", ".", "weight", "=", "second_module", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.resize_token_embeddings": [[253, 281], ["getattr", "getattr._resize_token_embeddings", "hasattr", "modeling_utils.PreTrainedModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel._resize_token_embeddings", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetLMHeadModel.tie_weights"], ["", "", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n            Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: does nothing and just returns a pointer to the input tokens Embedding Module of the model.\n\n        Return: ``torch.nn.Embeddings``\n            Pointer to the input tokens Embedding Module of the model\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "model_embeds", "=", "base_model", ".", "_resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "model_embeds", "\n", "\n", "# Update base model and current model config", "\n", "", "self", ".", "config", ".", "vocab_size", "=", "new_num_tokens", "\n", "base_model", ".", "vocab_size", "=", "new_num_tokens", "\n", "\n", "# Tie weights again if needed", "\n", "if", "hasattr", "(", "self", ",", "'tie_weights'", ")", ":", "\n", "            ", "self", ".", "tie_weights", "(", ")", "\n", "\n", "", "return", "model_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.prune_heads": [[282, 289], ["getattr", "getattr._prune_heads"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_xlnet.XLNetModel._prune_heads"], ["", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n            Args:\n                heads_to_prune: dict of {layer_num (int): list of heads to prune in this layer (list of int)}\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "base_model", ".", "_prune_heads", "(", "heads_to_prune", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.save_pretrained": [[290, 306], ["os.path.isdir", "model_to_save.config.save_pretrained", "os.path.join", "torch.save", "hasattr", "model_to_save.state_dict"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model with its configuration file to a directory, so that it\n            can be re-loaded using the `from_pretrained(save_directory)` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Only save the model it-self if we are using distributed training", "\n", "model_to_save", "=", "self", ".", "module", "if", "hasattr", "(", "self", ",", "'module'", ")", "else", "self", "\n", "\n", "# Save configuration file", "\n", "model_to_save", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "WEIGHTS_NAME", ")", "\n", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.from_pretrained": [[307, 475], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling_utils.PreTrainedModel.from_pretrained.load"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained pytorch model from a pre-trained model configuration.\n\n            The model is set in evaluation mode by default using `model.eval()` (Dropout modules are desactivated)\n            To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            **pretrained_model_name_or_path**: either:\n                - a string with the `shortcut name` of a pre-trained model to load from cache\n                    or download and cache if not already stored in cache (e.g. 'bert-base-uncased').\n                - a path to a `directory` containing a configuration file saved\n                    using the `save_pretrained(save_directory)` method.\n                - a path or url to a tensorflow index checkpoint `file` (e.g. `./tf_model/model.ckpt.index`).\n                    In this case, ``from_tf`` should be set to True and a configuration object should be\n                    provided as `config` argument. This loading option is slower than converting the TensorFlow\n                    checkpoint in a PyTorch model using the provided conversion scripts and loading\n                    the PyTorch model afterwards.\n            **config**: an optional configuration for the model to use instead of an automatically loaded configuation.\n                Configuration can be automatically loaded when:\n                - the model is a model provided by the library (loaded with a `shortcut name` of a pre-trained model), or\n                - the model was saved using the `save_pretrained(save_directory)` (loaded by suppling the save directory).\n            **state_dict**: an optional state dictionnary for the model to use instead of a state dictionary loaded\n                from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuraton but load your own weights.\n                In this case though, you should check if using `save_pretrained(dir)` and `from_pretrained(save_directory)` is not\n                a simpler option.\n            **cache_dir**: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n            **output_loading_info**: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n            **kwargs**: (`optional`) dict:\n                Dictionnary of key, values to update the configuration object after loading.\n                Can be used to override selected configuration parameters. E.g. ``output_attention=True``\n\n        Examples::\n\n            >>> model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            >>> model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            >>> model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            >>> assert model.config.output_attention == True\n            >>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            >>> config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            >>> model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "'config'", ",", "None", ")", "\n", "reweighting_factors", "=", "kwargs", ".", "pop", "(", "'reweighting_factors'", ",", "None", ")", "# mohamm", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "'state_dict'", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "'from_tf'", ",", "False", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "'output_loading_info'", ",", "False", ")", "\n", "\n", "# Load config", "\n", "if", "config", "is", "None", ":", "\n", "            ", "config", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "            ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "                ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "\n", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "reweighting_factors", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "return", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# Load from a PyTorch state_dict", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "''", "\n", "model_to_load", "=", "model", "\n", "if", "not", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "cls", ".", "base_model_prefix", "+", "'.'", "\n", "", "if", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "not", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "model_to_load", "=", "getattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "\n", "\n", "", "load", "(", "model_to_load", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "model", ",", "'tie_weights'", ")", ":", "\n", "            ", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.Conv1D.__init__": [[478, 488], ["torch.nn.Module.__init__", "torch.empty", "torch.nn.init.normal_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ")", ":", "\n", "        ", "\"\"\" Conv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.Conv1D.forward": [[489, 494], ["torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PoolerStartLogits.__init__": [[498, 501], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerStartLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PoolerStartLogits.forward": [[502, 514], ["modeling_utils.PoolerStartLogits.dense().squeeze", "modeling_utils.PoolerStartLogits.dense"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape `(batch_size, seq_len)`\n                invalid position mask such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "x", "=", "self", ".", "dense", "(", "hidden_states", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PoolerEndLogits.__init__": [[519, 525], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.LayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerEndLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PoolerEndLogits.forward": [[526, 555], ["modeling_utils.PoolerEndLogits.dense_0", "modeling_utils.PoolerEndLogits.activation", "modeling_utils.PoolerEndLogits.LayerNorm", "modeling_utils.PoolerEndLogits.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather", "start_states.expand.expand.expand", "torch.cat", "modeling_utils.PoolerEndLogits.dense_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to hidden_states\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span: \n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(batch_size, seq_len)``\n                Mask of invalid position such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "assert", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "slen", ",", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "2", ":", "]", "\n", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "start_states", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ")", "# shape (bsz, slen, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "hidden_states", ",", "start_states", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "LayerNorm", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PoolerAnswerClass.__init__": [[559, 564], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerAnswerClass", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PoolerAnswerClass.forward": [[565, 599], ["modeling_utils.PoolerAnswerClass.dense_0", "modeling_utils.PoolerAnswerClass.activation", "modeling_utils.PoolerAnswerClass.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather().squeeze", "cls_index[].expand", "hidden_states.gather().squeeze", "torch.cat", "modeling_utils.PoolerAnswerClass.dense_1", "hidden_states.gather", "hidden_states.gather"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to ``hidden_states``.\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span.\n            **cls_index**: torch.LongTensor of shape ``(batch_size,)``\n                position of the CLS token. If None, take the last token.\n\n            note(Original repo):\n                no dependency on end_feature so that we can obtain one single `cls_logits`\n                for each sample\n        \"\"\"", "\n", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "1", "]", "\n", "assert", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "\n", "", "if", "cls_index", "is", "not", "None", ":", "\n", "            ", "cls_index", "=", "cls_index", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "cls_token_state", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "", "else", ":", "\n", "            ", "cls_token_state", "=", "hidden_states", "[", ":", ",", "-", "1", ",", ":", "]", "# shape (bsz, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "start_states", ",", "cls_token_state", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.SQuADHead.__init__": [[641, 649], ["torch.nn.Module.__init__", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SQuADHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.SQuADHead.forward": [[650, 708], ["modeling_utils.SQuADHead.start_logits", "modeling_utils.SQuADHead.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_utils.SQuADHead.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_utils.SQuADHead.answer_class", "modeling_utils.SQuADHead.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "\n", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "start_states", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.SequenceSummary.__init__": [[725, 758], ["torch.nn.Module.__init__", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "hasattr", "hasattr", "torch.nn.Linear", "hasattr", "torch.nn.Tanh", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Dropout", "hasattr"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SequenceSummary", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "else", "'last'", "\n", "if", "config", ".", "summary_type", "==", "'attn'", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "summary", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "and", "config", ".", "summary_use_proj", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "'summary_proj_to_labels'", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "# num_classes = config.hidden_size", "\n", "                ", "num_classes", "=", "config", ".", "last_hidden_size", "\n", "\n", "", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", "\n", "# self.summary = nn.Linear(config.hidden_size, int(num_classes / 2))", "\n", "\n", "\n", "", "self", ".", "activation", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_activation'", ")", "and", "config", ".", "summary_activation", "==", "'tanh'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "self", ".", "first_dropout", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_first_dropout'", ")", "and", "config", ".", "summary_first_dropout", ">", "0", ":", "\n", "            ", "self", ".", "first_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "last_dropout", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_last_dropout'", ")", "and", "config", ".", "summary_last_dropout", ">", "0", ":", "\n", "            ", "self", ".", "last_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.SequenceSummary.forward": [[759, 789], ["modeling_utils.SequenceSummary.first_dropout", "modeling_utils.SequenceSummary.summary", "modeling_utils.SequenceSummary.activation", "modeling_utils.SequenceSummary.last_dropout", "hidden_states.mean", "hidden_states.gather().squeeze", "torch.full_like", "token_ids.expand.expand.unsqueeze().unsqueeze", "token_ids.expand.expand.expand", "hidden_states.gather", "token_ids.expand.expand.unsqueeze", "hidden_states.size", "token_ids.expand.expand.dim"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "token_ids", "=", "None", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, seq_len, hidden_size], the hidden-states of the last layer.\n            token_ids: [optional] index of the classification token if summary_type == 'token_ids',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'token_ids' and token_ids is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "self", ".", "summary_type", "==", "'last'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'first'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'mean'", ":", "\n", "            ", "output", "=", "hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "'token_ids'", ":", "\n", "            ", "if", "token_ids", "is", "None", ":", "\n", "                ", "token_ids", "=", "torch", ".", "full_like", "(", "hidden_states", "[", "...", ",", ":", "1", ",", ":", "]", ",", "hidden_states", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "                ", "token_ids", "=", "token_ids", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "token_ids", "=", "token_ids", ".", "expand", "(", "(", "-", "1", ",", ")", "*", "(", "token_ids", ".", "dim", "(", ")", "-", "1", ")", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", ")", "\n", "# shape of token_ids: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "token_ids", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, XX, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "output", "=", "self", ".", "first_dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "output", "=", "self", ".", "last_dropout", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.prune_linear_layer": [[791, 814], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "torch.nn.Linear().to", "nn.Linear().to.weight.copy_", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "nn.Linear().to.bias.copy_", "layer.weight.index_select().clone", "layer.bias.clone().detach", "layer.bias[].clone().detach", "torch.nn.Linear", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select", "layer.bias.clone", "layer.bias[].clone"], "function", ["None"], ["", "", "def", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\" Prune a linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "if", "dim", "==", "1", ":", "\n", "            ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "nn", ".", "Linear", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ",", "bias", "=", "layer", ".", "bias", "is", "not", "None", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.prune_conv1d_layer": [[816, 838], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "Conv1D().to", "Conv1D().to.weight.copy_", "Conv1D().to.bias.copy_", "layer.bias.clone().detach", "layer.bias[].clone().detach", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select().clone", "modeling_utils.Conv1D", "layer.bias.clone", "layer.bias[].clone", "layer.weight.index_select"], "function", ["None"], ["", "def", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D layer (a model parameters) to keep only entries in index.\n        A Conv1D work as a Linear layer (see e.g. BERT) but the weights are transposed.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "dim", "==", "0", ":", "\n", "        ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "Conv1D", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.prune_layer": [[840, 851], ["isinstance", "modeling_utils.prune_linear_layer", "isinstance", "modeling_utils.prune_conv1d_layer", "ValueError"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_layer", "(", "layer", ",", "index", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D or nn.Linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "if", "isinstance", "(", "layer", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "return", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "elif", "isinstance", "(", "layer", ",", "Conv1D", ")", ":", "\n", "        ", "return", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Can't prune layer of class {}\"", ".", "format", "(", "layer", ".", "__class__", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.__init__": [[63, 108], ["torch.nn.Module.__init__", "list", "torch.nn.Linear", "torch.nn.ModuleList", "range", "any", "ValueError", "len", "int", "torch.nn.Sequential", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.tail.append", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.cluster_size.append", "sorted", "min", "max", "len", "len", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.ReLU", "torch.nn.Linear", "set", "int"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "n_classes", ",", "cutoffs", ",", "div_value", "=", "2.", ",", "head_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaptiveBCEWithLogitsLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "cutoffs", "=", "list", "(", "cutoffs", ")", "\n", "\n", "if", "(", "cutoffs", "!=", "sorted", "(", "cutoffs", ")", ")", "or", "(", "min", "(", "cutoffs", ")", "<=", "0", ")", "or", "(", "max", "(", "cutoffs", ")", ">", "(", "n_classes", "-", "1", ")", ")", "or", "(", "len", "(", "set", "(", "cutoffs", ")", ")", "!=", "len", "(", "cutoffs", ")", ")", "or", "any", "(", "[", "int", "(", "c", ")", "!=", "c", "for", "c", "in", "cutoffs", "]", ")", ":", "\n", "\n", "            ", "raise", "ValueError", "(", "\"cutoffs should be a sequence of unique, positive \"", "\n", "\"integers sorted in an increasing order, where \"", "\n", "\"each value is between 1 and n_classes-1\"", ")", "\n", "\n", "", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_classes", "]", "\n", "self", ".", "div_value", "=", "div_value", "\n", "self", ".", "head_bias", "=", "head_bias", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "\n", "self", ".", "cluster_size", "=", "[", "]", "\n", "\n", "self", ".", "head", "=", "Linear", "(", "self", ".", "in_features", ",", "self", ".", "head_size", ",", "bias", "=", "self", ".", "head_bias", ")", "\n", "self", ".", "tail", "=", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_clusters", ")", ":", "\n", "\n", "            ", "hsz", "=", "int", "(", "self", ".", "in_features", "//", "(", "self", ".", "div_value", "**", "(", "i", "+", "1", ")", ")", ")", "\n", "osz", "=", "self", ".", "cutoffs", "[", "i", "+", "1", "]", "-", "self", ".", "cutoffs", "[", "i", "]", "\n", "\n", "projection", "=", "Sequential", "(", "\n", "Linear", "(", "self", ".", "in_features", ",", "hsz", ",", "bias", "=", "False", ")", ",", "\n", "LayerNorm", "(", "hsz", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "\n", "# torch.nn.Dropout(p=0.1),", "\n", "Linear", "(", "hsz", ",", "osz", ",", "bias", "=", "False", ")", "\n", ")", "\n", "\n", "self", ".", "tail", ".", "append", "(", "projection", ")", "\n", "self", ".", "cluster_size", ".", "append", "(", "osz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.reset_parameters": [[109, 114], ["Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.head.reset_parameters", "i2h.reset_parameters", "h2o.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.reset_parameters", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.reset_parameters", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.reset_parameters"], ["", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "head", ".", "reset_parameters", "(", ")", "\n", "for", "i2h", ",", "h2o", "in", "self", ".", "tail", ":", "\n", "            ", "i2h", ".", "reset_parameters", "(", ")", "\n", "h2o", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.weighted_binary_cross_entropy": [[115, 125], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "weighted_binary_cross_entropy", "(", "output", ",", "target", ",", "pos_weights", "=", "None", ")", ":", "\n", "\n", "        ", "if", "pos_weights", "is", "not", "None", ":", "\n", "\n", "            ", "loss", "=", "-", "pos_weights", "*", "(", "target", "*", "torch", ".", "clamp", "(", "torch", ".", "log", "(", "output", ")", ",", "-", "100.0", ")", ")", "-", "(", "1", "-", "target", ")", "*", "torch", ".", "clamp", "(", "torch", ".", "log", "(", "1", "-", "output", ")", ",", "-", "100.0", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "-", "target", "*", "torch", ".", "clamp", "(", "torch", ".", "log", "(", "output", ")", ",", "-", "100.0", ")", "-", "(", "1", "-", "target", ")", "*", "torch", ".", "clamp", "(", "torch", ".", "log", "(", "1", "-", "output", ")", ",", "-", "100.0", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.forward": [[126, 222], ["target.size", "input.new_zeros", "target.new_zeros", "target.new_zeros", "range", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.head", "torch.cat", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "torch.sum", "input.size", "target.size", "RuntimeError", "torch.sum", "torch.sum.nonzero().squeeze", "input.index_select", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.get_multi_hot_label().detach", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.view", "torch.cat.view().float", "multiplier.float", "torch.tensor().cuda", "torch.sum", "len", "torch.sum.nonzero().squeeze.numel", "torch.cat.index_copy_", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.head", "torch.nn.Sigmoid", "torch.diag", "torch.mm", "target.new_zeros().index_fill_", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.weighted_binary_cross_entropy", "torch.sum", "input.new_zeros", "input.new_zeros.index_copy_", "torch.sum.nonzero", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.get_multi_hot_label", "torch.nn.Sigmoid.", "torch.nn.Sigmoid.", "torch.mm.view", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.view().float", "reweighting_factors[].to", "torch.cat.view", "torch.tensor", "num_loss.float", "target.new_zeros", "Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.view", "reweighting_factors[].to"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.weighted_binary_cross_entropy", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.get_multi_hot_label"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "reweighting_factors", ")", ":", "\n", "        ", "if", "input", ".", "size", "(", "0", ")", "!=", "target", ".", "size", "(", "0", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Input and target should have the same size '", "\n", "'in the batch dimension.'", ")", "\n", "\n", "# used_rows = 0", "\n", "", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "# output = input.new_zeros(batch_size)", "\n", "# gather_inds = target.new_empty(batch_size)", "\n", "\n", "total_cluster_loss", "=", "input", ".", "new_zeros", "(", "batch_size", ")", "\n", "\n", "# mohamm: [head_onehot,cluster_onehot] is the taget labels of the head cluster", "\n", "head_onehot", "=", "target", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "cutoffs", "[", "0", "]", ")", "# mohamm: batch_size * ...", "\n", "cluster_onehot", "=", "target", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "n_clusters", ")", "# mohamm: batch_size * number of (tail) clusters. This is finally concateneted to head_onehot which are the nodes coressponding to the clusters in the head cluster (labels).", "\n", "\n", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "# # unpacking reweighting_factors", "\n", "# temp_factors = [None] * (len(cutoff_values)-1)", "\n", "# if reweighting_factors is not None:", "\n", "#     temp_factors[0] = reweighting_factors[cutoff_values[0]:cutoff_values[1]+self.n_clusters] # reweighting factors of the head cluster", "\n", "#     temp_factors[1:] = [reweighting_factors[value+self.n_clusters:cutoff_values[index+2]+self.n_clusters] for index, value in enumerate(cutoff_values[1:-1])]", "\n", "# reweighting_factors = temp_factors", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "\n", "            ", "low_idx", "=", "cutoff_values", "[", "i", "]", "\n", "high_idx", "=", "cutoff_values", "[", "i", "+", "1", "]", "\n", "num_idx", "=", "high_idx", "-", "low_idx", "\n", "\n", "target_mask", "=", "(", "target", ">=", "low_idx", ")", "&", "(", "target", "<", "high_idx", ")", "# mohamm: check which true labels are inside this cluster", "\n", "target_mask_row", "=", "torch", ".", "sum", "(", "target_mask", ",", "dim", "=", "1", ")", "\n", "row_indices", "=", "target_mask_row", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "# mohamm: indices of those samples which have a label in this cluster", "\n", "\n", "if", "row_indices", ".", "numel", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "input_subset", "=", "input", ".", "index_select", "(", "0", ",", "row_indices", ")", "# mohamm: select those samples which have a label in this cluster", "\n", "target_onehot", "=", "self", ".", "get_multi_hot_label", "(", "target", ",", "target_mask", ",", "row_indices", ",", "low_idx", ",", "num_idx", ")", ".", "detach", "(", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "# indices =  row_indices.repeat(num_idx, 1).transpose(1,0)", "\n", "                ", "head_onehot", ".", "index_copy_", "(", "0", ",", "row_indices", ",", "target_onehot", ")", "# copy target_onehot in head_onehot (those which are in this cluster otherwise zero)", "\n", "\n", "", "else", ":", "\n", "                ", "head_output", "=", "self", ".", "head", "(", "input_subset", ")", "\n", "cluster_root_output", "=", "head_output", "[", ":", ",", "self", ".", "shortlist_size", "+", "i", "-", "1", "]", "# mohamm: the output corresponding to this cluster in the head cluster", "\n", "\n", "sig_func", "=", "Sigmoid", "(", ")", "\n", "# test = sig_func(cluster_root_output)", "\n", "cluster_root_output", "=", "torch", ".", "diag", "(", "sig_func", "(", "cluster_root_output", ")", ")", "\n", "\n", "cluster_output", "=", "self", ".", "tail", "[", "i", "-", "1", "]", "(", "input_subset", ")", "\n", "\n", "# cluster_output = cluster_output * cluster_root_output", "\n", "cluster_output", "=", "torch", ".", "mm", "(", "cluster_root_output", ",", "sig_func", "(", "cluster_output", ")", ")", "# mohamm: second row of equation 2 in the paper", "\n", "\n", "# cluster_index = self.shortlist_size + i - 1", "\n", "\n", "temp_onehot", "=", "target", ".", "new_zeros", "(", "batch_size", ")", ".", "index_fill_", "(", "0", ",", "row_indices", ",", "1", ")", "\n", "cluster_onehot", "[", ":", ",", "i", "-", "1", "]", "=", "temp_onehot", "# mohamm: This is finally concateneted to head_onehot which are the nodes coressponding to the clusters in the head cluster (labels).", "\n", "\n", "# loss_fct = BCEWithLogitsLoss(reduction='none')", "\n", "# loss_fct = BCELoss(reduction='none')", "\n", "# loss = loss_fct(cluster_output.view(-1, num_idx), target_onehot.view(-1, num_idx).float())", "\n", "# loss = torch.sum(loss,dim=1)", "\n", "loss", "=", "AdaptiveBCEWithLogitsLoss", ".", "weighted_binary_cross_entropy", "(", "\n", "cluster_output", ".", "view", "(", "-", "1", ",", "num_idx", ")", ",", "target_onehot", ".", "view", "(", "-", "1", ",", "num_idx", ")", ".", "float", "(", ")", ",", "pos_weights", "=", "reweighting_factors", "[", "i", "]", ".", "to", "(", "'cuda'", ")", "if", "reweighting_factors", "[", "i", "]", "is", "not", "None", "else", "None", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "1", ")", "\n", "# total_cluster_loss = total_cluster_loss.scatter_add(0,row_indices,loss)", "\n", "temp_loss", "=", "input", ".", "new_zeros", "(", "batch_size", ")", "\n", "total_cluster_loss", "+=", "temp_loss", ".", "index_copy_", "(", "0", ",", "row_indices", ",", "loss", ")", "# mohamm: compute the loss in each cluster (for every sample) and add them together", "\n", "\n", "", "", "head_output", "=", "self", ".", "head", "(", "input", ")", "\n", "head_onehot", "=", "torch", ".", "cat", "(", "(", "head_onehot", ",", "cluster_onehot", ")", ",", "dim", "=", "1", ")", "\n", "loss_fct", "=", "BCEWithLogitsLoss", "(", "reduction", "=", "'none'", ",", "pos_weight", "=", "reweighting_factors", "[", "0", "]", ".", "to", "(", "'cuda'", ")", "if", "reweighting_factors", "[", "i", "]", "is", "not", "None", "else", "None", ")", "\n", "\n", "head_loss", "=", "loss_fct", "(", "head_output", ".", "view", "(", "-", "1", ",", "self", ".", "head_size", ")", ",", "head_onehot", ".", "view", "(", "-", "1", ",", "self", ".", "head_size", ")", ".", "float", "(", ")", ")", "\n", "\n", "cluster_root_loss", "=", "head_loss", "[", ":", ",", "self", ".", "shortlist_size", ":", "]", "\n", "# temp_mask = head_onehot[:,self.shortlist_size:]", "\n", "multiplier", "=", "(", "cluster_onehot", "==", "0", ")", ".", "long", "(", ")", "# mohamm: !!!!!!!!!!!!!???????????????????????? Does it mean that for a sample which also belongs to a tail cluster the loss for the tail node in the head cluster is not included in the total loss? why?!", "\n", "# multiplier += cluster_onehot * torch.tensor(self.cluster_size)", "\n", "cluster_root_loss", "=", "cluster_root_loss", "*", "multiplier", ".", "float", "(", ")", "\n", "\n", "head_loss", "[", ":", ",", "self", ".", "shortlist_size", ":", "]", "=", "cluster_root_loss", "\n", "head_loss", "=", "torch", ".", "sum", "(", "head_loss", ",", "dim", "=", "1", ")", "\n", "\n", "multiplier", "+=", "cluster_onehot", "*", "torch", ".", "tensor", "(", "self", ".", "cluster_size", ")", ".", "cuda", "(", ")", "# mohamm: !!!!!!!!!!!!??????????????????", "\n", "num_loss", "=", "torch", ".", "sum", "(", "multiplier", ",", "dim", "=", "1", ")", "+", "self", ".", "shortlist_size", "\n", "\n", "# loss = (head_loss + total_cluster_loss) / num_loss.float()", "\n", "loss", "=", "(", "(", "head_loss", "+", "total_cluster_loss", ")", "/", "num_loss", ".", "float", "(", ")", ")", ".", "mean", "(", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.predict": [[224, 246], ["Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.head", "torch.nn.Sigmoid", "torch.nn.Sigmoid.", "range", "torch.diag", "torch.mm", "torch.cat", "torch.nn.Sigmoid."], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "input", ")", ":", "\n", "        ", "r\"\"\"\n\n        Args:\n            input (Tensor): a minibatch of examples\n\n        \"\"\"", "\n", "head_output", "=", "self", ".", "head", "(", "input", ")", "\n", "sig_func", "=", "Sigmoid", "(", ")", "\n", "head_output", "=", "sig_func", "(", "head_output", ")", "\n", "output", "=", "head_output", "[", ":", ",", ":", "self", ".", "shortlist_size", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_clusters", ")", ":", "\n", "            ", "cluster_root_output", "=", "head_output", "[", ":", ",", "self", ".", "shortlist_size", "+", "i", "]", "\n", "cluster_root_output", "=", "torch", ".", "diag", "(", "cluster_root_output", ")", "\n", "\n", "cluster_output", "=", "self", ".", "tail", "[", "i", "]", "(", "input", ")", "\n", "cluster_output", "=", "torch", ".", "mm", "(", "cluster_root_output", ",", "sig_func", "(", "cluster_output", ")", ")", "\n", "\n", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "cluster_output", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.Adapative_label_clusters.AdaptiveBCEWithLogitsLoss.get_multi_hot_label": [[247, 264], ["target.index_select", "target_mask.index_select", "target.new_zeros().scatter", "target_mask.index_select.long", "torch.max", "target_prime.new_ones", "target_max.view", "target.new_zeros"], "methods", ["None"], ["", "def", "get_multi_hot_label", "(", "self", ",", "target", ",", "target_mask", ",", "row_indices", ",", "low_idx", ",", "num_idx", ")", ":", "\n", "\n", "        ", "target_subset", "=", "target", ".", "index_select", "(", "0", ",", "row_indices", ")", "\n", "\n", "target_mask_subset", "=", "target_mask", ".", "index_select", "(", "0", ",", "row_indices", ")", "\n", "\n", "target_prime", "=", "target_subset", "*", "(", "target_mask_subset", ".", "long", "(", ")", ")", "\n", "\n", "target_max", "=", "torch", ".", "max", "(", "target_prime", ",", "1", ")", "[", "0", "]", "\n", "target_pad", "=", "target_prime", ".", "new_ones", "(", "target_prime", ".", "shape", ")", "*", "target_max", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "target_pad", "=", "target_pad", "*", "(", "(", "~", "target_mask_subset", ")", ".", "long", "(", ")", ")", "\n", "\n", "relative_target", "=", "target_prime", "+", "target_pad", "-", "low_idx", "\n", "\n", "target_onehot", "=", "target", ".", "new_zeros", "(", "target_subset", ".", "shape", "[", "0", "]", ",", "num_idx", ")", ".", "scatter", "(", "1", ",", "relative_target", ",", "1", ")", "\n", "\n", "return", "target_onehot", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.InputFeatures.__init__": [[17, 21], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel.__init__": [[27, 31], ["predict_aplc.AplcXlnetModel.tokenizer_class.from_pretrained", "predict_aplc.AplcXlnetModel.model_class.from_pretrained().to", "predict_aplc.AplcXlnetModel.model_class.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.modeling_utils.PreTrainedModel.from_pretrained"], ["def", "__init__", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "self", ".", "tokenizer_class", ".", "from_pretrained", "(", "model_path", ")", "\n", "self", ".", "model", "=", "self", ".", "model_class", ".", "from_pretrained", "(", "model_path", ")", ".", "to", "(", "'cuda'", ")", "\n", "self", ".", "model", ".", "reweighting_factors", "=", "[", "None", "]", "*", "4", "\n", "# tgt_model.to('cuda')", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel.predict": [[33, 87], ["enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "predict_aplc.AplcXlnetModel._convert_feature_to_ids", "all_input_ids.append", "all_masks.append", "all_segs.append", "torch.no_grad", "predict_aplc.AplcXlnetModel.model.eval", "tqdm.tqdm.tqdm", "predict_aplc.AplcXlnetModel.model", "loss_all.append", "loss.item", "preds.append", "preds.append", "logits.cpu", "torch.topk", "logits.cpu"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel._convert_feature_to_ids"], ["", "def", "predict", "(", "self", ",", "list_seq", ":", "list", ",", "labels", ":", "list", ",", "max_length", ":", "int", ",", "return_logits", "=", "True", ",", "top", "=", "5", ",", "batch_size", "=", "12", ",", "ver", "=", "False", ")", ":", "\n", "\n", "        ", "all_input_ids", "=", "[", "]", "\n", "all_masks", "=", "[", "]", "\n", "all_segs", "=", "[", "]", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "list_seq", ")", ":", "\n", "            ", "feature_ids", "=", "self", ".", "_convert_feature_to_ids", "(", "seq", ",", "max_length", ",", "self", ".", "tokenizer", ",", "\n", "# xlnet has a cls token at the end", "\n", "cls_token_at_end", "=", "True", ",", "\n", "cls_token", "=", "self", ".", "tokenizer", ".", "cls_token", ",", "\n", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", ",", "\n", "cls_token_segment_id", "=", "2", ",", "\n", "# pad on the left for xlnet", "\n", "pad_on_left", "=", "True", ",", "\n", "pad_token_segment_id", "=", "4", ")", "\n", "\n", "all_input_ids", ".", "append", "(", "feature_ids", ".", "input_ids", ")", "\n", "all_masks", ".", "append", "(", "feature_ids", ".", "input_mask", ")", "\n", "all_segs", ".", "append", "(", "feature_ids", ".", "segment_ids", ")", "\n", "\n", "", "seqs", "=", "torch", ".", "tensor", "(", "all_input_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", "\n", "masks", "=", "torch", ".", "tensor", "(", "all_masks", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", "\n", "segs", "=", "torch", ".", "tensor", "(", "all_segs", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", "\n", "\n", "eval_data", "=", "TensorDataset", "(", "seqs", ",", "masks", ",", "segs", ",", "labels", ")", "\n", "# Run prediction for full data", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_data", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_data", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "loss_all", "=", "[", "]", "\n", "preds", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "ver", ":", "\n", "                ", "eval_dataloader", "=", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "'prediction'", ")", "\n", "", "for", "batch", "in", "eval_dataloader", ":", "\n", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "2", "]", ",", "\n", "'labels'", ":", "batch", "[", "3", "]", "\n", "}", "\n", "\n", "outputs", "=", "self", ".", "model", "(", "**", "inputs", ")", "\n", "loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "loss_all", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "if", "not", "return_logits", ":", "\n", "                    ", "preds", ".", "append", "(", "torch", ".", "topk", "(", "logits", ".", "cpu", "(", ")", ",", "top", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "preds", ".", "append", "(", "logits", ".", "cpu", "(", ")", ")", "\n", "", "", "", "return", "loss_all", ",", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.predict_aplc.AplcXlnetModel._convert_feature_to_ids": [[89, 147], ["tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "predict_aplc.InputFeatures", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "_convert_feature_to_ids", "(", "self", ",", "example", ",", "max_seq_length", ",", "\n", "tokenizer", ",", "cls_token_at_end", "=", "False", ",", "\n", "pad_on_left", "=", "False", ",", "cls_token", "=", "'[CLS]'", ",", "\n", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "        ", "\"\"\" Loads a data file into a list of `InputBatch`s\n            `cls_token_at_end` define the location of the CLS token:\n                - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n                - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n            `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n        \"\"\"", "\n", "\n", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ")", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "            ", "tokens_a", "=", "tokens_a", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "\n", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "feature_ids", "=", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ")", "\n", "\n", "return", "feature_ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputExample.__init__": [[45, 62], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ",", "target_label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "target_label", "=", "target_label", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.InputFeatures.__init__": [[67, 72], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_id", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.DataProcessor.get_train_examples": [[77, 80], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.DataProcessor.get_dev_examples": [[81, 84], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.DataProcessor.get_labels": [[85, 88], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.DataProcessor._read_tsv": [[89, 104], ["io.open", "csv.reader", "lines.append", "list", "unicode"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "\n", "                    ", "if", "sys", ".", "version_info", "[", "0", "]", ">=", "3", ":", "\n", "                        ", "unicode", "=", "str", "\n", "\n", "", "line", "=", "list", "(", "unicode", "(", "cell", ",", "'utf-8'", ")", "for", "cell", "in", "line", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor.get_train_examples": [[109, 123], ["logger.info", "pandas.read_csv", "utils_multi_label.MultiLabelTextProcessor._create_examples", "pandas.read_csv", "utils_multi_label.MultiLabelTextProcessor._create_examples", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv.sample"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor._create_examples", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor._create_examples"], ["    ", "def", "get_train_examples", "(", "self", ",", "data_dir", ",", "size", "=", "-", "1", ")", ":", "\n", "        ", "filename", "=", "'train.csv'", "\n", "logger", ".", "info", "(", "\"LOOKING AT {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "filename", ")", ")", ")", "\n", "if", "size", "==", "-", "1", ":", "\n", "# data_df = pd.read_csv(os.path.join(data_dir, filename))", "\n", "            ", "data_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "filename", ")", ",", "na_filter", "=", "False", ")", "\n", "\n", "return", "self", ".", "_create_examples", "(", "data_df", ",", "\"train\"", ")", "\n", "# return self._create_examples(reader, \"train\")", "\n", "\n", "", "else", ":", "\n", "            ", "data_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "filename", ")", ")", "\n", "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)", "\n", "return", "self", ".", "_create_examples", "(", "data_df", ".", "sample", "(", "size", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor.get_dev_examples": [[124, 137], ["pandas.read_csv", "utils_multi_label.MultiLabelTextProcessor._create_examples", "pandas.read_csv", "utils_multi_label.MultiLabelTextProcessor._create_examples", "os.path.join", "os.path.join", "pandas.read_csv.sample"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor._create_examples", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor._create_examples"], ["", "", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "dev_name", ",", "size", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "# filename = 'dev.csv'", "\n", "filename", "=", "dev_name", "\n", "if", "size", "==", "-", "1", ":", "\n", "# data_df = pd.read_csv(os.path.join(data_dir, filename))", "\n", "            ", "data_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "filename", ")", ",", "na_filter", "=", "False", ")", "\n", "\n", "return", "self", ".", "_create_examples", "(", "data_df", ",", "\"dev\"", ")", "\n", "", "else", ":", "\n", "            ", "data_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "filename", ")", ")", "\n", "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)", "\n", "return", "self", ".", "_create_examples", "(", "data_df", ".", "sample", "(", "size", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor.get_test_examples": [[138, 145], ["pandas.read_csv", "os.path.join", "utils_multi_label.MultiLabelTextProcessor._create_examples", "utils_multi_label.MultiLabelTextProcessor._create_examples", "pandas.read_csv.sample"], "methods", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor._create_examples", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor._create_examples"], ["", "", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "data_file_name", ",", "size", "=", "-", "1", ")", ":", "\n", "        ", "data_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "data_file_name", ")", ")", "\n", "#         data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)", "\n", "if", "size", "==", "-", "1", ":", "\n", "            ", "return", "self", ".", "_create_examples", "(", "data_df", ",", "\"test\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_create_examples", "(", "data_df", ".", "sample", "(", "size", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor.get_labels": [[146, 159], ["os.path.join", "io.open", "io.open.readlines", "io.open.close", "line.strip", "labels.append"], "methods", ["None"], ["", "", "def", "get_labels", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"labels.txt\"", ")", "\n", "labels", "=", "[", "]", "\n", "file", "=", "open", "(", "file_name", ",", "'r'", ")", "\n", "lines", "=", "file", ".", "readlines", "(", ")", "\n", "file", ".", "close", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "label", "=", "line", ".", "strip", "(", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.MultiLabelTextProcessor._create_examples": [[160, 184], ["enumerate", "examples.append", "utils_multi_label.InputExample", "row[].split"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "df", ",", "set_type", ",", "labels_available", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "row", ")", "in", "enumerate", "(", "df", ".", "values", ")", ":", "\n", "# for row in reader:", "\n", "            ", "top", ",", "freq", "=", "None", ",", "None", "\n", "guid", "=", "row", "[", "0", "]", "\n", "text_a", "=", "row", "[", "1", "]", "\n", "if", "labels_available", ":", "\n", "\n", "                ", "if", "row", "[", "2", "]", "==", "''", ":", "\n", "                    ", "labels", "=", "[", "]", "\n", "", "else", ":", "\n", "                    ", "labels", "=", "row", "[", "2", "]", ".", "split", "(", "','", ")", "\n", "\n", "", "target_label", "=", "[", "]", "\n", "if", "row", ".", "size", ">", "3", ":", "\n", "                    ", "if", "row", "[", "3", "]", "!=", "''", ":", "\n", "                        ", "target_label", "=", "row", "[", "3", "]", "\n", "", "", "", "else", ":", "\n", "                ", "labels", "=", "[", "]", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "label", "=", "labels", ",", "target_label", "=", "target_label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.convert_examples_to_features": [[186, 302], ["enumerate", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "logger.info", "tokenizer.tokenize", "utils_multi_label._truncate_seq_pair", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_multi_label.InputFeatures", "len", "float", "KeyError", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.models.tokenization_utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label._truncate_seq_pair"], ["", "", "def", "convert_examples_to_features", "(", "examples", ",", "label_list", ",", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ",", "\n", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "1000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "\n", "", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "", "tokens", "=", "tokens_a", "+", "[", "sep_token", "]", "\n", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "sep_token", "]", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "=", "tokens", "+", "[", "cls_token", "]", "\n", "segment_ids", "=", "segment_ids", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "=", "input_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "=", "segment_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "\n", "            ", "label_id", "=", "[", "label_map", "[", "item", "]", "for", "item", "in", "example", ".", "label", "]", "\n", "#label_id = label_map[example.label]", "\n", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "\n", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"label: %s (id = %s)\"", "%", "(", "','", ".", "join", "(", "example", ".", "label", ")", ",", "','", ".", "join", "(", "[", "str", "(", "item", ")", "for", "item", "in", "label_id", "]", ")", ")", ")", "\n", "# logger.info(\"label: %s (id = %d)\" % (example.label, label_id))", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_id", "=", "label_id", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label._truncate_seq_pair": [[304, 319], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "            ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "            ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.eval_precision": [[353, 359], ["numpy.sum", "numpy.arange"], "function", ["None"], ["def", "eval_precision", "(", "p_count", ",", "num_sample", ")", ":", "\n", "\n", "    ", "p_count", "=", "np", ".", "sum", "(", "p_count", ",", "axis", "=", "0", ")", "\n", "p_count", "=", "(", "p_count", "*", "100.0", ")", "/", "(", "num_sample", "*", "np", ".", "arange", "(", "1", ",", "p_count", ".", "size", "+", "1", ")", ")", "\n", "\n", "return", "p_count", "[", "0", "]", ",", "p_count", "[", "2", "]", ",", "p_count", "[", "4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.eval_ndcg": [[361, 367], ["numpy.sum"], "function", ["None"], ["", "def", "eval_ndcg", "(", "n_count", ",", "num_sample", ")", ":", "\n", "\n", "    ", "n_count", "=", "np", ".", "sum", "(", "n_count", ",", "axis", "=", "0", ")", "\n", "n_count", "=", "n_count", "*", "100.0", "/", "num_sample", "\n", "\n", "return", "n_count", "[", "0", "]", ",", "n_count", "[", "2", "]", ",", "n_count", "[", "4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.eval_ps": [[398, 404], ["numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "eval_ps", "(", "num", ",", "den", ")", ":", "# mohamm", "\n", "\n", "    ", "num", ",", "den", "=", "np", ".", "sum", "(", "num", ",", "axis", "=", "0", ")", ",", "np", ".", "sum", "(", "den", ",", "axis", "=", "0", ")", "\n", "ps", "=", "num", "*", "100.0", "/", "den", "\n", "\n", "return", "ps", "[", "0", "]", ",", "ps", "[", "2", "]", ",", "ps", "[", "4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.count_parameters": [[406, 408], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.get_one_hot": [[410, 420], ["label_id.tolist", "len", "numpy.zeros", "range", "torch.tensor"], "function", ["None"], ["", "def", "get_one_hot", "(", "label_id", ",", "num_label", ")", ":", "\n", "\n", "    ", "label_index", "=", "label_id", ".", "tolist", "(", ")", "\n", "batch_size", "=", "len", "(", "label_index", ")", "\n", "one_hot_label", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "num_label", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "index", "=", "label_index", "[", "i", "]", "\n", "one_hot_label", "[", "i", ",", "index", "]", "=", "1", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "one_hot_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.eval_batch": [[422, 465], ["torch.sigmoid", "pre_ind.detach().cpu().numpy.detach().cpu().numpy", "truth.detach().cpu().numpy.detach().cpu().numpy", "range", "torch.topk", "range", "hit_list.append", "hit_list_psp_num.append", "hit_list_psp_den.append", "pre_ind.detach().cpu().numpy.detach().cpu", "truth.detach().cpu().numpy.detach().cpu", "numpy.intersect1d", "len", "numpy.sum", "numpy.sum", "pre_ind.detach().cpu().numpy.detach", "truth.detach().cpu().numpy.detach", "numpy.unique", "numpy.array", "numpy.sort"], "function", ["None"], ["", "def", "eval_batch", "(", "logits", ",", "truth", ",", "inv_prop", ")", ":", "\n", "# row, col = predict.shape", "\n", "    ", "k", "=", "10", "\n", "result", "=", "torch", ".", "sigmoid", "(", "logits", ")", "\n", "pre_ind", "=", "torch", ".", "topk", "(", "result", ",", "k", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "\n", "pre_ind", "=", "pre_ind", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "truth", "=", "truth", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "row", ",", "col", "=", "truth", ".", "shape", "\n", "\n", "hit_list", "=", "[", "]", "\n", "hit_list_psp_num", "=", "[", "]", "\n", "hit_list_psp_den", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "1", ",", "6", ",", "2", ")", ":", "# k = 1, 3, 5", "\n", "        ", "pre_k", "=", "pre_ind", "[", ":", ",", ":", "k", "]", "\n", "hit_sum", "=", "0", "\n", "hit_sum_psp_num", "=", "0", "\n", "hit_sum_psp_den", "=", "0", "\n", "for", "i", "in", "range", "(", "row", ")", ":", "\n", "\n", "            ", "intersection", "=", "np", ".", "intersect1d", "(", "pre_k", "[", "i", ",", ":", "]", ",", "truth", "[", "i", ",", ":", "]", ")", "\n", "hit_sum", "+=", "len", "(", "intersection", ")", "\n", "\n", "# mohamm (check if labels start from zero !!!!!!!!!!!)", "\n", "hit_sum_psp_num", "+=", "np", ".", "sum", "(", "inv_prop", "[", "intersection", "]", ")", "\n", "psp_total", "=", "inv_prop", "[", "np", ".", "unique", "(", "np", ".", "array", "(", "truth", "[", "i", ",", ":", "]", ")", ")", "]", "\n", "# try:", "\n", "#     psp_total = inv_prop[np.unique(np.array(truth[i,:]))]", "\n", "# except IndexError:", "\n", "#     labels = np.unique(np.array(truth[i,:]))", "\n", "#     for label in labels:", "\n", "#         if label >= len(inv_prop):", "\n", "#             labels = np.delete(labels, np.where(labels==label))", "\n", "#     psp_total = inv_prop[labels]", "\n", "hit_sum_psp_den", "+=", "np", ".", "sum", "(", "np", ".", "sort", "(", "psp_total", ")", "[", ":", ":", "-", "1", "]", "[", ":", "k", "]", ")", "\n", "\n", "", "hit_list", ".", "append", "(", "hit_sum", ")", "\n", "\n", "hit_list_psp_num", ".", "append", "(", "hit_sum_psp_num", ")", "\n", "hit_list_psp_den", ".", "append", "(", "hit_sum_psp_den", ")", "\n", "\n", "", "return", "hit_list", ",", "hit_list_psp_num", ",", "hit_list_psp_den", ",", "row", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.precision": [[467, 476], ["numpy.zeros", "zip", "len", "len", "numpy.in1d", "numpy.cumsum"], "function", ["None"], ["", "def", "precision", "(", "pred_mat", ",", "true_mat", ",", "k", ")", ":", "\n", "\n", "    ", "assert", "len", "(", "pred_mat", ")", "==", "len", "(", "true_mat", ")", "\n", "correct_count", "=", "np", ".", "zeros", "(", "k", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "pred", ",", "tr", "in", "zip", "(", "pred_mat", ",", "true_mat", ")", ":", "\n", "        ", "match", "=", "np", ".", "in1d", "(", "pred", ",", "tr", ",", "assume_unique", "=", "True", ")", "\n", "correct_count", "+=", "np", ".", "cumsum", "(", "match", ")", "\n", "\n", "", "return", "correct_count", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.psp": [[478, 500], ["numpy.zeros", "numpy.zeros", "zip", "len", "len", "numpy.unique", "numpy.in1d().astype", "numpy.cumsum", "numpy.zeros", "numpy.min", "numpy.cumsum", "numpy.sort", "numpy.in1d"], "function", ["None"], ["", "def", "psp", "(", "pred_mat", ",", "true_mat", ",", "inv_prop", ",", "k", ")", ":", "\n", "\n", "    ", "assert", "len", "(", "pred_mat", ")", "==", "len", "(", "true_mat", ")", "\n", "num", "=", "np", ".", "zeros", "(", "k", ")", "\n", "den", "=", "np", ".", "zeros", "(", "k", ")", "\n", "for", "pred", ",", "tr", "in", "zip", "(", "pred_mat", ",", "true_mat", ")", ":", "\n", "\n", "        ", "tr", "=", "np", ".", "unique", "(", "tr", ")", "#!", "\n", "\n", "match", "=", "np", ".", "in1d", "(", "pred", ",", "tr", ",", "assume_unique", "=", "True", ")", ".", "astype", "(", "float", ")", "\n", "match", "[", "match", ">", "0", "]", "=", "inv_prop", "[", "pred", "[", "match", ">", "0", "]", "]", "\n", "num", "+=", "np", ".", "cumsum", "(", "match", ")", "\n", "\n", "inv_prop_sample", "=", "inv_prop", "[", "tr", "]", "\n", "inv_prop_sample", "=", "np", ".", "sort", "(", "inv_prop_sample", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "match", "=", "np", ".", "zeros", "(", "k", ")", "\n", "match_size", "=", "np", ".", "min", "(", "(", "inv_prop_sample", ".", "size", ",", "k", ")", ")", "\n", "match", "[", ":", "match_size", "]", "=", "inv_prop_sample", "[", ":", "match_size", "]", "\n", "den", "+=", "np", ".", "cumsum", "(", "match", ")", "\n", "\n", "", "return", "num", ",", "den", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.ndcg": [[501, 520], ["numpy.zeros", "zip", "len", "len", "numpy.array", "numpy.array", "numpy.in1d().astype", "numpy.zeros", "min", "numpy.log", "numpy.log", "numpy.cumsum", "numpy.cumsum", "numpy.in1d", "numpy.arange"], "function", ["None"], ["", "def", "ndcg", "(", "pred_mat", ",", "true_mat", ",", "k", ")", ":", "\n", "\n", "    ", "assert", "len", "(", "pred_mat", ")", "==", "len", "(", "true_mat", ")", "\n", "correct_count", "=", "np", ".", "zeros", "(", "k", ")", "\n", "for", "pred", ",", "tr", "in", "zip", "(", "pred_mat", ",", "true_mat", ")", ":", "\n", "        ", "pred", "=", "np", ".", "array", "(", "pred", ")", "\n", "tr", "=", "np", ".", "array", "(", "tr", ")", "\n", "num", "=", "np", ".", "in1d", "(", "pred", ",", "tr", ",", "assume_unique", "=", "True", ")", ".", "astype", "(", "float", ")", "\n", "\n", "num", "[", "num", ">", "0", "]", "=", "1.0", "/", "np", ".", "log", "(", "(", "num", ">", "0", ")", ".", "nonzero", "(", ")", "[", "0", "]", "+", "2", ")", "\n", "\n", "den", "=", "np", ".", "zeros", "(", "k", ")", "\n", "den_size", "=", "min", "(", "tr", ".", "size", ",", "k", ")", "\n", "den", "[", ":", "den_size", "]", "=", "1.0", "/", "np", ".", "log", "(", "np", ".", "arange", "(", "1", ",", "den_size", "+", "1", ")", "+", "1", ")", "\n", "\n", "correct_count", "+=", "np", ".", "cumsum", "(", "num", ")", "/", "np", ".", "cumsum", "(", "den", ")", "\n", "\n", "# ndcg = correct_count * 100.0 / len(pred_mat)", "\n", "", "return", "correct_count", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.psndcg": [[522, 542], ["numpy.zeros", "numpy.zeros", "zip", "numpy.unique", "numpy.in1d().astype", "numpy.cumsum", "numpy.zeros", "min", "numpy.cumsum", "numpy.log2", "numpy.argsort", "numpy.log2", "numpy.in1d", "numpy.arange"], "function", ["None"], ["", "def", "psndcg", "(", "pred_mat", ",", "true_mat", ",", "inv_prop", ",", "k", ")", ":", "\n", "\n", "    ", "den", "=", "np", ".", "zeros", "(", "k", ")", "\n", "num", "=", "np", ".", "zeros", "(", "k", ")", "\n", "for", "pred", ",", "tr", "in", "zip", "(", "pred_mat", ",", "true_mat", ")", ":", "\n", "\n", "        ", "tr", "=", "np", ".", "unique", "(", "tr", ")", "#!", "\n", "\n", "match", "=", "np", ".", "in1d", "(", "pred", ",", "tr", ",", "assume_unique", "=", "True", ")", ".", "astype", "(", "float", ")", "\n", "match", "[", "match", ">", "0", "]", "=", "inv_prop", "[", "pred", "[", "match", ">", "0", "]", "]", "/", "np", ".", "log2", "(", "(", "match", ">", "0", ")", ".", "nonzero", "(", ")", "[", "0", "]", "+", "2", ")", "\n", "num", "+=", "np", ".", "cumsum", "(", "match", ")", "\n", "\n", "match", "=", "np", ".", "zeros", "(", "k", ")", "\n", "match_size", "=", "min", "(", "tr", ".", "size", ",", "k", ")", "\n", "ind_large", "=", "np", ".", "argsort", "(", "inv_prop", "[", "tr", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "temp_match", "=", "inv_prop", "[", "tr", "[", "ind_large", "]", "]", "/", "np", ".", "log2", "(", "np", ".", "arange", "(", "ind_large", ".", "size", ")", "+", "2", ")", "\n", "match", "[", ":", "match_size", "]", "=", "temp_match", "[", ":", "match_size", "]", "\n", "den", "+=", "np", ".", "cumsum", "(", "match", ")", "\n", "\n", "", "return", "num", ",", "den", "\n", "\n"]], "home.repos.pwc.inspect_result.xmc-aalto_adv-xmtc.aplc_scripts.utils_multi_label.metric_pk": [[544, 563], ["pre_ind.detach().cpu().numpy.detach().cpu().numpy", "truth.detach().cpu().numpy.detach().cpu().numpy", "range", "torch.topk", "numpy.intersect1d", "len", "pre_ind.detach().cpu().numpy.detach().cpu", "truth.detach().cpu().numpy.detach().cpu", "pre_ind.detach().cpu().numpy.detach", "truth.detach().cpu().numpy.detach"], "function", ["None"], ["", "def", "metric_pk", "(", "logits", ",", "truth", ",", "k", "=", "1", ")", ":", "\n", "\n", "    ", "pre_ind", "=", "torch", ".", "topk", "(", "logits", ",", "k", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "\n", "pre_ind", "=", "pre_ind", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "truth", "=", "truth", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "row", ",", "col", "=", "truth", ".", "shape", "\n", "\n", "hit_sum", "=", "0", "\n", "for", "i", "in", "range", "(", "row", ")", ":", "\n", "\n", "        ", "intersection", "=", "np", ".", "intersect1d", "(", "pre_ind", "[", "i", ",", ":", "]", ",", "truth", "[", "i", ",", ":", "]", ")", "\n", "hit_sum", "+=", "len", "(", "intersection", ")", "\n", "\n", "", "p_k", "=", "hit_sum", "/", "row", "\n", "\n", "\n", "return", "p_k", "\n", "", ""]]}