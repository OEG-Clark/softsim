{"home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.parse_args": [[22, 45], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Translate using existing NMT models\"", ",", "\n", "usage", "=", "\"translator.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of input file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of output file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoints\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of trained models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--models\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.default_parameters": [[47, 73], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["", "def", "default_parameters", "(", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "None", ",", "\n", "output", "=", "None", ",", "\n", "vocabulary", "=", "None", ",", "\n", "model", "=", "None", ",", "\n", "# vocabulary specific", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<bos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "mapping", "=", "None", ",", "\n", "append_eos", "=", "False", ",", "\n", "# decoding", "\n", "top_beams", "=", "1", ",", "\n", "beam_size", "=", "4", ",", "\n", "decode_alpha", "=", "0.6", ",", "\n", "decode_length", "=", "50", ",", "\n", "decode_batch_size", "=", "32", ",", "\n", "decode_constant", "=", "5.0", ",", "\n", "decode_normalize", "=", "False", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "num_threads", "=", "6", "\n", ")", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.merge_parameters": [[75, 91], ["tensorflow.contrib.training.HParams", "params1.values().iteritems", "tf.contrib.training.HParams.values", "params2.values().iteritems", "tf.contrib.training.HParams.add_hparam", "params1.values", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["", "def", "merge_parameters", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "params1", ".", "values", "(", ")", ".", "iteritems", "(", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "params2", ".", "values", "(", ")", ".", "iteritems", "(", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.import_params": [[93, 106], ["os.path.abspath", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json"], "function", ["None"], ["", "def", "import_params", "(", "model_dir", ",", "model_name", ",", "params", ")", ":", "\n", "    ", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n", "        ", "return", "params", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.override_parameters": [[108, 137], ["thumt.process_vocabulary", "thumt.process_vocabulary", "params.parse", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.get_control_mapping"], ["", "def", "override_parameters", "(", "params", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "parameters", ":", "\n", "        ", "params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "", "params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "args", ".", "vocabulary", "[", "1", "]", ")", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "\n", "control_symbols", "=", "[", "params", ".", "pad", ",", "params", ".", "bos", ",", "params", ".", "eos", ",", "params", ".", "unk", "]", "\n", "\n", "params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.session_config": [[139, 150], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "str"], "function", ["None"], ["", "def", "session_config", "(", "params", ")", ":", "\n", "    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "False", ")", "\n", "graph_options", "=", "tf", ".", "GraphOptions", "(", "optimizer_options", "=", "optimizer_options", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ")", "\n", "if", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.set_variables": [[152, 166], ["tensorflow.logging.info", "list", "tensorflow.device", "tensorflow.assign", "ops.append", "name.split"], "function", ["None"], ["", "def", "set_variables", "(", "var_list", ",", "value_dict", ",", "prefix", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "for", "name", "in", "value_dict", ":", "\n", "            ", "var_name", "=", "\"/\"", ".", "join", "(", "[", "prefix", "]", "+", "list", "(", "name", ".", "split", "(", "\"/\"", ")", "[", "1", ":", "]", ")", ")", "\n", "\n", "if", "var", ".", "name", "[", ":", "-", "2", "]", "==", "var_name", ":", "\n", "                ", "tf", ".", "logging", ".", "info", "(", "\"restoring %s -> %s\"", "%", "(", "name", ",", "var", ".", "name", ")", ")", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "                    ", "op", "=", "tf", ".", "assign", "(", "var", ",", "value_dict", "[", "name", "]", ")", "\n", "ops", ".", "append", "(", "op", ")", "\n", "", "break", "\n", "\n", "", "", "", "return", "ops", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.main": [[168, 290], ["tensorflow.logging.set_verbosity", "thumt.get_model", "translator.default_parameters", "translator.merge_parameters", "translator.import_params", "translator.override_parameters", "tensorflow.Graph().as_default", "enumerate", "range", "thumt.sort_input_file", "thumt.get_inference_input", "thumt.create_inference_graph", "tensorflow.trainable_variables", "range", "tensorflow.group", "tensorflow.train.ChiefSessionCreator", "time.time", "time.time", "tensorflow.logging.log", "list", "range", "range", "model_cls.get_parameters", "zip", "range", "range", "print", "tensorflow.train.list_variables", "tensorflow.train.load_checkpoint", "model_var_lists.append", "len", "model_cls_list[].get_name", "model.get_inference_func", "model_fns.append", "len", "model_cls_list[].get_name", "translator.set_variables", "assign_ops.extend", "tensorflow.train.MonitoredSession", "sess.run", "list.append", "itertools.chain", "len", "restored_outputs.append", "open", "len", "len", "len", "tensorflow.Graph", "tf.train.load_checkpoint.get_tensor", "v.name.startswith", "translator.session_config", "sess.should_stop", "time.time", "results.append", "time.time", "tensorflow.logging.log", "result.tolist", "outfile.write", "model_cls_list[].get_name.startswith", "model_cls_list[].get_name.find", "un_init_var_list.append", "sess.run", "decoded.append", "model_cls_list[].get_name", "len"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.__init__.get_model", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.default_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.merge_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.import_params", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.override_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.sort_input_file", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.get_inference_input", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.create_inference_graph", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_name", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_inference_func", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_name", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.translator.set_variables", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.session_config", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_name"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "# Load configs", "\n", "model_cls_list", "=", "[", "models", ".", "get_model", "(", "model", ")", "for", "model", "in", "args", ".", "models", "]", "\n", "params_list", "=", "[", "default_parameters", "(", ")", "for", "_", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "]", "\n", "params_list", "=", "[", "\n", "merge_parameters", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", "for", "params", ",", "model_cls", "in", "zip", "(", "params_list", ",", "model_cls_list", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "import_params", "(", "args", ".", "checkpoints", "[", "i", "]", ",", "args", ".", "models", "[", "i", "]", ",", "params_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", "\n", "]", "\n", "params_list", "=", "[", "\n", "override_parameters", "(", "params_list", "[", "i", "]", ",", "args", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "model_cls_list", ")", ")", "\n", "]", "\n", "\n", "# Build Graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model_var_lists", "=", "[", "]", "\n", "\n", "# Load checkpoints", "\n", "for", "i", ",", "checkpoint", "in", "enumerate", "(", "args", ".", "checkpoints", ")", ":", "\n", "            ", "print", "(", "\"Loading %s\"", "%", "checkpoint", ")", "\n", "var_list", "=", "tf", ".", "train", ".", "list_variables", "(", "checkpoint", ")", "\n", "values", "=", "{", "}", "\n", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "                ", "if", "not", "name", ".", "startswith", "(", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "name", ".", "find", "(", "\"losses_avg\"", ")", ">=", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "values", "[", "name", "]", "=", "tensor", "\n", "\n", "", "model_var_lists", ".", "append", "(", "values", ")", "\n", "\n", "# Build models", "\n", "", "model_fns", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "model", "=", "model_cls_list", "[", "i", "]", "(", "params_list", "[", "i", "]", ",", "name", "+", "\"_%d\"", "%", "i", ")", "\n", "model_fn", "=", "model", ".", "get_inference_func", "(", ")", "\n", "model_fns", ".", "append", "(", "model_fn", ")", "\n", "\n", "", "params", "=", "params_list", "[", "0", "]", "\n", "# Read input file", "\n", "sorted_keys", ",", "sorted_inputs", "=", "dataset", ".", "sort_input_file", "(", "args", ".", "input", ")", "\n", "# Build input queue", "\n", "features", "=", "dataset", ".", "get_inference_input", "(", "sorted_inputs", ",", "params", ")", "\n", "predictions", "=", "search", ".", "create_inference_graph", "(", "model_fns", ",", "features", ",", "\n", "params", ")", "\n", "\n", "assign_ops", "=", "[", "]", "\n", "\n", "all_var_list", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "args", ".", "checkpoints", ")", ")", ":", "\n", "            ", "un_init_var_list", "=", "[", "]", "\n", "name", "=", "model_cls_list", "[", "i", "]", ".", "get_name", "(", ")", "\n", "\n", "for", "v", "in", "all_var_list", ":", "\n", "                ", "if", "v", ".", "name", ".", "startswith", "(", "name", "+", "\"_%d\"", "%", "i", ")", ":", "\n", "                    ", "un_init_var_list", ".", "append", "(", "v", ")", "\n", "\n", "", "", "ops", "=", "set_variables", "(", "un_init_var_list", ",", "model_var_lists", "[", "i", "]", ",", "\n", "name", "+", "\"_%d\"", "%", "i", ")", "\n", "assign_ops", ".", "extend", "(", "ops", ")", "\n", "\n", "", "assign_op", "=", "tf", ".", "group", "(", "*", "assign_ops", ")", "\n", "\n", "sess_creator", "=", "tf", ".", "train", ".", "ChiefSessionCreator", "(", "\n", "config", "=", "session_config", "(", "params", ")", "\n", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "# Create session", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "with", "tf", ".", "train", ".", "MonitoredSession", "(", "session_creator", "=", "sess_creator", ")", "as", "sess", ":", "\n", "# Restore variables", "\n", "            ", "sess", ".", "run", "(", "assign_op", ")", "\n", "\n", "while", "not", "sess", ".", "should_stop", "(", ")", ":", "\n", "                ", "batch_start", "=", "time", ".", "time", "(", ")", "\n", "results", ".", "append", "(", "sess", ".", "run", "(", "predictions", ")", ")", "\n", "batch_end", "=", "time", ".", "time", "(", ")", "\n", "message", "=", "\"Finished batch %s within %s seconds\"", "%", "(", "len", "(", "results", ")", ",", "batch_end", "-", "batch_start", ")", "\n", "tf", ".", "logging", ".", "log", "(", "tf", ".", "logging", ".", "INFO", ",", "message", ")", "\n", "", "", "end", "=", "time", ".", "time", "(", ")", "\n", "tf", ".", "logging", ".", "log", "(", "tf", ".", "logging", ".", "INFO", ",", "\"Decoding in %s seconds\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n", "# Convert to plain text", "\n", "vocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "outputs", "=", "[", "]", "\n", "\n", "for", "result", "in", "results", ":", "\n", "            ", "outputs", ".", "append", "(", "result", ".", "tolist", "(", ")", ")", "\n", "\n", "", "outputs", "=", "list", "(", "itertools", ".", "chain", "(", "*", "outputs", ")", ")", "\n", "\n", "restored_outputs", "=", "[", "]", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "sorted_inputs", ")", ")", ":", "\n", "            ", "restored_outputs", ".", "append", "(", "outputs", "[", "sorted_keys", "[", "index", "]", "]", ")", "\n", "\n", "# Write to file", "\n", "", "with", "open", "(", "args", ".", "output", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "for", "output", "in", "restored_outputs", ":", "\n", "                ", "decoded", "=", "[", "]", "\n", "for", "idx", "in", "output", ":", "\n", "                    ", "if", "idx", "==", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", ":", "\n", "                        ", "break", "\n", "", "decoded", ".", "append", "(", "vocab", "[", "idx", "]", ")", "\n", "\n", "", "decoded", "=", "\" \"", ".", "join", "(", "decoded", ")", "\n", "outfile", ".", "write", "(", "\"%s\\n\"", "%", "decoded", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.parse_args": [[24, 51], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.parse_args"], ["def", "parse_args", "(", "args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Training neural machine translation models\"", ",", "\n", "usage", "=", "\"trainer.py [<args>] [-h | --help]\"", "\n", ")", "\n", "\n", "# input files", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "\n", "help", "=", "\"Path of source and target corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--record\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to tf.Record data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ",", "\n", "help", "=", "\"Path to saved models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocabulary\"", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "\n", "help", "=", "\"Path of source and target vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of validation file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--references\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"Path of reference files\"", ")", "\n", "\n", "# model and configuration", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Name of the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parameters\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Additional hyper parameters\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.default_parameters": [[53, 101], ["tensorflow.contrib.training.HParams"], "function", ["None"], ["", "def", "default_parameters", "(", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "input", "=", "[", "\"\"", ",", "\"\"", "]", ",", "\n", "output", "=", "\"\"", ",", "\n", "record", "=", "\"\"", ",", "\n", "model", "=", "\"transformer\"", ",", "\n", "vocab", "=", "[", "\"\"", ",", "\"\"", "]", ",", "\n", "# Default training hyper parameters", "\n", "num_threads", "=", "6", ",", "\n", "batch_size", "=", "128", ",", "\n", "max_length", "=", "256", ",", "\n", "length_multiplier", "=", "1", ",", "\n", "mantissa_bits", "=", "2", ",", "\n", "warmup_steps", "=", "4000", ",", "\n", "train_steps", "=", "100000", ",", "\n", "buffer_size", "=", "10000", ",", "\n", "constant_batch_size", "=", "True", ",", "\n", "device_list", "=", "[", "0", "]", ",", "\n", "update_cycle", "=", "1", ",", "\n", "initializer", "=", "\"uniform\"", ",", "\n", "initializer_gain", "=", "0.08", ",", "\n", "adam_beta1", "=", "0.9", ",", "\n", "adam_beta2", "=", "0.999", ",", "\n", "adam_epsilon", "=", "1e-8", ",", "\n", "clip_grad_norm", "=", "5.0", ",", "\n", "learning_rate", "=", "1.0", ",", "\n", "learning_rate_decay", "=", "\"noam\"", ",", "\n", "learning_rate_boundaries", "=", "[", "0", "]", ",", "\n", "learning_rate_values", "=", "[", "0.0", "]", ",", "\n", "keep_checkpoint_max", "=", "5", ",", "\n", "keep_top_checkpoint_max", "=", "1", ",", "\n", "# Validation", "\n", "eval_steps", "=", "2000", ",", "\n", "eval_secs", "=", "0", ",", "\n", "eval_batch_size", "=", "32", ",", "\n", "top_beams", "=", "1", ",", "\n", "beam_size", "=", "4", ",", "\n", "decode_alpha", "=", "0.6", ",", "\n", "decode_length", "=", "50", ",", "\n", "decode_constant", "=", "5.0", ",", "\n", "decode_normalize", "=", "False", ",", "\n", "validation", "=", "\"\"", ",", "\n", "references", "=", "[", "\"\"", "]", ",", "\n", "save_checkpoint_secs", "=", "0", ",", "\n", "save_checkpoint_steps", "=", "1000", ",", "\n", ")", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.import_params": [[103, 122], ["os.path.abspath", "os.path.join", "os.path.join", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json", "tensorflow.gfile.Open", "tensorflow.logging.info", "fd.readline", "params.parse_json", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists"], "function", ["None"], ["", "def", "import_params", "(", "model_dir", ",", "model_name", ",", "params", ")", ":", "\n", "    ", "model_dir", "=", "os", ".", "path", ".", "abspath", "(", "model_dir", ")", "\n", "p_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "\"params.json\"", ")", "\n", "m_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "model_name", "+", "\".json\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "p_name", ")", "or", "not", "tf", ".", "gfile", ".", "Exists", "(", "m_name", ")", ":", "\n", "        ", "return", "params", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "p_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring hyper parameters from %s\"", "%", "p_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "Open", "(", "m_name", ")", "as", "fd", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring model parameters from %s\"", "%", "m_name", ")", "\n", "json_str", "=", "fd", ".", "readline", "(", ")", "\n", "params", ".", "parse_json", "(", "json_str", ")", "\n", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.export_params": [[124, 132], ["os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.MkDir", "tensorflow.gfile.Open", "fd.write", "params.to_json"], "function", ["None"], ["", "def", "export_params", "(", "output_dir", ",", "name", ",", "params", ")", ":", "\n", "    ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "output_dir", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MkDir", "(", "output_dir", ")", "\n", "\n", "# Save params as params.json", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "name", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "filename", ",", "\"w\"", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "params", ".", "to_json", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.collect_params": [[134, 141], ["tensorflow.contrib.training.HParams", "params.values().iterkeys", "tf.contrib.training.HParams.add_hparam", "params.values", "getattr"], "function", ["None"], ["", "", "def", "collect_params", "(", "all_params", ",", "params", ")", ":", "\n", "    ", "collected", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "k", "in", "params", ".", "values", "(", ")", ".", "iterkeys", "(", ")", ":", "\n", "        ", "collected", ".", "add_hparam", "(", "k", ",", "getattr", "(", "all_params", ",", "k", ")", ")", "\n", "\n", "", "return", "collected", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.merge_parameters": [[143, 159], ["tensorflow.contrib.training.HParams", "params1.values().iteritems", "tf.contrib.training.HParams.values", "params2.values().iteritems", "tf.contrib.training.HParams.add_hparam", "params1.values", "params2.values", "setattr", "tf.contrib.training.HParams.add_hparam"], "function", ["None"], ["", "def", "merge_parameters", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "params1", ".", "values", "(", ")", ".", "iteritems", "(", ")", ":", "\n", "        ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "params_dict", "=", "params", ".", "values", "(", ")", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "params2", ".", "values", "(", ")", ".", "iteritems", "(", ")", ":", "\n", "        ", "if", "k", "in", "params_dict", ":", "\n", "# Override", "\n", "            ", "setattr", "(", "params", ",", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "params", ".", "add_hparam", "(", "k", ",", "v", ")", "\n", "\n", "", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.override_parameters": [[161, 196], ["params.parse", "thumt.process_vocabulary", "thumt.process_vocabulary", "thumt.load_vocabulary", "thumt.load_vocabulary", "thumt.get_control_mapping", "thumt.get_control_mapping"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.process_vocabulary", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.load_vocabulary", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.get_control_mapping", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.get_control_mapping"], ["", "def", "override_parameters", "(", "params", ",", "args", ")", ":", "\n", "    ", "params", ".", "model", "=", "args", ".", "model", "\n", "params", ".", "input", "=", "args", ".", "input", "or", "params", ".", "input", "\n", "params", ".", "output", "=", "args", ".", "output", "or", "params", ".", "output", "\n", "params", ".", "record", "=", "args", ".", "record", "or", "params", ".", "record", "\n", "params", ".", "vocab", "=", "args", ".", "vocabulary", "or", "params", ".", "vocab", "\n", "params", ".", "validation", "=", "args", ".", "validation", "or", "params", ".", "validation", "\n", "params", ".", "references", "=", "args", ".", "references", "or", "params", ".", "references", "\n", "params", ".", "parse", "(", "args", ".", "parameters", ")", "\n", "\n", "params", ".", "vocabulary", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "load_vocabulary", "(", "params", ".", "vocab", "[", "0", "]", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "load_vocabulary", "(", "params", ".", "vocab", "[", "1", "]", ")", "\n", "}", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "params", "\n", ")", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", "=", "vocabulary", ".", "process_vocabulary", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "params", "\n", ")", "\n", "\n", "control_symbols", "=", "[", "params", ".", "pad", ",", "params", ".", "bos", ",", "params", ".", "eos", ",", "params", ".", "unk", "]", "\n", "\n", "params", ".", "mapping", "=", "{", "\n", "\"source\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"source\"", "]", ",", "\n", "control_symbols", "\n", ")", ",", "\n", "\"target\"", ":", "vocabulary", ".", "get_control_mapping", "(", "\n", "params", ".", "vocabulary", "[", "\"target\"", "]", ",", "\n", "control_symbols", "\n", ")", "\n", "}", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.get_initializer": [[198, 214], ["tensorflow.random_uniform_initializer", "tensorflow.random_normal_initializer", "tensorflow.variance_scaling_initializer", "tensorflow.variance_scaling_initializer", "ValueError"], "function", ["None"], ["", "def", "get_initializer", "(", "params", ")", ":", "\n", "    ", "if", "params", ".", "initializer", "==", "\"uniform\"", ":", "\n", "        ", "max_val", "=", "params", ".", "initializer_gain", "\n", "return", "tf", ".", "random_uniform_initializer", "(", "-", "max_val", ",", "max_val", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"normal\"", ":", "\n", "        ", "return", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "initializer_gain", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"normal_unit_scaling\"", ":", "\n", "        ", "return", "tf", ".", "variance_scaling_initializer", "(", "params", ".", "initializer_gain", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"normal\"", ")", "\n", "", "elif", "params", ".", "initializer", "==", "\"uniform_unit_scaling\"", ":", "\n", "        ", "return", "tf", ".", "variance_scaling_initializer", "(", "params", ".", "initializer_gain", ",", "\n", "mode", "=", "\"fan_avg\"", ",", "\n", "distribution", "=", "\"uniform\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unrecognized initializer: %s\"", "%", "params", ".", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.get_learning_rate_decay": [[216, 233], ["tensorflow.to_float", "tensorflow.to_float", "tensorflow.minimum", "tensorflow.train.piecewise_constant", "tensorflow.to_int32", "ValueError"], "function", ["None"], ["", "", "def", "get_learning_rate_decay", "(", "learning_rate", ",", "global_step", ",", "params", ")", ":", "\n", "    ", "if", "params", ".", "learning_rate_decay", "==", "\"noam\"", ":", "\n", "        ", "step", "=", "tf", ".", "to_float", "(", "global_step", ")", "\n", "warmup_steps", "=", "tf", ".", "to_float", "(", "params", ".", "warmup_steps", ")", "\n", "multiplier", "=", "params", ".", "hidden_size", "**", "-", "0.5", "\n", "decay", "=", "multiplier", "*", "tf", ".", "minimum", "(", "(", "step", "+", "1", ")", "*", "(", "warmup_steps", "**", "-", "1.5", ")", ",", "\n", "(", "step", "+", "1", ")", "**", "-", "0.5", ")", "\n", "\n", "return", "learning_rate", "*", "decay", "\n", "", "elif", "params", ".", "learning_rate_decay", "==", "\"piecewise_constant\"", ":", "\n", "        ", "return", "tf", ".", "train", ".", "piecewise_constant", "(", "tf", ".", "to_int32", "(", "global_step", ")", ",", "\n", "params", ".", "learning_rate_boundaries", ",", "\n", "params", ".", "learning_rate_values", ")", "\n", "", "elif", "params", ".", "learning_rate_decay", "==", "\"none\"", ":", "\n", "        ", "return", "learning_rate", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown learning_rate_decay\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.session_config": [[235, 246], ["tensorflow.OptimizerOptions", "tensorflow.GraphOptions", "tensorflow.ConfigProto", "str"], "function", ["None"], ["", "", "def", "session_config", "(", "params", ")", ":", "\n", "    ", "optimizer_options", "=", "tf", ".", "OptimizerOptions", "(", "opt_level", "=", "tf", ".", "OptimizerOptions", ".", "L1", ",", "\n", "do_function_inlining", "=", "True", ")", "\n", "graph_options", "=", "tf", ".", "GraphOptions", "(", "optimizer_options", "=", "optimizer_options", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "graph_options", "=", "graph_options", ")", "\n", "if", "params", ".", "device_list", ":", "\n", "        ", "device_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "params", ".", "device_list", "]", ")", "\n", "config", ".", "gpu_options", ".", "visible_device_list", "=", "device_str", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.decode_target_ids": [[248, 267], ["decoded.append", "syms.append"], "function", ["None"], ["", "def", "decode_target_ids", "(", "inputs", ",", "params", ")", ":", "\n", "    ", "decoded", "=", "[", "]", "\n", "vocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "\n", "for", "item", "in", "inputs", ":", "\n", "        ", "syms", "=", "[", "]", "\n", "for", "idx", "in", "item", ":", "\n", "            ", "sym", "=", "vocab", "[", "idx", "]", "\n", "\n", "if", "sym", "==", "params", ".", "eos", ":", "\n", "                ", "break", "\n", "\n", "", "if", "sym", "==", "params", ".", "pad", ":", "\n", "                ", "break", "\n", "\n", "", "syms", ".", "append", "(", "sym", ")", "\n", "", "decoded", ".", "append", "(", "syms", ")", "\n", "\n", "", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.main": [[269, 433], ["tensorflow.logging.set_verbosity", "thumt.get_model", "trainer.default_parameters", "trainer.merge_parameters", "trainer.import_params", "trainer.override_parameters", "trainer.export_params", "trainer.export_params", "models.get_model.get_parameters", "trainer.collect_params", "tensorflow.Graph().as_default", "trainer.get_initializer", "models.get_model.", "thumt.parallel_model", "tensorflow.train.get_or_create_global_step", "sorted", "tensorflow.logging.info", "trainer.get_learning_rate_decay", "tensorflow.convert_to_tensor", "tensorflow.summary.scalar", "tensorflow.train.AdamOptimizer", "trainer.session_config", "models.get_model.get_parameters", "thumt.get_training_input", "thumt.get_input_features", "model_cls.get_training_func", "tensorflow.add_n", "len", "list", "tensorflow.logging.info", "numpy.prod().tolist", "tensorflow.contrib.layers.optimize_loss", "tensorflow.no_op", "tensorflow.no_op", "tf.train.AdamOptimizer.compute_gradients", "thumt.replicate_variables", "thumt.zero_variables", "thumt.collect_gradients", "thumt.scale_gradients", "isinstance", "list", "thumt.sort_and_zip_files", "tensorflow.train.StopAtStepHook", "tensorflow.train.NanTensorHook", "tensorflow.train.LoggingTensorHook", "tensorflow.train.CheckpointSaverHook", "train_hooks.append", "tensorflow.train.MonitoredTrainingSession", "tensorflow.Graph", "os.path.join", "tensorflow.trainable_variables", "v.name[].ljust", "str().ljust", "tensorflow.clip_by_global_norm", "zip", "tensorflow.control_dependencies", "tf.train.AdamOptimizer.apply_gradients", "list", "thumt.EvaluationHook", "sess.should_stop", "thumt.session_run", "range", "sess.run", "numpy.prod", "tensorflow.trainable_variables", "tensorflow.shape", "tensorflow.shape", "tensorflow.train.Saver", "thumt.session_run", "str", "numpy.array", "thumt.create_inference_graph", "eval_input_fn", "trainer.decode_target_ids", "v.shape.as_list", "model_cls.get_evaluation_func"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.__init__.get_model", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.default_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.merge_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.import_params", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.override_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.export_params", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.export_params", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.collect_params", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.get_initializer", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel.parallel_model", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.get_learning_rate_decay", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.session_config", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_parameters", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.get_training_input", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.record.get_input_features", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_training_func", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.replicate_variables", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.zero_variables", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.collect_gradients", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.scale_gradients", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.sort_and_zip_files", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.session_run", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.session_run", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.create_inference_graph", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.code.trainer.decode_target_ids", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_evaluation_func"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "model_cls", "=", "models", ".", "get_model", "(", "args", ".", "model", ")", "\n", "params", "=", "default_parameters", "(", ")", "\n", "\n", "# Import and override parameters", "\n", "# Priorities (low -> high):", "\n", "# default -> saved -> command", "\n", "params", "=", "merge_parameters", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", "params", "=", "import_params", "(", "args", ".", "output", ",", "args", ".", "model", ",", "params", ")", "\n", "override_parameters", "(", "params", ",", "args", ")", "\n", "\n", "# Export all parameters and model specific parameters", "\n", "export_params", "(", "params", ".", "output", ",", "\"params.json\"", ",", "params", ")", "\n", "export_params", "(", "\n", "params", ".", "output", ",", "\n", "\"%s.json\"", "%", "args", ".", "model", ",", "\n", "collect_params", "(", "params", ",", "model_cls", ".", "get_parameters", "(", ")", ")", "\n", ")", "\n", "\n", "# Build Graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "if", "not", "params", ".", "record", ":", "\n", "# Build input queue", "\n", "            ", "features", "=", "dataset", ".", "get_training_input", "(", "params", ".", "input", ",", "params", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "record", ".", "get_input_features", "(", "\n", "os", ".", "path", ".", "join", "(", "params", ".", "record", ",", "\"*train*\"", ")", ",", "\"train\"", ",", "params", "\n", ")", "\n", "\n", "# Build model", "\n", "", "initializer", "=", "get_initializer", "(", "params", ")", "\n", "model", "=", "model_cls", "(", "params", ")", "\n", "\n", "# Multi-GPU setting", "\n", "sharded_losses", "=", "parallel", ".", "parallel_model", "(", "\n", "model", ".", "get_training_func", "(", "initializer", ")", ",", "\n", "features", ",", "\n", "params", ".", "device_list", "\n", ")", "\n", "loss", "=", "tf", ".", "add_n", "(", "sharded_losses", ")", "/", "len", "(", "sharded_losses", ")", "\n", "\n", "# Create global step", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "# Print parameters", "\n", "all_weights", "=", "{", "v", ".", "name", ":", "v", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "}", "\n", "total_size", "=", "0", "\n", "\n", "for", "v_name", "in", "sorted", "(", "list", "(", "all_weights", ")", ")", ":", "\n", "            ", "v", "=", "all_weights", "[", "v_name", "]", "\n", "tf", ".", "logging", ".", "info", "(", "\"%s\\tshape    %s\"", ",", "v", ".", "name", "[", ":", "-", "2", "]", ".", "ljust", "(", "80", ")", ",", "\n", "str", "(", "v", ".", "shape", ")", ".", "ljust", "(", "20", ")", ")", "\n", "v_size", "=", "np", ".", "prod", "(", "np", ".", "array", "(", "v", ".", "shape", ".", "as_list", "(", ")", ")", ")", ".", "tolist", "(", ")", "\n", "total_size", "+=", "v_size", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Total trainable variables size: %d\"", ",", "total_size", ")", "\n", "\n", "learning_rate", "=", "get_learning_rate_decay", "(", "params", ".", "learning_rate", ",", "\n", "global_step", ",", "params", ")", "\n", "learning_rate", "=", "tf", ".", "convert_to_tensor", "(", "learning_rate", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"learning_rate\"", ",", "learning_rate", ")", "\n", "\n", "# Create optimizer", "\n", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ",", "\n", "beta1", "=", "params", ".", "adam_beta1", ",", "\n", "beta2", "=", "params", ".", "adam_beta2", ",", "\n", "epsilon", "=", "params", ".", "adam_epsilon", ")", "\n", "\n", "if", "params", ".", "update_cycle", "==", "1", ":", "\n", "            ", "train_op", "=", "tf", ".", "contrib", ".", "layers", ".", "optimize_loss", "(", "\n", "name", "=", "\"training\"", ",", "\n", "loss", "=", "loss", ",", "\n", "global_step", "=", "global_step", ",", "\n", "learning_rate", "=", "learning_rate", ",", "\n", "clip_gradients", "=", "params", ".", "clip_grad_norm", "or", "None", ",", "\n", "optimizer", "=", "opt", ",", "\n", "colocate_gradients_with_ops", "=", "True", "\n", ")", "\n", "zero_op", "=", "tf", ".", "no_op", "(", "\"zero_op\"", ")", "\n", "collect_op", "=", "tf", ".", "no_op", "(", "\"collect_op\"", ")", "\n", "", "else", ":", "\n", "            ", "grads_and_vars", "=", "opt", ".", "compute_gradients", "(", "\n", "loss", ",", "colocate_gradients_with_ops", "=", "True", ")", "\n", "gradients", "=", "[", "item", "[", "0", "]", "for", "item", "in", "grads_and_vars", "]", "\n", "variables", "=", "[", "item", "[", "1", "]", "for", "item", "in", "grads_and_vars", "]", "\n", "\n", "variables", "=", "utils", ".", "replicate_variables", "(", "variables", ")", "\n", "zero_op", "=", "utils", ".", "zero_variables", "(", "variables", ")", "\n", "collect_op", "=", "utils", ".", "collect_gradients", "(", "gradients", ",", "variables", ")", "\n", "\n", "scale", "=", "1.0", "/", "params", ".", "update_cycle", "\n", "gradients", "=", "utils", ".", "scale_gradients", "(", "variables", ",", "scale", ")", "\n", "\n", "# Gradient clipping", "\n", "if", "isinstance", "(", "params", ".", "clip_grad_norm", "or", "None", ",", "float", ")", ":", "\n", "                ", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "\n", "params", ".", "clip_grad_norm", ")", "\n", "\n", "# Update variables", "\n", "", "grads_and_vars", "=", "list", "(", "zip", "(", "gradients", ",", "tf", ".", "trainable_variables", "(", ")", ")", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "collect_op", "]", ")", ":", "\n", "                ", "train_op", "=", "opt", ".", "apply_gradients", "(", "grads_and_vars", ",", "global_step", ")", "\n", "\n", "# Validation", "\n", "", "", "if", "params", ".", "validation", "and", "params", ".", "references", "[", "0", "]", ":", "\n", "            ", "files", "=", "[", "params", ".", "validation", "]", "+", "list", "(", "params", ".", "references", ")", "\n", "eval_inputs", "=", "dataset", ".", "sort_and_zip_files", "(", "files", ")", "\n", "eval_input_fn", "=", "dataset", ".", "get_evaluation_input", "\n", "", "else", ":", "\n", "            ", "eval_input_fn", "=", "None", "\n", "\n", "# Add hooks", "\n", "", "train_hooks", "=", "[", "\n", "tf", ".", "train", ".", "StopAtStepHook", "(", "last_step", "=", "params", ".", "train_steps", ")", ",", "\n", "tf", ".", "train", ".", "NanTensorHook", "(", "loss", ")", ",", "\n", "tf", ".", "train", ".", "LoggingTensorHook", "(", "\n", "{", "\n", "\"step\"", ":", "global_step", ",", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"source\"", ":", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", ",", "\n", "\"target\"", ":", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "\n", "}", ",", "\n", "every_n_iter", "=", "1", "\n", ")", ",", "\n", "tf", ".", "train", ".", "CheckpointSaverHook", "(", "\n", "checkpoint_dir", "=", "params", ".", "output", ",", "\n", "save_secs", "=", "params", ".", "save_checkpoint_secs", "or", "None", ",", "\n", "save_steps", "=", "params", ".", "save_checkpoint_steps", "or", "None", ",", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "\n", "max_to_keep", "=", "params", ".", "keep_checkpoint_max", ",", "\n", "sharded", "=", "False", "\n", ")", "\n", ")", "\n", "]", "\n", "\n", "config", "=", "session_config", "(", "params", ")", "\n", "\n", "if", "eval_input_fn", "is", "not", "None", ":", "\n", "            ", "train_hooks", ".", "append", "(", "\n", "hooks", ".", "EvaluationHook", "(", "\n", "lambda", "f", ":", "search", ".", "create_inference_graph", "(", "\n", "model", ".", "get_evaluation_func", "(", ")", ",", "f", ",", "params", "\n", ")", ",", "\n", "lambda", ":", "eval_input_fn", "(", "eval_inputs", ",", "params", ")", ",", "\n", "lambda", "x", ":", "decode_target_ids", "(", "x", ",", "params", ")", ",", "\n", "params", ".", "output", ",", "\n", "config", ",", "\n", "params", ".", "keep_top_checkpoint_max", ",", "\n", "eval_secs", "=", "params", ".", "eval_secs", ",", "\n", "eval_steps", "=", "params", ".", "eval_steps", "\n", ")", "\n", ")", "\n", "\n", "# Create session, do not use default CheckpointSaverHook", "\n", "", "with", "tf", ".", "train", ".", "MonitoredTrainingSession", "(", "\n", "checkpoint_dir", "=", "params", ".", "output", ",", "hooks", "=", "train_hooks", ",", "\n", "save_checkpoint_secs", "=", "None", ",", "config", "=", "config", ")", "as", "sess", ":", "\n", "            ", "while", "not", "sess", ".", "should_stop", "(", ")", ":", "\n", "# Bypass hook calls", "\n", "                ", "utils", ".", "session_run", "(", "sess", ",", "zero_op", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "params", ".", "update_cycle", ")", ":", "\n", "                    ", "utils", ".", "session_run", "(", "sess", ",", "collect_op", ")", "\n", "", "sess", ".", "run", "(", "train_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.closest_length": [[13, 29], ["len", "len", "abs"], "function", ["None"], ["def", "closest_length", "(", "candidate", ",", "references", ")", ":", "\n", "    ", "clen", "=", "len", "(", "candidate", ")", "\n", "closest_diff", "=", "9999", "\n", "closest_len", "=", "9999", "\n", "\n", "for", "reference", "in", "references", ":", "\n", "        ", "rlen", "=", "len", "(", "reference", ")", "\n", "diff", "=", "abs", "(", "rlen", "-", "clen", ")", "\n", "\n", "if", "diff", "<", "closest_diff", ":", "\n", "            ", "closest_diff", "=", "diff", "\n", "closest_len", "=", "rlen", "\n", "", "elif", "diff", "==", "closest_diff", ":", "\n", "            ", "closest_len", "=", "rlen", "if", "rlen", "<", "closest_len", "else", "closest_len", "\n", "\n", "", "", "return", "closest_len", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.shortest_length": [[31, 33], ["min", "len"], "function", ["None"], ["", "def", "shortest_length", "(", "references", ")", ":", "\n", "    ", "return", "min", "(", "[", "len", "(", "ref", ")", "for", "ref", "in", "references", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.modified_precision": [[35, 58], ["collections.Counter", "collections.Counter.items", "len", "collections.Counter", "min", "float", "float", "len", "tuple", "tuple", "max", "sum", "sum", "range", "len", "range", "clipped_counts.values", "collections.Counter.values"], "function", ["None"], ["", "def", "modified_precision", "(", "candidate", ",", "references", ",", "n", ")", ":", "\n", "    ", "tngrams", "=", "len", "(", "candidate", ")", "+", "1", "-", "n", "\n", "counts", "=", "Counter", "(", "[", "tuple", "(", "candidate", "[", "i", ":", "i", "+", "n", "]", ")", "for", "i", "in", "range", "(", "tngrams", ")", "]", ")", "\n", "\n", "if", "len", "(", "counts", ")", "==", "0", ":", "\n", "        ", "return", "0", ",", "0", "\n", "\n", "", "max_counts", "=", "{", "}", "\n", "for", "reference", "in", "references", ":", "\n", "        ", "rngrams", "=", "len", "(", "reference", ")", "+", "1", "-", "n", "\n", "ngrams", "=", "[", "tuple", "(", "reference", "[", "i", ":", "i", "+", "n", "]", ")", "for", "i", "in", "range", "(", "rngrams", ")", "]", "\n", "ref_counts", "=", "Counter", "(", "ngrams", ")", "\n", "for", "ngram", "in", "counts", ":", "\n", "            ", "mcount", "=", "0", "if", "ngram", "not", "in", "max_counts", "else", "max_counts", "[", "ngram", "]", "\n", "rcount", "=", "0", "if", "ngram", "not", "in", "ref_counts", "else", "ref_counts", "[", "ngram", "]", "\n", "max_counts", "[", "ngram", "]", "=", "max", "(", "mcount", ",", "rcount", ")", "\n", "\n", "", "", "clipped_counts", "=", "{", "}", "\n", "\n", "for", "ngram", ",", "count", "in", "counts", ".", "items", "(", ")", ":", "\n", "        ", "clipped_counts", "[", "ngram", "]", "=", "min", "(", "count", ",", "max_counts", "[", "ngram", "]", ")", "\n", "\n", "", "return", "float", "(", "sum", "(", "clipped_counts", ".", "values", "(", ")", ")", ")", ",", "float", "(", "sum", "(", "counts", ".", "values", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.brevity_penalty": [[60, 76], ["zip", "math.exp", "len", "min", "bleu.shortest_length", "bleu.closest_length"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.shortest_length", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.closest_length"], ["", "def", "brevity_penalty", "(", "trans", ",", "refs", ",", "mode", "=", "\"closest\"", ")", ":", "\n", "    ", "bp_c", "=", "0.0", "\n", "bp_r", "=", "0.0", "\n", "\n", "for", "candidate", ",", "references", "in", "zip", "(", "trans", ",", "refs", ")", ":", "\n", "        ", "bp_c", "+=", "len", "(", "candidate", ")", "\n", "\n", "if", "mode", "==", "\"shortest\"", ":", "\n", "            ", "bp_r", "+=", "shortest_length", "(", "references", ")", "\n", "", "else", ":", "\n", "            ", "bp_r", "+=", "closest_length", "(", "candidate", ",", "references", ")", "\n", "\n", "# Prevent zero divide", "\n", "", "", "bp_c", "=", "bp_c", "or", "1.0", "\n", "\n", "return", "math", ".", "exp", "(", "min", "(", "0", ",", "1.0", "-", "bp_r", "/", "bp_c", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.bleu": [[78, 113], ["zip", "range", "bleu.brevity_penalty", "range", "sum", "math.exp", "range", "range", "bleu.modified_precision", "range", "math.log", "len", "ValueError", "sum", "float", "float", "float", "range"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.brevity_penalty", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.modified_precision"], ["", "def", "bleu", "(", "trans", ",", "refs", ",", "bp", "=", "\"closest\"", ",", "smooth", "=", "False", ",", "n", "=", "4", ",", "weights", "=", "None", ")", ":", "\n", "    ", "p_norm", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "p_denorm", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "for", "candidate", ",", "references", "in", "zip", "(", "trans", ",", "refs", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "ccount", ",", "tcount", "=", "modified_precision", "(", "candidate", ",", "references", ",", "i", "+", "1", ")", "\n", "p_norm", "[", "i", "]", "+=", "ccount", "\n", "p_denorm", "[", "i", "]", "+=", "tcount", "\n", "\n", "", "", "bleu_n", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "# add one smoothing", "\n", "        ", "if", "smooth", "and", "i", ">", "0", ":", "\n", "            ", "p_norm", "[", "i", "]", "+=", "1", "\n", "p_denorm", "[", "i", "]", "+=", "1", "\n", "\n", "", "if", "p_norm", "[", "i", "]", "==", "0", "or", "p_denorm", "[", "i", "]", "==", "0", ":", "\n", "            ", "bleu_n", "[", "i", "]", "=", "-", "9999", "\n", "", "else", ":", "\n", "            ", "bleu_n", "[", "i", "]", "=", "math", ".", "log", "(", "float", "(", "p_norm", "[", "i", "]", ")", "/", "float", "(", "p_denorm", "[", "i", "]", ")", ")", "\n", "\n", "", "", "if", "weights", ":", "\n", "        ", "if", "len", "(", "weights", ")", "!=", "n", ":", "\n", "            ", "raise", "ValueError", "(", "\"len(weights) != n: invalid weight number\"", ")", "\n", "", "log_precision", "=", "sum", "(", "[", "bleu_n", "[", "i", "]", "*", "weights", "[", "i", "]", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "log_precision", "=", "sum", "(", "bleu_n", ")", "/", "float", "(", "n", ")", "\n", "\n", "", "bp", "=", "brevity_penalty", "(", "trans", ",", "refs", ",", "bp", ")", "\n", "\n", "score", "=", "bp", "*", "math", ".", "exp", "(", "log_precision", ")", "\n", "\n", "return", "score", "\n", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.loss.get_loss": [[8, 14], ["thumt.mrt_loss", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.mrt_loss"], ["def", "get_loss", "(", "features", ",", "params", ",", "ce", ",", "tgt_mask", ")", ":", "\n", "    ", "if", "params", ".", "use_mrt", ":", "\n", "        ", "loss", "=", "mrt_utils", ".", "mrt_loss", "(", "features", ",", "params", ",", "ce", ",", "tgt_mask", ")", "\n", "", "else", ":", "\n", "        ", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel.GPUParamServerDeviceSetter.__init__": [[15, 19], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "worker_device", ",", "ps_devices", ")", ":", "\n", "        ", "self", ".", "ps_devices", "=", "ps_devices", "\n", "self", ".", "worker_device", "=", "worker_device", "\n", "self", ".", "ps_sizes", "=", "[", "0", "]", "*", "len", "(", "self", ".", "ps_devices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel.GPUParamServerDeviceSetter.__call__": [[20, 34], ["min", "op.outputs[].get_shape().num_elements", "enumerate", "operator.itemgetter", "op.outputs[].get_shape"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "op", ")", ":", "\n", "        ", "if", "op", ".", "device", ":", "\n", "            ", "return", "op", ".", "device", "\n", "", "if", "op", ".", "type", "not", "in", "[", "\"Variable\"", ",", "\"VariableV2\"", ",", "\"VarHandleOp\"", "]", ":", "\n", "            ", "return", "self", ".", "worker_device", "\n", "\n", "# Gets the least loaded ps_device", "\n", "", "device_index", ",", "_", "=", "min", "(", "enumerate", "(", "self", ".", "ps_sizes", ")", ",", "\n", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ")", "\n", "device_name", "=", "self", ".", "ps_devices", "[", "device_index", "]", "\n", "var_size", "=", "op", ".", "outputs", "[", "0", "]", ".", "get_shape", "(", ")", ".", "num_elements", "(", ")", "\n", "self", ".", "ps_sizes", "[", "device_index", "]", "+=", "var_size", "\n", "\n", "return", "device_name", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel._maybe_repeat": [[36, 42], ["isinstance", "len"], "function", ["None"], ["", "", "def", "_maybe_repeat", "(", "x", ",", "n", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "        ", "assert", "len", "(", "x", ")", "==", "n", "\n", "return", "x", "\n", "", "else", ":", "\n", "        ", "return", "[", "x", "]", "*", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel._create_device_setter": [[44, 53], ["tensorflow.train.replica_device_setter", "parallel.GPUParamServerDeviceSetter", "range"], "function", ["None"], ["", "", "def", "_create_device_setter", "(", "is_cpu_ps", ",", "worker", ",", "num_gpus", ")", ":", "\n", "    ", "if", "is_cpu_ps", ":", "\n", "# tf.train.replica_device_setter supports placing variables on the CPU,", "\n", "# all on one GPU, or on ps_servers defined in a cluster_spec.", "\n", "        ", "return", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "worker_device", "=", "worker", ",", "ps_device", "=", "\"/cpu:0\"", ",", "ps_tasks", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "gpus", "=", "[", "\"/gpu:%d\"", "%", "i", "for", "i", "in", "range", "(", "num_gpus", ")", "]", "\n", "return", "GPUParamServerDeviceSetter", "(", "worker", ",", "gpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel.data_parallelism": [[56, 93], ["len", "kwargs.iteritems", "parallel._maybe_repeat", "range", "isinstance", "parallel._maybe_repeat", "range", "parallel._create_device_setter", "list", "tuple", "parallel._maybe_repeat", "list", "range", "len", "tensorflow.variable_scope", "zip", "zip", "range", "tensorflow.get_variable_scope", "tensorflow.name_scope", "list", "tensorflow.device", "tuple.append"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel._maybe_repeat", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel._maybe_repeat", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel._create_device_setter", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel._maybe_repeat"], ["", "", "def", "data_parallelism", "(", "devices", ",", "fn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "num_worker", "=", "len", "(", "devices", ")", "\n", "\n", "# Replicate args and kwargs", "\n", "if", "args", ":", "\n", "        ", "new_args", "=", "[", "_maybe_repeat", "(", "arg", ",", "num_worker", ")", "for", "arg", "in", "args", "]", "\n", "# Transpose", "\n", "new_args", "=", "[", "list", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "new_args", ")", "]", "\n", "", "else", ":", "\n", "        ", "new_args", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_worker", ")", "]", "\n", "\n", "", "new_kwargs", "=", "[", "{", "}", "for", "_", "in", "range", "(", "num_worker", ")", "]", "\n", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "iteritems", "(", ")", ":", "\n", "        ", "vals", "=", "_maybe_repeat", "(", "v", ",", "num_worker", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_worker", ")", ":", "\n", "            ", "new_kwargs", "[", "i", "]", "[", "k", "]", "=", "vals", "[", "i", "]", "\n", "\n", "", "", "fns", "=", "_maybe_repeat", "(", "fn", ",", "num_worker", ")", "\n", "\n", "# Now make the parallel call.", "\n", "outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_worker", ")", ":", "\n", "        ", "worker", "=", "\"/gpu:%d\"", "%", "i", "\n", "device_setter", "=", "_create_device_setter", "(", "False", ",", "worker", ",", "len", "(", "devices", ")", ")", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "(", "i", "!=", "0", ")", ")", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "\"parallel_%d\"", "%", "i", ")", ":", "\n", "                ", "with", "tf", ".", "device", "(", "device_setter", ")", ":", "\n", "                    ", "outputs", ".", "append", "(", "fns", "[", "i", "]", "(", "*", "new_args", "[", "i", "]", ",", "**", "new_kwargs", "[", "i", "]", ")", ")", "\n", "\n", "", "", "", "", "if", "isinstance", "(", "outputs", "[", "0", "]", ",", "tuple", ")", ":", "\n", "        ", "outputs", "=", "list", "(", "zip", "(", "*", "outputs", ")", ")", "\n", "outputs", "=", "tuple", "(", "[", "list", "(", "o", ")", "for", "o", "in", "outputs", "]", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel.shard_features": [[95, 117], ["len", "features.iteritems", "range", "tensorflow.convert_to_tensor", "datashard_to_features.append", "tf.tile.shape.as_list", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.device", "tensorflow.split", "sharded_features.iteritems"], "function", ["None"], ["", "def", "shard_features", "(", "features", ",", "device_list", ")", ":", "\n", "    ", "num_datashards", "=", "len", "(", "device_list", ")", "\n", "\n", "sharded_features", "=", "{", "}", "\n", "\n", "for", "k", ",", "v", "in", "features", ".", "iteritems", "(", ")", ":", "\n", "        ", "v", "=", "tf", ".", "convert_to_tensor", "(", "v", ")", "\n", "if", "not", "v", ".", "shape", ".", "as_list", "(", ")", ":", "\n", "            ", "v", "=", "tf", ".", "expand_dims", "(", "v", ",", "axis", "=", "-", "1", ")", "\n", "v", "=", "tf", ".", "tile", "(", "v", ",", "[", "num_datashards", "]", ")", "\n", "", "with", "tf", ".", "device", "(", "v", ".", "device", ")", ":", "\n", "            ", "sharded_features", "[", "k", "]", "=", "tf", ".", "split", "(", "v", ",", "num_datashards", ",", "0", ")", "\n", "\n", "", "", "datashard_to_features", "=", "[", "]", "\n", "\n", "for", "d", "in", "range", "(", "num_datashards", ")", ":", "\n", "        ", "feat", "=", "{", "\n", "k", ":", "v", "[", "d", "]", "for", "k", ",", "v", "in", "sharded_features", ".", "iteritems", "(", ")", "\n", "}", "\n", "datashard_to_features", ".", "append", "(", "feat", ")", "\n", "\n", "", "return", "datashard_to_features", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel.parallel_model": [[119, 132], ["parallel.shard_features", "parallel.data_parallelism", "len", "model_fn"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel.shard_features", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.parallel.data_parallelism"], ["", "def", "parallel_model", "(", "model_fn", ",", "features", ",", "devices", ",", "use_cpu", "=", "False", ")", ":", "\n", "    ", "devices", "=", "[", "\"gpu:%d\"", "%", "d", "for", "d", "in", "devices", "]", "\n", "\n", "if", "use_cpu", ":", "\n", "        ", "devices", "+=", "[", "\"cpu:0\"", "]", "\n", "\n", "", "if", "len", "(", "devices", ")", "==", "1", ":", "\n", "        ", "return", "[", "model_fn", "(", "features", ")", "]", "\n", "\n", "", "features", "=", "shard_features", "(", "features", ",", "devices", ")", "\n", "\n", "outputs", "=", "data_parallelism", "(", "devices", ",", "model_fn", ",", "features", ")", "\n", "return", "outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks.EvaluationHook.__init__": [[177, 211], ["tensorflow.logging.info", "base_dir.rstrip", "os.path.join", "os.path.join", "os.path.join", "tensorflow.train.SecondOrStepTimer", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "eval_fn", ",", "eval_input_fn", ",", "eval_decode_fn", ",", "base_dir", ",", "\n", "session_config", ",", "max_to_keep", "=", "5", ",", "eval_secs", "=", "None", ",", "\n", "eval_steps", "=", "None", ",", "metric", "=", "\"BLEU\"", ")", ":", "\n", "        ", "\"\"\" Initializes a `EvaluationHook`.\n        :param eval_fn: A function with signature (feature)\n        :param eval_input_fn: A function with signature ()\n        :param eval_decode_fn: A function with signature (inputs)\n        :param base_dir: A string. Base directory for the checkpoint files.\n        :param session_config: An instance of tf.ConfigProto\n        :param max_to_keep: An integer. The maximum of checkpoints to save\n        :param eval_secs: An integer, eval every N secs.\n        :param eval_steps: An integer, eval every N steps.\n        :param checkpoint_basename: `str`, base name for the checkpoint files.\n        :raises ValueError: One of `save_steps` or `save_secs` should be set.\n        :raises ValueError: At most one of saver or scaffold should be set.\n        \"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "\"Create EvaluationHook.\"", ")", "\n", "\n", "if", "metric", "!=", "\"BLEU\"", ":", "\n", "            ", "raise", "ValueError", "(", "\"Currently, EvaluationHook only support BLEU\"", ")", "\n", "\n", "", "self", ".", "_base_dir", "=", "base_dir", ".", "rstrip", "(", "\"/\"", ")", "\n", "self", ".", "_session_config", "=", "session_config", "\n", "self", ".", "_save_path", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "\"eval\"", ")", "\n", "self", ".", "_record_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "\"record\"", ")", "\n", "self", ".", "_log_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "\"log\"", ")", "\n", "self", ".", "_eval_fn", "=", "eval_fn", "\n", "self", ".", "_eval_input_fn", "=", "eval_input_fn", "\n", "self", ".", "_eval_decode_fn", "=", "eval_decode_fn", "\n", "self", ".", "_max_to_keep", "=", "max_to_keep", "\n", "self", ".", "_metric", "=", "metric", "\n", "self", ".", "_global_step", "=", "None", "\n", "self", ".", "_timer", "=", "tf", ".", "train", ".", "SecondOrStepTimer", "(", "\n", "every_secs", "=", "eval_secs", "or", "None", ",", "every_steps", "=", "eval_steps", "or", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks.EvaluationHook.begin": [[213, 234], ["tensorflow.train.get_global_step", "os.path.join", "tensorflow.gfile.Glob", "hooks.EvaluationHook._timer.last_triggered_step", "hooks.EvaluationHook._timer.update_last_triggered_step", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.gfile.MakeDirs", "name.replace", "tensorflow.gfile.Copy", "RuntimeError"], "methods", ["None"], ["", "def", "begin", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_timer", ".", "last_triggered_step", "(", ")", "is", "None", ":", "\n", "            ", "self", ".", "_timer", ".", "update_last_triggered_step", "(", "0", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "self", ".", "_save_path", ")", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"Making dir: %s\"", "%", "self", ".", "_save_path", ")", "\n", "tf", ".", "gfile", ".", "MakeDirs", "(", "self", ".", "_save_path", ")", "\n", "\n", "", "params_pattern", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "\"*.json\"", ")", "\n", "params_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "params_pattern", ")", "\n", "\n", "for", "name", "in", "params_files", ":", "\n", "            ", "new_name", "=", "name", ".", "replace", "(", "self", ".", "_base_dir", ",", "self", ".", "_save_path", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "name", ",", "new_name", ",", "overwrite", "=", "True", ")", "\n", "\n", "", "if", "global_step", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Global step should be created first\"", ")", "\n", "\n", "", "self", ".", "_global_step", "=", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks.EvaluationHook.before_run": [[235, 238], ["tensorflow.train.SessionRunArgs"], "methods", ["None"], ["", "def", "before_run", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "args", "=", "tf", ".", "train", ".", "SessionRunArgs", "(", "self", ".", "_global_step", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks.EvaluationHook.after_run": [[239, 304], ["hooks.EvaluationHook._timer.should_trigger_for_step", "run_context.session.run", "hooks.EvaluationHook._timer.should_trigger_for_step", "hooks.EvaluationHook._timer.update_last_triggered_step", "os.path.join", "hooks._get_saver", "tensorflow.logging.info", "_get_saver.save", "tensorflow.logging.info", "hooks._evaluate", "tensorflow.logging.info", "hooks._save_log", "os.path.join", "hooks._read_checkpoint_def", "hooks._read_score_record", "hooks._add_to_record", "hooks._save_score_record", "checkpoint_filename.replace.replace.replace", "hooks._save_checkpoint_def", "tensorflow.logging.info", "os.path.join", "os.path.join", "tensorflow.gfile.Glob", "tensorflow.logging.info", "os.path.join", "tensorflow.logging.info", "tensorflow.gfile.Glob", "o_file.replace", "tensorflow.gfile.Copy", "tensorflow.gfile.Remove"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._get_saver", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._evaluate", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._save_log", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._read_checkpoint_def", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._read_score_record", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._add_to_record", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._save_score_record", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._save_checkpoint_def"], ["", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "stale_global_step", "=", "run_values", ".", "results", "\n", "\n", "if", "self", ".", "_timer", ".", "should_trigger_for_step", "(", "stale_global_step", "+", "1", ")", ":", "\n", "            ", "global_step", "=", "run_context", ".", "session", ".", "run", "(", "self", ".", "_global_step", ")", "\n", "\n", "# Get the real value", "\n", "if", "self", ".", "_timer", ".", "should_trigger_for_step", "(", "global_step", ")", ":", "\n", "                ", "self", ".", "_timer", ".", "update_last_triggered_step", "(", "global_step", ")", "\n", "# Save model", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "\"model.ckpt\"", ")", "\n", "saver", "=", "_get_saver", "(", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Saving checkpoints for %d into %s.\"", "%", "\n", "(", "global_step", ",", "save_path", ")", ")", "\n", "saver", ".", "save", "(", "run_context", ".", "session", ",", "\n", "save_path", ",", "\n", "global_step", "=", "global_step", ")", "\n", "# Do validation here", "\n", "tf", ".", "logging", ".", "info", "(", "\"Validating model at step %d\"", "%", "global_step", ")", "\n", "score", "=", "_evaluate", "(", "self", ".", "_eval_fn", ",", "self", ".", "_eval_input_fn", ",", "\n", "self", ".", "_eval_decode_fn", ",", "\n", "self", ".", "_base_dir", ",", "\n", "self", ".", "_session_config", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"%s at step %d: %f\"", "%", "\n", "(", "self", ".", "_metric", ",", "global_step", ",", "score", ")", ")", "\n", "\n", "_save_log", "(", "self", ".", "_log_name", ",", "(", "self", ".", "_metric", ",", "global_step", ",", "score", ")", ")", "\n", "\n", "checkpoint_filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "\n", "\"checkpoint\"", ")", "\n", "all_checkpoints", "=", "_read_checkpoint_def", "(", "checkpoint_filename", ")", "\n", "records", "=", "_read_score_record", "(", "self", ".", "_record_name", ")", "\n", "latest_checkpoint", "=", "all_checkpoints", "[", "-", "1", "]", "\n", "record", "=", "[", "latest_checkpoint", ",", "score", "]", "\n", "added", ",", "removed", ",", "records", "=", "_add_to_record", "(", "records", ",", "record", ",", "\n", "self", ".", "_max_to_keep", ")", "\n", "\n", "if", "added", "is", "not", "None", ":", "\n", "                    ", "old_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "added", ")", "\n", "new_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "added", ")", "\n", "old_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "old_path", "+", "\"*\"", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Copying %s to %s\"", "%", "(", "old_path", ",", "new_path", ")", ")", "\n", "\n", "for", "o_file", "in", "old_files", ":", "\n", "                        ", "n_file", "=", "o_file", ".", "replace", "(", "old_path", ",", "new_path", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "o_file", ",", "n_file", ",", "overwrite", "=", "True", ")", "\n", "\n", "", "", "if", "removed", "is", "not", "None", ":", "\n", "                    ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "removed", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Removing %s\"", "%", "filename", ")", "\n", "files", "=", "tf", ".", "gfile", ".", "Glob", "(", "filename", "+", "\"*\"", ")", "\n", "\n", "for", "name", "in", "files", ":", "\n", "                        ", "tf", ".", "gfile", ".", "Remove", "(", "name", ")", "\n", "\n", "", "", "_save_score_record", "(", "self", ".", "_record_name", ",", "records", ")", "\n", "checkpoint_filename", "=", "checkpoint_filename", ".", "replace", "(", "\n", "self", ".", "_base_dir", ",", "self", ".", "_save_path", "\n", ")", "\n", "_save_checkpoint_def", "(", "checkpoint_filename", ",", "\n", "[", "item", "[", "0", "]", "for", "item", "in", "records", "]", ")", "\n", "\n", "best_score", "=", "records", "[", "0", "]", "[", "1", "]", "\n", "tf", ".", "logging", ".", "info", "(", "\"Best score at step %d: %f\"", "%", "\n", "(", "global_step", ",", "best_score", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks.EvaluationHook.end": [[305, 354], ["session.run", "hooks.EvaluationHook._timer.last_triggered_step", "tensorflow.logging.info", "hooks._evaluate", "tensorflow.logging.info", "os.path.join", "hooks._read_checkpoint_def", "hooks._read_score_record", "hooks._add_to_record", "hooks._save_score_record", "checkpoint_filename.replace.replace.replace", "hooks._save_checkpoint_def", "tensorflow.logging.info", "os.path.join", "os.path.join", "tensorflow.gfile.Glob", "tensorflow.logging.info", "os.path.join", "tensorflow.logging.info", "tensorflow.gfile.Glob", "o_file.replace", "tensorflow.gfile.Copy", "tensorflow.gfile.Remove"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._evaluate", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._read_checkpoint_def", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._read_score_record", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._add_to_record", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._save_score_record", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._save_checkpoint_def"], ["", "", "", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "last_step", "=", "session", ".", "run", "(", "self", ".", "_global_step", ")", "\n", "\n", "if", "last_step", "!=", "self", ".", "_timer", ".", "last_triggered_step", "(", ")", ":", "\n", "            ", "global_step", "=", "last_step", "\n", "tf", ".", "logging", ".", "info", "(", "\"Validating model at step %d\"", "%", "global_step", ")", "\n", "score", "=", "_evaluate", "(", "self", ".", "_eval_fn", ",", "self", ".", "_eval_input_fn", ",", "\n", "self", ".", "_eval_decode_fn", ",", "\n", "self", ".", "_base_dir", ",", "\n", "self", ".", "_session_config", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"%s at step %d: %f\"", "%", "\n", "(", "self", ".", "_metric", ",", "global_step", ",", "score", ")", ")", "\n", "\n", "checkpoint_filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "\n", "\"checkpoint\"", ")", "\n", "all_checkpoints", "=", "_read_checkpoint_def", "(", "checkpoint_filename", ")", "\n", "records", "=", "_read_score_record", "(", "self", ".", "_record_name", ")", "\n", "latest_checkpoint", "=", "all_checkpoints", "[", "-", "1", "]", "\n", "record", "=", "[", "latest_checkpoint", ",", "score", "]", "\n", "added", ",", "removed", ",", "records", "=", "_add_to_record", "(", "records", ",", "record", ",", "\n", "self", ".", "_max_to_keep", ")", "\n", "\n", "if", "added", "is", "not", "None", ":", "\n", "                ", "old_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_base_dir", ",", "added", ")", "\n", "new_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "added", ")", "\n", "old_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "old_path", "+", "\"*\"", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Copying %s to %s\"", "%", "(", "old_path", ",", "new_path", ")", ")", "\n", "\n", "for", "o_file", "in", "old_files", ":", "\n", "                    ", "n_file", "=", "o_file", ".", "replace", "(", "old_path", ",", "new_path", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "o_file", ",", "n_file", ",", "overwrite", "=", "True", ")", "\n", "\n", "", "", "if", "removed", "is", "not", "None", ":", "\n", "                ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_save_path", ",", "removed", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Removing %s\"", "%", "filename", ")", "\n", "files", "=", "tf", ".", "gfile", ".", "Glob", "(", "filename", "+", "\"*\"", ")", "\n", "\n", "for", "name", "in", "files", ":", "\n", "                    ", "tf", ".", "gfile", ".", "Remove", "(", "name", ")", "\n", "\n", "", "", "_save_score_record", "(", "self", ".", "_record_name", ",", "records", ")", "\n", "checkpoint_filename", "=", "checkpoint_filename", ".", "replace", "(", "\n", "self", ".", "_base_dir", ",", "self", ".", "_save_path", "\n", ")", "\n", "_save_checkpoint_def", "(", "checkpoint_filename", ",", "\n", "[", "item", "[", "0", "]", "for", "item", "in", "records", "]", ")", "\n", "\n", "best_score", "=", "records", "[", "0", "]", "[", "1", "]", "\n", "tf", ".", "logging", ".", "info", "(", "\"Best score: %f\"", "%", "best_score", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._get_saver": [[16, 28], ["tensorflow.get_collection", "RuntimeError", "len", "RuntimeError"], "function", ["None"], ["def", "_get_saver", "(", ")", ":", "\n", "# Get saver from the SAVERS collection if present.", "\n", "    ", "collection_key", "=", "tf", ".", "GraphKeys", ".", "SAVERS", "\n", "savers", "=", "tf", ".", "get_collection", "(", "collection_key", ")", "\n", "\n", "if", "not", "savers", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"No items in collection {}. \"", "\n", "\"Please add a saver to the collection \"", ")", "\n", "", "elif", "len", "(", "savers", ")", ">", "1", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"More than one item in collection\"", ")", "\n", "\n", "", "return", "savers", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._save_log": [[30, 37], ["open", "datetime.datetime.now", "fd.write"], "function", ["None"], ["", "def", "_save_log", "(", "filename", ",", "result", ")", ":", "\n", "    ", "metric", ",", "global_step", ",", "score", "=", "result", "\n", "\n", "with", "open", "(", "filename", ",", "\"a\"", ")", "as", "fd", ":", "\n", "        ", "time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "msg", "=", "\"%s: %s at step %d: %f\\n\"", "%", "(", "time", ",", "metric", ",", "global_step", ",", "score", ")", "\n", "fd", ".", "write", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._read_checkpoint_def": [[39, 49], ["tensorflow.gfile.GFile", "fd.readline", "records.append", "[].strip", "line.strip().split", "line.strip"], "function", ["None"], ["", "", "def", "_read_checkpoint_def", "(", "filename", ")", ":", "\n", "    ", "records", "=", "[", "]", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "readline", "(", ")", "\n", "\n", "for", "line", "in", "fd", ":", "\n", "            ", "records", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\":\"", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "", "", "return", "records", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._save_checkpoint_def": [[51, 67], ["sorted", "int", "keys.append", "tensorflow.gfile.GFile", "fd.write", "operator.itemgetter", "fd.write", "checkpoint_name.strip().split", "checkpoint_name.strip"], "function", ["None"], ["", "def", "_save_checkpoint_def", "(", "filename", ",", "checkpoint_names", ")", ":", "\n", "    ", "keys", "=", "[", "]", "\n", "\n", "for", "checkpoint_name", "in", "checkpoint_names", ":", "\n", "        ", "step", "=", "int", "(", "checkpoint_name", ".", "strip", "(", ")", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "keys", ".", "append", "(", "(", "step", ",", "checkpoint_name", ")", ")", "\n", "\n", "", "sorted_names", "=", "sorted", "(", "keys", ",", "key", "=", "operator", ".", "itemgetter", "(", "0", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"w\"", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "\"model_checkpoint_path: \\\"%s\\\"\\n\"", "%", "checkpoint_names", "[", "0", "]", ")", "\n", "\n", "for", "checkpoint_name", "in", "sorted_names", ":", "\n", "            ", "checkpoint_name", "=", "checkpoint_name", "[", "1", "]", "\n", "fd", ".", "write", "(", "\"all_model_checkpoint_paths: \\\"%s\\\"\\n\"", "%", "checkpoint_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._read_score_record": [[69, 84], ["tensorflow.gfile.Exists", "tensorflow.gfile.GFile", "line.strip().split", "float", "records.append", "name.strip", "line.strip"], "function", ["None"], ["", "", "", "def", "_read_score_record", "(", "filename", ")", ":", "\n", "# \"checkpoint_name\": score", "\n", "    ", "records", "=", "[", "]", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "filename", ")", ":", "\n", "        ", "return", "records", "\n", "\n", "", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "for", "line", "in", "fd", ":", "\n", "            ", "name", ",", "score", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\":\"", ")", "\n", "name", "=", "name", ".", "strip", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "score", "=", "float", "(", "score", ")", "\n", "records", ".", "append", "(", "[", "name", ",", "score", "]", ")", "\n", "\n", "", "", "return", "records", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._save_score_record": [[86, 102], ["sorted", "int", "keys.append", "tensorflow.gfile.GFile", "operator.itemgetter", "fd.write", "checkpoint_name.strip().split", "checkpoint_name.strip"], "function", ["None"], ["", "def", "_save_score_record", "(", "filename", ",", "records", ")", ":", "\n", "    ", "keys", "=", "[", "]", "\n", "\n", "for", "record", "in", "records", ":", "\n", "        ", "checkpoint_name", "=", "record", "[", "0", "]", "\n", "step", "=", "int", "(", "checkpoint_name", ".", "strip", "(", ")", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "keys", ".", "append", "(", "(", "step", ",", "record", ")", ")", "\n", "\n", "", "sorted_keys", "=", "sorted", "(", "keys", ",", "key", "=", "operator", ".", "itemgetter", "(", "0", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "sorted_records", "=", "[", "item", "[", "1", "]", "for", "item", "in", "sorted_keys", "]", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"w\"", ")", "as", "fd", ":", "\n", "        ", "for", "record", "in", "sorted_records", ":", "\n", "            ", "checkpoint_name", ",", "score", "=", "record", "\n", "fd", ".", "write", "(", "\"\\\"%s\\\": %f\\n\"", "%", "(", "checkpoint_name", ",", "score", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._add_to_record": [[104, 131], ["sorted", "len", "sorted", "sorted.append"], "function", ["None"], ["", "", "", "def", "_add_to_record", "(", "records", ",", "record", ",", "max_to_keep", ")", ":", "\n", "    ", "added", "=", "None", "\n", "removed", "=", "None", "\n", "models", "=", "{", "}", "\n", "\n", "for", "(", "name", ",", "score", ")", "in", "records", ":", "\n", "        ", "models", "[", "name", "]", "=", "score", "\n", "\n", "", "if", "len", "(", "records", ")", "<", "max_to_keep", ":", "\n", "        ", "if", "record", "[", "0", "]", "not", "in", "models", ":", "\n", "            ", "added", "=", "record", "[", "0", "]", "\n", "records", ".", "append", "(", "record", ")", "\n", "", "", "else", ":", "\n", "        ", "sorted_records", "=", "sorted", "(", "records", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "worst_score", "=", "sorted_records", "[", "-", "1", "]", "[", "1", "]", "\n", "current_score", "=", "record", "[", "1", "]", "\n", "\n", "if", "current_score", ">=", "worst_score", ":", "\n", "            ", "if", "record", "[", "0", "]", "not", "in", "models", ":", "\n", "                ", "added", "=", "record", "[", "0", "]", "\n", "removed", "=", "sorted_records", "[", "-", "1", "]", "[", "0", "]", "\n", "records", "=", "sorted_records", "[", ":", "-", "1", "]", "+", "[", "record", "]", "\n", "\n", "# Sort", "\n", "", "", "", "records", "=", "sorted", "(", "records", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "\n", "return", "added", ",", "removed", ",", "records", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.hooks._evaluate": [[133, 170], ["tensorflow.Graph", "tf.Graph.as_default", "input_fn", "eval_fn", "tensorflow.train.ChiefSessionCreator", "decode_fn", "thumt.bleu", "tensorflow.train.MonitoredSession", "decode_fn", "list", "range", "sess.should_stop", "sess.run", "outputs[].tolist", "all_outputs.extend", "range", "zip", "len", "item.tolist", "len", "all_refs[].extend"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.bleu"], ["", "def", "_evaluate", "(", "eval_fn", ",", "input_fn", ",", "decode_fn", ",", "path", ",", "config", ")", ":", "\n", "    ", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "graph", ".", "as_default", "(", ")", ":", "\n", "        ", "features", "=", "input_fn", "(", ")", "\n", "refs", "=", "features", "[", "\"references\"", "]", "\n", "predictions", "=", "eval_fn", "(", "features", ")", "\n", "results", "=", "{", "\n", "\"predictions\"", ":", "predictions", ",", "\n", "\"references\"", ":", "refs", "\n", "}", "\n", "\n", "all_refs", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "refs", ")", ")", "]", "\n", "all_outputs", "=", "[", "]", "\n", "\n", "sess_creator", "=", "tf", ".", "train", ".", "ChiefSessionCreator", "(", "\n", "checkpoint_dir", "=", "path", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "with", "tf", ".", "train", ".", "MonitoredSession", "(", "session_creator", "=", "sess_creator", ")", "as", "sess", ":", "\n", "            ", "while", "not", "sess", ".", "should_stop", "(", ")", ":", "\n", "                ", "outputs", "=", "sess", ".", "run", "(", "results", ")", "\n", "# shape: [batch, len]", "\n", "predictions", "=", "outputs", "[", "\"predictions\"", "]", ".", "tolist", "(", ")", "\n", "# shape: ([batch, len], ..., [batch, len])", "\n", "references", "=", "[", "item", ".", "tolist", "(", ")", "for", "item", "in", "outputs", "[", "\"references\"", "]", "]", "\n", "\n", "all_outputs", ".", "extend", "(", "predictions", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "refs", ")", ")", ":", "\n", "                    ", "all_refs", "[", "i", "]", ".", "extend", "(", "references", "[", "i", "]", ")", "\n", "\n", "", "", "", "decoded_symbols", "=", "decode_fn", "(", "all_outputs", ")", "\n", "decoded_refs", "=", "[", "decode_fn", "(", "refs", ")", "for", "refs", "in", "all_refs", "]", "\n", "decoded_refs", "=", "[", "list", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "decoded_refs", ")", "]", "\n", "\n", "return", "bleu", ".", "bleu", "(", "decoded_symbols", ",", "decoded_refs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search_aan.log_prob_from_logits": [[16, 18], ["tensorflow.reduce_logsumexp"], "function", ["None"], ["def", "log_prob_from_logits", "(", "logits", ")", ":", "\n", "    ", "return", "logits", "-", "tf", ".", "reduce_logsumexp", "(", "logits", ",", "axis", "=", "2", ",", "keep_dims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search_aan.compute_batch_indices": [[20, 34], ["tensorflow.reshape", "tensorflow.range"], "function", ["None"], ["", "def", "compute_batch_indices", "(", "batch_size", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Computes the i'th coordinate that contains the batch index for gathers.\n\n    Batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which\n    batch the beam item is in. This will create the i of the i,j coordinate\n    needed for the gather.\n\n    :param batch_size: Batch size\n    :param beam_size: Size of the beam.\n    :returns: batch_pos: [batch_size, beam_size] tensor of ids\n    \"\"\"", "\n", "batch_pos", "=", "tf", ".", "range", "(", "batch_size", "*", "beam_size", ")", "//", "beam_size", "\n", "batch_pos", "=", "tf", ".", "reshape", "(", "batch_pos", ",", "[", "batch_size", ",", "beam_size", "]", ")", "\n", "return", "batch_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search_aan.compute_topk_scores_and_seq": [[36, 84], ["tensorflow.nn.top_k", "search_aan.compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.gather_nd"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_batch_indices"], ["", "def", "compute_topk_scores_and_seq", "(", "sequences", ",", "scores", ",", "scores_to_gather", ",", "flags", ",", "\n", "beam_size", ",", "batch_size", ",", "decoded_states", "=", "None", ")", ":", "\n", "    ", "\"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n    This function is used to grow alive, and finished. It takes sequences,\n    scores, and flags, and returns the top k from sequences, scores_to_gather,\n    and flags based on the values in scores.\n\n    :param sequences: Tensor of sequences that we need to gather from.\n        [batch_size, beam_size, seq_length]\n    :param scores: Tensor of scores for each sequence in sequences.\n        [batch_size, beam_size]. We will use these to compute the topk.\n    :param scores_to_gather: Tensor of scores for each sequence in sequences.\n        [batch_size, beam_size]. We will return the gathered scores from\n        here. Scores to gather is different from scores because for\n        grow_alive, we will need to return log_probs, while for\n        grow_finished, we will need to return the length penalized scors.\n    :param flags: Tensor of bools for sequences that say whether a sequence has\n        reached EOS or not\n    :param beam_size: int\n    :param batch_size: int\n    :returns: Tuple of (topk_seq [batch_size, beam_size, decode_length],\n        topk_gathered_scores [batch_size, beam_size],\n        topk_finished_flags[batch_size, beam_size])\n    \"\"\"", "\n", "_", ",", "topk_indexes", "=", "tf", ".", "nn", ".", "top_k", "(", "scores", ",", "k", "=", "beam_size", ")", "\n", "# The next three steps are to create coordinates for tf.gather_nd to pull", "\n", "# out the top-k sequences from sequences based on scores.", "\n", "# batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which", "\n", "# batch the beam item is in. This will create the i of the i,j coordinate", "\n", "# needed for the gather", "\n", "batch_pos", "=", "compute_batch_indices", "(", "batch_size", ",", "beam_size", ")", "\n", "\n", "# top coordinates will give us the actual coordinates to do the gather.", "\n", "# stacking will create a tensor of dimension batch * beam * 2, where the", "\n", "# last dimension contains the i,j gathering coordinates.", "\n", "top_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "topk_indexes", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Gather up the highest scoring sequences", "\n", "topk_seq", "=", "tf", ".", "gather_nd", "(", "sequences", ",", "top_coordinates", ")", "\n", "topk_flags", "=", "tf", ".", "gather_nd", "(", "flags", ",", "top_coordinates", ")", "\n", "topk_gathered_scores", "=", "tf", ".", "gather_nd", "(", "scores_to_gather", ",", "top_coordinates", ")", "\n", "if", "decoded_states", "is", "not", "None", ":", "\n", "        ", "topk_decoded_states", "=", "[", "tf", ".", "gather_nd", "(", "state", ",", "top_coordinates", ")", "\n", "for", "state", "in", "decoded_states", "]", "\n", "return", "topk_seq", ",", "topk_gathered_scores", ",", "topk_flags", ",", "topk_decoded_states", "\n", "", "else", ":", "\n", "        ", "return", "topk_seq", ",", "topk_gathered_scores", ",", "topk_flags", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search_aan.beam_search": [[86, 448], ["tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.while_loop", "tf.expand_dims.set_shape", "tf.concat.set_shape", "tensorflow.where", "tensorflow.where", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.ones", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "search_aan.compute_topk_scores_and_seq", "search_aan.compute_topk_scores_and_seq", "tensorflow.reshape", "search_aan.create_inference_graph.symbols_to_logits_fn", "len", "tensorflow.pow", "tensorflow.reshape", "tensorflow.nn.top_k", "search_aan.compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.concat", "tensorflow.equal", "tf.concat.get_shape", "search_aan.beam_search.grow_topk"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_topk_scores_and_seq", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_topk_scores_and_seq", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_batch_indices"], ["", "", "def", "beam_search", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "beam_size", ",", "decode_length", ",", "\n", "vocab_size", ",", "alpha", ",", "decoded_states", ",", "eos_id", ",", "lp_constant", "=", "5.0", ")", ":", "\n", "    ", "\"\"\"Beam search with length penalties.\n\n    Uses an interface specific to the sequence cnn models;\n    Requires a function that can take the currently decoded symbols and return\n    the logits for the next symbol. The implementation is inspired by\n    https://arxiv.org/abs/1609.08144.\n\n    :param symbols_to_logits_fn: Interface to the model, to provide logits.\n        Should take [batch_size, decoded_ids] and return [\n        batch_size, vocab_size]\n    :param initial_ids: Ids to start off the decoding, this will be the first\n        thing handed to symbols_to_logits_fn\n        (after expanding to beam size) [batch_size]\n    :param beam_size: Size of the beam.\n    :param decode_length: Number of steps to decode for.\n    :param vocab_size: Size of the vocab, must equal the size of the logits\n        returned by symbols_to_logits_fn\n    :param alpha: alpha for length penalty.\n    :param eos_id: ID for end of sentence.\n    :param lp_constant: A floating number used in length penalty\n    :returns: Tuple of (decoded beams [batch_size, beam_size, decode_length]\n        decoding probabilities [batch_size, beam_size])\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "initial_ids", ")", "[", "0", "]", "\n", "\n", "# Assume initial_ids are prob 1.0", "\n", "initial_log_probs", "=", "tf", ".", "constant", "(", "[", "[", "0.", "]", "+", "[", "-", "float", "(", "\"inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", "]", ")", "\n", "# Expand to beam_size (batch_size, beam_size)", "\n", "alive_log_probs", "=", "tf", ".", "tile", "(", "initial_log_probs", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "\n", "# Expand each batch to beam_size", "\n", "alive_seq", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_ids", ",", "1", ")", ",", "[", "1", ",", "beam_size", "]", ")", "\n", "alive_seq", "=", "tf", ".", "expand_dims", "(", "alive_seq", ",", "2", ")", "# (batch_size, beam_size, 1)", "\n", "\n", "# Finished will keep track of all the sequences that have finished so far", "\n", "# Finished log probs will be negative infinity in the beginning", "\n", "# finished_flags will keep track of booleans", "\n", "finished_seq", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "alive_seq", ")", ",", "tf", ".", "int32", ")", "\n", "# Setting the scores of the initial to negative infinity.", "\n", "finished_scores", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "beam_size", "]", ")", "*", "-", "INF", "\n", "finished_flags", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "bool", ")", "\n", "\n", "def", "grow_finished", "(", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "curr_seq", ",", "\n", "curr_scores", ",", "curr_finished", ")", ":", "\n", "        ", "\"\"\"Given sequences and scores, will gather the top k=beam size\n           sequences.\n\n        :param finished_seq: Current finished sequences.\n            [batch_size, beam_size, current_decoded_length]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_flags: finished bools for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_seq: current topk sequence that has been grown by one\n            position. [batch_size, beam_size, current_decoded_length]\n        :param curr_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_finished: Finished flags for each of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences based on scores,\n                log probs of these sequences,\n                Finished flags of these sequences)\n        \"\"\"", "\n", "# First append a column of 0'ids to finished to make the same length", "\n", "# with finished scores", "\n", "finished_seq", "=", "tf", ".", "concat", "(", "\n", "[", "finished_seq", ",", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "tf", ".", "int32", ")", "]", ",", "\n", "axis", "=", "2", "\n", ")", "\n", "\n", "# Set the scores of the unfinished seq in curr_seq to large negative", "\n", "# values", "\n", "curr_scores", "+=", "(", "1.", "-", "tf", ".", "to_float", "(", "curr_finished", ")", ")", "*", "-", "INF", "\n", "# concatenating the sequences and scores along beam axis", "\n", "curr_finished_seq", "=", "tf", ".", "concat", "(", "[", "finished_seq", ",", "curr_seq", "]", ",", "axis", "=", "1", ")", "\n", "curr_finished_scores", "=", "tf", ".", "concat", "(", "[", "finished_scores", ",", "curr_scores", "]", ",", "\n", "axis", "=", "1", ")", "\n", "curr_finished_flags", "=", "tf", ".", "concat", "(", "[", "finished_flags", ",", "curr_finished", "]", ",", "\n", "axis", "=", "1", ")", "\n", "return", "compute_topk_scores_and_seq", "(", "\n", "curr_finished_seq", ",", "curr_finished_scores", ",", "curr_finished_scores", ",", "\n", "curr_finished_flags", ",", "beam_size", ",", "batch_size", ")", "\n", "\n", "", "def", "grow_alive", "(", "curr_seq", ",", "curr_scores", ",", "curr_log_probs", ",", "curr_finished", ",", "curr_decoded_states", ")", ":", "\n", "        ", "\"\"\"Given sequences and scores, will gather the top k=beam size\n           sequences.\n\n        :param curr_seq: current topk sequence that has been grown by one\n            position. [batch_size, beam_size, i+1]\n        :param curr_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_log_probs: log probs for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_finished: Finished flags for each of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences based on scores,\n                log probs of these sequences,\n                Finished flags of these sequences)\n        \"\"\"", "\n", "# Set the scores of the finished seq in curr_seq to large negative", "\n", "# values", "\n", "curr_scores", "+=", "tf", ".", "to_float", "(", "curr_finished", ")", "*", "-", "INF", "\n", "return", "compute_topk_scores_and_seq", "(", "curr_seq", ",", "curr_scores", ",", "\n", "curr_log_probs", ",", "curr_finished", ",", "\n", "beam_size", ",", "batch_size", ",", "decoded_states", "=", "curr_decoded_states", ")", "\n", "\n", "", "def", "grow_topk", "(", "i", ",", "alive_seq", ",", "alive_log_probs", ",", "decoded_states", ")", ":", "\n", "        ", "r\"\"\"Inner beam search loop.\n\n        This function takes the current alive sequences, and grows them to\n        topk sequences where k = 2*beam. We use 2*beam because, we could have\n        beam_size number of sequences that might hit <eos> and there will be\n        no alive sequences to continue. With 2*beam_size, this will not happen.\n        This relies on the assumption the vocab size is > beam size.\n        If this is true, we'll have at least beam_size non <eos> extensions if\n        we extract the next top 2*beam words.\n        Length penalty is given by = (5+len(decode)/6) ^ -\\alpha. Pls refer to\n        https://arxiv.org/abs/1609.08144.\n\n        :param i: loop index\n        :param alive_seq: Topk sequences decoded so far\n            [batch_size, beam_size, i+1]\n        :param alive_log_probs: probabilities of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences extended by the next word,\n                The log probs of these sequences,\n                The scores with length penalty of these sequences,\n                Flags indicating which of these sequences have finished\n                decoding)\n        \"\"\"", "\n", "# Get the logits for all the possible next symbols", "\n", "flat_ids", "=", "tf", ".", "reshape", "(", "alive_seq", ",", "[", "batch_size", "*", "beam_size", ",", "-", "1", "]", ")", "\n", "\n", "# (batch_size * beam_size, decoded_length)", "\n", "flat_logits_list", "=", "symbols_to_logits_fn", "(", "flat_ids", "[", ":", ",", "-", "1", ":", "]", ",", "decoded_states", ",", "tf", ".", "to_float", "(", "i", "+", "1", ")", ")", "\n", "logits_list", "=", "[", "\n", "tf", ".", "reshape", "(", "flat_logits", "[", "0", "]", ",", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", ")", "\n", "for", "flat_logits", "in", "flat_logits_list", "\n", "]", "\n", "states_list", "=", "[", "\n", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "flat_logits", "[", "1", "]", ",", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", ",", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", ")", "\n", "for", "flat_logits", "in", "flat_logits_list", "\n", "]", "\n", "\n", "# Convert logits to normalized log probs", "\n", "candidate_log_probs", "=", "[", "\n", "log_prob_from_logits", "(", "logits", ")", "\n", "for", "logits", "in", "logits_list", "\n", "]", "\n", "\n", "n_models", "=", "len", "(", "candidate_log_probs", ")", "\n", "candidate_log_probs", "=", "tf", ".", "add_n", "(", "candidate_log_probs", ")", "/", "float", "(", "n_models", ")", "\n", "\n", "# Multiply the probabilities by the current probabilities of the beam.", "\n", "# (batch_size, beam_size, vocab_size) + (batch_size, beam_size, 1)", "\n", "log_probs", "=", "candidate_log_probs", "+", "tf", ".", "expand_dims", "(", "alive_log_probs", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "length_penalty", "=", "tf", ".", "pow", "(", "\n", "(", "(", "lp_constant", "+", "tf", ".", "to_float", "(", "i", "+", "1", ")", ")", "/", "(", "1.0", "+", "lp_constant", ")", ")", ",", "alpha", "\n", ")", "\n", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "# Flatten out (beam_size, vocab_size) probs in to a list of", "\n", "# possibilities", "\n", "flat_curr_scores", "=", "tf", ".", "reshape", "(", "curr_scores", ",", "\n", "[", "-", "1", ",", "beam_size", "*", "vocab_size", "]", ")", "\n", "\n", "topk_scores", ",", "topk_ids", "=", "tf", ".", "nn", ".", "top_k", "(", "flat_curr_scores", ",", "k", "=", "beam_size", "*", "2", ")", "\n", "\n", "# Recovering the log probs because we will need to send them back", "\n", "topk_log_probs", "=", "topk_scores", "*", "length_penalty", "\n", "\n", "# Work out what beam the top probs are in.", "\n", "topk_beam_index", "=", "topk_ids", "//", "vocab_size", "\n", "topk_ids", "%=", "vocab_size", "# Unflatten the ids", "\n", "\n", "# The next three steps are to create coordinates for tf.gather_nd to", "\n", "# pull", "\n", "# out the correct sequences from id's that we need to grow.", "\n", "# We will also use the coordinates to gather the booleans of the beam", "\n", "# items that survived.", "\n", "batch_pos", "=", "compute_batch_indices", "(", "batch_size", ",", "beam_size", "*", "2", ")", "\n", "\n", "# top beams will give us the actual coordinates to do the gather.", "\n", "# stacking will create a tensor of dimension batch * beam * 2, where", "\n", "# the last dimension contains the i,j gathering coordinates.", "\n", "topk_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "topk_beam_index", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Gather up the most probable 2*beams both for the ids and", "\n", "# finished_in_alive bools", "\n", "topk_seq", "=", "tf", ".", "gather_nd", "(", "alive_seq", ",", "topk_coordinates", ")", "\n", "topk_decoded_states", "=", "[", "tf", ".", "gather_nd", "(", "state", ",", "topk_coordinates", ")", "\n", "for", "state", "in", "states_list", "]", "\n", "\n", "# Append the most probable alive", "\n", "topk_seq", "=", "tf", ".", "concat", "(", "[", "topk_seq", ",", "tf", ".", "expand_dims", "(", "topk_ids", ",", "axis", "=", "2", ")", "]", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "topk_finished", "=", "tf", ".", "equal", "(", "topk_ids", ",", "eos_id", ")", "\n", "\n", "return", "topk_seq", ",", "topk_log_probs", ",", "topk_scores", ",", "topk_finished", ",", "topk_decoded_states", "\n", "\n", "", "def", "inner_loop", "(", "i", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", ",", "decoded_states", ")", ":", "\n", "        ", "\"\"\"Inner beam search loop.\n\n        There are three groups of tensors, alive, finished, and topk.\n        The alive group contains information about the current alive sequences\n        The top-k group contains information about alive + topk current decoded\n        words the finished group contains information about finished sentences,\n        that is, the ones that have decoded to <EOS>. These are what we return.\n        The general beam search algorithm is as follows:\n        While we haven't terminated (pls look at termination condition)\n            1. Grow the current alive to get beam*2 top-k sequences\n            2. Among the top-k, keep the top beam_size ones that haven't\n            reached <eos> into alive\n            3. Among the top-k, keep the top beam_size ones have reached <eos>\n            into finished\n        Repeat\n        To make things simple with using fixed size tensors, we will end\n        up inserting unfinished sequences into finished in the beginning. To\n        stop that we add -ve INF to the score of the unfinished sequence so\n        that when a true finished sequence does appear, it will have a higher\n        score than all the unfinished ones.\n\n        :param i: loop index\n        :param alive_seq: Topk sequences decoded so far\n            [batch_size, beam_size, i+1]\n        :param alive_log_probs: probabilities of the beams.\n            [batch_size, beam_size]\n        :param finished_seq: Current finished sequences.\n            [batch_size, beam_size, i+1]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_flags: finished bools for each of these sequences.\n            [batch_size, beam_size]\n\n        :returns:\n            Tuple of\n                (Incremented loop index\n                New alive sequences,\n                Log probs of the alive sequences,\n                New finished sequences,\n                Scores of the new finished sequences,\n                Flags indicating which sequence in finished as reached EOS)\n        \"\"\"", "\n", "\n", "# Each inner loop, we carry out three steps:", "\n", "# 1. Get the current topk items.", "\n", "# 2. Extract the ones that have finished and haven't finished", "\n", "# 3. Recompute the contents of finished based on scores.", "\n", "decoded_shape", "=", "decoded_states", ".", "get_shape", "(", ")", "\n", "topk_seq", ",", "topk_log_probs", ",", "topk_scores", ",", "topk_finished", ",", "topk_decoded_states", "=", "grow_topk", "(", "\n", "i", ",", "alive_seq", ",", "alive_log_probs", ",", "decoded_states", "\n", ")", "\n", "alive_seq", ",", "alive_log_probs", ",", "_", ",", "decoded_states", "=", "grow_alive", "(", "topk_seq", ",", "topk_scores", ",", "\n", "topk_log_probs", ",", "\n", "topk_finished", ",", "\n", "topk_decoded_states", ")", "\n", "decoded_states", "=", "[", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "state", ",", "\n", "[", "batch_size", "*", "beam_size", ",", "decoded_shape", "[", "1", "]", ",", "-", "1", ",", "decoded_shape", "[", "-", "1", "]", "]", ")", ",", "\n", "[", "1", ",", "0", ",", "2", ",", "3", "]", ")", "\n", "for", "state", "in", "decoded_states", "]", "\n", "decoded_states", "=", "[", "tf", ".", "expand_dims", "(", "state", ",", "axis", "=", "0", ")", "for", "state", "in", "decoded_states", "]", "\n", "decoded_states", "=", "tf", ".", "concat", "(", "decoded_states", ",", "axis", "=", "0", ")", "\n", "finished_seq", ",", "finished_scores", ",", "finished_flags", "=", "grow_finished", "(", "\n", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "topk_seq", ",", "\n", "topk_scores", ",", "topk_finished", "\n", ")", "\n", "\n", "return", "(", "i", "+", "1", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", ",", "decoded_states", ")", "\n", "\n", "", "def", "_is_finished", "(", "i", ",", "unused_alive_seq", ",", "alive_log_probs", ",", "unused_finished_seq", ",", "\n", "finished_scores", ",", "finished_in_finished", ",", "unused_decoded_states", ")", ":", "\n", "        ", "\"\"\"Checking termination condition.\n\n        We terminate when we decoded up to decode_length or the lowest scoring\n        item in finished has a greater score that the highest prob item in\n        alive divided by the max length penalty\n\n        :param i: loop index\n        :param alive_log_probs: probabilities of the beams.\n            [batch_size, beam_size]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_in_finished: finished bools for each of these\n            sequences. [batch_size, beam_size]\n\n        :returns: Bool.\n        \"\"\"", "\n", "max_length_penalty", "=", "tf", ".", "pow", "(", "(", "(", "5.", "+", "tf", ".", "to_float", "(", "decode_length", ")", ")", "/", "6.", ")", ",", "\n", "alpha", ")", "\n", "# The best possible score of the most likley alive sequence", "\n", "lower_bound_alive_scores", "=", "alive_log_probs", "[", ":", ",", "0", "]", "/", "max_length_penalty", "\n", "\n", "# Now to compute the lowest score of a finished sequence in finished", "\n", "# If the sequence isn't finished, we multiply it's score by 0. since", "\n", "# scores are all -ve, taking the min will give us the score of the", "\n", "# lowest finished item.", "\n", "lowest_score_of_finished_in_finished", "=", "tf", ".", "reduce_min", "(", "\n", "finished_scores", "*", "tf", ".", "to_float", "(", "finished_in_finished", ")", ",", "axis", "=", "1", "\n", ")", "\n", "# If none of the sequences have finished, then the min will be 0 and", "\n", "# we have to replace it by -ve INF if it is. The score of any seq in", "\n", "# alive will be much higher than -ve INF and the termination condition", "\n", "# will not be met.", "\n", "lowest_score_of_finished_in_finished", "+=", "(", "\n", "(", "1.", "-", "tf", ".", "to_float", "(", "tf", ".", "reduce_any", "(", "finished_in_finished", ",", "1", ")", ")", ")", "*", "-", "INF", "\n", ")", "\n", "\n", "bound_is_met", "=", "tf", ".", "reduce_all", "(", "\n", "tf", ".", "greater", "(", "lowest_score_of_finished_in_finished", ",", "\n", "lower_bound_alive_scores", ")", "\n", ")", "\n", "\n", "return", "tf", ".", "logical_and", "(", "tf", ".", "less", "(", "i", ",", "decode_length", ")", ",", "\n", "tf", ".", "logical_not", "(", "bound_is_met", ")", ")", "\n", "\n", "", "(", "_", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "finished_scores", ",", "\n", "finished_flags", ",", "decoded_states", ")", "=", "tf", ".", "while_loop", "(", "\n", "_is_finished", ",", "\n", "inner_loop", ",", "[", "\n", "tf", ".", "constant", "(", "0", ")", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", ",", "decoded_states", ",", "\n", "]", ",", "\n", "shape_invariants", "=", "[", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "alive_log_probs", ".", "get_shape", "(", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "finished_scores", ".", "get_shape", "(", ")", ",", "\n", "finished_flags", ".", "get_shape", "(", ")", ",", "\n", "decoded_states", ".", "get_shape", "(", ")", "\n", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", "\n", ")", "\n", "\n", "alive_seq", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "finished_seq", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "\n", "# Accounting for corner case: It's possible that no sequence in alive for", "\n", "# a particular batch item ever reached <eos>. In that case, we should just", "\n", "# copy the contents of alive for that batch item.", "\n", "# tf.reduce_any(finished_flags, 1) if 0, means that no sequence for that", "\n", "# batch index had reached EOS. We need to do the same for the scores as", "\n", "# well.", "\n", "finished_seq", "=", "tf", ".", "where", "(", "\n", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ",", "finished_seq", ",", "alive_seq", ")", "\n", "finished_scores", "=", "tf", ".", "where", "(", "\n", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ",", "finished_scores", ",", "alive_log_probs", ")", "\n", "return", "finished_seq", ",", "finished_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search_aan.create_inference_graph": [[450, 546], ["tensorflow.fill", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "len", "enumerate", "tensorflow.concat", "search_aan.beam_search", "isinstance", "tensorflow.shape", "tensorflow.constant", "src_encodings.append", "src_masks.append", "tf.concat.append", "tensorflow.fill", "enumerate", "tensorflow.shape", "tensorflow.expand_dims", "results.append", "tensorflow.tile", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.zeros_like"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.beam_search"], ["", "def", "create_inference_graph", "(", "model_fns", ",", "features", ",", "params", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "model_fns", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "model_fns", "=", "[", "model_fns", "]", "\n", "\n", "", "decode_length", "=", "params", ".", "decode_length", "\n", "beam_size", "=", "params", ".", "beam_size", "\n", "top_beams", "=", "params", ".", "top_beams", "\n", "alpha", "=", "params", ".", "decode_alpha", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "# Prepend <bos> symbol", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "initial_ids", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "tf", ".", "constant", "(", "bos_id", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "\n", "inputs_old", "=", "features", "[", "\"source\"", "]", "\n", "inputs_length_old", "=", "features", "[", "\"source_length\"", "]", "\n", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source\"", "]", ",", "1", ")", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For source sequence length", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "# Setting decode length to input length + decode_length", "\n", "decode_length", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", "+", "decode_length", "\n", "\n", "# SEARCH", "\n", "# Append dummy target-side information", "\n", "features", "[", "\"target\"", "]", "=", "features", "[", "\"source\"", "]", "\n", "features", "[", "\"target_length\"", "]", "=", "features", "[", "\"source_length\"", "]", "\n", "# Generate source-side encoding outputs and masks", "\n", "src_encodings", "=", "[", "]", "\n", "src_masks", "=", "[", "]", "\n", "decoded_states", "=", "[", "]", "\n", "for", "i", ",", "model_fn", "in", "enumerate", "(", "model_fns", ")", ":", "\n", "        ", "src_encoding", ",", "src_mask", "=", "model_fn", "[", "0", "]", "(", "features", ")", "\n", "src_encodings", ".", "append", "(", "src_encoding", ")", "\n", "src_masks", ".", "append", "(", "src_mask", ")", "\n", "decoded_states", ".", "append", "(", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "zeros_like", "(", "src_encoding", "[", ":", ",", ":", "1", ",", ":", "]", ")", ",", "axis", "=", "0", ")", ",", "\n", "[", "params", ".", "num_decoder_layers", ",", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "0", ")", ")", "\n", "", "decoded_states", "=", "tf", ".", "concat", "(", "decoded_states", ",", "axis", "=", "0", ")", "\n", "\n", "# [batch, decoded_ids] => [batch, vocab_size]", "\n", "def", "symbols_to_logits_fn", "(", "decoded_ids", ",", "decoded_states", ",", "decoded_position", ")", ":", "\n", "        ", "features", "[", "\"target\"", "]", "=", "decoded_ids", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "for", "i", ",", "model_fn", "in", "enumerate", "(", "model_fns", ")", ":", "\n", "            ", "results", ".", "append", "(", "model_fn", "[", "1", "]", "(", "features", ",", "src_encodings", "[", "i", "]", ",", "src_masks", "[", "i", "]", ",", "decoded_states", "[", "i", "]", ",", "decoded_position", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "ids", ",", "scores", "=", "beam_search", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "\n", "beam_size", ",", "decode_length", ",", "vocab_size", ",", "\n", "alpha", ",", "\n", "decoded_states", ",", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", ",", "\n", "lp_constant", "=", "params", ".", "decode_constant", ")", "\n", "\n", "# Set inputs back to the unexpanded inputs to not to confuse the Estimator", "\n", "features", "[", "\"source\"", "]", "=", "inputs_old", "\n", "features", "[", "\"source_length\"", "]", "=", "inputs_length_old", "\n", "\n", "# Return `top_beams` decoding", "\n", "# (also remove initial id from the beam search)", "\n", "if", "not", "params", ".", "decode_normalize", ":", "\n", "        ", "if", "top_beams", "==", "1", ":", "\n", "            ", "return", "ids", "[", ":", ",", "0", ",", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "return", "ids", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", "\n", "", "", "else", ":", "\n", "        ", "if", "top_beams", "==", "1", ":", "\n", "            ", "return", "ids", "[", ":", ",", "0", ",", "1", ":", "]", ",", "scores", "[", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "ids", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", ",", "scores", "[", ":", ",", ":", "top_beams", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.log_prob_from_logits": [[16, 18], ["tensorflow.reduce_logsumexp"], "function", ["None"], ["def", "log_prob_from_logits", "(", "logits", ")", ":", "\n", "    ", "return", "logits", "-", "tf", ".", "reduce_logsumexp", "(", "logits", ",", "axis", "=", "2", ",", "keep_dims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_batch_indices": [[20, 34], ["tensorflow.reshape", "tensorflow.range"], "function", ["None"], ["", "def", "compute_batch_indices", "(", "batch_size", ",", "beam_size", ")", ":", "\n", "    ", "\"\"\"Computes the i'th coordinate that contains the batch index for gathers.\n\n    Batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which\n    batch the beam item is in. This will create the i of the i,j coordinate\n    needed for the gather.\n\n    :param batch_size: Batch size\n    :param beam_size: Size of the beam.\n    :returns: batch_pos: [batch_size, beam_size] tensor of ids\n    \"\"\"", "\n", "batch_pos", "=", "tf", ".", "range", "(", "batch_size", "*", "beam_size", ")", "//", "beam_size", "\n", "batch_pos", "=", "tf", ".", "reshape", "(", "batch_pos", ",", "[", "batch_size", ",", "beam_size", "]", ")", "\n", "return", "batch_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_topk_scores_and_seq": [[36, 79], ["tensorflow.nn.top_k", "search.compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.gather_nd"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_batch_indices"], ["", "def", "compute_topk_scores_and_seq", "(", "sequences", ",", "scores", ",", "scores_to_gather", ",", "flags", ",", "\n", "beam_size", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"Given sequences and scores, will gather the top k=beam size sequences.\n\n    This function is used to grow alive, and finished. It takes sequences,\n    scores, and flags, and returns the top k from sequences, scores_to_gather,\n    and flags based on the values in scores.\n\n    :param sequences: Tensor of sequences that we need to gather from.\n        [batch_size, beam_size, seq_length]\n    :param scores: Tensor of scores for each sequence in sequences.\n        [batch_size, beam_size]. We will use these to compute the topk.\n    :param scores_to_gather: Tensor of scores for each sequence in sequences.\n        [batch_size, beam_size]. We will return the gathered scores from\n        here. Scores to gather is different from scores because for\n        grow_alive, we will need to return log_probs, while for\n        grow_finished, we will need to return the length penalized scors.\n    :param flags: Tensor of bools for sequences that say whether a sequence has\n        reached EOS or not\n    :param beam_size: int\n    :param batch_size: int\n    :returns: Tuple of (topk_seq [batch_size, beam_size, decode_length],\n        topk_gathered_scores [batch_size, beam_size],\n        topk_finished_flags[batch_size, beam_size])\n    \"\"\"", "\n", "_", ",", "topk_indexes", "=", "tf", ".", "nn", ".", "top_k", "(", "scores", ",", "k", "=", "beam_size", ")", "\n", "# The next three steps are to create coordinates for tf.gather_nd to pull", "\n", "# out the top-k sequences from sequences based on scores.", "\n", "# batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..]. It says which", "\n", "# batch the beam item is in. This will create the i of the i,j coordinate", "\n", "# needed for the gather", "\n", "batch_pos", "=", "compute_batch_indices", "(", "batch_size", ",", "beam_size", ")", "\n", "\n", "# top coordinates will give us the actual coordinates to do the gather.", "\n", "# stacking will create a tensor of dimension batch * beam * 2, where the", "\n", "# last dimension contains the i,j gathering coordinates.", "\n", "top_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "topk_indexes", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Gather up the highest scoring sequences", "\n", "topk_seq", "=", "tf", ".", "gather_nd", "(", "sequences", ",", "top_coordinates", ")", "\n", "topk_flags", "=", "tf", ".", "gather_nd", "(", "flags", ",", "top_coordinates", ")", "\n", "topk_gathered_scores", "=", "tf", ".", "gather_nd", "(", "scores_to_gather", ",", "top_coordinates", ")", "\n", "return", "topk_seq", ",", "topk_gathered_scores", ",", "topk_flags", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.beam_search": [[81, 428], ["tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.while_loop", "tf.expand_dims.set_shape", "tf.concat.set_shape", "tensorflow.where", "tensorflow.where", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.ones", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "search.compute_topk_scores_and_seq", "search.compute_topk_scores_and_seq", "tensorflow.reshape", "search.create_inference_graph.symbols_to_logits_fn", "len", "tensorflow.pow", "tensorflow.reshape", "tensorflow.nn.top_k", "search.compute_batch_indices", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.concat", "tensorflow.equal", "search.beam_search.grow_topk"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_topk_scores_and_seq", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_topk_scores_and_seq", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.compute_batch_indices"], ["", "def", "beam_search", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "beam_size", ",", "decode_length", ",", "\n", "vocab_size", ",", "alpha", ",", "eos_id", ",", "lp_constant", "=", "5.0", ")", ":", "\n", "    ", "\"\"\"Beam search with length penalties.\n\n    Uses an interface specific to the sequence cnn models;\n    Requires a function that can take the currently decoded symbols and return\n    the logits for the next symbol. The implementation is inspired by\n    https://arxiv.org/abs/1609.08144.\n\n    :param symbols_to_logits_fn: Interface to the model, to provide logits.\n        Should take [batch_size, decoded_ids] and return [\n        batch_size, vocab_size]\n    :param initial_ids: Ids to start off the decoding, this will be the first\n        thing handed to symbols_to_logits_fn\n        (after expanding to beam size) [batch_size]\n    :param beam_size: Size of the beam.\n    :param decode_length: Number of steps to decode for.\n    :param vocab_size: Size of the vocab, must equal the size of the logits\n        returned by symbols_to_logits_fn\n    :param alpha: alpha for length penalty.\n    :param eos_id: ID for end of sentence.\n    :param lp_constant: A floating number used in length penalty\n    :returns: Tuple of (decoded beams [batch_size, beam_size, decode_length]\n        decoding probabilities [batch_size, beam_size])\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "initial_ids", ")", "[", "0", "]", "\n", "\n", "# Assume initial_ids are prob 1.0", "\n", "initial_log_probs", "=", "tf", ".", "constant", "(", "[", "[", "0.", "]", "+", "[", "-", "float", "(", "\"inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", "]", ")", "\n", "# Expand to beam_size (batch_size, beam_size)", "\n", "alive_log_probs", "=", "tf", ".", "tile", "(", "initial_log_probs", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "\n", "# Expand each batch to beam_size", "\n", "alive_seq", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_ids", ",", "1", ")", ",", "[", "1", ",", "beam_size", "]", ")", "\n", "alive_seq", "=", "tf", ".", "expand_dims", "(", "alive_seq", ",", "2", ")", "# (batch_size, beam_size, 1)", "\n", "\n", "# Finished will keep track of all the sequences that have finished so far", "\n", "# Finished log probs will be negative infinity in the beginning", "\n", "# finished_flags will keep track of booleans", "\n", "finished_seq", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "alive_seq", ")", ",", "tf", ".", "int32", ")", "\n", "# Setting the scores of the initial to negative infinity.", "\n", "finished_scores", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "beam_size", "]", ")", "*", "-", "INF", "\n", "finished_flags", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", "]", ",", "tf", ".", "bool", ")", "\n", "\n", "def", "grow_finished", "(", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "curr_seq", ",", "\n", "curr_scores", ",", "curr_finished", ")", ":", "\n", "        ", "\"\"\"Given sequences and scores, will gather the top k=beam size\n           sequences.\n\n        :param finished_seq: Current finished sequences.\n            [batch_size, beam_size, current_decoded_length]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_flags: finished bools for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_seq: current topk sequence that has been grown by one\n            position. [batch_size, beam_size, current_decoded_length]\n        :param curr_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_finished: Finished flags for each of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences based on scores,\n                log probs of these sequences,\n                Finished flags of these sequences)\n        \"\"\"", "\n", "# First append a column of 0'ids to finished to make the same length", "\n", "# with finished scores", "\n", "finished_seq", "=", "tf", ".", "concat", "(", "\n", "[", "finished_seq", ",", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ",", "tf", ".", "int32", ")", "]", ",", "\n", "axis", "=", "2", "\n", ")", "\n", "\n", "# Set the scores of the unfinished seq in curr_seq to large negative", "\n", "# values", "\n", "curr_scores", "+=", "(", "1.", "-", "tf", ".", "to_float", "(", "curr_finished", ")", ")", "*", "-", "INF", "\n", "# concatenating the sequences and scores along beam axis", "\n", "curr_finished_seq", "=", "tf", ".", "concat", "(", "[", "finished_seq", ",", "curr_seq", "]", ",", "axis", "=", "1", ")", "\n", "curr_finished_scores", "=", "tf", ".", "concat", "(", "[", "finished_scores", ",", "curr_scores", "]", ",", "\n", "axis", "=", "1", ")", "\n", "curr_finished_flags", "=", "tf", ".", "concat", "(", "[", "finished_flags", ",", "curr_finished", "]", ",", "\n", "axis", "=", "1", ")", "\n", "return", "compute_topk_scores_and_seq", "(", "\n", "curr_finished_seq", ",", "curr_finished_scores", ",", "curr_finished_scores", ",", "\n", "curr_finished_flags", ",", "beam_size", ",", "batch_size", ")", "\n", "\n", "", "def", "grow_alive", "(", "curr_seq", ",", "curr_scores", ",", "curr_log_probs", ",", "curr_finished", ")", ":", "\n", "        ", "\"\"\"Given sequences and scores, will gather the top k=beam size\n           sequences.\n\n        :param curr_seq: current topk sequence that has been grown by one\n            position. [batch_size, beam_size, i+1]\n        :param curr_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_log_probs: log probs for each of these sequences.\n            [batch_size, beam_size]\n        :param curr_finished: Finished flags for each of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences based on scores,\n                log probs of these sequences,\n                Finished flags of these sequences)\n        \"\"\"", "\n", "# Set the scores of the finished seq in curr_seq to large negative", "\n", "# values", "\n", "curr_scores", "+=", "tf", ".", "to_float", "(", "curr_finished", ")", "*", "-", "INF", "\n", "return", "compute_topk_scores_and_seq", "(", "curr_seq", ",", "curr_scores", ",", "\n", "curr_log_probs", ",", "curr_finished", ",", "\n", "beam_size", ",", "batch_size", ")", "\n", "\n", "", "def", "grow_topk", "(", "i", ",", "alive_seq", ",", "alive_log_probs", ")", ":", "\n", "        ", "r\"\"\"Inner beam search loop.\n\n        This function takes the current alive sequences, and grows them to\n        topk sequences where k = 2*beam. We use 2*beam because, we could have\n        beam_size number of sequences that might hit <eos> and there will be\n        no alive sequences to continue. With 2*beam_size, this will not happen.\n        This relies on the assumption the vocab size is > beam size.\n        If this is true, we'll have at least beam_size non <eos> extensions if\n        we extract the next top 2*beam words.\n        Length penalty is given by = (5+len(decode)/6) ^ -\\alpha. Pls refer to\n        https://arxiv.org/abs/1609.08144.\n\n        :param i: loop index\n        :param alive_seq: Topk sequences decoded so far\n            [batch_size, beam_size, i+1]\n        :param alive_log_probs: probabilities of these sequences.\n            [batch_size, beam_size]\n        :returns:\n            Tuple of\n                (Top-k sequences extended by the next word,\n                The log probs of these sequences,\n                The scores with length penalty of these sequences,\n                Flags indicating which of these sequences have finished\n                decoding)\n        \"\"\"", "\n", "# Get the logits for all the possible next symbols", "\n", "flat_ids", "=", "tf", ".", "reshape", "(", "alive_seq", ",", "[", "batch_size", "*", "beam_size", ",", "-", "1", "]", ")", "\n", "\n", "# (batch_size * beam_size, decoded_length)", "\n", "flat_logits_list", "=", "symbols_to_logits_fn", "(", "flat_ids", ")", "\n", "logits_list", "=", "[", "\n", "tf", ".", "reshape", "(", "flat_logits", ",", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", ")", "\n", "for", "flat_logits", "in", "flat_logits_list", "\n", "]", "\n", "\n", "# Convert logits to normalized log probs", "\n", "candidate_log_probs", "=", "[", "\n", "log_prob_from_logits", "(", "logits", ")", "\n", "for", "logits", "in", "logits_list", "\n", "]", "\n", "\n", "n_models", "=", "len", "(", "candidate_log_probs", ")", "\n", "candidate_log_probs", "=", "tf", ".", "add_n", "(", "candidate_log_probs", ")", "/", "float", "(", "n_models", ")", "\n", "\n", "# Multiply the probabilities by the current probabilities of the beam.", "\n", "# (batch_size, beam_size, vocab_size) + (batch_size, beam_size, 1)", "\n", "log_probs", "=", "candidate_log_probs", "+", "tf", ".", "expand_dims", "(", "alive_log_probs", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "length_penalty", "=", "tf", ".", "pow", "(", "\n", "(", "(", "lp_constant", "+", "tf", ".", "to_float", "(", "i", "+", "1", ")", ")", "/", "(", "1.0", "+", "lp_constant", ")", ")", ",", "alpha", "\n", ")", "\n", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "# Flatten out (beam_size, vocab_size) probs in to a list of", "\n", "# possibilities", "\n", "flat_curr_scores", "=", "tf", ".", "reshape", "(", "curr_scores", ",", "\n", "[", "-", "1", ",", "beam_size", "*", "vocab_size", "]", ")", "\n", "\n", "topk_scores", ",", "topk_ids", "=", "tf", ".", "nn", ".", "top_k", "(", "flat_curr_scores", ",", "k", "=", "beam_size", "*", "2", ")", "\n", "\n", "# Recovering the log probs because we will need to send them back", "\n", "topk_log_probs", "=", "topk_scores", "*", "length_penalty", "\n", "\n", "# Work out what beam the top probs are in.", "\n", "topk_beam_index", "=", "topk_ids", "//", "vocab_size", "\n", "topk_ids", "%=", "vocab_size", "# Unflatten the ids", "\n", "\n", "# The next three steps are to create coordinates for tf.gather_nd to", "\n", "# pull", "\n", "# out the correct sequences from id's that we need to grow.", "\n", "# We will also use the coordinates to gather the booleans of the beam", "\n", "# items that survived.", "\n", "batch_pos", "=", "compute_batch_indices", "(", "batch_size", ",", "beam_size", "*", "2", ")", "\n", "\n", "# top beams will give us the actual coordinates to do the gather.", "\n", "# stacking will create a tensor of dimension batch * beam * 2, where", "\n", "# the last dimension contains the i,j gathering coordinates.", "\n", "topk_coordinates", "=", "tf", ".", "stack", "(", "[", "batch_pos", ",", "topk_beam_index", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# Gather up the most probable 2*beams both for the ids and", "\n", "# finished_in_alive bools", "\n", "topk_seq", "=", "tf", ".", "gather_nd", "(", "alive_seq", ",", "topk_coordinates", ")", "\n", "\n", "# Append the most probable alive", "\n", "topk_seq", "=", "tf", ".", "concat", "(", "[", "topk_seq", ",", "tf", ".", "expand_dims", "(", "topk_ids", ",", "axis", "=", "2", ")", "]", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "topk_finished", "=", "tf", ".", "equal", "(", "topk_ids", ",", "eos_id", ")", "\n", "\n", "return", "topk_seq", ",", "topk_log_probs", ",", "topk_scores", ",", "topk_finished", "\n", "\n", "", "def", "inner_loop", "(", "i", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", ")", ":", "\n", "        ", "\"\"\"Inner beam search loop.\n\n        There are three groups of tensors, alive, finished, and topk.\n        The alive group contains information about the current alive sequences\n        The top-k group contains information about alive + topk current decoded\n        words the finished group contains information about finished sentences,\n        that is, the ones that have decoded to <EOS>. These are what we return.\n        The general beam search algorithm is as follows:\n        While we haven't terminated (pls look at termination condition)\n            1. Grow the current alive to get beam*2 top-k sequences\n            2. Among the top-k, keep the top beam_size ones that haven't\n            reached <eos> into alive\n            3. Among the top-k, keep the top beam_size ones have reached <eos>\n            into finished\n        Repeat\n        To make things simple with using fixed size tensors, we will end\n        up inserting unfinished sequences into finished in the beginning. To\n        stop that we add -ve INF to the score of the unfinished sequence so\n        that when a true finished sequence does appear, it will have a higher\n        score than all the unfinished ones.\n\n        :param i: loop index\n        :param alive_seq: Topk sequences decoded so far\n            [batch_size, beam_size, i+1]\n        :param alive_log_probs: probabilities of the beams.\n            [batch_size, beam_size]\n        :param finished_seq: Current finished sequences.\n            [batch_size, beam_size, i+1]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_flags: finished bools for each of these sequences.\n            [batch_size, beam_size]\n\n        :returns:\n            Tuple of\n                (Incremented loop index\n                New alive sequences,\n                Log probs of the alive sequences,\n                New finished sequences,\n                Scores of the new finished sequences,\n                Flags indicating which sequence in finished as reached EOS)\n        \"\"\"", "\n", "\n", "# Each inner loop, we carry out three steps:", "\n", "# 1. Get the current topk items.", "\n", "# 2. Extract the ones that have finished and haven't finished", "\n", "# 3. Recompute the contents of finished based on scores.", "\n", "topk_seq", ",", "topk_log_probs", ",", "topk_scores", ",", "topk_finished", "=", "grow_topk", "(", "\n", "i", ",", "alive_seq", ",", "alive_log_probs", "\n", ")", "\n", "alive_seq", ",", "alive_log_probs", ",", "_", "=", "grow_alive", "(", "topk_seq", ",", "topk_scores", ",", "\n", "topk_log_probs", ",", "\n", "topk_finished", ")", "\n", "finished_seq", ",", "finished_scores", ",", "finished_flags", "=", "grow_finished", "(", "\n", "finished_seq", ",", "finished_scores", ",", "finished_flags", ",", "topk_seq", ",", "\n", "topk_scores", ",", "topk_finished", "\n", ")", "\n", "\n", "return", "(", "i", "+", "1", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", ")", "\n", "\n", "", "def", "_is_finished", "(", "i", ",", "unused_alive_seq", ",", "alive_log_probs", ",", "unused_finished_seq", ",", "\n", "finished_scores", ",", "finished_in_finished", ")", ":", "\n", "        ", "\"\"\"Checking termination condition.\n\n        We terminate when we decoded up to decode_length or the lowest scoring\n        item in finished has a greater score that the highest prob item in\n        alive divided by the max length penalty\n\n        :param i: loop index\n        :param alive_log_probs: probabilities of the beams.\n            [batch_size, beam_size]\n        :param finished_scores: scores for each of these sequences.\n            [batch_size, beam_size]\n        :param finished_in_finished: finished bools for each of these\n            sequences. [batch_size, beam_size]\n\n        :returns: Bool.\n        \"\"\"", "\n", "max_length_penalty", "=", "tf", ".", "pow", "(", "(", "(", "5.", "+", "tf", ".", "to_float", "(", "decode_length", ")", ")", "/", "6.", ")", ",", "\n", "alpha", ")", "\n", "# The best possible score of the most likley alive sequence", "\n", "lower_bound_alive_scores", "=", "alive_log_probs", "[", ":", ",", "0", "]", "/", "max_length_penalty", "\n", "\n", "# Now to compute the lowest score of a finished sequence in finished", "\n", "# If the sequence isn't finished, we multiply it's score by 0. since", "\n", "# scores are all -ve, taking the min will give us the score of the", "\n", "# lowest finished item.", "\n", "lowest_score_of_finished_in_finished", "=", "tf", ".", "reduce_min", "(", "\n", "finished_scores", "*", "tf", ".", "to_float", "(", "finished_in_finished", ")", ",", "axis", "=", "1", "\n", ")", "\n", "# If none of the sequences have finished, then the min will be 0 and", "\n", "# we have to replace it by -ve INF if it is. The score of any seq in", "\n", "# alive will be much higher than -ve INF and the termination condition", "\n", "# will not be met.", "\n", "lowest_score_of_finished_in_finished", "+=", "(", "\n", "(", "1.", "-", "tf", ".", "to_float", "(", "tf", ".", "reduce_any", "(", "finished_in_finished", ",", "1", ")", ")", ")", "*", "-", "INF", "\n", ")", "\n", "\n", "bound_is_met", "=", "tf", ".", "reduce_all", "(", "\n", "tf", ".", "greater", "(", "lowest_score_of_finished_in_finished", ",", "\n", "lower_bound_alive_scores", ")", "\n", ")", "\n", "\n", "return", "tf", ".", "logical_and", "(", "tf", ".", "less", "(", "i", ",", "decode_length", ")", ",", "\n", "tf", ".", "logical_not", "(", "bound_is_met", ")", ")", "\n", "\n", "", "(", "_", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "finished_scores", ",", "\n", "finished_flags", ")", "=", "tf", ".", "while_loop", "(", "\n", "_is_finished", ",", "\n", "inner_loop", ",", "[", "\n", "tf", ".", "constant", "(", "0", ")", ",", "alive_seq", ",", "alive_log_probs", ",", "finished_seq", ",", "\n", "finished_scores", ",", "finished_flags", "\n", "]", ",", "\n", "shape_invariants", "=", "[", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "alive_log_probs", ".", "get_shape", "(", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", ",", "None", "]", ")", ",", "\n", "finished_scores", ".", "get_shape", "(", ")", ",", "\n", "finished_flags", ".", "get_shape", "(", ")", "\n", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", "\n", ")", "\n", "\n", "alive_seq", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "finished_seq", ".", "set_shape", "(", "(", "None", ",", "beam_size", ",", "None", ")", ")", "\n", "\n", "# Accounting for corner case: It's possible that no sequence in alive for", "\n", "# a particular batch item ever reached <eos>. In that case, we should just", "\n", "# copy the contents of alive for that batch item.", "\n", "# tf.reduce_any(finished_flags, 1) if 0, means that no sequence for that", "\n", "# batch index had reached EOS. We need to do the same for the scores as", "\n", "# well.", "\n", "finished_seq", "=", "tf", ".", "where", "(", "\n", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ",", "finished_seq", ",", "alive_seq", ")", "\n", "finished_scores", "=", "tf", ".", "where", "(", "\n", "tf", ".", "reduce_any", "(", "finished_flags", ",", "1", ")", ",", "finished_scores", ",", "alive_log_probs", ")", "\n", "return", "finished_seq", ",", "finished_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.create_inference_graph": [[430, 506], ["tensorflow.fill", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "len", "search.beam_search", "isinstance", "tensorflow.pad", "tensorflow.fill", "enumerate", "tensorflow.shape", "tensorflow.constant", "results.append", "tensorflow.shape", "tensorflow.shape", "model_fn", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.search.beam_search"], ["", "def", "create_inference_graph", "(", "model_fns", ",", "features", ",", "params", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "model_fns", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "model_fns", "=", "[", "model_fns", "]", "\n", "\n", "", "decode_length", "=", "params", ".", "decode_length", "\n", "beam_size", "=", "params", ".", "beam_size", "\n", "top_beams", "=", "params", ".", "top_beams", "\n", "alpha", "=", "params", ".", "decode_alpha", "\n", "\n", "# [batch, decoded_ids] => [batch, vocab_size]", "\n", "def", "symbols_to_logits_fn", "(", "decoded_ids", ")", ":", "\n", "        ", "features", "[", "\"target\"", "]", "=", "tf", ".", "pad", "(", "decoded_ids", "[", ":", ",", "1", ":", "]", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "for", "i", ",", "model_fn", "in", "enumerate", "(", "model_fns", ")", ":", "\n", "            ", "results", ".", "append", "(", "model_fn", "(", "features", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "# Prepend <bos> symbol", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "initial_ids", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "tf", ".", "constant", "(", "bos_id", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "\n", "inputs_old", "=", "features", "[", "\"source\"", "]", "\n", "inputs_length_old", "=", "features", "[", "\"source_length\"", "]", "\n", "\n", "# Expand the inputs in to the beam size", "\n", "# [batch, length] => [batch, beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source\"", "]", ",", "1", ")", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "# For source sequence length", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "1", ",", "beam_size", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "# [batch, beam_size, length] => [batch * beam_size, length]", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "# Setting decode length to input length + decode_length", "\n", "decode_length", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", "+", "decode_length", "\n", "\n", "ids", ",", "scores", "=", "beam_search", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "\n", "beam_size", ",", "decode_length", ",", "vocab_size", ",", "\n", "alpha", ",", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", ",", "\n", "lp_constant", "=", "params", ".", "decode_constant", ")", "\n", "\n", "# Set inputs back to the unexpanded inputs to not to confuse the Estimator", "\n", "features", "[", "\"source\"", "]", "=", "inputs_old", "\n", "features", "[", "\"source_length\"", "]", "=", "inputs_length_old", "\n", "\n", "# Return `top_beams` decoding", "\n", "# (also remove initial id from the beam search)", "\n", "if", "not", "params", ".", "decode_normalize", ":", "\n", "        ", "if", "top_beams", "==", "1", ":", "\n", "            ", "return", "ids", "[", ":", ",", "0", ",", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "return", "ids", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", "\n", "", "", "else", ":", "\n", "        ", "if", "top_beams", "==", "1", ":", "\n", "            ", "return", "ids", "[", ":", ",", "0", ",", "1", ":", "]", ",", "scores", "[", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "ids", "[", ":", ",", ":", "top_beams", ",", "1", ":", "]", ",", "scores", "[", ":", ",", ":", "top_beams", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.get_mrt_features": [[15, 59], ["mrt_utils.create_sampling_graph", "tensorflow.shape", "tensorflow.to_int32", "tensorflow.concat", "tensorflow.zeros", "tensorflow.concat", "tensorflow.concat", "tensorflow.py_func", "features[].set_shape", "tensorflow.shape", "mrt_utils.get_len", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.tile", "tensorflow.tile", "tensorflow.map_fn", "features[].set_shape", "model.get_inference_func", "tensorflow.ones", "mrt_utils.bleu_tensor", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.create_sampling_graph", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.get_len", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_inference_func", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.bleu_tensor"], ["def", "get_mrt_features", "(", "features", ",", "params", ",", "model", ")", ":", "\n", "# Generate samples", "\n", "    ", "samples", "=", "create_sampling_graph", "(", "model", ".", "get_inference_func", "(", ")", ",", "features", ",", "\n", "params", ",", "training", "=", "True", ")", "\n", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", "\n", "features", "[", "\"samples\"", "]", "=", "samples", "\n", "# Delete bos & add eos", "\n", "features", "[", "\"samples\"", "]", "=", "features", "[", "\"samples\"", "]", "[", ":", ",", "1", ":", "]", "\n", "sample_shape", "=", "tf", ".", "shape", "(", "features", "[", "\"samples\"", "]", ")", "\n", "eos_seq", "=", "tf", ".", "ones", "(", "[", "sample_shape", "[", "0", "]", ",", "1", "]", ")", "*", "eos_id", "\n", "eos_seq", "=", "tf", ".", "to_int32", "(", "eos_seq", ")", "\n", "features", "[", "\"samples\"", "]", "=", "tf", ".", "concat", "(", "[", "features", "[", "\"samples\"", "]", ",", "eos_seq", "]", ",", "1", ")", "\n", "\n", "# Add the gold reference", "\n", "pad_num", "=", "(", "tf", ".", "shape", "(", "features", "[", "\"samples\"", "]", ")", "[", "1", "]", "-", "\n", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "\n", "padding", "=", "tf", ".", "zeros", "(", "(", "1", ",", "pad_num", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "target_pad", "=", "tf", ".", "concat", "(", "[", "features", "[", "\"target\"", "]", ",", "padding", "]", ",", "axis", "=", "1", ")", "\n", "features", "[", "\"samples\"", "]", "=", "tf", ".", "concat", "(", "[", "features", "[", "\"samples\"", "]", ",", "target_pad", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Delete repetition", "\n", "features", "[", "\"samples\"", "]", "=", "tf", ".", "py_func", "(", "get_unique", ",", "[", "features", "[", "\"samples\"", "]", ",", "eos_id", "]", ",", "\n", "tf", ".", "int32", ")", "\n", "features", "[", "\"samples\"", "]", ".", "set_shape", "(", "[", "None", ",", "None", "]", ")", "\n", "sample_shape", "=", "tf", ".", "shape", "(", "features", "[", "\"samples\"", "]", ")", "\n", "# Get sentence length", "\n", "features", "[", "\"sample_length\"", "]", "=", "get_len", "(", "features", "[", "\"samples\"", "]", ",", "eos_id", ")", "\n", "# Transform to int32", "\n", "features", "[", "\"samples\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"samples\"", "]", ")", "\n", "features", "[", "\"sample_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"sample_length\"", "]", ")", "\n", "# Repeat source sentences", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "sample_shape", "[", "0", "]", ",", "1", "]", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "sample_shape", "[", "0", "]", "]", ")", "\n", "# Calculate BLEU", "\n", "bleu_fn", "=", "lambda", "x", ":", "bleu_tensor", "(", "x", ",", "features", "[", "\"target\"", "]", ",", "eos_id", ")", "\n", "features", "[", "\"BLEU\"", "]", "=", "tf", ".", "map_fn", "(", "bleu_fn", ",", "features", "[", "\"samples\"", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "features", "[", "\"BLEU\"", "]", ".", "set_shape", "(", "(", "None", ",", ")", ")", "\n", "# Set target", "\n", "features", "[", "\"target\"", "]", "=", "features", "[", "\"samples\"", "]", "\n", "features", "[", "\"target_length\"", "]", "=", "features", "[", "\"sample_length\"", "]", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.cut_sen": [[61, 67], ["sen.index"], "function", ["None"], ["", "def", "cut_sen", "(", "sen", ",", "eos", ")", ":", "\n", "    ", "if", "not", "eos", "in", "sen", ":", "\n", "        ", "return", "sen", "\n", "", "else", ":", "\n", "        ", "pos_eos", "=", "sen", ".", "index", "(", "eos", ")", "\n", "return", "sen", "[", ":", "pos_eos", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.get_unique": [[69, 83], ["sens.tolist.tolist", "numpy.asarray", "mrt_utils.cut_sen", "numpy.asarray.append", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.cut_sen"], ["", "", "def", "get_unique", "(", "sens", ",", "eos", ")", ":", "\n", "    ", "sens", "=", "sens", ".", "tolist", "(", ")", "\n", "result", "=", "[", "]", "\n", "maxlen", "=", "-", "1", "\n", "# remove repetition", "\n", "for", "sen", "in", "sens", ":", "\n", "        ", "tmp", "=", "cut_sen", "(", "sen", ",", "eos", ")", "\n", "if", "tmp", "not", "in", "result", ":", "\n", "            ", "result", ".", "append", "(", "tmp", ")", "\n", "if", "len", "(", "tmp", ")", ">", "maxlen", ":", "\n", "                ", "maxlen", "=", "len", "(", "tmp", ")", "\n", "", "", "", "result", "=", "[", "sen", "+", "[", "eos", "]", "*", "(", "maxlen", "-", "len", "(", "sen", ")", ")", "for", "sen", "in", "result", "]", "\n", "result", "=", "numpy", ".", "asarray", "(", "result", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.get_len": [[85, 89], ["tensorflow.where", "tensorflow.segment_min", "tensorflow.equal"], "function", ["None"], ["", "def", "get_len", "(", "sen", ",", "eos", ")", ":", "\n", "    ", "indices", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "sen", ",", "eos", ")", ")", "\n", "result", "=", "tf", ".", "segment_min", "(", "indices", "[", ":", ",", "1", "]", ",", "indices", "[", ":", ",", "0", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.log_prob_from_logits": [[91, 93], ["tensorflow.reduce_logsumexp"], "function", ["None"], ["", "def", "log_prob_from_logits", "(", "logits", ")", ":", "\n", "    ", "return", "logits", "-", "tf", ".", "reduce_logsumexp", "(", "logits", ",", "axis", "=", "2", ",", "keep_dims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.sampler": [[95, 130], ["tensorflow.constant", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.reshape", "tensorflow.while_loop", "tf.concat.set_shape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.multinomial", "tensorflow.to_int32", "tensorflow.concat", "mrt_utils.create_sampling_graph.symbols_to_logits_fn", "tensorflow.TensorShape", "tensorflow.TensorShape"], "function", ["None"], ["", "def", "sampler", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "sample_num", ",", "decode_length", ",", "\n", "vocab_size", ",", "eos_id", ",", "features", "=", "None", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "initial_ids", ")", "[", "0", "]", "\n", "\n", "# Expand each batch to sample_num", "\n", "seqlen", "=", "tf", ".", "constant", "(", "0", ")", "\n", "alive_seq", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_ids", ",", "1", ")", ",", "[", "1", ",", "sample_num", "]", ")", "\n", "alive_seq", "=", "tf", ".", "expand_dims", "(", "alive_seq", ",", "2", ")", "# (batch_size, sample_num, 1)", "\n", "sa", "=", "tf", ".", "shape", "(", "alive_seq", ")", "\n", "alive_seq", "=", "tf", ".", "reshape", "(", "alive_seq", ",", "[", "sa", "[", "0", "]", "*", "sa", "[", "1", "]", ",", "1", "]", ")", "\n", "\n", "def", "_is_finished", "(", "i", ",", "alive_seq", ")", ":", "\n", "        ", "return", "i", "<", "decode_length", "\n", "\n", "", "def", "inner_loop", "(", "i", ",", "alive_seq", ")", ":", "\n", "        ", "logit", "=", "symbols_to_logits_fn", "(", "alive_seq", ")", "[", "0", "]", "\n", "new_samples", "=", "tf", ".", "multinomial", "(", "logit", ",", "1", ")", "\n", "new_samples", "=", "tf", ".", "to_int32", "(", "new_samples", ")", "\n", "alive_seq", "=", "tf", ".", "concat", "(", "[", "alive_seq", ",", "new_samples", "]", ",", "1", ")", "\n", "return", "(", "i", "+", "1", ",", "alive_seq", ")", "\n", "\n", "", "(", "_", ",", "alive_seq", ")", "=", "tf", ".", "while_loop", "(", "\n", "_is_finished", ",", "\n", "inner_loop", ",", "\n", "[", "seqlen", ",", "alive_seq", "]", ",", "\n", "shape_invariants", "=", "[", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "tf", ".", "TensorShape", "(", "[", "None", ",", "None", "]", ")", "\n", "]", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", "\n", ")", "\n", "alive_seq", ".", "set_shape", "(", "(", "sample_num", ",", "None", ")", ")", "\n", "\n", "return", "alive_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.create_sampling_graph": [[132, 211], ["isinstance", "tensorflow.fill", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.shape", "tensorflow.reshape", "len", "tensorflow.to_int32", "mrt_utils.sampler", "isinstance", "tensorflow.pad", "tensorflow.fill", "enumerate", "tensorflow.shape", "tensorflow.constant", "tensorflow.to_float", "tensorflow.constant", "results.append", "tensorflow.shape", "model_fn", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.sampler"], ["", "def", "create_sampling_graph", "(", "model_fns", ",", "features", ",", "params", ",", "training", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "params", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "params_list", "=", "params", "\n", "params", "=", "params_list", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "params_list", "=", "[", "params", "]", "\n", "\n", "", "if", "not", "isinstance", "(", "model_fns", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "model_fns", "=", "[", "model_fns", "]", "\n", "\n", "", "decode_length", "=", "params", ".", "decode_length", "\n", "sample_num", "=", "params", ".", "mrt_sample", "\n", "top_beams", "=", "params", ".", "top_beams", "\n", "\n", "# [batch, decoded_ids] => [batch, vocab_size]", "\n", "def", "symbols_to_logits_fn", "(", "decoded_ids", ")", ":", "\n", "        ", "features", "[", "\"target\"", "]", "=", "tf", ".", "pad", "(", "decoded_ids", "[", ":", ",", "1", ":", "]", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "fill", "(", "[", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "0", "]", "]", ",", "\n", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "for", "i", ",", "model_fn", "in", "enumerate", "(", "model_fns", ")", ":", "\n", "            ", "results", ".", "append", "(", "model_fn", "(", "features", ",", "params_list", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "0", "]", "\n", "# append <bos> symbol", "\n", "bos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "bos", "]", "\n", "initial_ids", "=", "tf", ".", "fill", "(", "[", "batch_size", "]", ",", "tf", ".", "constant", "(", "bos_id", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "\n", "inputs_old", "=", "features", "[", "\"source\"", "]", "\n", "inputs_length_old", "=", "features", "[", "\"source_length\"", "]", "\n", "if", "training", ":", "\n", "        ", "outputs_old", "=", "features", "[", "\"target\"", "]", "\n", "outputs_length_old", "=", "features", "[", "\"target_length\"", "]", "\n", "\n", "#return", "\n", "# Expand the inputs in to the number of samples", "\n", "# [batch, length] => [batch, sample_num, length]", "\n", "", "features", "[", "\"source\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source\"", "]", ",", "1", ")", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source\"", "]", ",", "[", "1", ",", "sample_num", ",", "1", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "# [batch, sample_num, length] => [batch * sample_num, length]", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", "\n", "\n", "#return", "\n", "# For source sequence length", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "expand_dims", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "tile", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "1", ",", "sample_num", "]", ")", "\n", "shape", "=", "tf", ".", "shape", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "# [batch, sample_num, length] => [batch * sample_num, length]", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "reshape", "(", "features", "[", "\"source_length\"", "]", ",", "\n", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", ")", "\n", "\n", "vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "# Setting decode length to input length + decode_length", "\n", "decode_length", "=", "tf", ".", "to_float", "(", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ")", "*", "tf", ".", "constant", "(", "params", ".", "mrt_length_ratio", ")", "\n", "decode_length", "=", "tf", ".", "to_int32", "(", "decode_length", ")", "\n", "\n", "ids", "=", "sampler", "(", "symbols_to_logits_fn", ",", "initial_ids", ",", "params", ".", "mrt_sample", ",", "\n", "decode_length", ",", "vocab_size", ",", "\n", "eos_id", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "eos", "]", ",", "\n", "features", "=", "features", ")", "\n", "\n", "# Set inputs back to the unexpanded inputs to not to confuse the Estimator", "\n", "features", "[", "\"source\"", "]", "=", "inputs_old", "\n", "features", "[", "\"source_length\"", "]", "=", "inputs_length_old", "\n", "if", "training", ":", "\n", "        ", "features", "[", "\"target\"", "]", "=", "outputs_old", "\n", "features", "[", "\"target_length\"", "]", "=", "outputs_length_old", "\n", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.mrt_loss": [[213, 223], ["tensorflow.reduce_sum", "tensorflow.reduce_min", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "mrt_loss", "(", "features", ",", "params", ",", "ce", ",", "tgt_mask", ")", ":", "\n", "    ", "logprobs", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ",", "axis", "=", "1", ")", "\n", "logprobs", "*=", "params", ".", "mrt_alpha", "\n", "logprobs", "-=", "tf", ".", "reduce_min", "(", "logprobs", ")", "\n", "probs", "=", "tf", ".", "exp", "(", "-", "logprobs", ")", "\n", "probs", "/=", "tf", ".", "reduce_sum", "(", "probs", ")", "\n", "ave_bleu", "=", "probs", "*", "features", "[", "\"BLEU\"", "]", "\n", "loss", "=", "-", "tf", ".", "reduce_sum", "(", "ave_bleu", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.bleu_tensor": [[225, 228], ["tensorflow.py_func", "mrt_utils.bleu_numpy"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.bleu_numpy"], ["", "def", "bleu_tensor", "(", "trans", ",", "ref", ",", "eos", ")", ":", "\n", "    ", "return", "tf", ".", "py_func", "(", "lambda", "x", ",", "y", ":", "bleu_numpy", "(", "x", ",", "y", ",", "eos", ",", "smooth", "=", "True", ")", ",", "\n", "[", "trans", ",", "ref", "]", ",", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.bleu_numpy": [[230, 275], ["cut_sen.tolist", "cut_sen.tolist", "mrt_utils.cut_sen", "mrt_utils.cut_sen", "zip", "range", "thumt.brevity_penalty", "numpy.float32", "range", "sum", "math.exp", "range", "range", "thumt.modified_precision", "range", "math.log", "len", "ValueError", "sum", "float", "float", "float", "range"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.cut_sen", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.mrt_utils.cut_sen", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.brevity_penalty", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.bleu.modified_precision"], ["", "def", "bleu_numpy", "(", "trans", ",", "refs", ",", "eos", ",", "bp", "=", "\"closest\"", ",", "smooth", "=", "False", ",", "n", "=", "4", ",", "\n", "weights", "=", "None", ")", ":", "\n", "    ", "trans", "=", "trans", ".", "tolist", "(", ")", "\n", "refs", "=", "refs", ".", "tolist", "(", ")", "\n", "# cut sentence", "\n", "trans", "=", "cut_sen", "(", "trans", ",", "eos", ")", "\n", "refs", "=", "cut_sen", "(", "refs", ",", "eos", ")", "\n", "# wrap", "\n", "trans", "=", "[", "trans", "]", "\n", "refs", "=", "[", "refs", "]", "\n", "p_norm", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "p_denorm", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "for", "candidate", ",", "references", "in", "zip", "(", "trans", ",", "refs", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "ccount", ",", "tcount", "=", "bleu", ".", "modified_precision", "(", "candidate", ",", "references", ",", "\n", "i", "+", "1", ")", "\n", "p_norm", "[", "i", "]", "+=", "ccount", "\n", "p_denorm", "[", "i", "]", "+=", "tcount", "\n", "\n", "", "", "bleu_n", "=", "[", "0", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "# add one smoothing", "\n", "        ", "if", "smooth", "and", "i", ">", "0", ":", "\n", "            ", "p_norm", "[", "i", "]", "+=", "1", "\n", "p_denorm", "[", "i", "]", "+=", "1", "\n", "\n", "", "if", "p_norm", "[", "i", "]", "==", "0", "or", "p_denorm", "[", "i", "]", "==", "0", ":", "\n", "            ", "bleu_n", "[", "i", "]", "=", "-", "9999", "\n", "", "else", ":", "\n", "            ", "bleu_n", "[", "i", "]", "=", "math", ".", "log", "(", "float", "(", "p_norm", "[", "i", "]", ")", "/", "float", "(", "p_denorm", "[", "i", "]", ")", ")", "\n", "\n", "", "", "if", "weights", ":", "\n", "        ", "if", "len", "(", "weights", ")", "!=", "n", ":", "\n", "            ", "raise", "ValueError", "(", "\"len(weights) != n: invalid weight number\"", ")", "\n", "", "log_precision", "=", "sum", "(", "[", "bleu_n", "[", "i", "]", "*", "weights", "[", "i", "]", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "log_precision", "=", "sum", "(", "bleu_n", ")", "/", "float", "(", "n", ")", "\n", "\n", "", "bp", "=", "bleu", ".", "brevity_penalty", "(", "trans", ",", "refs", ",", "bp", ")", "\n", "\n", "score", "=", "bp", "*", "math", ".", "exp", "(", "log_precision", ")", "\n", "\n", "return", "numpy", ".", "float32", "(", "score", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.session_run": [[11, 14], ["monitored_session._tf_sess().run", "monitored_session._tf_sess"], "function", ["None"], ["def", "session_run", "(", "monitored_session", ",", "args", ")", ":", "\n", "# Call raw TF session directly", "\n", "    ", "return", "monitored_session", ".", "_tf_sess", "(", ")", ".", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.zero_variables": [[16, 25], ["tensorflow.group", "ops.append", "tensorflow.device", "var.assign", "tensorflow.zeros", "var.shape.as_list"], "function", ["None"], ["", "def", "zero_variables", "(", "variables", ",", "name", "=", "None", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "\n", "for", "var", "in", "variables", ":", "\n", "        ", "with", "tf", ".", "device", "(", "var", ".", "device", ")", ":", "\n", "            ", "op", "=", "var", ".", "assign", "(", "tf", ".", "zeros", "(", "var", ".", "shape", ".", "as_list", "(", ")", ")", ")", "\n", "", "ops", ".", "append", "(", "op", ")", "\n", "\n", "", "return", "tf", ".", "group", "(", "*", "ops", ",", "name", "=", "name", "or", "\"zero_op\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.replicate_variables": [[27, 38], ["tensorflow.device", "new_vars.append", "tensorflow.Variable", "var.name.split", "tensorflow.zeros", "var.shape.as_list"], "function", ["None"], ["", "def", "replicate_variables", "(", "variables", ",", "device", "=", "None", ")", ":", "\n", "    ", "new_vars", "=", "[", "]", "\n", "\n", "for", "var", "in", "variables", ":", "\n", "        ", "device", "=", "device", "or", "var", ".", "device", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "            ", "name", "=", "\"replicate/\"", "+", "var", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "\n", "new_vars", ".", "append", "(", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "var", ".", "shape", ".", "as_list", "(", ")", ")", ",", "\n", "name", "=", "name", ",", "trainable", "=", "False", ")", ")", "\n", "\n", "", "", "return", "new_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.collect_gradients": [[40, 50], ["zip", "tensorflow.group", "isinstance", "ops.append", "ops.append", "tensorflow.assign_add", "tensorflow.scatter_add"], "function", ["None"], ["", "def", "collect_gradients", "(", "gradients", ",", "variables", ")", ":", "\n", "    ", "ops", "=", "[", "]", "\n", "\n", "for", "grad", ",", "var", "in", "zip", "(", "gradients", ",", "variables", ")", ":", "\n", "        ", "if", "isinstance", "(", "grad", ",", "tf", ".", "Tensor", ")", ":", "\n", "            ", "ops", ".", "append", "(", "tf", ".", "assign_add", "(", "var", ",", "grad", ")", ")", "\n", "", "else", ":", "\n", "            ", "ops", ".", "append", "(", "tf", ".", "scatter_add", "(", "var", ",", "grad", ".", "indices", ",", "grad", ".", "values", ")", ")", "\n", "\n", "", "", "return", "tf", ".", "group", "(", "*", "ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.utils.utils.scale_gradients": [[52, 63], ["tuple", "isinstance", "tensorflow.IndexedSlices", "scaled_gradients.append", "scaled_gradients.append"], "function", ["None"], ["", "def", "scale_gradients", "(", "gradients", ",", "scale", ")", ":", "\n", "    ", "scaled_gradients", "=", "[", "]", "\n", "\n", "for", "grad", "in", "gradients", ":", "\n", "        ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "            ", "slices", "=", "tf", ".", "IndexedSlices", "(", "scale", "*", "grad", ".", "values", ",", "grad", ".", "indices", ")", "\n", "scaled_gradients", ".", "append", "(", "slices", ")", "\n", "", "else", ":", "\n", "            ", "scaled_gradients", ".", "append", "(", "scale", "*", "grad", ")", "\n", "\n", "", "", "return", "tuple", "(", "scaled_gradients", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.interface.model.NMTModel.__init__": [[11, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", ")", ":", "\n", "        ", "self", ".", "_scope", "=", "scope", "\n", "self", ".", "_params", "=", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.interface.model.NMTModel.get_training_func": [[15, 17], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.interface.model.NMTModel.get_evaluation_func": [[18, 20], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.interface.model.NMTModel.get_inference_func": [[21, 23], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.interface.model.NMTModel.get_name": [[24, 27], ["NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.interface.model.NMTModel.get_parameters": [[28, 31], ["NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.interface.model.NMTModel.parameters": [[32, 35], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.LegacyGRUCell.__init__": [[22, 25], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.__init__"], ["def", "__init__", "(", "self", ",", "num_units", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "super", "(", "LegacyGRUCell", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "self", ".", "_num_units", "=", "num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.LegacyGRUCell.__call__": [[26, 44], ["tensorflow.variable_scope", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "nn.linear", "isinstance", "list", "nn.linear", "nn.linear", "list", "tensorflow.tanh"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"gru_cell\"", ",", "\n", "values", "=", "[", "inputs", ",", "state", "]", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "all_inputs", "=", "list", "(", "inputs", ")", "+", "[", "state", "]", "\n", "r", "=", "tf", ".", "nn", ".", "sigmoid", "(", "linear", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "False", ",", "False", ",", "\n", "scope", "=", "\"reset_gate\"", ")", ")", "\n", "u", "=", "tf", ".", "nn", ".", "sigmoid", "(", "linear", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "False", ",", "False", ",", "\n", "scope", "=", "\"update_gate\"", ")", ")", "\n", "all_inputs", "=", "list", "(", "inputs", ")", "+", "[", "r", "*", "state", "]", "\n", "c", "=", "linear", "(", "all_inputs", ",", "self", ".", "_num_units", ",", "True", ",", "False", ",", "\n", "scope", "=", "\"candidate\"", ")", "\n", "\n", "new_state", "=", "(", "1.0", "-", "u", ")", "*", "state", "+", "u", "*", "tf", ".", "tanh", "(", "c", ")", "\n", "\n", "", "return", "new_state", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.LegacyGRUCell.state_size": [[45, 48], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.LegacyGRUCell.output_size": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.StateToOutputWrapper.__init__": [[64, 67], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.__init__"], ["def", "__init__", "(", "self", ",", "cell", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "super", "(", "StateToOutputWrapper", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "self", ".", "_cell", "=", "cell", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.StateToOutputWrapper.__call__": [[68, 72], ["rnn_cell.StateToOutputWrapper._cell"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "output", ",", "new_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ",", "scope", "=", "scope", ")", "\n", "\n", "return", "(", "output", ",", "new_state", ")", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.StateToOutputWrapper.state_size": [[73, 76], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.StateToOutputWrapper.output_size": [[77, 80], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "tuple", "(", "[", "self", ".", "_cell", ".", "output_size", ",", "self", ".", "state_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.AttentionWrapper.__init__": [[97, 107], ["super().__init__", "memory.shape.assert_has_rank"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.__init__"], ["def", "__init__", "(", "self", ",", "cell", ",", "memory", ",", "bias", ",", "attention_fn", ",", "output_weight", "=", "False", ",", "\n", "output_value", "=", "False", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "super", "(", "AttentionWrapper", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "memory", ".", "shape", ".", "assert_has_rank", "(", "3", ")", "\n", "self", ".", "_cell", "=", "cell", "\n", "self", ".", "_memory", "=", "memory", "\n", "self", ".", "_bias", "=", "bias", "\n", "self", ".", "_attention_fn", "=", "attention_fn", "\n", "self", ".", "_output_weight", "=", "output_weight", "\n", "self", ".", "_output_value", "=", "output_value", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.AttentionWrapper.__call__": [[108, 126], ["rnn_cell.AttentionWrapper._attention_fn", "rnn_cell.AttentionWrapper._cell", "new_output.append", "new_output.append", "tuple"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_attention_fn", "(", "inputs", ",", "state", ",", "self", ".", "_memory", ",", "self", ".", "_bias", ")", "\n", "cell_inputs", ",", "cell_state", ",", "weight", ",", "value", "=", "outputs", "\n", "cell_output", ",", "new_state", "=", "self", ".", "_cell", "(", "cell_inputs", ",", "cell_state", ",", "\n", "scope", "=", "scope", ")", "\n", "\n", "if", "not", "self", ".", "_output_weight", "and", "not", "self", ".", "_output_value", ":", "\n", "            ", "return", "cell_output", ",", "new_state", "\n", "\n", "", "new_output", "=", "[", "cell_output", "]", "\n", "\n", "if", "self", ".", "_output_weight", ":", "\n", "            ", "new_output", ".", "append", "(", "weights", ")", "\n", "\n", "", "if", "self", ".", "_output_value", ":", "\n", "            ", "new_output", ".", "append", "(", "value", ")", "\n", "\n", "", "return", "tuple", "(", "new_output", ")", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.AttentionWrapper.state_size": [[127, 130], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.rnn_cell.AttentionWrapper.output_size": [[131, 145], ["tuple", "new_output_size.append", "new_output_size.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "_output_weight", "and", "not", "self", ".", "_output_value", ":", "\n", "            ", "return", "self", ".", "_cell", ".", "output_size", "\n", "\n", "", "new_output_size", "=", "[", "self", ".", "_cell", ".", "output_size", "]", "\n", "\n", "if", "self", ".", "_output_weight", ":", "\n", "            ", "new_output_size", ".", "append", "(", "self", ".", "_memory", ".", "shape", "[", "1", "]", ")", "\n", "\n", "", "if", "self", ".", "_output_value", ":", "\n", "            ", "new_output_size", ".", "append", "(", "self", ".", "_memory", ".", "shape", "[", "2", "]", ".", "value", ")", "\n", "\n", "", "return", "tuple", "(", "new_output_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.add_timing_signal": [[14, 48], ["tensorflow.name_scope", "tensorflow.to_float", "tensorflow.concat", "tensorflow.pad", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape", "tensorflow.range", "math.log", "tensorflow.exp", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.sin", "tensorflow.cos", "float", "float", "tensorflow.to_float", "tensorflow.mod", "tensorflow.range"], "function", ["None"], ["def", "add_timing_signal", "(", "x", ",", "min_timescale", "=", "1.0", ",", "max_timescale", "=", "1.0e4", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function adds a bunch of sinusoids of different frequencies to a\n    Tensor. See paper: Attention is all you need\n\n    :param x: A tensor with shape [batch, length, channels]\n    :param min_timescale: A floating point number\n    :param max_timescale: A floating point number\n    :param name: An optional string\n\n    :returns: a Tensor the same shape as x.\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"add_timing_signal\"", ",", "values", "=", "[", "x", "]", ")", ":", "\n", "        ", "length", "=", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "\n", "channels", "=", "tf", ".", "shape", "(", "x", ")", "[", "2", "]", "\n", "position", "=", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "length", ")", ")", "\n", "num_timescales", "=", "channels", "//", "2", "\n", "\n", "log_timescale_increment", "=", "(", "\n", "math", ".", "log", "(", "float", "(", "max_timescale", ")", "/", "float", "(", "min_timescale", ")", ")", "/", "\n", "(", "tf", ".", "to_float", "(", "num_timescales", ")", "-", "1", ")", "\n", ")", "\n", "inv_timescales", "=", "min_timescale", "*", "tf", ".", "exp", "(", "\n", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "num_timescales", ")", ")", "*", "-", "log_timescale_increment", "\n", ")", "\n", "\n", "scaled_time", "=", "(", "tf", ".", "expand_dims", "(", "position", ",", "1", ")", "*", "\n", "tf", ".", "expand_dims", "(", "inv_timescales", ",", "0", ")", ")", "\n", "signal", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "scaled_time", ")", ",", "tf", ".", "cos", "(", "scaled_time", ")", "]", ",", "axis", "=", "1", ")", "\n", "signal", "=", "tf", ".", "pad", "(", "signal", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "tf", ".", "mod", "(", "channels", ",", "2", ")", "]", "]", ")", "\n", "signal", "=", "tf", ".", "reshape", "(", "signal", ",", "[", "1", ",", "length", ",", "channels", "]", ")", "\n", "\n", "return", "x", "+", "signal", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.split_heads": [[50, 68], ["tensorflow.name_scope", "tensorflow.reshape", "tf.reshape.set_shape", "tensorflow.transpose", "x.get_shape", "tensorflow.concat", "tensorflow.shape"], "function", ["None"], ["", "", "def", "split_heads", "(", "inputs", ",", "num_heads", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Split heads\n    :param inputs: A tensor with shape [batch, length, channels]\n    :param num_heads: An integer\n    :param name: An optional string\n    :returns: A tensor with shape [batch, heads, length, channels / heads]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"split_heads\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "n", "=", "num_heads", "\n", "old_shape", "=", "x", ".", "get_shape", "(", ")", ".", "dims", "\n", "\n", "last", "=", "old_shape", "[", "-", "1", "]", "\n", "new_shape", "=", "old_shape", "[", ":", "-", "1", "]", "+", "[", "n", "]", "+", "[", "last", "//", "n", "if", "last", "else", "None", "]", "\n", "ret", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", ":", "-", "1", "]", ",", "[", "n", ",", "-", "1", "]", "]", ",", "0", ")", ")", "\n", "ret", ".", "set_shape", "(", "new_shape", ")", "\n", "return", "tf", ".", "transpose", "(", "ret", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.combine_heads": [[70, 87], ["tensorflow.name_scope", "tensorflow.transpose", "tensorflow.reshape", "tf.reshape.set_shape", "tf.reshape.get_shape", "tensorflow.concat", "tensorflow.shape"], "function", ["None"], ["", "", "def", "combine_heads", "(", "inputs", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Combine heads\n    :param inputs: A tensor with shape [batch, heads, length, channels]\n    :param name: An optional string\n    :returns: A tensor with shape [batch, length, heads * channels]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"combine_heads\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "old_shape", "=", "x", ".", "get_shape", "(", ")", ".", "dims", "\n", "a", ",", "b", "=", "old_shape", "[", "-", "2", ":", "]", "\n", "new_shape", "=", "old_shape", "[", ":", "-", "2", "]", "+", "[", "a", "*", "b", "if", "a", "and", "b", "else", "None", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", ":", "-", "2", "]", ",", "[", "-", "1", "]", "]", ",", "0", ")", ")", "\n", "x", ".", "set_shape", "(", "new_shape", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.attention_bias": [[89, 139], ["tensorflow.name_scope", "tensorflow.matrix_band_part", "tensorflow.reshape", "tensorflow.ones", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.eye", "tensorflow.expand_dims", "tensorflow.nn.softmax", "tensorflow.shape", "tensorflow.cumsum", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.where", "tensorflow.cast", "tensorflow.matrix_band_part", "tensorflow.reshape", "ValueError", "tensorflow.ones", "tensorflow.matrix_band_part", "tensorflow.log", "tensorflow.ones", "tensorflow.abs"], "function", ["None"], ["", "", "def", "attention_bias", "(", "inputs", ",", "mode", ",", "inf", "=", "-", "1e9", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" A bias tensor used in attention mechanism\n    :param inputs:\n    :param mode:\n    :param inf:\n    :param name:\n    :returns:\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"attention_bias\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "if", "mode", "==", "\"causal\"", ":", "\n", "            ", "length", "=", "inputs", "\n", "lower_triangle", "=", "tf", ".", "matrix_band_part", "(", "\n", "tf", ".", "ones", "(", "[", "length", ",", "length", "]", ")", ",", "-", "1", ",", "0", "\n", ")", "\n", "ret", "=", "inf", "*", "(", "1.0", "-", "lower_triangle", ")", "\n", "return", "tf", ".", "reshape", "(", "ret", ",", "[", "1", ",", "1", ",", "length", ",", "length", "]", ")", "\n", "", "elif", "mode", "==", "\"masking\"", ":", "\n", "            ", "mask", "=", "inputs", "\n", "ret", "=", "(", "1.0", "-", "mask", ")", "*", "inf", "\n", "return", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "ret", ",", "1", ")", ",", "1", ")", "\n", "", "elif", "mode", "==", "\"aan\"", ":", "\n", "            ", "length", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "diagonal", "=", "tf", ".", "eye", "(", "length", ")", "\n", "cum_factor", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cumsum", "(", "diagonal", ",", "axis", "=", "0", ")", ",", "0", ")", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "inputs", ",", "1", ")", "*", "tf", ".", "expand_dims", "(", "inputs", ",", "2", ")", "\n", "mask", "*=", "cum_factor", "\n", "weight", "=", "tf", ".", "nn", ".", "softmax", "(", "mask", "+", "(", "1.0", "-", "mask", ")", "*", "inf", ")", "\n", "weight", "*=", "mask", "\n", "return", "weight", "\n", "", "elif", "mode", "==", "\"proximal\"", ":", "\n", "            ", "length", "=", "inputs", "\n", "r", "=", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "length", ")", ")", "\n", "diff", "=", "tf", ".", "expand_dims", "(", "r", ",", "0", ")", "-", "tf", ".", "expand_dims", "(", "r", ",", "1", ")", "\n", "m", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "-", "tf", ".", "log", "(", "1", "+", "tf", ".", "abs", "(", "diff", ")", ")", ",", "0", ")", ",", "0", ")", "\n", "return", "m", "\n", "", "elif", "mode", "==", "\"distance\"", ":", "\n", "            ", "length", ",", "distance", "=", "inputs", "\n", "distance", "=", "tf", ".", "where", "(", "distance", ">", "length", ",", "0", ",", "distance", ")", "\n", "distance", "=", "tf", ".", "cast", "(", "distance", ",", "tf", ".", "int64", ")", "\n", "lower_triangle", "=", "tf", ".", "matrix_band_part", "(", "\n", "tf", ".", "ones", "(", "[", "length", ",", "length", "]", ")", ",", "-", "1", ",", "0", "\n", ")", "\n", "mask_triangle", "=", "1.0", "-", "tf", ".", "matrix_band_part", "(", "\n", "tf", ".", "ones", "(", "[", "length", ",", "length", "]", ")", ",", "distance", "-", "1", ",", "0", "\n", ")", "\n", "ret", "=", "inf", "*", "(", "1.0", "-", "lower_triangle", "+", "mask_triangle", ")", "\n", "return", "tf", ".", "reshape", "(", "ret", ",", "[", "1", ",", "1", ",", "length", ",", "length", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown mode %s\"", "%", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.attention": [[141, 192], ["tensorflow.variable_scope", "tensorflow.shape", "thumt.layers.nn.linear", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.reshape", "thumt.layers.nn.linear", "tensorflow.reshape", "tensorflow.nn.softmax", "memories.get_shape().as_list", "tensorflow.reshape", "thumt.layers.nn.linear", "tensorflow.reduce_sum", "memories.get_shape"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear"], ["", "", "", "def", "attention", "(", "query", ",", "memories", ",", "bias", ",", "hidden_size", ",", "cache", "=", "None", ",", "reuse", "=", "None", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\" Standard attention layer\n\n    :param query: A tensor with shape [batch, key_size]\n    :param memories: A tensor with shape [batch, memory_size, key_size]\n    :param bias: A tensor with shape [batch, memory_size]\n    :param hidden_size: An integer\n    :param cache: A dictionary of precomputed value\n    :param reuse: A boolean value, whether to reuse the scope\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string, the scope of this layer\n    :return: A tensor with shape [batch, value_size] and\n        a Tensor with shape [batch, memory_size]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"attention\"", ",", "reuse", "=", "reuse", ",", "\n", "values", "=", "[", "query", ",", "memories", ",", "bias", "]", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "mem_shape", "=", "tf", ".", "shape", "(", "memories", ")", "\n", "key_size", "=", "memories", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "if", "cache", "is", "None", ":", "\n", "            ", "k", "=", "tf", ".", "reshape", "(", "memories", ",", "[", "-", "1", ",", "key_size", "]", ")", "\n", "k", "=", "linear", "(", "k", ",", "hidden_size", ",", "False", ",", "False", ",", "scope", "=", "\"k_transform\"", ")", "\n", "\n", "if", "query", "is", "None", ":", "\n", "                ", "return", "{", "\"key\"", ":", "k", "}", "\n", "", "", "else", ":", "\n", "            ", "k", "=", "cache", "[", "\"key\"", "]", "\n", "\n", "", "q", "=", "linear", "(", "query", ",", "hidden_size", ",", "False", ",", "False", ",", "scope", "=", "\"q_transform\"", ")", "\n", "k", "=", "tf", ".", "reshape", "(", "k", ",", "[", "mem_shape", "[", "0", "]", ",", "mem_shape", "[", "1", "]", ",", "hidden_size", "]", ")", "\n", "\n", "hidden", "=", "tf", ".", "tanh", "(", "q", "[", ":", ",", "None", ",", ":", "]", "+", "k", ")", "\n", "hidden", "=", "tf", ".", "reshape", "(", "hidden", ",", "[", "-", "1", ",", "hidden_size", "]", ")", "\n", "\n", "# Shape: [batch, mem_size, 1]", "\n", "logits", "=", "linear", "(", "hidden", ",", "1", ",", "False", ",", "False", ",", "scope", "=", "\"logits\"", ")", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", ",", "mem_shape", "[", "1", "]", "]", ")", "\n", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "logits", "=", "logits", "+", "bias", "\n", "\n", "", "alpha", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "outputs", "=", "{", "\n", "\"value\"", ":", "tf", ".", "reduce_sum", "(", "alpha", "[", ":", ",", ":", ",", "None", "]", "*", "memories", ",", "axis", "=", "1", ")", ",", "\n", "\"weight\"", ":", "alpha", "\n", "}", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.additive_attention": [[194, 247], ["tensorflow.variable_scope", "tensorflow.tile", "tensorflow.tile", "tensorflow.squeeze", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.shape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.tanh", "thumt.layers.nn.linear", "thumt.layers.nn.linear", "tensorflow.tanh", "thumt.layers.nn.linear", "tensorflow.nn.dropout", "thumt.layers.nn.linear", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear"], ["", "def", "additive_attention", "(", "queries", ",", "keys", ",", "values", ",", "bias", ",", "hidden_size", ",", "concat", "=", "False", ",", "\n", "keep_prob", "=", "None", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\" Additive attention mechanism. This layer is implemented using a\n        one layer feed forward neural network\n\n    :param queries: A tensor with shape [batch, heads, length_q, depth_k]\n    :param keys: A tensor with shape [batch, heads, length_kv, depth_k]\n    :param values: A tensor with shape [batch, heads, length_kv, depth_v]\n    :param bias: A tensor\n    :param hidden_size: An integer\n    :param concat: A boolean value. If ``concat'' is set to True, then\n        the computation of attention mechanism is following $tanh(W[q, k])$.\n        When ``concat'' is set to False, the computation is following\n        $tanh(Wq + Vk)$\n    :param keep_prob: a scalar in [0, 1]\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string, the scope of this layer\n\n    :returns: A dict with the following keys:\n        weights: A tensor with shape [batch, length_q]\n        outputs: A tensor with shape [batch, length_q, depth_v]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"additive_attention\"", ",", "\n", "values", "=", "[", "queries", ",", "keys", ",", "values", ",", "bias", "]", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "length_q", "=", "tf", ".", "shape", "(", "queries", ")", "[", "2", "]", "\n", "length_kv", "=", "tf", ".", "shape", "(", "keys", ")", "[", "2", "]", "\n", "q", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "queries", ",", "3", ")", ",", "[", "1", ",", "1", ",", "1", ",", "length_kv", ",", "1", "]", ")", "\n", "k", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "keys", ",", "2", ")", ",", "[", "1", ",", "1", ",", "length_q", ",", "1", ",", "1", "]", ")", "\n", "\n", "if", "concat", ":", "\n", "            ", "combined", "=", "tf", ".", "tanh", "(", "linear", "(", "tf", ".", "concat", "(", "[", "q", ",", "k", "]", ",", "axis", "=", "-", "1", ")", ",", "hidden_size", ",", "\n", "True", ",", "True", ",", "name", "=", "\"qk_transform\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "linear", "(", "queries", ",", "hidden_size", ",", "True", ",", "True", ",", "name", "=", "\"q_transform\"", ")", "\n", "k", "=", "linear", "(", "keys", ",", "hidden_size", ",", "True", ",", "True", ",", "name", "=", "\"key_transform\"", ")", "\n", "combined", "=", "tf", ".", "tanh", "(", "q", "+", "k", ")", "\n", "\n", "# shape: [batch, heads, length_q, length_kv]", "\n", "", "logits", "=", "tf", ".", "squeeze", "(", "linear", "(", "combined", ",", "1", ",", "True", ",", "True", ",", "name", "=", "\"logits\"", ")", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "logits", "+=", "bias", "\n", "\n", "", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "\"attention_weights\"", ")", "\n", "\n", "if", "keep_prob", "or", "keep_prob", "<", "1.0", ":", "\n", "            ", "weights", "=", "tf", ".", "nn", ".", "dropout", "(", "weights", ",", "keep_prob", ")", "\n", "\n", "", "outputs", "=", "tf", ".", "matmul", "(", "weights", ",", "values", ")", "\n", "\n", "return", "{", "\"weights\"", ":", "weights", ",", "\"outputs\"", ":", "outputs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.multiplicative_attention": [[249, 282], ["tensorflow.name_scope", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.nn.dropout"], "function", ["None"], ["", "", "def", "multiplicative_attention", "(", "queries", ",", "keys", ",", "values", ",", "bias", ",", "keep_prob", "=", "None", ",", "\n", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Multiplicative attention mechanism. This layer is implemented using\n        dot-product operation.\n\n    :param queries: A tensor with shape [batch, heads, length_q, depth_k]\n    :param keys: A tensor with shape [batch, heads, length_kv, depth_k]\n    :param values: A tensor with shape [batch, heads, length_kv, depth_v]\n    :param bias: A tensor\n    :param keep_prob: a scalar in (0, 1]\n    :param name: the name of this operation\n\n    :returns: A dict with the following keys:\n        weights: A tensor with shape [batch, length_q]\n        outputs: A tensor with shape [batch, length_q, depth_v]\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "name", ",", "default_name", "=", "\"multiplicative_attention\"", ",", "\n", "values", "=", "[", "queries", ",", "keys", ",", "values", ",", "bias", "]", ")", ":", "\n", "# shape: [batch, heads, length_q, length_kv]", "\n", "        ", "logits", "=", "tf", ".", "matmul", "(", "queries", ",", "keys", ",", "transpose_b", "=", "True", ")", "\n", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "logits", "+=", "bias", "\n", "\n", "", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "\"attention_weights\"", ")", "\n", "\n", "if", "keep_prob", "is", "not", "None", "and", "keep_prob", "<", "1.0", ":", "\n", "            ", "weights", "=", "tf", ".", "nn", ".", "dropout", "(", "weights", ",", "keep_prob", ")", "\n", "\n", "", "outputs", "=", "tf", ".", "matmul", "(", "weights", ",", "values", ")", "\n", "\n", "return", "{", "\"weights\"", ":", "weights", ",", "\"outputs\"", ":", "outputs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.multihead_attention": [[284, 352], ["ValueError", "ValueError", "tensorflow.variable_scope", "attention.split_heads", "attention.split_heads", "attention.split_heads", "attention.multiplicative_attention", "attention.combine_heads", "thumt.layers.nn.linear", "tensorflow.split", "thumt.layers.nn.linear", "thumt.layers.nn.linear", "tensorflow.split", "thumt.layers.nn.linear"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.split_heads", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.split_heads", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.split_heads", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.multiplicative_attention", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.combine_heads", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear"], ["", "", "def", "multihead_attention", "(", "queries", ",", "memories", ",", "bias", ",", "num_heads", ",", "key_size", ",", "\n", "value_size", ",", "output_size", ",", "keep_prob", "=", "None", ",", "output", "=", "True", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\" Multi-head scaled-dot-product attention with input/output\n        transformations.\n\n    :param queries: A tensor with shape [batch, length_q, depth_q] if\n    :param memories: A tensor with shape [batch, length_m, depth_m]\n    :param bias: A tensor (see attention_bias)\n    :param num_heads: An integer dividing key_size and value_size\n    :param key_size: An integer\n    :param value_size: An integer\n    :param output_size: An integer\n    :param keep_prob: A floating point number in (0, 1]\n    :param output: Whether to use output transformation\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string\n\n    :returns: A dict with the following keys:\n        weights: A tensor with shape [batch, length_q]\n        outputs: A tensor with shape [batch, length_q, depth_v]\n    \"\"\"", "\n", "\n", "if", "key_size", "%", "num_heads", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Key size (%d) must be divisible by the number of \"", "\n", "\"attention heads (%d).\"", "%", "(", "key_size", ",", "num_heads", ")", ")", "\n", "\n", "", "if", "value_size", "%", "num_heads", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Value size (%d) must be divisible by the number of \"", "\n", "\"attention heads (%d).\"", "%", "(", "value_size", ",", "num_heads", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"multihead_attention\"", ",", "\n", "values", "=", "[", "queries", ",", "memories", "]", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "if", "memories", "is", "None", ":", "\n", "# self attention", "\n", "            ", "size", "=", "key_size", "*", "2", "+", "value_size", "\n", "combined", "=", "linear", "(", "queries", ",", "size", ",", "True", ",", "True", ",", "scope", "=", "\"qkv_transform\"", ")", "\n", "q", ",", "k", ",", "v", "=", "tf", ".", "split", "(", "combined", ",", "[", "key_size", ",", "key_size", ",", "value_size", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "linear", "(", "queries", ",", "key_size", ",", "True", ",", "True", ",", "scope", "=", "\"q_transform\"", ")", "\n", "combined", "=", "linear", "(", "memories", ",", "key_size", "+", "value_size", ",", "True", ",", "\n", "scope", "=", "\"kv_transform\"", ")", "\n", "k", ",", "v", "=", "tf", ".", "split", "(", "combined", ",", "[", "key_size", ",", "value_size", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# split heads", "\n", "", "q", "=", "split_heads", "(", "q", ",", "num_heads", ")", "\n", "k", "=", "split_heads", "(", "k", ",", "num_heads", ")", "\n", "v", "=", "split_heads", "(", "v", ",", "num_heads", ")", "\n", "\n", "# scale query", "\n", "key_depth_per_head", "=", "key_size", "//", "num_heads", "\n", "q", "*=", "key_depth_per_head", "**", "-", "0.5", "\n", "\n", "# attention", "\n", "results", "=", "multiplicative_attention", "(", "q", ",", "k", ",", "v", ",", "bias", ",", "keep_prob", ")", "\n", "\n", "# combine heads", "\n", "weights", "=", "results", "[", "\"weights\"", "]", "\n", "x", "=", "combine_heads", "(", "results", "[", "\"outputs\"", "]", ")", "\n", "\n", "if", "output", ":", "\n", "            ", "outputs", "=", "linear", "(", "x", ",", "output_size", ",", "True", ",", "True", ",", "\n", "scope", "=", "\"output_transform\"", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "x", "\n", "\n", "", "return", "{", "\"weights\"", ":", "weights", ",", "\"outputs\"", ":", "outputs", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear": [[11, 65], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.add_n", "tensorflow.reshape", "isinstance", "len", "len", "RuntimeError", "tensorflow.reshape", "sum", "tensorflow.concat", "tensorflow.get_variable", "results.append", "range", "tensorflow.get_variable", "tensorflow.nn.bias_add", "tensorflow.matmul", "len", "tensorflow.get_variable", "results.append", "item.get_shape", "tensorflow.shape", "tensorflow.matmul"], "function", ["None"], ["def", "linear", "(", "inputs", ",", "output_size", ",", "bias", ",", "concat", "=", "True", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Linear layer\n    :param inputs: A Tensor or a list of Tensors with shape [batch, input_size]\n    :param output_size: An integer specify the output size\n    :param bias: a boolean value indicate whether to use bias term\n    :param concat: a boolean value indicate whether to concatenate all inputs\n    :param dtype: an instance of tf.DType, the default value is ``tf.float32''\n    :param scope: the scope of this layer, the default value is ``linear''\n    :returns: a Tensor with shape [batch, output_size]\n    :raises RuntimeError: raises ``RuntimeError'' when input sizes do not\n                          compatible with each other\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"linear\"", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "input_size", "=", "[", "item", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "for", "item", "in", "inputs", "]", "\n", "\n", "if", "len", "(", "inputs", ")", "!=", "len", "(", "input_size", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"inputs and input_size unmatched!\"", ")", "\n", "\n", "", "output_shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", "[", ":", "-", "1", "]", ",", "[", "output_size", "]", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Flatten to 2D", "\n", "inputs", "=", "[", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "inp", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "for", "inp", "in", "inputs", "]", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "if", "concat", ":", "\n", "            ", "input_size", "=", "sum", "(", "input_size", ")", "\n", "inputs", "=", "tf", ".", "concat", "(", "inputs", ",", "1", ")", "\n", "\n", "shape", "=", "[", "input_size", ",", "output_size", "]", "\n", "matrix", "=", "tf", ".", "get_variable", "(", "\"matrix\"", ",", "shape", ",", "dtype", "=", "dtype", ")", "\n", "results", ".", "append", "(", "tf", ".", "matmul", "(", "inputs", ",", "matrix", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "input_size", ")", ")", ":", "\n", "                ", "shape", "=", "[", "input_size", "[", "i", "]", ",", "output_size", "]", "\n", "name", "=", "\"matrix_%d\"", "%", "i", "\n", "matrix", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", ",", "dtype", "=", "dtype", ")", "\n", "results", ".", "append", "(", "tf", ".", "matmul", "(", "inputs", "[", "i", "]", ",", "matrix", ")", ")", "\n", "\n", "", "", "output", "=", "tf", ".", "add_n", "(", "results", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "shape", "=", "[", "output_size", "]", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "shape", ",", "dtype", "=", "dtype", ")", "\n", "output", "=", "tf", ".", "nn", ".", "bias_add", "(", "output", ",", "bias", ")", "\n", "\n", "", "output", "=", "tf", ".", "reshape", "(", "output", ",", "output_shape", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.maxout": [[67, 90], ["nn.linear", "tensorflow.concat", "tensorflow.reshape", "tensorflow.reduce_max", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear"], ["", "", "def", "maxout", "(", "inputs", ",", "output_size", ",", "maxpart", "=", "2", ",", "use_bias", "=", "True", ",", "concat", "=", "True", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Maxout layer\n    :param inputs: see the corresponding description of ``linear''\n    :param output_size: see the corresponding description of ``linear''\n    :param maxpart: an integer, the default value is 2\n    :param use_bias: a boolean value indicate whether to use bias term\n    :param concat: concat all tensors if inputs is a list of tensors\n    :param dtype: an optional instance of tf.Dtype\n    :param scope: the scope of this layer, the default value is ``maxout''\n    :returns: a Tensor with shape [batch, output_size]\n    :raises RuntimeError: see the corresponding description of ``linear''\n    \"\"\"", "\n", "\n", "candidate", "=", "linear", "(", "inputs", ",", "output_size", "*", "maxpart", ",", "use_bias", ",", "concat", ",", "\n", "dtype", "=", "dtype", ",", "scope", "=", "scope", "or", "\"maxout\"", ")", "\n", "shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "candidate", ")", "[", ":", "-", "1", "]", ",", "[", "output_size", ",", "maxpart", "]", "]", ",", "\n", "axis", "=", "0", ")", "\n", "value", "=", "tf", ".", "reshape", "(", "candidate", ",", "shape", ")", "\n", "output", "=", "tf", ".", "reduce_max", "(", "value", ",", "-", "1", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.layer_norm": [[92, 118], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "inputs.get_shape().as_list", "tensorflow.square", "tensorflow.rsqrt", "tensorflow.ones_initializer", "tensorflow.zeros_initializer", "inputs.get_shape"], "function", ["None"], ["", "def", "layer_norm", "(", "inputs", ",", "epsilon", "=", "1e-6", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Layer Normalization\n    :param inputs: A Tensor of shape [..., channel_size]\n    :param epsilon: A floating number\n    :param dtype: An optional instance of tf.DType\n    :param scope: An optional string\n    :returns: A Tensor with the same shape as inputs\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"layer_norm\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "channel_size", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "scale", "=", "tf", ".", "get_variable", "(", "\"scale\"", ",", "shape", "=", "[", "channel_size", "]", ",", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ")", "\n", "\n", "offset", "=", "tf", ".", "get_variable", "(", "\"offset\"", ",", "shape", "=", "[", "channel_size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n", "mean", "=", "tf", ".", "reduce_mean", "(", "inputs", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "variance", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "inputs", "-", "mean", ")", ",", "axis", "=", "-", "1", ",", "\n", "keep_dims", "=", "True", ")", "\n", "\n", "norm_inputs", "=", "(", "inputs", "-", "mean", ")", "*", "tf", ".", "rsqrt", "(", "variance", "+", "epsilon", ")", "\n", "\n", "return", "norm_inputs", "*", "scale", "+", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.smoothed_softmax_cross_entropy_with_logits": [[120, 163], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "ValueError", "tensorflow.name_scope", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.one_hot", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.shape", "tensorflow.cast", "tensorflow.log", "tensorflow.log"], "function", ["None"], ["", "", "def", "smoothed_softmax_cross_entropy_with_logits", "(", "**", "kwargs", ")", ":", "\n", "    ", "logits", "=", "kwargs", ".", "get", "(", "\"logits\"", ")", "\n", "labels", "=", "kwargs", ".", "get", "(", "\"labels\"", ")", "\n", "smoothing", "=", "kwargs", ".", "get", "(", "\"smoothing\"", ")", "or", "0.0", "\n", "normalize", "=", "kwargs", ".", "get", "(", "\"normalize\"", ")", "\n", "scope", "=", "kwargs", ".", "get", "(", "\"scope\"", ")", "\n", "\n", "if", "logits", "is", "None", "or", "labels", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Both logits and labels must be provided\"", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "scope", "or", "\"smoothed_softmax_cross_entropy_with_logits\"", ",", "\n", "values", "=", "[", "logits", ",", "labels", "]", ")", ":", "\n", "\n", "        ", "labels", "=", "tf", ".", "reshape", "(", "labels", ",", "[", "-", "1", "]", ")", "\n", "\n", "if", "not", "smoothing", ":", "\n", "            ", "ce", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", "\n", ")", "\n", "return", "ce", "\n", "\n", "# label smoothing", "\n", "", "vocab_size", "=", "tf", ".", "shape", "(", "logits", ")", "[", "1", "]", "\n", "\n", "n", "=", "tf", ".", "to_float", "(", "vocab_size", "-", "1", ")", "\n", "p", "=", "1.0", "-", "smoothing", "\n", "q", "=", "smoothing", "/", "n", "\n", "\n", "soft_targets", "=", "tf", ".", "one_hot", "(", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "int32", ")", ",", "depth", "=", "vocab_size", ",", "\n", "on_value", "=", "p", ",", "off_value", "=", "q", ")", "\n", "xentropy", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "\n", "labels", "=", "soft_targets", ")", "\n", "\n", "if", "normalize", "is", "False", ":", "\n", "            ", "return", "xentropy", "\n", "\n", "# Normalizing constant is the best cross-entropy value with soft", "\n", "# targets. We subtract it just for readability, makes no difference on", "\n", "# learning", "\n", "", "normalizing", "=", "-", "(", "p", "*", "tf", ".", "log", "(", "p", ")", "+", "n", "*", "q", "*", "tf", ".", "log", "(", "q", "+", "1e-20", ")", ")", "\n", "\n", "return", "xentropy", "-", "normalizing", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.convert_old_model.parseargs": [[15, 24], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Convert old models\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of old model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path of output checkpoint\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.convert_old_model.old_keys": [[26, 71], ["None"], "function", ["None"], ["", "def", "old_keys", "(", ")", ":", "\n", "    ", "keys", "=", "[", "\n", "\"GRU_dec_attcontext\"", ",", "\n", "\"GRU_dec_att\"", ",", "\n", "\"GRU_dec_atthidden\"", ",", "\n", "\"GRU_dec_inputoffset\"", ",", "\n", "\"GRU_dec_inputemb\"", ",", "\n", "\"GRU_dec_inputcontext\"", ",", "\n", "\"GRU_dec_inputhidden\"", ",", "\n", "\"GRU_dec_resetemb\"", ",", "\n", "\"GRU_dec_resetcontext\"", ",", "\n", "\"GRU_dec_resethidden\"", ",", "\n", "\"GRU_dec_gateemb\"", ",", "\n", "\"GRU_dec_gatecontext\"", ",", "\n", "\"GRU_dec_gatehidden\"", ",", "\n", "\"initer_b\"", ",", "\n", "\"initer_W\"", ",", "\n", "\"GRU_dec_probsemb\"", ",", "\n", "\"GRU_enc_back_inputoffset\"", ",", "\n", "\"GRU_enc_back_inputemb\"", ",", "\n", "\"GRU_enc_back_inputhidden\"", ",", "\n", "\"GRU_enc_back_resetemb\"", ",", "\n", "\"GRU_enc_back_resethidden\"", ",", "\n", "\"GRU_enc_back_gateemb\"", ",", "\n", "\"GRU_enc_back_gatehidden\"", ",", "\n", "\"GRU_enc_inputoffset\"", ",", "\n", "\"GRU_enc_inputemb\"", ",", "\n", "\"GRU_enc_inputhidden\"", ",", "\n", "\"GRU_enc_resetemb\"", ",", "\n", "\"GRU_enc_resethidden\"", ",", "\n", "\"GRU_enc_gateemb\"", ",", "\n", "\"GRU_enc_gatehidden\"", ",", "\n", "\"GRU_dec_readoutoffset\"", ",", "\n", "\"GRU_dec_readoutemb\"", ",", "\n", "\"GRU_dec_readouthidden\"", ",", "\n", "\"GRU_dec_readoutcontext\"", ",", "\n", "\"GRU_dec_probsoffset\"", ",", "\n", "\"GRU_dec_probs\"", ",", "\n", "\"emb_src_b\"", ",", "\n", "\"emb_src_emb\"", ",", "\n", "\"emb_trg_b\"", ",", "\n", "\"emb_trg_emb\"", "\n", "]", "\n", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.convert_old_model.new_keys": [[73, 118], ["None"], "function", ["None"], ["", "def", "new_keys", "(", ")", ":", "\n", "    ", "keys", "=", "[", "\n", "\"rnnsearch/decoder/attention/k_transform/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/attention/logits/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/attention/q_transform/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/candidate/bias\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/candidate/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/candidate/matrix_1\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/candidate/matrix_2\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/reset_gate/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/reset_gate/matrix_1\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/reset_gate/matrix_2\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/update_gate/matrix_0\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/update_gate/matrix_1\"", ",", "\n", "\"rnnsearch/decoder/gru_cell/update_gate/matrix_2\"", ",", "\n", "\"rnnsearch/decoder/s_transform/bias\"", ",", "\n", "\"rnnsearch/decoder/s_transform/matrix_0\"", ",", "\n", "\"rnnsearch/deepout/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/candidate/bias\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/candidate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/candidate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/reset_gate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/reset_gate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/update_gate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/backward/gru_cell/update_gate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/candidate/bias\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/candidate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/candidate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/reset_gate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/reset_gate/matrix_1\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/update_gate/matrix_0\"", ",", "\n", "\"rnnsearch/encoder/forward/gru_cell/update_gate/matrix_1\"", ",", "\n", "\"rnnsearch/maxout/bias\"", ",", "\n", "\"rnnsearch/maxout/matrix_0\"", ",", "\n", "\"rnnsearch/maxout/matrix_1\"", ",", "\n", "\"rnnsearch/maxout/matrix_2\"", ",", "\n", "\"rnnsearch/softmax/bias\"", ",", "\n", "\"rnnsearch/softmax/matrix_0\"", ",", "\n", "\"rnnsearch/source_embedding/bias\"", ",", "\n", "\"rnnsearch/source_embedding/embedding\"", ",", "\n", "\"rnnsearch/target_embedding/bias\"", ",", "\n", "\"rnnsearch/target_embedding/embedding\"", ",", "\n", "]", "\n", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.convert_old_model.main": [[120, 144], ["dict", "convert_old_model.old_keys", "convert_old_model.new_keys", "enumerate", "numpy.load", "tensorflow.Graph().as_default", "tensorflow.train.Saver", "tensorflow.device", "tensorflow.Variable", "tensorflow.Session", "sess.run", "tf.train.Saver.save", "tensorflow.Graph", "tensorflow.get_variable", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.convert_old_model.old_keys", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.convert_old_model.new_keys"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "values", "=", "dict", "(", "np", ".", "load", "(", "args", ".", "input", ")", ")", "\n", "variables", "=", "{", "}", "\n", "o_keys", "=", "old_keys", "(", ")", "\n", "n_keys", "=", "new_keys", "(", ")", "\n", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "o_keys", ")", ":", "\n", "        ", "v", "=", "values", "[", "key", "]", "\n", "variables", "[", "n_keys", "[", "i", "]", "]", "=", "v", "\n", "\n", "", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "            ", "tf_vars", "=", "[", "\n", "tf", ".", "get_variable", "(", "v", ",", "initializer", "=", "variables", "[", "v", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "v", "in", "variables", "\n", "]", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf_vars", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "saver", ".", "save", "(", "sess", ",", "args", ".", "output", ",", "global_step", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.shuffle_corpus.parseargs": [[12, 22], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Shuffle corpus\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--corpus\"", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"input corpora\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--suffix\"", ",", "type", "=", "str", ",", "default", "=", "\"shuf\"", ",", "\n", "help", "=", "\"Suffix of output files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "help", "=", "\"Random seed\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.shuffle_corpus.main": [[24, 48], ["min", "numpy.arange", "numpy.random.shuffle", "numpy.arange.tolist", "zip", "open", "fd.readlines", "numpy.random.seed", "open", "zip", "fdr.close", "fdw.close", "len", "fd.write"], "function", ["None"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "name", "=", "args", ".", "corpus", "\n", "suffix", "=", "\".\"", "+", "args", ".", "suffix", "\n", "stream", "=", "[", "open", "(", "item", ",", "\"r\"", ")", "for", "item", "in", "name", "]", "\n", "data", "=", "[", "fd", ".", "readlines", "(", ")", "for", "fd", "in", "stream", "]", "\n", "minlen", "=", "min", "(", "[", "len", "(", "lines", ")", "for", "lines", "in", "data", "]", ")", "\n", "\n", "if", "args", ".", "seed", ":", "\n", "        ", "numpy", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "indices", "=", "numpy", ".", "arange", "(", "minlen", ")", "\n", "numpy", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "\n", "newstream", "=", "[", "open", "(", "item", "+", "suffix", ",", "\"w\"", ")", "for", "item", "in", "name", "]", "\n", "\n", "for", "idx", "in", "indices", ".", "tolist", "(", ")", ":", "\n", "        ", "lines", "=", "[", "item", "[", "idx", "]", "for", "item", "in", "data", "]", "\n", "\n", "for", "line", ",", "fd", "in", "zip", "(", "lines", ",", "newstream", ")", ":", "\n", "            ", "fd", ".", "write", "(", "line", ")", "\n", "\n", "", "", "for", "fdr", ",", "fdw", "in", "zip", "(", "stream", ",", "newstream", ")", ":", "\n", "        ", "fdr", ".", "close", "(", ")", "\n", "fdw", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.checkpoint_averaging.parseargs": [[17, 29], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.parse_args"], ["def", "parseargs", "(", ")", ":", "\n", "    ", "msg", "=", "\"Average checkpoints\"", "\n", "usage", "=", "\"average.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--path\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoints\"", ",", "type", "=", "int", ",", "required", "=", "True", ",", "\n", "help", "=", "\"number of checkpoints to use\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "help", "=", "\"output path\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.checkpoint_averaging.get_checkpoints": [[31, 49], ["sorted", "tensorflow.gfile.Exists", "ValueError", "tensorflow.gfile.GFile", "fd.readline", "os.path.join", "os.path.join", "int", "checkpoint_names.append", "operator.itemgetter", "[].strip", "name.split", "os.path.join", "line.strip().split", "line.strip"], "function", ["None"], ["", "def", "get_checkpoints", "(", "path", ")", ":", "\n", "    ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"checkpoint\"", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cannot find checkpoints in %s\"", "%", "path", ")", "\n", "\n", "", "checkpoint_names", "=", "[", "]", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"checkpoint\"", ")", ")", "as", "fd", ":", "\n", "# Skip the first line", "\n", "        ", "fd", ".", "readline", "(", ")", "\n", "for", "line", "in", "fd", ":", "\n", "            ", "name", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\":\"", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "key", "=", "int", "(", "name", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "checkpoint_names", ".", "append", "(", "(", "key", ",", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", ")", ")", "\n", "\n", "", "", "sorted_names", "=", "sorted", "(", "checkpoint_names", ",", "key", "=", "operator", ".", "itemgetter", "(", "0", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "return", "[", "item", "[", "-", "1", "]", "for", "item", "in", "sorted_names", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.checkpoint_averaging.checkpoint_exists": [[51, 54], ["tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists"], "function", ["None"], ["", "def", "checkpoint_exists", "(", "path", ")", ":", "\n", "    ", "return", "(", "tf", ".", "gfile", ".", "Exists", "(", "path", ")", "or", "tf", ".", "gfile", ".", "Exists", "(", "path", "+", "\".meta\"", ")", "or", "\n", "tf", ".", "gfile", ".", "Exists", "(", "path", "+", "\".index\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.checkpoint_averaging.main": [[56, 117], ["tensorflow.logging.set_verbosity", "checkpoint_averaging.get_checkpoints", "tensorflow.contrib.framework.list_variables", "tensorflow.Variable", "tensorflow.train.Saver", "tensorflow.logging.info", "os.path.join", "tensorflow.gfile.Glob", "ValueError", "ValueError", "tensorflow.contrib.framework.load_checkpoint", "tensorflow.logging.info", "len", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.assign", "tensorflow.global_variables", "tensorflow.Session", "sess.run", "zip", "os.path.join", "tf.train.Saver.save", "name.replace", "tensorflow.gfile.Copy", "checkpoint_averaging.checkpoint_exists", "name.startswith", "numpy.zeros", "tf.contrib.framework.load_checkpoint.get_tensor", "zip", "tensorflow.global_variables_initializer", "var_values.iteritems", "sess.run", "FLAGS.path.rstrip", "FLAGS.output.rstrip"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.checkpoint_averaging.get_checkpoints", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.checkpoint_averaging.checkpoint_exists"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "checkpoints", "=", "get_checkpoints", "(", "FLAGS", ".", "path", ")", "\n", "checkpoints", "=", "checkpoints", "[", ":", "FLAGS", ".", "checkpoints", "]", "\n", "\n", "if", "not", "checkpoints", ":", "\n", "        ", "raise", "ValueError", "(", "\"No checkpoints provided for averaging.\"", ")", "\n", "\n", "", "checkpoints", "=", "[", "c", "for", "c", "in", "checkpoints", "if", "checkpoint_exists", "(", "c", ")", "]", "\n", "\n", "if", "not", "checkpoints", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"None of the provided checkpoints exist. %s\"", "%", "FLAGS", ".", "checkpoints", "\n", ")", "\n", "\n", "", "var_list", "=", "tf", ".", "contrib", ".", "framework", ".", "list_variables", "(", "checkpoints", "[", "0", "]", ")", "\n", "var_values", ",", "var_dtypes", "=", "{", "}", ",", "{", "}", "\n", "\n", "for", "(", "name", ",", "shape", ")", "in", "var_list", ":", "\n", "        ", "if", "not", "name", ".", "startswith", "(", "\"global_step\"", ")", ":", "\n", "            ", "var_values", "[", "name", "]", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "\n", "", "", "for", "checkpoint", "in", "checkpoints", ":", "\n", "        ", "reader", "=", "tf", ".", "contrib", ".", "framework", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "for", "name", "in", "var_values", ":", "\n", "            ", "tensor", "=", "reader", ".", "get_tensor", "(", "name", ")", "\n", "var_dtypes", "[", "name", "]", "=", "tensor", ".", "dtype", "\n", "var_values", "[", "name", "]", "+=", "tensor", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Read from checkpoint %s\"", ",", "checkpoint", ")", "\n", "\n", "# Average checkpoints", "\n", "", "for", "name", "in", "var_values", ":", "\n", "        ", "var_values", "[", "name", "]", "/=", "len", "(", "checkpoints", ")", "\n", "\n", "", "tf_vars", "=", "[", "\n", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "var_values", "[", "name", "]", ".", "shape", ",", "\n", "dtype", "=", "var_dtypes", "[", "name", "]", ")", "for", "name", "in", "var_values", "\n", "]", "\n", "placeholders", "=", "[", "tf", ".", "placeholder", "(", "v", ".", "dtype", ",", "shape", "=", "v", ".", "shape", ")", "for", "v", "in", "tf_vars", "]", "\n", "assign_ops", "=", "[", "tf", ".", "assign", "(", "v", ",", "p", ")", "for", "(", "v", ",", "p", ")", "in", "zip", "(", "tf_vars", ",", "placeholders", ")", "]", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "p", ",", "assign_op", ",", "(", "name", ",", "value", ")", "in", "zip", "(", "placeholders", ",", "assign_ops", ",", "\n", "var_values", ".", "iteritems", "(", ")", ")", ":", "\n", "            ", "sess", ".", "run", "(", "assign_op", ",", "{", "p", ":", "value", "}", ")", "\n", "", "saved_name", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output", ",", "\"average\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "saved_name", ",", "global_step", "=", "global_step", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Averaged checkpoints saved in %s\"", ",", "saved_name", ")", "\n", "\n", "params_pattern", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "path", ",", "\"*.json\"", ")", "\n", "params_files", "=", "tf", ".", "gfile", ".", "Glob", "(", "params_pattern", ")", "\n", "\n", "for", "name", "in", "params_files", ":", "\n", "        ", "new_name", "=", "name", ".", "replace", "(", "FLAGS", ".", "path", ".", "rstrip", "(", "\"/\"", ")", ",", "\n", "FLAGS", ".", "output", ".", "rstrip", "(", "\"/\"", ")", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "name", ",", "new_name", ",", "overwrite", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.load_vocab": [[16, 26], ["tensorflow.gfile.Open", "line.strip"], "function", ["None"], ["def", "load_vocab", "(", "filename", ")", ":", "\n", "    ", "with", "tf", ".", "gfile", ".", "Open", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "count", "=", "0", "\n", "vocab", "=", "{", "}", "\n", "for", "line", "in", "fd", ":", "\n", "            ", "word", "=", "line", ".", "strip", "(", ")", "\n", "vocab", "[", "word", "]", "=", "count", "\n", "count", "+=", "1", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.to_example": [[28, 50], ["six.iteritems", "tensorflow.train.Example", "isinstance", "ValueError", "tensorflow.train.Int64List", "tensorflow.train.Feature", "isinstance", "tensorflow.train.Features", "str", "tensorflow.train.FloatList", "tensorflow.train.Feature", "isinstance", "tensorflow.train.BytesList", "tensorflow.train.Feature", "ValueError", "str", "str", "type"], "function", ["None"], ["", "def", "to_example", "(", "dictionary", ")", ":", "\n", "    ", "\"\"\" Convert python dictionary to tf.train.Example \"\"\"", "\n", "features", "=", "{", "}", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "dictionary", ")", ":", "\n", "        ", "if", "not", "v", ":", "\n", "            ", "raise", "ValueError", "(", "\"Empty generated field: %s\"", ",", "str", "(", "(", "k", ",", "v", ")", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "v", "[", "0", "]", ",", "six", ".", "integer_types", ")", ":", "\n", "            ", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "v", ")", "\n", "features", "[", "k", "]", "=", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "int64_list", ")", "\n", "", "elif", "isinstance", "(", "v", "[", "0", "]", ",", "float", ")", ":", "\n", "            ", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "v", ")", "\n", "features", "[", "k", "]", "=", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "float_list", ")", "\n", "", "elif", "isinstance", "(", "v", "[", "0", "]", ",", "six", ".", "string_types", ")", ":", "\n", "            ", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "v", ")", "\n", "features", "[", "k", "]", "=", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "bytes_list", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Value is neither an int nor a float; \"", "\n", "\"v: %s type: %s\"", "%", "(", "str", "(", "v", "[", "0", "]", ")", ",", "str", "(", "type", "(", "v", "[", "0", "]", ")", ")", ")", ")", "\n", "\n", "", "", "return", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "features", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.write_records": [[52, 62], ["tensorflow.python_io.TFRecordWriter", "enumerate", "tf.python_io.TFRecordWriter.close", "tf.python_io.TFRecordWriter.write", "tensorflow.logging.info"], "function", ["None"], ["", "def", "write_records", "(", "records", ",", "out_filename", ")", ":", "\n", "    ", "\"\"\" Write to TensorFlow record \"\"\"", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "out_filename", ")", "\n", "\n", "for", "count", ",", "record", "in", "enumerate", "(", "records", ")", ":", "\n", "        ", "writer", ".", "write", "(", "record", ")", "\n", "if", "count", "%", "10000", "==", "0", ":", "\n", "            ", "tf", ".", "logging", ".", "info", "(", "\"write: %d\"", ",", "count", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.convert_to_record": [[64, 111], ["xrange", "tensorflow.gfile.Open", "os.path.join", "output_files.append", "writers.append", "random.shuffle", "input_converter.to_example", "writers[].write", "writer.close", "tensorflow.gfile.Open", "zip", "tensorflow.python_io.TFRecordWriter", "to_example.SerializeToString", "sline.strip().split.strip().split", "tline.strip().split.strip().split", "records.append", "sline.strip().split.strip", "tline.strip().split.strip", "len", "len"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.to_example"], ["", "def", "convert_to_record", "(", "inputs", ",", "vocab", ",", "output_name", ",", "output_dir", ",", "num_shards", ",", "\n", "shuffle", "=", "False", ")", ":", "\n", "    ", "\"\"\" Convert plain parallel text to TensorFlow record \"\"\"", "\n", "source", ",", "target", "=", "inputs", "\n", "svocab", ",", "tvocab", "=", "vocab", "\n", "records", "=", "[", "]", "\n", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "source", ")", "as", "src", ":", "\n", "        ", "with", "tf", ".", "gfile", ".", "Open", "(", "target", ")", "as", "tgt", ":", "\n", "            ", "for", "sline", ",", "tline", "in", "zip", "(", "src", ",", "tgt", ")", ":", "\n", "                ", "sline", "=", "sline", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "sline", "=", "[", "svocab", "[", "item", "]", "if", "item", "in", "svocab", "else", "svocab", "[", "FLAGS", ".", "unk", "]", "\n", "for", "item", "in", "sline", "]", "+", "[", "svocab", "[", "FLAGS", ".", "eos", "]", "]", "\n", "tline", "=", "tline", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "tline", "=", "[", "tvocab", "[", "item", "]", "if", "item", "in", "tvocab", "else", "tvocab", "[", "FLAGS", ".", "unk", "]", "\n", "for", "item", "in", "tline", "]", "+", "[", "tvocab", "[", "FLAGS", ".", "eos", "]", "]", "\n", "\n", "feature", "=", "{", "\n", "\"source\"", ":", "sline", ",", "\n", "\"target\"", ":", "tline", ",", "\n", "\"source_length\"", ":", "[", "len", "(", "sline", ")", "]", ",", "\n", "\"target_length\"", ":", "[", "len", "(", "tline", ")", "]", "\n", "}", "\n", "records", ".", "append", "(", "feature", ")", "\n", "\n", "", "", "", "output_files", "=", "[", "]", "\n", "writers", "=", "[", "]", "\n", "\n", "for", "shard", "in", "xrange", "(", "num_shards", ")", ":", "\n", "        ", "output_filename", "=", "\"%s-%.5d-of-%.5d\"", "%", "(", "output_name", ",", "shard", ",", "num_shards", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "output_filename", ")", "\n", "output_files", ".", "append", "(", "output_file", ")", "\n", "writers", ".", "append", "(", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "output_file", ")", ")", "\n", "\n", "", "counter", ",", "shard", "=", "0", ",", "0", "\n", "\n", "if", "shuffle", ":", "\n", "        ", "random", ".", "shuffle", "(", "records", ")", "\n", "\n", "", "for", "record", "in", "records", ":", "\n", "        ", "counter", "+=", "1", "\n", "example", "=", "to_example", "(", "record", ")", "\n", "writers", "[", "shard", "]", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "shard", "=", "(", "shard", "+", "1", ")", "%", "num_shards", "\n", "\n", "", "for", "writer", "in", "writers", ":", "\n", "        ", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.parse_args": [[113, 136], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "msg", "=", "\"convert inputs to tf.Record format\"", "\n", "usage", "=", "\"input_converter.py [<args>] [-h | --help]\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "msg", ",", "usage", "=", "usage", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--input\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "nargs", "=", "2", ",", "\n", "help", "=", "\"Path of input file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_name\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Output name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab\"", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path of vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_shards\"", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of output shards\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--shuffle\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Shuffle inputs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--unk\"", ",", "default", "=", "\"<unk>\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Unknown word symbol\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eos\"", ",", "default", "=", "\"<eos>\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"End of sentence symbol\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.main": [[138, 145], ["input_converter.load_vocab", "input_converter.load_vocab", "input_converter.convert_to_record"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.load_vocab", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.load_vocab", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.input_converter.convert_to_record"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "svocab", "=", "load_vocab", "(", "FLAGS", ".", "vocab", "[", "0", "]", ")", "\n", "tvocab", "=", "load_vocab", "(", "FLAGS", ".", "vocab", "[", "1", "]", ")", "\n", "\n", "# convert data", "\n", "convert_to_record", "(", "FLAGS", ".", "input", ",", "[", "svocab", ",", "tvocab", "]", ",", "FLAGS", ".", "output_name", ",", "\n", "FLAGS", ".", "output_dir", ",", "FLAGS", ".", "num_shards", ",", "FLAGS", ".", "shuffle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.count_words": [[13, 25], ["collections.Counter", "sorted", "list", "open", "collections.Counter.items", "zip", "line.strip().split", "collections.Counter.update", "line.strip"], "function", ["None"], ["def", "count_words", "(", "filename", ")", ":", "\n", "    ", "counter", "=", "collections", ".", "Counter", "(", ")", "\n", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "fd", ":", "\n", "        ", "for", "line", "in", "fd", ":", "\n", "            ", "words", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "counter", ".", "update", "(", "words", ")", "\n", "\n", "", "", "count_pairs", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "words", ",", "counts", "=", "list", "(", "zip", "(", "*", "count_pairs", ")", ")", "\n", "\n", "return", "words", ",", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.control_symbols": [[27, 32], ["string.strip().split", "string.strip"], "function", ["None"], ["", "def", "control_symbols", "(", "string", ")", ":", "\n", "    ", "if", "not", "string", ":", "\n", "        ", "return", "[", "]", "\n", "", "else", ":", "\n", "        ", "return", "string", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.save_vocab": [[34, 44], ["sorted", "list", "vocab.items", "zip", "open", "name.split", "f.write"], "function", ["None"], ["", "", "def", "save_vocab", "(", "name", ",", "vocab", ")", ":", "\n", "    ", "if", "name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "!=", "\"txt\"", ":", "\n", "        ", "name", "=", "name", "+", "\".txt\"", "\n", "\n", "", "pairs", "=", "sorted", "(", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "words", ",", "ids", "=", "list", "(", "zip", "(", "*", "pairs", ")", ")", "\n", "\n", "with", "open", "(", "name", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "word", "in", "words", ":", "\n", "            ", "f", ".", "write", "(", "word", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.parse_args": [[46, 58], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.parse_args"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Create vocabulary\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"corpus\"", ",", "help", "=", "\"input corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output\"", ",", "default", "=", "\"vocab.txt\"", ",", "\n", "help", "=", "\"Output vocabulary name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--limit\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Vocabulary size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--control\"", ",", "type", "=", "str", ",", "default", "=", "\"<pad>,<eos>,<unk>\"", ",", "\n", "help", "=", "\"Add control symbols to vocabulary. \"", "\n", "\"Control symbols are separated by comma.\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.main": [[60, 87], ["build_vocab.count_words", "build_vocab.control_symbols", "zip", "build_vocab.save_vocab", "print", "print", "print", "len", "len", "print", "sum", "len", "len", "sum"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.count_words", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.control_symbols", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.scripts.build_vocab.save_vocab"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "vocab", "=", "{", "}", "\n", "limit", "=", "args", ".", "limit", "\n", "count", "=", "0", "\n", "\n", "words", ",", "counts", "=", "count_words", "(", "args", ".", "corpus", ")", "\n", "ctrl_symbols", "=", "control_symbols", "(", "args", ".", "control", ")", "\n", "\n", "for", "sym", "in", "ctrl_symbols", ":", "\n", "        ", "vocab", "[", "sym", "]", "=", "len", "(", "vocab", ")", "\n", "\n", "", "for", "word", ",", "freq", "in", "zip", "(", "words", ",", "counts", ")", ":", "\n", "        ", "if", "limit", "and", "len", "(", "vocab", ")", ">=", "limit", ":", "\n", "            ", "break", "\n", "\n", "", "if", "word", "in", "vocab", ":", "\n", "            ", "print", "(", "\"Warning: found duplicate token %s, ignored\"", "%", "word", ")", "\n", "continue", "\n", "\n", "", "vocab", "[", "word", "]", "=", "len", "(", "vocab", ")", "\n", "count", "+=", "freq", "\n", "\n", "", "save_vocab", "(", "args", ".", "output", ",", "vocab", ")", "\n", "\n", "print", "(", "\"Total words: %d\"", "%", "sum", "(", "counts", ")", ")", "\n", "print", "(", "\"Unique words: %d\"", "%", "len", "(", "words", ")", ")", "\n", "print", "(", "\"Vocabulary coverage: %4.2f%%\"", "%", "(", "100.0", "*", "count", "/", "sum", "(", "counts", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch.RNNsearch.__init__": [[328, 330], ["thumt.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"rnnsearch\"", ")", ":", "\n", "        ", "super", "(", "RNNsearch", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch.RNNsearch.get_training_func": [[331, 341], ["tensorflow.variable_scope", "rnnsearch.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "self", ".", "parameters", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "features", "[", "\"target\"", "]", ",", "params", ")", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch.RNNsearch.get_evaluation_func": [[342, 358], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "rnnsearch.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch.RNNsearch.get_inference_func": [[359, 375], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "rnnsearch.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "inference_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch.RNNsearch.get_name": [[376, 379], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"rnnsearch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch.RNNsearch.get_parameters": [[380, 405], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "# vocabulary", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "append_eos", "=", "False", ",", "\n", "# model", "\n", "rnn_cell", "=", "\"LegacyGRUCell\"", ",", "\n", "embedding_size", "=", "620", ",", "\n", "hidden_size", "=", "1000", ",", "\n", "maxnum", "=", "2", ",", "\n", "# regularization", "\n", "dropout", "=", "0.2", ",", "\n", "use_variational_dropout", "=", "False", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "constant_batch_size", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "max_length", "=", "60", ",", "\n", "clip_grad_norm", "=", "5.0", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._copy_through": [[15, 18], ["tensorflow.where"], "function", ["None"], ["def", "_copy_through", "(", "time", ",", "length", ",", "output", ",", "new_output", ")", ":", "\n", "    ", "copy_cond", "=", "(", "time", ">=", "length", ")", "\n", "return", "tf", ".", "where", "(", "copy_cond", ",", "output", ",", "new_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._gru_encoder": [[20, 63], ["tensorflow.zeros", "tensorflow.TensorArray", "tensorflow.TensorArray", "input_ta.unstack.unstack", "tensorflow.constant", "tensorflow.while_loop", "output_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "tensorflow.shape", "tensorflow.shape", "cell.zero_state", "tensorflow.transpose", "input_ta.unstack.read", "cell", "rnnsearch._copy_through", "rnnsearch._copy_through", "out_ta.write.write"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._copy_through", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._copy_through"], ["", "def", "_gru_encoder", "(", "cell", ",", "inputs", ",", "sequence_length", ",", "initial_state", ",", "dtype", "=", "None", ")", ":", "\n", "# Assume that the underlying cell is GRUCell-like", "\n", "    ", "output_size", "=", "cell", ".", "output_size", "\n", "dtype", "=", "dtype", "or", "inputs", ".", "dtype", "\n", "\n", "batch", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "\n", "zero_output", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "output_size", "]", ",", "dtype", ")", "\n", "\n", "if", "initial_state", "is", "None", ":", "\n", "        ", "initial_state", "=", "cell", ".", "zero_state", "(", "batch", ",", "dtype", ")", "\n", "\n", "", "input_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"input_array\"", ")", "\n", "output_ta", "=", "tf", ".", "TensorArray", "(", "dtype", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"output_array\"", ")", "\n", "input_ta", "=", "input_ta", ".", "unstack", "(", "tf", ".", "transpose", "(", "inputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", ")", "\n", "\n", "def", "loop_func", "(", "t", ",", "out_ta", ",", "state", ")", ":", "\n", "        ", "inp_t", "=", "input_ta", ".", "read", "(", "t", ")", "\n", "cell_output", ",", "new_state", "=", "cell", "(", "inp_t", ",", "state", ")", "\n", "cell_output", "=", "_copy_through", "(", "t", ",", "sequence_length", ",", "zero_output", ",", "\n", "cell_output", ")", "\n", "new_state", "=", "_copy_through", "(", "t", ",", "sequence_length", ",", "state", ",", "new_state", ")", "\n", "out_ta", "=", "out_ta", ".", "write", "(", "t", ",", "cell_output", ")", "\n", "return", "t", "+", "1", ",", "out_ta", ",", "new_state", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"time\"", ")", "\n", "loop_vars", "=", "(", "time", ",", "output_ta", ",", "initial_state", ")", "\n", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "lambda", "t", ",", "*", "_", ":", "t", "<", "time_steps", ",", "loop_func", ",", "\n", "loop_vars", ",", "parallel_iterations", "=", "32", ",", "\n", "swap_memory", "=", "True", ")", "\n", "\n", "output_final_ta", "=", "outputs", "[", "1", "]", "\n", "final_state", "=", "outputs", "[", "2", "]", "\n", "\n", "all_output", "=", "output_final_ta", ".", "stack", "(", ")", "\n", "all_output", ".", "set_shape", "(", "[", "None", ",", "None", ",", "output_size", "]", ")", "\n", "all_output", "=", "tf", ".", "transpose", "(", "all_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "return", "all_output", ",", "final_state", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._encoder": [[65, 98], ["tensorflow.variable_scope", "tensorflow.reverse_sequence", "tensorflow.variable_scope", "rnnsearch._gru_encoder", "tensorflow.variable_scope", "rnnsearch._gru_encoder", "tensorflow.reverse_sequence", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._gru_encoder", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._gru_encoder"], ["", "def", "_encoder", "(", "cell_fw", ",", "cell_bw", ",", "inputs", ",", "sequence_length", ",", "dtype", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"encoder\"", ",", "\n", "values", "=", "[", "inputs", ",", "sequence_length", "]", ")", ":", "\n", "        ", "inputs_fw", "=", "inputs", "\n", "inputs_bw", "=", "tf", ".", "reverse_sequence", "(", "inputs", ",", "sequence_length", ",", "\n", "batch_axis", "=", "0", ",", "seq_axis", "=", "1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"forward\"", ")", ":", "\n", "            ", "output_fw", ",", "state_fw", "=", "_gru_encoder", "(", "cell_fw", ",", "inputs_fw", ",", "\n", "sequence_length", ",", "None", ",", "\n", "dtype", "=", "dtype", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"backward\"", ")", ":", "\n", "            ", "output_bw", ",", "state_bw", "=", "_gru_encoder", "(", "cell_bw", ",", "inputs_bw", ",", "\n", "sequence_length", ",", "None", ",", "\n", "dtype", "=", "dtype", ")", "\n", "output_bw", "=", "tf", ".", "reverse_sequence", "(", "output_bw", ",", "sequence_length", ",", "\n", "batch_axis", "=", "0", ",", "seq_axis", "=", "1", ")", "\n", "\n", "", "results", "=", "{", "\n", "\"annotation\"", ":", "tf", ".", "concat", "(", "[", "output_fw", ",", "output_bw", "]", ",", "axis", "=", "2", ")", ",", "\n", "\"outputs\"", ":", "{", "\n", "\"forward\"", ":", "output_fw", ",", "\n", "\"backward\"", ":", "output_bw", "\n", "}", ",", "\n", "\"final_states\"", ":", "{", "\n", "\"forward\"", ":", "state_fw", ",", "\n", "\"backward\"", ":", "state_bw", "\n", "}", "\n", "}", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._decoder": [[100, 181], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.transpose", "tensorflow.sequence_mask", "thumt.attention.attention_bias", "tensorflow.squeeze", "thumt.attention.attention", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray", "input_ta.unstack.unstack", "thumt.nn.linear", "tensorflow.tanh", "tensorflow.constant", "tensorflow.while_loop", "output_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "value_final_ta.stack", "tf.transpose.set_shape", "tensorflow.transpose", "input_ta.unstack.read", "thumt.attention.attention", "cell", "rnnsearch._copy_through", "rnnsearch._copy_through", "rnnsearch._copy_through", "out_ta.write.write", "att_ta.write.write", "val_ta.write.write", "tensorflow.identity", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.attention_bias", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.attention", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.attention", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._copy_through", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._copy_through", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._copy_through"], ["", "", "def", "_decoder", "(", "cell", ",", "inputs", ",", "memory", ",", "sequence_length", ",", "initial_state", ",", "dtype", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "# Assume that the underlying cell is GRUCell-like", "\n", "    ", "batch", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "\n", "dtype", "=", "dtype", "or", "inputs", ".", "dtype", "\n", "output_size", "=", "cell", ".", "output_size", "\n", "zero_output", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "output_size", "]", ",", "dtype", ")", "\n", "zero_value", "=", "tf", ".", "zeros", "(", "[", "batch", ",", "memory", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ",", "dtype", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"decoder\"", ",", "dtype", "=", "dtype", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "transpose", "(", "inputs", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "mem_mask", "=", "tf", ".", "sequence_mask", "(", "sequence_length", "[", "\"source\"", "]", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "memory", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "mem_mask", ",", "\"masking\"", ")", "\n", "bias", "=", "tf", ".", "squeeze", "(", "bias", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "cache", "=", "layers", ".", "attention", ".", "attention", "(", "None", ",", "memory", ",", "None", ",", "output_size", ")", "\n", "\n", "input_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"input_array\"", ")", "\n", "output_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"output_array\"", ")", "\n", "value_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"value_array\"", ")", "\n", "alpha_ta", "=", "tf", ".", "TensorArray", "(", "tf", ".", "float32", ",", "time_steps", ",", "\n", "tensor_array_name", "=", "\"alpha_array\"", ")", "\n", "input_ta", "=", "input_ta", ".", "unstack", "(", "inputs", ")", "\n", "initial_state", "=", "layers", ".", "nn", ".", "linear", "(", "initial_state", ",", "output_size", ",", "True", ",", "\n", "False", ",", "scope", "=", "\"s_transform\"", ")", "\n", "initial_state", "=", "tf", ".", "tanh", "(", "initial_state", ")", "\n", "\n", "def", "loop_func", "(", "t", ",", "out_ta", ",", "att_ta", ",", "val_ta", ",", "state", ",", "cache_key", ")", ":", "\n", "            ", "inp_t", "=", "input_ta", ".", "read", "(", "t", ")", "\n", "results", "=", "layers", ".", "attention", ".", "attention", "(", "state", ",", "memory", ",", "bias", ",", "\n", "output_size", ",", "\n", "cache", "=", "{", "\"key\"", ":", "cache_key", "}", ")", "\n", "alpha", "=", "results", "[", "\"weight\"", "]", "\n", "context", "=", "results", "[", "\"value\"", "]", "\n", "cell_input", "=", "[", "inp_t", ",", "context", "]", "\n", "cell_output", ",", "new_state", "=", "cell", "(", "cell_input", ",", "state", ")", "\n", "cell_output", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "\n", "zero_output", ",", "cell_output", ")", "\n", "new_state", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "state", ",", "\n", "new_state", ")", "\n", "new_value", "=", "_copy_through", "(", "t", ",", "sequence_length", "[", "\"target\"", "]", ",", "zero_value", ",", "\n", "context", ")", "\n", "\n", "out_ta", "=", "out_ta", ".", "write", "(", "t", ",", "cell_output", ")", "\n", "att_ta", "=", "att_ta", ".", "write", "(", "t", ",", "alpha", ")", "\n", "val_ta", "=", "val_ta", ".", "write", "(", "t", ",", "new_value", ")", "\n", "cache_key", "=", "tf", ".", "identity", "(", "cache_key", ")", "\n", "return", "t", "+", "1", ",", "out_ta", ",", "att_ta", ",", "val_ta", ",", "new_state", ",", "cache_key", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "\"time\"", ")", "\n", "loop_vars", "=", "(", "time", ",", "output_ta", ",", "alpha_ta", ",", "value_ta", ",", "initial_state", ",", "\n", "cache", "[", "\"key\"", "]", ")", "\n", "\n", "outputs", "=", "tf", ".", "while_loop", "(", "lambda", "t", ",", "*", "_", ":", "t", "<", "time_steps", ",", "\n", "loop_func", ",", "loop_vars", ",", "\n", "parallel_iterations", "=", "32", ",", "\n", "swap_memory", "=", "True", ")", "\n", "\n", "output_final_ta", "=", "outputs", "[", "1", "]", "\n", "value_final_ta", "=", "outputs", "[", "3", "]", "\n", "\n", "final_output", "=", "output_final_ta", ".", "stack", "(", ")", "\n", "final_output", ".", "set_shape", "(", "[", "None", ",", "None", ",", "output_size", "]", ")", "\n", "final_output", "=", "tf", ".", "transpose", "(", "final_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "final_value", "=", "value_final_ta", ".", "stack", "(", ")", "\n", "final_value", ".", "set_shape", "(", "[", "None", ",", "None", ",", "memory", ".", "shape", "[", "-", "1", "]", ".", "value", "]", ")", "\n", "final_value", "=", "tf", ".", "transpose", "(", "final_value", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "result", "=", "{", "\n", "\"outputs\"", ":", "final_output", ",", "\n", "\"values\"", ":", "final_value", ",", "\n", "\"initial_state\"", ":", "initial_state", "\n", "}", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch.model_graph": [[183, 325], ["len", "len", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "thumt.rnn_cell.LegacyGRUCell", "thumt.rnn_cell.LegacyGRUCell", "rnnsearch._encoder", "thumt.rnn_cell.LegacyGRUCell", "rnnsearch._decoder", "tensorflow.pad", "tensorflow.concat", "thumt.nn.maxout", "thumt.nn.linear", "thumt.nn.linear", "tensorflow.reshape", "thumt.nn.smoothed_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.rnn_cell.DropoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper", "thumt.nn.maxout", "thumt.nn.linear", "thumt.nn.linear", "tensorflow.nn.dropout", "tensorflow.shape", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._encoder", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.rnnsearch._decoder", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.maxout", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.maxout", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear"], ["", "def", "model_graph", "(", "features", ",", "labels", ",", "params", ")", ":", "\n", "    ", "src_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", "\n", "tgt_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"source_embedding\"", ")", ":", "\n", "        ", "src_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "src_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "src_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "src_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "src_emb", ",", "features", "[", "\"source\"", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"target_embedding\"", ")", ":", "\n", "        ", "tgt_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "tgt_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "tgt_emb", ",", "features", "[", "\"target\"", "]", ")", "\n", "\n", "", "src_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "src_inputs", ",", "src_bias", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "tgt_inputs", ",", "tgt_bias", ")", "\n", "\n", "if", "params", ".", "dropout", "and", "not", "params", ".", "use_variational_dropout", ":", "\n", "        ", "src_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "src_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "tgt_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "# encoder", "\n", "", "cell_fw", "=", "layers", ".", "rnn_cell", ".", "LegacyGRUCell", "(", "params", ".", "hidden_size", ")", "\n", "cell_bw", "=", "layers", ".", "rnn_cell", ".", "LegacyGRUCell", "(", "params", ".", "hidden_size", ")", "\n", "\n", "if", "params", ".", "use_variational_dropout", ":", "\n", "        ", "cell_fw", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_fw", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "cell_bw", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_bw", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "", "encoder_output", "=", "_encoder", "(", "cell_fw", ",", "cell_bw", ",", "src_inputs", ",", "\n", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "# decoder", "\n", "cell", "=", "layers", ".", "rnn_cell", ".", "LegacyGRUCell", "(", "params", ".", "hidden_size", ")", "\n", "\n", "if", "params", ".", "use_variational_dropout", ":", "\n", "        ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "input_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "state_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "True", ",", "\n", "# input + context", "\n", "input_size", "=", "params", ".", "embedding_size", "+", "2", "*", "params", ".", "hidden_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "", "length", "=", "{", "\n", "\"source\"", ":", "features", "[", "\"source_length\"", "]", ",", "\n", "\"target\"", ":", "features", "[", "\"target_length\"", "]", "\n", "}", "\n", "initial_state", "=", "encoder_output", "[", "\"final_states\"", "]", "[", "\"backward\"", "]", "\n", "decoder_output", "=", "_decoder", "(", "cell", ",", "tgt_inputs", ",", "encoder_output", "[", "\"annotation\"", "]", ",", "\n", "length", ",", "initial_state", ")", "\n", "\n", "# Shift left", "\n", "shifted_tgt_inputs", "=", "tf", ".", "pad", "(", "tgt_inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "shifted_tgt_inputs", "=", "shifted_tgt_inputs", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "all_outputs", "=", "tf", ".", "concat", "(", "\n", "[", "\n", "tf", ".", "expand_dims", "(", "decoder_output", "[", "\"initial_state\"", "]", ",", "axis", "=", "1", ")", ",", "\n", "decoder_output", "[", "\"outputs\"", "]", ",", "\n", "]", ",", "\n", "axis", "=", "1", "\n", ")", "\n", "shifted_outputs", "=", "all_outputs", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "maxout_features", "=", "[", "\n", "shifted_tgt_inputs", ",", "\n", "shifted_outputs", ",", "\n", "decoder_output", "[", "\"values\"", "]", "\n", "]", "\n", "maxout_size", "=", "params", ".", "hidden_size", "//", "params", ".", "maxnum", "\n", "\n", "if", "labels", "is", "None", ":", "\n", "# Special case for non-incremental decoding", "\n", "        ", "maxout_features", "=", "[", "\n", "shifted_tgt_inputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "\n", "shifted_outputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "\n", "decoder_output", "[", "\"values\"", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "]", "\n", "maxhid", "=", "layers", ".", "nn", ".", "maxout", "(", "maxout_features", ",", "maxout_size", ",", "params", ".", "maxnum", ",", "\n", "concat", "=", "False", ")", "\n", "readout", "=", "layers", ".", "nn", ".", "linear", "(", "maxhid", ",", "params", ".", "embedding_size", ",", "False", ",", "\n", "False", ",", "scope", "=", "\"deepout\"", ")", "\n", "\n", "# Prediction", "\n", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "readout", ",", "tgt_vocab_size", ",", "True", ",", "False", ",", "\n", "scope", "=", "\"softmax\"", ")", "\n", "\n", "return", "logits", "\n", "\n", "", "maxhid", "=", "layers", ".", "nn", ".", "maxout", "(", "maxout_features", ",", "maxout_size", ",", "params", ".", "maxnum", ",", "\n", "concat", "=", "False", ")", "\n", "readout", "=", "layers", ".", "nn", ".", "linear", "(", "maxhid", ",", "params", ".", "embedding_size", ",", "False", ",", "False", ",", "\n", "scope", "=", "\"deepout\"", ")", "\n", "\n", "if", "params", ".", "dropout", "and", "not", "params", ".", "use_variational_dropout", ":", "\n", "        ", "readout", "=", "tf", ".", "nn", ".", "dropout", "(", "readout", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "# Prediction", "\n", "", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "readout", ",", "tgt_vocab_size", ",", "True", ",", "False", ",", "\n", "scope", "=", "\"softmax\"", ")", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", ",", "tgt_vocab_size", "]", ")", "\n", "\n", "ce", "=", "layers", ".", "nn", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "labels", ")", ")", "\n", "tgt_mask", "=", "tf", ".", "to_float", "(", "\n", "tf", ".", "sequence_mask", "(", "\n", "features", "[", "\"target_length\"", "]", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", "\n", ")", "\n", ")", "\n", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.seq2seq.Seq2Seq.__init__": [[131, 133], ["thumt.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"seq2seq\"", ")", ":", "\n", "        ", "super", "(", "Seq2Seq", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.seq2seq.Seq2Seq.get_training_func": [[134, 144], ["tensorflow.variable_scope", "seq2seq.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "self", ".", "parameters", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "features", "[", "\"target\"", "]", ",", "params", ")", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.seq2seq.Seq2Seq.get_evaluation_func": [[145, 161], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "seq2seq.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.seq2seq.Seq2Seq.get_inference_func": [[162, 178], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "seq2seq.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "inference_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "", "params", ".", "dropout", "=", "0.0", "\n", "params", ".", "use_variational_dropout", "=", "False", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "inference_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.seq2seq.Seq2Seq.get_name": [[179, 182], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"seq2seq\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.seq2seq.Seq2Seq.get_parameters": [[183, 210], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "# vocabulary", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "append_eos", "=", "False", ",", "\n", "# model", "\n", "rnn_cell", "=", "\"LSTMCell\"", ",", "\n", "embedding_size", "=", "1000", ",", "\n", "hidden_size", "=", "1000", ",", "\n", "num_hidden_layers", "=", "4", ",", "\n", "# regularization", "\n", "dropout", "=", "0.2", ",", "\n", "use_variational_dropout", "=", "False", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "constant_batch_size", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "\n", "max_length", "=", "80", ",", "\n", "reverse_source", "=", "True", ",", "\n", "use_residual", "=", "True", ",", "\n", "clip_grad_norm", "=", "5.0", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.seq2seq.model_graph": [[15, 128], ["len", "len", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "range", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.nn.rnn_cell.MultiRNNCell", "tensorflow.pad", "thumt.nn.linear", "tensorflow.reshape", "thumt.nn.smoothed_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.reverse_sequence", "tensorflow.device", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.rnn_cell.DropoutWrapper", "tensorflow.nn.rnn_cell.DropoutWrapper", "tf.nn.rnn_cell.MultiRNNCell.append", "tf.nn.rnn_cell.MultiRNNCell.append", "tensorflow.variable_scope", "tensorflow.nn.dynamic_rnn", "tensorflow.variable_scope", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dropout", "thumt.nn.linear", "tensorflow.shape", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.nn.rnn_cell.BasicLSTMCell", "tensorflow.nn.rnn_cell.BasicLSTMCell", "tensorflow.nn.rnn_cell.ResidualWrapper", "tensorflow.nn.rnn_cell.ResidualWrapper", "tensorflow.nn.rnn_cell.GRUCell", "tensorflow.nn.rnn_cell.GRUCell", "ValueError", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear"], ["def", "model_graph", "(", "features", ",", "labels", ",", "params", ")", ":", "\n", "    ", "src_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", "\n", "tgt_vocab_size", "=", "len", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", "\n", "\n", "src_seq", "=", "features", "[", "\"source\"", "]", "\n", "tgt_seq", "=", "features", "[", "\"target\"", "]", "\n", "\n", "if", "params", ".", "reverse_source", ":", "\n", "        ", "src_seq", "=", "tf", ".", "reverse_sequence", "(", "src_seq", ",", "seq_dim", "=", "1", ",", "\n", "seq_lengths", "=", "features", "[", "\"source_length\"", "]", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"source_embedding\"", ")", ":", "\n", "            ", "src_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "src_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "src_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "src_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "src_emb", ",", "src_seq", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"target_embedding\"", ")", ":", "\n", "            ", "tgt_emb", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "params", ".", "embedding_size", "]", ")", "\n", "tgt_bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "params", ".", "embedding_size", "]", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "tgt_emb", ",", "tgt_seq", ")", "\n", "\n", "", "", "src_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "src_inputs", ",", "src_bias", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "tgt_inputs", ",", "tgt_bias", ")", "\n", "\n", "if", "params", ".", "dropout", "and", "not", "params", ".", "use_variational_dropout", ":", "\n", "        ", "src_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "src_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "tgt_inputs", "=", "tf", ".", "nn", ".", "dropout", "(", "tgt_inputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "", "cell_enc", "=", "[", "]", "\n", "cell_dec", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "params", ".", "num_hidden_layers", ")", ":", "\n", "        ", "if", "params", ".", "rnn_cell", "==", "\"LSTMCell\"", ":", "\n", "            ", "cell_e", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "cell_d", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "BasicLSTMCell", "(", "params", ".", "hidden_size", ")", "\n", "", "elif", "params", ".", "rnn_cell", "==", "\"GRUCell\"", ":", "\n", "            ", "cell_e", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "params", ".", "hidden_size", ")", "\n", "cell_d", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "params", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"%s not supported\"", "%", "params", ".", "rnn_cell", ")", "\n", "\n", "", "cell_e", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_e", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "params", ".", "use_variational_dropout", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "cell_d", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell_d", ",", "\n", "output_keep_prob", "=", "1.0", "-", "params", ".", "dropout", ",", "\n", "variational_recurrent", "=", "params", ".", "use_variational_dropout", ",", "\n", "input_size", "=", "params", ".", "embedding_size", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "\n", "if", "params", ".", "use_residual", ":", "\n", "            ", "cell_e", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "ResidualWrapper", "(", "cell_e", ")", "\n", "cell_d", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "ResidualWrapper", "(", "cell_d", ")", "\n", "\n", "", "cell_enc", ".", "append", "(", "cell_e", ")", "\n", "cell_dec", ".", "append", "(", "cell_d", ")", "\n", "\n", "", "cell_enc", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "cell_enc", ")", "\n", "cell_dec", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "cell_dec", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ")", ":", "\n", "        ", "_", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell_enc", ",", "src_inputs", ",", "\n", "features", "[", "\"source_length\"", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Shift left", "\n", "", "shifted_tgt_inputs", "=", "tf", ".", "pad", "(", "tgt_inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "shifted_tgt_inputs", "=", "shifted_tgt_inputs", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ")", ":", "\n", "        ", "outputs", ",", "_", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell_dec", ",", "shifted_tgt_inputs", ",", "\n", "features", "[", "\"target_length\"", "]", ",", "\n", "initial_state", "=", "final_state", ")", "\n", "\n", "", "if", "params", ".", "dropout", ":", "\n", "        ", "outputs", "=", "tf", ".", "nn", ".", "dropout", "(", "outputs", ",", "1.0", "-", "params", ".", "dropout", ")", "\n", "\n", "", "if", "labels", "is", "None", ":", "\n", "# Prediction", "\n", "        ", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "outputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "tgt_vocab_size", ",", "True", ",", "\n", "scope", "=", "\"softmax\"", ")", "\n", "\n", "return", "logits", "\n", "\n", "# Prediction", "\n", "", "logits", "=", "layers", ".", "nn", ".", "linear", "(", "outputs", ",", "tgt_vocab_size", ",", "True", ",", "scope", "=", "\"softmax\"", ")", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "-", "1", ",", "tgt_vocab_size", "]", ")", "\n", "\n", "ce", "=", "layers", ".", "nn", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "labels", ")", ")", "\n", "tgt_mask", "=", "tf", ".", "to_float", "(", "\n", "tf", ".", "sequence_mask", "(", "\n", "features", "[", "\"target_length\"", "]", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", "\n", ")", "\n", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.__init__.get_model": [[13, 24], ["name.lower.lower", "LookupError"], "function", ["None"], []], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.__init__": [[300, 302], ["thumt.NMTModel.__init__"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "scope", "=", "\"transformer\"", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", "params", "=", "params", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_training_func": [[303, 314], ["tensorflow.variable_scope", "transformer.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_training_func", "(", "self", ",", "initializer", ")", ":", "\n", "        ", "def", "training_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "self", ".", "parameters", "\n", "", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "initializer", "=", "initializer", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "loss", "=", "model_graph", "(", "features", ",", "features", "[", "\"target\"", "]", ",", "\n", "\"train\"", ",", "params", ")", "\n", "return", "loss", "\n", "\n", "", "", "return", "training_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_evaluation_func": [[315, 333], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_evaluation_func", "(", "self", ")", ":", "\n", "        ", "def", "evaluation_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ")", ":", "\n", "                ", "logits", "=", "model_graph", "(", "features", ",", "None", ",", "\"infer\"", ",", "params", ")", "\n", "\n", "", "return", "logits", "\n", "\n", "", "return", "evaluation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_inference_func": [[334, 370], ["copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer.model_graph", "copy.copy", "copy.copy", "tensorflow.variable_scope", "transformer.model_graph"], "methods", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph"], ["", "def", "get_inference_func", "(", "self", ")", ":", "\n", "        ", "def", "inference_encoder_fn", "(", "features", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "# SEARCH", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "encoder_output", ",", "src_mask", "=", "model_graph", "(", "features", ",", "None", ",", "\"encoder\"", ",", "params", ")", "\n", "\n", "", "return", "encoder_output", ",", "src_mask", "\n", "\n", "", "def", "inference_decoder_fn", "(", "features", ",", "encoder_output", ",", "src_mask", ",", "decoder_output", ",", "position", ",", "params", "=", "None", ")", ":", "\n", "            ", "if", "params", "is", "None", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "self", ".", "parameters", ")", "\n", "", "else", ":", "\n", "                ", "params", "=", "copy", ".", "copy", "(", "params", ")", "\n", "\n", "", "params", ".", "residual_dropout", "=", "0.0", "\n", "params", ".", "attention_dropout", "=", "0.0", "\n", "params", ".", "relu_dropout", "=", "0.0", "\n", "params", ".", "label_smoothing", "=", "0.0", "\n", "\n", "# SEARCH", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_scope", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "logits", ",", "decoder_output", "=", "model_graph", "(", "features", ",", "None", ",", "\"decoder\"", ",", "params", ",", "given_memory", "=", "encoder_output", ",", "given_src_mask", "=", "src_mask", ",", "given_decoder", "=", "decoder_output", ",", "given_position", "=", "position", ")", "\n", "\n", "", "return", "logits", ",", "decoder_output", "\n", "\n", "", "return", "inference_encoder_fn", ",", "inference_decoder_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_name": [[372, 375], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_name", "(", ")", ":", "\n", "        ", "return", "\"transformer\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.Transformer.get_parameters": [[376, 416], ["tensorflow.contrib.training.HParams"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_parameters", "(", ")", ":", "\n", "        ", "params", "=", "tf", ".", "contrib", ".", "training", ".", "HParams", "(", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "bos", "=", "\"<eos>\"", ",", "\n", "eos", "=", "\"<eos>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "append_eos", "=", "False", ",", "\n", "hidden_size", "=", "512", ",", "\n", "filter_size", "=", "2048", ",", "\n", "num_heads", "=", "8", ",", "\n", "num_encoder_layers", "=", "6", ",", "\n", "num_decoder_layers", "=", "6", ",", "\n", "attention_dropout", "=", "0.0", ",", "\n", "residual_dropout", "=", "0.1", ",", "\n", "relu_dropout", "=", "0.0", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "attention_key_channels", "=", "0", ",", "\n", "attention_value_channels", "=", "0", ",", "\n", "multiply_embedding_mode", "=", "\"sqrt_depth\"", ",", "\n", "shared_embedding_and_softmax_weights", "=", "False", ",", "\n", "shared_source_target_embedding", "=", "False", ",", "\n", "# Override default parameters", "\n", "learning_rate_decay", "=", "\"noam\"", ",", "\n", "initializer", "=", "\"uniform_unit_scaling\"", ",", "\n", "initializer_gain", "=", "1.0", ",", "\n", "learning_rate", "=", "1.0", ",", "\n", "layer_preprocess", "=", "\"none\"", ",", "\n", "layer_postprocess", "=", "\"layer_norm\"", ",", "\n", "batch_size", "=", "4096", ",", "\n", "constant_batch_size", "=", "False", ",", "\n", "adam_beta1", "=", "0.9", ",", "\n", "adam_beta2", "=", "0.98", ",", "\n", "adam_epsilon", "=", "1e-9", ",", "\n", "clip_grad_norm", "=", "0.0", ",", "\n", "aan_mask", "=", "True", ",", "\n", "use_ffn", "=", "False", ",", "\n", ")", "\n", "\n", "return", "params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.get_weights": [[15, 47], ["len", "len", "tensorflow.random_normal_initializer", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "cmp", "ValueError"], "function", ["None"], ["def", "get_weights", "(", "params", ")", ":", "\n", "    ", "svocab", "=", "params", ".", "vocabulary", "[", "\"source\"", "]", "\n", "tvocab", "=", "params", ".", "vocabulary", "[", "\"target\"", "]", "\n", "src_vocab_size", "=", "len", "(", "svocab", ")", "\n", "tgt_vocab_size", "=", "len", "(", "tvocab", ")", "\n", "vocab_size", "=", "tgt_vocab_size", "\n", "\n", "hidden_size", "=", "params", ".", "hidden_size", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.0", ",", "params", ".", "hidden_size", "**", "-", "0.5", ")", "\n", "\n", "if", "params", ".", "shared_source_target_embedding", ":", "\n", "        ", "if", "cmp", "(", "svocab", ",", "tvocab", ")", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Source and target vocabularies are not the same\"", ")", "\n", "\n", "", "weights", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "semb", ",", "temb", "=", "weights", ",", "weights", "\n", "", "else", ":", "\n", "        ", "semb", "=", "tf", ".", "get_variable", "(", "\"source_embedding\"", ",", "\n", "[", "src_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "temb", "=", "tf", ".", "get_variable", "(", "\"target_embedding\"", ",", "\n", "[", "tgt_vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "\n", "", "if", "params", ".", "shared_embedding_and_softmax_weights", ":", "\n", "        ", "softmax_weights", "=", "temb", "\n", "", "else", ":", "\n", "        ", "softmax_weights", "=", "tf", ".", "get_variable", "(", "\"softmax\"", ",", "[", "vocab_size", ",", "hidden_size", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "\n", "", "return", "semb", ",", "temb", ",", "softmax_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process": [[49, 56], ["thumt.nn.layer_norm", "ValueError"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.layer_norm"], ["", "def", "layer_process", "(", "x", ",", "mode", ")", ":", "\n", "    ", "if", "not", "mode", "or", "mode", "==", "\"none\"", ":", "\n", "        ", "return", "x", "\n", "", "elif", "mode", "==", "\"layer_norm\"", ":", "\n", "        ", "return", "layers", ".", "nn", ".", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown mode %s\"", "%", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.residual_fn": [[58, 62], ["tensorflow.nn.dropout"], "function", ["None"], ["", "", "def", "residual_fn", "(", "x", ",", "y", ",", "keep_prob", "=", "None", ")", ":", "\n", "    ", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "        ", "y", "=", "tf", ".", "nn", ".", "dropout", "(", "y", ",", "keep_prob", ")", "\n", "", "return", "x", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.ffn_layer": [[64, 79], ["tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.nn.linear", "tensorflow.nn.relu", "tensorflow.nn.dropout", "tensorflow.variable_scope", "thumt.nn.linear"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear"], ["", "def", "ffn_layer", "(", "inputs", ",", "hidden_size", ",", "output_size", ",", "keep_prob", "=", "None", ",", "\n", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"ffn_layer\"", ",", "values", "=", "[", "inputs", "]", ",", "\n", "dtype", "=", "dtype", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"input_layer\"", ")", ":", "\n", "            ", "hidden", "=", "layers", ".", "nn", ".", "linear", "(", "inputs", ",", "hidden_size", ",", "True", ",", "True", ")", "\n", "hidden", "=", "tf", ".", "nn", ".", "relu", "(", "hidden", ")", "\n", "\n", "", "if", "keep_prob", "and", "keep_prob", "<", "1.0", ":", "\n", "            ", "hidden", "=", "tf", ".", "nn", ".", "dropout", "(", "hidden", ",", "keep_prob", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"output_layer\"", ")", ":", "\n", "            ", "output", "=", "layers", ".", "nn", ".", "linear", "(", "hidden", ",", "output_size", ",", "True", ",", "True", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.transformer_encoder": [[81, 115], ["tensorflow.variable_scope", "range", "transformer.layer_process", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer.residual_fn", "transformer.layer_process", "tensorflow.variable_scope", "transformer.ffn_layer", "transformer.residual_fn", "transformer.layer_process", "transformer.layer_process", "transformer.layer_process"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.residual_fn", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.ffn_layer", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.residual_fn", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process"], ["", "", "def", "transformer_encoder", "(", "inputs", ",", "bias", ",", "params", ",", "pos", "=", "None", ",", "dtype", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"encoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "bias", "]", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_encoder_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"self_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "None", ",", "\n", "bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", ",", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "ffn_layer", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", ")", "\n", "x", "=", "residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "", "", "outputs", "=", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.transformer_decoder": [[117, 186], ["tensorflow.variable_scope", "range", "transformer.layer_process", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.variable_scope", "thumt.nn.linear", "tensorflow.split", "transformer.residual_fn", "transformer.layer_process", "tensorflow.variable_scope", "thumt.attention.multihead_attention", "transformer.residual_fn", "transformer.layer_process", "tensorflow.variable_scope", "transformer.ffn_layer", "transformer.residual_fn", "transformer.layer_process", "tf.concat.append", "transformer.ffn_layer", "tensorflow.concat", "transformer.layer_process", "transformer.layer_process", "tensorflow.expand_dims", "tensorflow.matmul", "transformer.layer_process", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.cumsum"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.linear", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.residual_fn", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.multihead_attention", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.residual_fn", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.ffn_layer", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.residual_fn", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.ffn_layer", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.layer_process"], ["", "", "def", "transformer_decoder", "(", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", ",", "params", ",", "pos", "=", "None", ",", "dtype", "=", "None", ",", "\n", "scope", "=", "None", ",", "given_inputs", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"decoder\"", ",", "dtype", "=", "dtype", ",", "\n", "values", "=", "[", "inputs", ",", "memory", ",", "bias", ",", "mem_bias", "]", "+", "pos", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "decoding_outputs", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "params", ".", "num_decoder_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer", ")", ":", "\n", "# The Average Attention Network", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"position_forward\"", ")", ":", "\n", "# Cumulative Summing", "\n", "                    ", "if", "given_inputs", "is", "not", "None", ":", "\n", "                        ", "x_fwd", "=", "(", "x", "+", "given_inputs", "[", "layer", "]", ")", "/", "pos", "[", "0", "]", "\n", "decoding_outputs", ".", "append", "(", "tf", ".", "expand_dims", "(", "x", "+", "given_inputs", "[", "layer", "]", ",", "axis", "=", "0", ")", ")", "\n", "", "else", ":", "\n", "                        ", "if", "not", "params", ".", "aan_mask", ":", "\n", "                            ", "x_fwd", "=", "tf", ".", "cumsum", "(", "x", ",", "axis", "=", "1", ")", "/", "pos", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "x_fwd", "=", "tf", ".", "matmul", "(", "pos", "[", "0", "]", ",", "x", ")", "\n", "# FFN activation", "\n", "", "", "if", "params", ".", "use_ffn", ":", "\n", "                        ", "y", "=", "ffn_layer", "(", "\n", "layer_process", "(", "x_fwd", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "y", "=", "x_fwd", "\n", "\n", "# Gating layer", "\n", "", "z", "=", "layers", ".", "nn", ".", "linear", "(", "tf", ".", "concat", "(", "[", "x", ",", "y", "]", ",", "axis", "=", "-", "1", ")", ",", "\n", "params", ".", "hidden_size", "*", "2", ",", "True", ",", "True", ",", "scope", "=", "\"z_project\"", ")", "\n", "i", ",", "f", "=", "tf", ".", "split", "(", "z", ",", "[", "params", ".", "hidden_size", ",", "params", ".", "hidden_size", "]", ",", "axis", "=", "-", "1", ")", "\n", "y", "=", "tf", ".", "sigmoid", "(", "i", ")", "*", "x", "+", "tf", ".", "sigmoid", "(", "f", ")", "*", "y", "\n", "\n", "x", "=", "residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"encdec_attention\"", ")", ":", "\n", "                    ", "y", "=", "layers", ".", "attention", ".", "multihead_attention", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "memory", ",", "\n", "mem_bias", ",", "\n", "params", ".", "num_heads", ",", "\n", "params", ".", "attention_key_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "attention_value_channels", "or", "params", ".", "hidden_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "attention_dropout", "\n", ")", "\n", "y", "=", "y", "[", "\"outputs\"", "]", "\n", "x", "=", "residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"feed_forward\"", ")", ":", "\n", "                    ", "y", "=", "ffn_layer", "(", "\n", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", ",", "\n", "params", ".", "filter_size", ",", "\n", "params", ".", "hidden_size", ",", "\n", "1.0", "-", "params", ".", "relu_dropout", ",", "\n", ")", "\n", "x", "=", "residual_fn", "(", "x", ",", "y", ",", "1.0", "-", "params", ".", "residual_dropout", ")", "\n", "x", "=", "layer_process", "(", "x", ",", "params", ".", "layer_postprocess", ")", "\n", "\n", "", "", "", "outputs", "=", "layer_process", "(", "x", ",", "params", ".", "layer_preprocess", ")", "\n", "\n", "if", "given_inputs", "is", "not", "None", ":", "\n", "            ", "decoding_outputs", "=", "tf", ".", "concat", "(", "decoding_outputs", ",", "axis", "=", "0", ")", "\n", "", "return", "outputs", ",", "decoding_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.model_graph": [[188, 297], ["tensorflow.sequence_mask", "tensorflow.sequence_mask", "transformer.get_weights", "tensorflow.get_variable", "tensorflow.nn.bias_add", "thumt.attention.add_timing_signal", "thumt.attention.attention_bias", "thumt.attention.attention_bias", "thumt.attention.add_timing_signal", "transformer.transformer_encoder", "transformer.transformer_decoder", "tensorflow.reshape", "tensorflow.matmul", "thumt.nn.smoothed_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.gather", "tensorflow.gather", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.cumsum", "tensorflow.where", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.matmul", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.less_equal", "tensorflow.ones_like", "tensorflow.cast", "thumt.attention.attention_bias", "tensorflow.cumsum", "tensorflow.where", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.pad", "tensorflow.shape", "tensorflow.shape", "tensorflow.less_equal", "tensorflow.ones_like", "tensorflow.cast", "tensorflow.to_int32", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.get_weights", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.attention_bias", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.attention_bias", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.add_timing_signal", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.transformer_encoder", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.models.transformer.transformer_decoder", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.nn.smoothed_softmax_cross_entropy_with_logits", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.layers.attention.attention_bias"], ["", "", "def", "model_graph", "(", "features", ",", "labels", ",", "mode", ",", "params", ",", "given_memory", "=", "None", ",", "given_src_mask", "=", "None", ",", "given_decoder", "=", "None", ",", "given_position", "=", "None", ")", ":", "\n", "    ", "hidden_size", "=", "params", ".", "hidden_size", "\n", "\n", "src_seq", "=", "features", "[", "\"source\"", "]", "\n", "tgt_seq", "=", "features", "[", "\"target\"", "]", "\n", "src_len", "=", "features", "[", "\"source_length\"", "]", "\n", "tgt_len", "=", "features", "[", "\"target_length\"", "]", "\n", "src_mask", "=", "tf", ".", "sequence_mask", "(", "src_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"source\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "if", "given_src_mask", "is", "not", "None", ":", "\n", "        ", "src_mask", "=", "given_src_mask", "\n", "", "tgt_mask", "=", "tf", ".", "sequence_mask", "(", "tgt_len", ",", "\n", "maxlen", "=", "tf", ".", "shape", "(", "features", "[", "\"target\"", "]", ")", "[", "1", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "src_embedding", ",", "tgt_embedding", ",", "weights", "=", "get_weights", "(", "params", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "hidden_size", "]", ")", "\n", "\n", "# id => embedding", "\n", "# src_seq: [batch, max_src_length]", "\n", "# tgt_seq: [batch, max_tgt_length]", "\n", "inputs", "=", "tf", ".", "gather", "(", "src_embedding", ",", "src_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "targets", "=", "tf", ".", "gather", "(", "tgt_embedding", ",", "tgt_seq", ")", "*", "(", "hidden_size", "**", "0.5", ")", "\n", "inputs", "=", "inputs", "*", "tf", ".", "expand_dims", "(", "src_mask", ",", "-", "1", ")", "\n", "targets", "=", "targets", "*", "tf", ".", "expand_dims", "(", "tgt_mask", ",", "-", "1", ")", "\n", "\n", "# Preparing encoder & decoder input", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "bias_add", "(", "inputs", ",", "bias", ")", "\n", "encoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "encoder_input", ")", "\n", "enc_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "src_mask", ",", "\"masking\"", ")", "\n", "dec_attn_bias", "=", "layers", ".", "attention", ".", "attention_bias", "(", "tf", ".", "shape", "(", "targets", ")", "[", "1", "]", ",", "\n", "\"causal\"", ")", "\n", "\n", "if", "given_decoder", "is", "not", "None", ":", "\n", "        ", "dec_pos_bias_fwd", "=", "tf", ".", "cumsum", "(", "tgt_mask", ",", "axis", "=", "1", ")", "\n", "dec_pos_bias_fwd", "=", "tf", ".", "where", "(", "tf", ".", "less_equal", "(", "dec_pos_bias_fwd", ",", "0.", ")", ",", "tf", ".", "ones_like", "(", "dec_pos_bias_fwd", ")", ",", "dec_pos_bias_fwd", ")", "\n", "dec_pos_bias_fwd", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "dec_pos_bias_fwd", ",", "tf", ".", "float32", ")", ",", "2", ")", "\n", "", "else", ":", "\n", "        ", "if", "params", ".", "aan_mask", ":", "\n", "            ", "dec_pos_bias_fwd", "=", "layers", ".", "attention", ".", "attention_bias", "(", "tgt_mask", ",", "\"aan\"", ")", "\n", "", "else", ":", "\n", "            ", "dec_pos_bias_fwd", "=", "tf", ".", "cumsum", "(", "tgt_mask", ",", "axis", "=", "1", ")", "\n", "dec_pos_bias_fwd", "=", "tf", ".", "where", "(", "tf", ".", "less_equal", "(", "dec_pos_bias_fwd", ",", "0.", ")", ",", "tf", ".", "ones_like", "(", "dec_pos_bias_fwd", ")", ",", "dec_pos_bias_fwd", ")", "\n", "dec_pos_bias_fwd", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "dec_pos_bias_fwd", ",", "tf", ".", "float32", ")", ",", "2", ")", "\n", "\n", "# Shift left", "\n", "# If given_decoer is not None, indicating a inference procedure,", "\n", "", "", "if", "given_decoder", "is", "not", "None", ":", "\n", "# given_position: starts from 1, a value greater than 1 means non-start position", "\n", "        ", "decoder_input", "=", "targets", "*", "tf", ".", "to_float", "(", "given_position", ">", "1.", ")", "\n", "decoder_input", "=", "tf", ".", "tile", "(", "decoder_input", ",", "[", "1", ",", "tf", ".", "to_int32", "(", "given_position", ")", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "decoder_input", "=", "tf", ".", "pad", "(", "targets", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "# This is a lazy implementation, to assign the correct position embedding, I simply copy the", "\n", "# current decoder input 'given_position' times, and assign the whole position embeddings,", "\n", "# Only the last decoding value has the meaningful position embeddings", "\n", "# TODO: With Average Attention Network, Decoder side position embedding may be unnecessary ", "\n", "", "decoder_input", "=", "layers", ".", "attention", ".", "add_timing_signal", "(", "decoder_input", ")", "\n", "if", "given_decoder", "is", "not", "None", ":", "\n", "        ", "decoder_input", "=", "decoder_input", "[", ":", ",", "-", "1", ":", ",", ":", "]", "\n", "\n", "", "if", "params", ".", "residual_dropout", ":", "\n", "        ", "keep_prob", "=", "1.0", "-", "params", ".", "residual_dropout", "\n", "encoder_input", "=", "tf", ".", "nn", ".", "dropout", "(", "encoder_input", ",", "keep_prob", ")", "\n", "decoder_input", "=", "tf", ".", "nn", ".", "dropout", "(", "decoder_input", ",", "keep_prob", ")", "\n", "\n", "", "encoder_output", "=", "transformer_encoder", "(", "encoder_input", ",", "enc_attn_bias", ",", "params", ",", "pos", "=", "[", "None", "]", ")", "\n", "# Given memory indicates the source-side encoding output during inference", "\n", "if", "given_memory", "is", "not", "None", ":", "\n", "        ", "encoder_output", "=", "given_memory", "\n", "# During inference, the bias for decoder is exactly the decoding position ", "\n", "", "if", "given_position", "is", "not", "None", ":", "\n", "        ", "dec_pos_bias_fwd", "=", "given_position", "\n", "", "decoder_output", ",", "decoder_outputs", "=", "transformer_decoder", "(", "decoder_input", ",", "encoder_output", ",", "\n", "dec_attn_bias", ",", "enc_attn_bias", ",", "params", ",", "pos", "=", "[", "dec_pos_bias_fwd", "]", ",", "given_inputs", "=", "given_decoder", ")", "\n", "\n", "# inference mode, take the last position", "\n", "if", "mode", "==", "\"infer\"", ":", "\n", "        ", "decoder_output", "=", "decoder_output", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "logits", "=", "tf", ".", "matmul", "(", "decoder_output", ",", "weights", ",", "False", ",", "True", ")", "\n", "\n", "return", "logits", "\n", "# SEARCH", "\n", "", "elif", "mode", "==", "\"encoder\"", ":", "\n", "        ", "return", "encoder_output", ",", "src_mask", "\n", "# Particularly for AAN decoding, we need the last decoding states for acceleration", "\n", "", "elif", "mode", "==", "\"decoder\"", ":", "\n", "        ", "decoder_output", "=", "decoder_output", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "logits", "=", "tf", ".", "matmul", "(", "decoder_output", ",", "weights", ",", "False", ",", "True", ")", "\n", "\n", "return", "logits", ",", "decoder_outputs", "\n", "\n", "# [batch, length, channel] => [batch * length, vocab_size]", "\n", "", "decoder_output", "=", "tf", ".", "reshape", "(", "decoder_output", ",", "[", "-", "1", ",", "hidden_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "decoder_output", ",", "weights", ",", "False", ",", "True", ")", "\n", "\n", "# label smoothing", "\n", "ce", "=", "layers", ".", "nn", ".", "smoothed_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", ",", "\n", "smoothing", "=", "params", ".", "label_smoothing", ",", "\n", "normalize", "=", "True", "\n", ")", "\n", "\n", "ce", "=", "tf", ".", "reshape", "(", "ce", ",", "tf", ".", "shape", "(", "tgt_seq", ")", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "ce", "*", "tgt_mask", ")", "/", "tf", ".", "reduce_sum", "(", "tgt_mask", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.batch_examples": [[15, 82], ["tensorflow.name_scope", "example.values", "tensorflow.contrib.training.bucket_by_sequence_length", "boundaries.append", "max", "max", "tensorflow.maximum", "tensorflow.shape", "int", "math.log"], "function", ["None"], ["def", "batch_examples", "(", "example", ",", "batch_size", ",", "max_length", ",", "mantissa_bits", ",", "\n", "shard_multiplier", "=", "1", ",", "length_multiplier", "=", "1", ",", "constant", "=", "False", ",", "\n", "num_threads", "=", "4", ",", "drop_long_sequences", "=", "True", ")", ":", "\n", "    ", "\"\"\" Batch examples\n\n    :param example: A dictionary of <feature name, Tensor>.\n    :param batch_size: The number of tokens or sentences in a batch\n    :param max_length: The maximum length of a example to keep\n    :param mantissa_bits: An integer\n    :param shard_multiplier: an integer increasing the batch_size to suit\n        splitting across data shards.\n    :param length_multiplier: an integer multiplier that is used to\n        increase the batch sizes and sequence length tolerance.\n    :param constant: Whether to use constant batch size\n    :param num_threads: Number of threads\n    :param drop_long_sequences: Whether to drop long sequences\n\n    :returns: A dictionary of batched examples\n    \"\"\"", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"batch_examples\"", ")", ":", "\n", "        ", "max_length", "=", "max_length", "or", "batch_size", "\n", "min_length", "=", "8", "\n", "mantissa_bits", "=", "mantissa_bits", "\n", "\n", "# Compute boundaries", "\n", "x", "=", "min_length", "\n", "boundaries", "=", "[", "]", "\n", "\n", "while", "x", "<", "max_length", ":", "\n", "            ", "boundaries", ".", "append", "(", "x", ")", "\n", "x", "+=", "2", "**", "max", "(", "0", ",", "int", "(", "math", ".", "log", "(", "x", ",", "2", ")", ")", "-", "mantissa_bits", ")", "\n", "\n", "# Whether the batch size is constant", "\n", "", "if", "not", "constant", ":", "\n", "            ", "batch_sizes", "=", "[", "max", "(", "1", ",", "batch_size", "//", "length", ")", "\n", "for", "length", "in", "boundaries", "+", "[", "max_length", "]", "]", "\n", "batch_sizes", "=", "[", "b", "*", "shard_multiplier", "for", "b", "in", "batch_sizes", "]", "\n", "bucket_capacities", "=", "[", "2", "*", "b", "for", "b", "in", "batch_sizes", "]", "\n", "", "else", ":", "\n", "            ", "batch_sizes", "=", "batch_size", "*", "shard_multiplier", "\n", "bucket_capacities", "=", "[", "2", "*", "n", "for", "n", "in", "boundaries", "+", "[", "max_length", "]", "]", "\n", "\n", "", "max_length", "*=", "length_multiplier", "\n", "boundaries", "=", "[", "boundary", "*", "length_multiplier", "for", "boundary", "in", "boundaries", "]", "\n", "max_length", "=", "max_length", "if", "drop_long_sequences", "else", "10", "**", "9", "\n", "\n", "# The queue to bucket on will be chosen based on maximum length", "\n", "max_example_length", "=", "0", "\n", "for", "v", "in", "example", ".", "values", "(", ")", ":", "\n", "            ", "if", "v", ".", "shape", ".", "ndims", ">", "0", ":", "\n", "                ", "seq_length", "=", "tf", ".", "shape", "(", "v", ")", "[", "0", "]", "\n", "max_example_length", "=", "tf", ".", "maximum", "(", "max_example_length", ",", "seq_length", ")", "\n", "\n", "", "", "(", "_", ",", "outputs", ")", "=", "tf", ".", "contrib", ".", "training", ".", "bucket_by_sequence_length", "(", "\n", "max_example_length", ",", "\n", "example", ",", "\n", "batch_sizes", ",", "\n", "[", "b", "+", "1", "for", "b", "in", "boundaries", "]", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "capacity", "=", "2", ",", "# Number of full batches to store, we don't need many.", "\n", "bucket_capacities", "=", "bucket_capacities", ",", "\n", "dynamic_pad", "=", "True", ",", "\n", "keep_input", "=", "(", "max_example_length", "<=", "max_length", ")", "\n", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.get_training_input": [[84, 165], ["tensorflow.device", "tensorflow.data.TextLineDataset", "tensorflow.data.TextLineDataset", "tensorflow.data.Dataset.zip", "dataset.map.shuffle", "dataset.map.repeat", "dataset.map.map", "dataset.map.map", "dataset.map.map", "dataset.map.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tf.contrib.lookup.index_table_from_tensor.lookup", "dataset.batch_examples", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.constant", "tensorflow.constant", "len", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.string_split", "tensorflow.string_split", "tensorflow.constant", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.record.batch_examples"], ["", "def", "get_training_input", "(", "filenames", ",", "params", ")", ":", "\n", "    ", "\"\"\" Get input for training stage\n\n    :param filenames: A list contains [source_filename, target_filename]\n    :param params: Hyper-parameters\n\n    :returns: A dictionary of pair <Key, Tensor>\n    \"\"\"", "\n", "\n", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "src_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "filenames", "[", "0", "]", ")", "\n", "tgt_dataset", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "filenames", "[", "1", "]", ")", "\n", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "(", "src_dataset", ",", "tgt_dataset", ")", ")", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "params", ".", "buffer_size", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ":", "(", "\n", "tf", ".", "string_split", "(", "[", "src", "]", ")", ".", "values", ",", "\n", "tf", ".", "string_split", "(", "[", "tgt", "]", ")", ".", "values", "\n", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Append <eos> symbol", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ":", "(", "\n", "tf", ".", "concat", "(", "[", "src", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "tgt", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", "\n", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Convert to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "src", ",", "tgt", ":", "{", "\n", "\"source\"", ":", "src", ",", "\n", "\"target\"", ":", "tgt", ",", "\n", "\"source_length\"", ":", "tf", ".", "shape", "(", "src", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "shape", "(", "tgt", ")", "\n", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Create iterator", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "# Create lookup table", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "tgt_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "\n", "# String to index lookup", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"target\"", "]", "=", "tgt_table", ".", "lookup", "(", "features", "[", "\"target\"", "]", ")", "\n", "\n", "# Batching", "\n", "features", "=", "batch_examples", "(", "features", ",", "params", ".", "batch_size", ",", "\n", "params", ".", "max_length", ",", "params", ".", "mantissa_bits", ",", "\n", "shard_multiplier", "=", "len", "(", "params", ".", "device_list", ")", ",", "\n", "length_multiplier", "=", "params", ".", "length_multiplier", ",", "\n", "constant", "=", "params", ".", "constant_batch_size", ",", "\n", "num_threads", "=", "params", ".", "num_threads", ")", "\n", "\n", "# Convert to int32", "\n", "features", "[", "\"source\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"target\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"target\"", "]", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"source_length\"", "]", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "to_int32", "(", "features", "[", "\"target_length\"", "]", ")", "\n", "features", "[", "\"source_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"source_length\"", "]", ",", "1", ")", "\n", "features", "[", "\"target_length\"", "]", "=", "tf", ".", "squeeze", "(", "features", "[", "\"target_length\"", "]", ",", "1", ")", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.sort_input_file": [[167, 186], ["sorted", "enumerate", "tensorflow.gfile.Open", "sorted_inputs.append", "line.strip", "len", "enumerate", "operator.itemgetter", "line.strip().split", "line.strip"], "function", ["None"], ["", "", "def", "sort_input_file", "(", "filename", ",", "reverse", "=", "True", ")", ":", "\n", "# Read file", "\n", "    ", "with", "tf", ".", "gfile", ".", "Open", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "inputs", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fd", "]", "\n", "\n", "", "input_lens", "=", "[", "\n", "(", "i", ",", "len", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", ")", ")", "for", "i", ",", "line", "in", "enumerate", "(", "inputs", ")", "\n", "]", "\n", "\n", "sorted_input_lens", "=", "sorted", "(", "input_lens", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "\n", "reverse", "=", "reverse", ")", "\n", "sorted_keys", "=", "{", "}", "\n", "sorted_inputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "(", "index", ",", "_", ")", "in", "enumerate", "(", "sorted_input_lens", ")", ":", "\n", "        ", "sorted_inputs", ".", "append", "(", "inputs", "[", "index", "]", ")", "\n", "sorted_keys", "[", "index", "]", "=", "i", "\n", "\n", "", "return", "sorted_keys", ",", "sorted_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.sort_and_zip_files": [[188, 213], ["zip", "sorted", "enumerate", "tensorflow.gfile.GFile", "input_lens.append", "inputs.append", "fd.close", "sorted_inputs.append", "list", "line.strip", "operator.itemgetter", "zip", "len", "lines[].split"], "function", ["None"], ["", "def", "sort_and_zip_files", "(", "names", ")", ":", "\n", "    ", "inputs", "=", "[", "]", "\n", "input_lens", "=", "[", "]", "\n", "files", "=", "[", "tf", ".", "gfile", ".", "GFile", "(", "name", ")", "for", "name", "in", "names", "]", "\n", "\n", "count", "=", "0", "\n", "\n", "for", "lines", "in", "zip", "(", "*", "files", ")", ":", "\n", "        ", "lines", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "lines", "]", "\n", "input_lens", ".", "append", "(", "(", "count", ",", "len", "(", "lines", "[", "0", "]", ".", "split", "(", ")", ")", ")", ")", "\n", "inputs", ".", "append", "(", "lines", ")", "\n", "count", "+=", "1", "\n", "\n", "# Close files", "\n", "", "for", "fd", "in", "files", ":", "\n", "        ", "fd", ".", "close", "(", ")", "\n", "\n", "", "sorted_input_lens", "=", "sorted", "(", "input_lens", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "sorted_inputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "(", "index", ",", "_", ")", "in", "enumerate", "(", "sorted_input_lens", ")", ":", "\n", "        ", "sorted_inputs", ".", "append", "(", "inputs", "[", "index", "]", ")", "\n", "\n", "", "return", "[", "list", "(", "x", ")", "for", "x", "in", "zip", "(", "*", "sorted_inputs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.get_evaluation_input": [[215, 275], ["tensorflow.device", "tensorflow.data.Dataset.zip", "dataset.map.map", "dataset.map.padded_batch", "dataset.map.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tuple", "tensorflow.data.Dataset.from_tensor_slices", "dataset.map.map", "dataset.map.map", "datasets.append", "tuple", "tensorflow.constant", "tensorflow.constant", "tf.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.concat", "tensorflow.Dimension", "tensorflow.string_split", "tensorflow.shape", "tensorflow.Dimension", "len", "len", "tensorflow.constant"], "function", ["None"], ["", "def", "get_evaluation_input", "(", "inputs", ",", "params", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "# Create datasets", "\n", "        ", "datasets", "=", "[", "]", "\n", "\n", "for", "data", "in", "inputs", ":", "\n", "            ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "data", ")", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "x", ":", "tf", ".", "string_split", "(", "[", "x", "]", ")", ".", "values", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", ")", "\n", "# Append <eos>", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "tuple", "(", "datasets", ")", ")", "\n", "\n", "# Convert tuple to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "*", "x", ":", "{", "\n", "\"source\"", ":", "x", "[", "0", "]", ",", "\n", "\"source_length\"", ":", "tf", ".", "shape", "(", "x", "[", "0", "]", ")", "[", "0", "]", ",", "\n", "\"references\"", ":", "x", "[", "1", ":", "]", "\n", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "dataset", "=", "dataset", ".", "padded_batch", "(", "\n", "params", ".", "eval_batch_size", ",", "\n", "{", "\n", "\"source\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\n", "\"source_length\"", ":", "[", "]", ",", "\n", "\"references\"", ":", "(", "tf", ".", "Dimension", "(", "None", ")", ",", ")", "*", "(", "len", "(", "inputs", ")", "-", "1", ")", "\n", "}", ",", "\n", "{", "\n", "\"source\"", ":", "params", ".", "pad", ",", "\n", "\"source_length\"", ":", "0", ",", "\n", "\"references\"", ":", "(", "params", ".", "pad", ",", ")", "*", "(", "len", "(", "inputs", ")", "-", "1", ")", "\n", "}", "\n", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "tgt_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"target\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"target\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "features", "[", "\"references\"", "]", "=", "tuple", "(", "\n", "tgt_table", ".", "lookup", "(", "item", ")", "for", "item", "in", "features", "[", "\"references\"", "]", "\n", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.dataset.get_inference_input": [[277, 314], ["tensorflow.data.Dataset.from_tensor_slices", "dataset.padded_batch.map", "dataset.padded_batch.map", "dataset.padded_batch.map", "dataset.padded_batch.padded_batch", "dataset.padded_batch.make_one_shot_iterator", "dataset.make_one_shot_iterator.get_next", "tensorflow.contrib.lookup.index_table_from_tensor", "tf.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.constant", "tensorflow.constant", "tensorflow.concat", "tensorflow.string_split", "tensorflow.Dimension", "tensorflow.shape", "tensorflow.constant"], "function", ["None"], ["", "def", "get_inference_input", "(", "inputs", ",", "params", ")", ":", "\n", "    ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "\n", "tf", ".", "constant", "(", "inputs", ")", "\n", ")", "\n", "\n", "# Split string", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "x", ":", "tf", ".", "string_split", "(", "[", "x", "]", ")", ".", "values", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", ")", "\n", "\n", "# Append <eos>", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", ",", "[", "tf", ".", "constant", "(", "params", ".", "eos", ")", "]", "]", ",", "axis", "=", "0", ")", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "# Convert tuple to dictionary", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ":", "{", "\"source\"", ":", "x", ",", "\"source_length\"", ":", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "}", ",", "\n", "num_parallel_calls", "=", "params", ".", "num_threads", "\n", ")", "\n", "\n", "dataset", "=", "dataset", ".", "padded_batch", "(", "\n", "params", ".", "decode_batch_size", ",", "\n", "{", "\"source\"", ":", "[", "tf", ".", "Dimension", "(", "None", ")", "]", ",", "\"source_length\"", ":", "[", "]", "}", ",", "\n", "{", "\"source\"", ":", "params", ".", "pad", ",", "\"source_length\"", ":", "0", "}", "\n", ")", "\n", "\n", "iterator", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "features", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "src_table", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "tf", ".", "constant", "(", "params", ".", "vocabulary", "[", "\"source\"", "]", ")", ",", "\n", "default_value", "=", "params", ".", "mapping", "[", "\"source\"", "]", "[", "params", ".", "unk", "]", "\n", ")", "\n", "features", "[", "\"source\"", "]", "=", "src_table", ".", "lookup", "(", "features", "[", "\"source\"", "]", ")", "\n", "\n", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.record.input_pipeline": [[17, 58], ["tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.contrib.slim.tfexample_decoder.Tensor", "tensorflow.contrib.slim.tfexample_decoder.Tensor", "tensorflow.contrib.slim.tfexample_decoder.Tensor", "tensorflow.contrib.slim.tfexample_decoder.Tensor", "tensorflow.name_scope", "tensorflow.contrib.slim.parallel_reader.get_data_files", "min", "tensorflow.contrib.slim.parallel_reader.parallel_read", "tensorflow.contrib.slim.tfexample_decoder.TFExampleDecoder", "tfexample_decoder.TFExampleDecoder.decode", "zip", "len", "tensorflow.to_int32", "list", "six.iteritems"], "function", ["None"], ["def", "input_pipeline", "(", "file_pattern", ",", "mode", ",", "capacity", "=", "64", ")", ":", "\n", "    ", "keys_to_features", "=", "{", "\n", "\"source\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "\"target\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", ",", "\n", "\"source_length\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "tf", ".", "int64", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "tf", ".", "int64", ")", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "\"source\"", ":", "tfexample_decoder", ".", "Tensor", "(", "\"source\"", ")", ",", "\n", "\"target\"", ":", "tfexample_decoder", ".", "Tensor", "(", "\"target\"", ")", ",", "\n", "\"source_length\"", ":", "tfexample_decoder", ".", "Tensor", "(", "\"source_length\"", ")", ",", "\n", "\"target_length\"", ":", "tfexample_decoder", ".", "Tensor", "(", "\"target_length\"", ")", "\n", "}", "\n", "\n", "# Now the non-trivial case construction.", "\n", "with", "tf", ".", "name_scope", "(", "\"examples_queue\"", ")", ":", "\n", "        ", "training", "=", "(", "mode", "==", "\"train\"", ")", "\n", "# Read serialized examples using slim parallel_reader.", "\n", "num_epochs", "=", "None", "if", "training", "else", "1", "\n", "data_files", "=", "parallel_reader", ".", "get_data_files", "(", "file_pattern", ")", "\n", "num_readers", "=", "min", "(", "4", "if", "training", "else", "1", ",", "len", "(", "data_files", ")", ")", "\n", "_", ",", "examples", "=", "parallel_reader", ".", "parallel_read", "(", "[", "file_pattern", "]", ",", "\n", "tf", ".", "TFRecordReader", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "shuffle", "=", "training", ",", "\n", "capacity", "=", "2", "*", "capacity", ",", "\n", "min_after_dequeue", "=", "capacity", ",", "\n", "num_readers", "=", "num_readers", ")", "\n", "\n", "decoder", "=", "tfexample_decoder", ".", "TFExampleDecoder", "(", "keys_to_features", ",", "\n", "items_to_handlers", ")", "\n", "\n", "decoded", "=", "decoder", ".", "decode", "(", "examples", ",", "items", "=", "list", "(", "items_to_handlers", ")", ")", "\n", "examples", "=", "{", "}", "\n", "\n", "for", "(", "field", ",", "tensor", ")", "in", "zip", "(", "keys_to_features", ",", "decoded", ")", ":", "\n", "            ", "examples", "[", "field", "]", "=", "tensor", "\n", "\n", "# We do not want int64s as they do are not supported on GPUs.", "\n", "", "return", "{", "k", ":", "tf", ".", "to_int32", "(", "v", ")", "for", "(", "k", ",", "v", ")", "in", "six", ".", "iteritems", "(", "examples", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.record.batch_examples": [[60, 107], ["tensorflow.name_scope", "examples.values", "tensorflow.contrib.training.bucket_by_sequence_length", "boundaries.append", "tensorflow.maximum", "max", "max", "tensorflow.shape", "int", "math.log"], "function", ["None"], ["", "", "def", "batch_examples", "(", "examples", ",", "batch_size", ",", "max_length", ",", "mantissa_bits", ",", "\n", "shard_multiplier", "=", "1", ",", "length_multiplier", "=", "1", ",", "scheme", "=", "\"token\"", ",", "\n", "drop_long_sequences", "=", "True", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"batch_examples\"", ")", ":", "\n", "        ", "max_length", "=", "max_length", "or", "batch_size", "\n", "min_length", "=", "8", "\n", "mantissa_bits", "=", "mantissa_bits", "\n", "\n", "# compute boundaries", "\n", "x", "=", "min_length", "\n", "boundaries", "=", "[", "]", "\n", "\n", "while", "x", "<", "max_length", ":", "\n", "            ", "boundaries", ".", "append", "(", "x", ")", "\n", "x", "+=", "2", "**", "max", "(", "0", ",", "int", "(", "math", ".", "log", "(", "x", ",", "2", ")", ")", "-", "mantissa_bits", ")", "\n", "\n", "", "if", "scheme", "is", "\"token\"", ":", "\n", "            ", "batch_sizes", "=", "[", "max", "(", "1", ",", "batch_size", "//", "length", ")", "\n", "for", "length", "in", "boundaries", "+", "[", "max_length", "]", "]", "\n", "batch_sizes", "=", "[", "b", "*", "shard_multiplier", "for", "b", "in", "batch_sizes", "]", "\n", "bucket_capacities", "=", "[", "2", "*", "b", "for", "b", "in", "batch_sizes", "]", "\n", "", "else", ":", "\n", "            ", "batch_sizes", "=", "batch_size", "*", "shard_multiplier", "\n", "bucket_capacities", "=", "[", "2", "*", "n", "for", "n", "in", "boundaries", "+", "[", "max_length", "]", "]", "\n", "\n", "", "max_length", "*=", "length_multiplier", "\n", "boundaries", "=", "[", "boundary", "*", "length_multiplier", "for", "boundary", "in", "boundaries", "]", "\n", "max_length", "=", "max_length", "if", "drop_long_sequences", "else", "10", "**", "9", "\n", "\n", "# The queue to bucket on will be chosen based on maximum length.", "\n", "max_example_length", "=", "0", "\n", "for", "v", "in", "examples", ".", "values", "(", ")", ":", "\n", "            ", "seq_length", "=", "tf", ".", "shape", "(", "v", ")", "[", "0", "]", "\n", "max_example_length", "=", "tf", ".", "maximum", "(", "max_example_length", ",", "seq_length", ")", "\n", "\n", "", "(", "_", ",", "outputs", ")", "=", "tf", ".", "contrib", ".", "training", ".", "bucket_by_sequence_length", "(", "\n", "max_example_length", ",", "\n", "examples", ",", "\n", "batch_sizes", ",", "\n", "[", "b", "+", "1", "for", "b", "in", "boundaries", "]", ",", "\n", "capacity", "=", "2", ",", "\n", "bucket_capacities", "=", "bucket_capacities", ",", "\n", "dynamic_pad", "=", "True", ",", "\n", "keep_input", "=", "(", "max_example_length", "<=", "max_length", ")", "\n", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.record.get_input_features": [[109, 143], ["tensorflow.name_scope", "tensorflow.device", "record.input_pipeline", "record.batch_examples", "tensorflow.squeeze", "tensorflow.squeeze", "len"], "function", ["home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.record.input_pipeline", "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.record.batch_examples"], ["", "def", "get_input_features", "(", "file_patterns", ",", "mode", ",", "params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"input_queues\"", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "            ", "if", "mode", "!=", "\"train\"", ":", "\n", "                ", "num_datashards", "=", "1", "\n", "batch_size", "=", "params", ".", "eval_batch_size", "\n", "", "else", ":", "\n", "                ", "num_datashards", "=", "len", "(", "params", ".", "device_list", ")", "\n", "batch_size", "=", "params", ".", "batch_size", "\n", "\n", "", "batch_size_multiplier", "=", "1", "\n", "capacity", "=", "64", "*", "num_datashards", "\n", "examples", "=", "input_pipeline", "(", "file_patterns", ",", "mode", ",", "capacity", ")", "\n", "drop_long_sequences", "=", "(", "mode", "==", "\"train\"", ")", "\n", "\n", "feature_map", "=", "batch_examples", "(", "\n", "examples", ",", "\n", "batch_size", ",", "\n", "params", ".", "max_length", ",", "\n", "params", ".", "mantissa_bits", ",", "\n", "num_datashards", ",", "\n", "batch_size_multiplier", ",", "\n", "\"token\"", "if", "not", "params", ".", "constant_batch_size", "else", "\"constant\"", ",", "\n", "drop_long_sequences", "\n", ")", "\n", "\n", "", "features", "=", "{", "\n", "\"source\"", ":", "feature_map", "[", "\"source\"", "]", ",", "\n", "\"target\"", ":", "feature_map", "[", "\"target\"", "]", ",", "\n", "\"source_length\"", ":", "tf", ".", "squeeze", "(", "feature_map", "[", "\"source_length\"", "]", ",", "axis", "=", "1", ")", ",", "\n", "\"target_length\"", ":", "tf", ".", "squeeze", "(", "feature_map", "[", "\"target_length\"", "]", ",", "axis", "=", "1", ")", "\n", "}", "\n", "\n", "", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.load_vocabulary": [[11, 19], ["tensorflow.gfile.GFile", "line.strip", "vocab.append"], "function", ["None"], ["def", "load_vocabulary", "(", "filename", ")", ":", "\n", "    ", "vocab", "=", "[", "]", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ")", "as", "fd", ":", "\n", "        ", "for", "line", "in", "fd", ":", "\n", "            ", "word", "=", "line", ".", "strip", "(", ")", "\n", "vocab", ".", "append", "(", "word", ")", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.process_vocabulary": [[21, 26], ["vocab.append"], "function", ["None"], ["", "def", "process_vocabulary", "(", "vocab", ",", "params", ")", ":", "\n", "    ", "if", "params", ".", "append_eos", ":", "\n", "        ", "vocab", ".", "append", "(", "params", ".", "eos", ")", "\n", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.bzhangXMU_transformer-aan.data.vocab.get_control_mapping": [[28, 37], ["enumerate", "symbol.decode", "token.decode"], "function", ["None"], ["", "def", "get_control_mapping", "(", "vocab", ",", "symbols", ")", ":", "\n", "    ", "mapping", "=", "{", "}", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "for", "symbol", "in", "symbols", ":", "\n", "            ", "if", "symbol", ".", "decode", "(", "\"utf-8\"", ")", "==", "token", ".", "decode", "(", "\"utf-8\"", ")", ":", "\n", "                ", "mapping", "[", "symbol", "]", "=", "i", "\n", "\n", "", "", "", "return", "mapping", "\n", "", ""]]}