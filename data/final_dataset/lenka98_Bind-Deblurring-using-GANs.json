{"home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv": [[8, 16], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.random_normal_initializer", "tensorflow.zeros_initializer"], "function", ["None"], ["def", "Conv", "(", "name", ",", "x", ",", "filter_size", ",", "in_filters", ",", "out_filters", ",", "strides", ",", "padding", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "n", "=", "filter_size", "*", "filter_size", "*", "out_filters", "\n", "kernel", "=", "tf", ".", "get_variable", "(", "'filter'", ",", "[", "filter_size", ",", "filter_size", ",", "in_filters", ",", "out_filters", "]", ",", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "out_filters", "]", ",", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "kernel", ",", "[", "1", ",", "strides", ",", "strides", ",", "1", "]", ",", "padding", "=", "padding", ")", "+", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv_transpose": [[19, 29], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.shape", "tensorflow.stack", "tensorflow.nn.conv2d_transpose", "tensorflow.random_normal_initializer", "numpy.sqrt"], "function", ["None"], ["", "", "def", "Conv_transpose", "(", "name", ",", "x", ",", "filter_size", ",", "in_filters", ",", "out_filters", ",", "fraction", "=", "2", ",", "padding", "=", "\"SAME\"", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "n", "=", "filter_size", "*", "filter_size", "*", "out_filters", "\n", "kernel", "=", "tf", ".", "get_variable", "(", "'filter'", ",", "[", "filter_size", ",", "filter_size", ",", "out_filters", ",", "in_filters", "]", ",", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "n", ")", ")", ")", "\n", "size", "=", "tf", ".", "shape", "(", "x", ")", "\n", "output_shape", "=", "tf", ".", "stack", "(", "[", "size", "[", "0", "]", ",", "size", "[", "1", "]", "*", "fraction", ",", "size", "[", "2", "]", "*", "fraction", ",", "out_filters", "]", ")", "\n", "x", "=", "tf", ".", "nn", ".", "conv2d_transpose", "(", "x", ",", "kernel", ",", "output_shape", ",", "[", "1", ",", "fraction", ",", "fraction", ",", "1", "]", ",", "padding", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm": [[30, 43], ["tensorflow.nn.moments", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "function", ["None"], ["", "", "def", "instance_norm", "(", "name", ",", "x", ",", "dim", ",", "affine", "=", "False", ",", "BN_decay", "=", "0.999", ",", "BN_epsilon", "=", "1e-3", ")", ":", "\n", "\n", "    ", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "axes", "=", "[", "1", ",", "2", "]", ")", "\n", "x", "=", "(", "x", "-", "mean", ")", "/", "(", "(", "variance", "+", "BN_epsilon", ")", "**", "0.5", ")", "\n", "\n", "if", "affine", ":", "\n", "        ", "beta", "=", "tf", ".", "get_variable", "(", "name", "=", "name", "+", "\"beta\"", ",", "shape", "=", "dim", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ",", "tf", ".", "float32", ")", ")", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "name", "+", "\"gamma\"", ",", "dim", ",", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ",", "tf", ".", "float32", ")", ")", "\n", "x", "=", "gamma", "*", "x", "+", "beta", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.main.str2bool": [[9, 11], ["v.lower"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "return", "v", ".", "lower", "(", ")", "in", "(", "'true'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.data_loader.dataloader.__init__": [[8, 23], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "\n", "        ", "self", ".", "mode", "=", "args", ".", "mode", "\n", "self", ".", "patch_size", "=", "args", ".", "patch_size", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "self", ".", "train_Sharp_path", "=", "args", ".", "train_Sharp_path", "\n", "self", ".", "train_Blur_path", "=", "args", ".", "train_Blur_path", "\n", "self", ".", "test_Sharp_path", "=", "args", ".", "test_Sharp_path", "\n", "self", ".", "test_Blur_path", "=", "args", ".", "test_Blur_path", "\n", "self", ".", "test_with_train", "=", "args", ".", "test_with_train", "\n", "self", ".", "test_batch", "=", "args", ".", "test_batch", "\n", "self", ".", "load_X", "=", "args", ".", "load_X", "\n", "self", ".", "load_Y", "=", "args", ".", "load_Y", "\n", "self", ".", "augmentation", "=", "args", ".", "augmentation", "\n", "self", ".", "channel", "=", "args", ".", "channel", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.data_loader.dataloader.build_loader": [[24, 94], ["sorted", "sorted", "tensorflow.data.Dataset.from_tensor_slices", "data_loader.dataloader.tr_dataset.map().prefetch", "data_loader.dataloader.tr_dataset.map().prefetch", "data_loader.dataloader.tr_dataset.map().prefetch", "data_loader.dataloader.tr_dataset.shuffle", "data_loader.dataloader.tr_dataset.repeat", "data_loader.dataloader.tr_dataset.batch", "tensorflow.data.Iterator.from_structure", "tensorflow.data.Iterator.from_structure.get_next", "tensorflow.data.Iterator.from_structure.make_initializer", "os.listdir", "os.listdir", "os.path.join", "os.path.join", "data_loader.dataloader.tr_dataset.map().prefetch", "sorted", "sorted", "tensorflow.data.Dataset.from_tensor_slices", "data_loader.dataloader.val_dataset.map().prefetch", "data_loader.dataloader.val_dataset.batch", "tensorflow.data.Iterator.from_structure.make_initializer", "sorted", "sorted", "tensorflow.data.Dataset.from_tensor_slices", "data_loader.dataloader.val_dataset.map().prefetch", "data_loader.dataloader.val_dataset.batch", "tensorflow.data.Iterator.from_structure", "tensorflow.data.Iterator.from_structure.get_next", "tensorflow.data.Iterator.from_structure.make_initializer", "data_loader.dataloader.tr_dataset.map", "data_loader.dataloader.tr_dataset.map", "data_loader.dataloader.tr_dataset.map", "os.listdir", "os.listdir", "os.path.join", "os.path.join", "os.listdir", "os.listdir", "os.path.join", "os.path.join", "sorted", "tensorflow.data.Dataset.from_tensor_slices", "data_loader.dataloader.te_dataset.map().prefetch", "data_loader.dataloader.te_dataset.batch", "tensorflow.data.Iterator.from_structure", "tensorflow.data.Iterator.from_structure.get_next", "tensorflow.data.Iterator.from_structure.make_initializer", "data_loader.dataloader.tr_dataset.map", "data_loader.dataloader.val_dataset.map", "data_loader.dataloader.val_dataset.map", "os.listdir", "os.path.join", "data_loader.dataloader.te_dataset.map"], "methods", ["None"], ["", "def", "build_loader", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "\n", "            ", "tr_sharp_imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "train_Sharp_path", ")", ")", "\n", "tr_blur_imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "train_Blur_path", ")", ")", "\n", "tr_sharp_imgs", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "train_Sharp_path", ",", "ele", ")", "for", "ele", "in", "tr_sharp_imgs", "]", "\n", "tr_blur_imgs", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "train_Blur_path", ",", "ele", ")", "for", "ele", "in", "tr_blur_imgs", "]", "\n", "train_list", "=", "(", "tr_blur_imgs", ",", "tr_sharp_imgs", ")", "\n", "\n", "self", ".", "tr_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "train_list", ")", "\n", "self", ".", "tr_dataset", "=", "self", ".", "tr_dataset", ".", "map", "(", "self", ".", "_parse", ",", "num_parallel_calls", "=", "4", ")", ".", "prefetch", "(", "32", ")", "\n", "self", ".", "tr_dataset", "=", "self", ".", "tr_dataset", ".", "map", "(", "self", ".", "_resize", ",", "num_parallel_calls", "=", "4", ")", ".", "prefetch", "(", "32", ")", "\n", "self", ".", "tr_dataset", "=", "self", ".", "tr_dataset", ".", "map", "(", "self", ".", "_get_patch", ",", "num_parallel_calls", "=", "4", ")", ".", "prefetch", "(", "32", ")", "\n", "if", "self", ".", "augmentation", ":", "\n", "                ", "self", ".", "tr_dataset", "=", "self", ".", "tr_dataset", ".", "map", "(", "self", ".", "_data_augmentation", ",", "num_parallel_calls", "=", "4", ")", ".", "prefetch", "(", "32", ")", "\n", "", "self", ".", "tr_dataset", "=", "self", ".", "tr_dataset", ".", "shuffle", "(", "32", ")", "\n", "self", ".", "tr_dataset", "=", "self", ".", "tr_dataset", ".", "repeat", "(", ")", "\n", "self", ".", "tr_dataset", "=", "self", ".", "tr_dataset", ".", "batch", "(", "self", ".", "batch_size", ")", "\n", "\n", "if", "self", ".", "test_with_train", ":", "\n", "\n", "                ", "val_sharp_imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "test_Sharp_path", ")", ")", "\n", "val_blur_imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "test_Blur_path", ")", ")", "\n", "val_sharp_imgs", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "test_Sharp_path", ",", "ele", ")", "for", "ele", "in", "val_sharp_imgs", "]", "\n", "val_blur_imgs", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "test_Blur_path", ",", "ele", ")", "for", "ele", "in", "val_blur_imgs", "]", "\n", "valid_list", "=", "(", "val_blur_imgs", ",", "val_sharp_imgs", ")", "\n", "\n", "self", ".", "val_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "valid_list", ")", "\n", "self", ".", "val_dataset", "=", "self", ".", "val_dataset", ".", "map", "(", "self", ".", "_parse", ",", "num_parallel_calls", "=", "4", ")", ".", "prefetch", "(", "32", ")", "\n", "self", ".", "val_dataset", "=", "self", ".", "val_dataset", ".", "batch", "(", "self", ".", "test_batch", ")", "\n", "\n", "", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "self", ".", "tr_dataset", ".", "output_types", ",", "self", ".", "tr_dataset", ".", "output_shapes", ")", "\n", "self", ".", "next_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "self", ".", "init_op", "=", "{", "}", "\n", "self", ".", "init_op", "[", "'tr_init'", "]", "=", "iterator", ".", "make_initializer", "(", "self", ".", "tr_dataset", ")", "\n", "\n", "if", "self", ".", "test_with_train", ":", "\n", "                ", "self", ".", "init_op", "[", "'val_init'", "]", "=", "iterator", ".", "make_initializer", "(", "self", ".", "val_dataset", ")", "\n", "\n", "", "", "elif", "self", ".", "mode", "==", "'test'", ":", "\n", "\n", "            ", "val_sharp_imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "test_Sharp_path", ")", ")", "\n", "val_blur_imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "test_Blur_path", ")", ")", "\n", "val_sharp_imgs", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "test_Sharp_path", ",", "ele", ")", "for", "ele", "in", "val_sharp_imgs", "]", "\n", "val_blur_imgs", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "test_Blur_path", ",", "ele", ")", "for", "ele", "in", "val_blur_imgs", "]", "\n", "valid_list", "=", "(", "val_blur_imgs", ",", "val_sharp_imgs", ")", "\n", "\n", "self", ".", "val_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "valid_list", ")", "\n", "self", ".", "val_dataset", "=", "self", ".", "val_dataset", ".", "map", "(", "self", ".", "_parse", ",", "num_parallel_calls", "=", "4", ")", ".", "prefetch", "(", "32", ")", "\n", "self", ".", "val_dataset", "=", "self", ".", "val_dataset", ".", "batch", "(", "1", ")", "\n", "\n", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "self", ".", "val_dataset", ".", "output_types", ",", "self", ".", "val_dataset", ".", "output_shapes", ")", "\n", "self", ".", "next_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "self", ".", "init_op", "=", "{", "}", "\n", "self", ".", "init_op", "[", "'val_init'", "]", "=", "iterator", ".", "make_initializer", "(", "self", ".", "val_dataset", ")", "\n", "\n", "", "elif", "self", ".", "mode", "==", "'test_only'", ":", "\n", "\n", "            ", "blur_imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "test_Blur_path", ")", ")", "\n", "blur_imgs", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "test_Blur_path", ",", "ele", ")", "for", "ele", "in", "blur_imgs", "]", "\n", "\n", "self", ".", "te_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "blur_imgs", ")", "\n", "self", ".", "te_dataset", "=", "self", ".", "te_dataset", ".", "map", "(", "self", ".", "_parse_Blur_only", ",", "num_parallel_calls", "=", "4", ")", ".", "prefetch", "(", "32", ")", "\n", "self", ".", "te_dataset", "=", "self", ".", "te_dataset", ".", "batch", "(", "1", ")", "\n", "\n", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "self", ".", "te_dataset", ".", "output_types", ",", "self", ".", "te_dataset", ".", "output_shapes", ")", "\n", "self", ".", "next_batch", "=", "iterator", ".", "get_next", "(", ")", "\n", "self", ".", "init_op", "=", "{", "}", "\n", "self", ".", "init_op", "[", "'te_init'", "]", "=", "iterator", ".", "make_initializer", "(", "self", ".", "te_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.data_loader.dataloader._parse": [[96, 108], ["tensorflow.read_file", "tensorflow.read_file", "tensorflow.image.decode_png", "tensorflow.image.decode_png", "tensorflow.cast", "tensorflow.cast"], "methods", ["None"], ["", "", "def", "_parse", "(", "self", ",", "image_blur", ",", "image_sharp", ")", ":", "\n", "\n", "        ", "image_blur", "=", "tf", ".", "read_file", "(", "image_blur", ")", "\n", "image_sharp", "=", "tf", ".", "read_file", "(", "image_sharp", ")", "\n", "\n", "image_blur", "=", "tf", ".", "image", ".", "decode_png", "(", "image_blur", ",", "channels", "=", "self", ".", "channel", ")", "\n", "image_sharp", "=", "tf", ".", "image", ".", "decode_png", "(", "image_sharp", ",", "channels", "=", "self", ".", "channel", ")", "\n", "\n", "image_blur", "=", "tf", ".", "cast", "(", "image_blur", ",", "tf", ".", "float32", ")", "\n", "image_sharp", "=", "tf", ".", "cast", "(", "image_sharp", ",", "tf", ".", "float32", ")", "\n", "\n", "return", "image_blur", ",", "image_sharp", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.data_loader.dataloader._resize": [[109, 115], ["tensorflow.image.resize_images", "tensorflow.image.resize_images"], "methods", ["None"], ["", "def", "_resize", "(", "self", ",", "image_blur", ",", "image_sharp", ")", ":", "\n", "\n", "        ", "image_blur", "=", "tf", ".", "image", ".", "resize_images", "(", "image_blur", ",", "(", "self", ".", "load_Y", ",", "self", ".", "load_X", ")", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "image_sharp", "=", "tf", ".", "image", ".", "resize_images", "(", "image_sharp", ",", "(", "self", ".", "load_Y", ",", "self", ".", "load_X", ")", ",", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "return", "image_blur", ",", "image_sharp", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.data_loader.dataloader._parse_Blur_only": [[117, 124], ["tensorflow.read_file", "tensorflow.image.decode_image", "tensorflow.cast"], "methods", ["None"], ["", "def", "_parse_Blur_only", "(", "self", ",", "image_blur", ")", ":", "\n", "\n", "        ", "image_blur", "=", "tf", ".", "read_file", "(", "image_blur", ")", "\n", "image_blur", "=", "tf", ".", "image", ".", "decode_image", "(", "image_blur", ",", "channels", "=", "self", ".", "channel", ")", "\n", "image_blur", "=", "tf", ".", "cast", "(", "image_blur", ",", "tf", ".", "float32", ")", "\n", "\n", "return", "image_blur", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.data_loader.dataloader._get_patch": [[125, 138], ["tensorflow.shape", "tensorflow.random_uniform", "tensorflow.random_uniform"], "methods", ["None"], ["", "def", "_get_patch", "(", "self", ",", "image_blur", ",", "image_sharp", ")", ":", "\n", "\n", "        ", "shape", "=", "tf", ".", "shape", "(", "image_blur", ")", "\n", "ih", "=", "shape", "[", "0", "]", "\n", "iw", "=", "shape", "[", "1", "]", "\n", "\n", "ix", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "1", "]", ",", "minval", "=", "0", ",", "maxval", "=", "iw", "-", "self", ".", "patch_size", "+", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "0", "]", "\n", "iy", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "1", "]", ",", "minval", "=", "0", ",", "maxval", "=", "ih", "-", "self", ".", "patch_size", "+", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "0", "]", "\n", "\n", "img_sharp_in", "=", "image_sharp", "[", "iy", ":", "iy", "+", "self", ".", "patch_size", ",", "ix", ":", "ix", "+", "self", ".", "patch_size", "]", "\n", "img_blur_in", "=", "image_blur", "[", "iy", ":", "iy", "+", "self", ".", "patch_size", ",", "ix", ":", "ix", "+", "self", ".", "patch_size", "]", "\n", "\n", "return", "img_blur_in", ",", "img_sharp_in", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.data_loader.dataloader._data_augmentation": [[139, 158], ["tensorflow.image.rot90", "tensorflow.image.rot90", "tensorflow.equal", "tensorflow.equal", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.mod", "tensorflow.mod", "tensorflow.image.flip_left_right", "tensorflow.image.flip_left_right", "tensorflow.image.flip_up_down", "tensorflow.image.flip_up_down"], "methods", ["None"], ["", "def", "_data_augmentation", "(", "self", ",", "image_blur", ",", "image_sharp", ")", ":", "\n", "\n", "        ", "rot", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "1", "]", ",", "minval", "=", "0", ",", "maxval", "=", "3", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "0", "]", "\n", "flip_rl", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "1", "]", ",", "minval", "=", "0", ",", "maxval", "=", "3", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "0", "]", "\n", "flip_updown", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "1", "]", ",", "minval", "=", "0", ",", "maxval", "=", "3", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "0", "]", "\n", "\n", "image_blur", "=", "tf", ".", "image", ".", "rot90", "(", "image_blur", ",", "rot", ")", "\n", "image_sharp", "=", "tf", ".", "image", ".", "rot90", "(", "image_sharp", ",", "rot", ")", "\n", "\n", "rl", "=", "tf", ".", "equal", "(", "tf", ".", "mod", "(", "flip_rl", ",", "2", ")", ",", "0", ")", "\n", "ud", "=", "tf", ".", "equal", "(", "tf", ".", "mod", "(", "flip_updown", ",", "2", ")", ",", "0", ")", "\n", "\n", "image_blur", "=", "tf", ".", "cond", "(", "rl", ",", "true_fn", "=", "lambda", ":", "tf", ".", "image", ".", "flip_left_right", "(", "image_blur", ")", ",", "false_fn", "=", "lambda", ":", "(", "image_blur", ")", ")", "\n", "image_sharp", "=", "tf", ".", "cond", "(", "rl", ",", "true_fn", "=", "lambda", ":", "tf", ".", "image", ".", "flip_left_right", "(", "image_sharp", ")", ",", "false_fn", "=", "lambda", ":", "(", "image_sharp", ")", ")", "\n", "\n", "image_blur", "=", "tf", ".", "cond", "(", "ud", ",", "true_fn", "=", "lambda", ":", "tf", ".", "image", ".", "flip_up_down", "(", "image_blur", ")", ",", "false_fn", "=", "lambda", ":", "(", "image_blur", ")", ")", "\n", "image_sharp", "=", "tf", ".", "cond", "(", "ud", ",", "true_fn", "=", "lambda", ":", "tf", ".", "image", ".", "flip_up_down", "(", "image_sharp", ")", ",", "false_fn", "=", "lambda", ":", "(", "image_sharp", ")", ")", "\n", "\n", "return", "image_blur", ",", "image_sharp", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.mode.train": [[11, 94], ["len", "tensorflow.summary.merge_all", "tensorflow.summary.FileWriter", "saver.restore", "print", "print", "os.listdir", "open", "util.image_loader", "util.image_loader", "util.image_loader", "saver.save", "saver.save", "open.close", "numpy.random.permutation", "range", "sess.run", "range", "len", "time.time", "util.batch_gen", "range", "sess.run", "time.time", "sess.run", "tf.summary.FileWriter.add_summary", "print", "print", "print", "saver.save", "time.time", "range", "sess.run", "time.time", "sess.run", "tf.summary.FileWriter.add_summary", "print", "print", "print", "saver.save", "sess.run", "mode.test", "sess.run", "mode.test"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.image_loader", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.image_loader", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.image_loader", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.batch_gen", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.mode.test", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.mode.test"], ["def", "train", "(", "args", ",", "model", ",", "sess", ",", "saver", ")", ":", "\n", "\n", "    ", "if", "args", ".", "fine_tuning", ":", "\n", "        ", "saver", ".", "restore", "(", "sess", ",", "args", ".", "pre_trained_model", ")", "\n", "print", "(", "\"saved model is loaded for fine-tuning!\"", ")", "\n", "print", "(", "\"model path is %s\"", "%", "(", "args", ".", "pre_trained_model", ")", ")", "\n", "\n", "", "num_imgs", "=", "len", "(", "os", ".", "listdir", "(", "args", ".", "train_Sharp_path", ")", ")", "\n", "\n", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "'./logs'", ",", "sess", ".", "graph", ")", "\n", "if", "args", ".", "test_with_train", ":", "\n", "        ", "f", "=", "open", "(", "\"valid_logs.txt\"", ",", "'w'", ")", "\n", "\n", "", "epoch", "=", "0", "\n", "step", "=", "num_imgs", "//", "args", ".", "batch_size", "\n", "\n", "if", "args", ".", "in_memory", ":", "\n", "\n", "        ", "blur_imgs", "=", "util", ".", "image_loader", "(", "args", ".", "train_Blur_path", ",", "args", ".", "load_X", ",", "args", ".", "load_Y", ")", "\n", "sharp_imgs", "=", "util", ".", "image_loader", "(", "args", ".", "train_Sharp_path", ",", "args", ".", "load_X", ",", "args", ".", "load_Y", ")", "\n", "edges_imgs", "=", "util", ".", "image_loader", "(", "args", ".", "train_edge_path", ",", "args", ".", "load_X", ",", "args", ".", "load_Y", ")", "\n", "\n", "while", "epoch", "<", "args", ".", "max_epoch", ":", "\n", "            ", "random_index", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "blur_imgs", ")", ")", "\n", "for", "k", "in", "range", "(", "step", ")", ":", "\n", "                ", "s_time", "=", "time", ".", "time", "(", ")", "\n", "blur_batch", ",", "sharp_batch", ",", "edge_batch", "=", "util", ".", "batch_gen", "(", "blur_imgs", ",", "sharp_imgs", ",", "edges_imgs", ",", "args", ".", "patch_size", ",", "args", ".", "batch_size", ",", "random_index", ",", "k", ",", "args", ".", "augmentation", ")", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "critic_updates", ")", ":", "\n", "                    ", "_", ",", "D_loss", "=", "sess", ".", "run", "(", "[", "model", ".", "D_train", ",", "model", ".", "D_loss", "]", ",", "feed_dict", "=", "{", "model", ".", "blur", ":", "blur_batch", ",", "model", ".", "sharp", ":", "sharp_batch", ",", "model", ".", "epoch", ":", "epoch", "}", ")", "\n", "\n", "", "_", ",", "G_loss", "=", "sess", ".", "run", "(", "[", "model", ".", "G_train", ",", "model", ".", "G_loss", "]", ",", "feed_dict", "=", "{", "model", ".", "blur", ":", "blur_batch", ",", "model", ".", "sharp", ":", "sharp_batch", ",", "model", ".", "edges", ":", "edge_batch", ",", "model", ".", "epoch", ":", "epoch", "}", ")", "\n", "\n", "e_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "if", "epoch", "%", "args", ".", "log_freq", "==", "0", ":", "\n", "                ", "summary", "=", "sess", ".", "run", "(", "merged", ",", "feed_dict", "=", "{", "model", ".", "blur", ":", "blur_batch", ",", "model", ".", "sharp", ":", "sharp_batch", ",", "model", ".", "edges", ":", "edge_batch", "}", ")", "\n", "train_writer", ".", "add_summary", "(", "summary", ",", "epoch", ")", "\n", "if", "args", ".", "test_with_train", ":", "\n", "                    ", "test", "(", "args", ",", "model", ",", "sess", ",", "saver", ",", "f", ",", "epoch", ",", "loading", "=", "False", ")", "\n", "", "print", "(", "\"%d training epoch completed\"", "%", "epoch", ")", "\n", "print", "(", "\"D_loss : %0.4f, \\t G_loss : %0.4f\"", "%", "(", "D_loss", ",", "G_loss", ")", ")", "\n", "print", "(", "\"Elpased time : %0.4f\"", "%", "(", "e_time", "-", "s_time", ")", ")", "\n", "", "if", "(", "(", "epoch", ")", "%", "args", ".", "model_save_freq", "==", "0", ")", ":", "\n", "                ", "saver", ".", "save", "(", "sess", ",", "'./model/DeblurrGAN'", ",", "global_step", "=", "epoch", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "epoch", "+=", "1", "\n", "\n", "", "saver", ".", "save", "(", "sess", ",", "'./model/DeblurrGAN_last'", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "else", ":", "\n", "        ", "while", "epoch", "<", "args", ".", "max_epoch", ":", "\n", "\n", "            ", "sess", ".", "run", "(", "model", ".", "data_loader", ".", "init_op", "[", "'tr_init'", "]", ")", "\n", "\n", "for", "k", "in", "range", "(", "step", ")", ":", "\n", "                ", "s_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "t", "in", "range", "(", "args", ".", "critic_updates", ")", ":", "\n", "                    ", "_", ",", "D_loss", "=", "sess", ".", "run", "(", "[", "model", ".", "D_train", ",", "model", ".", "D_loss", "]", ",", "feed_dict", "=", "{", "model", ".", "epoch", ":", "epoch", "}", ")", "\n", "\n", "", "_", ",", "G_loss", "=", "sess", ".", "run", "(", "[", "model", ".", "G_train", ",", "model", ".", "G_loss", "]", ",", "feed_dict", "=", "{", "model", ".", "epoch", ":", "epoch", "}", ")", "\n", "\n", "e_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "if", "epoch", "%", "args", ".", "log_freq", "==", "0", ":", "\n", "                ", "summary", "=", "sess", ".", "run", "(", "merged", ")", "\n", "train_writer", ".", "add_summary", "(", "summary", ",", "epoch", ")", "\n", "if", "args", ".", "test_with_train", ":", "\n", "                    ", "test", "(", "args", ",", "model", ",", "sess", ",", "saver", ",", "f", ",", "epoch", ",", "loading", "=", "False", ")", "\n", "", "print", "(", "\"%d training epoch completed\"", "%", "epoch", ")", "\n", "print", "(", "\"D_loss : %0.4f, \\t G_loss : %0.4f\"", "%", "(", "D_loss", ",", "G_loss", ")", ")", "\n", "print", "(", "\"Elpased time : %0.4f\"", "%", "(", "e_time", "-", "s_time", ")", ")", "\n", "", "if", "(", "(", "epoch", ")", "%", "args", ".", "model_save_freq", "==", "0", ")", ":", "\n", "                ", "saver", ".", "save", "(", "sess", ",", "'./model/DeblurrGAN'", ",", "global_step", "=", "epoch", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "epoch", "+=", "1", "\n", "\n", "", "saver", ".", "save", "(", "sess", ",", "'./model/DeblurrGAN_last'", ",", "global_step", "=", "epoch", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "if", "args", ".", "test_with_train", ":", "\n", "        ", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.mode.test": [[96, 154], ["sorted", "sorted", "len", "saver.restore", "print", "print", "os.listdir", "os.listdir", "util.image_loader", "util.image_loader", "util.image_loader", "enumerate", "sess.run", "range", "sum", "sum", "file.write", "file.close", "file.write", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "sess.run", "PSNR_list.append", "ssim_list.append", "len", "sess.run", "PSNR_list.append", "ssim_list.append", "PIL.Image.fromarray", "blur_img_name[].split", "Image.fromarray.save", "PIL.Image.fromarray", "blur_img_name[].split", "Image.fromarray.save", "os.path.join", "os.path.join", "map", "map"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.image_loader", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.image_loader", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.image_loader"], ["", "", "def", "test", "(", "args", ",", "model", ",", "sess", ",", "saver", ",", "file", ",", "step", "=", "-", "1", ",", "loading", "=", "False", ")", ":", "\n", "\n", "    ", "if", "loading", ":", "\n", "        ", "saver", ".", "restore", "(", "sess", ",", "args", ".", "pre_trained_model", ")", "\n", "print", "(", "\"saved model is loaded for test!\"", ")", "\n", "print", "(", "\"model path is %s\"", "%", "args", ".", "pre_trained_model", ")", "\n", "\n", "", "blur_img_name", "=", "sorted", "(", "os", ".", "listdir", "(", "args", ".", "test_Blur_path", ")", ")", "\n", "sharp_img_name", "=", "sorted", "(", "os", ".", "listdir", "(", "args", ".", "test_Sharp_path", ")", ")", "\n", "\n", "PSNR_list", "=", "[", "]", "\n", "ssim_list", "=", "[", "]", "\n", "\n", "if", "args", ".", "in_memory", ":", "\n", "\n", "        ", "blur_imgs", "=", "util", ".", "image_loader", "(", "args", ".", "test_Blur_path", ",", "args", ".", "load_X", ",", "args", ".", "load_Y", ",", "is_train", "=", "False", ")", "\n", "sharp_imgs", "=", "util", ".", "image_loader", "(", "args", ".", "test_Sharp_path", ",", "args", ".", "load_X", ",", "args", ".", "load_Y", ",", "is_train", "=", "False", ")", "\n", "edges", "=", "util", ".", "image_loader", "(", "args", ".", "test_edges_path", ",", "args", ".", "load_X", ",", "args", ".", "load_Y", ",", "is_train", "=", "False", ")", "\n", "for", "i", ",", "ele", "in", "enumerate", "(", "blur_imgs", ")", ":", "\n", "            ", "blur", "=", "np", ".", "expand_dims", "(", "ele", ",", "axis", "=", "0", ")", "\n", "edges", "=", "np", ".", "expand_dims", "(", "ele", ",", "axis", "=", "0", ")", "\n", "sharp", "=", "np", ".", "expand_dims", "(", "sharp_imgs", "[", "i", "]", ",", "axis", "=", "0", ")", "\n", "output", ",", "psnr", ",", "ssim", "=", "sess", ".", "run", "(", "[", "model", ".", "output", ",", "model", ".", "PSNR", ",", "model", ".", "ssim", "]", ",", "feed_dict", "=", "{", "model", ".", "blur", ":", "blur", ",", "model", ".", "sharp", ":", "sharp", ",", "model", ".", "edges", ":", "edges", "}", ")", "\n", "if", "args", ".", "save_test_result", ":", "\n", "                ", "output", "=", "Image", ".", "fromarray", "(", "output", "[", "0", "]", ")", "\n", "split_name", "=", "blur_img_name", "[", "i", "]", ".", "split", "(", "'.'", ")", "\n", "output", ".", "save", "(", "os", ".", "path", ".", "join", "(", "args", ".", "result_path", ",", "'%s_sharp.png'", "%", "(", "''", ".", "join", "(", "map", "(", "str", ",", "split_name", "[", ":", "-", "1", "]", ")", ")", ")", ")", ")", "\n", "\n", "", "PSNR_list", ".", "append", "(", "psnr", ")", "\n", "ssim_list", ".", "append", "(", "ssim", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "        ", "sess", ".", "run", "(", "model", ".", "data_loader", ".", "init_op", "[", "'val_init'", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "blur_img_name", ")", ")", ":", "\n", "\n", "            ", "output", ",", "psnr", ",", "ssim", "=", "sess", ".", "run", "(", "[", "model", ".", "output", ",", "model", ".", "PSNR", ",", "model", ".", "ssim", "]", ")", "\n", "\n", "if", "args", ".", "save_test_result", ":", "\n", "                ", "output", "=", "Image", ".", "fromarray", "(", "output", "[", "0", "]", ")", "\n", "split_name", "=", "blur_img_name", "[", "i", "]", ".", "split", "(", "'.'", ")", "\n", "output", ".", "save", "(", "os", ".", "path", ".", "join", "(", "args", ".", "result_path", ",", "'%s_sharp.png'", "%", "(", "''", ".", "join", "(", "map", "(", "str", ",", "split_name", "[", ":", "-", "1", "]", ")", ")", ")", ")", ")", "\n", "\n", "", "PSNR_list", ".", "append", "(", "psnr", ")", "\n", "ssim_list", ".", "append", "(", "ssim", ")", "\n", "\n", "", "", "length", "=", "len", "(", "PSNR_list", ")", "\n", "\n", "mean_PSNR", "=", "sum", "(", "PSNR_list", ")", "/", "length", "\n", "mean_ssim", "=", "sum", "(", "ssim_list", ")", "/", "length", "\n", "\n", "if", "step", "==", "-", "1", ":", "\n", "        ", "file", ".", "write", "(", "'PSNR : 0.4f SSIM : %0.4f'", "%", "(", "mean_PSNR", ",", "mean_ssim", ")", ")", "\n", "file", ".", "close", "(", ")", "\n", "\n", "", "else", ":", "\n", "        ", "file", ".", "write", "(", "\"%d-epoch step PSNR : %0.4f SSIM : %0.4f \\n\"", "%", "(", "step", ",", "mean_PSNR", ",", "mean_ssim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.mode.test_only": [[157, 192], ["saver.restore", "print", "print", "sorted", "os.listdir", "util.image_loader", "enumerate", "sess.run", "range", "numpy.expand_dims", "blur_img_name[].split", "Image.fromarray.save", "len", "sess.run", "PIL.Image.fromarray", "blur_img_name[].split", "Image.fromarray.save", "util.recursive_forwarding", "PIL.Image.fromarray", "sess.run", "PIL.Image.fromarray", "os.path.join", "os.path.join", "map", "map"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.image_loader", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.recursive_forwarding"], ["", "", "def", "test_only", "(", "args", ",", "model", ",", "sess", ",", "saver", ")", ":", "\n", "\n", "    ", "saver", ".", "restore", "(", "sess", ",", "args", ".", "pre_trained_model", ")", "\n", "print", "(", "\"saved model is loaded for test only!\"", ")", "\n", "print", "(", "\"model path is %s\"", "%", "args", ".", "pre_trained_model", ")", "\n", "\n", "blur_img_name", "=", "sorted", "(", "os", ".", "listdir", "(", "args", ".", "test_Blur_path", ")", ")", "\n", "\n", "if", "args", ".", "in_memory", ":", "\n", "\n", "        ", "blur_imgs", "=", "util", ".", "image_loader", "(", "args", ".", "test_Blur_path", ",", "args", ".", "load_X", ",", "args", ".", "load_Y", ",", "is_train", "=", "False", ")", "\n", "\n", "for", "i", ",", "ele", "in", "enumerate", "(", "blur_imgs", ")", ":", "\n", "            ", "blur", "=", "np", ".", "expand_dims", "(", "ele", ",", "axis", "=", "0", ")", "\n", "\n", "if", "args", ".", "chop_forward", ":", "\n", "                ", "output", "=", "util", ".", "recursive_forwarding", "(", "blur", ",", "args", ".", "chop_size", ",", "sess", ",", "model", ",", "args", ".", "chop_shave", ")", "\n", "output", "=", "Image", ".", "fromarray", "(", "output", "[", "0", "]", ")", "\n", "\n", "", "else", ":", "\n", "                ", "output", "=", "sess", ".", "run", "(", "model", ".", "output", ",", "feed_dict", "=", "{", "model", ".", "blur", ":", "blur", "}", ")", "\n", "output", "=", "Image", ".", "fromarray", "(", "output", "[", "0", "]", ")", "\n", "\n", "", "split_name", "=", "blur_img_name", "[", "i", "]", ".", "split", "(", "'.'", ")", "\n", "output", ".", "save", "(", "os", ".", "path", ".", "join", "(", "args", ".", "result_path", ",", "'%s_sharp.png'", "%", "(", "''", ".", "join", "(", "map", "(", "str", ",", "split_name", "[", ":", "-", "1", "]", ")", ")", ")", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "        ", "sess", ".", "run", "(", "model", ".", "data_loader", ".", "init_op", "[", "'te_init'", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "blur_img_name", ")", ")", ":", "\n", "            ", "output", "=", "sess", ".", "run", "(", "model", ".", "output", ")", "\n", "output", "=", "Image", ".", "fromarray", "(", "output", "[", "0", "]", ")", "\n", "split_name", "=", "blur_img_name", "[", "i", "]", ".", "split", "(", "'.'", ")", "\n", "output", ".", "save", "(", "os", ".", "path", ".", "join", "(", "args", ".", "result_path", ",", "'%s_sharp.png'", "%", "(", "''", ".", "join", "(", "map", "(", "str", ",", "split_name", "[", ":", "-", "1", "]", ")", ")", ")", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.__init__": [[10, 26], ["data_loader.dataloader"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "\n", "        ", "self", ".", "data_loader", "=", "dataloader", "(", "args", ")", "\n", "\n", "self", ".", "channel", "=", "args", ".", "channel", "\n", "self", ".", "n_feats", "=", "args", ".", "n_feats", "\n", "self", ".", "in_memory", "=", "args", ".", "in_memory", "\n", "self", ".", "mode", "=", "args", ".", "mode", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "self", ".", "num_of_down_scale", "=", "args", ".", "num_of_down_scale", "\n", "self", ".", "gen_resblocks", "=", "args", ".", "gen_resblocks", "\n", "self", ".", "discrim_blocks", "=", "args", ".", "discrim_blocks", "\n", "self", ".", "vgg_path", "=", "args", ".", "vgg_path", "\n", "\n", "self", ".", "learning_rate", "=", "args", ".", "learning_rate", "\n", "self", ".", "decay_step", "=", "args", ".", "decay_step", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.down_scaling_feature": [[27, 33], ["ops.Conv", "ops.instance_norm", "tensorflow.nn.relu"], "methods", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu"], ["", "def", "down_scaling_feature", "(", "self", ",", "name", ",", "x", ",", "n_feats", ")", ":", "\n", "        ", "x", "=", "Conv", "(", "name", "=", "name", "+", "'conv'", ",", "x", "=", "x", ",", "filter_size", "=", "3", ",", "in_filters", "=", "n_feats", ",", "out_filters", "=", "n_feats", "*", "2", ",", "strides", "=", "2", ",", "padding", "=", "'SAME'", ")", "\n", "x", "=", "instance_norm", "(", "name", "=", "name", "+", "'instance_norm'", ",", "x", "=", "x", ",", "dim", "=", "n_feats", "*", "2", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.up_scaling_feature": [[34, 40], ["ops.Conv_transpose", "ops.instance_norm", "tensorflow.nn.relu"], "methods", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv_transpose", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu"], ["", "def", "up_scaling_feature", "(", "self", ",", "name", ",", "x", ",", "n_feats", ")", ":", "\n", "        ", "x", "=", "Conv_transpose", "(", "name", "=", "name", "+", "'deconv'", ",", "x", "=", "x", ",", "filter_size", "=", "3", ",", "in_filters", "=", "n_feats", ",", "out_filters", "=", "n_feats", "//", "2", ",", "fraction", "=", "2", ",", "padding", "=", "'SAME'", ")", "\n", "x", "=", "instance_norm", "(", "name", "=", "name", "+", "'instance_norm'", ",", "x", "=", "x", ",", "dim", "=", "n_feats", "//", "2", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.res_block": [[41, 57], ["tensorflow.pad", "ops.Conv", "ops.instance_norm", "tensorflow.nn.relu", "tensorflow.pad", "ops.Conv", "ops.instance_norm"], "methods", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm"], ["", "def", "res_block", "(", "self", ",", "name", ",", "x", ",", "n_feats", ")", ":", "\n", "\n", "        ", "_res", "=", "x", "\n", "\n", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "'REFLECT'", ")", "\n", "x", "=", "Conv", "(", "name", "=", "name", "+", "'conv1'", ",", "x", "=", "x", ",", "filter_size", "=", "3", ",", "in_filters", "=", "n_feats", ",", "out_filters", "=", "n_feats", ",", "strides", "=", "1", ",", "padding", "=", "'VALID'", ")", "\n", "x", "=", "instance_norm", "(", "name", "=", "name", "+", "'instance_norm1'", ",", "x", "=", "x", ",", "dim", "=", "n_feats", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "'REFLECT'", ")", "\n", "x", "=", "Conv", "(", "name", "=", "name", "+", "'conv2'", ",", "x", "=", "x", ",", "filter_size", "=", "3", ",", "in_filters", "=", "n_feats", ",", "out_filters", "=", "n_feats", ",", "strides", "=", "1", ",", "padding", "=", "'VALID'", ")", "\n", "x", "=", "instance_norm", "(", "name", "=", "name", "+", "'instance_norm2'", ",", "x", "=", "x", ",", "dim", "=", "n_feats", ")", "\n", "\n", "x", "=", "x", "+", "_res", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.generator": [[58, 84], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.pad", "ops.Conv", "ops.instance_norm", "tensorflow.nn.relu", "range", "range", "range", "tensorflow.pad", "ops.Conv", "tensorflow.nn.tanh", "tensorflow.clip_by_value", "Deblur_Net.Deblur_Net.down_scaling_feature", "Deblur_Net.Deblur_Net.res_block", "Deblur_Net.Deblur_Net.up_scaling_feature"], "methods", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.down_scaling_feature", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.res_block", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.up_scaling_feature"], ["", "def", "generator", "(", "self", ",", "x", ",", "edge", ",", "reuse", "=", "False", ",", "name", "=", "'generator'", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name_or_scope", "=", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "_res", "=", "x", "\n", "x", "=", "tf", ".", "concat", "(", "[", "x", ",", "edge", "]", ",", "axis", "=", "-", "1", ")", "\n", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "3", ",", "3", "]", ",", "[", "3", ",", "3", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "'REFLECT'", ")", "\n", "x", "=", "Conv", "(", "name", "=", "'conv1'", ",", "x", "=", "x", ",", "filter_size", "=", "7", ",", "in_filters", "=", "self", ".", "channel", "+", "1", ",", "out_filters", "=", "self", ".", "n_feats", ",", "strides", "=", "1", ",", "padding", "=", "'VALID'", ")", "\n", "x", "=", "instance_norm", "(", "name", "=", "'inst_norm1'", ",", "x", "=", "x", ",", "dim", "=", "self", ".", "n_feats", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_of_down_scale", ")", ":", "\n", "                ", "x", "=", "self", ".", "down_scaling_feature", "(", "name", "=", "'down_%02d'", "%", "i", ",", "x", "=", "x", ",", "n_feats", "=", "self", ".", "n_feats", "*", "(", "i", "+", "1", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "gen_resblocks", ")", ":", "\n", "                ", "x", "=", "self", ".", "res_block", "(", "name", "=", "'res_%02d'", "%", "i", ",", "x", "=", "x", ",", "n_feats", "=", "self", ".", "n_feats", "*", "(", "2", "**", "self", ".", "num_of_down_scale", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_of_down_scale", ")", ":", "\n", "                ", "x", "=", "self", ".", "up_scaling_feature", "(", "name", "=", "'up_%02d'", "%", "i", ",", "x", "=", "x", ",", "n_feats", "=", "self", ".", "n_feats", "*", "(", "2", "**", "(", "self", ".", "num_of_down_scale", "-", "i", ")", ")", ")", "\n", "\n", "", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "3", ",", "3", "]", ",", "[", "3", ",", "3", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "'REFLECT'", ")", "\n", "x", "=", "Conv", "(", "name", "=", "'conv_last'", ",", "x", "=", "x", ",", "filter_size", "=", "7", ",", "in_filters", "=", "self", ".", "n_feats", ",", "out_filters", "=", "self", ".", "channel", ",", "strides", "=", "1", ",", "padding", "=", "'VALID'", ")", "\n", "x", "=", "tf", ".", "nn", ".", "tanh", "(", "x", ")", "\n", "x", "=", "x", "+", "_res", "\n", "x", "=", "tf", ".", "clip_by_value", "(", "x", ",", "-", "1.0", ",", "1.0", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.discriminator": [[85, 112], ["tensorflow.variable_scope", "ops.Conv", "ops.instance_norm", "tensorflow.nn.leaky_relu", "range", "min", "ops.Conv", "ops.instance_norm", "tensorflow.nn.leaky_relu", "ops.Conv", "tensorflow.nn.sigmoid", "min", "ops.Conv", "ops.instance_norm", "tensorflow.nn.leaky_relu"], "methods", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.Conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.ops.instance_norm"], ["", "", "def", "discriminator", "(", "self", ",", "x", ",", "reuse", "=", "False", ",", "name", "=", "'discriminator'", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name_or_scope", "=", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "x", "=", "Conv", "(", "name", "=", "'conv1'", ",", "x", "=", "x", ",", "filter_size", "=", "4", ",", "in_filters", "=", "self", ".", "channel", ",", "out_filters", "=", "self", ".", "n_feats", ",", "strides", "=", "2", ",", "padding", "=", "\"SAME\"", ")", "\n", "x", "=", "instance_norm", "(", "name", "=", "'inst_norm1'", ",", "x", "=", "x", ",", "dim", "=", "self", ".", "n_feats", ")", "\n", "x", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "x", ")", "\n", "\n", "prev", "=", "1", "\n", "n", "=", "1", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "discrim_blocks", ")", ":", "\n", "                ", "prev", "=", "n", "\n", "n", "=", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "x", "=", "Conv", "(", "name", "=", "'conv%02d'", "%", "i", ",", "x", "=", "x", ",", "filter_size", "=", "4", ",", "in_filters", "=", "self", ".", "n_feats", "*", "prev", ",", "out_filters", "=", "self", ".", "n_feats", "*", "n", ",", "strides", "=", "2", ",", "padding", "=", "\"SAME\"", ")", "\n", "x", "=", "instance_norm", "(", "name", "=", "'instance_norm%02d'", "%", "i", ",", "x", "=", "x", ",", "dim", "=", "self", ".", "n_feats", "*", "n", ")", "\n", "x", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "x", ")", "\n", "\n", "", "prev", "=", "n", "\n", "n", "=", "min", "(", "2", "**", "self", ".", "discrim_blocks", ",", "8", ")", "\n", "x", "=", "Conv", "(", "name", "=", "'conv_d1'", ",", "x", "=", "x", ",", "filter_size", "=", "4", ",", "in_filters", "=", "self", ".", "n_feats", "*", "prev", ",", "out_filters", "=", "self", ".", "n_feats", "*", "n", ",", "strides", "=", "1", ",", "padding", "=", "\"SAME\"", ")", "\n", "x", "=", "instance_norm", "(", "name", "=", "'instance_norm_d1'", ",", "x", "=", "x", ",", "dim", "=", "self", ".", "n_feats", "*", "n", ")", "\n", "x", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "x", ")", "\n", "\n", "x", "=", "Conv", "(", "name", "=", "'conv_d2'", ",", "x", "=", "x", ",", "filter_size", "=", "4", ",", "in_filters", "=", "self", ".", "n_feats", "*", "n", ",", "out_filters", "=", "1", ",", "strides", "=", "1", ",", "padding", "=", "\"SAME\"", ")", "\n", "x", "=", "tf", ".", "nn", ".", "sigmoid", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.Deblur_Net.Deblur_Net.build_graph": [[114, 183], ["tensorflow.placeholder", "Deblur_Net.Deblur_Net.generator", "Deblur_Net.Deblur_Net.discriminator", "Deblur_Net.Deblur_Net.discriminator", "tensorflow.random_uniform", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.round", "tensorflow.cast", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "Deblur_Net.Deblur_Net.data_loader.build_loader", "tensorflow.gradients", "tensorflow.square", "tensorflow.reduce_mean", "vgg19.Vgg19", "Deblur_Net.Deblur_Net.vgg_net.build", "tensorflow.reduce_mean", "tensorflow.trainable_variables", "tensorflow.minimum", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.image.psnr", "tensorflow.image.ssim", "tensorflow.placeholder", "Deblur_Net.Deblur_Net.discriminator", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.abs", "tensorflow.sqrt", "tensorflow.square", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.generator", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.discriminator", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.discriminator", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.data_loader.dataloader.build_loader", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.discriminator"], ["", "", "def", "build_graph", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "in_memory", ":", "\n", "            ", "self", ".", "blur", "=", "tf", ".", "placeholder", "(", "name", "=", "\"blur\"", ",", "shape", "=", "[", "None", ",", "None", ",", "None", ",", "self", ".", "channel", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "sharp", "=", "tf", ".", "placeholder", "(", "name", "=", "\"sharp\"", ",", "shape", "=", "[", "None", ",", "None", ",", "None", ",", "self", ".", "channel", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "edges", "=", "tf", ".", "placeholder", "(", "name", "=", "\"edges\"", ",", "shape", "=", "[", "None", ",", "None", ",", "None", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "x", "=", "self", ".", "blur", "\n", "edge", "=", "self", ".", "edges", "\n", "label", "=", "self", ".", "sharp", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "data_loader", ".", "build_loader", "(", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'test_only'", ":", "\n", "                ", "x", "=", "self", ".", "data_loader", ".", "next_batch", "\n", "label", "=", "tf", ".", "placeholder", "(", "name", "=", "'dummy'", ",", "shape", "=", "[", "None", ",", "None", ",", "None", ",", "self", ".", "channel", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "elif", "self", ".", "mode", "==", "'train'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "x", "=", "self", ".", "data_loader", ".", "next_batch", "[", "0", "]", "\n", "label", "=", "self", ".", "data_loader", ".", "next_batch", "[", "1", "]", "\n", "\n", "", "", "self", ".", "epoch", "=", "tf", ".", "placeholder", "(", "name", "=", "'train_step'", ",", "shape", "=", "None", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "x", "=", "(", "2.0", "*", "x", "/", "255.0", ")", "-", "1.0", "\n", "label", "=", "(", "2.0", "*", "label", "/", "255.0", ")", "-", "1.0", "\n", "edge", "=", "(", "2.0", "*", "edge", "/", "255", ")", "-", "1.0", "\n", "\n", "self", ".", "gene_img", "=", "self", ".", "generator", "(", "x", ",", "edge", ",", "reuse", "=", "False", ")", "\n", "self", ".", "real_prob", "=", "self", ".", "discriminator", "(", "label", ",", "reuse", "=", "False", ")", "\n", "self", ".", "fake_prob", "=", "self", ".", "discriminator", "(", "self", ".", "gene_img", ",", "reuse", "=", "True", ")", "\n", "\n", "epsilon", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "self", ".", "batch_size", ",", "1", ",", "1", ",", "1", "]", ",", "minval", "=", "0.0", ",", "maxval", "=", "1.0", ")", "\n", "\n", "interpolated_input", "=", "epsilon", "*", "label", "+", "(", "1", "-", "epsilon", ")", "*", "self", ".", "gene_img", "\n", "gradient", "=", "tf", ".", "gradients", "(", "self", ".", "discriminator", "(", "interpolated_input", ",", "reuse", "=", "True", ")", ",", "[", "interpolated_input", "]", ")", "[", "0", "]", "\n", "GP_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "gradient", ")", ",", "axis", "=", "[", "1", ",", "2", ",", "3", "]", ")", ")", "-", "1", ")", ")", "\n", "\n", "d_loss_real", "=", "-", "tf", ".", "reduce_mean", "(", "self", ".", "real_prob", ")", "\n", "d_loss_fake", "=", "tf", ".", "reduce_mean", "(", "self", ".", "fake_prob", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "            ", "self", ".", "vgg_net", "=", "Vgg19", "(", "self", ".", "vgg_path", ")", "\n", "self", ".", "vgg_net", ".", "build", "(", "tf", ".", "concat", "(", "[", "label", ",", "self", ".", "gene_img", "]", ",", "axis", "=", "0", ")", ")", "\n", "self", ".", "content_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "self", ".", "vgg_net", ".", "relu3_3", "[", "self", ".", "batch_size", ":", "]", "-", "self", ".", "vgg_net", ".", "relu3_3", "[", ":", "self", ".", "batch_size", "]", ")", ",", "axis", "=", "3", ")", ")", "\n", "\n", "self", ".", "D_loss", "=", "d_loss_real", "+", "d_loss_fake", "+", "10.0", "*", "GP_loss", "\n", "self", ".", "G_loss", "=", "-", "d_loss_fake", "+", "100.0", "*", "self", ".", "content_loss", "\n", "\n", "t_vars", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "G_vars", "=", "[", "var", "for", "var", "in", "t_vars", "if", "'generator'", "in", "var", ".", "name", "]", "\n", "D_vars", "=", "[", "var", "for", "var", "in", "t_vars", "if", "'discriminator'", "in", "var", ".", "name", "]", "\n", "\n", "lr", "=", "tf", ".", "minimum", "(", "self", ".", "learning_rate", ",", "tf", ".", "abs", "(", "2", "*", "self", ".", "learning_rate", "-", "(", "self", ".", "learning_rate", "*", "tf", ".", "cast", "(", "self", ".", "epoch", ",", "tf", ".", "float32", ")", "/", "self", ".", "decay_step", ")", ")", ")", "\n", "self", ".", "D_train", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "lr", ")", ".", "minimize", "(", "self", ".", "D_loss", ",", "var_list", "=", "D_vars", ")", "\n", "self", ".", "G_train", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "lr", ")", ".", "minimize", "(", "self", ".", "G_loss", ",", "var_list", "=", "G_vars", ")", "\n", "\n", "logging_D_loss", "=", "tf", ".", "summary", ".", "scalar", "(", "name", "=", "'D_loss'", ",", "tensor", "=", "self", ".", "D_loss", ")", "\n", "logging_G_loss", "=", "tf", ".", "summary", ".", "scalar", "(", "name", "=", "'G_loss'", ",", "tensor", "=", "self", ".", "G_loss", ")", "\n", "\n", "", "self", ".", "PSNR", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "image", ".", "psnr", "(", "(", "(", "self", ".", "gene_img", "+", "1.0", ")", "/", "2.0", ")", ",", "(", "(", "label", "+", "1.0", ")", "/", "2.0", ")", ",", "max_val", "=", "1.0", ")", ")", "\n", "self", ".", "ssim", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "image", ".", "ssim", "(", "(", "(", "self", ".", "gene_img", "+", "1.0", ")", "/", "2.0", ")", ",", "(", "(", "label", "+", "1.0", ")", "/", "2.0", ")", ",", "max_val", "=", "1.0", ")", ")", "\n", "\n", "logging_PSNR", "=", "tf", ".", "summary", ".", "scalar", "(", "name", "=", "'PSNR'", ",", "tensor", "=", "self", ".", "PSNR", ")", "\n", "logging_ssim", "=", "tf", ".", "summary", ".", "scalar", "(", "name", "=", "'ssim'", ",", "tensor", "=", "self", ".", "ssim", ")", "\n", "\n", "self", ".", "output", "=", "(", "self", ".", "gene_img", "+", "1.0", ")", "*", "255.0", "/", "2.0", "\n", "self", ".", "output", "=", "tf", ".", "round", "(", "self", ".", "output", ")", "\n", "self", ".", "output", "=", "tf", ".", "cast", "(", "self", ".", "output", ",", "tf", ".", "uint8", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.image_loader": [[7, 18], ["sorted", "os.listdir", "PIL.Image.open", "img_list.append", "os.path.join", "img.resize.resize", "numpy.array"], "function", ["None"], ["def", "image_loader", "(", "image_path", ",", "load_x", ",", "load_y", ",", "is_train", "=", "True", ")", ":", "\n", "\n", "    ", "imgs", "=", "sorted", "(", "os", ".", "listdir", "(", "image_path", ")", ")", "\n", "img_list", "=", "[", "]", "\n", "for", "ele", "in", "imgs", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "image_path", ",", "ele", ")", ")", "\n", "if", "is_train", ":", "\n", "            ", "img", "=", "img", ".", "resize", "(", "(", "load_x", ",", "load_y", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "", "img_list", ".", "append", "(", "np", ".", "array", "(", "img", ")", ")", "\n", "\n", "", "return", "img_list", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.data_augument": [[19, 42], ["numpy.rot90", "numpy.rot90", "numpy.fliplr", "numpy.fliplr", "numpy.flipud", "numpy.flipud", "numpy.rot90", "numpy.rot90", "numpy.fliplr", "numpy.fliplr", "numpy.rot90", "numpy.rot90", "numpy.flipud", "numpy.flipud"], "function", ["None"], ["", "def", "data_augument", "(", "lr_img", ",", "hr_img", ",", "aug", ")", ":", "\n", "\n", "    ", "if", "aug", "<", "4", ":", "\n", "        ", "lr_img", "=", "np", ".", "rot90", "(", "lr_img", ",", "aug", ")", "\n", "hr_img", "=", "np", ".", "rot90", "(", "hr_img", ",", "aug", ")", "\n", "\n", "", "elif", "aug", "==", "4", ":", "\n", "        ", "lr_img", "=", "np", ".", "fliplr", "(", "lr_img", ")", "\n", "hr_img", "=", "np", ".", "fliplr", "(", "hr_img", ")", "\n", "\n", "", "elif", "aug", "==", "5", ":", "\n", "        ", "lr_img", "=", "np", ".", "flipud", "(", "lr_img", ")", "\n", "hr_img", "=", "np", ".", "flipud", "(", "hr_img", ")", "\n", "\n", "", "elif", "aug", "==", "6", ":", "\n", "        ", "lr_img", "=", "np", ".", "rot90", "(", "np", ".", "fliplr", "(", "lr_img", ")", ")", "\n", "hr_img", "=", "np", ".", "rot90", "(", "np", ".", "fliplr", "(", "hr_img", ")", ")", "\n", "\n", "", "elif", "aug", "==", "7", ":", "\n", "        ", "lr_img", "=", "np", ".", "rot90", "(", "np", ".", "flipud", "(", "lr_img", ")", ")", "\n", "hr_img", "=", "np", ".", "rot90", "(", "np", ".", "flipud", "(", "hr_img", ")", ")", "\n", "\n", "", "return", "lr_img", ",", "hr_img", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.batch_gen": [[43, 85], ["range", "numpy.array", "numpy.array", "numpy.array", "numpy.reshape", "all_img_blur.append", "all_img_sharp.append", "all_img_edges.append", "len", "random.randrange", "random.randrange", "np.array.append", "np.array.append", "np.reshape.append", "random.randrange", "util.data_augument"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.data_augument"], ["", "def", "batch_gen", "(", "blur_imgs", ",", "sharp_imgs", ",", "edges_imgs", ",", "patch_size", ",", "batch_size", ",", "random_index", ",", "step", ",", "augment", ")", ":", "\n", "\n", "    ", "img_index", "=", "random_index", "[", "step", "*", "batch_size", ":", "(", "step", "+", "1", ")", "*", "batch_size", "]", "\n", "\n", "all_img_blur", "=", "[", "]", "\n", "all_img_sharp", "=", "[", "]", "\n", "all_img_edges", "=", "[", "]", "\n", "\n", "for", "_index", "in", "img_index", ":", "\n", "        ", "all_img_blur", ".", "append", "(", "blur_imgs", "[", "_index", "]", ")", "\n", "all_img_sharp", ".", "append", "(", "sharp_imgs", "[", "_index", "]", ")", "\n", "all_img_edges", ".", "append", "(", "edges_imgs", "[", "_index", "]", ")", "\n", "\n", "", "blur_batch", "=", "[", "]", "\n", "sharp_batch", "=", "[", "]", "\n", "edges_batch", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "all_img_blur", ")", ")", ":", "\n", "\n", "        ", "ih", ",", "iw", ",", "_", "=", "all_img_blur", "[", "i", "]", ".", "shape", "\n", "ix", "=", "random", ".", "randrange", "(", "0", ",", "iw", "-", "patch_size", "+", "1", ")", "\n", "iy", "=", "random", ".", "randrange", "(", "0", ",", "ih", "-", "patch_size", "+", "1", ")", "\n", "\n", "img_blur_in", "=", "all_img_blur", "[", "i", "]", "[", "iy", ":", "iy", "+", "patch_size", ",", "ix", ":", "ix", "+", "patch_size", "]", "\n", "img_sharp_in", "=", "all_img_sharp", "[", "i", "]", "[", "iy", ":", "iy", "+", "patch_size", ",", "ix", ":", "ix", "+", "patch_size", "]", "\n", "img_edge_in", "=", "all_img_edges", "[", "i", "]", "[", "iy", ":", "iy", "+", "patch_size", ",", "ix", ":", "ix", "+", "patch_size", "]", "\n", "\n", "if", "augment", ":", "\n", "\n", "            ", "aug", "=", "random", ".", "randrange", "(", "0", ",", "8", ")", "\n", "img_blur_in", ",", "img_sharp_in", "=", "data_augument", "(", "img_blur_in", ",", "img_sharp_in", ",", "aug", ")", "\n", "\n", "", "blur_batch", ".", "append", "(", "img_blur_in", ")", "\n", "sharp_batch", ".", "append", "(", "img_sharp_in", ")", "\n", "edges_batch", ".", "append", "(", "img_edge_in", ")", "\n", "\n", "", "blur_batch", "=", "np", ".", "array", "(", "blur_batch", ")", "\n", "sharp_batch", "=", "np", ".", "array", "(", "sharp_batch", ")", "\n", "edges_batch", "=", "np", ".", "array", "(", "edges_batch", ")", "\n", "edges_batch", "=", "np", ".", "reshape", "(", "edges_batch", ",", "(", "batch_size", ",", "edges_batch", ".", "shape", "[", "1", "]", ",", "edges_batch", ".", "shape", "[", "2", "]", ",", "1", ")", ")", "\n", "\n", "return", "blur_batch", ",", "sharp_batch", ",", "edges_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.recursive_forwarding": [[90, 115], ["math.floor", "math.floor", "numpy.array", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "session.run", "outputPatch.append", "util.recursive_forwarding", "outputPatch.append"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.DeblurGAN.util.recursive_forwarding"], ["", "def", "recursive_forwarding", "(", "blur", ",", "chopSize", ",", "session", ",", "net_model", ",", "chopShave", "=", "20", ")", ":", "\n", "    ", "b", ",", "h", ",", "w", ",", "c", "=", "blur", ".", "shape", "\n", "wHalf", "=", "math", ".", "floor", "(", "w", "/", "2", ")", "\n", "hHalf", "=", "math", ".", "floor", "(", "h", "/", "2", ")", "\n", "\n", "wc", "=", "wHalf", "+", "chopShave", "\n", "hc", "=", "hHalf", "+", "chopShave", "\n", "\n", "inputPatch", "=", "np", ".", "array", "(", "(", "blur", "[", ":", ",", ":", "hc", ",", ":", "wc", ",", ":", "]", ",", "blur", "[", ":", ",", ":", "hc", ",", "(", "w", "-", "wc", ")", ":", ",", ":", "]", ",", "blur", "[", ":", ",", "(", "h", "-", "hc", ")", ":", ",", ":", "wc", ",", ":", "]", ",", "blur", "[", ":", ",", "(", "h", "-", "hc", ")", ":", ",", "(", "w", "-", "wc", ")", ":", ",", ":", "]", ")", ")", "\n", "outputPatch", "=", "[", "]", "\n", "if", "wc", "*", "hc", "<", "chopSize", ":", "\n", "        ", "for", "ele", "in", "inputPatch", ":", "\n", "            ", "output", "=", "session", ".", "run", "(", "net_model", ".", "output", ",", "feed_dict", "=", "{", "net_model", ".", "blur", ":", "ele", "}", ")", "\n", "outputPatch", ".", "append", "(", "output", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "for", "ele", "in", "inputPatch", ":", "\n", "            ", "output", "=", "recursive_forwarding", "(", "ele", ",", "chopSize", ",", "session", ",", "net_model", ",", "chopShave", ")", "\n", "outputPatch", ".", "append", "(", "output", ")", "\n", "\n", "", "", "upper", "=", "np", ".", "concatenate", "(", "(", "outputPatch", "[", "0", "]", "[", ":", ",", ":", "hHalf", ",", ":", "wHalf", ",", ":", "]", ",", "outputPatch", "[", "1", "]", "[", ":", ",", ":", "hHalf", ",", "wc", "-", "w", "+", "wHalf", ":", ",", ":", "]", ")", ",", "axis", "=", "2", ")", "\n", "rower", "=", "np", ".", "concatenate", "(", "(", "outputPatch", "[", "2", "]", "[", ":", ",", "hc", "-", "h", "+", "hHalf", ":", ",", ":", "wHalf", ",", ":", "]", ",", "outputPatch", "[", "3", "]", "[", ":", ",", "hc", "-", "h", "+", "hHalf", ":", ",", "wc", "-", "w", "+", "wHalf", ":", ",", ":", "]", ")", ",", "axis", "=", "2", ")", "\n", "output", "=", "np", ".", "concatenate", "(", "(", "upper", ",", "rower", ")", ",", "axis", "=", "1", ")", "\n", "\n", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.preprocess": [[68, 72], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.deprocess": [[74, 78], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.preprocess_lab": [[80, 87], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.deprocess_lab": [[89, 93], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.augment": [[95, 102], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix.deprocess_lab", "pix2pix.lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.deprocess_lab", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.l2_norm": [[106, 108], ["tensorflow.reduce_sum"], "function", ["None"], ["def", "l2_norm", "(", "v", ",", "eps", "=", "1e-12", ")", ":", "\n", "    ", "return", "v", "/", "(", "tf", ".", "reduce_sum", "(", "v", "**", "2", ")", "**", "0.5", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.spectral_norm": [[109, 135], ["tf.reshape.shape.as_list", "tensorflow.reshape", "tensorflow.get_variable", "range", "tensorflow.matmul", "tensorflow.matmul", "pix2pix.l2_norm", "tensorflow.matmul", "pix2pix.l2_norm", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.control_dependencies", "tensorflow.reshape", "tensorflow.truncated_normal_initializer", "tensorflow.transpose", "tf.get_variable.assign"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.l2_norm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.l2_norm"], ["", "def", "spectral_norm", "(", "w", ",", "iteration", "=", "1", ")", ":", "\n", "    ", "w_shape", "=", "w", ".", "shape", ".", "as_list", "(", ")", "\n", "w", "=", "tf", ".", "reshape", "(", "w", ",", "[", "-", "1", ",", "w_shape", "[", "-", "1", "]", "]", ")", "\n", "\n", "u", "=", "tf", ".", "get_variable", "(", "\"u\"", ",", "[", "1", ",", "w_shape", "[", "-", "1", "]", "]", ",", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", ")", ",", "trainable", "=", "False", ")", "\n", "\n", "u_hat", "=", "u", "\n", "v_hat", "=", "None", "\n", "for", "i", "in", "range", "(", "iteration", ")", ":", "\n", "        ", "\"\"\"\n        power iteration\n        Usually iteration = 1 will be enough\n        \"\"\"", "\n", "v_", "=", "tf", ".", "matmul", "(", "u_hat", ",", "tf", ".", "transpose", "(", "w", ")", ")", "\n", "v_hat", "=", "l2_norm", "(", "v_", ")", "\n", "\n", "u_", "=", "tf", ".", "matmul", "(", "v_hat", ",", "w", ")", "\n", "u_hat", "=", "l2_norm", "(", "u_", ")", "\n", "\n", "", "sigma", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "v_hat", ",", "w", ")", ",", "tf", ".", "transpose", "(", "u_hat", ")", ")", "\n", "w_norm", "=", "w", "/", "sigma", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "u", ".", "assign", "(", "u_hat", ")", "]", ")", ":", "\n", "        ", "w_norm", "=", "tf", ".", "reshape", "(", "w_norm", ",", "w_shape", ")", "\n", "\n", "", "return", "w_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.conv": [[137, 163], ["tensorflow.variable_scope", "tensorflow.pad", "tensorflow.pad", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.get_variable", "tensorflow.nn.bias_add", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d", "pix2pix.spectral_norm", "tensorflow.constant_initializer", "tf.layers.conv2d.get_shape"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.spectral_norm"], ["", "def", "conv", "(", "x", ",", "channels", ",", "kernel", "=", "4", ",", "stride", "=", "2", ",", "pad", "=", "0", ",", "pad_type", "=", "'zero'", ",", "padding", "=", "\"SAME\"", ",", "use_bias", "=", "True", ",", "scope", "=", "'conv'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "if", "pad_type", "==", "'zero'", ":", "\n", "            ", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "", "if", "pad_type", "==", "'reflect'", ":", "\n", "            ", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "'REFLECT'", ")", "\n", "\n", "", "if", "a", ".", "spectral_norm", ":", "\n", "            ", "w", "=", "tf", ".", "get_variable", "(", "\"kernel\"", ",", "shape", "=", "[", "kernel", ",", "kernel", ",", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "channels", "]", ",", "initializer", "=", "weight_init", ",", "\n", "regularizer", "=", "weight_regularizer", ")", "\n", "x", "=", "tf", ".", "nn", ".", "conv2d", "(", "input", "=", "x", ",", "filter", "=", "spectral_norm", "(", "w", ")", ",", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "padding", ")", "\n", "if", "use_bias", ":", "\n", "                ", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "channels", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "bias_add", "(", "x", ",", "bias", ")", "\n", "\n", "", "", "elif", "a", ".", "separable_conv", ":", "\n", "            ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "padding", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "\n", "", "else", ":", "\n", "            ", "x", "=", "tf", ".", "layers", ".", "conv2d", "(", "inputs", "=", "x", ",", "filters", "=", "channels", ",", "\n", "kernel_size", "=", "kernel", ",", "kernel_initializer", "=", "weight_init", ",", "\n", "kernel_regularizer", "=", "weight_regularizer", ",", "\n", "strides", "=", "stride", ",", "use_bias", "=", "use_bias", ",", "padding", "=", "padding", ")", "\n", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.deconv": [[165, 194], ["tensorflow.variable_scope", "tf.layers.conv2d_transpose.get_shape().as_list", "tensorflow.get_variable", "tensorflow.nn.conv2d_transpose", "tf.layers.conv2d_transpose.get_shape", "tensorflow.get_variable", "tensorflow.nn.bias_add", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose", "max", "max", "pix2pix.spectral_norm", "tensorflow.constant_initializer", "tf.layers.conv2d_transpose.get_shape"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.spectral_norm"], ["", "", "def", "deconv", "(", "x", ",", "channels", ",", "kernel", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ",", "use_bias", "=", "True", ",", "scope", "=", "'deconv'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "x_shape", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "\n", "if", "padding", "==", "'SAME'", ":", "\n", "            ", "output_shape", "=", "[", "x_shape", "[", "0", "]", ",", "x_shape", "[", "1", "]", "*", "stride", ",", "x_shape", "[", "2", "]", "*", "stride", ",", "channels", "]", "\n", "\n", "", "else", ":", "\n", "            ", "output_shape", "=", "[", "x_shape", "[", "0", "]", ",", "x_shape", "[", "1", "]", "*", "stride", "+", "max", "(", "kernel", "-", "stride", ",", "0", ")", ",", "x_shape", "[", "2", "]", "*", "stride", "+", "max", "(", "kernel", "-", "stride", ",", "0", ")", ",", "channels", "]", "\n", "\n", "", "if", "a", ".", "spectral_norm", ":", "\n", "            ", "w", "=", "tf", ".", "get_variable", "(", "\"kernel\"", ",", "shape", "=", "[", "kernel", ",", "kernel", ",", "channels", ",", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "]", ",", "initializer", "=", "weight_init", ",", "regularizer", "=", "weight_regularizer", ")", "\n", "x", "=", "tf", ".", "nn", ".", "conv2d_transpose", "(", "x", ",", "filter", "=", "spectral_norm", "(", "w", ")", ",", "output_shape", "=", "output_shape", ",", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "padding", ")", "\n", "\n", "if", "use_bias", ":", "\n", "                ", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "channels", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "bias_add", "(", "x", ",", "bias", ")", "\n", "\n", "", "", "elif", "a", ".", "separable_conv", ":", "\n", "            ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "\n", "", "else", ":", "\n", "            ", "x", "=", "tf", ".", "layers", ".", "conv2d_transpose", "(", "inputs", "=", "x", ",", "filters", "=", "channels", ",", "\n", "kernel_size", "=", "kernel", ",", "kernel_initializer", "=", "weight_init", ",", "kernel_regularizer", "=", "weight_regularizer", ",", "\n", "strides", "=", "stride", ",", "padding", "=", "padding", ",", "use_bias", "=", "use_bias", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.lrelu": [[195, 205], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.batchnorm": [[207, 209], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.check_image": [[211, 224], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.rgb_to_lab": [[226, 265], ["tensorflow.name_scope", "pix2pix.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.matmul", "tensorflow.name_scope", "tensorflow.multiply", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.shape", "tensorflow.matmul", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.check_image"], ["", "def", "rgb_to_lab", "(", "srgb", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"rgb_to_lab\"", ")", ":", "\n", "        ", "srgb", "=", "check_image", "(", "srgb", ")", "\n", "srgb_pixels", "=", "tf", ".", "reshape", "(", "srgb", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"srgb_to_xyz\"", ")", ":", "\n", "            ", "linear_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", "<=", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", ">", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rgb_pixels", "=", "(", "srgb_pixels", "/", "12.92", "*", "linear_mask", ")", "+", "(", "(", "(", "srgb_pixels", "+", "0.055", ")", "/", "1.055", ")", "**", "2.4", ")", "*", "exponential_mask", "\n", "rgb_to_xyz", "=", "tf", ".", "constant", "(", "[", "\n", "#    X        Y          Z", "\n", "[", "0.412453", ",", "0.212671", ",", "0.019334", "]", ",", "# R", "\n", "[", "0.357580", ",", "0.715160", ",", "0.119193", "]", ",", "# G", "\n", "[", "0.180423", ",", "0.072169", ",", "0.950227", "]", ",", "# B", "\n", "]", ")", "\n", "xyz_pixels", "=", "tf", ".", "matmul", "(", "rgb_pixels", ",", "rgb_to_xyz", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_cielab\"", ")", ":", "\n", "# convert to fx = f(X/Xn), fy = f(Y/Yn), fz = f(Z/Zn)", "\n", "\n", "# normalize for D65 white point", "\n", "            ", "xyz_normalized_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "1", "/", "0.950456", ",", "1.0", ",", "1", "/", "1.088754", "]", ")", "\n", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", "<=", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", ">", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "fxfyfz_pixels", "=", "(", "xyz_normalized_pixels", "/", "(", "3", "*", "epsilon", "**", "2", ")", "+", "4", "/", "29", ")", "*", "linear_mask", "+", "(", "xyz_normalized_pixels", "**", "(", "1", "/", "3", ")", ")", "*", "exponential_mask", "\n", "\n", "# convert to lab", "\n", "fxfyfz_to_lab", "=", "tf", ".", "constant", "(", "[", "\n", "#  l       a       b", "\n", "[", "0.0", ",", "500.0", ",", "0.0", "]", ",", "# fx", "\n", "[", "116.0", ",", "-", "500.0", ",", "200.0", "]", ",", "# fy", "\n", "[", "0.0", ",", "0.0", ",", "-", "200.0", "]", ",", "# fz", "\n", "]", ")", "\n", "lab_pixels", "=", "tf", ".", "matmul", "(", "fxfyfz_pixels", ",", "fxfyfz_to_lab", ")", "+", "tf", ".", "constant", "(", "[", "-", "16.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "lab_pixels", ",", "tf", ".", "shape", "(", "srgb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.lab_to_rgb": [[267, 307], ["tensorflow.name_scope", "pix2pix.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.cast", "tensorflow.cast", "tensorflow.multiply", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.cast", "tensorflow.shape", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.check_image"], ["", "", "def", "lab_to_rgb", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lab_to_rgb\"", ")", ":", "\n", "        ", "lab", "=", "check_image", "(", "lab", ")", "\n", "lab_pixels", "=", "tf", ".", "reshape", "(", "lab", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "with", "tf", ".", "name_scope", "(", "\"cielab_to_xyz\"", ")", ":", "\n", "# convert to fxfyfz", "\n", "            ", "lab_to_fxfyfz", "=", "tf", ".", "constant", "(", "[", "\n", "#   fx      fy        fz", "\n", "[", "1", "/", "116.0", ",", "1", "/", "116.0", ",", "1", "/", "116.0", "]", ",", "# l", "\n", "[", "1", "/", "500.0", ",", "0.0", ",", "0.0", "]", ",", "# a", "\n", "[", "0.0", ",", "0.0", ",", "-", "1", "/", "200.0", "]", ",", "# b", "\n", "]", ")", "\n", "fxfyfz_pixels", "=", "tf", ".", "matmul", "(", "lab_pixels", "+", "tf", ".", "constant", "(", "[", "16.0", ",", "0.0", ",", "0.0", "]", ")", ",", "lab_to_fxfyfz", ")", "\n", "\n", "# convert to xyz", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", "<=", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", ">", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "xyz_pixels", "=", "(", "3", "*", "epsilon", "**", "2", "*", "(", "fxfyfz_pixels", "-", "4", "/", "29", ")", ")", "*", "linear_mask", "+", "(", "fxfyfz_pixels", "**", "3", ")", "*", "exponential_mask", "\n", "\n", "# denormalize for D65 white point", "\n", "xyz_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "0.950456", ",", "1.0", ",", "1.088754", "]", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_srgb\"", ")", ":", "\n", "            ", "xyz_to_rgb", "=", "tf", ".", "constant", "(", "[", "\n", "#     r           g          b", "\n", "[", "3.2404542", ",", "-", "0.9692660", ",", "0.0556434", "]", ",", "# x", "\n", "[", "-", "1.5371385", ",", "1.8760108", ",", "-", "0.2040259", "]", ",", "# y", "\n", "[", "-", "0.4985314", ",", "0.0415560", ",", "1.0572252", "]", ",", "# z", "\n", "]", ")", "\n", "rgb_pixels", "=", "tf", ".", "matmul", "(", "xyz_pixels", ",", "xyz_to_rgb", ")", "\n", "# avoid a slightly negative number messing up the conversion", "\n", "rgb_pixels", "=", "tf", ".", "clip_by_value", "(", "rgb_pixels", ",", "0.0", ",", "1.0", ")", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", "<=", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", ">", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "srgb_pixels", "=", "(", "rgb_pixels", "*", "12.92", "*", "linear_mask", ")", "+", "(", "(", "rgb_pixels", "**", "(", "1", "/", "2.4", ")", "*", "1.055", ")", "-", "0.055", ")", "*", "exponential_mask", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "srgb_pixels", ",", "tf", ".", "shape", "(", "lab", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.load_examples": [[309, 402], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "tensorflow.image.resize_images", "tensorflow.name_scope", "pix2pix.load_examples.transform"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode"], ["", "", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "# load color and brightness from image, no B image exists here", "\n", "            ", "lab", "=", "rgb_to_lab", "(", "raw_input", ")", "\n", "L_chan", ",", "a_chan", ",", "b_chan", "=", "preprocess_lab", "(", "lab", ")", "\n", "a_images", "=", "tf", ".", "expand_dims", "(", "L_chan", ",", "axis", "=", "2", ")", "\n", "b_images", "=", "tf", ".", "stack", "(", "[", "a_chan", ",", "b_chan", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "            ", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "2", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "2", ":", ",", ":", "]", ")", "\n", "\n", "", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "a_images", ",", "b_images", "]", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "b_images", ",", "a_images", "]", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size_h", ",", "a", ".", "scale_size_w", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "if", "a", ".", "mode", "==", "\"train\"", ":", "\n", "            ", "offset_h", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "1", "]", ",", "0", ",", "a", ".", "scale_size_h", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "offset_w", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "1", "]", ",", "0", ",", "a", ".", "scale_size_w", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size_h", ">", "CROP_SIZE", "and", "a", ".", "scale_size_w", ">", "CROP_SIZE", ":", "\n", "                ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset_h", "[", "0", "]", ",", "offset_w", "[", "0", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "\n", "", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_images", "=", "transform", "(", "targets", ")", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets", "=", "targets_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.hw_flatten": [[404, 406], ["tensorflow.reshape"], "function", ["None"], ["", "def", "hw_flatten", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "x", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.sp_attn": [[408, 429], ["x.get_shape().as_list", "pix2pix.conv", "pix2pix.conv", "pix2pix.conv", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.reshape", "pix2pix.conv", "tensorflow.get_variable", "pix2pix.hw_flatten", "pix2pix.hw_flatten", "pix2pix.hw_flatten", "x.get_shape", "tensorflow.constant_initializer"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.hw_flatten", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.hw_flatten", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.hw_flatten"], ["", "def", "sp_attn", "(", "x", ")", ":", "\n", "    ", "batch_size", ",", "height", ",", "width", ",", "ch", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "\n", "f", "=", "conv", "(", "x", ",", "ch", "//", "8", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "'f_conv'", ")", "# [bs, h, w, c']", "\n", "g", "=", "conv", "(", "x", ",", "ch", "//", "8", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "'g_conv'", ")", "# [bs, h, w, c']", "\n", "h", "=", "conv", "(", "x", ",", "ch", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "'h_conv'", ")", "# [bs, h, w, c]", "\n", "\n", "# N = h * w", "\n", "s", "=", "tf", ".", "matmul", "(", "hw_flatten", "(", "g", ")", ",", "hw_flatten", "(", "f", ")", ",", "transpose_b", "=", "True", ")", "# # [bs, N, N]", "\n", "beta", "=", "tf", ".", "nn", ".", "softmax", "(", "s", ")", "# attention map", "\n", "\n", "alpha", "=", "tf", ".", "matmul", "(", "beta", ",", "hw_flatten", "(", "h", ")", ")", "# [bs, N, C]", "\n", "alpha", "=", "tf", ".", "reshape", "(", "alpha", ",", "shape", "=", "x", ".", "shape", ")", "# [bs, h, w, C]", "\n", "\n", "v", "=", "conv", "(", "alpha", ",", "ch", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "'v_conv'", ")", "\n", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "\"gamma\"", ",", "[", "1", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "o", "=", "gamma", "*", "v", "+", "x", "\n", "\n", "return", "o", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.Fully_connected": [[430, 433], ["tensorflow.name_scope", "tensorflow.layers.dense"], "function", ["None"], ["", "def", "Fully_connected", "(", "x", ",", "units", ",", "layer_name", "=", "'fully_connected'", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "layer_name", ")", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "dense", "(", "inputs", "=", "x", ",", "use_bias", "=", "False", ",", "units", "=", "units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.ch_attn": [[434, 448], ["x.get_shape().as_list", "tflearn.layers.conv.global_avg_pool", "pix2pix.Fully_connected", "pix2pix.lrelu", "pix2pix.Fully_connected", "tensorflow.nn.sigmoid", "tensorflow.reshape", "x.get_shape"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.Fully_connected", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.lrelu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.Fully_connected"], ["", "", "def", "ch_attn", "(", "x", ")", ":", "\n", "    ", "batch_size", ",", "height", ",", "width", ",", "ch", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "\n", "squeeze", "=", "global_avg_pool", "(", "x", ",", "name", "=", "'Global_avg_pooling'", ")", "\n", "excitation", "=", "Fully_connected", "(", "squeeze", ",", "units", "=", "ch", "//", "16", ",", "layer_name", "=", "'_fully_connected1'", ")", "\n", "excitation", "=", "lrelu", "(", "excitation", ",", "0.2", ")", "\n", "excitation", "=", "Fully_connected", "(", "excitation", ",", "units", "=", "ch", ",", "layer_name", "=", "'_fully_connected2'", ")", "\n", "excitation", "=", "tf", ".", "nn", ".", "sigmoid", "(", "excitation", ")", "\n", "\n", "excitation", "=", "tf", ".", "reshape", "(", "excitation", ",", "[", "-", "1", ",", "1", ",", "1", ",", "ch", "]", ")", "\n", "\n", "scale", "=", "x", "*", "excitation", "\n", "\n", "return", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.create_generator": [[451, 555], ["enumerate", "len", "enumerate", "tensorflow.variable_scope", "pix2pix.conv", "layers.append", "tensorflow.variable_scope", "pix2pix.ch_attn", "layers.append", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix.deconv", "tensorflow.tanh", "layers.append", "tensorflow.variable_scope", "pix2pix.lrelu", "pix2pix.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix.batchnorm", "layers.append", "tensorflow.variable_scope", "pix2pix.conv", "tensorflow.concat", "pix2pix.deconv", "tensorflow.nn.dropout", "pix2pix.sp_attn", "pix2pix.ch_attn", "pix2pix.conv", "pix2pix.sp_attn", "pix2pix.ch_attn", "pix2pix.deconv", "len", "pix2pix.sp_attn", "pix2pix.conv", "pix2pix.ch_attn", "pix2pix.conv", "pix2pix.sp_attn", "pix2pix.deconv", "pix2pix.ch_attn", "pix2pix.deconv"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.ch_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.lrelu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.batchnorm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.batchnorm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.sp_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.ch_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.sp_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.ch_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.sp_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.ch_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.sp_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.ch_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "encoder_layer", ",", "out_channels", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "if", "a", ".", "add_attn", "and", "(", "encoder_layer", "+", "1", ")", "%", "3", "==", "0", ":", "\n", "                ", "if", "a", ".", "attn_type", "==", "'both'", ":", "\n", "                    ", "sa", "=", "sp_attn", "(", "rectified", ")", "\n", "ca", "=", "ch_attn", "(", "sa", ")", "\n", "convolved", "=", "conv", "(", "ca", ",", "out_channels", ")", "\n", "", "elif", "a", ".", "attn_type", "==", "'spatial'", ":", "\n", "                    ", "sa", "=", "sp_attn", "(", "rectified", ")", "\n", "convolved", "=", "conv", "(", "sa", ",", "out_channels", ")", "\n", "", "else", ":", "\n", "                    ", "ca", "=", "ch_attn", "(", "rectified", ")", "\n", "convolved", "=", "conv", "(", "ca", ",", "out_channels", ")", "\n", "", "", "else", ":", "\n", "                ", "convolved", "=", "conv", "(", "rectified", ",", "out_channels", ")", "\n", "", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'ch_attn'", ")", ":", "\n", "        ", "output", "=", "ch_attn", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "2", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "if", "a", ".", "add_attn", "and", "decoder_layer", "%", "3", "==", "0", ":", "\n", "                ", "if", "a", ".", "attn_type", "==", "'both'", ":", "\n", "                    ", "sa", "=", "sp_attn", "(", "rectified", ")", "\n", "ca", "=", "ch_attn", "(", "sa", ")", "\n", "output", "=", "deconv", "(", "ca", ",", "out_channels", ")", "\n", "", "elif", "a", ".", "attn_type", "==", "'spatial'", ":", "\n", "                    ", "sa", "=", "sp_attn", "(", "rectified", ")", "\n", "output", "=", "deconv", "(", "sa", ",", "out_channels", ")", "\n", "", "else", ":", "\n", "                    ", "ca", "=", "ch_attn", "(", "rectified", ")", "\n", "output", "=", "deconv", "(", "ca", ",", "out_channels", ")", "\n", "", "", "else", ":", "\n", "                ", "output", "=", "deconv", "(", "rectified", ",", "out_channels", ")", "\n", "\n", "", "output", "=", "batchnorm", "(", "output", ")", "\n", "#output = attn_block(output)", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "if", "a", ".", "add_global_skip", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"global_skip\"", ")", ":", "\n", "            ", "final", "=", "layers", "[", "-", "1", "]", "+", "generator_inputs", "\n", "final", "=", "final", "/", "2", "\n", "return", "final", "\n", "\n", "", "", "else", ":", "\n", "        ", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.create_model": [[556, 668], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "tensorflow.concat", "range", "tensorflow.variable_scope", "int", "pix2pix.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix.conv", "pix2pix.lrelu", "layers.append", "tensorflow.variable_scope", "pix2pix.conv", "tensorflow.sigmoid", "layers.append", "tensorflow.variable_scope", "pix2pix.create_model.create_discriminator"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.create_generator", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.lrelu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv"], ["", "", "def", "create_model", "(", "inputs", ",", "targets", ")", ":", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "conv", "(", "input", ",", "a", ".", "ndf", ",", "pad", "=", "1", ",", "padding", "=", "\"VALID\"", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ",", "pad", "=", "1", ",", "padding", "=", "\"VALID\"", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "if", "a", ".", "add_attn", "and", "i", "%", "2", "==", "0", ":", "\n", "                    ", "if", "a", ".", "attn_type", "==", "'both'", ":", "\n", "                        ", "sa", "=", "sp_attn", "(", "rectified", ")", "\n", "ca", "=", "ch_attn", "(", "sa", ")", "\n", "layers", ".", "append", "(", "ca", ")", "\n", "", "elif", "a", ".", "attn_type", "==", "'spatial'", ":", "\n", "                        ", "sa", "=", "sp_attn", "(", "rectified", ")", "\n", "layers", ".", "append", "(", "sa", ")", "\n", "", "else", ":", "\n", "                        ", "ca", "=", "ch_attn", "(", "rectified", ")", "\n", "layers", ".", "append", "(", "ca", ")", "\n", "", "", "else", ":", "\n", "                    ", "layers", ".", "append", "(", "rectified", ")", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "conv", "(", "rectified", ",", "1", ",", "stride", "=", "1", ",", "pad", "=", "1", ",", "padding", "=", "\"VALID\"", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "\n", "if", "a", ".", "loss_type", "==", "\"perpixel\"", ":", "\n", "            ", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "", "if", "a", ".", "loss_type", "==", "\"perceptual\"", ":", "\n", "            ", "vgg_model", "=", "VGG", "(", "'vgg19'", ")", "\n", "real_feat", "=", "vgg_model", ".", "model", "(", "targets", ")", "\n", "gen_feat", "=", "vgg_model", ".", "model", "(", "outputs", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "gen_feat", "-", "real_feat", ")", ")", "\n", "\n", "", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "outputs", "=", "outputs", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.save_images": [[671, 691], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.append_index": [[693, 716], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output</th><th>target</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.pix2pix.main": [[718, 977], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix.load_examples", "print", "pix2pix.create_model", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.placeholder", "tensorflow.decode_base64", "tensorflow.image.decode_png", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.convert_image_dtype", "tf.image.convert_image_dtype.set_shape", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.placeholder", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "pix2pix.deprocess", "pix2pix.deprocess", "pix2pix.deprocess", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix.main.convert"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.load_examples", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.create_model", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deprocess", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deprocess", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"export\"", ":", "\n", "# export the generator to a meta graph that can be imported later for standalone generation", "\n", "        ", "if", "a", ".", "lab_colorization", ":", "\n", "            ", "raise", "Exception", "(", "\"export not supported for lab_colorization\"", ")", "\n", "\n", "", "input", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "input_data", "=", "tf", ".", "decode_base64", "(", "input", "[", "0", "]", ")", "\n", "input_image", "=", "tf", ".", "image", ".", "decode_png", "(", "input_data", ")", "\n", "\n", "# remove alpha channel if present", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "4", ")", ",", "lambda", ":", "input_image", "[", ":", ",", ":", ",", ":", "3", "]", ",", "lambda", ":", "input_image", ")", "\n", "# convert grayscale to RGB", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "1", ")", ",", "lambda", ":", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "input_image", ")", ",", "lambda", ":", "input_image", ")", "\n", "\n", "input_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "input_image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_image", ".", "set_shape", "(", "[", "CROP_SIZE", ",", "CROP_SIZE", ",", "3", "]", ")", "\n", "batch_input", "=", "tf", ".", "expand_dims", "(", "input_image", ",", "axis", "=", "0", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "            ", "batch_output", "=", "deprocess", "(", "create_generator", "(", "preprocess", "(", "batch_input", ")", ",", "3", ")", ")", "\n", "\n", "", "output_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "batch_output", ",", "dtype", "=", "tf", ".", "uint8", ")", "[", "0", "]", "\n", "if", "a", ".", "output_filetype", "==", "\"png\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_png", "(", "output_image", ")", "\n", "", "elif", "a", ".", "output_filetype", "==", "\"jpeg\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_jpeg", "(", "output_image", ",", "quality", "=", "80", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid filetype\"", ")", "\n", "", "output", "=", "tf", ".", "convert_to_tensor", "(", "[", "tf", ".", "encode_base64", "(", "output_data", ")", "]", ")", "\n", "\n", "key", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "inputs", "=", "{", "\n", "\"key\"", ":", "key", ".", "name", ",", "\n", "\"input\"", ":", "input", ".", "name", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"inputs\"", ",", "json", ".", "dumps", "(", "inputs", ")", ")", "\n", "outputs", "=", "{", "\n", "\"key\"", ":", "tf", ".", "identity", "(", "key", ")", ".", "name", ",", "\n", "\"output\"", ":", "output", ".", "name", ",", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"outputs\"", ",", "json", ".", "dumps", "(", "outputs", ")", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "restore_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "export_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "restore_saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "print", "(", "\"exporting model\"", ")", "\n", "export_saver", ".", "export_meta_graph", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export.meta\"", ")", ")", "\n", "export_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export\"", ")", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "return", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "\n", "# undo colorization splitting on images that we use for display/output", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "        ", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "# inputs is brightness, this will be handled fine as a grayscale image", "\n", "# need to augment targets and outputs with brightness", "\n", "            ", "targets", "=", "augment", "(", "examples", ".", "targets", ",", "examples", ".", "inputs", ")", "\n", "outputs", "=", "augment", "(", "model", ".", "outputs", ",", "examples", ".", "inputs", ")", "\n", "# inputs can be deprocessed normally and handled as if they are single channel", "\n", "# grayscale images", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "# inputs will be color channels only, get brightness from targets", "\n", "            ", "inputs", "=", "augment", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "", "", "else", ":", "\n", "        ", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "\n", "", "def", "convert", "(", "image", ")", ":", "\n", "        ", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets", "=", "convert", "(", "targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs", "=", "convert", "(", "outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_pngs\"", ")", ",", "\n", "\"outputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets\"", ",", "converted_targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs\"", ",", "converted_outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "#for grad, var in model.discrim_grads_and_vars + model.gen_grads_and_vars:", "\n", "#    tf.summary.histogram(var.op.name + \"/gradients\", grad)", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "\n", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"discrim_loss\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "print", "(", "\"gen_loss_GAN\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.vgg19.VGG.__init__": [[8, 23], ["tensorflow.variable_scope", "tensorflow.keras.Model", "print", "name.upper", "tensorflow.keras.applications.VGG19", "name.upper", "tensorflow.keras.applications.VGG16", "TypeError", "vgg19.VGG.vgg.get_layer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "include_top", "=", "False", ",", "weights", "=", "'imagenet'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope", ":", "\n", "            ", "if", "name", ".", "upper", "(", ")", "==", "'VGG19'", ":", "\n", "                ", "self", ".", "vgg", "=", "tf", ".", "keras", ".", "applications", ".", "VGG19", "(", "include_top", "=", "include_top", ",", "\n", "weights", "=", "weights", ")", "\n", "", "elif", "name", ".", "upper", "(", ")", "==", "'VGG16'", ":", "\n", "                ", "self", ".", "vgg", "=", "tf", ".", "keras", ".", "applications", ".", "VGG16", "(", "include_top", "=", "include_top", ",", "\n", "weights", "=", "weights", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Not supported model: VGG{}'", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "self", ".", "model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "self", ".", "vgg", ".", "input", ",", "\n", "outputs", "=", "self", ".", "vgg", ".", "get_layer", "(", "'block3_conv3'", ")", ".", "output", ")", "\n", "self", ".", "model", ".", "trainable", "=", "False", "\n", "print", "(", "\" [*] \"", ",", "name", ",", "\" model was created\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.Pix2Pix.vgg19.VGG.get_pair_feature": [[24, 32], ["tensorflow.concat", "vgg19.VGG.model", "gen_img.shape.as_list", "real_img.shape.as_list", "gen_img.shape.as_list"], "methods", ["None"], ["", "", "def", "get_pair_feature", "(", "self", ",", "gen_img", ",", "real_img", ")", ":", "\n", "        ", "assert", "gen_img", ".", "shape", ".", "as_list", "(", ")", "==", "real_img", ".", "shape", ".", "as_list", "(", ")", "\n", "batch_num", "=", "gen_img", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", "\n", "\n", "pair", "=", "tf", ".", "concat", "(", "[", "gen_img", ",", "real_img", "]", ",", "axis", "=", "0", ")", "\n", "output", "=", "self", ".", "model", "(", "pair", ")", "\n", "gen_feat", ",", "real_feat", "=", "output", "[", ":", "batch_num", ",", ":", ",", ":", ",", ":", "]", ",", "output", "[", "batch_num", ":", ",", ":", ",", ":", ",", ":", "]", "\n", "return", "gen_feat", ",", "real_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.preprocess": [[59, 63], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deprocess": [[65, 69], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.check_image": [[70, 83], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.load_examples": [[84, 170], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "net.decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "net.preprocess", "net.preprocess", "tensorflow.image.resize_images", "tensorflow.name_scope", "net.load_examples.transform"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.preprocess", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.preprocess"], ["", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "2", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "2", ":", ",", ":", "]", ")", "\n", "\n", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "a_images", ",", "b_images", "]", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "b_images", ",", "a_images", "]", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size_h", ",", "a", ".", "scale_size_w", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "if", "a", ".", "mode", "==", "\"train\"", ":", "\n", "            ", "offset_h", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "1", "]", ",", "0", ",", "a", ".", "scale_size_h", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "offset_w", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "1", "]", ",", "0", ",", "a", ".", "scale_size_w", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size_h", ">", "CROP_SIZE", "and", "a", ".", "scale_size_w", ">", "CROP_SIZE", ":", "\n", "                ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset_h", "[", "0", "]", ",", "offset_w", "[", "0", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "\n", "", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_images", "=", "transform", "(", "targets", ")", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets", "=", "targets_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.save_images": [[172, 192], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.append_index": [[194, 217], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output</th><th>target</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu": [[220, 222], ["tensorflow.nn.relu"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu"], ["", "def", "relu", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.lrelu": [[223, 225], ["tensorflow.nn.leaky_relu"], "function", ["None"], ["", "def", "lrelu", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "leaky_relu", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn": [[226, 228], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "bn", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.l2_norm": [[229, 231], ["tensorflow.reduce_sum"], "function", ["None"], ["", "def", "l2_norm", "(", "v", ",", "eps", "=", "1e-12", ")", ":", "\n", "    ", "return", "v", "/", "(", "tf", ".", "reduce_sum", "(", "v", "**", "2", ")", "**", "0.5", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.hw_flatten": [[232, 234], ["tensorflow.reshape"], "function", ["None"], ["", "def", "hw_flatten", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "x", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.spectral_norm": [[235, 261], ["tf.reshape.shape.as_list", "tensorflow.reshape", "tensorflow.get_variable", "range", "tensorflow.matmul", "tensorflow.matmul", "net.l2_norm", "tensorflow.matmul", "net.l2_norm", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.control_dependencies", "tensorflow.reshape", "tensorflow.truncated_normal_initializer", "tensorflow.transpose", "tf.get_variable.assign"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.l2_norm", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.l2_norm"], ["", "def", "spectral_norm", "(", "w", ",", "iteration", "=", "1", ")", ":", "\n", "    ", "w_shape", "=", "w", ".", "shape", ".", "as_list", "(", ")", "\n", "w", "=", "tf", ".", "reshape", "(", "w", ",", "[", "-", "1", ",", "w_shape", "[", "-", "1", "]", "]", ")", "\n", "\n", "u", "=", "tf", ".", "get_variable", "(", "\"u\"", ",", "[", "1", ",", "w_shape", "[", "-", "1", "]", "]", ",", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", ")", ",", "trainable", "=", "False", ")", "\n", "\n", "u_hat", "=", "u", "\n", "v_hat", "=", "None", "\n", "for", "i", "in", "range", "(", "iteration", ")", ":", "\n", "        ", "\"\"\"\n        power iteration\n        Usually iteration = 1 will be enough\n        \"\"\"", "\n", "v_", "=", "tf", ".", "matmul", "(", "u_hat", ",", "tf", ".", "transpose", "(", "w", ")", ")", "\n", "v_hat", "=", "l2_norm", "(", "v_", ")", "\n", "\n", "u_", "=", "tf", ".", "matmul", "(", "v_hat", ",", "w", ")", "\n", "u_hat", "=", "l2_norm", "(", "u_", ")", "\n", "\n", "", "sigma", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "v_hat", ",", "w", ")", ",", "tf", ".", "transpose", "(", "u_hat", ")", ")", "\n", "w_norm", "=", "w", "/", "sigma", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "u", ".", "assign", "(", "u_hat", ")", "]", ")", ":", "\n", "        ", "w_norm", "=", "tf", ".", "reshape", "(", "w_norm", ",", "w_shape", ")", "\n", "\n", "", "return", "w_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv": [[262, 273], ["tensorflow.random_normal_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.get_variable", "tensorflow.nn.bias_add", "net.spectral_norm", "tensorflow.constant_initializer", "tf.nn.bias_add.get_shape"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.spectral_norm"], ["", "def", "conv", "(", "x", ",", "out_channels", ",", "kernel", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "\"SAME\"", ",", "scope", "=", "\"conv\"", ")", ":", "\n", "    ", "weight_init", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "0.0", ",", "stddev", "=", "0.02", ")", "\n", "weight_regularizer", "=", "None", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "w", "=", "tf", ".", "get_variable", "(", "\"kernel\"", ",", "shape", "=", "[", "kernel", ",", "kernel", ",", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "out_channels", "]", ",", "initializer", "=", "weight_init", ",", "regularizer", "=", "weight_regularizer", ")", "\n", "x", "=", "tf", ".", "nn", ".", "conv2d", "(", "input", "=", "x", ",", "filter", "=", "spectral_norm", "(", "w", ")", ",", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "padding", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "out_channels", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "bias_add", "(", "x", ",", "bias", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv": [[274, 287], ["tensorflow.random_normal_initializer", "tf.nn.bias_add.get_shape().as_list", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.conv2d_transpose", "tensorflow.get_variable", "tensorflow.nn.bias_add", "tf.nn.bias_add.get_shape", "net.spectral_norm", "tensorflow.constant_initializer", "tf.nn.bias_add.get_shape"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.spectral_norm"], ["", "def", "deconv", "(", "x", ",", "out_channels", ",", "kernel", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "\"SAME\"", ",", "scope", "=", "\"deconv\"", ")", ":", "\n", "    ", "weight_init", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "0.0", ",", "stddev", "=", "0.02", ")", "\n", "weight_regularizer", "=", "None", "\n", "x_shape", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "output_shape", "=", "[", "x_shape", "[", "0", "]", ",", "x_shape", "[", "1", "]", "*", "stride", ",", "x_shape", "[", "2", "]", "*", "stride", ",", "out_channels", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "w", "=", "tf", ".", "get_variable", "(", "\"kernel\"", ",", "shape", "=", "[", "kernel", ",", "kernel", ",", "out_channels", ",", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", "]", ",", "initializer", "=", "weight_init", ",", "regularizer", "=", "weight_regularizer", ")", "\n", "x", "=", "tf", ".", "nn", ".", "conv2d_transpose", "(", "x", ",", "filter", "=", "spectral_norm", "(", "w", ")", ",", "output_shape", "=", "output_shape", ",", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "padding", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "out_channels", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "bias_add", "(", "x", ",", "bias", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.ch_attn": [[288, 299], ["tensorflow.variable_scope", "tflearn.layers.conv.global_avg_pool", "tensorflow.reshape", "net.conv", "net.relu", "net.conv", "tensorflow.nn.sigmoid"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv"], ["", "def", "ch_attn", "(", "input", ",", "channels", ",", "scope", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "squeeze", "=", "global_avg_pool", "(", "input", ")", "\n", "squeeze", "=", "tf", ".", "reshape", "(", "squeeze", ",", "[", "-", "1", ",", "1", ",", "1", ",", "channels", "]", ")", "\n", "squeeze", "=", "conv", "(", "squeeze", ",", "channels", "//", "8", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "\"squeeze_conv\"", ")", "\n", "excite", "=", "relu", "(", "squeeze", ")", "\n", "excite", "=", "conv", "(", "excite", ",", "channels", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "\"excite_conv\"", ")", "\n", "attn", "=", "tf", ".", "nn", ".", "sigmoid", "(", "excite", ")", "\n", "output", "=", "attn", "*", "input", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.res": [[300, 309], ["tensorflow.variable_scope", "net.conv", "net.ch_attn", "net.conv", "net.ch_attn"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.ch_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.ch_attn"], ["", "def", "res", "(", "input", ",", "channels", ",", "scope", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "x", "=", "conv", "(", "input", ",", "channels", ",", "stride", "=", "1", ",", "scope", "=", "\"conv1\"", ")", "\n", "x", "=", "ch_attn", "(", "x", ",", "channels", ",", "\"ch_attn1\"", ")", "\n", "x", "=", "conv", "(", "x", ",", "channels", ",", "stride", "=", "1", ",", "scope", "=", "\"conv2\"", ")", "\n", "x", "=", "ch_attn", "(", "x", ",", "channels", ",", "\"ch_attn2\"", ")", "\n", "output", "=", "input", "+", "x", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.encode": [[310, 327], ["tensorflow.variable_scope", "tensorflow.variable_scope", "net.res", "net.res", "net.conv", "net.bn", "net.relu", "tensorflow.variable_scope", "net.conv", "net.bn", "net.relu"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.res", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.res", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu"], ["", "def", "encode", "(", "input", ",", "in_channels", ",", "scope", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"path1\"", ")", ":", "\n", "            ", "p1", "=", "res", "(", "input", ",", "in_channels", ",", "\"res1\"", ")", "\n", "p1", "=", "res", "(", "p1", ",", "in_channels", ",", "\"res2\"", ")", "\n", "p1", "=", "conv", "(", "p1", ",", "in_channels", "*", "2", ")", "\n", "p1", "=", "bn", "(", "p1", ")", "\n", "p1", "=", "relu", "(", "p1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"path2\"", ")", ":", "\n", "            ", "p2", "=", "conv", "(", "input", ",", "in_channels", "*", "2", ")", "\n", "p2", "=", "bn", "(", "p2", ")", "\n", "p2", "=", "relu", "(", "p2", ")", "\n", "\n", "", "output", "=", "p1", "+", "p2", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode": [[328, 344], ["tensorflow.variable_scope", "tensorflow.variable_scope", "net.res", "net.res", "net.deconv", "net.bn", "net.relu", "tensorflow.variable_scope", "net.deconv", "net.bn", "net.relu"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.res", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.res", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu"], ["", "def", "decode", "(", "input", ",", "in_channels", ",", "factor", ",", "scope", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"path1\"", ")", ":", "\n", "            ", "p1", "=", "res", "(", "input", ",", "in_channels", ",", "\"res1\"", ")", "\n", "p1", "=", "res", "(", "p1", ",", "in_channels", ",", "\"res2\"", ")", "\n", "p1", "=", "deconv", "(", "p1", ",", "in_channels", "//", "factor", ")", "\n", "p1", "=", "bn", "(", "p1", ")", "\n", "p1", "=", "relu", "(", "p1", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"path2\"", ")", ":", "\n", "            ", "p2", "=", "deconv", "(", "input", ",", "in_channels", "//", "factor", ")", "\n", "p2", "=", "bn", "(", "p2", ")", "\n", "p2", "=", "relu", "(", "p2", ")", "\n", "\n", "", "output", "=", "p1", "+", "p2", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.sp_attn": [[345, 360], ["net.conv", "net.conv", "net.conv", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.reshape", "net.conv", "tensorflow.get_variable", "tensorflow.matmul", "net.hw_flatten", "net.hw_flatten", "net.hw_flatten", "tensorflow.constant_initializer"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.hw_flatten", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.hw_flatten", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.hw_flatten"], ["", "def", "sp_attn", "(", "input", ",", "channels", ")", ":", "\n", "    ", "f", "=", "conv", "(", "input", ",", "channels", "//", "8", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "\"f\"", ")", "\n", "g", "=", "conv", "(", "input", ",", "channels", "//", "8", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "\"g\"", ")", "\n", "h", "=", "conv", "(", "input", ",", "channels", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "\"h\"", ")", "\n", "\n", "attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "hw_flatten", "(", "g", ")", ",", "hw_flatten", "(", "f", ")", ",", "transpose_b", "=", "True", ")", ")", "\n", "\n", "v", "=", "tf", ".", "matmul", "(", "attn", ",", "hw_flatten", "(", "h", ")", ")", "\n", "v_reshaped", "=", "tf", ".", "reshape", "(", "v", ",", "shape", "=", "input", ".", "shape", ")", "\n", "o", "=", "conv", "(", "v_reshaped", ",", "channels", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "scope", "=", "\"v\"", ")", "\n", "\n", "gamma", "=", "tf", ".", "get_variable", "(", "\"gamma\"", ",", "[", "1", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "output", "=", "o", "*", "gamma", "+", "input", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.generator": [[363, 393], ["tensorflow.variable_scope", "net.conv", "net.bn", "net.relu", "tensorflow.variable_scope", "net.encode", "net.encode", "net.encode", "net.encode", "tensorflow.variable_scope", "net.sp_attn", "tensorflow.variable_scope", "net.decode", "net.decode", "net.decode", "net.decode", "tensorflow.variable_scope", "net.deconv", "net.bn", "tensorflow.tanh", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.relu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.encode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.encode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.encode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.encode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.sp_attn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.decode", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deconv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn"], ["", "def", "generator", "(", "input_image", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"en1\"", ")", ":", "\n", "        ", "en1", "=", "conv", "(", "input_image", ",", "64", ")", "#[bs, 256, 256, 3] -> [bs, 128, 128, 64]", "\n", "en1", "=", "bn", "(", "en1", ")", "\n", "en1", "=", "relu", "(", "en1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ")", ":", "\n", "        ", "en2", "=", "encode", "(", "en1", ",", "64", ",", "\"en2\"", ")", "#[bs, 128, 128, 64] -> [bs, 64, 64, 128]", "\n", "en3", "=", "encode", "(", "en2", ",", "128", ",", "\"en3\"", ")", "#[bs, 64, 64, 128] -> [bs, 32, 32, 256]", "\n", "en4", "=", "encode", "(", "en3", ",", "256", ",", "\"en4\"", ")", "#[bs, 32, 32, 256] -> [bs, 16, 16, 512]", "\n", "en5", "=", "encode", "(", "en4", ",", "512", ",", "\"en5\"", ")", "#[bs, 16, 16, 512] -> [bs, 8, 8, 1024]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"spatial_attention\"", ")", ":", "\n", "        ", "encoded", "=", "sp_attn", "(", "en5", ",", "1024", ")", "#[bs, 8, 8, 1024] -> [bs, 8, 8, 1024]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ")", ":", "\n", "        ", "de5", "=", "decode", "(", "encoded", ",", "1024", ",", "2", ",", "\"de5\"", ")", "#[bs, 8, 8, 1024] -> [bs, 16, 16, 512]", "\n", "de4", "=", "decode", "(", "tf", ".", "concat", "(", "[", "de5", ",", "en4", "]", ",", "axis", "=", "3", ")", ",", "1024", ",", "4", ",", "\"de4\"", ")", "#[bs, 16, 16, 1024] -> [bs, 32, 32, 256]", "\n", "de3", "=", "decode", "(", "tf", ".", "concat", "(", "[", "de4", ",", "en3", "]", ",", "axis", "=", "3", ")", ",", "512", ",", "4", ",", "\"de3\"", ")", "#[bs, 32, 32, 512] -> [bs, 64, 64, 128]", "\n", "de2", "=", "decode", "(", "tf", ".", "concat", "(", "[", "de3", ",", "en2", "]", ",", "axis", "=", "3", ")", ",", "256", ",", "4", ",", "\"de2\"", ")", "#[bs, 64, 64, 256] -> [bs, 128, 128, 64]", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"de1\"", ")", ":", "\n", "        ", "de1", "=", "deconv", "(", "tf", ".", "concat", "(", "[", "de2", ",", "en1", "]", ",", "axis", "=", "3", ")", ",", "3", ")", "#[bs, 128, 128, 128] -> [bs, 256, 256, 3]", "\n", "de1", "=", "bn", "(", "de1", ")", "\n", "decoded", "=", "tf", ".", "tanh", "(", "de1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"global_skip\"", ")", ":", "\n", "        ", "output", "=", "(", "decoded", "+", "input_image", ")", "/", "2", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.discriminator": [[394, 422], ["tensorflow.concat", "tensorflow.variable_scope", "net.conv", "net.bn", "net.lrelu", "tensorflow.variable_scope", "net.conv", "net.bn", "net.lrelu", "tensorflow.variable_scope", "net.conv", "net.bn", "net.lrelu", "tensorflow.variable_scope", "net.conv", "net.bn", "net.lrelu", "tensorflow.variable_scope", "net.conv", "tensorflow.sigmoid"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.lrelu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.lrelu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.lrelu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.bn", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.lrelu", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.conv"], ["", "def", "discriminator", "(", "input_image", ",", "target_image", ")", ":", "\n", "    ", "input", "=", "tf", ".", "concat", "(", "[", "input_image", ",", "target_image", "]", ",", "axis", "=", "3", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"block1\"", ")", ":", "\n", "        ", "convolved", "=", "conv", "(", "input", ",", "64", ")", "\n", "normalized", "=", "bn", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"block2\"", ")", ":", "\n", "        ", "convolved", "=", "conv", "(", "rectified", ",", "128", ")", "\n", "normalized", "=", "bn", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"block3\"", ")", ":", "\n", "        ", "convolved", "=", "conv", "(", "rectified", ",", "256", ")", "\n", "normalized", "=", "bn", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"block4\"", ")", ":", "\n", "        ", "convolved", "=", "conv", "(", "rectified", ",", "512", ",", "stride", "=", "1", ")", "\n", "normalized", "=", "bn", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"block5\"", ")", ":", "\n", "        ", "convolved", "=", "conv", "(", "rectified", ",", "1", ",", "kernel", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "\"VALID\"", ")", "\n", "patch", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "\n", "", "return", "patch", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.create_model": [[423, 483], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "tensorflow.variable_scope", "net.generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "net.discriminator", "tensorflow.variable_scope", "net.discriminator", "tensorflow.abs", "tensorflow.control_dependencies", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tensorflow.group", "tensorflow.log", "tensorflow.trainable_variables", "var.name.startswith", "tensorflow.log", "tensorflow.log", "tensorflow.trainable_variables", "var.name.startswith"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.generator", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.discriminator", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.discriminator"], ["", "def", "create_model", "(", "inputs", ",", "targets", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "outputs", "=", "generator", "(", "inputs", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_content", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_content", "*", "a", ".", "content_weight", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_content", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_content", "=", "ema", ".", "average", "(", "gen_loss_content", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "outputs", "=", "outputs", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.main": [[487, 656], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "net.load_examples", "print", "net.create_model", "net.deprocess", "net.deprocess", "net.deprocess", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "net.main.convert"], "function", ["home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.load_examples", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.create_model", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deprocess", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deprocess", "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.net.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "\n", "def", "convert", "(", "image", ")", ":", "\n", "        ", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets", "=", "convert", "(", "targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs", "=", "convert", "(", "outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_pngs\"", ")", ",", "\n", "\"outputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_pngs\"", ")", ",", "\n", "}", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets\"", ",", "converted_targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs\"", ",", "converted_outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_content\"", ",", "model", ".", "gen_loss_content", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "\n", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_content\"", "]", "=", "model", ".", "gen_loss_content", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"discrim_loss\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "print", "(", "\"gen_loss_GAN\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_content\"", ",", "results", "[", "\"gen_loss_content\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.vgg19.VGG.__init__": [[8, 23], ["tensorflow.variable_scope", "tensorflow.keras.Model", "print", "name.upper", "tensorflow.keras.applications.VGG19", "name.upper", "tensorflow.keras.applications.VGG16", "TypeError", "vgg19.VGG.vgg.get_layer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "include_top", "=", "False", ",", "weights", "=", "'imagenet'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope", ":", "\n", "            ", "if", "name", ".", "upper", "(", ")", "==", "'VGG19'", ":", "\n", "                ", "self", ".", "vgg", "=", "tf", ".", "keras", ".", "applications", ".", "VGG19", "(", "include_top", "=", "include_top", ",", "\n", "weights", "=", "weights", ")", "\n", "", "elif", "name", ".", "upper", "(", ")", "==", "'VGG16'", ":", "\n", "                ", "self", ".", "vgg", "=", "tf", ".", "keras", ".", "applications", ".", "VGG16", "(", "include_top", "=", "include_top", ",", "\n", "weights", "=", "weights", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Not supported model: VGG{}'", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "self", ".", "model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "self", ".", "vgg", ".", "input", ",", "\n", "outputs", "=", "self", ".", "vgg", ".", "get_layer", "(", "'block3_conv3'", ")", ".", "output", ")", "\n", "self", ".", "model", ".", "trainable", "=", "False", "\n", "print", "(", "\" [*] \"", ",", "name", ",", "\" model was created\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lenka98_Bind-Deblurring-using-GANs.RiR.vgg19.VGG.get_pair_feature": [[24, 32], ["tensorflow.concat", "vgg19.VGG.model", "gen_img.shape.as_list", "real_img.shape.as_list", "gen_img.shape.as_list"], "methods", ["None"], ["", "", "def", "get_pair_feature", "(", "self", ",", "gen_img", ",", "real_img", ")", ":", "\n", "        ", "assert", "gen_img", ".", "shape", ".", "as_list", "(", ")", "==", "real_img", ".", "shape", ".", "as_list", "(", ")", "\n", "batch_num", "=", "gen_img", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", "\n", "\n", "pair", "=", "tf", ".", "concat", "(", "[", "gen_img", ",", "real_img", "]", ",", "axis", "=", "0", ")", "\n", "output", "=", "self", ".", "model", "(", "pair", ")", "\n", "gen_feat", ",", "real_feat", "=", "output", "[", ":", "batch_num", ",", ":", ",", ":", ",", ":", "]", ",", "output", "[", "batch_num", ":", ",", ":", ",", ":", ",", ":", "]", "\n", "return", "gen_feat", ",", "real_feat", "\n", "\n"]]}