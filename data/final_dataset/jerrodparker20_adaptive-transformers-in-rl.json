{"home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.dqn.DQN.__init__": [[6, 21], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "DQN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "layer3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "output_layer", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.dqn.DQN.forward": [[22, 28], ["dqn.DQN.layer1", "dqn.DQN.layer2", "dqn.DQN.layer3", "dqn.DQN.output_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "layer1", "(", "x", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "self", ".", "output_layer", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.dqn.DQN.select_action": [[29, 45], ["dqn.DQN.", "torch.argmax().reshape", "torch.argmax().reshape", "torch.argmax().reshape", "torch.argmax().reshape", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax"], "methods", ["None"], ["", "def", "select_action", "(", "self", ",", "current_state", ",", "epsilon", "=", "0.1", ")", ":", "\n", "        ", "\"\"\"\n        selects an action as per the decided exploration\n        :param current_state: the current state\n        :param epsilon: the param for exploration, typical value = 0.1\n        :return: the chosen action\n\n        \"\"\"", "\n", "q_values", "=", "self", "(", "current_state", ")", "\n", "action", "=", "torch", ".", "argmax", "(", "q_values", ")", ".", "reshape", "(", "-", "1", ")", "\n", "if", "torch", ".", "rand", "(", "1", ")", ">", "epsilon", ":", "\n", "# then take the argmax action", "\n", "            ", "return", "action", "\n", "", "else", ":", "\n", "# else take a random exploration action", "\n", "            ", "return", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "self", ".", "output_layer", ".", "out_features", ",", "size", "=", "(", "1", ",", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.PositionalEmbedding.__init__": [[36, 43], ["torch.Module.__init__", "old_transformer_xl.PositionalEmbedding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ")", ":", "\n", "        ", "super", "(", "PositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "demb", "=", "demb", "\n", "\n", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "torch", ".", "arange", "(", "0.0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "self", ".", "register_buffer", "(", "'inv_freq'", ",", "inv_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.PositionalEmbedding.forward": [[44, 52], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_emb[].expand", "torch.ger.sin", "torch.ger.sin", "torch.ger.sin", "torch.ger.cos", "torch.ger.cos", "torch.ger.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "ger", "(", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "sinusoid_inp", ".", "sin", "(", ")", ",", "sinusoid_inp", ".", "cos", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.GRUGate.__init__": [[61, 72], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ")", ":", "\n", "#d_model is dimension of embedding for each token as input to layer (want to maintain this in the gate)", "\n", "        ", "super", "(", "GRUGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# TODO: DEBUG Make sure intitialize biases to small positive number like in paper", "\n", "self", ".", "linear_w_r", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_u_r", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_w_z", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ")", "### Giving bias to this layer (will count as b_g so can just initialize negative)", "\n", "self", ".", "linear_u_z", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_w_g", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_u_g", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.GRUGate.forward": [[73, 80], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "old_transformer_xl.GRUGate.linear_w_z", "old_transformer_xl.GRUGate.linear_u_z", "old_transformer_xl.GRUGate.linear_w_r", "old_transformer_xl.GRUGate.linear_u_r", "old_transformer_xl.GRUGate.linear_w_g", "old_transformer_xl.GRUGate.linear_u_g"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "### Here x,y follow from notation in paper", "\n", "# TODO: DEBUG MAKE SURE THIS IS APPLIED ON PROPER AXIS", "\n", "        ", "z", "=", "torch", ".", "sigmoid", "(", "self", ".", "linear_w_z", "(", "y", ")", "+", "self", ".", "linear_u_z", "(", "x", ")", ")", "#MAKE SURE THIS IS APPLIED ON PROPER AXIS", "\n", "r", "=", "torch", ".", "sigmoid", "(", "self", ".", "linear_w_r", "(", "y", ")", "+", "self", ".", "linear_u_r", "(", "x", ")", ")", "\n", "h_hat", "=", "torch", ".", "tanh", "(", "self", ".", "linear_w_g", "(", "y", ")", "+", "self", ".", "linear_u_g", "(", "r", "*", "x", ")", ")", "#Note elementwise multiplication of r and x", "\n", "return", "(", "1.", "-", "z", ")", "*", "x", "+", "z", "*", "h_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.PositionwiseFF.__init__": [[85, 97], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "PositionwiseFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "CoreNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "d_model", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.PositionwiseFF.forward": [[101, 107], ["old_transformer_xl.PositionwiseFF.CoreNet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "\n", "##### positionwise feed-forward (this is what's used in original transformer)", "\n", "        ", "core_out", "=", "self", ".", "CoreNet", "(", "inp", ")", "\n", "\n", "return", "core_out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelPartialLearnableDecoderLayer.__init__": [[110, 126], ["torch.Module.__init__", "old_transformer_xl.GRUGate", "old_transformer_xl.GRUGate", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "old_transformer_xl.RelPartialLearnableMultiHeadAttn", "old_transformer_xl.PositionwiseFF", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "use_gate", ",", "use_stable_version", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "use_gate", "=", "use_gate", "\n", "self", ".", "use_stable_version", "=", "use_stable_version", "\n", "self", ".", "gate_mha", "=", "GRUGate", "(", "d_model", ")", "\n", "self", ".", "gate_mlp", "=", "GRUGate", "(", "d_model", ")", "\n", "self", ".", "norm1", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelPartialLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "\n", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ")", "\n", "self", ".", "layer_norm1", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "layer_norm2", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelPartialLearnableDecoderLayer.forward_orig": [[127, 136], ["old_transformer_xl.RelPartialLearnableDecoderLayer.dec_attn", "old_transformer_xl.RelPartialLearnableDecoderLayer.layer_norm1", "old_transformer_xl.RelPartialLearnableDecoderLayer.pos_ff", "old_transformer_xl.RelPartialLearnableDecoderLayer.layer_norm2"], "methods", ["None"], ["", "def", "forward_orig", "(", "self", ",", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "layer_norm1", "(", "dec_inp", "+", "output", ")", "\n", "output2", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "output2", "=", "self", ".", "layer_norm2", "(", "output", "+", "output2", ")", "\n", "return", "output2", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelPartialLearnableDecoderLayer.forward_stable": [[138, 162], ["old_transformer_xl.RelPartialLearnableDecoderLayer.layer_norm1", "old_transformer_xl.RelPartialLearnableDecoderLayer.dec_attn", "old_transformer_xl.RelPartialLearnableDecoderLayer.layer_norm2", "old_transformer_xl.RelPartialLearnableDecoderLayer.pos_ff", "old_transformer_xl.RelPartialLearnableDecoderLayer.gate_mha", "old_transformer_xl.RelPartialLearnableDecoderLayer.gate_mlp", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "def", "forward_stable", "(", "self", ",", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "#Layer norm will be applied at start of MHA module on both dec_inp2 and mems", "\n", "        ", "dec_inp2", "=", "self", ".", "layer_norm1", "(", "dec_inp", ")", "\n", "dec_inp2", "=", "self", ".", "dec_attn", "(", "dec_inp2", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ",", "use_stable_version", "=", "self", ".", "use_stable_version", ")", "\n", "\n", "#NOTE: In stable transformer they apply Relu before the layernorm/gate (in appendix C.3)", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "dec_inp2", "=", "self", ".", "gate_mha", "(", "dec_inp", ",", "F", ".", "relu", "(", "dec_inp2", ")", ")", "\n", "", "else", ":", "\n", "            ", "dec_inp2", "=", "dec_inp", "+", "F", ".", "relu", "(", "dec_inp2", ")", "\n", "\n", "", "dec_inp3", "=", "self", ".", "layer_norm2", "(", "dec_inp2", ")", "\n", "\n", "dec_inp3", "=", "self", ".", "pos_ff", "(", "dec_inp3", ")", "\n", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "dec_inp3", "=", "self", ".", "gate_mlp", "(", "dec_inp2", ",", "F", ".", "relu", "(", "dec_inp3", ")", ")", "\n", "", "else", ":", "\n", "            ", "dec_inp3", "=", "F", ".", "relu", "(", "dec_inp3", ")", "+", "dec_inp2", "\n", "\n", "", "return", "dec_inp3", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelPartialLearnableDecoderLayer.forward": [[164, 170], ["old_transformer_xl.RelPartialLearnableDecoderLayer.forward_orig", "old_transformer_xl.RelPartialLearnableDecoderLayer.forward_stable"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward_orig", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward_stable"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "if", "self", ".", "use_stable_version", ":", "\n", "            ", "return", "self", ".", "forward_stable", "(", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", ",", "mems", ")", "\n", "\n", "", "return", "self", ".", "forward_orig", "(", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", ",", "mems", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelMultiHeadAttn.__init__": [[175, 197], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "None", ",", "pre_lnorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "RelMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "#Get query, key and value for each token (NOTE SOME Inefficiency since", "\n", "#don't need query for any of the memory. Parallelization must make up for it", "\n", "self", ".", "qkv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "3", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelMultiHeadAttn._parallelogram_mask": [[198, 212], ["torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "min", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones().bool.flip", "torch.ones().bool.flip", "torch.ones().bool.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "_parallelogram_mask", "(", "self", ",", "h", ",", "w", ",", "left", "=", "False", ")", ":", "\n", "# UserWarning: masked_fill_ received a mask with dtype torch.uint8,", "\n", "# this behavior is now deprecated,please use a mask with dtype torch.bool instead.", "\n", "# changed .byte() to .bool()", "\n", "# mask = torch.ones((h, w)).byte()", "\n", "        ", "mask", "=", "torch", ".", "ones", "(", "(", "h", ",", "w", ")", ")", ".", "bool", "(", ")", "\n", "m", "=", "min", "(", "h", ",", "w", ")", "\n", "mask", "[", ":", "m", ",", ":", "m", "]", "=", "torch", ".", "triu", "(", "mask", "[", ":", "m", ",", ":", "m", "]", ")", "\n", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", "=", "torch", ".", "tril", "(", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", ")", "\n", "\n", "if", "left", ":", "\n", "            ", "return", "mask", "\n", "", "else", ":", "\n", "            ", "return", "mask", ".", "flip", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelMultiHeadAttn._shift": [[213, 230], ["torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mask.flip.flip.flip", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "_shift", "(", "self", ",", "x", ",", "qlen", ",", "klen", ",", "mask", ",", "left", "=", "False", ")", ":", "\n", "        ", "if", "qlen", ">", "1", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "qlen", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "0", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n", "", "if", "left", ":", "\n", "            ", "mask", "=", "mask", ".", "flip", "(", "1", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_padded", "=", "torch", ".", "cat", "(", "[", "x", ",", "zero_pad", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "x", "=", "x_padded", ".", "masked_select", "(", "mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ".", "view", "(", "qlen", ",", "klen", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelMultiHeadAttn._rel_shift": [[231, 245], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_padded.view.view.view", "x_padded[].view_as", "x_padded[].view_as.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size"], "methods", ["None"], ["", "def", "_rel_shift", "(", "self", ",", "x", ",", "zero_triu", "=", "False", ")", ":", "\n", "        ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "*", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "x", ".", "size", "(", "1", ")", "+", "1", ",", "x", ".", "size", "(", "0", ")", ",", "*", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "\n", "x", "=", "x_padded", "[", "1", ":", "]", ".", "view_as", "(", "x", ")", "\n", "\n", "if", "zero_triu", ":", "\n", "            ", "ones", "=", "torch", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", ")", "\n", "x", "=", "x", "*", "torch", ".", "tril", "(", "ones", ",", "x", ".", "size", "(", "1", ")", "-", "x", ".", "size", "(", "0", ")", ")", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelMultiHeadAttn.forward": [[246, 248], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelPartialLearnableMultiHeadAttn.__init__": [[253, 257], ["old_transformer_xl.RelMultiHeadAttn.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "r_net", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.RelPartialLearnableMultiHeadAttn.forward": [[258, 329], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "old_transformer_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.o_net", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.drop", "w.size", "r.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_vec.contiguous().view.contiguous().view.contiguous", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "old_transformer_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "attn_mask.any", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "float"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelMultiHeadAttn._rel_shift"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ",", "use_stable_version", "=", "False", ")", ":", "\n", "        ", "qlen", ",", "rlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "r", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "#if using stable version, then want layernorm of memory as well before MHA", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "\n", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "if", "not", "use_stable_version", "else", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "if", "not", "use_stable_version", "else", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "r_head_k", ".", "view", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x n_head x d_head", "\n", "\n", "#### compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "r_r_bias", "\n", "BD", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "rr_head_q", ",", "r_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "#THIS IS WHAT IS Usually executed", "\n", "#print('Attentionscore shape: ',attn_score.shape)", "\n", "#print('MASK SHAPE: ', attn_mask[:,:,:,None].shape)", "\n", "#print('MASK EL 1: ', attn_mask[:,:,0])", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", ".", "type_as", "(", "attn_score", ")", "\n", "\n", "#print('ATTENTION SCORE: ', attn_score)", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "#### compute attention vector", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "##### residual connection + layer normalization", "\n", "#output = self.layer_norm(w + attn_out)", "\n", "\n", "return", "attn_out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.MemTransformerLM.__init__": [[333, 377], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "old_transformer_xl.MemTransformerLM._create_params", "old_transformer_xl.MemTransformerLM.layers.append", "old_transformer_xl.RelPartialLearnableDecoderLayer"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._create_params"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "n_layer", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "\n", "dropout", ",", "dropatt", ",", "tie_weight", "=", "True", ",", "d_embed", "=", "None", ",", "\n", "div_val", "=", "1", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "1", ",", "\n", "cutoffs", "=", "[", "]", ",", "adapt_inp", "=", "False", ",", "\n", "same_length", "=", "False", ",", "clamp_len", "=", "-", "1", ",", "\n", "use_gate", "=", "True", ",", "use_stable_version", "=", "True", ")", ":", "\n", "        ", "super", "(", "MemTransformerLM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_token", "=", "n_token", "# TODO : Check this is not being used anywhere", "\n", "\n", "self", ".", "d_embed", "=", "d_model", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_head", "=", "d_head", "\n", "\n", "# self.state_emb = State_Embedder()", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "self", ".", "max_klen", "=", "tgt_len", "+", "ext_len", "+", "mem_len", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_layer", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "RelPartialLearnableDecoderLayer", "(", "\n", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "use_stable_version", "=", "use_stable_version", ",", "use_gate", "=", "use_gate", ",", "\n", "tgt_len", "=", "tgt_len", ",", "ext_len", "=", "ext_len", ",", "mem_len", "=", "mem_len", ",", "\n", "dropatt", "=", "dropatt", ")", "\n", ")", "\n", "\n", "#To do: Look into sample softmax and adaptive softmax for future, not relevant here though", "\n", "# are useful when need fast softmax over many classes", "\n", "\n", "", "self", ".", "same_length", "=", "same_length", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "\n", "self", ".", "_create_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.MemTransformerLM.backward_compatible": [[378, 380], ["None"], "methods", ["None"], ["", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.MemTransformerLM._create_params": [[381, 385], ["old_transformer_xl.PositionalEmbedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "_create_params", "(", "self", ")", ":", "\n", "        ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.MemTransformerLM.reset_length": [[386, 390], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.MemTransformerLM.init_mems": [[391, 402], ["next", "range", "old_transformer_xl.MemTransformerLM.parameters", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "mems.append"], "methods", ["None"], ["", "def", "init_mems", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", "+", "1", ")", ":", "\n", "                ", "empty", "=", "torch", ".", "empty", "(", "0", ",", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.MemTransformerLM._update_mems": [[405, 430], ["len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_mems.append", "cat[].detach"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "return", "None", "\n", "\n", "# mems is not None", "\n", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "'len(hids) != len(mems)'", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "# ext_len looks to usually be 0 (in their experiments anyways", "\n", "\n", "# TODO: I have changed beg_idx to 0 since want to use all memory, may want to change", "\n", "#       this once move to larger environments", "\n", "beg_idx", "=", "0", "#max(0, end_idx - self.mem_len)", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "dim", "=", "0", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ".", "detach", "(", ")", ")", "\n", "\n", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.MemTransformerLM._forward": [[435, 495], ["obs_emb.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "old_transformer_xl.MemTransformerLM.pos_emb", "old_transformer_xl.MemTransformerLM.drop", "old_transformer_xl.MemTransformerLM.drop", "hids.append", "enumerate", "old_transformer_xl.MemTransformerLM.drop", "old_transformer_xl.MemTransformerLM._update_mems", "mems[].size", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "dec_attn_mask.repeat.repeat.repeat", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "layer", "hids.append", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "obs_emb.new_ones", "range", "range"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._update_mems"], ["", "def", "_forward", "(", "self", ",", "obs_emb", ",", "padding_mask", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "qlen", ",", "bsz", ",", "_", "=", "obs_emb", ".", "size", "(", ")", "#qlen is number of characters in input ex", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "# print('HERE: mlen: {}, len mems: {}, mems[0] shape: {}'.format(mlen, len(mems),mems[0].shape))", "\n", "", "else", ":", "\n", "            ", "mlen", "=", "0", "\n", "# mlen = mems[0].size(0) if mems is not None else 0", "\n", "\n", "", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "# create the mask taking in consideration the mlen as well. All memory should be attended by the first query", "\n", "dec_attn_mask", "=", "torch", ".", "triu", "(", "\n", "obs_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", ",", "diagonal", "=", "1", "+", "mlen", ")", ".", "bool", "(", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "# TODO: Possibly make this more efficient (check how much things slow down)", "\n", "# This part only runs when calling model in \"learn\" since in \"act\" we will", "\n", "# never need padding", "\n", "if", "not", "(", "padding_mask", "is", "None", ")", ":", "\n", "# concat the memory padding along with the padding_mask", "\n", "            ", "dec_attn_mask", "=", "dec_attn_mask", ".", "repeat", "(", "1", ",", "1", ",", "bsz", ")", "\n", "dec_attn_mask", "=", "dec_attn_mask", "|", "padding_mask", "\n", "#print('Dec_attn_mask: ', dec_attn_mask[:,:,0])", "\n", "#want the mlen diagonal to be 0's so that each query can attend", "\n", "#to itself", "\n", "dec_attn_mask", "[", "range", "(", "qlen", ")", ",", "range", "(", "mlen", ",", "klen", ")", ",", ":", "]", "=", "False", "\n", "#print('AFTER: ', dec_attn_mask[:,:,0])", "\n", "#print('ATTN SHAPE: ', dec_attn_mask.shape)", "\n", "\n", "", "hids", "=", "[", "]", "\n", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "obs_emb", ".", "device", ",", "\n", "dtype", "=", "obs_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "            ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "obs_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "hids", ".", "append", "(", "core_out", ")", "\n", "#SEEMS THAT THEY store memory per layer which makes sense to attend to (for ex if at first layer, if we were", "\n", "#applying attention to memory and this new data, this would give us the same result.", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "#print('HIDDEN iter: {}, output: {}'.format(i, core_out[-1,0, :10]))", "\n", "\n", "# TODO : The memory should be the same hidden layer's state of the previous T timesteps", "\n", "            ", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "# print('from txl483 shapes : ', core_out.shape, pos_emb.shape, self.r_w_bias.shape, self.r_r_bias.shape, dec_attn_mask.shape, mems_i.shape)", "\n", "core_out", "=", "layer", "(", "core_out", ",", "pos_emb", ",", "self", ".", "r_w_bias", ",", "\n", "self", ".", "r_r_bias", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ")", "\n", "hids", ".", "append", "(", "core_out", ")", "\n", "\n", "\n", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "return", "core_out", ",", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_transformer_xl.MemTransformerLM.forward": [[497, 520], ["old_transformer_xl.MemTransformerLM._forward", "old_transformer_xl.MemTransformerLM.init_mems", "print", "print", "print", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._forward", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.init_mems"], ["", "def", "forward", "(", "self", ",", "data", ",", "mems", ",", "padding_mask", ",", "mem_padding", ")", ":", "\n", "#padding_mask should be shape 1 X (mlen+qlen) X batch_size,", "\n", "#which we apply row wise", "\n", "\n", "        ", "if", "not", "mems", ":", "\n", "# print('INITIALIZED MEMS')", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", ")", "\n", "\n", "#Concatenate mem_padding and padding_mask (slight modifications if None)", "\n", "", "padding_mask2", "=", "mem_padding", "\n", "if", "padding_mask2", "is", "None", ":", "\n", "            ", "padding_mask2", "=", "padding_mask", "\n", "", "elif", "padding_mask", "is", "not", "None", ":", "\n", "            ", "padding_mask2", "=", "torch", ".", "cat", "(", "[", "mem_padding", ",", "padding_mask", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "mem_padding", "is", "not", "None", "and", "padding_mask", "is", "not", "None", ":", "\n", "            ", "print", "(", "'Adding orig: '", ",", "padding_mask", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "print", "(", "'mem_padding: '", ",", "mem_padding", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "print", "(", "'Result: '", ",", "padding_mask2", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "\n", "", "hidden", ",", "new_mems", "=", "self", ".", "_forward", "(", "data", ",", "padding_mask", "=", "padding_mask2", ",", "mems", "=", "mems", ")", "\n", "\n", "return", "hidden", ",", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.transformerDqn.CartPoleEmbedder.__init__": [[25, 58], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", ",", "B", ",", "input_size", ",", "embedding_size", ")", ":", "\n", "        ", "'''\n        :param B: Number of times we embed each state (with dropout each time)\n\n        '''", "\n", "\n", "super", "(", "CartPoleEmbedder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "B", "=", "B", "\n", "self", ".", "dropout_p", "=", "dropout", "\n", "self", ".", "layer1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_size", ",", "embedding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", ")", "\n", "\n", "self", ".", "layer2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "embedding_size", ",", "embedding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", ")", "\n", "\n", "self", ".", "layer3", "=", "nn", ".", "Linear", "(", "embedding_size", ",", "embedding_size", ")", "\n", "\n", "#now need to combine the B copies of the elements", "\n", "#Can start by using just linear combo then move to nonlinear combo", "\n", "\n", "\n", "'''\n        self.layer3 = nn.Sequential(\n            nn.Linear(embedding_size, embedding_size),\n            nn.ReLU()\n        )\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.transformerDqn.CartPoleEmbedder.forward": [[59, 70], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformerDqn.CartPoleEmbedder.layer1", "transformerDqn.CartPoleEmbedder.layer3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "is_training", "=", "True", ")", ":", "\n", "#want to now stack B copies of input on top of eachother", "\n", "#Batch dim is dim 0", "\n", "        ", "input", "=", "torch", ".", "cat", "(", "self", ".", "B", "*", "[", "input", "]", ")", "\n", "\n", "#The dropout implementation in pytorch applies dropout differently per element in batch", "\n", "#which is what we want", "\n", "\n", "hidden", "=", "self", ".", "layer1", "(", "input", ")", "\n", "#hidden = self.layer2(hidden)", "\n", "return", "self", ".", "layer3", "(", "hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.transformerDqn.TransformerDqn.__init__": [[75, 88], ["torch.Module.__init__", "embedder", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.TransformerEncoder", "torch.TransformerEncoder", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedder", ",", "embedder_params", ",", "encoder_layer_params", ",", "num_encoder_layers", ",", "output_size", ")", ":", "\n", "        ", "'''\n        :param embedder: module to embed the states\n        :param output_size: number of actions we can choose\n        '''", "\n", "\n", "dropout", "=", "embedder_params", "[", "'dropout'", "]", "\n", "\n", "super", "(", "TransformerDqn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedder", "=", "embedder", "(", "**", "embedder_params", ")", "\n", "self", ".", "encoder_layer", "=", "nn", ".", "TransformerEncoderLayer", "(", "**", "encoder_layer_params", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "TransformerEncoder", "(", "encoder_layer", "=", "self", ".", "encoder_layer", ",", "num_layers", "=", "num_encoder_layers", ")", "\n", "self", ".", "output_layer", "=", "nn", ".", "Linear", "(", "encoder_layer_params", "[", "'d_model'", "]", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.transformerDqn.TransformerDqn.forward": [[89, 98], ["transformerDqn.TransformerDqn.embedder", "transformerDqn.TransformerDqn.encoder", "transformerDqn.TransformerDqn.output_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "'''\n        :param input: matrix of state vectors (last column will contain state of interest)\n        :return: vector of Q values for each action\n        '''", "\n", "\n", "embedding", "=", "self", ".", "embedder", "(", "input", ")", "\n", "embedding", "=", "self", ".", "encoder", "(", "embedding", ")", "\n", "return", "self", ".", "output_layer", "(", "embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.AtariNet.__init__": [[1083, 1187], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "feats_convs.append", "feats_convs.append", "train.AtariNet.feat_convs.append", "range", "torch.nn.Linear", "torch.nn.Linear", "adaptive_span2.models.TransformerSeq", "StableTransformersReplication.transformer_xl.MemTransformerLM", "train.AtariNet.core.apply", "train.AtariNet.policy.apply", "train.AtariNet.baseline.apply", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "torch.nn.Sequential", "resnet_block.append", "resnet_block.append", "resnet_block.append", "resnet_block.append", "train.AtariNet.core.init_gru_bias", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "train.AtariNet.resnet1.append", "train.AtariNet.resnet2.append", "torch.nn.Sequential", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.init_gru_bias"], ["    ", "def", "__init__", "(", "self", ",", "observation_shape", ",", "num_actions", ",", "flags", ")", ":", "\n", "        ", "super", "(", "AtariNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "observation_shape", "=", "observation_shape", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "\n", "self", ".", "feat_convs", "=", "[", "]", "\n", "self", ".", "resnet1", "=", "[", "]", "\n", "self", ".", "resnet2", "=", "[", "]", "\n", "\n", "self", ".", "convs", "=", "[", "]", "\n", "input_channels", "=", "self", ".", "observation_shape", "[", "0", "]", "\n", "for", "num_ch", "in", "[", "16", ",", "32", ",", "32", "]", ":", "\n", "            ", "feats_convs", "=", "[", "]", "\n", "feats_convs", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "feats_convs", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "self", ".", "feat_convs", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "feats_convs", ")", ")", "\n", "\n", "input_channels", "=", "num_ch", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "                ", "resnet_block", "=", "[", "]", "\n", "resnet_block", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "resnet_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "resnet_block", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "resnet_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "self", ".", "resnet1", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "resnet_block", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "resnet2", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "resnet_block", ")", ")", "\n", "\n", "", "", "", "self", ".", "feat_convs", "=", "nn", ".", "ModuleList", "(", "self", ".", "feat_convs", ")", "\n", "self", ".", "resnet1", "=", "nn", ".", "ModuleList", "(", "self", ".", "resnet1", ")", "\n", "self", ".", "resnet2", "=", "nn", ".", "ModuleList", "(", "self", ".", "resnet2", ")", "\n", "\n", "# Fully connected layer.", "\n", "# Changed the FC output to match the transformer output which should be divisible by number of heads", "\n", "if", "flags", ".", "atari", ":", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3872", ",", "256", "-", "num_actions", "-", "1", ")", "\n", "", "else", ":", "\n", "#DMLAB CHANGES", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3456", ",", "256", "-", "num_actions", "-", "1", ")", "\n", "\n", "# FC output size + one-hot of last action + last reward.", "\n", "", "core_output_size", "=", "self", ".", "fc", ".", "out_features", "+", "num_actions", "+", "1", "\n", "###############################################################transformer", "\n", "# TODO : 1st replacement, sanity check the parameters", "\n", "# TODO : play around with d_inner, this is the dimension for positionwise feedforward hidden projection", "\n", "# TODO : Change the n_layer=1 to 12", "\n", "self", ".", "adaptive_span", "=", "flags", ".", "use_adaptive", "\n", "self", ".", "hidden_size", "=", "core_output_size", "\n", "pers_mem_params", "=", "{", "'pers_mem_size'", ":", "flags", ".", "pers_mem_size", "}", "\n", "adapt_span_params", "=", "{", "\n", "'adapt_span_enabled'", ":", "True", ",", "\n", "'adapt_span_loss'", ":", "flags", ".", "adapt_span_loss", ",", "\n", "'adapt_span_ramp'", ":", "flags", ".", "adapt_span_ramp", ",", "\n", "'adapt_span_init'", ":", "flags", ".", "adapt_span_init", ",", "\n", "'adapt_span_cache'", ":", "flags", ".", "adapt_span_cache", "\n", "}", "\n", "\n", "self", ".", "policy", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "baseline", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "1", ")", "\n", "\n", "if", "flags", ".", "use_adaptive", ":", "\n", "            ", "self", ".", "core", "=", "AdaptiveTransformer", "(", "hidden_size", "=", "self", ".", "hidden_size", ",", "nb_heads", "=", "4", ",", "nb_layers", "=", "flags", ".", "n_layer", ",", "\n", "attn_span", "=", "flags", ".", "attn_span", ",", "flags", "=", "flags", ",", "dropout", "=", "flags", ".", "dropout", ",", "adapt_span_params", "=", "adapt_span_params", ",", "\n", "pers_mem_params", "=", "pers_mem_params", ",", "inner_hidden_size", "=", "flags", ".", "d_inner", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "core", "=", "MemTransformerLM", "(", "n_token", "=", "None", ",", "n_layer", "=", "flags", ".", "n_layer", ",", "n_head", "=", "4", ",", "d_head", "=", "core_output_size", "//", "4", ",", "\n", "d_model", "=", "core_output_size", ",", "d_inner", "=", "flags", ".", "d_inner", ",", "\n", "dropout", "=", "0.1", ",", "dropatt", "=", "0.0", ",", "mem_len", "=", "flags", ".", "mem_len", ",", "# TODO : CHeck if tgt_len=None causes any issue", "\n", "use_stable_version", "=", "True", ",", "use_gate", "=", "flags", ".", "use_gate", ")", "\n", "\n", "self", ".", "core", ".", "apply", "(", "weights_init", ")", "\n", "\n", "if", "flags", ".", "use_gate", ":", "\n", "                ", "self", ".", "core", ".", "init_gru_bias", "(", ")", "\n", "\n", "", "self", ".", "policy", ".", "apply", "(", "weights_init", ")", "\n", "self", ".", "baseline", ".", "apply", "(", "weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.AtariNet.initial_state": [[1191, 1201], ["tuple"], "methods", ["None"], ["", "", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "\n", "        ", "return", "tuple", "(", ")", "\n", "'''\n        return tuple(\n            # torch.zeros(self.core.num_layers, batch_size, self.core.hidden_size)\n            torch.zeros(self.core.n_layer, batch_size, self.core.d_model)\n            for _ in range(2)\n        )\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.AtariNet.forward": [[1202, 1304], ["torch.flatten", "enumerate", "torch.nn.functional.relu", "fconv.view", "torch.nn.functional.relu", "torch.nn.functional.one_hot().float", "torch.clamp().view", "torch.cat", "core_input.transpose.transpose.view", "torch.clone().bool", "padding_mask.unsqueeze.unsqueeze.unsqueeze", "train.AtariNet.core", "train.AtariNet.policy", "train.AtariNet.baseline", "policy_logits.view.view.reshape", "policy_logits.view.view.view", "baseline.view.view.view", "torch.argmax.view", "fconv.float", "fconv", "train.AtariNet.fc", "padding_mask.unsqueeze.unsqueeze.dim", "torch.clone", "logging.debug", "core_input.transpose.transpose.transpose", "logging.debug", "core_output.transpose.transpose.transpose", "torch.multinomial", "torch.argmax", "dict", "torch.nn.functional.one_hot", "torch.clamp", "torch.clone", "padding_mask.unsqueeze.unsqueeze.long().argmin", "torch.nn.functional.softmax", "inputs[].view", "padding_mask.unsqueeze.unsqueeze.long", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "core_state", "=", "(", ")", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "x", "=", "inputs", "[", "\"frame\"", "]", "\n", "T", ",", "B", ",", "*", "_", "=", "x", ".", "shape", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "0", ",", "1", ")", "# Merge time and batch.", "\n", "x", "=", "x", ".", "float", "(", ")", "/", "255.0", "\n", "\n", "for", "i", ",", "fconv", "in", "enumerate", "(", "self", ".", "feat_convs", ")", ":", "\n", "            ", "x", "=", "fconv", "(", "x", ")", "\n", "res_input", "=", "x", "\n", "x", "=", "self", ".", "resnet1", "[", "i", "]", "(", "x", ")", "\n", "x", "+=", "res_input", "\n", "res_input", "=", "x", "\n", "x", "=", "self", ".", "resnet2", "[", "i", "]", "(", "x", ")", "\n", "x", "+=", "res_input", "\n", "", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "# print('x shape : ',x.shape)", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n", "#logging.debug('In Atari net shape inputs: {}'.format(inputs['done'].shape))", "\n", "# print('inputs: ', inputs)", "\n", "# print('inputs last action', inputs['last_action'])", "\n", "one_hot_last_action", "=", "F", ".", "one_hot", "(", "\n", "inputs", "[", "\"last_action\"", "]", ".", "view", "(", "T", "*", "B", ")", ",", "self", ".", "num_actions", "\n", ")", ".", "float", "(", ")", "\n", "\n", "clipped_reward", "=", "torch", ".", "clamp", "(", "inputs", "[", "\"reward\"", "]", ",", "-", "1", ",", "1", ")", ".", "view", "(", "T", "*", "B", ",", "1", ")", "\n", "core_input", "=", "torch", ".", "cat", "(", "[", "x", ",", "clipped_reward", ",", "one_hot_last_action", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "core_input", "=", "core_input", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "\n", "\n", "padding_mask", "=", "torch", ".", "clone", "(", "inputs", "[", "'done'", "]", ")", ".", "bool", "(", ")", "\n", "\n", "ind_first_done", "=", "None", "\n", "if", "padding_mask", ".", "dim", "(", ")", ">", "1", ":", "# This only seems to not happen on first state ever in env.initialize()", "\n", "# this block just tries to push the dones one position down so that the loss calculation does account", "\n", "# for that step and not ignores it as mask", "\n", "            ", "ind_first_done", "=", "padding_mask", ".", "long", "(", ")", ".", "argmin", "(", "0", ")", "+", "1", "# will be index of first 1 in each column", "\n", "orig_first_row", "=", "torch", ".", "clone", "(", "padding_mask", "[", "0", ",", ":", "]", ")", "\n", "# If there aren't any 0's in the whole inputs['done'] then set ind_first_done to 0", "\n", "ind_first_done", "[", "padding_mask", "[", "0", ",", ":", "]", "==", "1", "]", "=", "0", "\n", "ind_first_done", "[", "ind_first_done", ">=", "padding_mask", ".", "shape", "[", "0", "]", "]", "=", "-", "1", "# choosing -1 helps in learn function", "\n", "padding_mask", "[", "ind_first_done", ",", "range", "(", "B", ")", "]", "=", "False", "\n", "padding_mask", "[", "0", ",", ":", "]", "=", "orig_first_row", "\n", "\n", "", "padding_mask", "=", "padding_mask", ".", "unsqueeze", "(", "0", ")", "\n", "if", "padding_mask", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "            ", "padding_mask", "=", "None", "#This means we're in act or test so no need for padding", "\n", "\n", "# core_input is of shape (T, B, ...)", "\n", "", "if", "self", ".", "adaptive_span", ":", "\n", "            ", "logging", ".", "debug", "(", "'USING ADAPTIVE'", ")", "\n", "#need input to B,T,H", "\n", "core_input", "=", "core_input", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "#mems is just the cache if using adaptive", "\n", "", "core_output", ",", "mems", "=", "self", ".", "core", "(", "core_input", ",", "mems", ")", "\n", "\n", "if", "self", ".", "adaptive_span", ":", "\n", "            ", "logging", ".", "debug", "(", "'USING ADAPTIVE'", ")", "\n", "#need output to T,B,H", "\n", "core_output", "=", "core_output", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "#print('Output shape: ', core_output.shape)", "\n", "#TODO Check what shape is in each case (want adaptive same as txl)", "\n", "\n", "", "policy_logits", "=", "self", ".", "policy", "(", "core_output", ")", "\n", "baseline", "=", "self", ".", "baseline", "(", "core_output", ")", "\n", "\n", "policy_logits", "=", "policy_logits", ".", "reshape", "(", "T", "*", "B", ",", "self", ".", "num_actions", ")", "\n", "# # if policy_logits.shape[0] == 32 and policy_logits.shape[1] == 6:", "\n", "# if not torch.all(policy_logits == policy_logits).item():", "\n", "#     # nans only come when the learner_model calls this forward", "\n", "#     print('from monobeast 921\\n', policy_logits)", "\n", "#     print('core output : ',core_output.shape, '\\n', core_output)", "\n", "#     print('core input : \\n', core_input)", "\n", "#     print('mask : \\n', padding_mask)", "\n", "#     print('mems : \\n', mems)", "\n", "#     torch.save(core_input, './core_input.pt')", "\n", "#     torch.save(padding_mask, './padding_mask.pt')", "\n", "#     torch.save(mems, './mems.pt')", "\n", "\n", "if", "self", ".", "training", ":", "\n", "# Sample from multinomial distribution for exploration", "\n", "# if not (padding_mask is None) and padding_mask.shape[1] > 1:", "\n", "#     print('Padding shape: {}, logits shape: {}'.format(padding_mask.shape, policy_logits.shape))", "\n", "#     print('PADDING: ', padding_mask)", "\n", "#     print(\"LOGITS: \", policy_logits)", "\n", "            ", "action", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "policy_logits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "# Don't sample when testing.", "\n", "            ", "action", "=", "torch", ".", "argmax", "(", "policy_logits", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_logits", "=", "policy_logits", ".", "view", "(", "T", ",", "B", ",", "self", ".", "num_actions", ")", "\n", "baseline", "=", "baseline", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "action", "=", "action", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "return", "(", "\n", "dict", "(", "policy_logits", "=", "policy_logits", ",", "baseline", "=", "baseline", ",", "action", "=", "action", ")", ",", "\n", "core_state", ",", "mems", ",", "padding_mask", ",", "ind_first_done", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.compute_baseline_loss": [[189, 193], ["torch.sum"], "function", ["None"], ["def", "compute_baseline_loss", "(", "advantages", ",", "padding_mask", ")", ":", "\n", "    ", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "advantages", "=", "advantages", "*", "padding_mask", "\n", "", "return", "0.5", "*", "torch", ".", "sum", "(", "advantages", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.compute_entropy_loss": [[196, 205], ["torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.sum", "padding_mask.unsqueeze"], "function", ["None"], ["", "def", "compute_entropy_loss", "(", "logits", ",", "padding_mask", ")", ":", "\n", "    ", "\"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"", "\n", "policy", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "log_policy", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "log_policy", "=", "log_policy", "*", "padding_mask", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "", "return", "torch", ".", "sum", "(", "policy", "*", "log_policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.compute_policy_gradient_loss": [[207, 217], ["torch.nn.functional.nll_loss", "cross_entropy.view_as.view_as", "torch.sum", "torch.nn.functional.log_softmax", "torch.flatten", "torch.flatten", "advantages.detach"], "function", ["None"], ["", "def", "compute_policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ",", "padding_mask", ")", ":", "\n", "    ", "cross_entropy", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "logits", ",", "0", ",", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "torch", ".", "flatten", "(", "actions", ",", "0", ",", "1", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", "\n", "cross_entropy", "=", "cross_entropy", ".", "view_as", "(", "advantages", ")", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "cross_entropy", "=", "cross_entropy", "*", "padding_mask", "\n", "", "return", "torch", ".", "sum", "(", "cross_entropy", "*", "advantages", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.act": [[219, 335], ["logging.info", "Model.core.prof.Timings", "train.create_env", "dmlab_environment.Environment.initial", "torch.tensor", "model.initial_state", "model", "int.from_bytes", "Model.core.environment.Environment", "torchbeast.core.environment.Environment", "model.core.initial_cache", "free_queue.get", "enumerate", "logging.debug", "env_output[].item", "full_queue.put", "logging.info", "logging.error", "traceback.print_exc", "os.urandom", "prof.Timings.reset", "prof.Timings.time", "range", "prof.Timings.time", "prof.Timings.time", "logging.debug", "dmlab_environment.Environment.step", "torch.tensor().repeat", "prof.Timings.summary", "env_output[].item", "torch.no_grad", "model", "dmlab_environment.Environment.step", "env_output[].item", "model.core.initial_cache", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.initial_cache", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.initial_cache"], ["", "def", "act", "(", "\n", "flags", ",", "\n", "actor_index", ":", "int", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "level_name", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"Actor %i started.\"", ",", "actor_index", ")", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "# Keep track of how fast things are.", "\n", "\n", "seed", "=", "actor_index", "^", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "4", ")", ",", "byteorder", "=", "\"little\"", ")", "\n", "# gym_env.seed(seed)", "\n", "gym_env", "=", "create_env", "(", "flags", "=", "flags", ",", "seed", "=", "seed", ")", "\n", "if", "flags", ".", "atari", ":", "\n", "            ", "env", "=", "atari_environment", ".", "Environment", "(", "gym_env", ")", "\n", "", "else", ":", "\n", "#DMLAB CHANGES", "\n", "            ", "env", "=", "dmlab_environment", ".", "Environment", "(", "gym_env", ")", "\n", "\n", "", "env_output", "=", "env", ".", "initial", "(", ")", "\n", "env_output", "[", "'done'", "]", "=", "torch", ".", "tensor", "(", "[", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "agent_state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "mems", "=", "None", "\n", "if", "flags", ".", "use_adaptive", ":", "\n", "            ", "mems", "=", "model", ".", "core", ".", "initial_cache", "(", "batch_size", "=", "1", ",", "device", "=", "None", ")", "\n", "\n", "", "agent_output", ",", "unused_state", ",", "mems", ",", "pad_mask1", ",", "_", "=", "model", "(", "env_output", ",", "agent_state", ",", "mems", ")", "\n", "while", "True", ":", "\n", "            ", "index", "=", "free_queue", ".", "get", "(", ")", "\n", "if", "index", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "# explicitly make done False to allow the loop to run", "\n", "# Don't need to set 'done' to true since now take step out of done state", "\n", "# when do arrive at 'done'", "\n", "# env_output['done'] = torch.tensor([0], dtype=torch.uint8)", "\n", "\n", "# Write old rollout end.", "\n", "", "for", "key", "in", "env_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "agent_state", ")", ":", "\n", "                ", "initial_agent_state_buffers", "[", "index", "]", "[", "i", "]", "[", "...", "]", "=", "tensor", "\n", "\n", "# Do one new rollout, untill flags.unroll_length", "\n", "", "t", "=", "0", "\n", "logging", ".", "debug", "(", "'STARTING UP ACTOR: %i'", ",", "actor_index", ")", "\n", "while", "t", "<", "flags", ".", "unroll_length", "and", "not", "env_output", "[", "'done'", "]", ".", "item", "(", ")", ":", "\n", "# for t in range(flags.unroll_length):", "\n", "                ", "timings", ".", "reset", "(", ")", "\n", "# REmoved since never this will never be true (MOVED TO AFTER FOR LOOP)", "\n", "# if env_output['done'].item():", "\n", "#    mems = None", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "agent_output", ",", "agent_state", ",", "mems", ",", "pad_mask1", ",", "_", "=", "model", "(", "env_output", ",", "agent_state", ",", "mems", ")", "\n", "#if actor_index == 0:", "\n", "#    logging.debug('actor: t: {}, mems size: {}, mem_padding size: {}'.format(t, mems[0].shape, mem_padding))", "\n", "", "timings", ".", "time", "(", "\"model\"", ")", "\n", "\n", "# TODO : Check if this probability skipping can compromise granularity", "\n", "# repeat_times = torch.randint(low=2, high=flags.action_repeat + 1, size=(1,)).item()", "\n", "for", "el", "in", "range", "(", "flags", ".", "action_repeat", ")", ":", "\n", "                    ", "env_output", "=", "env", ".", "step", "(", "agent_output", "[", "\"action\"", "]", ")", "\n", "if", "env_output", "[", "'done'", "]", ".", "item", "(", ")", ":", "\n", "                        ", "break", "\n", "\n", "", "", "timings", ".", "time", "(", "\"step\"", ")", "\n", "\n", "for", "key", "in", "env_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "\n", "", "timings", ".", "time", "(", "\"write\"", ")", "\n", "t", "+=", "1", "\n", "\n", "", "if", "env_output", "[", "'done'", "]", ".", "item", "(", ")", ":", "\n", "#for key in env_output:", "\n", "#    buffers[key][index][t + 1, ...] = env_output[key]", "\n", "#for key in agent_output:", "\n", "#    buffers[key][index][t + 1, ...] = agent_output[key]", "\n", "\n", "                ", "mems", "=", "None", "\n", "if", "flags", ".", "use_adaptive", ":", "\n", "                    ", "mems", "=", "model", ".", "core", ".", "initial_cache", "(", "batch_size", "=", "1", ",", "device", "=", "None", ")", "\n", "\n", "# Take arbitrary step to reset environment", "\n", "", "logging", ".", "debug", "(", "'actor: {}, RETURN: {}'", ".", "format", "(", "actor_index", ",", "env_output", "[", "'episode_return'", "]", ")", ")", "\n", "env_output", "=", "env", ".", "step", "(", "torch", ".", "tensor", "(", "[", "2", "]", ")", ")", "\n", "\n", "", "buffers", "[", "'len_traj'", "]", "[", "index", "]", "[", "0", "]", "=", "t", "\n", "\n", "if", "t", "!=", "flags", ".", "unroll_length", ":", "\n", "# TODO Is there a potential bug here", "\n", "                ", "buffers", "[", "'done'", "]", "[", "index", "]", "[", "t", "+", "1", ":", "]", "=", "torch", ".", "tensor", "(", "[", "True", "]", ")", ".", "repeat", "(", "flags", ".", "unroll_length", "-", "t", ")", "\n", "\n", "#logging.debug('Done rollout actor: %i', actor_index)", "\n", "", "full_queue", ".", "put", "(", "index", ")", "\n", "\n", "", "if", "actor_index", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Actor %i: %s\"", ",", "actor_index", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# Return silently.", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logging", ".", "error", "(", "\"Exception in worker process %i\"", ",", "actor_index", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "# print()", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.get_batch": [[337, 375], ["threading.Lock", "logging.debug", "timings.time", "timings.time", "tuple", "timings.time", "logging.debug", "timings.time", "timings.time", "torch.stack", "torch.cat", "free_queue.put", "t.to", "full_queue.get", "zip", "batch.items", "t.to", "range"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["", "", "def", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "\n", ")", ":", "\n", "    ", "logging", ".", "debug", "(", "'STARTING GET_BATCH'", ")", "\n", "with", "lock", ":", "\n", "        ", "timings", ".", "time", "(", "\"lock\"", ")", "\n", "indices", "=", "[", "full_queue", ".", "get", "(", ")", "for", "_", "in", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "\n", "# TODO: Check if emptying full_queue and then readding to it takes very long,", "\n", "#       seems like the only way to ensure a batch of similar length elements", "\n", "# One problem with doing this is that if get a really short trajectory, may never end up", "\n", "# using it. DONT CHANGE THIS FOR NOW.", "\n", "\n", "timings", ".", "time", "(", "\"dequeue\"", ")", "\n", "", "batch", "=", "{", "\n", "key", ":", "torch", ".", "stack", "(", "[", "buffers", "[", "key", "]", "[", "m", "]", "for", "m", "in", "indices", "]", ",", "dim", "=", "1", ")", "for", "key", "in", "buffers", "\n", "}", "\n", "initial_agent_state", "=", "(", "\n", "torch", ".", "cat", "(", "ts", ",", "dim", "=", "1", ")", "\n", "for", "ts", "in", "zip", "(", "*", "[", "initial_agent_state_buffers", "[", "m", "]", "for", "m", "in", "indices", "]", ")", "\n", ")", "\n", "timings", ".", "time", "(", "\"batch\"", ")", "\n", "for", "m", "in", "indices", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "", "timings", ".", "time", "(", "\"enqueue\"", ")", "\n", "batch", "=", "{", "k", ":", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "k", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "initial_agent_state", "=", "tuple", "(", "\n", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "t", "in", "initial_agent_state", "\n", ")", "\n", "timings", ".", "time", "(", "\"device\"", ")", "\n", "logging", ".", "debug", "(", "'Returned GetBATCH'", ")", "\n", "return", "batch", ",", "initial_agent_state", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.learn": [[377, 597], ["threading.Lock", "logging.debug", "range", "batch[].max().item", "actor_model.load_state_dict", "model.core.initial_cache", "list", "list", "torch.prod().item", "logging.debug", "torch.zeros_like().bool", "model", "mini_batch[].any", "Model.core.vtrace.from_logits", "train.compute_policy_gradient_loss", "logging.debug", "optimizer.zero_grad", "total_loss.backward", "stats[].extend", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "sum", "model.state_dict", "logging.debug", "mini_batch[].sum().item", "logging.debug", "print", "torch.clamp", "train.compute_baseline_loss", "train.compute_entropy_loss", "model.core.get_adaptive_span_loss", "enumerate", "tuple", "torch.mean().item", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "batch[].max().item", "str", "tuple", "torch.mean().item", "torch.mean().item", "model.parameters", "batch[].max", "torch.prod", "torch.zeros_like", "mini_batch.items", "learner_outputs.items", "episode_returns.cpu().numpy", "episode_returns.cpu().numpy", "stats[].append", "torch.tensor", "mini_batch[].sum", "rows_to_use.append", "cols_to_use.append", "torch.mean", "batch[].max", "torch.mean", "torch.mean", "torch.mean().item", "mini_batch[].size", "range", "episode_returns.cpu", "episode_returns.cpu", "curpad_mask.squeeze", "torch.mean"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.initial_cache", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.get_adaptive_span_loss"], ["", "def", "learn", "(", "\n", "flags", ",", "\n", "actor_model", ",", "\n", "model", ",", "\n", "batch", ",", "\n", "initial_agent_state", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "# noqa: B008", "\n", ")", ":", "\n", "    ", "\"\"\"Performs a learning (optimization) step.\"\"\"", "\n", "with", "lock", ":", "\n", "        ", "\"\"\"\n        put a lock on the central learner,\n        send the trajectories to it.\n        Update the parameters of the central learner,\n        copy the parameters of the central learner back to the actors\n        \"\"\"", "\n", "\n", "# TODO: Chop up batch into smaller pieces to run through TXL one at a time (caching previous as memory)", "\n", "# TODO: Change batch function to look for trajectories of similar lengths", "\n", "# TODO: Add in adaptive attention (and think of how things change (for ex no memory))", "\n", "# print({key: batch[key].shape for key in batch})", "\n", "mems", "=", "None", "\n", "if", "flags", ".", "use_adaptive", ":", "\n", "            ", "mems", "=", "model", ".", "core", ".", "initial_cache", "(", "batch_size", "=", "flags", ".", "batch_size", ",", "device", "=", "flags", ".", "device", ")", "\n", "\n", "# initialize stats", "\n", "", "stats", "=", "{", "\n", "\"episode_returns\"", ":", "list", "(", ")", ",", "\n", "\"mean_episode_return\"", ":", "list", "(", ")", ",", "\n", "\"total_loss\"", ":", "0", ",", "\n", "\"pg_loss\"", ":", "0", ",", "\n", "\"baseline_loss\"", ":", "0", ",", "\n", "\"entropy_loss\"", ":", "0", ",", "\n", "\"num_unpadded_steps\"", ":", "0", ",", "\n", "\"len_max_traj\"", ":", "0", ",", "\n", "\"learning_rate\"", ":", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "}", "\n", "\n", "logging", ".", "debug", "(", "'AT LEARN'", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "flags", ".", "unroll_length", "+", "1", ",", "flags", ".", "chunk_size", ")", ":", "\n", "            ", "mini_batch", "=", "{", "key", ":", "batch", "[", "key", "]", "[", "i", ":", "i", "+", "flags", ".", "chunk_size", "]", "for", "key", "in", "batch", "if", "key", "!=", "'len_traj'", "}", "\n", "# Note that initial agent state isn't used by transformer (I think this is hidden state)", "\n", "# Will need to change if want to use this with LSTM", "\n", "\n", "if", "mini_batch", "[", "'done'", "]", ".", "shape", "[", "0", "]", "!=", "flags", ".", "chunk_size", ":", "\n", "                ", "logging", ".", "debug", "(", "'BREAKING WITH SHAPE : %s'", ",", "mini_batch", "[", "'done'", "]", ".", "shape", ")", "\n", "break", "#This would break around memory padding", "\n", "\n", "#TODO Trim mini_batch if all dones at the end: If everything is done just continue here", "\n", "#    CAN DO THIS by looking at buffers['len_traj']", "\n", "# For now just say that if more than half the minibatch is done, then continue", "\n", "", "mini_batch_size", "=", "torch", ".", "prod", "(", "torch", ".", "tensor", "(", "mini_batch", "[", "'done'", "]", ".", "size", "(", ")", ")", ")", ".", "item", "(", ")", "\n", "if", "mini_batch", "[", "'done'", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "mini_batch_size", ":", "#> mini_batch_size / 2:", "\n", "                ", "logging", ".", "debug", "(", "'Breaking with all elements done'", ")", "#Breaking with more than half elements done')", "\n", "break", "\n", "\n", "#if mini_batch['done'].sum().item() > 0:", "\n", "#    print(mini_batch['done'])", "\n", "#    print('FOUND ONE')", "\n", "", "logging", ".", "debug", "(", "'MiniBatch shape: %s'", ",", "mini_batch", "[", "'done'", "]", ".", "shape", ")", "\n", "\n", "tmp_mask", "=", "torch", ".", "zeros_like", "(", "mini_batch", "[", "\"done\"", "]", ")", ".", "bool", "(", ")", "\n", "\n", "if", "flags", ".", "learner_no_mem", ":", "\n", "                ", "mems", "=", "None", "\n", "\n", "", "learner_outputs", ",", "unused_state", ",", "mems", ",", "curpad_mask", ",", "ind_first_done", "=", "model", "(", "mini_batch", ",", "initial_agent_state", ",", "\n", "mems", "=", "mems", ")", "\n", "if", "mini_batch", "[", "'done'", "]", ".", "any", "(", ")", ":", "\n", "                ", "print", "(", "'********Should see some return*********'", ")", "\n", "#     www = time.time()", "\n", "#     torch.save(mini_batch['done'],'./'+str(www)+'mini_batch_done.pt')", "\n", "#     print(\"mini_batch['done'] true at \", www)", "\n", "#     torch.save(ind_first_done, './' + str(www) + 'ind_first_done.pt')", "\n", "\n", "#to_print = False", "\n", "#if mini_batch['done'].sum().item() > 0:", "\n", "#    print('INds done: ', ind_first_done)", "\n", "#    print('MEM PADDING AFTER: ', mem_padding)", "\n", "#    to_print = True", "\n", "\n", "# Here mem_padding is same as \"batch\" padding for this iteration so can use", "\n", "# for masking loss", "\n", "\n", "# if mini_batch[\"done\"].any().item():", "\n", "#    print('Indfirstdone: ',ind_first_done)", "\n", "#    print('miniBATCH DONE: ', mini_batch[\"done\"])", "\n", "#    print('Mem padding: ', mem_padding)", "\n", "\n", "# Take final value function slice for bootstrapping.", "\n", "# this is the final value from this trajectory", "\n", "", "if", "ind_first_done", "is", "not", "None", ":", "\n", "# B dimensional tensor", "\n", "                ", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "ind_first_done", ",", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "", "else", ":", "\n", "                ", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "-", "1", "]", "\n", "\n", "# Move from obs[t] -> action[t] to action[t] -> obs[t].", "\n", "", "mini_batch", "=", "{", "key", ":", "tensor", "[", "1", ":", "]", "for", "key", ",", "tensor", "in", "mini_batch", ".", "items", "(", ")", "}", "\n", "learner_outputs", "=", "{", "key", ":", "tensor", "[", ":", "-", "1", "]", "for", "key", ",", "tensor", "in", "learner_outputs", ".", "items", "(", ")", "}", "\n", "\n", "# Using learner_outputs to predict batch since batch is always one ahead of learner_outputs?", "\n", "\n", "rewards", "=", "mini_batch", "[", "\"reward\"", "]", "\n", "if", "flags", ".", "reward_clipping", "==", "\"abs_one\"", ":", "\n", "                ", "clipped_rewards", "=", "torch", ".", "clamp", "(", "rewards", ",", "-", "1", ",", "1", ")", "\n", "", "elif", "flags", ".", "reward_clipping", "==", "\"none\"", ":", "\n", "                ", "clipped_rewards", "=", "rewards", "\n", "\n", "", "discounts", "=", "(", "~", "mini_batch", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "*", "flags", ".", "discounting", "\n", "\n", "vtrace_returns", "=", "vtrace", ".", "from_logits", "(", "\n", "behavior_policy_logits", "=", "mini_batch", "[", "\"policy_logits\"", "]", ",", "\n", "target_policy_logits", "=", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "# WHY IS THIS THE TARGET?", "\n", "actions", "=", "mini_batch", "[", "\"action\"", "]", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "clipped_rewards", ",", "\n", "values", "=", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", "ind_first_done", "=", "ind_first_done", ",", "# -1 to compensate the one shifted arrays will", "\n", "# be taken care in the function from_importance_weights", "\n", ")", "\n", "\n", "# TODO Next Step: the losses also have to be computed with the padding, think on a structure of mask", "\n", "#                   to do this efficiently", "\n", "# Advantages are [rollout_len, batch_size]", "\n", "\n", "# First we mask out vtrace_returns.pg_advantages where there is padding which fixes pg_loss", "\n", "pad_mask", "=", "(", "~", "(", "curpad_mask", ".", "squeeze", "(", "0", ")", "[", "1", ":", "]", ")", ")", ".", "float", "(", ")", "if", "curpad_mask", "is", "not", "None", "else", "None", "\n", "\n", "#if to_print:", "\n", "#    print('AFTER WARDS 2 mem_padding: ', mem_padding)", "\n", "#    print('Pad_mask: ', pad_mask)", "\n", "\n", "pg_loss", "=", "compute_policy_gradient_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "mini_batch", "[", "\"action\"", "]", ",", "\n", "vtrace_returns", ".", "pg_advantages", ",", "\n", "pad_mask", "\n", ")", "\n", "baseline_loss", "=", "flags", ".", "baseline_cost", "*", "compute_baseline_loss", "(", "\n", "vtrace_returns", ".", "vs", "-", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "pad_mask", "\n", ")", "\n", "entropy_loss", "=", "flags", ".", "entropy_cost", "*", "compute_entropy_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "pad_mask", "\n", ")", "\n", "\n", "total_loss", "=", "pg_loss", "+", "baseline_loss", "+", "entropy_loss", "\n", "\n", "#Now adding L1 norm of adaptive span params (is already multiplied", "\n", "#by scaling coefficient (chosen hyper param)).", "\n", "if", "flags", ".", "use_adaptive", ":", "\n", "                ", "total_loss", "+=", "model", ".", "core", ".", "get_adaptive_span_loss", "(", ")", "\n", "\n", "# tmp_mask is defined above", "\n", "", "if", "ind_first_done", "is", "not", "None", ":", "\n", "                ", "rows_to_use", "=", "[", "]", "\n", "cols_to_use", "=", "[", "]", "\n", "for", "i", ",", "val", "in", "enumerate", "(", "ind_first_done", ")", ":", "\n", "                    ", "if", "val", "!=", "-", "1", ":", "\n", "                        ", "rows_to_use", ".", "append", "(", "val", ")", "\n", "cols_to_use", ".", "append", "(", "i", ")", "\n", "\n", "", "", "tmp_mask", "[", "rows_to_use", ",", "cols_to_use", "]", "=", "True", "# NOT RIGHT FOR COLS THAT DIDNT FINISH", "\n", "tmp_mask", "=", "tmp_mask", "[", "1", ":", "]", "# This is how they initially had it so will keep like this", "\n", "# if mini_batch[\"done\"].any().item():", "\n", "#    print('TMP MASK: ',tmp_mask)", "\n", "#    print('BATCH DONE: ', mini_batch[\"done\"])", "\n", "#    print('shape1: {}, shape2: {}'.format(tmp_mask.shape, mini_batch['done'].shape))", "\n", "\n", "# episode_returns = mini_batch[\"episode_return\"][mini_batch[\"done\"]]", "\n", "", "episode_returns", "=", "mini_batch", "[", "\"episode_return\"", "]", "[", "tmp_mask", "]", "\n", "num_unpadded_steps", "=", "(", "~", "curpad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "if", "curpad_mask", "is", "not", "None", "else", "mini_batch_size", "\n", "\n", "stats_per_chunk", "=", "{", "\n", "\"episode_returns\"", ":", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "\"mean_episode_return\"", ":", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ",", "\n", "\"total_loss\"", ":", "total_loss", ".", "item", "(", ")", ",", "\n", "\"pg_loss\"", ":", "pg_loss", ".", "item", "(", ")", ",", "\n", "\"baseline_loss\"", ":", "baseline_loss", ".", "item", "(", ")", ",", "\n", "\"entropy_loss\"", ":", "entropy_loss", ".", "item", "(", ")", ",", "\n", "\"num_unpadded_steps\"", ":", "num_unpadded_steps", ",", "\n", "\"len_max_traj\"", ":", "batch", "[", "'len_traj'", "]", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "}", "\n", "logging", ".", "debug", "(", "'in learn with stats_per_chunk : %s'", ",", "str", "(", "stats_per_chunk", ")", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "\n", "# append the current stats_per_chunk with overall stats", "\n", "stats", "[", "'episode_returns'", "]", ".", "extend", "(", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "if", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", "==", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ":", "\n", "                ", "stats", "[", "\"mean_episode_return\"", "]", ".", "append", "(", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ")", ",", "\n", "\n", "", "stats", "[", "\"total_loss\"", "]", "+=", "total_loss", ".", "item", "(", ")", "\n", "stats", "[", "\"pg_loss\"", "]", "+=", "pg_loss", ".", "item", "(", ")", "\n", "stats", "[", "\"baseline_loss\"", "]", "+=", "baseline_loss", ".", "item", "(", ")", "\n", "stats", "[", "\"entropy_loss\"", "]", "+=", "entropy_loss", ".", "item", "(", ")", "\n", "stats", "[", "\"num_unpadded_steps\"", "]", "+=", "num_unpadded_steps", "\n", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "flags", ".", "grad_norm_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "# scheduler is being stepped in the lock of batch_and_learn itself", "\n", "\n", "# update len_max_traj separately since it doesnt depend on minibatches", "\n", "", "stats", "[", "\"len_max_traj\"", "]", "=", "batch", "[", "'len_traj'", "]", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "# update the losses as the mean", "\n", "total_num_minibatches", "=", "(", "flags", ".", "unroll_length", "+", "1", ")", "//", "flags", ".", "chunk_size", "\n", "stats", "[", "\"mean_episode_return\"", "]", "=", "sum", "(", "stats", "[", "\"mean_episode_return\"", "]", ")", "/", "total_num_minibatches", "\n", "stats", "[", "\"total_loss\"", "]", "/=", "total_num_minibatches", "\n", "stats", "[", "\"pg_loss\"", "]", "/=", "total_num_minibatches", "\n", "stats", "[", "\"baseline_loss\"", "]", "/=", "total_num_minibatches", "\n", "stats", "[", "\"entropy_loss\"", "]", "/=", "total_num_minibatches", "\n", "\n", "\n", "actor_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.create_buffers": [[599, 618], ["dict", "range", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "buffers[].append", "torch.zeros().share_memory_", "torch.zeros"], "function", ["None"], ["", "", "def", "create_buffers", "(", "flags", ",", "obs_shape", ",", "num_actions", ")", "->", "Buffers", ":", "\n", "    ", "T", "=", "flags", ".", "unroll_length", "\n", "specs", "=", "dict", "(", "\n", "frame", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "*", "obs_shape", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "reward", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "done", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "\n", "episode_return", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "episode_step", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "policy_logits", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "num_actions", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "baseline", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "last_action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "len_traj", "=", "dict", "(", "size", "=", "(", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "# is min(length til trajectory is done, T)", "\n", ")", "\n", "buffers", ":", "Buffers", "=", "{", "key", ":", "[", "]", "for", "key", "in", "specs", "}", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "for", "key", "in", "buffers", ":", "\n", "            ", "buffers", "[", "key", "]", ".", "append", "(", "torch", ".", "zeros", "(", "**", "specs", "[", "key", "]", ")", ".", "share_memory_", "(", ")", ")", "\n", "", "", "return", "buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.get_optimizer": [[620, 629], ["flags.optim.lower", "torch.optim.SGD", "flags.optim.lower", "torch.optim.Adam", "flags.optim.lower", "torch.optim.Adagrad"], "function", ["None"], ["", "def", "get_optimizer", "(", "flags", ",", "parameters", ")", ":", "\n", "    ", "optimizer", "=", "None", "\n", "if", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ",", "momentum", "=", "flags", ".", "momentum", ")", "\n", "", "elif", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ")", "\n", "", "elif", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'adagrad'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.get_scheduler": [[631, 659], ["torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.ReduceLROnPlateau"], "function", ["None"], ["", "def", "get_scheduler", "(", "flags", ",", "optimizer", ")", ":", "\n", "    ", "scheduler", "=", "None", "\n", "if", "flags", ".", "scheduler", "==", "'cosine'", ":", "\n", "# here we do not set eta_min to lr_min to be backward compatible", "\n", "# because in previous versions eta_min is default to 0", "\n", "# rather than the default value of lr_min 1e-6", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "\n", "(", "flags", ".", "total_steps", "-", "flags", ".", "warmup_step", ")", "//", "flags", ".", "steps_btw_sched_updates", ",", "\n", "eta_min", "=", "flags", ".", "eta_min", ")", "\n", "", "elif", "flags", ".", "scheduler", "==", "'inv_sqrt'", ":", "\n", "# originally used for Transformer (in Attention is all you need)", "\n", "        ", "def", "lr_lambda", "(", "step", ")", ":", "\n", "# return a multiplier instead of a learning rate", "\n", "            ", "if", "step", "==", "0", "and", "flags", ".", "warmup_step", "==", "0", ":", "\n", "                ", "return", "1.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "/", "(", "step", "**", "0.5", ")", "if", "step", ">", "flags", ".", "warmup_step", "else", "step", "/", "(", "flags", ".", "warmup_step", "**", "1.5", ")", "\n", "\n", "", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lr_lambda", ")", "\n", "\n", "", "elif", "flags", ".", "scheduler", "==", "'dev_perf'", ":", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "\n", "factor", "=", "flags", ".", "decay_rate", ",", "patience", "=", "flags", ".", "patience", ",", "\n", "min_lr", "=", "flags", ".", "lr_min", ")", "\n", "", "elif", "flags", ".", "scheduler", "==", "'constant'", ":", "\n", "        ", "pass", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.train": [[661, 977], ["logging.debug", "Model.core.file_writer.FileWriter", "os.path.expandvars", "train.create_env", "Net.share_memory", "range", "torch.multiprocessing.get_context", "mp.get_context.SimpleQueue", "mp.get_context.SimpleQueue", "range", "print", "train.get_optimizer", "train.get_scheduler", "logging.getLogger", "logging.getLogger.info", "torch.zeros", "range", "range", "logging.debug", "train.train.checkpoint"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_optimizer", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_scheduler", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.checkpoint"], ["", "def", "train", "(", "flags", ")", ":", "# pylint: disable=too-many-branches, too-many-statements", "\n", "\n", "    ", "if", "flags", ".", "debug", ":", "\n", "        ", "logging", ".", "root", ".", "setLevel", "(", "level", "=", "logging", ".", "DEBUG", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "root", ".", "setLevel", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "", "logging", ".", "debug", "(", "'First Debug message'", ")", "\n", "# load the previous config if use_pretrained is true", "\n", "if", "flags", ".", "use_pretrained", ":", "\n", "        ", "logging", ".", "info", "(", "'Using Pretrained Model'", ")", "\n", "#TODO Check if this loading below works properly", "\n", "class", "Bunch", "(", "object", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "adict", ")", ":", "\n", "                ", "self", ".", "__dict__", ".", "update", "(", "adict", ")", "\n", "\n", "", "", "model_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "\n", "'logs/torchbeast/'", "+", "flags", ".", "xpid", "+", "'/model.tar'", ")", "\n", "pretrained_model", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "'cpu'", "if", "flags", ".", "disable_cuda", "else", "'gpu'", ")", "\n", "flags", "=", "Bunch", "(", "pretrained_model", "[", "'flags'", "]", ")", "\n", "flags", ".", "use_pretrained", "=", "True", "\n", "\n", "", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "flags", ".", "xpid", "=", "\"torchbeast-%s\"", "%", "time", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "", "plogger", "=", "file_writer", ".", "FileWriter", "(", "\n", "xpid", "=", "flags", ".", "xpid", ",", "xp_args", "=", "flags", ".", "__dict__", ",", "rootdir", "=", "flags", ".", "savedir", "\n", ")", "\n", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "if", "flags", ".", "num_buffers", "is", "None", ":", "# Set sensible default for num_buffers.", "\n", "        ", "flags", ".", "num_buffers", "=", "max", "(", "2", "*", "flags", ".", "num_actors", ",", "flags", ".", "batch_size", ")", "\n", "", "if", "flags", ".", "num_actors", ">=", "flags", ".", "num_buffers", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than num_actors\"", ")", "\n", "", "if", "flags", ".", "num_buffers", "<", "flags", ".", "batch_size", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than batch_size\"", ")", "\n", "\n", "", "T", "=", "flags", ".", "unroll_length", "\n", "B", "=", "flags", ".", "batch_size", "\n", "\n", "flags", ".", "device", "=", "None", "\n", "if", "not", "flags", ".", "disable_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Not using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "env", "=", "create_env", "(", "flags", ")", "\n", "if", "flags", ".", "atari", ":", "\n", "        ", "\"\"\"model is each of the actors, running parallel. The upcoming block ctx.Process(...)\"\"\"", "\n", "model", "=", "Net", "(", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ",", "flags", "=", "flags", ")", "\n", "buffers", "=", "create_buffers", "(", "flags", ",", "env", ".", "observation_space", ".", "shape", ",", "model", ".", "num_actions", ")", "\n", "", "else", ":", "\n", "# DMLAB CHANGES", "\n", "        ", "\"\"\"model is each of the actors, running parallel. The upcoming block ctx.Process(...)\"\"\"", "\n", "model", "=", "Net", "(", "env", ".", "initial", "(", ")", ".", "shape", ",", "len", "(", "dmlab_environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", "=", "flags", ")", "\n", "buffers", "=", "create_buffers", "(", "flags", ",", "env", ".", "_observation", "(", ")", ".", "shape", ",", "model", ".", "num_actions", ")", "\n", "\n", "", "model", ".", "share_memory", "(", ")", "\n", "\n", "# Add initial RNN state.", "\n", "initial_agent_state_buffers", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "for", "t", "in", "state", ":", "\n", "            ", "t", ".", "share_memory_", "(", ")", "\n", "", "initial_agent_state_buffers", ".", "append", "(", "state", ")", "\n", "\n", "", "actor_processes", "=", "[", "]", "\n", "ctx", "=", "mp", ".", "get_context", "(", "\"fork\"", ")", "\n", "free_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "full_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "        ", "actor", "=", "ctx", ".", "Process", "(", "\n", "target", "=", "act", ",", "\n", "args", "=", "(", "\n", "flags", ",", "\n", "i", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "model", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "flags", ".", "level_name", "\n", ")", ",", "\n", ")", "\n", "actor", ".", "start", "(", ")", "\n", "actor_processes", ".", "append", "(", "actor", ")", "\n", "\n", "", "\"\"\"learner_model is the central learner, which takes in the experiences and updates itself\"\"\"", "\n", "if", "flags", ".", "atari", ":", "\n", "        ", "learner_model", "=", "Net", "(", "\n", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ",", "flags", "=", "flags", ")", ".", "to", "(", "device", "=", "flags", ".", "device", ")", "\n", "", "else", ":", "\n", "# DMLAB CHANGES", "\n", "        ", "learner_model", "=", "Net", "(", "\n", "env", ".", "_observation", "(", ")", ".", "shape", ",", "len", "(", "dmlab_environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", "=", "flags", ")", ".", "to", "(", "device", "=", "flags", ".", "device", ")", "\n", "# DMLAB CHANGES END", "\n", "\n", "", "print", "(", "'--------------- TOTAL MODEL PARAMETERS : {} ---------------'", ".", "format", "(", "get_model_parameters", "(", "learner_model", ")", ")", ")", "\n", "\n", "optimizer", "=", "get_optimizer", "(", "flags", ",", "learner_model", ".", "parameters", "(", ")", ")", "\n", "if", "optimizer", "is", "None", ":", "\n", "# Use the default optimizer used in monobeast", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "\n", "learner_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "flags", ".", "learning_rate", ",", "\n", "momentum", "=", "flags", ".", "momentum", ",", "\n", "eps", "=", "flags", ".", "epsilon", ",", "\n", "alpha", "=", "flags", ".", "alpha", ",", "\n", "weight_decay", "=", "flags", ".", "weight_decay", "\n", ")", "\n", "\n", "", "def", "lr_lambda", "(", "epoch", ")", ":", "\n", "        ", "return", "1", "-", "min", "(", "epoch", "*", "T", "*", "B", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "\n", "", "scheduler", "=", "get_scheduler", "(", "flags", ",", "optimizer", ")", "\n", "if", "scheduler", "is", "None", ":", "\n", "# use the default scheduler as used in monobeast", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ")", "\n", "\n", "", "last_n_episode_return_key", "=", "\"last_{}_episode_returns\"", ".", "format", "(", "flags", ".", "stats_episodes", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"logfile\"", ")", "\n", "stat_keys", "=", "[", "\n", "\"total_loss\"", ",", "\n", "\"mean_episode_return\"", ",", "\n", "last_n_episode_return_key", ",", "\n", "\"max_return_achieved\"", ",", "\n", "\"pg_loss\"", ",", "\n", "\"baseline_loss\"", ",", "\n", "\"entropy_loss\"", ",", "\n", "\"learning_rate\"", ",", "\n", "]", "\n", "logger", ".", "info", "(", "\"# Step\\t%s\"", ",", "\"\\t\"", ".", "join", "(", "stat_keys", ")", ")", "\n", "\n", "step", ",", "stats", "=", "0", ",", "{", "}", "\n", "last_n_episode_returns", "=", "torch", ".", "zeros", "(", "(", "flags", ".", "stats_episodes", ")", ")", "\n", "steps_since_sched_update", "=", "0", "\n", "if", "flags", ".", "use_pretrained", ":", "\n", "        ", "logging", ".", "info", "(", "'Using Pretrained Model -> loading learner_model, optimizer, scheduler states'", ")", "\n", "learner_model", ".", "load_state_dict", "(", "pretrained_model", "[", "'model_state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "pretrained_model", "[", "'optimizer_state_dict'", "]", ")", "\n", "scheduler", ".", "load_state_dict", "(", "pretrained_model", "[", "'scheduler_state_dict'", "]", ")", "\n", "\n", "", "def", "batch_and_learn", "(", "i", ",", "lock", "=", "threading", ".", "Lock", "(", ")", ")", ":", "\n", "        ", "\"\"\"Thread target for the learning process.\"\"\"", "\n", "nonlocal", "step", ",", "stats", ",", "steps_since_sched_update", ",", "last_n_episode_returns", "\n", "# TODO : last_n_episode_returns and curr_index will be screwed if you use 1+ learner threads, keep in mind", "\n", "curr_index", "=", "-", "1", "\n", "max_return", "=", "-", "1e5", "\n", "max_return_step", "=", "0", "\n", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "timings", ".", "reset", "(", ")", "\n", "zz1", "=", "time", ".", "time", "(", ")", "\n", "batch", ",", "agent_state", "=", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", ")", "\n", "zz2", "=", "time", ".", "time", "(", ")", "\n", "\n", "logging", ".", "debug", "(", "'Before Learn'", ")", "\n", "stats", "=", "learn", "(", "\n", "flags", ",", "model", ",", "learner_model", ",", "batch", ",", "agent_state", ",", "optimizer", ",", "scheduler", "\n", ")", "\n", "logging", ".", "debug", "(", "'After Learn'", ")", "\n", "logging", ".", "debug", "(", "'stats: %s '", ",", "stats", ")", "\n", "timings", ".", "time", "(", "\"learn\"", ")", "\n", "with", "lock", ":", "\n", "# step-wise learning rate annealing", "\n", "                ", "if", "flags", ".", "scheduler", "in", "[", "'cosine'", ",", "'constant'", ",", "'dev_perf'", ",", "'linear_decay'", "]", ":", "\n", "# linear warmup stage", "\n", "                    ", "if", "step", "<", "flags", ".", "warmup_step", ":", "\n", "                        ", "curr_lr", "=", "flags", ".", "learning_rate", "*", "step", "/", "flags", ".", "warmup_step", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "curr_lr", "\n", "", "elif", "flags", ".", "scheduler", "==", "'cosine'", ":", "\n", "#TODO: Right now number of steps to do depends on T and B, which isn't ideal.", "\n", "#Instead will", "\n", "#Is better to step based on number of non padded entries in the padding mask.", "\n", "#Can make when we take a step be conditional on the step number (maybe each", "\n", "#10000 we step or so.", "\n", "                        ", "if", "steps_since_sched_update", ">=", "flags", ".", "steps_btw_sched_updates", ":", "\n", "                            ", "scheduler", ".", "step", "(", ")", "\n", "steps_since_sched_update", "=", "0", "\n", "", "", "elif", "flags", ".", "scheduler", "==", "'linear_decay'", ":", "\n", "#print('LR before: ', optimizer.param_groups[0]['lr'])", "\n", "                        ", "multiplier", "=", "1", "-", "min", "(", "step", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "flags", ".", "learning_rate", "*", "multiplier", "\n", "#print('LR AFTER : ',optimizer.param_groups[0]['lr'])", "\n", "", "", "elif", "flags", ".", "scheduler", "==", "'inv_sqrt'", ":", "\n", "                    ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "episode_returns", "=", "stats", ".", "get", "(", "\"episode_returns\"", ",", "None", ")", "\n", "if", "episode_returns", ":", "\n", "                    ", "for", "el", "in", "episode_returns", ":", "\n", "                        ", "last_n_episode_returns", "[", "(", "curr_index", "+", "1", ")", "%", "flags", ".", "stats_episodes", "]", "=", "el", ".", "item", "(", ")", "\n", "curr_index", "+=", "1", "\n", "if", "el", ".", "item", "(", ")", ">=", "max_return", ":", "\n", "                            ", "max_return", "=", "el", ".", "item", "(", ")", "\n", "max_return_step", "=", "step", "\n", "", "", "", "stats", ".", "update", "(", "{", "last_n_episode_return_key", ":", "last_n_episode_returns", ".", "mean", "(", ")", ".", "item", "(", ")", "}", ")", "\n", "stats", ".", "update", "(", "{", "'max_return_achieved'", ":", "'{} at step {}'", ".", "format", "(", "max_return", ",", "max_return_step", ")", "}", ")", "\n", "\n", "to_log", "=", "dict", "(", "step", "=", "step", ")", "\n", "to_log", ".", "update", "(", "{", "k", ":", "stats", ".", "get", "(", "k", ",", "None", ")", "for", "k", "in", "stat_keys", "}", ")", "\n", "\n", "# Now keep track of the max span per layer and log them in the csv file if adaptive is enabled", "\n", "if", "flags", ".", "use_adaptive", ":", "\n", "# Get max span per layer in learner_model", "\n", "                    ", "max_spans", "=", "[", "]", "\n", "for", "layer", "in", "learner_model", ".", "core", ".", "layers", ":", "\n", "                        ", "max_spans", ".", "append", "(", "layer", ".", "attn", ".", "attn", ".", "adaptive_span", ".", "_mask", ".", "get_current_max_size", "(", ")", ")", "\n", "", "print", "(", "'MAX SPANS : '", ",", "max_spans", ")", "\n", "for", "i", ",", "span_val", "in", "enumerate", "(", "max_spans", ")", ":", "\n", "                        ", "to_log", ".", "update", "(", "{", "'max_span_layer_'", "+", "str", "(", "i", ")", ":", "span_val", "}", ")", "\n", "\n", "", "", "plogger", ".", "log", "(", "to_log", ")", "\n", "# print('updating step from {} to {}'.format(step, step+(T*B)))", "\n", "if", "len", "(", "stats", ")", ">", "0", ":", "\n", "                    ", "step", "+=", "stats", "[", "'num_unpadded_steps'", "]", "#stats.get('num_unpadded_steps', 0) #T * B", "\n", "steps_since_sched_update", "+=", "stats", "[", "'num_unpadded_steps'", "]", "#.get('num_unpadded_steps', 0)", "\n", "", "", "print", "(", "'act took : '", ",", "zz2", "-", "zz1", ",", "' learn took : '", ",", "time", ".", "time", "(", ")", "-", "zz2", ")", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Batch and learn: %s\"", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "for", "m", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_learner_threads", ")", ":", "\n", "        ", "thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "batch_and_learn", ",", "name", "=", "\"batch-and-learn-%d\"", "%", "i", ",", "args", "=", "(", "i", ",", ")", "\n", ")", "\n", "thread", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "thread", ")", "\n", "\n", "", "logging", ".", "debug", "(", "'FINSIHED starting batchand learn'", ")", "\n", "def", "checkpoint", "(", ")", ":", "\n", "        ", "if", "flags", ".", "disable_checkpoint", ":", "\n", "            ", "return", "\n", "", "logging", ".", "info", "(", "\"Saving checkpoint to %s\"", ",", "checkpointpath", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"flags\"", ":", "vars", "(", "flags", ")", ",", "\n", "}", ",", "\n", "checkpointpath", ",", "\n", ")", "\n", "\n", "", "timer", "=", "timeit", ".", "default_timer", "\n", "try", ":", "\n", "        ", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "logging", ".", "debug", "(", "'initialized stats_eposiodes'", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "start_step", "=", "step", "\n", "start_time", "=", "timer", "(", ")", "\n", "time", ".", "sleep", "(", "flags", ".", "sleep_length", ")", "\n", "\n", "if", "timer", "(", ")", "-", "last_checkpoint_time", ">", "10", "*", "60", ":", "# Save every 10 min.", "\n", "                ", "checkpoint", "(", ")", "\n", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "\n", "", "sps", "=", "(", "step", "-", "start_step", ")", "/", "(", "timer", "(", ")", "-", "start_time", ")", "\n", "episode_returns", "=", "stats", ".", "get", "(", "\"episode_returns\"", ",", "None", ")", "\n", "if", "episode_returns", ":", "\n", "                ", "mean_return", "=", "(", "\n", "\"Return per episode: %.1f. \"", "%", "stats", "[", "\"mean_episode_return\"", "]", "\n", ")", "\n", "# print(episode_returns)", "\n", "# print(type(episode_returns[0]))", "\n", "# torch.save(episode_returns, './ep_return.pt')", "\n", "", "else", ":", "\n", "                ", "mean_return", "=", "\"\"", "\n", "", "total_loss", "=", "stats", ".", "get", "(", "\"total_loss\"", ",", "float", "(", "\"inf\"", ")", ")", "\n", "# TODO : We also should save the model if the loss is the best loss seen so far", "\n", "# TODO : call checkpoint() here with some differen prefix", "\n", "# if not best_val_loss or val_loss < best_val_loss:", "\n", "#     if not args.debug:", "\n", "#         with open(os.path.join(args.work_dir, 'model.pt'), 'wb') as f:", "\n", "#             torch.save(model, f)", "\n", "#         with open(os.path.join(args.work_dir, 'optimizer.pt'), 'wb') as f:", "\n", "#             torch.save(optimizer.state_dict(), f)", "\n", "#     best_val_loss = val_loss", "\n", "\n", "logging", ".", "info", "(", "\n", "\"Steps %i @ %.1f SPS. Loss %f. %sStats:\\n%s\"", ",", "\n", "step", ",", "\n", "sps", ",", "\n", "total_loss", ",", "\n", "mean_return", ",", "\n", "pprint", ".", "pformat", "(", "stats", ")", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "return", "# Try joining actors then quit.", "\n", "", "else", ":", "\n", "        ", "for", "thread", "in", "threads", ":", "\n", "            ", "thread", ".", "join", "(", ")", "\n", "", "logging", ".", "info", "(", "\"Learning finished after %d steps.\"", ",", "step", ")", "\n", "", "finally", ":", "\n", "        ", "for", "_", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "            ", "free_queue", ".", "put", "(", "None", ")", "\n", "", "for", "actor", "in", "actor_processes", ":", "\n", "            ", "actor", ".", "join", "(", "timeout", "=", "1", ")", "\n", "\n", "", "", "checkpoint", "(", ")", "\n", "plogger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.test": [[979, 1027], ["train.create_env", "Net.eval", "torch.load", "Net.load_state_dict", "dmlab_environment.Environment.initial", "dmlab_environment.Environment.close", "logging.info", "os.path.expandvars", "Model.core.environment.Environment", "torchbeast.core.environment.Environment", "Net", "Net", "Net.core.initial_cache", "len", "Net.", "dmlab_environment.Environment.step", "observation[].item", "os.path.expanduser", "len", "dmlab_environment.Environment.gym_env.render", "returns.append", "logging.info", "sum", "len", "dmlab_environment.Environment.initial", "observation[].item", "observation[].item", "observation[].item"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.initial_cache", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial"], ["", "def", "test", "(", "flags", ",", "num_episodes", ":", "int", "=", "10", ")", ":", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "checkpointpath", "=", "\"./latest/model.tar\"", "\n", "", "else", ":", "\n", "        ", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "if", "flags", ".", "atari", ":", "\n", "        ", "env", "=", "atari_environment", ".", "Environment", "(", "gym_env", ")", "\n", "", "else", ":", "\n", "#DMLAB CHANGES", "\n", "        ", "env", "=", "dmlab_environment", ".", "Environment", "(", "gym_env", ")", "\n", "\n", "", "if", "flags", ".", "atari", ":", "\n", "        ", "model", "=", "Net", "(", "env", ".", "gym_env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ",", "flags", "=", "flags", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "Net", "(", "env", ".", "initial", "(", ")", ".", "shape", ",", "len", "(", "dmlab_environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", "=", "flags", ")", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpointpath", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "\n", "observation", "=", "env", ".", "initial", "(", ")", "\n", "returns", "=", "[", "]", "\n", "\n", "mems", "=", "None", "\n", "if", "flags", ".", "use_adaptive", ":", "\n", "        ", "mems", "=", "model", ".", "core", ".", "initial_cache", "(", "batch_size", "=", "1", ",", "device", "=", "None", ")", "\n", "\n", "", "while", "len", "(", "returns", ")", "<", "num_episodes", ":", "\n", "        ", "if", "flags", ".", "mode", "==", "\"test_render\"", ":", "\n", "            ", "env", ".", "gym_env", ".", "render", "(", ")", "\n", "\n", "", "agent_outputs", ",", "core_state", ",", "mems", ",", "_", ",", "ind_first_done", "=", "model", "(", "observation", ",", "mems", "=", "mems", ")", "\n", "\n", "observation", "=", "env", ".", "step", "(", "agent_outputs", "[", "\"action\"", "]", ")", "\n", "if", "observation", "[", "\"done\"", "]", ".", "item", "(", ")", ":", "\n", "            ", "returns", ".", "append", "(", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Episode ended after %d steps. Return: %.1f\"", ",", "\n", "observation", "[", "\"episode_step\"", "]", ".", "item", "(", ")", ",", "\n", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Average returns over %i steps: %.1f\"", ",", "num_episodes", ",", "sum", "(", "returns", ")", "/", "len", "(", "returns", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.init_weight": [[1030, 1035], ["torch.nn.init.normal_"], "function", ["None"], ["", "def", "init_weight", "(", "weight", ")", ":", "\n", "# if args.init == 'uniform':", "\n", "#    nn.init.uniform_(weight, -args.init_range, args.init_range)", "\n", "# elif args.init == 'normal':", "\n", "    ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "0.02", ")", "# args.init_std)", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.init_bias": [[1037, 1039], ["torch.nn.init.constant_"], "function", ["None"], ["", "def", "init_bias", "(", "bias", ")", ":", "\n", "    ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.weights_init": [[1041, 1080], ["classname.find", "hasattr", "train.init_weight", "hasattr", "train.init_bias", "classname.find", "hasattr", "range", "classname.find", "hasattr", "len", "train.init_weight", "classname.find", "hasattr", "torch.nn.init.normal_", "hasattr", "train.init_weight", "hasattr", "train.init_bias", "range", "classname.find", "hasattr", "len", "torch.nn.init.normal_", "hasattr", "train.init_bias", "classname.find", "hasattr", "hasattr", "hasattr", "hasattr", "torch.nn.init.normal_", "train.init_weight", "train.init_weight", "train.init_weight", "train.init_bias"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias"], ["", "def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "            ", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'AdaptiveEmbedding'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'emb_projs'", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "0.01", ")", "# args.proj_init_std)", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'Embedding'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'ProjectedAdaptiveLogSoftmax'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'cluster_weight'", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "            ", "init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'cluster_bias'", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'out_projs'", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "0.01", ")", "# args.proj_init_std)", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'LayerNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "0.02", ")", "# args.init_std)", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'TransformerLM'", ")", "!=", "-", "1", ":", "\n", "# print('FOUND TRNASFORMER LM')", "\n", "        ", "if", "hasattr", "(", "m", ",", "'r_emb'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_w_bias'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_r_bias'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_bias'", ")", ":", "\n", "            ", "init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.create_env": [[1309, 1328], ["dmlab_wrappers.createDmLab", "Model.atari_wrappers.wrap_pytorch", "Model.atari_wrappers.wrap_deepmind", "Model.atari_wrappers.make_atari"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_pytorch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.make_atari"], ["def", "create_env", "(", "flags", ",", "seed", "=", "1", ")", ":", "\n", "\n", "    ", "if", "flags", ".", "atari", ":", "\n", "        ", "return", "atari_wrappers", ".", "wrap_pytorch", "(", "\n", "atari_wrappers", ".", "wrap_deepmind", "(", "\n", "atari_wrappers", ".", "make_atari", "(", "flags", ".", "env", ")", ",", "\n", "clip_rewards", "=", "False", ",", "\n", "frame_stack", "=", "True", ",", "\n", "scale", "=", "False", ",", "\n", ")", "\n", ")", "\n", "\n", "", "level_name", "=", "'contributed/dmlab30/'", "+", "flags", ".", "level_name", "\n", "config", "=", "{", "\n", "'width'", ":", "96", ",", "\n", "'height'", ":", "72", ",", "\n", "'logLevel'", ":", "'WARN'", ",", "\n", "}", "\n", "return", "dmlab_wrappers", ".", "createDmLab", "(", "level_name", ",", "config", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.get_model_parameters": [[1330, 1338], ["list", "model.parameters", "list", "layer.size"], "function", ["None"], ["", "def", "get_model_parameters", "(", "model", ")", ":", "\n", "    ", "total_parameters", "=", "0", "\n", "for", "layer", "in", "list", "(", "model", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "layer_parameter", "=", "1", "\n", "for", "l", "in", "list", "(", "layer", ".", "size", "(", ")", ")", ":", "\n", "            ", "layer_parameter", "*=", "l", "\n", "", "total_parameters", "+=", "layer_parameter", "\n", "", "return", "total_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.train.main": [[1340, 1345], ["train.train", "train.test"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.test"], ["", "def", "main", "(", "flags", ")", ":", "\n", "    ", "if", "flags", ".", "mode", "==", "\"train\"", ":", "\n", "        ", "train", "(", "flags", ")", "\n", "", "else", ":", "\n", "        ", "test", "(", "flags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.AtariNet.__init__": [[814, 889], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear", "StableTransformersReplication.transformer_xl.MemTransformerLM", "old_monobeast_test.AtariNet.core.apply", "torch.nn.Linear", "torch.nn.Linear", "feats_convs.append", "feats_convs.append", "old_monobeast_test.AtariNet.feat_convs.append", "range", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "torch.nn.Sequential", "resnet_block.append", "resnet_block.append", "resnet_block.append", "resnet_block.append", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "old_monobeast_test.AtariNet.resnet1.append", "old_monobeast_test.AtariNet.resnet2.append", "torch.nn.Sequential", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "observation_shape", ",", "num_actions", ")", ":", "\n", "        ", "super", "(", "AtariNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "observation_shape", "=", "observation_shape", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "\n", "self", ".", "feat_convs", "=", "[", "]", "\n", "self", ".", "resnet1", "=", "[", "]", "\n", "self", ".", "resnet2", "=", "[", "]", "\n", "\n", "self", ".", "convs", "=", "[", "]", "\n", "input_channels", "=", "self", ".", "observation_shape", "[", "0", "]", "\n", "for", "num_ch", "in", "[", "16", ",", "32", ",", "32", "]", ":", "\n", "            ", "feats_convs", "=", "[", "]", "\n", "feats_convs", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "feats_convs", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "self", ".", "feat_convs", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "feats_convs", ")", ")", "\n", "\n", "input_channels", "=", "num_ch", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "                ", "resnet_block", "=", "[", "]", "\n", "resnet_block", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "resnet_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "resnet_block", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "resnet_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "self", ".", "resnet1", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "resnet_block", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "resnet2", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "resnet_block", ")", ")", "\n", "\n", "", "", "", "self", ".", "feat_convs", "=", "nn", ".", "ModuleList", "(", "self", ".", "feat_convs", ")", "\n", "self", ".", "resnet1", "=", "nn", ".", "ModuleList", "(", "self", ".", "resnet1", ")", "\n", "self", ".", "resnet2", "=", "nn", ".", "ModuleList", "(", "self", ".", "resnet2", ")", "\n", "\n", "# Fully connected layer.", "\n", "# Changed the FC output to match the transformer output which should be divisible by number of heads", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3872", ",", "256", "-", "num_actions", "-", "1", ")", "\n", "\n", "# FC output size + one-hot of last action + last reward.", "\n", "core_output_size", "=", "self", ".", "fc", ".", "out_features", "+", "num_actions", "+", "1", "\n", "###############################################################transformer", "\n", "# TODO : 1st replacement, sanity check the parameters", "\n", "# TODO : play around with d_inner, this is the dimension for positionwise feedforward hidden projection", "\n", "# TODO : Change the n_layer=1 to 12", "\n", "self", ".", "core", "=", "MemTransformerLM", "(", "n_token", "=", "None", ",", "n_layer", "=", "1", ",", "n_head", "=", "8", ",", "d_head", "=", "core_output_size", "//", "8", ",", "\n", "d_model", "=", "core_output_size", ",", "d_inner", "=", "2048", ",", "\n", "dropout", "=", "0.1", ",", "dropatt", "=", "0.0", ",", "tgt_len", "=", "512", ",", "mem_len", "=", "1", ",", "ext_len", "=", "0", ",", "\n", "use_stable_version", "=", "True", ",", "use_gate", "=", "False", ")", "\n", "self", ".", "core", ".", "apply", "(", "weights_init", ")", "\n", "self", ".", "policy", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "baseline", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.AtariNet.initial_state": [[890, 897], ["tuple", "torch.zeros", "range"], "methods", ["None"], ["", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "# if not self.use_lstm:", "\n", "#     return tuple()", "\n", "        ", "return", "tuple", "(", "\n", "# torch.zeros(self.core.num_layers, batch_size, self.core.hidden_size)", "\n", "torch", ".", "zeros", "(", "self", ".", "core", ".", "n_layer", ",", "batch_size", ",", "self", ".", "core", ".", "d_model", ")", "\n", "for", "_", "in", "range", "(", "2", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.AtariNet.forward": [[899, 978], ["torch.flatten", "enumerate", "torch.nn.functional.relu", "fconv.view", "torch.nn.functional.relu", "torch.nn.functional.one_hot().float", "torch.clamp().view", "torch.cat", "core_input.view.view.view", "padding_mask.unsqueeze.unsqueeze.unsqueeze", "old_monobeast_test.AtariNet.core", "old_monobeast_test.AtariNet.policy", "old_monobeast_test.AtariNet.baseline", "policy_logits.view.view.reshape", "policy_logits.view.view.view", "baseline.view.view.view", "torch.argmax.view", "fconv.float", "fconv", "old_monobeast_test.AtariNet.fc", "padding_mask.unsqueeze.unsqueeze.dim", "padding_mask.unsqueeze.unsqueeze.any().item", "torch.multinomial", "torch.argmax", "dict", "torch.nn.functional.one_hot", "torch.clamp", "padding_mask.unsqueeze.unsqueeze.long().argmin", "torch.nn.functional.softmax", "inputs[].view", "padding_mask.unsqueeze.unsqueeze.any", "padding_mask.unsqueeze.unsqueeze.long", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "core_state", "=", "(", ")", ",", "mems", "=", "None", ",", "mem_padding", "=", "None", ")", ":", "\n", "\n", "        ", "x", "=", "inputs", "[", "\"frame\"", "]", "\n", "T", ",", "B", ",", "*", "_", "=", "x", ".", "shape", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "0", ",", "1", ")", "# Merge time and batch.", "\n", "x", "=", "x", ".", "float", "(", ")", "/", "255.0", "\n", "\n", "for", "i", ",", "fconv", "in", "enumerate", "(", "self", ".", "feat_convs", ")", ":", "\n", "            ", "x", "=", "fconv", "(", "x", ")", "\n", "res_input", "=", "x", "\n", "x", "=", "self", ".", "resnet1", "[", "i", "]", "(", "x", ")", "\n", "x", "+=", "res_input", "\n", "res_input", "=", "x", "\n", "x", "=", "self", ".", "resnet2", "[", "i", "]", "(", "x", ")", "\n", "x", "+=", "res_input", "\n", "", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n", "one_hot_last_action", "=", "F", ".", "one_hot", "(", "\n", "inputs", "[", "\"last_action\"", "]", ".", "view", "(", "T", "*", "B", ")", ",", "self", ".", "num_actions", "\n", ")", ".", "float", "(", ")", "\n", "\n", "clipped_reward", "=", "torch", ".", "clamp", "(", "inputs", "[", "\"reward\"", "]", ",", "-", "1", ",", "1", ")", ".", "view", "(", "T", "*", "B", ",", "1", ")", "\n", "core_input", "=", "torch", ".", "cat", "(", "[", "x", ",", "clipped_reward", ",", "one_hot_last_action", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "core_input", "=", "core_input", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "\n", "\n", "padding_mask", "=", "inputs", "[", "'done'", "]", "\n", "ind_first_done", "=", "None", "\n", "if", "padding_mask", ".", "dim", "(", ")", ">", "1", ":", "# This only seems to not happen on first state ever in env.initialize()", "\n", "            ", "ind_first_done", "=", "padding_mask", ".", "long", "(", ")", ".", "argmin", "(", "0", ")", "+", "1", "# will be index of first 1 in each column", "\n", "ind_first_done", "[", "ind_first_done", ">=", "padding_mask", ".", "shape", "[", "0", "]", "]", "=", "-", "1", "# choosing -1 helps in learn function", "\n", "padding_mask", "[", "ind_first_done", ",", "range", "(", "B", ")", "]", "=", "False", "\n", "# print('ALL IS FALSE: {}, shape: {}'.format(padding_mask.any().item(), padding_mask.shape ))", "\n", "\n", "", "padding_mask", "=", "padding_mask", ".", "unsqueeze", "(", "0", ")", "\n", "if", "not", "padding_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "# In this case no need for padding_mask", "\n", "            ", "padding_mask", "=", "None", "\n", "\n", "", "core_output", ",", "mems", "=", "self", ".", "core", "(", "core_input", ",", "mems", ",", "padding_mask", "=", "padding_mask", ",", "\n", "mem_padding", "=", "mem_padding", ")", "# core_input is of shape (T, B, ...)", "\n", "# core_output is (B, ...)", "\n", "\n", "policy_logits", "=", "self", ".", "policy", "(", "core_output", ")", "\n", "baseline", "=", "self", ".", "baseline", "(", "core_output", ")", "\n", "\n", "policy_logits", "=", "policy_logits", ".", "reshape", "(", "T", "*", "B", ",", "self", ".", "num_actions", ")", "\n", "# # if policy_logits.shape[0] == 32 and policy_logits.shape[1] == 6:", "\n", "# if not torch.all(policy_logits == policy_logits).item():", "\n", "#     # nans only come when the learner_model calls this forward", "\n", "#     print('from monobeast 921\\n', policy_logits)", "\n", "#     print('core output : ',core_output.shape, '\\n', core_output)", "\n", "#     print('core input : \\n', core_input)", "\n", "#     print('mask : \\n', padding_mask)", "\n", "#     print('mems : \\n', mems)", "\n", "#     torch.save(core_input, './core_input.pt')", "\n", "#     torch.save(padding_mask, './padding_mask.pt')", "\n", "#     torch.save(mems, './mems.pt')", "\n", "\n", "if", "self", ".", "training", ":", "\n", "# Sample from multinomial distribution for exploration", "\n", "# if not (padding_mask is None) and padding_mask.shape[1] > 1:", "\n", "#     print('Padding shape: {}, logits shape: {}'.format(padding_mask.shape, policy_logits.shape))", "\n", "#     print('PADDING: ', padding_mask)", "\n", "#     print(\"LOGITS: \", policy_logits)", "\n", "            ", "action", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "policy_logits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "# Don't sample when testing.", "\n", "            ", "action", "=", "torch", ".", "argmax", "(", "policy_logits", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_logits", "=", "policy_logits", ".", "view", "(", "T", ",", "B", ",", "self", ".", "num_actions", ")", "\n", "baseline", "=", "baseline", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "action", "=", "action", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "return", "(", "\n", "dict", "(", "policy_logits", "=", "policy_logits", ",", "baseline", "=", "baseline", ",", "action", "=", "action", ")", ",", "\n", "core_state", ",", "mems", ",", "padding_mask", ",", "ind_first_done", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.compute_baseline_loss": [[135, 139], ["torch.sum"], "function", ["None"], ["def", "compute_baseline_loss", "(", "advantages", ",", "padding_mask", ")", ":", "\n", "    ", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "advantages", "=", "advantages", "*", "padding_mask", "\n", "", "return", "0.5", "*", "torch", ".", "sum", "(", "advantages", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.compute_entropy_loss": [[142, 153], ["torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.sum", "padding_mask.unsqueeze"], "function", ["None"], ["", "def", "compute_entropy_loss", "(", "logits", ",", "padding_mask", ")", ":", "\n", "    ", "\"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"", "\n", "policy", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "log_policy", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "# print('log_policyshape: ', log_policy.shape)", "\n", "# print('padding mask: ', padding_mask.shape)", "\n", "        ", "log_policy", "=", "log_policy", "*", "padding_mask", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "", "return", "torch", ".", "sum", "(", "policy", "*", "log_policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.compute_policy_gradient_loss": [[155, 165], ["torch.nn.functional.nll_loss", "cross_entropy.view_as.view_as", "torch.sum", "torch.nn.functional.log_softmax", "torch.flatten", "torch.flatten", "advantages.detach"], "function", ["None"], ["", "def", "compute_policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ",", "padding_mask", ")", ":", "\n", "    ", "cross_entropy", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "logits", ",", "0", ",", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "torch", ".", "flatten", "(", "actions", ",", "0", ",", "1", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", "\n", "cross_entropy", "=", "cross_entropy", ".", "view_as", "(", "advantages", ")", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "cross_entropy", "=", "cross_entropy", "*", "padding_mask", "\n", "", "return", "torch", ".", "sum", "(", "cross_entropy", "*", "advantages", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.act": [[167, 256], ["logging.info", "Model.core.prof.Timings", "old_monobeast_test.create_env", "create_env.seed", "Model.core.environment.Environment", "environment.Environment.initial", "model.initial_state", "model", "int.from_bytes", "free_queue.get", "enumerate", "env_output[].item", "full_queue.put", "logging.info", "logging.error", "traceback.print_exc", "os.urandom", "prof.Timings.reset", "prof.Timings.time", "environment.Environment.step", "prof.Timings.time", "prof.Timings.time", "environment.Environment.step", "torch.tensor().repeat", "prof.Timings.summary", "env_output[].item", "torch.no_grad", "model", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary"], ["", "def", "act", "(", "\n", "flags", ",", "\n", "actor_index", ":", "int", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"Actor %i started.\"", ",", "actor_index", ")", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "# Keep track of how fast things are.", "\n", "\n", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "seed", "=", "actor_index", "^", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "4", ")", ",", "byteorder", "=", "\"little\"", ")", "\n", "gym_env", ".", "seed", "(", "seed", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "env_output", "=", "env", ".", "initial", "(", ")", "\n", "\n", "agent_state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "mems", ",", "mem_padding", "=", "None", ",", "None", "\n", "agent_output", ",", "unused_state", ",", "mems", ",", "mem_padding", ",", "_", "=", "model", "(", "env_output", ",", "agent_state", ",", "mems", ",", "mem_padding", ")", "\n", "while", "True", ":", "\n", "            ", "index", "=", "free_queue", ".", "get", "(", ")", "\n", "if", "index", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "# explicitly make done False to allow the loop to run", "\n", "# Don't need to set 'done' to true since now take step out of done state", "\n", "# when do arrive at 'done'", "\n", "# env_output['done'] = torch.tensor([0], dtype=torch.uint8)", "\n", "\n", "# Write old rollout end.", "\n", "", "for", "key", "in", "env_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "agent_state", ")", ":", "\n", "                ", "initial_agent_state_buffers", "[", "index", "]", "[", "i", "]", "[", "...", "]", "=", "tensor", "\n", "\n", "# Do one new rollout, untill flags.unroll_length", "\n", "", "t", "=", "0", "\n", "while", "t", "<", "flags", ".", "unroll_length", "and", "not", "env_output", "[", "'done'", "]", ".", "item", "(", ")", ":", "\n", "# for t in range(flags.unroll_length):", "\n", "                ", "timings", ".", "reset", "(", ")", "\n", "\n", "# REmoved since never this will never be true (MOVED TO AFTER FOR LOOP)", "\n", "# if env_output['done'].item():", "\n", "#    mems = None", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "agent_output", ",", "agent_state", ",", "mems", ",", "mem_padding", ",", "_", "=", "model", "(", "env_output", ",", "agent_state", ",", "mems", ",", "mem_padding", ")", "\n", "\n", "", "timings", ".", "time", "(", "\"model\"", ")", "\n", "\n", "# TODO: Shakti add action repeat?", "\n", "env_output", "=", "env", ".", "step", "(", "agent_output", "[", "\"action\"", "]", ")", "\n", "\n", "timings", ".", "time", "(", "\"step\"", ")", "\n", "\n", "for", "key", "in", "env_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "\n", "", "timings", ".", "time", "(", "\"write\"", ")", "\n", "t", "+=", "1", "\n", "\n", "", "if", "env_output", "[", "'done'", "]", ".", "item", "(", ")", ":", "\n", "                ", "mems", "=", "None", "\n", "# Take arbitrary step to reset environment", "\n", "env_output", "=", "env", ".", "step", "(", "torch", ".", "tensor", "(", "[", "2", "]", ")", ")", "\n", "\n", "", "if", "t", "!=", "flags", ".", "unroll_length", ":", "\n", "# TODO I checked and seems good but Shakti can you check as well?", "\n", "                ", "buffers", "[", "'done'", "]", "[", "index", "]", "[", "t", "+", "1", ":", "]", "=", "torch", ".", "tensor", "(", "[", "True", "]", ")", ".", "repeat", "(", "flags", ".", "unroll_length", "-", "t", ")", "\n", "\n", "", "full_queue", ".", "put", "(", "index", ")", "\n", "\n", "", "if", "actor_index", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Actor %i: %s\"", ",", "actor_index", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# Return silently.", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logging", ".", "error", "(", "\"Exception in worker process %i\"", ",", "actor_index", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "# print()", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.get_batch": [[258, 288], ["threading.Lock", "timings.time", "timings.time", "tuple", "timings.time", "timings.time", "timings.time", "torch.stack", "torch.cat", "free_queue.put", "t.to", "full_queue.get", "zip", "batch.items", "t.to", "range"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["", "", "def", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "\n", ")", ":", "\n", "    ", "with", "lock", ":", "\n", "        ", "timings", ".", "time", "(", "\"lock\"", ")", "\n", "indices", "=", "[", "full_queue", ".", "get", "(", ")", "for", "_", "in", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "timings", ".", "time", "(", "\"dequeue\"", ")", "\n", "", "batch", "=", "{", "\n", "key", ":", "torch", ".", "stack", "(", "[", "buffers", "[", "key", "]", "[", "m", "]", "for", "m", "in", "indices", "]", ",", "dim", "=", "1", ")", "for", "key", "in", "buffers", "\n", "}", "\n", "initial_agent_state", "=", "(", "\n", "torch", ".", "cat", "(", "ts", ",", "dim", "=", "1", ")", "\n", "for", "ts", "in", "zip", "(", "*", "[", "initial_agent_state_buffers", "[", "m", "]", "for", "m", "in", "indices", "]", ")", "\n", ")", "\n", "timings", ".", "time", "(", "\"batch\"", ")", "\n", "for", "m", "in", "indices", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "", "timings", ".", "time", "(", "\"enqueue\"", ")", "\n", "batch", "=", "{", "k", ":", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "k", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "initial_agent_state", "=", "tuple", "(", "\n", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "t", "in", "initial_agent_state", "\n", ")", "\n", "timings", ".", "time", "(", "\"device\"", ")", "\n", "return", "batch", ",", "initial_agent_state", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.learn": [[290, 401], ["threading.Lock", "model", "Model.core.vtrace.from_logits", "old_monobeast_test.compute_policy_gradient_loss", "optimizer.zero_grad", "total_loss.backward", "optimizer.step", "actor_model.load_state_dict", "torch.clamp", "old_monobeast_test.compute_baseline_loss", "old_monobeast_test.compute_entropy_loss", "tuple", "torch.mean().item", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "optimizer.clip_master_grads", "torch.nn.utils.clip_grad_norm_", "model.state_dict", "batch.items", "learner_outputs.items", "episode_returns.cpu().numpy", "model.parameters", "torch.mean", "range", "episode_returns.cpu", "mem_padding.squeeze"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict"], ["", "def", "learn", "(", "\n", "flags", ",", "\n", "actor_model", ",", "\n", "model", ",", "\n", "batch", ",", "\n", "initial_agent_state", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "# noqa: B008", "\n", ")", ":", "\n", "    ", "\"\"\"Performs a learning (optimization) step.\"\"\"", "\n", "with", "lock", ":", "\n", "        ", "\"\"\"\n        put a lock on the central learner,\n        send the trajectories to it.\n        Update the parameters of the central learner,\n        copy the parameters of the central learner back to the actors\n        \"\"\"", "\n", "# print('RUNNING MAIN MODEL')", "\n", "# print('MODEL OUTOUT: ', model(batch, initial_agent_state))", "\n", "# print('batch size : ', batch['frame'].size())", "\n", "\n", "# TODO Next Step: think about chopping the sequences up for attending to long sequences", "\n", "# TODO Next Step: make the actors put only one sequence in one rollout. And then mask the remaining rollout", "\n", "#       positions. And then change the triu in line 461 in TXL", "\n", "# Here entire 81 length sequence is considered as a query, and is autoregressively being attended to the", "\n", "# keys and values of length 81. This sequence length when becomes very large is when we'll need memory to", "\n", "# kick in", "\n", "learner_outputs", ",", "unused_state", ",", "unused_mems", ",", "mem_padding", ",", "ind_first_done", "=", "model", "(", "batch", ",", "initial_agent_state", ",", "\n", "mems", "=", "None", ",", "mem_padding", "=", "None", ")", "\n", "# Here mem_padding is same as \"batch\" padding for this iteration so can use", "\n", "# for masking loss", "\n", "\n", "# Take final value function slice for bootstrapping.", "\n", "# this is the final value from this trajectory", "\n", "if", "ind_first_done", "is", "not", "None", ":", "\n", "# B dimensional tensor", "\n", "            ", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "ind_first_done", ",", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "", "else", ":", "\n", "            ", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "-", "1", "]", "\n", "\n", "# Move from obs[t] -> action[t] to action[t] -> obs[t].", "\n", "", "batch", "=", "{", "key", ":", "tensor", "[", "1", ":", "]", "for", "key", ",", "tensor", "in", "batch", ".", "items", "(", ")", "}", "\n", "learner_outputs", "=", "{", "key", ":", "tensor", "[", ":", "-", "1", "]", "for", "key", ",", "tensor", "in", "learner_outputs", ".", "items", "(", ")", "}", "\n", "\n", "# Using learner_outputs to predict batch since batch is always one ahead of learner_outputs?", "\n", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "\n", "if", "flags", ".", "reward_clipping", "==", "\"abs_one\"", ":", "\n", "            ", "clipped_rewards", "=", "torch", ".", "clamp", "(", "rewards", ",", "-", "1", ",", "1", ")", "\n", "", "elif", "flags", ".", "reward_clipping", "==", "\"none\"", ":", "\n", "            ", "clipped_rewards", "=", "rewards", "\n", "\n", "", "discounts", "=", "(", "~", "batch", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "*", "flags", ".", "discounting", "\n", "\n", "vtrace_returns", "=", "vtrace", ".", "from_logits", "(", "\n", "behavior_policy_logits", "=", "batch", "[", "\"policy_logits\"", "]", ",", "\n", "target_policy_logits", "=", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "# WHY IS THIS THE TARGET?", "\n", "actions", "=", "batch", "[", "\"action\"", "]", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "clipped_rewards", ",", "\n", "values", "=", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", ")", "\n", "\n", "# TODO Next Step: the losses also have to be computed with the padding, think on a structure of mask", "\n", "#                   to do this efficiently", "\n", "# Advantages are [rollout_len, batch_size]", "\n", "\n", "# First we mask out vtrace_returns.pg_advantages where there is padding which fixes pg_loss", "\n", "pad_mask", "=", "(", "~", "(", "mem_padding", ".", "squeeze", "(", "0", ")", "[", "1", ":", "]", ")", ")", ".", "float", "(", ")", "if", "mem_padding", "is", "not", "None", "else", "None", "\n", "\n", "pg_loss", "=", "compute_policy_gradient_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "batch", "[", "\"action\"", "]", ",", "\n", "vtrace_returns", ".", "pg_advantages", ",", "\n", "pad_mask", "\n", ")", "\n", "baseline_loss", "=", "flags", ".", "baseline_cost", "*", "compute_baseline_loss", "(", "\n", "vtrace_returns", ".", "vs", "-", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "pad_mask", "\n", ")", "\n", "entropy_loss", "=", "flags", ".", "entropy_cost", "*", "compute_entropy_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "pad_mask", "\n", ")", "\n", "\n", "total_loss", "=", "pg_loss", "+", "baseline_loss", "+", "entropy_loss", "\n", "\n", "episode_returns", "=", "batch", "[", "\"episode_return\"", "]", "[", "batch", "[", "\"done\"", "]", "]", "\n", "stats", "=", "{", "\n", "\"episode_returns\"", ":", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "\"mean_episode_return\"", ":", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ",", "\n", "\"total_loss\"", ":", "total_loss", ".", "item", "(", ")", ",", "\n", "\"pg_loss\"", ":", "pg_loss", ".", "item", "(", ")", ",", "\n", "\"baseline_loss\"", ":", "baseline_loss", ".", "item", "(", ")", ",", "\n", "\"entropy_loss\"", ":", "entropy_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "if", "flags", ".", "fp16", ":", "\n", "            ", "optimizer", ".", "clip_master_grads", "(", "flags", ".", "grad_norm_clipping", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "flags", ".", "grad_norm_clipping", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "# scheduler is being stepped in the lock of batch_and_learn itself", "\n", "# scheduler.step()", "\n", "\n", "actor_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.create_buffers": [[403, 421], ["dict", "range", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "buffers[].append", "torch.empty().share_memory_", "torch.empty"], "function", ["None"], ["", "", "def", "create_buffers", "(", "flags", ",", "obs_shape", ",", "num_actions", ")", "->", "Buffers", ":", "\n", "    ", "T", "=", "flags", ".", "unroll_length", "\n", "specs", "=", "dict", "(", "\n", "frame", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "*", "obs_shape", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "reward", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "done", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "\n", "episode_return", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "episode_step", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "policy_logits", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "num_actions", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "baseline", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "last_action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", ")", "\n", "buffers", ":", "Buffers", "=", "{", "key", ":", "[", "]", "for", "key", "in", "specs", "}", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "for", "key", "in", "buffers", ":", "\n", "            ", "buffers", "[", "key", "]", ".", "append", "(", "torch", ".", "empty", "(", "**", "specs", "[", "key", "]", ")", ".", "share_memory_", "(", ")", ")", "\n", "", "", "return", "buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.get_optimizer": [[423, 432], ["flags.optim.lower", "torch.optim.SGD", "flags.optim.lower", "torch.optim.Adam", "flags.optim.lower", "torch.optim.Adagrad"], "function", ["None"], ["", "def", "get_optimizer", "(", "flags", ",", "parameters", ")", ":", "\n", "    ", "optimizer", "=", "None", "\n", "if", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ",", "momentum", "=", "flags", ".", "momentum", ")", "\n", "", "elif", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ")", "\n", "", "elif", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'adagrad'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.get_scheduler": [[434, 461], ["torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.ReduceLROnPlateau"], "function", ["None"], ["", "def", "get_scheduler", "(", "flags", ",", "optimizer", ")", ":", "\n", "    ", "scheduler", "=", "None", "\n", "if", "flags", ".", "scheduler", "==", "'cosine'", ":", "\n", "# here we do not set eta_min to lr_min to be backward compatible", "\n", "# because in previous versions eta_min is default to 0", "\n", "# rather than the default value of lr_min 1e-6", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "\n", "flags", ".", "max_step", ",", "eta_min", "=", "flags", ".", "eta_min", ")", "\n", "", "elif", "flags", ".", "scheduler", "==", "'inv_sqrt'", ":", "\n", "# originally used for Transformer (in Attention is all you need)", "\n", "        ", "def", "lr_lambda", "(", "step", ")", ":", "\n", "# return a multiplier instead of a learning rate", "\n", "            ", "if", "step", "==", "0", "and", "flags", ".", "warmup_step", "==", "0", ":", "\n", "                ", "return", "1.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "/", "(", "step", "**", "0.5", ")", "if", "step", ">", "flags", ".", "warmup_step", "else", "step", "/", "(", "flags", ".", "warmup_step", "**", "1.5", ")", "\n", "\n", "", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lr_lambda", ")", "\n", "\n", "", "elif", "flags", ".", "scheduler", "==", "'dev_perf'", ":", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "\n", "factor", "=", "flags", ".", "decay_rate", ",", "patience", "=", "flags", ".", "patience", ",", "\n", "min_lr", "=", "flags", ".", "lr_min", ")", "\n", "", "elif", "flags", ".", "scheduler", "==", "'constant'", ":", "\n", "        ", "pass", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.train": [[463, 719], ["Model.core.file_writer.FileWriter", "os.path.expandvars", "old_monobeast_test.create_env", "Net", "old_monobeast_test.create_buffers", "Net.share_memory", "range", "torch.multiprocessing.get_context", "mp.get_context.SimpleQueue", "mp.get_context.SimpleQueue", "range", "Net().to", "old_monobeast_test.get_optimizer", "old_monobeast_test.get_scheduler", "logging.getLogger", "logging.getLogger.info", "range", "range", "old_monobeast_test.train.checkpoint"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_buffers", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_optimizer", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_scheduler", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.checkpoint"], ["", "def", "train", "(", "flags", ")", ":", "# pylint: disable=too-many-branches, too-many-statements", "\n", "\n", "# load the previous config if use_pretrained is true", "\n", "    ", "if", "flags", ".", "use_pretrained", ":", "\n", "        ", "logging", ".", "info", "(", "'Using Pretrained Model'", ")", "\n", "\n", "class", "Bunch", "(", "object", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "adict", ")", ":", "\n", "                ", "self", ".", "__dict__", ".", "update", "(", "adict", ")", "\n", "\n", "", "", "model_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "\n", "'logs/torchbeast/'", "+", "flags", ".", "xpid", "+", "'/model.tar'", ")", "\n", "pretrained_model", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "'cpu'", "if", "flags", ".", "disable_cuda", "else", "'gpu'", ")", "\n", "flags", "=", "Bunch", "(", "pretrained_model", "[", "'flags'", "]", ")", "\n", "flags", ".", "use_pretrained", "=", "True", "\n", "\n", "", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "flags", ".", "xpid", "=", "\"torchbeast-%s\"", "%", "time", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "", "plogger", "=", "file_writer", ".", "FileWriter", "(", "\n", "xpid", "=", "flags", ".", "xpid", ",", "xp_args", "=", "flags", ".", "__dict__", ",", "rootdir", "=", "flags", ".", "savedir", "\n", ")", "\n", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "if", "flags", ".", "num_buffers", "is", "None", ":", "# Set sensible default for num_buffers.", "\n", "        ", "flags", ".", "num_buffers", "=", "max", "(", "2", "*", "flags", ".", "num_actors", ",", "flags", ".", "batch_size", ")", "\n", "", "if", "flags", ".", "num_actors", ">=", "flags", ".", "num_buffers", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than num_actors\"", ")", "\n", "", "if", "flags", ".", "num_buffers", "<", "flags", ".", "batch_size", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than batch_size\"", ")", "\n", "\n", "", "T", "=", "flags", ".", "unroll_length", "\n", "B", "=", "flags", ".", "batch_size", "\n", "\n", "flags", ".", "device", "=", "None", "\n", "if", "not", "flags", ".", "disable_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Not using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "env", "=", "create_env", "(", "flags", ")", "\n", "\n", "\"\"\"model is each of the actors, running parallel. The upcoming block ctx.Process(...)\"\"\"", "\n", "model", "=", "Net", "(", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ")", "\n", "buffers", "=", "create_buffers", "(", "flags", ",", "env", ".", "observation_space", ".", "shape", ",", "model", ".", "num_actions", ")", "\n", "\n", "model", ".", "share_memory", "(", ")", "\n", "\n", "# Add initial RNN state.", "\n", "initial_agent_state_buffers", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "for", "t", "in", "state", ":", "\n", "            ", "t", ".", "share_memory_", "(", ")", "\n", "", "initial_agent_state_buffers", ".", "append", "(", "state", ")", "\n", "\n", "", "actor_processes", "=", "[", "]", "\n", "ctx", "=", "mp", ".", "get_context", "(", "\"fork\"", ")", "\n", "free_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "full_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "        ", "actor", "=", "ctx", ".", "Process", "(", "\n", "target", "=", "act", ",", "\n", "args", "=", "(", "\n", "flags", ",", "\n", "i", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "model", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ",", "\n", ")", "\n", "actor", ".", "start", "(", ")", "\n", "actor_processes", ".", "append", "(", "actor", ")", "\n", "\n", "", "\"\"\"learner_model is the central learner, which takes in the experiences and updates itself\"\"\"", "\n", "learner_model", "=", "Net", "(", "\n", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ")", ".", "to", "(", "device", "=", "flags", ".", "device", ")", "\n", "\n", "optimizer", "=", "get_optimizer", "(", "flags", ",", "learner_model", ".", "parameters", "(", ")", ")", "\n", "if", "optimizer", "is", "None", ":", "\n", "# Use the default optimizer used in monobeast", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "\n", "learner_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "flags", ".", "learning_rate", ",", "\n", "momentum", "=", "flags", ".", "momentum", ",", "\n", "eps", "=", "flags", ".", "epsilon", ",", "\n", "alpha", "=", "flags", ".", "alpha", ",", "\n", "weight_decay", "=", "flags", ".", "weight_decay", "\n", ")", "\n", "\n", "", "try", ":", "\n", "        ", "from", "apex", ".", "fp16_utils", "import", "FP16_Optimizer", "\n", "", "except", ":", "\n", "        ", "print", "(", "'WARNING: apex not installed, ignoring --fp16 option'", ")", "\n", "flags", ".", "fp16", "=", "False", "\n", "\n", "", "if", "not", "flags", ".", "disable_cuda", "and", "flags", ".", "fp16", ":", "\n", "# If args.dynamic_loss_scale is False, static_loss_scale will be used.", "\n", "# If args.dynamic_loss_scale is True, it will take precedence over static_loss_scale.", "\n", "        ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "\n", "static_loss_scale", "=", "flags", ".", "static_loss_scale", ",", "\n", "dynamic_loss_scale", "=", "flags", ".", "dynamic_loss_scale", ",", "\n", "dynamic_loss_args", "=", "{", "'init_scale'", ":", "2", "**", "16", "}", ")", "\n", "\n", "", "def", "lr_lambda", "(", "epoch", ")", ":", "\n", "        ", "return", "1", "-", "min", "(", "epoch", "*", "T", "*", "B", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "\n", "", "scheduler", "=", "get_scheduler", "(", "flags", ",", "optimizer", ")", "\n", "if", "scheduler", "is", "None", ":", "\n", "# use the default scheduler as used in monobeast", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ")", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "\"logfile\"", ")", "\n", "stat_keys", "=", "[", "\n", "\"total_loss\"", ",", "\n", "\"mean_episode_return\"", ",", "\n", "\"pg_loss\"", ",", "\n", "\"baseline_loss\"", ",", "\n", "\"entropy_loss\"", ",", "\n", "]", "\n", "logger", ".", "info", "(", "\"# Step\\t%s\"", ",", "\"\\t\"", ".", "join", "(", "stat_keys", ")", ")", "\n", "\n", "step", ",", "stats", "=", "0", ",", "{", "}", "\n", "\n", "if", "flags", ".", "use_pretrained", ":", "\n", "        ", "logging", ".", "info", "(", "'Using Pretrained Model -> loading learner_model, optimizer, scheduler states'", ")", "\n", "learner_model", ".", "load_state_dict", "(", "pretrained_model", "[", "'model_state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "pretrained_model", "[", "'optimizer_state_dict'", "]", ")", "\n", "scheduler", ".", "load_state_dict", "(", "pretrained_model", "[", "'scheduler_state_dict'", "]", ")", "\n", "\n", "", "def", "batch_and_learn", "(", "i", ",", "lock", "=", "threading", ".", "Lock", "(", ")", ")", ":", "\n", "        ", "\"\"\"Thread target for the learning process.\"\"\"", "\n", "nonlocal", "step", ",", "stats", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "timings", ".", "reset", "(", ")", "\n", "batch", ",", "agent_state", "=", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", ")", "\n", "# print('Before Learn')", "\n", "stats", "=", "learn", "(", "\n", "flags", ",", "model", ",", "learner_model", ",", "batch", ",", "agent_state", ",", "optimizer", ",", "scheduler", "\n", ")", "\n", "# print('After Learn')", "\n", "timings", ".", "time", "(", "\"learn\"", ")", "\n", "with", "lock", ":", "\n", "# step-wise learning rate annealing", "\n", "# TODO : How to perform annealing here exactly, we dont have access to the train_step !", "\n", "                ", "if", "flags", ".", "scheduler", "in", "[", "'cosine'", ",", "'constant'", ",", "'dev_perf'", "]", ":", "\n", "# linear warmup stage", "\n", "                    ", "if", "step", "<", "flags", ".", "warmup_step", ":", "\n", "                        ", "curr_lr", "=", "flags", ".", "lr", "*", "step", "/", "flags", ".", "warmup_step", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "curr_lr", "\n", "", "else", ":", "\n", "                        ", "if", "flags", ".", "scheduler", "==", "'cosine'", ":", "\n", "                            ", "scheduler", ".", "step", "(", ")", "\n", "", "", "", "elif", "flags", ".", "scheduler", "==", "'inv_sqrt'", ":", "\n", "                    ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "to_log", "=", "dict", "(", "step", "=", "step", ")", "\n", "to_log", ".", "update", "(", "{", "k", ":", "stats", "[", "k", "]", "for", "k", "in", "stat_keys", "}", ")", "\n", "plogger", ".", "log", "(", "to_log", ")", "\n", "# print('updating step from {} to {}'.format(step, step+(T*B)))", "\n", "step", "+=", "T", "*", "B", "\n", "\n", "", "", "if", "i", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Batch and learn: %s\"", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "for", "m", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_learner_threads", ")", ":", "\n", "        ", "thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "batch_and_learn", ",", "name", "=", "\"batch-and-learn-%d\"", "%", "i", ",", "args", "=", "(", "i", ",", ")", "\n", ")", "\n", "thread", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "thread", ")", "\n", "\n", "", "def", "checkpoint", "(", ")", ":", "\n", "        ", "if", "flags", ".", "disable_checkpoint", ":", "\n", "            ", "return", "\n", "", "logging", ".", "info", "(", "\"Saving checkpoint to %s\"", ",", "checkpointpath", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"flags\"", ":", "vars", "(", "flags", ")", ",", "\n", "}", ",", "\n", "checkpointpath", ",", "\n", ")", "\n", "\n", "", "timer", "=", "timeit", ".", "default_timer", "\n", "try", ":", "\n", "        ", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "start_step", "=", "step", "\n", "start_time", "=", "timer", "(", ")", "\n", "time", ".", "sleep", "(", "5", ")", "\n", "\n", "if", "timer", "(", ")", "-", "last_checkpoint_time", ">", "10", "*", "60", ":", "# Save every 10 min.", "\n", "                ", "checkpoint", "(", ")", "\n", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "\n", "", "sps", "=", "(", "step", "-", "start_step", ")", "/", "(", "timer", "(", ")", "-", "start_time", ")", "\n", "if", "stats", ".", "get", "(", "\"episode_returns\"", ",", "None", ")", ":", "\n", "                ", "mean_return", "=", "(", "\n", "\"Return per episode: %.1f. \"", "%", "stats", "[", "\"mean_episode_return\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "mean_return", "=", "\"\"", "\n", "", "total_loss", "=", "stats", ".", "get", "(", "\"total_loss\"", ",", "float", "(", "\"inf\"", ")", ")", "\n", "# TODO : We also should save the model if the loss is the best loss seen so far", "\n", "# TODO : call checkpoint() here with some differen prefix", "\n", "# if not best_val_loss or val_loss < best_val_loss:", "\n", "#     if not args.debug:", "\n", "#         with open(os.path.join(args.work_dir, 'model.pt'), 'wb') as f:", "\n", "#             torch.save(model, f)", "\n", "#         with open(os.path.join(args.work_dir, 'optimizer.pt'), 'wb') as f:", "\n", "#             torch.save(optimizer.state_dict(), f)", "\n", "#     best_val_loss = val_loss", "\n", "\n", "logging", ".", "info", "(", "\n", "\"Steps %i @ %.1f SPS. Loss %f. %sStats:\\n%s\"", ",", "\n", "step", ",", "\n", "sps", ",", "\n", "total_loss", ",", "\n", "mean_return", ",", "\n", "pprint", ".", "pformat", "(", "stats", ")", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "return", "# Try joining actors then quit.", "\n", "", "else", ":", "\n", "        ", "for", "thread", "in", "threads", ":", "\n", "            ", "thread", ".", "join", "(", ")", "\n", "", "logging", ".", "info", "(", "\"Learning finished after %d steps.\"", ",", "step", ")", "\n", "", "finally", ":", "\n", "        ", "for", "_", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "            ", "free_queue", ".", "put", "(", "None", ")", "\n", "", "for", "actor", "in", "actor_processes", ":", "\n", "            ", "actor", ".", "join", "(", "timeout", "=", "1", ")", "\n", "\n", "", "", "checkpoint", "(", ")", "\n", "plogger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.test": [[721, 758], ["old_monobeast_test.create_env", "Model.core.environment.Environment", "Net", "Net.eval", "torch.load", "Net.load_state_dict", "environment.Environment.initial", "environment.Environment.close", "logging.info", "os.path.expandvars", "len", "Net.", "environment.Environment.step", "observation[].item", "os.path.expanduser", "environment.Environment.gym_env.render", "returns.append", "logging.info", "sum", "len", "observation[].item", "observation[].item", "observation[].item"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "test", "(", "flags", ",", "num_episodes", ":", "int", "=", "10", ")", ":", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "checkpointpath", "=", "\"./latest/model.tar\"", "\n", "", "else", ":", "\n", "        ", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "model", "=", "Net", "(", "gym_env", ".", "observation_space", ".", "shape", ",", "gym_env", ".", "action_space", ".", "n", ")", "\n", "model", ".", "eval", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpointpath", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "\n", "observation", "=", "env", ".", "initial", "(", ")", "\n", "returns", "=", "[", "]", "\n", "\n", "mems", "=", "None", "\n", "mem_padding", "=", "None", "\n", "while", "len", "(", "returns", ")", "<", "num_episodes", ":", "\n", "        ", "if", "flags", ".", "mode", "==", "\"test_render\"", ":", "\n", "            ", "env", ".", "gym_env", ".", "render", "(", ")", "\n", "\n", "", "agent_outputs", ",", "core_state", ",", "mems", ",", "mem_padding", ",", "ind_first_done", "=", "model", "(", "observation", ",", "mems", "=", "mems", ",", "\n", "mem_padding", "=", "mem_padding", ")", "\n", "observation", "=", "env", ".", "step", "(", "agent_outputs", "[", "\"action\"", "]", ")", "\n", "if", "observation", "[", "\"done\"", "]", ".", "item", "(", ")", ":", "\n", "            ", "returns", ".", "append", "(", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Episode ended after %d steps. Return: %.1f\"", ",", "\n", "observation", "[", "\"episode_step\"", "]", ".", "item", "(", ")", ",", "\n", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Average returns over %i steps: %.1f\"", ",", "num_episodes", ",", "sum", "(", "returns", ")", "/", "len", "(", "returns", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.init_weight": [[761, 766], ["torch.nn.init.normal_"], "function", ["None"], ["", "def", "init_weight", "(", "weight", ")", ":", "\n", "# if args.init == 'uniform':", "\n", "#    nn.init.uniform_(weight, -args.init_range, args.init_range)", "\n", "# elif args.init == 'normal':", "\n", "    ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "0.02", ")", "# args.init_std)", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.init_bias": [[768, 770], ["torch.nn.init.constant_"], "function", ["None"], ["", "def", "init_bias", "(", "bias", ")", ":", "\n", "    ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.weights_init": [[772, 811], ["classname.find", "hasattr", "old_monobeast_test.init_weight", "hasattr", "old_monobeast_test.init_bias", "classname.find", "hasattr", "range", "classname.find", "hasattr", "len", "old_monobeast_test.init_weight", "classname.find", "hasattr", "torch.nn.init.normal_", "hasattr", "old_monobeast_test.init_weight", "hasattr", "old_monobeast_test.init_bias", "range", "classname.find", "hasattr", "len", "torch.nn.init.normal_", "hasattr", "old_monobeast_test.init_bias", "classname.find", "hasattr", "hasattr", "hasattr", "hasattr", "torch.nn.init.normal_", "old_monobeast_test.init_weight", "old_monobeast_test.init_weight", "old_monobeast_test.init_weight", "old_monobeast_test.init_bias"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias"], ["", "def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "            ", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'AdaptiveEmbedding'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'emb_projs'", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "0.01", ")", "# args.proj_init_std)", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'Embedding'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'ProjectedAdaptiveLogSoftmax'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'cluster_weight'", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "            ", "init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'cluster_bias'", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'out_projs'", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "0.01", ")", "# args.proj_init_std)", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'LayerNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "0.02", ")", "# args.init_std)", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'TransformerLM'", ")", "!=", "-", "1", ":", "\n", "# print('FOUND TRNASFORMER LM')", "\n", "        ", "if", "hasattr", "(", "m", ",", "'r_emb'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_w_bias'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_r_bias'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_bias'", ")", ":", "\n", "            ", "init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.create_env": [[984, 991], ["Model.atari_wrappers.wrap_pytorch", "Model.atari_wrappers.wrap_deepmind", "Model.atari_wrappers.make_atari"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_pytorch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.make_atari"], ["def", "create_env", "(", "flags", ")", ":", "\n", "    ", "return", "atari_wrappers", ".", "wrap_pytorch", "(", "\n", "atari_wrappers", ".", "wrap_deepmind", "(", "\n", "atari_wrappers", ".", "make_atari", "(", "flags", ".", "env", ")", ",", "\n", "clip_rewards", "=", "False", ",", "\n", "frame_stack", "=", "True", ",", "\n", "scale", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.old_monobeast_test.main": [[995, 1000], ["old_monobeast_test.train", "old_monobeast_test.test"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.test"], ["", "def", "main", "(", "flags", ")", ":", "\n", "    ", "if", "flags", ".", "mode", "==", "\"train\"", ":", "\n", "        ", "train", "(", "flags", ")", "\n", "", "else", ":", "\n", "        ", "test", "(", "flags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.replayBuffer.ReplayBuffer.__init__": [[7, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "max_size", "=", "2000", ")", ":", "\n", "        ", "self", ".", "max_size", "=", "max_size", "\n", "\n", "self", ".", "cur_states", "=", "[", "]", "\n", "self", ".", "actions", "=", "[", "]", "\n", "self", ".", "next_states", "=", "[", "]", "\n", "self", ".", "rewards", "=", "[", "]", "\n", "self", ".", "dones", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.replayBuffer.ReplayBuffer.__len__": [[16, 18], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "cur_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.replayBuffer.ReplayBuffer.add": [[19, 25], ["replayBuffer.ReplayBuffer.cur_states.append", "replayBuffer.ReplayBuffer.actions.append", "replayBuffer.ReplayBuffer.next_states.append", "replayBuffer.ReplayBuffer.rewards.append", "replayBuffer.ReplayBuffer.dones.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "cur_state", ",", "action", ",", "next_state", ",", "reward", ",", "done", ")", ":", "\n", "        ", "self", ".", "cur_states", ".", "append", "(", "cur_state", ")", "\n", "self", ".", "actions", ".", "append", "(", "action", ")", "\n", "self", ".", "next_states", ".", "append", "(", "next_state", ")", "\n", "self", ".", "rewards", ".", "append", "(", "reward", ")", "\n", "self", ".", "dones", ".", "append", "(", "done", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.replayBuffer.ReplayBuffer.sample": [[26, 46], ["replayBuffer.ReplayBuffer.__len__", "numpy.random.choice", "torch.stack", "torch.stack", "torch.stack", "torch.Tensor", "torch.Tensor", "replayBuffer.ReplayBuffer.__len__", "torch.stack", "torch.stack", "torch.stack", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames.__len__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames.__len__"], ["", "def", "sample", "(", "self", ",", "sample_size", "=", "32", ")", ":", "\n", "        ", "sample_transitions", "=", "{", "}", "\n", "if", "self", ".", "__len__", "(", ")", ">=", "sample_size", ":", "\n", "# pick up only random 32 events from the memory", "\n", "# TODO : Replace np with torch functionality and remove import numpy from above", "\n", "            ", "indices", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "__len__", "(", ")", ",", "size", "=", "sample_size", ")", "\n", "sample_transitions", "[", "'cur_states'", "]", "=", "torch", ".", "stack", "(", "self", ".", "cur_states", ")", "[", "indices", "]", "\n", "sample_transitions", "[", "'actions'", "]", "=", "torch", ".", "stack", "(", "self", ".", "actions", ")", "[", "indices", "]", "\n", "sample_transitions", "[", "'next_states'", "]", "=", "torch", ".", "stack", "(", "self", ".", "next_states", ")", "[", "indices", "]", "\n", "sample_transitions", "[", "'rewards'", "]", "=", "torch", ".", "Tensor", "(", "self", ".", "rewards", ")", "[", "indices", "]", "\n", "sample_transitions", "[", "'dones'", "]", "=", "torch", ".", "Tensor", "(", "self", ".", "dones", ")", "[", "indices", "]", "\n", "", "else", ":", "\n", "# if the current buffer size is not greater than 32 then pick up the entire memory", "\n", "            ", "sample_transitions", "[", "'cur_states'", "]", "=", "torch", ".", "stack", "(", "self", ".", "cur_states", ")", "\n", "sample_transitions", "[", "'actions'", "]", "=", "torch", ".", "stack", "(", "self", ".", "actions", ")", "\n", "sample_transitions", "[", "'next_states'", "]", "=", "torch", ".", "stack", "(", "self", ".", "next_states", ")", "\n", "sample_transitions", "[", "'rewards'", "]", "=", "torch", ".", "Tensor", "(", "self", ".", "rewards", ")", "\n", "sample_transitions", "[", "'dones'", "]", "=", "torch", ".", "Tensor", "(", "self", ".", "dones", ")", "\n", "\n", "", "return", "sample_transitions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.tester.Tester.__init__": [[7, 12], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "5", ",", "5", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.tester.Tester.forward": [[13, 18], ["tester.Tester.linear", "print", "tester.Tester.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "linear", "(", "input", ")", "\n", "print", "(", "self", ".", "dropout", "(", "output", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.AtariNet.__init__": [[552, 579], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LSTM"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "observation_shape", ",", "num_actions", ",", "use_lstm", "=", "False", ")", ":", "\n", "        ", "super", "(", "AtariNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "observation_shape", "=", "observation_shape", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "\n", "# Feature extraction.", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "self", ".", "observation_shape", "[", "0", "]", ",", "\n", "out_channels", "=", "32", ",", "\n", "kernel_size", "=", "8", ",", "\n", "stride", "=", "4", ",", "\n", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "# Fully connected layer.", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "2560", ",", "512", ")", "\n", "\n", "# FC output size + one-hot of last action + last reward.", "\n", "core_output_size", "=", "self", ".", "fc", ".", "out_features", "+", "num_actions", "+", "1", "\n", "\n", "self", ".", "use_lstm", "=", "use_lstm", "\n", "if", "use_lstm", ":", "\n", "            ", "self", ".", "core", "=", "nn", ".", "LSTM", "(", "core_output_size", ",", "core_output_size", ",", "2", ")", "\n", "\n", "", "self", ".", "policy", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "baseline", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.AtariNet.initial_state": [[580, 586], ["tuple", "tuple", "torch.zeros", "range"], "methods", ["None"], ["", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "not", "self", ".", "use_lstm", ":", "\n", "            ", "return", "tuple", "(", ")", "\n", "", "return", "tuple", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "core", ".", "num_layers", ",", "batch_size", ",", "self", ".", "core", ".", "hidden_size", ")", "\n", "for", "_", "in", "range", "(", "2", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.AtariNet.forward": [[588, 638], ["torch.flatten", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu.view", "torch.nn.functional.relu", "torch.nn.functional.one_hot().float", "torch.clamp().view", "torch.cat", "monobeast.AtariNet.policy", "monobeast.AtariNet.baseline", "policy_logits.view.view.view", "baseline.view.view.view", "torch.argmax.view", "torch.nn.functional.relu.float", "monobeast.AtariNet.conv1", "monobeast.AtariNet.conv2", "monobeast.AtariNet.conv3", "monobeast.AtariNet.fc", "core_input.view.view.view", "zip", "torch.flatten", "tuple", "torch.multinomial", "torch.argmax", "dict", "torch.nn.functional.one_hot", "torch.clamp", "core_input.view.view.unbind", "notdone.unbind", "nd.view.view.view", "tuple", "monobeast.AtariNet.core", "core_output_list.append", "torch.cat", "torch.nn.functional.softmax", "inputs[].view", "input.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "core_state", "=", "(", ")", ")", ":", "\n", "        ", "x", "=", "inputs", "[", "\"frame\"", "]", "# [T, B, C, H, W].", "\n", "T", ",", "B", ",", "*", "_", "=", "x", ".", "shape", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "0", ",", "1", ")", "# Merge time and batch.", "\n", "x", "=", "x", ".", "float", "(", ")", "/", "255.0", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv3", "(", "x", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n", "one_hot_last_action", "=", "F", ".", "one_hot", "(", "\n", "inputs", "[", "\"last_action\"", "]", ".", "view", "(", "T", "*", "B", ")", ",", "self", ".", "num_actions", "\n", ")", ".", "float", "(", ")", "\n", "clipped_reward", "=", "torch", ".", "clamp", "(", "inputs", "[", "\"reward\"", "]", ",", "-", "1", ",", "1", ")", ".", "view", "(", "T", "*", "B", ",", "1", ")", "\n", "core_input", "=", "torch", ".", "cat", "(", "[", "x", ",", "clipped_reward", ",", "one_hot_last_action", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "use_lstm", ":", "\n", "            ", "core_input", "=", "core_input", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "\n", "core_output_list", "=", "[", "]", "\n", "notdone", "=", "(", "~", "inputs", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "\n", "for", "input", ",", "nd", "in", "zip", "(", "core_input", ".", "unbind", "(", ")", ",", "notdone", ".", "unbind", "(", ")", ")", ":", "\n", "# Reset core state to zero whenever an episode ended.", "\n", "# Make `done` broadcastable with (num_layers, B, hidden_size)", "\n", "# states:", "\n", "                ", "nd", "=", "nd", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "core_state", "=", "tuple", "(", "nd", "*", "s", "for", "s", "in", "core_state", ")", "\n", "output", ",", "core_state", "=", "self", ".", "core", "(", "input", ".", "unsqueeze", "(", "0", ")", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "output", ")", "\n", "", "core_output", "=", "torch", ".", "flatten", "(", "torch", ".", "cat", "(", "core_output_list", ")", ",", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "core_output", "=", "core_input", "\n", "core_state", "=", "tuple", "(", ")", "\n", "\n", "", "policy_logits", "=", "self", ".", "policy", "(", "core_output", ")", "\n", "baseline", "=", "self", ".", "baseline", "(", "core_output", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "action", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "policy_logits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "# Don't sample when testing.", "\n", "            ", "action", "=", "torch", ".", "argmax", "(", "policy_logits", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_logits", "=", "policy_logits", ".", "view", "(", "T", ",", "B", ",", "self", ".", "num_actions", ")", "\n", "baseline", "=", "baseline", ".", "view", "(", "T", ",", "B", ")", "\n", "action", "=", "action", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "return", "(", "\n", "dict", "(", "policy_logits", "=", "policy_logits", ",", "baseline", "=", "baseline", ",", "action", "=", "action", ")", ",", "\n", "core_state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.compute_baseline_loss": [[111, 113], ["torch.sum"], "function", ["None"], ["def", "compute_baseline_loss", "(", "advantages", ")", ":", "\n", "    ", "return", "0.5", "*", "torch", ".", "sum", "(", "advantages", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.compute_entropy_loss": [[115, 120], ["torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.sum"], "function", ["None"], ["", "def", "compute_entropy_loss", "(", "logits", ")", ":", "\n", "    ", "\"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"", "\n", "policy", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "log_policy", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "sum", "(", "policy", "*", "log_policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.compute_policy_gradient_loss": [[122, 130], ["torch.nn.functional.nll_loss", "cross_entropy.view_as.view_as", "torch.sum", "torch.nn.functional.log_softmax", "torch.flatten", "torch.flatten", "advantages.detach"], "function", ["None"], ["", "def", "compute_policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ")", ":", "\n", "    ", "cross_entropy", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "logits", ",", "0", ",", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "torch", ".", "flatten", "(", "actions", ",", "0", ",", "1", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", "\n", "cross_entropy", "=", "cross_entropy", ".", "view_as", "(", "advantages", ")", "\n", "return", "torch", ".", "sum", "(", "cross_entropy", "*", "advantages", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.act": [[133, 197], ["logging.info", "torchbeast.core.prof.Timings", "monobeast.create_env", "torchbeast.core.environment.Environment", "environment.Environment.initial", "model.initial_state", "model", "int.from_bytes", "free_queue.get", "enumerate", "range", "full_queue.put", "logging.info", "logging.error", "traceback.print_exc", "print", "os.urandom", "prof.Timings.reset", "prof.Timings.time", "environment.Environment.step", "prof.Timings.time", "prof.Timings.time", "prof.Timings.summary", "torch.no_grad", "model"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary"], ["", "def", "act", "(", "\n", "flags", ",", "\n", "actor_index", ":", "int", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "level_name", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"Actor %i started.\"", ",", "actor_index", ")", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "# Keep track of how fast things are.", "\n", "seed", "=", "actor_index", "^", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "4", ")", ",", "byteorder", "=", "\"little\"", ")", "\n", "######changed next line", "\n", "gym_env", "=", "create_env", "(", "flags", ",", "level_name", ",", "seed", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "env_output", "=", "env", ".", "initial", "(", ")", "\n", "agent_state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "agent_output", ",", "unused_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "while", "True", ":", "\n", "            ", "index", "=", "free_queue", ".", "get", "(", ")", "\n", "if", "index", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "# Write old rollout end.", "\n", "", "for", "key", "in", "env_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "agent_state", ")", ":", "\n", "                ", "initial_agent_state_buffers", "[", "index", "]", "[", "i", "]", "[", "...", "]", "=", "tensor", "\n", "\n", "# Do new rollout.", "\n", "", "for", "t", "in", "range", "(", "flags", ".", "unroll_length", ")", ":", "\n", "                ", "timings", ".", "reset", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "agent_output", ",", "agent_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "\n", "", "timings", ".", "time", "(", "\"model\"", ")", "\n", "\n", "env_output", "=", "env", ".", "step", "(", "agent_output", "[", "\"action\"", "]", ")", "\n", "\n", "timings", ".", "time", "(", "\"step\"", ")", "\n", "\n", "for", "key", "in", "env_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "\n", "", "timings", ".", "time", "(", "\"write\"", ")", "\n", "", "full_queue", ".", "put", "(", "index", ")", "\n", "\n", "", "if", "actor_index", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Actor %i: %s\"", ",", "actor_index", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# Return silently.", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logging", ".", "error", "(", "\"Exception in worker process %i\"", ",", "actor_index", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "print", "(", ")", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.get_batch": [[199, 229], ["threading.Lock", "timings.time", "timings.time", "tuple", "timings.time", "timings.time", "timings.time", "torch.stack", "torch.cat", "free_queue.put", "t.to", "full_queue.get", "zip", "batch.items", "t.to", "range"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["", "", "def", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "\n", ")", ":", "\n", "    ", "with", "lock", ":", "\n", "        ", "timings", ".", "time", "(", "\"lock\"", ")", "\n", "indices", "=", "[", "full_queue", ".", "get", "(", ")", "for", "_", "in", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "timings", ".", "time", "(", "\"dequeue\"", ")", "\n", "", "batch", "=", "{", "\n", "key", ":", "torch", ".", "stack", "(", "[", "buffers", "[", "key", "]", "[", "m", "]", "for", "m", "in", "indices", "]", ",", "dim", "=", "1", ")", "for", "key", "in", "buffers", "\n", "}", "\n", "initial_agent_state", "=", "(", "\n", "torch", ".", "cat", "(", "ts", ",", "dim", "=", "1", ")", "\n", "for", "ts", "in", "zip", "(", "*", "[", "initial_agent_state_buffers", "[", "m", "]", "for", "m", "in", "indices", "]", ")", "\n", ")", "\n", "timings", ".", "time", "(", "\"batch\"", ")", "\n", "for", "m", "in", "indices", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "", "timings", ".", "time", "(", "\"enqueue\"", ")", "\n", "batch", "=", "{", "k", ":", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "k", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "initial_agent_state", "=", "tuple", "(", "\n", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "t", "in", "initial_agent_state", "\n", ")", "\n", "timings", ".", "time", "(", "\"device\"", ")", "\n", "return", "batch", ",", "initial_agent_state", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.learn": [[231, 302], ["threading.Lock", "model", "torchbeast.core.vtrace.from_logits", "monobeast.compute_policy_gradient_loss", "optimizer.zero_grad", "total_loss.backward", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "actor_model.load_state_dict", "torch.clamp", "monobeast.compute_baseline_loss", "monobeast.compute_entropy_loss", "tuple", "torch.mean().item", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "model.parameters", "model.state_dict", "batch.items", "learner_outputs.items", "episode_returns.cpu().numpy", "torch.mean", "episode_returns.cpu"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict"], ["", "def", "learn", "(", "\n", "flags", ",", "\n", "actor_model", ",", "\n", "model", ",", "\n", "batch", ",", "\n", "initial_agent_state", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "# noqa: B008", "\n", ")", ":", "\n", "    ", "\"\"\"Performs a learning (optimization) step.\"\"\"", "\n", "with", "lock", ":", "\n", "        ", "learner_outputs", ",", "unused_state", "=", "model", "(", "batch", ",", "initial_agent_state", ")", "\n", "\n", "# Take final value function slice for bootstrapping.", "\n", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "-", "1", "]", "\n", "\n", "# Move from obs[t] -> action[t] to action[t] -> obs[t].", "\n", "batch", "=", "{", "key", ":", "tensor", "[", "1", ":", "]", "for", "key", ",", "tensor", "in", "batch", ".", "items", "(", ")", "}", "\n", "learner_outputs", "=", "{", "key", ":", "tensor", "[", ":", "-", "1", "]", "for", "key", ",", "tensor", "in", "learner_outputs", ".", "items", "(", ")", "}", "\n", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "\n", "if", "flags", ".", "reward_clipping", "==", "\"abs_one\"", ":", "\n", "            ", "clipped_rewards", "=", "torch", ".", "clamp", "(", "rewards", ",", "-", "1", ",", "1", ")", "\n", "", "elif", "flags", ".", "reward_clipping", "==", "\"none\"", ":", "\n", "            ", "clipped_rewards", "=", "rewards", "\n", "\n", "", "discounts", "=", "(", "~", "batch", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "*", "flags", ".", "discounting", "\n", "\n", "vtrace_returns", "=", "vtrace", ".", "from_logits", "(", "\n", "behavior_policy_logits", "=", "batch", "[", "\"policy_logits\"", "]", ",", "\n", "target_policy_logits", "=", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "actions", "=", "batch", "[", "\"action\"", "]", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "clipped_rewards", ",", "\n", "values", "=", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", ")", "\n", "\n", "pg_loss", "=", "compute_policy_gradient_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "batch", "[", "\"action\"", "]", ",", "\n", "vtrace_returns", ".", "pg_advantages", ",", "\n", ")", "\n", "baseline_loss", "=", "flags", ".", "baseline_cost", "*", "compute_baseline_loss", "(", "\n", "vtrace_returns", ".", "vs", "-", "learner_outputs", "[", "\"baseline\"", "]", "\n", ")", "\n", "entropy_loss", "=", "flags", ".", "entropy_cost", "*", "compute_entropy_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", "\n", ")", "\n", "\n", "total_loss", "=", "pg_loss", "+", "baseline_loss", "+", "entropy_loss", "\n", "\n", "episode_returns", "=", "batch", "[", "\"episode_return\"", "]", "[", "batch", "[", "\"done\"", "]", "]", "\n", "stats", "=", "{", "\n", "\"episode_returns\"", ":", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "\"mean_episode_return\"", ":", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ",", "\n", "\"total_loss\"", ":", "total_loss", ".", "item", "(", ")", ",", "\n", "\"pg_loss\"", ":", "pg_loss", ".", "item", "(", ")", ",", "\n", "\"baseline_loss\"", ":", "baseline_loss", ".", "item", "(", ")", ",", "\n", "\"entropy_loss\"", ":", "entropy_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "flags", ".", "grad_norm_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "actor_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.create_buffers": [[304, 322], ["dict", "range", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "buffers[].append", "torch.empty().share_memory_", "torch.empty"], "function", ["None"], ["", "", "def", "create_buffers", "(", "flags", ",", "obs_shape", ",", "num_actions", ")", "->", "Buffers", ":", "\n", "    ", "T", "=", "flags", ".", "unroll_length", "\n", "specs", "=", "dict", "(", "\n", "frame", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "*", "obs_shape", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "reward", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "done", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "\n", "episode_return", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "episode_step", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "policy_logits", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "num_actions", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "baseline", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "last_action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", ")", "\n", "buffers", ":", "Buffers", "=", "{", "key", ":", "[", "]", "for", "key", "in", "specs", "}", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "for", "key", "in", "buffers", ":", "\n", "            ", "buffers", "[", "key", "]", ".", "append", "(", "torch", ".", "empty", "(", "**", "specs", "[", "key", "]", ")", ".", "share_memory_", "(", ")", ")", "\n", "", "", "return", "buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.train": [[325, 512], ["torchbeast.core.file_writer.FileWriter", "os.path.expandvars", "monobeast.create_env", "Net", "monobeast.create_buffers", "print", "Net.share_memory", "range", "torch.multiprocessing.get_context", "mp.get_context.SimpleQueue", "mp.get_context.SimpleQueue", "range", "Net().to", "torch.optim.RMSprop", "torch.optim.lr_scheduler.LambdaLR", "logging.getLogger", "logging.getLogger.info", "range", "range", "monobeast.train.checkpoint"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_buffers", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.checkpoint"], ["", "def", "train", "(", "flags", ")", ":", "# pylint: disable=too-many-branches, too-many-statements", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "flags", ".", "xpid", "=", "\"torchbeast-%s\"", "%", "time", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "", "plogger", "=", "file_writer", ".", "FileWriter", "(", "\n", "xpid", "=", "flags", ".", "xpid", ",", "xp_args", "=", "flags", ".", "__dict__", ",", "rootdir", "=", "flags", ".", "savedir", "\n", ")", "\n", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "if", "flags", ".", "num_buffers", "is", "None", ":", "# Set sensible default for num_buffers.", "\n", "        ", "flags", ".", "num_buffers", "=", "max", "(", "2", "*", "flags", ".", "num_actors", ",", "flags", ".", "batch_size", ")", "\n", "", "if", "flags", ".", "num_actors", ">=", "flags", ".", "num_buffers", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than num_actors\"", ")", "\n", "", "if", "flags", ".", "num_buffers", "<", "flags", ".", "batch_size", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than batch_size\"", ")", "\n", "\n", "", "T", "=", "flags", ".", "unroll_length", "\n", "B", "=", "flags", ".", "batch_size", "\n", "\n", "flags", ".", "device", "=", "None", "\n", "if", "not", "flags", ".", "disable_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Not using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "######I changed the next two line with level name and env.initial", "\n", "", "env", "=", "create_env", "(", "flags", ",", "flags", ".", "level_name", ",", "1", ")", "\n", "model", "=", "Net", "(", "env", ".", "initial", "(", ")", ".", "shape", ",", "len", "(", "environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", ".", "use_lstm", ")", "\n", "buffers", "=", "create_buffers", "(", "flags", ",", "env", ".", "_observation", "(", ")", ".", "shape", ",", "model", ".", "num_actions", ")", "\n", "print", "(", "env", ".", "_observation", "(", ")", ".", "shape", ")", "\n", "model", ".", "share_memory", "(", ")", "\n", "\n", "# Add initial RNN state.", "\n", "initial_agent_state_buffers", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "for", "t", "in", "state", ":", "\n", "            ", "t", ".", "share_memory_", "(", ")", "\n", "", "initial_agent_state_buffers", ".", "append", "(", "state", ")", "\n", "\n", "", "actor_processes", "=", "[", "]", "\n", "ctx", "=", "mp", ".", "get_context", "(", "\"fork\"", ")", "\n", "free_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "full_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "##########I changed this part", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "        ", "actor", "=", "ctx", ".", "Process", "(", "\n", "target", "=", "act", ",", "\n", "args", "=", "(", "\n", "flags", ",", "\n", "i", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "model", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "flags", ".", "level_name", "\n", ")", ",", "\n", ")", "\n", "actor", ".", "start", "(", ")", "\n", "actor_processes", ".", "append", "(", "actor", ")", "\n", "\n", "", "learner_model", "=", "Net", "(", "\n", "env", ".", "_observation", "(", ")", ".", "shape", ",", "len", "(", "environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", ".", "use_lstm", "\n", ")", ".", "to", "(", "device", "=", "flags", ".", "device", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "\n", "learner_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "flags", ".", "learning_rate", ",", "\n", "momentum", "=", "flags", ".", "momentum", ",", "\n", "eps", "=", "flags", ".", "epsilon", ",", "\n", "alpha", "=", "flags", ".", "alpha", ",", "\n", ")", "\n", "\n", "def", "lr_lambda", "(", "epoch", ")", ":", "\n", "        ", "return", "1", "-", "min", "(", "epoch", "*", "T", "*", "B", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "\n", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"logfile\"", ")", "\n", "stat_keys", "=", "[", "\n", "\"total_loss\"", ",", "\n", "\"mean_episode_return\"", ",", "\n", "\"pg_loss\"", ",", "\n", "\"baseline_loss\"", ",", "\n", "\"entropy_loss\"", ",", "\n", "]", "\n", "logger", ".", "info", "(", "\"# Step\\t%s\"", ",", "\"\\t\"", ".", "join", "(", "stat_keys", ")", ")", "\n", "\n", "step", ",", "stats", "=", "0", ",", "{", "}", "\n", "\n", "def", "batch_and_learn", "(", "i", ",", "lock", "=", "threading", ".", "Lock", "(", ")", ")", ":", "\n", "        ", "\"\"\"Thread target for the learning process.\"\"\"", "\n", "nonlocal", "step", ",", "stats", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "timings", ".", "reset", "(", ")", "\n", "batch", ",", "agent_state", "=", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", ")", "\n", "stats", "=", "learn", "(", "\n", "flags", ",", "model", ",", "learner_model", ",", "batch", ",", "agent_state", ",", "optimizer", ",", "scheduler", "\n", ")", "\n", "timings", ".", "time", "(", "\"learn\"", ")", "\n", "with", "lock", ":", "\n", "                ", "to_log", "=", "dict", "(", "step", "=", "step", ")", "\n", "to_log", ".", "update", "(", "{", "k", ":", "stats", "[", "k", "]", "for", "k", "in", "stat_keys", "}", ")", "\n", "plogger", ".", "log", "(", "to_log", ")", "\n", "step", "+=", "T", "*", "B", "\n", "\n", "", "", "if", "i", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Batch and learn: %s\"", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "for", "m", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_learner_threads", ")", ":", "\n", "        ", "thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "batch_and_learn", ",", "name", "=", "\"batch-and-learn-%d\"", "%", "i", ",", "args", "=", "(", "i", ",", ")", "\n", ")", "\n", "thread", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "thread", ")", "\n", "\n", "", "def", "checkpoint", "(", ")", ":", "\n", "        ", "if", "flags", ".", "disable_checkpoint", ":", "\n", "            ", "return", "\n", "", "logging", ".", "info", "(", "\"Saving checkpoint to %s\"", ",", "checkpointpath", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"flags\"", ":", "vars", "(", "flags", ")", ",", "\n", "}", ",", "\n", "checkpointpath", ",", "\n", ")", "\n", "\n", "", "timer", "=", "timeit", ".", "default_timer", "\n", "try", ":", "\n", "        ", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "start_step", "=", "step", "\n", "start_time", "=", "timer", "(", ")", "\n", "time", ".", "sleep", "(", "5", ")", "\n", "\n", "if", "timer", "(", ")", "-", "last_checkpoint_time", ">", "10", "*", "60", ":", "# Save every 10 min.", "\n", "                ", "checkpoint", "(", ")", "\n", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "\n", "", "sps", "=", "(", "step", "-", "start_step", ")", "/", "(", "timer", "(", ")", "-", "start_time", ")", "\n", "if", "stats", ".", "get", "(", "\"episode_returns\"", ",", "None", ")", ":", "\n", "                ", "mean_return", "=", "(", "\n", "\"Return per episode: %.1f. \"", "%", "stats", "[", "\"mean_episode_return\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "mean_return", "=", "\"\"", "\n", "", "total_loss", "=", "stats", ".", "get", "(", "\"total_loss\"", ",", "float", "(", "\"inf\"", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Steps %i @ %.1f SPS. Loss %f. %sStats:\\n%s\"", ",", "\n", "step", ",", "\n", "sps", ",", "\n", "total_loss", ",", "\n", "mean_return", ",", "\n", "pprint", ".", "pformat", "(", "stats", ")", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "return", "# Try joining actors then quit.", "\n", "", "else", ":", "\n", "        ", "for", "thread", "in", "threads", ":", "\n", "            ", "thread", ".", "join", "(", ")", "\n", "", "logging", ".", "info", "(", "\"Learning finished after %d steps.\"", ",", "step", ")", "\n", "", "finally", ":", "\n", "        ", "for", "_", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "            ", "free_queue", ".", "put", "(", "None", ")", "\n", "", "for", "actor", "in", "actor_processes", ":", "\n", "            ", "actor", ".", "join", "(", "timeout", "=", "1", ")", "\n", "\n", "", "", "checkpoint", "(", ")", "\n", "plogger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.test": [[514, 548], ["monobeast.create_env", "torchbeast.core.environment.Environment", "Net", "Net.eval", "torch.load", "Net.load_state_dict", "environment.Environment.initial", "environment.Environment.close", "logging.info", "os.path.expandvars", "len", "len", "Net.", "environment.Environment.step", "observation[].item", "os.path.expanduser", "create_env._observation", "returns.append", "logging.info", "sum", "len", "observation[].item", "observation[].item", "observation[].item"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab._observation"], ["", "def", "test", "(", "flags", ",", "num_episodes", ":", "int", "=", "10", ")", ":", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "checkpointpath", "=", "\"./latest/model.tar\"", "\n", "", "else", ":", "\n", "        ", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "", "gym_env", "=", "create_env", "(", "flags", ",", "flags", ".", "level_name", ",", "1", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "model", "=", "Net", "(", "gym_env", ".", "_observation", "(", ")", ".", "shape", ",", "len", "(", "environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", ".", "use_lstm", ")", "\n", "model", ".", "eval", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpointpath", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "\n", "observation", "=", "env", ".", "initial", "(", ")", "\n", "returns", "=", "[", "]", "\n", "\n", "while", "len", "(", "returns", ")", "<", "num_episodes", ":", "\n", "# if flags.mode == \"test_render\":", "\n", "# env.gym_env.render()", "\n", "        ", "agent_outputs", "=", "model", "(", "observation", ")", "\n", "policy_outputs", ",", "_", "=", "agent_outputs", "\n", "observation", "=", "env", ".", "step", "(", "policy_outputs", "[", "\"action\"", "]", ")", "\n", "if", "observation", "[", "\"done\"", "]", ".", "item", "(", ")", ":", "\n", "            ", "returns", ".", "append", "(", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Episode ended after %d steps. Return: %.1f\"", ",", "\n", "observation", "[", "\"episode_step\"", "]", ".", "item", "(", ")", ",", "\n", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Average returns over %i steps: %.1f\"", ",", "num_episodes", ",", "sum", "(", "returns", ")", "/", "len", "(", "returns", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.create_env": [[645, 653], ["torchbeast.dmlab_wrappers.createDmLab"], "function", ["None"], ["def", "create_env", "(", "flags", ",", "level_name", ",", "seed", "=", "1", ")", ":", "\n", "    ", "level_name", "=", "'contributed/dmlab30/'", "+", "level_name", "\n", "config", "=", "{", "\n", "'width'", ":", "96", ",", "\n", "'height'", ":", "72", ",", "\n", "'logLevel'", ":", "'WARN'", ",", "\n", "}", "\n", "return", "dmlab_wrappers", ".", "createDmLab", "(", "level_name", ",", "config", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.monobeast.main": [[656, 661], ["monobeast.train", "monobeast.test"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.test"], ["", "def", "main", "(", "flags", ")", ":", "\n", "    ", "if", "flags", ".", "mode", "==", "\"train\"", ":", "\n", "        ", "train", "(", "flags", ")", "\n", "", "else", ":", "\n", "        ", "test", "(", "flags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab30._transform_level_returns": [[165, 184], ["level_returns.items", "set", "new_level_returns.items", "LEVEL_MAPPING.values", "set", "ValueError", "new_level_returns.keys", "tensorflow.logging.info", "LEVEL_MAPPING.get", "list", "ValueError"], "function", ["None"], ["def", "_transform_level_returns", "(", "level_returns", ")", ":", "\n", "  ", "\"\"\"Converts training level names to test level names.\"\"\"", "\n", "new_level_returns", "=", "{", "}", "\n", "for", "level_name", ",", "returns", "in", "level_returns", ".", "items", "(", ")", ":", "\n", "    ", "new_level_returns", "[", "LEVEL_MAPPING", ".", "get", "(", "level_name", ",", "level_name", ")", "]", "=", "returns", "\n", "\n", "", "test_set", "=", "set", "(", "LEVEL_MAPPING", ".", "values", "(", ")", ")", "\n", "diff", "=", "test_set", "-", "set", "(", "new_level_returns", ".", "keys", "(", ")", ")", "\n", "if", "diff", ":", "\n", "    ", "raise", "ValueError", "(", "'Missing levels: %s'", "%", "list", "(", "diff", ")", ")", "\n", "\n", "", "for", "level_name", ",", "returns", "in", "new_level_returns", ".", "items", "(", ")", ":", "\n", "    ", "if", "level_name", "in", "test_set", ":", "\n", "      ", "if", "not", "returns", ":", "\n", "        ", "raise", "ValueError", "(", "'Missing returns for level: \\'%s\\': '", "%", "level_name", ")", "\n", "", "", "else", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "'Skipping level %s for calculation.'", ",", "level_name", ")", "\n", "\n", "", "", "return", "new_level_returns", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab30.compute_human_normalized_score": [[186, 215], ["dmlab30._transform_level_returns", "numpy.mean", "numpy.mean", "min", "min."], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab30._transform_level_returns"], ["", "def", "compute_human_normalized_score", "(", "level_returns", ",", "per_level_cap", ")", ":", "\n", "  ", "\"\"\"Computes human normalized score.\n  Levels that have different training and test versions, will use the returns\n  for the training level to calculate the score. E.g.\n  'rooms_collect_good_objects_train' will be used for\n  'rooms_collect_good_objects_test'. All returns for levels not in DmLab-30\n  will be ignored.\n  Args:\n    level_returns: A dictionary from level to list of episode returns.\n    per_level_cap: A percentage cap (e.g. 100.) on the per level human\n      normalized score. If None, no cap is applied.\n  Returns:\n    A float with the human normalized score in percentage.\n  Raises:\n    ValueError: If a level is missing from `level_returns` or has no returns.\n  \"\"\"", "\n", "new_level_returns", "=", "_transform_level_returns", "(", "level_returns", ")", "\n", "\n", "def", "human_normalized_score", "(", "level_name", ",", "returns", ")", ":", "\n", "    ", "score", "=", "np", ".", "mean", "(", "returns", ")", "\n", "human", "=", "HUMAN_SCORES", "[", "level_name", "]", "\n", "random", "=", "RANDOM_SCORES", "[", "level_name", "]", "\n", "human_normalized_score", "=", "(", "score", "-", "random", ")", "/", "(", "human", "-", "random", ")", "*", "100", "\n", "if", "per_level_cap", "is", "not", "None", ":", "\n", "      ", "human_normalized_score", "=", "min", "(", "human_normalized_score", ",", "per_level_cap", ")", "\n", "", "return", "human_normalized_score", "\n", "\n", "", "return", "np", ".", "mean", "(", "\n", "[", "human_normalized_score", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "new_level_returns", ".", "items", "(", ")", "]", ")", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab.__init__": [[37, 50], ["numpy.random.RandomState", "deepmind_lab.Lab", "deepmind_lab.set_runfiles_path", "str", "config.items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "level", ",", "config", ",", "seed", ",", "\n", "runfiles_path", "=", "None", ",", "level_cache", "=", "None", ")", ":", "\n", "\n", "    ", "self", ".", "_random_state", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "seed", ")", "\n", "if", "runfiles_path", ":", "\n", "      ", "deepmind_lab", ".", "set_runfiles_path", "(", "runfiles_path", ")", "\n", "", "config", "=", "{", "k", ":", "str", "(", "v", ")", "for", "k", ",", "v", "in", "config", ".", "items", "(", ")", "}", "\n", "self", ".", "_observation_spec", "=", "[", "'RGBD'", "]", "\n", "self", ".", "_env", "=", "deepmind_lab", ".", "Lab", "(", "\n", "level", "=", "level", ",", "\n", "observations", "=", "self", ".", "_observation_spec", ",", "\n", "config", "=", "config", ",", "\n", "level_cache", "=", "level_cache", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab._reset": [[52, 54], ["dmlab_wrappers.createDmLab._env.reset", "dmlab_wrappers.createDmLab._random_state.randint"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset"], ["", "def", "_reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "_env", ".", "reset", "(", "seed", "=", "self", ".", "_random_state", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab._observation": [[55, 58], ["dmlab_wrappers.createDmLab._env.observations"], "methods", ["None"], ["", "def", "_observation", "(", "self", ")", ":", "\n", "    ", "d", "=", "self", ".", "_env", ".", "observations", "(", ")", "\n", "return", "d", "[", "'RGBD'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab.initial": [[59, 63], ["dmlab_wrappers.createDmLab._reset", "dmlab_wrappers.createDmLab._env.observations"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab._reset"], ["", "def", "initial", "(", "self", ")", ":", "\n", "    ", "self", ".", "_reset", "(", ")", "\n", "d", "=", "self", ".", "_env", ".", "observations", "(", ")", "\n", "return", "d", "[", "'RGBD'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab.step": [[64, 72], ["dmlab_wrappers.createDmLab._env.step", "numpy.array", "numpy.array", "numpy.array", "dmlab_wrappers.createDmLab._reset", "dmlab_wrappers.createDmLab._observation", "dmlab_wrappers.createDmLab._env.is_running"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab._reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab._observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "reward", "=", "self", ".", "_env", ".", "step", "(", "action", ")", "#, num_steps=self._num_action_repeats)", "\n", "done", "=", "np", ".", "array", "(", "not", "self", ".", "_env", ".", "is_running", "(", ")", ")", "\n", "if", "done", ":", "\n", "      ", "self", ".", "_reset", "(", ")", "\n", "", "observation", "=", "np", ".", "array", "(", "self", ".", "_observation", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "reward", "=", "np", ".", "array", "(", "reward", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "return", "observation", ",", "reward", ",", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.torchbeast.dmlab_wrappers.createDmLab.close": [[73, 75], ["dmlab_wrappers.createDmLab._env.close"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "    ", "self", ".", "_env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.action_log_probs": [[50, 56], ["torch.nll_loss().view_as", "torch.nll_loss", "torch.log_softmax", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten"], "function", ["None"], ["def", "action_log_probs", "(", "policy_logits", ",", "actions", ")", ":", "\n", "    ", "return", "-", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "policy_logits", ",", "0", ",", "-", "2", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "torch", ".", "flatten", "(", "actions", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", ".", "view_as", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits": [[58, 90], ["vtrace.action_log_probs", "vtrace.action_log_probs", "vtrace.from_importance_weights", "VTraceFromLogitsReturns", "from_importance_weights._asdict"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.action_log_probs", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.action_log_probs", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_importance_weights"], ["", "def", "from_logits", "(", "\n", "behavior_policy_logits", ",", "\n", "target_policy_logits", ",", "\n", "actions", ",", "\n", "discounts", ",", "\n", "rewards", ",", "\n", "values", ",", "\n", "bootstrap_value", ",", "\n", "clip_rho_threshold", "=", "1.0", ",", "\n", "clip_pg_rho_threshold", "=", "1.0", ",", "\n", ")", ":", "\n", "    ", "\"\"\"V-trace for softmax policies.\"\"\"", "\n", "\n", "target_action_log_probs", "=", "action_log_probs", "(", "target_policy_logits", ",", "actions", ")", "\n", "behavior_action_log_probs", "=", "action_log_probs", "(", "behavior_policy_logits", ",", "actions", ")", "\n", "log_rhos", "=", "target_action_log_probs", "-", "behavior_action_log_probs", "\n", "vtrace_returns", "=", "from_importance_weights", "(", "\n", "log_rhos", "=", "log_rhos", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "rewards", ",", "\n", "values", "=", "values", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", "clip_rho_threshold", "=", "clip_rho_threshold", ",", "\n", "clip_pg_rho_threshold", "=", "clip_pg_rho_threshold", ",", "\n", ")", "\n", "return", "VTraceFromLogitsReturns", "(", "\n", "log_rhos", "=", "log_rhos", ",", "\n", "behavior_action_log_probs", "=", "behavior_action_log_probs", ",", "\n", "target_action_log_probs", "=", "target_action_log_probs", ",", "\n", "**", "vtrace_returns", ".", "_asdict", "(", ")", ",", "\n", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_importance_weights": [[93, 165], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.exp", "torch.exp", "torch.clamp", "torch.clamp", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "range", "torch.add", "torch.add", "torch.cat", "torch.cat", "VTraceReturns", "torch.clamp", "torch.clamp", "bootstrap_value.size", "ind_first_done[].item", "range", "torch.ones_like", "torch.ones_like", "torch.clamp", "torch.clamp", "torch.unsqueeze", "torch.unsqueeze", "result.append", "len", "result.reverse", "torch.stack", "torch.stack", "broadcasted_bootstrap_values.unsqueeze", "len"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.replayBuffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.replayBuffer.ReplayBuffer.add"], ["log_rhos", ",", "\n", "discounts", ",", "\n", "rewards", ",", "\n", "values", ",", "\n", "bootstrap_value", ",", "\n", "clip_rho_threshold", "=", "1.0", ",", "\n", "clip_pg_rho_threshold", "=", "1.0", ",", "\n", ")", ":", "\n", "    ", "\"\"\"V-trace from log importance weights.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "rhos", "=", "torch", ".", "exp", "(", "log_rhos", ")", "\n", "if", "clip_rho_threshold", "is", "not", "None", ":", "\n", "            ", "clipped_rhos", "=", "torch", ".", "clamp", "(", "rhos", ",", "max", "=", "clip_rho_threshold", ")", "\n", "", "else", ":", "\n", "            ", "clipped_rhos", "=", "rhos", "\n", "\n", "", "cs", "=", "torch", ".", "clamp", "(", "rhos", ",", "max", "=", "1.0", ")", "\n", "# Append bootstrapped value to get [v1, ..., v_t+1]", "\n", "values_t_plus_1", "=", "torch", ".", "cat", "(", "\n", "[", "values", "[", "1", ":", "]", ",", "torch", ".", "unsqueeze", "(", "bootstrap_value", ",", "0", ")", "]", ",", "dim", "=", "0", "\n", ")", "\n", "deltas", "=", "clipped_rhos", "*", "(", "rewards", "+", "discounts", "*", "values_t_plus_1", "-", "values", ")", "\n", "\n", "acc", "=", "torch", ".", "zeros_like", "(", "bootstrap_value", ")", "\n", "result", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "discounts", ".", "shape", "[", "0", "]", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "acc", "=", "deltas", "[", "t", "]", "+", "discounts", "[", "t", "]", "*", "cs", "[", "t", "]", "*", "acc", "\n", "result", ".", "append", "(", "acc", ")", "\n", "", "result", ".", "reverse", "(", ")", "\n", "vs_minus_v_xs", "=", "torch", ".", "stack", "(", "result", ")", "\n", "\n", "# Add V(x_s) to get v_s.", "\n", "vs", "=", "torch", ".", "add", "(", "vs_minus_v_xs", ",", "values", ")", "\n", "\n", "# Advantage for policy gradient.", "\n", "broadcasted_bootstrap_values", "=", "torch", ".", "ones_like", "(", "vs", "[", "0", "]", ")", "*", "bootstrap_value", "\n", "vs_t_plus_1", "=", "torch", ".", "cat", "(", "\n", "[", "vs", "[", "1", ":", "]", ",", "broadcasted_bootstrap_values", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", "\n", ")", "\n", "if", "clip_pg_rho_threshold", "is", "not", "None", ":", "\n", "            ", "clipped_pg_rhos", "=", "torch", ".", "clamp", "(", "rhos", ",", "max", "=", "clip_pg_rho_threshold", ")", "\n", "", "else", ":", "\n", "            ", "clipped_pg_rhos", "=", "rhos", "\n", "", "pg_advantages", "=", "clipped_pg_rhos", "*", "(", "rewards", "+", "discounts", "*", "vs_t_plus_1", "-", "values", ")", "\n", "\n", "# Make sure no gradients backpropagated through the returned values.", "\n", "return", "VTraceReturns", "(", "vs", "=", "vs", ",", "pg_advantages", "=", "pg_advantages", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.__init__": [[23, 28], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "prof.Timings.reset"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_means", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "self", ".", "_vars", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "self", ".", "_counts", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.reset": [[29, 31], ["timeit.default_timer"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "last_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time": [[32, 57], ["timeit.default_timer"], "methods", ["None"], ["", "def", "time", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Save an update for event `name`.\n\n        Nerd alarm: We could just store a\n            collections.defaultdict(list)\n        and compute means and standard deviations at the end. But thanks to the\n        clever math in Sutton-Barto\n        (http://www.incompleteideas.net/book/first/ebook/node19.html) and\n        https://math.stackexchange.com/a/103025/5051 we can update both the\n        means and the stds online. O(1) FTW!\n        \"\"\"", "\n", "now", "=", "timeit", ".", "default_timer", "(", ")", "\n", "x", "=", "now", "-", "self", ".", "last_time", "\n", "self", ".", "last_time", "=", "now", "\n", "\n", "n", "=", "self", ".", "_counts", "[", "name", "]", "\n", "\n", "mean", "=", "self", ".", "_means", "[", "name", "]", "+", "(", "x", "-", "self", ".", "_means", "[", "name", "]", ")", "/", "(", "n", "+", "1", ")", "\n", "var", "=", "(", "\n", "n", "*", "self", ".", "_vars", "[", "name", "]", "+", "n", "*", "(", "self", ".", "_means", "[", "name", "]", "-", "mean", ")", "**", "2", "+", "(", "x", "-", "mean", ")", "**", "2", "\n", ")", "/", "(", "n", "+", "1", ")", "\n", "\n", "self", ".", "_means", "[", "name", "]", "=", "mean", "\n", "self", ".", "_vars", "[", "name", "]", "=", "var", "\n", "self", ".", "_counts", "[", "name", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.means": [[58, 60], ["None"], "methods", ["None"], ["", "def", "means", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_means", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.vars": [[61, 63], ["None"], "methods", ["None"], ["", "def", "vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.stds": [[64, 66], ["prof.Timings._vars.items"], "methods", ["None"], ["", "def", "stds", "(", "self", ")", ":", "\n", "        ", "return", "{", "k", ":", "v", "**", "0.5", "for", "k", ",", "v", "in", "self", ".", "_vars", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary": [[67, 82], ["prof.Timings.means", "prof.Timings.stds", "sum", "sorted", "prof.Timings.values"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.means", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.stds"], ["", "def", "summary", "(", "self", ",", "prefix", "=", "\"\"", ")", ":", "\n", "        ", "means", "=", "self", ".", "means", "(", ")", "\n", "stds", "=", "self", ".", "stds", "(", ")", "\n", "total", "=", "sum", "(", "means", ".", "values", "(", ")", ")", "\n", "\n", "result", "=", "prefix", "\n", "for", "k", "in", "sorted", "(", "means", ",", "key", "=", "means", ".", "get", ",", "reverse", "=", "True", ")", ":", "\n", "            ", "result", "+=", "f\"\\n    %s: %.6fms +- %.6fms (%.2f%%) \"", "%", "(", "\n", "k", ",", "\n", "1000", "*", "means", "[", "k", "]", ",", "\n", "1000", "*", "stds", "[", "k", "]", ",", "\n", "100", "*", "means", "[", "k", "]", "/", "total", ",", "\n", ")", "\n", "", "result", "+=", "\"\\nTotal: %.6fms\"", "%", "(", "1000", "*", "total", ")", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.__init__": [[66, 174], ["file_writer.gather_metadata", "copy.deepcopy", "logging.Formatter", "logging.getLogger", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "file_writer.FileWriter._logger.addHandler", "file_writer.FileWriter._logger.setLevel", "os.path.expandvars", "os.path.join", "dict", "file_writer.FileWriter._logger.info", "os.path.exists", "file_writer.FileWriter._logger.info", "os.path.exists", "logging.FileHandler", "logging.FileHandler.setFormatter", "file_writer.FileWriter._logger.addHandler", "file_writer.FileWriter._logger.info", "file_writer.FileWriter._logger.info", "os.path.exists", "open", "csv.writer", "open", "csv.DictWriter", "os.path.expanduser", "os.path.exists", "file_writer.FileWriter._logger.info", "os.makedirs", "file_writer.FileWriter._logger.info", "os.path.join", "file_writer.FileWriter._logger.warning", "file_writer.FileWriter._save_metadata", "file_writer.FileWriter._logger.warning", "file_writer.FileWriter._logger.warning", "os.path.islink", "open", "csv.reader", "list", "open", "csv.reader", "list", "os.getpid", "int", "os.remove", "os.path.exists", "os.symlink", "file_writer.FileWriter._logger.info", "len", "len", "time.time", "int"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.gather_metadata", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter._save_metadata", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "xpid", ":", "str", "=", "None", ",", "\n", "xp_args", ":", "dict", "=", "None", ",", "\n", "rootdir", ":", "str", "=", "\"~/logs\"", ",", "\n", "symlink_to_latest", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "if", "not", "xpid", ":", "\n", "# Make unique id.", "\n", "            ", "xpid", "=", "\"{proc}_{unixtime}\"", ".", "format", "(", "\n", "proc", "=", "os", ".", "getpid", "(", ")", ",", "unixtime", "=", "int", "(", "time", ".", "time", "(", ")", ")", "\n", ")", "\n", "", "self", ".", "xpid", "=", "xpid", "\n", "self", ".", "_tick", "=", "0", "\n", "\n", "# Metadata gathering.", "\n", "if", "xp_args", "is", "None", ":", "\n", "            ", "xp_args", "=", "{", "}", "\n", "", "self", ".", "metadata", "=", "gather_metadata", "(", ")", "\n", "# We need to copy the args, otherwise when we close the file writer", "\n", "# (and rewrite the args) we might have non-serializable objects (or", "\n", "# other unwanted side-effects).", "\n", "self", ".", "metadata", "[", "\"args\"", "]", "=", "copy", ".", "deepcopy", "(", "xp_args", ")", "\n", "self", ".", "metadata", "[", "\"xpid\"", "]", "=", "self", ".", "xpid", "\n", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "\"%(message)s\"", ")", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "\"logs/out\"", ")", "\n", "\n", "# To stdout handler.", "\n", "shandle", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "shandle", ".", "setFormatter", "(", "formatter", ")", "\n", "self", ".", "_logger", ".", "addHandler", "(", "shandle", ")", "\n", "self", ".", "_logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "rootdir", "=", "os", ".", "path", ".", "expandvars", "(", "os", ".", "path", ".", "expanduser", "(", "rootdir", ")", ")", "\n", "# To file handler.", "\n", "self", ".", "basepath", "=", "os", ".", "path", ".", "join", "(", "rootdir", ",", "self", ".", "xpid", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "basepath", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Creating log directory: %s\"", ",", "self", ".", "basepath", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "basepath", ",", "exist_ok", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Found log directory: %s\"", ",", "self", ".", "basepath", ")", "\n", "\n", "", "if", "symlink_to_latest", ":", "\n", "# Add 'latest' as symlink unless it exists and is no symlink.", "\n", "            ", "symlink", "=", "os", ".", "path", ".", "join", "(", "rootdir", ",", "\"latest\"", ")", "\n", "try", ":", "\n", "                ", "if", "os", ".", "path", ".", "islink", "(", "symlink", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "symlink", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "symlink", ")", ":", "\n", "                    ", "os", ".", "symlink", "(", "self", ".", "basepath", ",", "symlink", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Symlinked log directory: %s\"", ",", "symlink", ")", "\n", "", "", "except", "OSError", ":", "\n", "# os.remove() or os.symlink() raced. Don't do anything.", "\n", "                ", "pass", "\n", "\n", "", "", "self", ".", "paths", "=", "dict", "(", "\n", "msg", "=", "\"{base}/out.log\"", ".", "format", "(", "base", "=", "self", ".", "basepath", ")", ",", "\n", "logs", "=", "\"{base}/logs.csv\"", ".", "format", "(", "base", "=", "self", ".", "basepath", ")", ",", "\n", "fields", "=", "\"{base}/fields.csv\"", ".", "format", "(", "base", "=", "self", ".", "basepath", ")", ",", "\n", "meta", "=", "\"{base}/meta.json\"", ".", "format", "(", "base", "=", "self", ".", "basepath", ")", ",", "\n", ")", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving arguments to %s\"", ",", "self", ".", "paths", "[", "\"meta\"", "]", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "paths", "[", "\"meta\"", "]", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\n", "\"Path to meta file already exists. \"", "\"Not overriding meta.\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_save_metadata", "(", ")", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Saving messages to %s\"", ",", "self", ".", "paths", "[", "\"msg\"", "]", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "paths", "[", "\"msg\"", "]", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\n", "\"Path to message file already exists. \"", "\"New data will be appended.\"", "\n", ")", "\n", "\n", "", "fhandle", "=", "logging", ".", "FileHandler", "(", "self", ".", "paths", "[", "\"msg\"", "]", ")", "\n", "fhandle", ".", "setFormatter", "(", "formatter", ")", "\n", "self", ".", "_logger", ".", "addHandler", "(", "fhandle", ")", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving logs data to %s\"", ",", "self", ".", "paths", "[", "\"logs\"", "]", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving logs' fields to %s\"", ",", "self", ".", "paths", "[", "\"fields\"", "]", ")", "\n", "self", ".", "fieldnames", "=", "[", "\"_tick\"", ",", "\"_time\"", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "paths", "[", "\"logs\"", "]", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\n", "\"Path to log file already exists. \"", "\"New data will be appended.\"", "\n", ")", "\n", "# Override default fieldnames.", "\n", "with", "open", "(", "self", ".", "paths", "[", "\"fields\"", "]", ",", "\"r\"", ")", "as", "csvfile", ":", "\n", "                ", "reader", "=", "csv", ".", "reader", "(", "csvfile", ")", "\n", "lines", "=", "list", "(", "reader", ")", "\n", "if", "len", "(", "lines", ")", ">", "0", ":", "\n", "                    ", "self", ".", "fieldnames", "=", "lines", "[", "-", "1", "]", "\n", "# Override default tick: use the last tick from the logs file plus 1.", "\n", "", "", "with", "open", "(", "self", ".", "paths", "[", "\"logs\"", "]", ",", "\"r\"", ")", "as", "csvfile", ":", "\n", "                ", "reader", "=", "csv", ".", "reader", "(", "csvfile", ")", "\n", "lines", "=", "list", "(", "reader", ")", "\n", "# Need at least two lines in order to read the last tick:", "\n", "# the first is the csv header and the second is the first line", "\n", "# of data.", "\n", "if", "len", "(", "lines", ")", ">", "1", ":", "\n", "                    ", "self", ".", "_tick", "=", "int", "(", "lines", "[", "-", "1", "]", "[", "0", "]", ")", "+", "1", "\n", "\n", "", "", "", "self", ".", "_fieldfile", "=", "open", "(", "self", ".", "paths", "[", "\"fields\"", "]", ",", "\"a\"", ")", "\n", "self", ".", "_fieldwriter", "=", "csv", ".", "writer", "(", "self", ".", "_fieldfile", ")", "\n", "self", ".", "_logfile", "=", "open", "(", "self", ".", "paths", "[", "\"logs\"", "]", ",", "\"a\"", ")", "\n", "self", ".", "_logwriter", "=", "csv", ".", "DictWriter", "(", "self", ".", "_logfile", ",", "fieldnames", "=", "self", ".", "fieldnames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.log": [[175, 202], ["time.time", "len", "file_writer.FileWriter._logwriter.writerow", "file_writer.FileWriter._logfile.flush", "len", "file_writer.FileWriter._fieldwriter.writerow", "file_writer.FileWriter._logger.info", "file_writer.FileWriter._logfile.write", "file_writer.FileWriter._logger.info", "file_writer.FileWriter.fieldnames.append", "sorted"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["", "def", "log", "(", "self", ",", "to_log", ":", "Dict", ",", "tick", ":", "int", "=", "None", ",", "verbose", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "if", "tick", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "to_log", "[", "\"_tick\"", "]", "=", "self", ".", "_tick", "\n", "self", ".", "_tick", "+=", "1", "\n", "", "to_log", "[", "\"_time\"", "]", "=", "time", ".", "time", "(", ")", "\n", "\n", "old_len", "=", "len", "(", "self", ".", "fieldnames", ")", "\n", "for", "k", "in", "to_log", ":", "\n", "            ", "if", "k", "not", "in", "self", ".", "fieldnames", ":", "\n", "                ", "self", ".", "fieldnames", ".", "append", "(", "k", ")", "\n", "", "", "if", "old_len", "!=", "len", "(", "self", ".", "fieldnames", ")", ":", "\n", "            ", "self", ".", "_fieldwriter", ".", "writerow", "(", "self", ".", "fieldnames", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Updated log fields: %s\"", ",", "self", ".", "fieldnames", ")", "\n", "\n", "", "if", "to_log", "[", "\"_tick\"", "]", "==", "0", ":", "\n", "            ", "self", ".", "_logfile", ".", "write", "(", "\"# %s\\n\"", "%", "\",\"", ".", "join", "(", "self", ".", "fieldnames", ")", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\n", "\"LOG | %s\"", ",", "\n", "\", \"", ".", "join", "(", "[", "\"{}: {}\"", ".", "format", "(", "k", ",", "to_log", "[", "k", "]", ")", "for", "k", "in", "sorted", "(", "to_log", ")", "]", ")", ",", "\n", ")", "\n", "\n", "", "self", ".", "_logwriter", ".", "writerow", "(", "to_log", ")", "\n", "self", ".", "_logfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.close": [[203, 212], ["datetime.datetime.now().strftime", "file_writer.FileWriter._save_metadata", "f.close", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter._save_metadata", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close"], ["", "def", "close", "(", "self", ",", "successful", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "self", ".", "metadata", "[", "\"date_end\"", "]", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\n", "\"%Y-%m-%d %H:%M:%S.%f\"", "\n", ")", "\n", "self", ".", "metadata", "[", "\"successful\"", "]", "=", "successful", "\n", "self", ".", "_save_metadata", "(", ")", "\n", "\n", "for", "f", "in", "[", "self", ".", "_logfile", ",", "self", ".", "_fieldfile", "]", ":", "\n", "            ", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter._save_metadata": [[213, 216], ["open", "json.dump"], "methods", ["None"], ["", "", "def", "_save_metadata", "(", "self", ")", "->", "None", ":", "\n", "        ", "with", "open", "(", "self", ".", "paths", "[", "\"meta\"", "]", ",", "\"w\"", ")", "as", "jsonfile", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "metadata", ",", "jsonfile", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.gather_metadata": [[27, 62], ["datetime.datetime.now().strftime", "dict", "datetime.datetime.now", "git.Repo", "dict", "k.replace().replace().lower", "os.environ.copy", "git.Repo.commit", "k.startswith", "git.Repo.is_dirty", "k.replace().replace", "k.replace"], "function", ["None"], ["def", "gather_metadata", "(", ")", "->", "Dict", ":", "\n", "    ", "date_start", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S.%f\"", ")", "\n", "# Gathering git metadata.", "\n", "try", ":", "\n", "        ", "import", "git", "\n", "\n", "try", ":", "\n", "            ", "repo", "=", "git", ".", "Repo", "(", "search_parent_directories", "=", "True", ")", "\n", "git_sha", "=", "repo", ".", "commit", "(", ")", ".", "hexsha", "\n", "git_data", "=", "dict", "(", "\n", "commit", "=", "git_sha", ",", "\n", "branch", "=", "None", "if", "repo", ".", "head", ".", "is_detached", "else", "repo", ".", "active_branch", ".", "name", ",", "\n", "is_dirty", "=", "repo", ".", "is_dirty", "(", ")", ",", "\n", "path", "=", "repo", ".", "git_dir", ",", "\n", ")", "\n", "", "except", "git", ".", "InvalidGitRepositoryError", ":", "\n", "            ", "git_data", "=", "None", "\n", "", "", "except", "ImportError", ":", "\n", "        ", "git_data", "=", "None", "\n", "# Gathering slurm metadata.", "\n", "", "if", "\"SLURM_JOB_ID\"", "in", "os", ".", "environ", ":", "\n", "        ", "slurm_env_keys", "=", "[", "k", "for", "k", "in", "os", ".", "environ", "if", "k", ".", "startswith", "(", "\"SLURM\"", ")", "]", "\n", "slurm_data", "=", "{", "}", "\n", "for", "k", "in", "slurm_env_keys", ":", "\n", "            ", "d_key", "=", "k", ".", "replace", "(", "\"SLURM_\"", ",", "\"\"", ")", ".", "replace", "(", "\"SLURMD_\"", ",", "\"\"", ")", ".", "lower", "(", ")", "\n", "slurm_data", "[", "d_key", "]", "=", "os", ".", "environ", "[", "k", "]", "\n", "", "", "else", ":", "\n", "        ", "slurm_data", "=", "None", "\n", "", "return", "dict", "(", "\n", "date_start", "=", "date_start", ",", "\n", "date_end", "=", "None", ",", "\n", "successful", "=", "False", ",", "\n", "git", "=", "git_data", ",", "\n", "slurm", "=", "slurm_data", ",", "\n", "env", "=", "os", ".", "environ", ".", "copy", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.__init__": [[25, 29], ["None"], "methods", ["None"], ["(", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ")", ",", "# Strafe Right", "\n", "(", "-", "20", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ")", ",", "# Look Left", "\n", "(", "20", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ")", ",", "# Look Right", "\n", "(", "-", "20", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ")", ",", "# Look Left + Forward", "\n", "(", "20", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ")", ",", "# Look Right + Forward", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial": [[30, 45], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "environment._format_frame", "dict", "environment.Environment.gym_env.reset"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment._format_frame", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset"], ["(", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ")", ",", "# Fire.", "\n", ")", "\n", "\n", "\n", "def", "_format_frame", "(", "frame", ")", ":", "\n", "    ", "frame", "=", "torch", ".", "from_numpy", "(", "frame", ")", "\n", "return", "frame", ".", "view", "(", "(", "1", ",", "1", ")", "+", "frame", ".", "shape", ")", "# (...) -> (T,B,...).", "\n", "\n", "\n", "", "class", "Environment", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "gym_env", ")", ":", "\n", "        ", "self", ".", "gym_env", "=", "gym_env", "\n", "self", ".", "episode_return", "=", "None", "\n", "self", ".", "episode_step", "=", "None", "\n", "\n", "", "def", "initial", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.step": [[47, 69], ["environment.Environment.gym_env.step", "environment._format_frame", "torch.tensor().view", "torch.tensor().view", "dict", "action.item", "environment.Environment.gym_env.reset", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment._format_frame", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset"], ["# This supports only single-tensor actions ATM.", "\n", "initial_last_action", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "self", ".", "episode_return", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", "\n", "self", ".", "episode_step", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "initial_done", "=", "torch", ".", "ones", "(", "1", ",", "1", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "###### changed reset to inital to match the format of createDMLab", "\n", "initial_frame", "=", "_format_frame", "(", "self", ".", "gym_env", ".", "initial", "(", ")", ")", "\n", "return", "dict", "(", "\n", "frame", "=", "initial_frame", ",", "\n", "reward", "=", "initial_reward", ",", "\n", "done", "=", "initial_done", ",", "\n", "episode_return", "=", "self", ".", "episode_return", ",", "\n", "episode_step", "=", "self", ".", "episode_step", ",", "\n", "last_action", "=", "initial_last_action", ",", "\n", ")", "\n", "\n", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "######## changed actions from int to one of the default_action_set above", "\n", "        ", "raw_action", "=", "np", ".", "array", "(", "DEFAULT_ACTION_SET", "[", "action", "]", ",", "dtype", "=", "np", ".", "intc", ")", "\n", "frame", ",", "reward", ",", "done", "=", "self", ".", "gym_env", ".", "step", "(", "raw_action", ")", "\n", "self", ".", "episode_step", "+=", "1", "\n", "self", ".", "episode_return", "+=", "reward", "\n", "episode_step", "=", "self", ".", "episode_step", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close": [[71, 73], ["environment.Environment.gym_env.close"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close"], ["if", "done", ":", "\n", "            ", "frame", "=", "self", ".", "gym_env", ".", "initial", "(", ")", "\n", "self", ".", "episode_return", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment._format_frame": [[19, 22], ["torch.from_numpy", "torch.from_numpy.view"], "function", ["None"], ["\n", "########## The set of actions that can go as input to the DMLAB step", "\n", "DEFAULT_ACTION_SET", "=", "(", "\n", "(", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ")", ",", "# Forward", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.AdaptiveEmbedding.__init__": [[18, 43], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ParameterList", "range", "min", "max", "len", "len", "adaptive_io.AdaptiveEmbedding.emb_layers.append", "adaptive_io.AdaptiveEmbedding.emb_projs.append", "torch.nn.Embedding", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["def", "__init__", "(", "self", ",", "n_tokens", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "4", ")", ":", "\n", "        ", "super", "(", "AdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_tokens", "=", "n_tokens", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "assert", "0", "<", "min", "(", "cutoffs", ")", "<=", "max", "(", "cutoffs", ")", "<", "n_tokens", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_tokens", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "assert", "self", ".", "div_val", ">", "1", "\n", "assert", "len", "(", "self", ".", "cutoffs", ")", ">", "1", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "emb_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "emb_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "# embedding layers / projections", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "            ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "nn", ".", "Embedding", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ")", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "d_proj", ")", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.AdaptiveEmbedding.forward": [[44, 74], ["indices.contiguous().view", "torch.zeros", "range", "torch.zeros.view", "torch.zeros.view.mul_", "len", "mask_i.nonzero().squeeze", "torch.nn.functional.linear", "torch.zeros.index_copy_", "indices.contiguous", "indices.contiguous().view.size", "mask_i.nonzero().squeeze.numel", "indices.contiguous().view.index_select", "torch.zeros.type_as", "indices.size", "mask_i.nonzero"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "indices", ")", ":", "\n", "        ", "param", "=", "self", ".", "emb_layers", "[", "0", "]", ".", "weight", ".", "data", "\n", "idx_flat", "=", "indices", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "emb_flat", "=", "torch", ".", "zeros", "(", "[", "idx_flat", ".", "size", "(", "0", ")", ",", "self", ".", "d_proj", "]", ",", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "\n", "# for each cluster", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "# find elements in that cluster", "\n", "            ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "mask_i", "=", "(", "idx_flat", ">=", "l_idx", ")", "&", "(", "idx_flat", "<", "r_idx", ")", "\n", "\n", "# if there are no elements, continue", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "# add embeddings from this cluster", "\n", "", "idx_i", "=", "idx_flat", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "idx_i", ")", "\n", "emb_i", "=", "F", ".", "linear", "(", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "emb_flat", "=", "emb_flat", ".", "type_as", "(", "emb_i", ")", "if", "emb_flat", ".", "dtype", "!=", "emb_i", ".", "dtype", "else", "emb_flat", "# small hack for AMP-O1", "\n", "emb_flat", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "emb_i", ")", "\n", "\n", "# reshape embeddings", "\n", "", "embed", "=", "emb_flat", ".", "view", "(", "*", "indices", ".", "size", "(", ")", ",", "self", ".", "d_proj", ")", "\n", "\n", "# rescale embeddings", "\n", "embed", ".", "mul_", "(", "self", ".", "emb_scale", ")", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.ProjectedAdaptiveLogSoftmax.__init__": [[79, 109], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ParameterList", "range", "min", "max", "len", "len", "len", "adaptive_io.ProjectedAdaptiveLogSoftmax.out_projs.append", "adaptive_io.ProjectedAdaptiveLogSoftmax.out_layers.append", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["def", "__init__", "(", "self", ",", "n_tokens", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "4", ")", ":", "\n", "        ", "super", "(", "ProjectedAdaptiveLogSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_tokens", "=", "n_tokens", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "assert", "0", "<", "min", "(", "cutoffs", ")", "<=", "max", "(", "cutoffs", ")", "<", "n_tokens", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_tokens", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "assert", "self", ".", "div_val", ">", "1", "\n", "assert", "len", "(", "self", ".", "cutoffs", ")", ">", "1", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "\n", "# clusters parameters", "\n", "self", ".", "cluster_proj", "=", "nn", ".", "Linear", "(", "self", ".", "d_embed", ",", "self", ".", "n_clusters", ")", "\n", "\n", "self", ".", "out_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "# output layers / projections", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "            ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "out_projs", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "d_proj", ")", ".", "weight", ")", "\n", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "r_idx", "-", "l_idx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit": [[110, 114], ["torch.nn.functional.linear", "torch.nn.functional.linear", "proj.t().contiguous", "proj.t"], "methods", ["None"], ["", "", "def", "_compute_logit", "(", "self", ",", "hidden", ",", "weight", ",", "bias", ",", "proj", ")", ":", "\n", "        ", "proj_hid", "=", "F", ".", "linear", "(", "hidden", ",", "proj", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "# TODO: .contiguous() not necessary?", "\n", "logit", "=", "F", ".", "linear", "(", "proj_hid", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.ProjectedAdaptiveLogSoftmax.forward": [[115, 182], ["hidden.view.view.view", "target.view.view.view", "range", "adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.nn.functional.log_softmax", "torch.zeros_like", "range", "torch.zeros_like.view", "len", "weights.append", "biases.append", "adaptive_io.ProjectedAdaptiveLogSoftmax.float", "mask_i.nonzero().squeeze", "torch.nn.functional.log_softmax.index_select", "torch.zeros_like.index_copy_", "head_logprob.index_select.gather().squeeze.size", "torch.cat", "torch.cat", "len", "mask_i.nonzero().squeeze.numel", "target.view.view.index_select", "F.log_softmax.index_select.gather().squeeze", "hidden.view.view.index_select", "adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.nn.functional.log_softmax", "mask_i.nonzero", "adaptive_io.ProjectedAdaptiveLogSoftmax.float", "torch.nn.functional.log_softmax.gather().squeeze", "F.log_softmax.index_select.gather", "torch.nn.functional.log_softmax.gather"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Input:\n            - `hidden` FloatTensor(shape + (d_proj,))\n            - `target` LongTensor(shape)\n        Output:\n            - `nll` FloatTensor(shape)\n        \"\"\"", "\n", "assert", "hidden", ".", "shape", "[", "-", "1", "]", "==", "self", ".", "d_proj", "\n", "assert", "hidden", ".", "shape", "[", ":", "-", "1", "]", "==", "target", ".", "shape", "\n", "shape", "=", "target", ".", "shape", "\n", "hidden", "=", "hidden", ".", "view", "(", "-", "1", ",", "self", ".", "d_proj", ")", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "\n", "# construct weights and biases", "\n", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "            ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "if", "i", "==", "0", ":", "\n", "                ", "weight_i", "=", "torch", ".", "cat", "(", "[", "weight_i", ",", "self", ".", "cluster_proj", ".", "weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "[", "bias_i", ",", "self", ".", "cluster_proj", ".", "bias", "]", ",", "dim", "=", "0", ")", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "# head / cluster assignments", "\n", "", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# final log-probabilities", "\n", "nll", "=", "torch", ".", "zeros_like", "(", "target", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "hidden", ".", "device", ")", "\n", "\n", "offset", "=", "0", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "# for each cluster", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "\n", "# select the target tokens in that cluster", "\n", "            ", "l_idx", ",", "r_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "mask_i", "=", "(", "target", ">=", "l_idx", ")", "&", "(", "target", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "# if there are not any, there is nothing to do", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "# index in current cluster", "\n", "", "target_i", "=", "target", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "head_logprob_i", "=", "head_logprob", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "# for targets in the head cluster, there is just the head score", "\n", "                ", "logprob_i", "=", "head_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# otherwise, we sum the cluster assignment (head) and target scores", "\n", "                ", "hidden_i", "=", "hidden", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden_i", ",", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "logprob_i", "=", "head_logprob_i", "[", ":", ",", "-", "i", "]", "+", "tail_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "# populate output", "\n", "", "nll", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "-", "logprob_i", ")", "\n", "\n", "offset", "+=", "logprob_i", ".", "size", "(", "0", ")", "\n", "\n", "", "return", "nll", ".", "view", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.compute_dummy_loss": [[184, 194], ["sum", "sum", "sum", "sum", "sum"], "function", ["None"], ["", "", "def", "compute_dummy_loss", "(", "in_emb", ",", "out_emb", ")", ":", "\n", "# hack to fix adaptive ou/in with distributed code", "\n", "    ", "dummy_loss", "=", "0", "*", "(", "\n", "sum", "(", "x", ".", "weight", "[", "0", ",", "0", "]", "for", "x", "in", "in_emb", ".", "emb_layers", ")", "+", "\n", "sum", "(", "x", "[", "0", ",", "0", "]", "for", "x", "in", "in_emb", ".", "emb_projs", ")", "+", "\n", "sum", "(", "x", "[", "0", ",", "0", "]", "for", "x", "in", "out_emb", ".", "out_projs", ")", "+", "\n", "sum", "(", "x", ".", "weight", "[", "0", ",", "0", "]", "for", "x", "in", "out_emb", ".", "out_layers", ")", "+", "\n", "sum", "(", "x", ".", "bias", "[", "0", "]", "for", "x", "in", "out_emb", ".", "out_layers", ")", "\n", ")", "\n", "return", "dummy_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_io.build_adaptive_io": [[196, 211], ["adaptive_io.AdaptiveEmbedding", "adaptive_io.ProjectedAdaptiveLogSoftmax", "range", "len"], "function", ["None"], ["", "def", "build_adaptive_io", "(", "vocab_size", ",", "hidden_size", ",", "adapt_io_cutoffs", ",", "\n", "adapt_io_divval", ",", "adapt_io_tied", ",", "**", "kargs", ")", ":", "\n", "    ", "in_emb", "=", "AdaptiveEmbedding", "(", "\n", "vocab_size", ",", "hidden_size", ",", "hidden_size", ",", "\n", "cutoffs", "=", "adapt_io_cutoffs", ",", "\n", "div_val", "=", "adapt_io_divval", ")", "\n", "out_emb", "=", "ProjectedAdaptiveLogSoftmax", "(", "\n", "vocab_size", ",", "hidden_size", ",", "hidden_size", ",", "\n", "cutoffs", "=", "adapt_io_cutoffs", ",", "\n", "div_val", "=", "adapt_io_divval", ")", "\n", "if", "adapt_io_tied", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "adapt_io_cutoffs", ")", "+", "1", ")", ":", "\n", "            ", "out_emb", ".", "out_layers", "[", "i", "]", ".", "weight", "=", "in_emb", ".", "emb_layers", "[", "i", "]", ".", "weight", "\n", "out_emb", ".", "out_projs", "[", "i", "]", "=", "in_emb", ".", "emb_projs", "[", "i", "]", "\n", "", "", "return", "in_emb", ",", "out_emb", "\n", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.SeqAttention.__init__": [[54, 71], ["torch.Module.__init__", "torch.Module.__init__", "torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "adaptive_span2.adaptive_span.AdaptiveSpan", "adaptive_span2.persistent_memory.PersistentMemory"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "nb_heads", ",", "attn_span", ",", "\n", "dropout", ",", "adapt_span_params", ",", "pers_mem_params", ",", "**", "kargs", ")", ":", "\n", "        ", "nn", ".", "Module", ".", "__init__", "(", "self", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "# size of a single head", "\n", "self", ".", "attn_span", "=", "attn_span", "\n", "self", ".", "adapt_span_enabled", "=", "adapt_span_params", "[", "'adapt_span_enabled'", "]", "\n", "if", "self", ".", "adapt_span_enabled", ":", "\n", "            ", "self", ".", "adaptive_span", "=", "AdaptiveSpan", "(", "attn_span", "=", "attn_span", ",", "nb_heads", "=", "nb_heads", ",", "\n", "**", "adapt_span_params", ",", "**", "kargs", ")", "\n", "\n", "", "self", ".", "persistent_memory", "=", "None", "\n", "if", "pers_mem_params", "[", "'pers_mem_size'", "]", ">", "0", ":", "\n", "            ", "self", ".", "persistent_memory", "=", "PersistentMemory", "(", "\n", "pers_mem_params", "[", "'pers_mem_size'", "]", ",", "nb_heads", ",", "hidden_size", ",", "dropout", ")", "\n", "if", "self", ".", "adapt_span_enabled", ":", "\n", "                ", "self", ".", "persistent_memory", ".", "adaptive_span", "=", "self", ".", "adaptive_span", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.SeqAttention.forward": [[72, 111], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "models._unskew", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "models.SeqAttention.dropout", "models._skew", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "models.SeqAttention.adaptive_span.trim_memory", "key.transpose", "models.SeqAttention.persistent_memory", "torch.softmax", "torch.softmax", "torch.softmax", "math.sqrt", "models.SeqAttention.adaptive_span"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models._unskew", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models._skew", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.trim_memory"], ["", "", "", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_pe", ")", ":", "\n", "# query size = B x M x H", "\n", "# key, value sizes = B x (M+L) x H", "\n", "\n", "        ", "if", "self", ".", "adapt_span_enabled", ":", "\n", "# [optional] trim out memory to reduce unnecessary computation", "\n", "            ", "key", ",", "value", ",", "key_pe", "=", "self", ".", "adaptive_span", ".", "trim_memory", "(", "\n", "query", ",", "key", ",", "value", ",", "key_pe", ")", "\n", "\n", "# compute attention from context", "\n", "# B x M (dest) x (M+L) (src)", "\n", "", "attn_cont", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attn_cont", "=", "_unskew", "(", "attn_cont", ")", "# B x M x L", "\n", "\n", "attn_cont", "[", "attn_cont", "==", "0", "]", "=", "-", "1e6", "#don't want to attend to padding.", "\n", "\n", "# compute the effect of position embedding", "\n", "attn_pos", "=", "torch", ".", "matmul", "(", "query", ",", "key_pe", ")", "# B x M x L_pos", "\n", "attn", "=", "attn_cont", "+", "attn_pos", "\n", "\n", "if", "self", ".", "persistent_memory", "is", "not", "None", ":", "\n", "            ", "attn", ",", "pers_mem_out", "=", "self", ".", "persistent_memory", "(", "query", ",", "attn", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "attn", "/", "math", ".", "sqrt", "(", "self", ".", "hidden_size", ")", "# B x M X L_pos", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "adapt_span_enabled", ":", "\n", "# trim attention lengths according to the learned span", "\n", "                ", "attn", "=", "self", ".", "adaptive_span", "(", "attn", ")", "\n", "\n", "", "", "attn", "=", "self", ".", "dropout", "(", "attn", ")", "# B x M X L_pos", "\n", "\n", "attn_cont", "=", "_skew", "(", "attn", ",", "0", ")", "# B x M X (L+M)", "\n", "out", "=", "torch", ".", "matmul", "(", "attn_cont", ",", "value", ")", "# B x M x H", "\n", "\n", "if", "self", ".", "persistent_memory", "is", "not", "None", ":", "\n", "            ", "out", "=", "out", "+", "pers_mem_out", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.SeqAttention.get_cache_size": [[112, 117], ["models.SeqAttention.adaptive_span.get_cache_size"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_cache_size"], ["", "def", "get_cache_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "adapt_span_enabled", ":", "\n", "            ", "return", "self", ".", "adaptive_span", ".", "get_cache_size", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "attn_span", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.MultiHeadSeqAttention.__init__": [[120, 131], ["torch.Module.__init__", "torch.Module.__init__", "torch.Module.__init__", "models.SeqAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "nb_heads", ",", "**", "kargs", ")", ":", "\n", "        ", "nn", ".", "Module", ".", "__init__", "(", "self", ")", "\n", "assert", "hidden_size", "%", "nb_heads", "==", "0", "\n", "self", ".", "nb_heads", "=", "nb_heads", "\n", "self", ".", "head_dim", "=", "hidden_size", "//", "nb_heads", "\n", "self", ".", "attn", "=", "SeqAttention", "(", "\n", "hidden_size", "=", "self", ".", "head_dim", ",", "nb_heads", "=", "nb_heads", ",", "**", "kargs", ")", "\n", "self", ".", "proj_query", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "proj_out", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "proj_val", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "proj_key", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.MultiHeadSeqAttention.head_reshape": [[132, 139], ["x.view.view.view", "x.view.view.transpose().contiguous", "x.view.view.view", "x.view.view.size", "x.view.view.size", "x.view.view.transpose", "x.view.view.size"], "methods", ["None"], ["", "def", "head_reshape", "(", "self", ",", "x", ")", ":", "\n", "        ", "K", "=", "self", ".", "nb_heads", "\n", "D", "=", "self", ".", "head_dim", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "K", ",", "D", ")", ")", "# B x (M+L) x K x D", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "# B x K x (M+L) x D", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "2", ")", ",", "x", ".", "size", "(", "-", "1", ")", ")", "# B_K x (M+L) x D", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.MultiHeadSeqAttention.forward": [[140, 159], ["models.MultiHeadSeqAttention.size", "models.MultiHeadSeqAttention.size", "models.MultiHeadSeqAttention.proj_query", "models.MultiHeadSeqAttention.head_reshape", "models.MultiHeadSeqAttention.proj_val", "models.MultiHeadSeqAttention.head_reshape", "models.MultiHeadSeqAttention.proj_key", "models.MultiHeadSeqAttention.head_reshape", "models.MultiHeadSeqAttention.attn", "models.MultiHeadSeqAttention.view", "models.MultiHeadSeqAttention.transpose().contiguous", "models.MultiHeadSeqAttention.view", "models.MultiHeadSeqAttention.proj_out", "models.MultiHeadSeqAttention.transpose"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.MultiHeadSeqAttention.head_reshape", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.MultiHeadSeqAttention.head_reshape", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.MultiHeadSeqAttention.head_reshape"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_pe", ")", ":", "\n", "        ", "B", "=", "query", ".", "size", "(", "0", ")", "\n", "K", "=", "self", ".", "nb_heads", "\n", "D", "=", "self", ".", "head_dim", "\n", "M", "=", "query", ".", "size", "(", "1", ")", "\n", "\n", "query", "=", "self", ".", "proj_query", "(", "query", ")", "\n", "query", "=", "self", ".", "head_reshape", "(", "query", ")", "\n", "value", "=", "self", ".", "proj_val", "(", "value", ")", "\n", "value", "=", "self", ".", "head_reshape", "(", "value", ")", "\n", "key", "=", "self", ".", "proj_key", "(", "key", ")", "\n", "key", "=", "self", ".", "head_reshape", "(", "key", ")", "\n", "\n", "out", "=", "self", ".", "attn", "(", "query", ",", "key", ",", "value", ",", "key_pe", ")", "# B_K x M x D", "\n", "out", "=", "out", ".", "view", "(", "B", ",", "K", ",", "M", ",", "D", ")", "# B x K x M x D", "\n", "out", "=", "out", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "# B x M x K x D", "\n", "out", "=", "out", ".", "view", "(", "B", ",", "M", ",", "-", "1", ")", "# B x M x K_D", "\n", "out", "=", "self", ".", "proj_out", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.FeedForwardLayer.__init__": [[162, 167], ["torch.Module.__init__", "torch.Module.__init__", "torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "inner_hidden_size", ",", "dropout", ",", "**", "kargs", ")", ":", "\n", "        ", "nn", ".", "Module", ".", "__init__", "(", "self", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "inner_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "inner_hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.FeedForwardLayer.forward": [[168, 174], ["torch.relu", "torch.relu", "torch.relu", "models.FeedForwardLayer.dropout", "models.FeedForwardLayer.fc2", "models.FeedForwardLayer.dropout", "models.FeedForwardLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ")", ":", "\n", "        ", "h1", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "h", ")", ")", "\n", "h1", "=", "self", ".", "dropout", "(", "h1", ")", "\n", "h2", "=", "self", ".", "fc2", "(", "h1", ")", "\n", "h2", "=", "self", ".", "dropout", "(", "h2", ")", "#ADDED THIS FOR DIRECT COMPARISON WITH TXL VERSION", "\n", "return", "h2", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeqLayer.__init__": [[177, 194], ["torch.Module.__init__", "torch.Module.__init__", "torch.Module.__init__", "models.MultiHeadSeqAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "models.FeedForwardLayer", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "StableTransformersReplication.transformer_xl.GRUGate", "StableTransformersReplication.transformer_xl.GRUGate"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "flags", ",", "**", "kargs", ")", ":", "\n", "        ", "nn", ".", "Module", ".", "__init__", "(", "self", ")", "\n", "self", ".", "attn", "=", "MultiHeadSeqAttention", "(", "hidden_size", "=", "hidden_size", ",", "**", "kargs", ")", "\n", "self", ".", "norm1", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ")", "\n", "if", "kargs", "[", "'pers_mem_params'", "]", "[", "'pers_mem_size'", "]", ">", "0", ":", "\n", "# replacing FF with persistent memory", "\n", "            ", "self", ".", "ff", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "ff", "=", "FeedForwardLayer", "(", "hidden_size", "=", "hidden_size", ",", "**", "kargs", ")", "\n", "self", ".", "norm2", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ")", "\n", "\n", "", "self", ".", "use_gate", "=", "flags", ".", "use_gate", "\n", "self", ".", "use_stable_version", "=", "True", "#use_stable_version", "\n", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "self", ".", "gate_mha", "=", "GRUGate", "(", "hidden_size", ")", "\n", "self", ".", "gate_mlp", "=", "GRUGate", "(", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeqLayer.forward_orig": [[195, 208], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.TransformerSeqLayer.attn", "models.TransformerSeqLayer.norm1", "models.TransformerSeqLayer.ff", "models.TransformerSeqLayer.norm2"], "methods", ["None"], ["", "", "def", "forward_orig", "(", "self", ",", "h", ",", "h_cache", ",", "key_pe", ",", "cache_size", ")", ":", "\n", "\n", "# h = B x M x H", "\n", "# h_cache = B x L x H", "\n", "        ", "h_all", "=", "torch", ".", "cat", "(", "[", "h_cache", ",", "h", "]", ",", "dim", "=", "1", ")", "# B x (M+L) x H", "\n", "attn_out", "=", "self", ".", "attn", "(", "h", ",", "h_all", ",", "h_all", ",", "key_pe", ")", "\n", "h", "=", "self", ".", "norm1", "(", "h", "+", "attn_out", ")", "# B x M x H", "\n", "if", "self", ".", "ff", "is", "not", "None", ":", "\n", "            ", "ff_out", "=", "self", ".", "ff", "(", "h", ")", "\n", "out", "=", "self", ".", "norm2", "(", "h", "+", "ff_out", ")", "# B x M x H", "\n", "", "else", ":", "\n", "            ", "out", "=", "h", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeqLayer.forward_stable": [[210, 239], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.TransformerSeqLayer.norm1", "models.TransformerSeqLayer.attn", "models.TransformerSeqLayer.norm2", "models.TransformerSeqLayer.ff", "models.TransformerSeqLayer.gate_mha", "models.TransformerSeqLayer.gate_mlp", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "def", "forward_stable", "(", "self", ",", "h", ",", "h_cache", ",", "key_pe", ",", "cache_size", ")", ":", "\n", "# Layer norm will be applied at start of MHA module on both dec_inp2 and mems", "\n", "\n", "#print('original h shape: ', h.shape)", "\n", "#To do this properly need to concat h_cache and h, then layer norm", "\n", "#then get slice of h back.", "\n", "        ", "h_all", "=", "torch", ".", "cat", "(", "[", "h_cache", ",", "h", "]", ",", "dim", "=", "1", ")", "# B x (M+L) x H", "\n", "h_all", "=", "self", ".", "norm1", "(", "h_all", ")", "\n", "h_normalized", "=", "h_all", "[", ":", ",", "-", "h", ".", "shape", "[", "1", "]", ":", ",", ":", "]", "\n", "#print('shape afer: ', h_normalized.shape)", "\n", "\n", "attn_out", "=", "self", ".", "attn", "(", "h_normalized", ",", "h_all", ",", "h_all", ",", "key_pe", ")", "#is dec_inp2", "\n", "\n", "# NOTE: In stable transformer they apply Relu before the layernorm/gate (in appendix C.3)", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "dec_inp2", "=", "self", ".", "gate_mha", "(", "h", ",", "F", ".", "relu", "(", "attn_out", ")", ")", "\n", "", "else", ":", "\n", "            ", "dec_inp2", "=", "h", "+", "F", ".", "relu", "(", "attn_out", ")", "\n", "\n", "", "dec_inp3", "=", "self", ".", "norm2", "(", "dec_inp2", ")", "\n", "\n", "dec_inp3", "=", "self", ".", "ff", "(", "dec_inp3", ")", "\n", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "dec_inp3", "=", "self", ".", "gate_mlp", "(", "dec_inp2", ",", "F", ".", "relu", "(", "dec_inp3", ")", ")", "\n", "", "else", ":", "\n", "            ", "dec_inp3", "=", "F", ".", "relu", "(", "dec_inp3", ")", "+", "dec_inp2", "\n", "\n", "", "return", "dec_inp3", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeqLayer.forward": [[240, 245], ["models.TransformerSeqLayer.forward_orig", "models.TransformerSeqLayer.forward_stable"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward_orig", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward_stable"], ["", "def", "forward", "(", "self", ",", "h", ",", "h_cache", ",", "key_pe", ",", "cache_size", ")", ":", "\n", "        ", "if", "self", ".", "use_stable_version", ":", "\n", "            ", "return", "self", ".", "forward_stable", "(", "h", ",", "h_cache", ",", "key_pe", ",", "cache_size", ")", "\n", "\n", "", "return", "self", ".", "forward_orig", "(", "h", ",", "h_cache", ",", "key_pe", ",", "cache_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.__init__": [[249, 264], ["torch.Module.__init__", "torch.Module.__init__", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "models.TransformerSeq.layers.extend", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "models.TransformerSeqLayer", "range"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "nb_heads", ",", "nb_layers", ",", "\n", "attn_span", ",", "flags", ",", "**", "kargs", ")", ":", "\n", "        ", "nn", ".", "Module", ".", "__init__", "(", "self", ")", "\n", "\n", "# position embeddings", "\n", "self", ".", "key_pe", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "1", ",", "hidden_size", "//", "nb_heads", ",", "attn_span", ")", ")", "\n", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layers", ".", "extend", "(", "\n", "TransformerSeqLayer", "(", "\n", "hidden_size", "=", "hidden_size", ",", "flags", "=", "flags", ",", "nb_heads", "=", "nb_heads", ",", "\n", "attn_span", "=", "attn_span", ",", "**", "kargs", ")", "\n", "for", "_", "in", "range", "(", "nb_layers", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.initial_cache": [[265, 276], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "layer.attn.attn.get_cache_size"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_cache_size"], ["", "def", "initial_cache", "(", "self", ",", "batch_size", ",", "device", ")", ":", "\n", "        ", "hid_cache", "=", "[", "\n", "torch", ".", "zeros", "(", "\n", "batch_size", ",", "\n", "layer", ".", "attn", ".", "attn", ".", "get_cache_size", "(", ")", ",", "\n", "self", ".", "hidden_size", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "for", "layer", "in", "self", ".", "layers", "]", "\n", "\n", "self", ".", "cache_size", "=", "0", "\n", "#print('shape initial cache: {}, len: {} '.format(hid_cache[0].shape,len(hid_cache)))", "\n", "return", "hid_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.get_adaptive_span_loss": [[277, 284], ["sum", "layer.attn.attn.adaptive_span.get_loss"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_loss"], ["", "def", "get_adaptive_span_loss", "(", "self", ")", ":", "\n", "        ", "loss", "=", "0", "\n", "if", "self", ".", "layers", "[", "0", "]", ".", "attn", ".", "attn", ".", "adapt_span_enabled", ":", "\n", "            ", "loss", "=", "sum", "(", "layer", ".", "attn", ".", "attn", ".", "adaptive_span", ".", "get_loss", "(", ")", "\n", "for", "layer", "in", "self", ".", "layers", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models.TransformerSeq.forward": [[285, 304], ["layer.size", "enumerate", "layer.attn.attn.get_cache_size", "h_cache_next.append", "layer", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "h[].detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_cache_size"], ["", "def", "forward", "(", "self", ",", "h", ",", "h_cache", ",", "target", "=", "None", ")", ":", "\n", "# h size = B x M x H", "\n", "        ", "block_size", "=", "h", ".", "size", "(", "1", ")", "\n", "\n", "h_cache_next", "=", "[", "]", "\n", "for", "l", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "cache_size", "=", "layer", ".", "attn", ".", "attn", ".", "get_cache_size", "(", ")", "\n", "if", "cache_size", ">", "block_size", ":", "\n", "                ", "h_cache_next_l", "=", "torch", ".", "cat", "(", "\n", "[", "h_cache", "[", "l", "]", "[", ":", ",", "-", "cache_size", "+", "block_size", ":", ",", ":", "]", ",", "h", "]", ",", "\n", "dim", "=", "1", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                ", "h_cache_next_l", "=", "h", "[", ":", ",", "-", "cache_size", ":", ",", ":", "]", ".", "detach", "(", ")", "\n", "", "h_cache_next", ".", "append", "(", "h_cache_next_l", ")", "\n", "h", "=", "layer", "(", "h", ",", "h_cache", "[", "l", "]", ",", "self", ".", "key_pe", ",", "self", ".", "cache_size", ")", "# B x M x H", "\n", "\n", "", "self", ".", "cache_size", "+=", "block_size", "\n", "\n", "return", "h", ",", "h_cache_next", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models._skew": [[26, 35], ["X.view.size", "torch.pad", "X.view.view", "X.view.view"], "function", ["None"], ["def", "_skew", "(", "X", ",", "pad_value", ")", ":", "\n", "    ", "\"\"\"shift every row 1 step to right\"\"\"", "\n", "# X = B x M x L", "\n", "B", ",", "M", ",", "L", "=", "X", ".", "size", "(", ")", "\n", "X", "=", "F", ".", "pad", "(", "X", ",", "(", "0", ",", "M", "+", "1", ")", ",", "value", "=", "pad_value", ")", "# B x M x (L+M+1)", "\n", "X", "=", "X", ".", "view", "(", "B", ",", "-", "1", ")", "# B x ML+MM+M", "\n", "X", "=", "X", "[", ":", ",", ":", "-", "M", "]", "# B x ML+MM", "\n", "X", "=", "X", ".", "view", "(", "B", ",", "M", ",", "M", "+", "L", ")", "# B x M x L+M", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.models._unskew": [[37, 47], ["X.view.size", "X.view.view", "torch.pad", "X.view.view"], "function", ["None"], ["", "def", "_unskew", "(", "X", ")", ":", "\n", "    ", "\"\"\"reverse _skew operation\"\"\"", "\n", "# X = B x M x L+M", "\n", "B", ",", "M", ",", "L", "=", "X", ".", "size", "(", ")", "\n", "L", "-=", "M", "\n", "X", "=", "X", ".", "view", "(", "B", ",", "-", "1", ")", "# B x ML+MM", "\n", "X", "=", "F", ".", "pad", "(", "X", ",", "(", "0", ",", "M", ")", ")", "# B x ML+MM+M", "\n", "X", "=", "X", ".", "view", "(", "B", ",", "M", ",", "M", "+", "L", "+", "1", ")", "# B x M x L+M+1", "\n", "X", "=", "X", "[", ":", ",", ":", ",", ":", "L", "]", "# B x M x L", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.main.launch": [[28, 152], ["utils.set_up_env", "data.get_train_val_test_data", "models.TransformerSeq", "utils.get_optimizer_and_scheduler", "utils.Logger", "utils.load_checkpoint", "range", "print", "print", "print", "print", "print", "print", "print", "model.to.to", "torch.nn.parallel.DistributedDataParallel", "torch.nn.DataParallel", "model.to.to", "time.time", "trainer.train_iteration", "utils.Logger.log_iter", "utils.save_checkpoint", "torch.no_grad", "trainer.full_eval", "trainer.full_eval", "torch.zeros().to", "range", "torch.no_grad", "trainer.train_iteration", "torch.tensor().to", "torch.distributed.reduce", "torch.tensor().to", "torch.distributed.reduce", "print", "print", "print", "print", "torch.zeros", "time.time", "torch.tensor", "torch.tensor", "math.exp", "math.exp", "train_data.size", "layer.attn.attn.get_cache_size", "math.log", "math.log"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.set_up_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data.get_train_val_test_data", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.get_optimizer_and_scheduler", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.load_checkpoint", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer.train_iteration", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.log_iter", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.save_checkpoint", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer.full_eval", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer.full_eval", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer.train_iteration", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_cache_size", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.log"], ["def", "launch", "(", "env_params", ",", "\n", "model_params", ",", "\n", "adapt_io_params", ",", "\n", "adapt_span_params", ",", "\n", "pers_mem_params", ",", "\n", "optim_params", ",", "\n", "data_params", ",", "\n", "trainer_params", ")", ":", "\n", "# ENVIRONMENT (device, distributed, etc.)", "\n", "    ", "set_up_env", "(", "env_params", ")", "\n", "device", "=", "env_params", "[", "'device'", "]", "\n", "distributed", "=", "env_params", "[", "'distributed'", "]", "\n", "\n", "if", "distributed", "==", "False", "or", "env_params", "[", "'rank'", "]", "==", "0", ":", "\n", "        ", "print", "(", "'model_params:\\t'", ",", "model_params", ")", "\n", "print", "(", "'optim_params:\\t'", ",", "optim_params", ")", "\n", "print", "(", "'data_params:\\t'", ",", "data_params", ")", "\n", "print", "(", "'trainer_params:\\t'", ",", "trainer_params", ")", "\n", "print", "(", "'adapt_io_params:\\t'", ",", "adapt_io_params", ")", "\n", "print", "(", "'adapt_span_params:\\t'", ",", "adapt_span_params", ")", "\n", "print", "(", "'pers_mem_params:\\t'", ",", "pers_mem_params", ")", "\n", "\n", "# DATA", "\n", "", "train_data", ",", "val_data", ",", "test_data", "=", "get_train_val_test_data", "(", "\n", "data_params", "=", "data_params", ",", "\n", "env_params", "=", "env_params", ",", "\n", "batch_size", "=", "trainer_params", "[", "'batch_size'", "]", ",", "\n", "device", "=", "device", ",", "\n", "sort_dict", "=", "adapt_io_params", "[", "'adapt_io_enabled'", "]", ")", "\n", "\n", "# MODEL", "\n", "model", "=", "TransformerSeq", "(", "\n", "vocab_size", "=", "data_params", "[", "'vocab_size'", "]", ",", "**", "model_params", ",", "\n", "adapt_io_params", "=", "adapt_io_params", ",", "\n", "adapt_span_params", "=", "adapt_span_params", ",", "\n", "pers_mem_params", "=", "pers_mem_params", ")", "\n", "if", "distributed", ":", "\n", "        ", "local_rank", "=", "env_params", "[", "'local_rank'", "]", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "output_device", "=", "local_rank", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "# OPTIMIZER AND SCHEDULER", "\n", "", "optimizer", ",", "scheduler", "=", "get_optimizer_and_scheduler", "(", "\n", "model", "=", "model", ",", "optim_params", "=", "optim_params", ")", "\n", "\n", "# create logger", "\n", "logger", "=", "Logger", "(", "data_params", "[", "'data_unit'", "]", ")", "\n", "\n", "# resume training from last checkpoint if exists", "\n", "iter_init", "=", "load_checkpoint", "(", "\n", "trainer_params", "[", "'checkpoint_path'", "]", ",", "model", ",", "optimizer", ",", "scheduler", ",", "\n", "logger", ",", "distributed", ")", "\n", "\n", "if", "trainer_params", "[", "'full_eval_mode'", "]", ":", "\n", "# evaluate the model on test data", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "loss_val", "=", "full_eval", "(", "model", ",", "optimizer", ",", "scheduler", ",", "val_data", ",", "\n", "model_params", "[", "'block_size'", "]", ",", "\n", "model_params", "[", "'hidden_size'", "]", ")", "\n", "loss_test", "=", "full_eval", "(", "model", ",", "optimizer", ",", "scheduler", ",", "test_data", ",", "\n", "model_params", "[", "'block_size'", "]", ",", "\n", "model_params", "[", "'hidden_size'", "]", ")", "\n", "if", "distributed", ":", "\n", "# collect results into rank0", "\n", "                ", "stats", "=", "torch", ".", "tensor", "(", "\n", "[", "loss_val", ",", "loss_test", "]", ")", ".", "to", "(", "device", ")", "\n", "torch", ".", "distributed", ".", "reduce", "(", "stats", ",", "0", ")", "\n", "if", "env_params", "[", "'rank'", "]", "==", "0", ":", "\n", "                    ", "loss_val", "=", "stats", "[", "0", "]", "/", "env_params", "[", "'world_size'", "]", "\n", "loss_test", "=", "stats", "[", "1", "]", "/", "env_params", "[", "'world_size'", "]", "\n", "", "else", ":", "\n", "                    ", "return", "\n", "\n", "", "", "if", "data_params", "[", "'data_unit'", "]", "==", "'bpc'", ":", "\n", "                ", "print", "(", "'val: {:.3f}bpc'", ".", "format", "(", "loss_val", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "print", "(", "'test: {:.3f}bpc'", ".", "format", "(", "loss_test", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'val: {:.2f}ppl'", ".", "format", "(", "math", ".", "exp", "(", "loss_val", ")", ")", ")", "\n", "print", "(", "'test: {:.2f}ppl'", ".", "format", "(", "math", ".", "exp", "(", "loss_test", ")", ")", ")", "\n", "", "", "return", "\n", "\n", "# position of current batch", "\n", "", "data_pos", "=", "[", "0", "]", "*", "2", "\n", "# initialize caches for train and valid", "\n", "hid_cache", "=", "[", "[", "\n", "torch", ".", "zeros", "(", "\n", "train_data", ".", "size", "(", "0", ")", ",", "\n", "layer", ".", "attn", ".", "attn", ".", "get_cache_size", "(", ")", ",", "\n", "model_params", "[", "'hidden_size'", "]", ")", ".", "to", "(", "device", ")", "\n", "for", "layer", "in", "model", ".", "module", ".", "layers", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "\n", "nb_batches_per_iter", "=", "trainer_params", "[", "'nb_batches_per_iter'", "]", "\n", "for", "iter_no", "in", "range", "(", "iter_init", ",", "trainer_params", "[", "'nb_iter'", "]", ")", ":", "\n", "        ", "t_sta", "=", "time", ".", "time", "(", ")", "\n", "loss_train", ",", "data_pos", "[", "0", "]", ",", "hid_cache", "[", "0", "]", "=", "train_iteration", "(", "\n", "model", ",", "optimizer", ",", "scheduler", ",", "train_data", ",", "nb_batches_per_iter", ",", "\n", "model_params", "[", "'block_size'", "]", ",", "False", ",", "data_pos", "[", "0", "]", ",", "hid_cache", "[", "0", "]", ",", "\n", "trainer_params", "[", "'batch_split'", "]", ")", "\n", "elapsed", "=", "1000", "*", "(", "time", ".", "time", "(", ")", "-", "t_sta", ")", "/", "nb_batches_per_iter", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "loss_val", ",", "data_pos", "[", "1", "]", ",", "hid_cache", "[", "1", "]", "=", "train_iteration", "(", "\n", "model", ",", "optimizer", ",", "scheduler", ",", "val_data", ",", "nb_batches_per_iter", ",", "\n", "model_params", "[", "'block_size'", "]", ",", "True", ",", "data_pos", "[", "1", "]", ",", "hid_cache", "[", "1", "]", ",", "\n", "trainer_params", "[", "'batch_split'", "]", ")", "\n", "\n", "", "if", "distributed", ":", "\n", "# collect results into rank0", "\n", "            ", "stats", "=", "torch", ".", "tensor", "(", "\n", "[", "loss_train", ",", "loss_val", "]", ")", ".", "to", "(", "device", ")", "\n", "torch", ".", "distributed", ".", "reduce", "(", "stats", ",", "0", ")", "\n", "if", "env_params", "[", "'rank'", "]", "==", "0", ":", "\n", "                ", "loss_train", "=", "stats", "[", "0", "]", "/", "env_params", "[", "'world_size'", "]", "\n", "loss_val", "=", "stats", "[", "1", "]", "/", "env_params", "[", "'world_size'", "]", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "\n", "", "", "logger", ".", "log_iter", "(", "iter_no", ",", "nb_batches_per_iter", ",", "loss_train", ",", "\n", "loss_val", ",", "elapsed", ",", "model", ")", "\n", "save_checkpoint", "(", "trainer_params", "[", "'checkpoint_path'", "]", ",", "\n", "iter_no", ",", "model", ",", "optimizer", ",", "scheduler", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer._train_step": [[17, 37], ["model", "out.view.view", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss.item", "out.view.mean", "dummy_loss.sum", "out.view.size", "Y.view", "sum", "layer.attn.attn.adaptive_span.get_loss"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_loss"], ["def", "_train_step", "(", "model", ",", "X", ",", "Y", ",", "h_cache", ",", "eval_only", ",", "loss_div", "=", "1", ")", ":", "\n", "    ", "\"\"\"Single training step.\"\"\"", "\n", "\n", "out", ",", "h_cache", ",", "dummy_loss", "=", "model", "(", "X", ",", "h_cache", ",", "target", "=", "Y", ")", "\n", "if", "model", ".", "module", ".", "adapt_io", ":", "\n", "        ", "loss", "=", "out", ".", "mean", "(", ")", "+", "dummy_loss", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "        ", "out", "=", "out", ".", "view", "(", "-", "1", ",", "out", ".", "size", "(", "-", "1", ")", ")", "\n", "loss", "=", "torch", ".", "nn", ".", "functional", ".", "nll_loss", "(", "out", ",", "Y", ".", "view", "(", "-", "1", ")", ")", "\n", "", "loss_value", "=", "loss", ".", "item", "(", ")", "/", "loss_div", "\n", "\n", "if", "not", "eval_only", ":", "\n", "# loss term from adaptive-span", "\n", "        ", "if", "model", ".", "module", ".", "layers", "[", "0", "]", ".", "attn", ".", "attn", ".", "adapt_span_enabled", ":", "\n", "            ", "loss", "+=", "sum", "(", "layer", ".", "attn", ".", "attn", ".", "adaptive_span", ".", "get_loss", "(", ")", "\n", "for", "layer", "in", "model", ".", "module", ".", "layers", ")", "\n", "\n", "", "(", "loss", "/", "loss_div", ")", ".", "backward", "(", ")", "\n", "\n", "", "return", "loss_value", ",", "h_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer._train_batch": [[39, 81], ["optimizer.zero_grad", "trainer._train_step", "range", "optimizer.step", "X.size", "slice", "trainer._train_step", "h_cache_list.append", "torch.cat", "scheduler.step", "torch.nn.utils.clip_grad_norm_", "X.size", "range", "model.parameters", "layer.attn.attn.adaptive_span.clamp_param", "len", "range"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer._train_step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer._train_step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.clamp_param"], ["", "def", "_train_batch", "(", "model", ",", "optimizer", ",", "scheduler", ",", "X", ",", "Y", ",", "h_cache", ",", "\n", "eval_only", ",", "batch_split", ")", ":", "\n", "    ", "\"\"\"Train on a batch.\"\"\"", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "batch_split", "==", "1", ":", "\n", "# process a batch in a single step (default behaviour)", "\n", "        ", "loss_value", ",", "h_cache", "=", "_train_step", "(", "model", ",", "X", ",", "Y", ",", "h_cache", ",", "eval_only", ")", "\n", "", "else", ":", "\n", "# split a batch into multiple pieces that each can fit in memory", "\n", "        ", "assert", "X", ".", "size", "(", "0", ")", "%", "batch_split", "==", "0", "\n", "split_size", "=", "X", ".", "size", "(", "0", ")", "//", "batch_split", "\n", "loss_value", "=", "0", "\n", "h_cache_list", "=", "[", "]", "\n", "for", "split_ind", "in", "range", "(", "batch_split", ")", ":", "\n", "            ", "split_slice", "=", "slice", "(", "split_ind", "*", "split_size", ",", "(", "split_ind", "+", "1", ")", "*", "split_size", ")", "\n", "split_h_cache", "=", "[", "h", "[", "split_slice", ",", ":", ",", ":", "]", "for", "h", "in", "h_cache", "]", "\n", "split_loss_value", ",", "split_h_cache", "=", "_train_step", "(", "\n", "model", ",", "X", "[", "split_slice", ",", ":", "]", ",", "Y", "[", "split_slice", "]", ",", "\n", "split_h_cache", ",", "eval_only", ",", "batch_split", ")", "\n", "loss_value", "+=", "split_loss_value", "\n", "h_cache_list", ".", "append", "(", "split_h_cache", ")", "\n", "", "h_cache", "=", "[", "\n", "torch", ".", "cat", "(", "\n", "[", "h_cache_list", "[", "i", "]", "[", "l", "]", "for", "i", "in", "range", "(", "batch_split", ")", "]", "\n", ",", "dim", "=", "0", ")", "for", "l", "in", "range", "(", "len", "(", "h_cache", ")", ")", "]", "\n", "\n", "", "if", "not", "eval_only", ":", "\n", "        ", "if", "scheduler", "is", "not", "None", ":", "\n", "            ", "scheduler", ".", "step", "(", ")", "\n", "", "if", "optimizer", ".", "grad_clip", ">", "0", ":", "\n", "            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "optimizer", ".", "grad_clip", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "# make sure span parameters are in a correct range", "\n", "if", "model", ".", "module", ".", "layers", "[", "0", "]", ".", "attn", ".", "attn", ".", "adapt_span_enabled", ":", "\n", "            ", "for", "layer", "in", "model", ".", "module", ".", "layers", ":", "\n", "                ", "layer", ".", "attn", ".", "attn", ".", "adaptive_span", ".", "clamp_param", "(", ")", "\n", "\n", "", "", "", "return", "loss_value", ",", "h_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer.train_iteration": [[83, 124], ["range", "model.eval", "model.train", "max", "min", "data[].contiguous", "data[].contiguous", "trainer._train_batch", "math.ceil", "random.randrange", "data.size", "h.fill_", "data.size"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer._train_batch"], ["", "def", "train_iteration", "(", "model", ",", "optimizer", ",", "scheduler", ",", "data", ",", "nb_batches_per_iter", ",", "\n", "block_size", ",", "eval_only", ",", "train_pos", ",", "h_cache", ",", "batch_split", ")", ":", "\n", "    ", "\"\"\"Single training iteration.\"\"\"", "\n", "if", "eval_only", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "\n", "", "nb_batches_per_iter_max", "=", "nb_batches_per_iter", "\n", "if", "eval_only", ":", "\n", "# eval on fewer batches during training for speed-up", "\n", "        ", "nb_batches_per_iter_max", "=", "max", "(", "1", ",", "nb_batches_per_iter", "//", "10", ")", "\n", "nb_batches_per_iter_max", "=", "min", "(", "nb_batches_per_iter_max", ",", "\n", "math", ".", "ceil", "(", "data", ".", "size", "(", "1", ")", "/", "block_size", ")", ")", "\n", "\n", "", "loss_all", "=", "0", "\n", "actual_nb_batches_per_iter", "=", "0", "\n", "for", "_", "in", "range", "(", "nb_batches_per_iter_max", ")", ":", "\n", "        ", "actual_nb_batches_per_iter", "+=", "1", "\n", "X", "=", "data", "[", ":", ",", "train_pos", ":", "train_pos", "+", "block_size", "]", ".", "contiguous", "(", ")", "\n", "Y", "=", "data", "[", ":", ",", "train_pos", "+", "1", ":", "train_pos", "+", "block_size", "+", "1", "]", ".", "contiguous", "(", ")", "\n", "\n", "loss", ",", "h_cache", "=", "_train_batch", "(", "\n", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "X", "=", "X", ",", "Y", "=", "Y", ",", "\n", "h_cache", "=", "h_cache", ",", "\n", "eval_only", "=", "eval_only", ",", "\n", "batch_split", "=", "batch_split", ")", "\n", "loss_all", "+=", "loss", "\n", "train_pos", "+=", "block_size", "\n", "if", "train_pos", ">=", "data", ".", "size", "(", "1", ")", "-", "block_size", ":", "\n", "# reached the end. randomize the offset to reduce overfitting", "\n", "            ", "train_pos", "=", "random", ".", "randrange", "(", "block_size", ")", "\n", "# reset the cache", "\n", "for", "h", "in", "h_cache", ":", "\n", "                ", "h", ".", "fill_", "(", "0", ")", "\n", "\n", "", "", "", "loss_all", "=", "loss_all", "/", "actual_nb_batches_per_iter", "\n", "return", "loss_all", ",", "train_pos", ",", "h_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer.full_eval": [[127, 162], ["model.eval", "math.ceil", "range", "torch.zeros().to", "data[].contiguous", "data[].contiguous", "trainer._train_batch", "data.size", "torch.zeros", "data.size", "data.size", "layer.attn.attn.get_cache_size"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.trainer._train_batch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_cache_size"], ["", "def", "full_eval", "(", "model", ",", "optimizer", ",", "scheduler", ",", "data", ",", "block_size", ",", "hidden_size", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "train_pos", "=", "0", "\n", "nb_batches_per_iter_max", "=", "math", ".", "ceil", "(", "data", ".", "size", "(", "1", ")", "/", "block_size", ")", "\n", "h_cache", "=", "[", "\n", "torch", ".", "zeros", "(", "\n", "data", ".", "size", "(", "0", ")", ",", "\n", "layer", ".", "attn", ".", "attn", ".", "get_cache_size", "(", ")", ",", "\n", "hidden_size", ")", ".", "to", "(", "data", ".", "device", ")", "\n", "for", "layer", "in", "model", ".", "module", ".", "layers", "]", "\n", "\n", "loss_all", "=", "0", "\n", "actual_nb_batches_per_iter", "=", "0", "\n", "for", "_", "in", "range", "(", "nb_batches_per_iter_max", ")", ":", "\n", "        ", "actual_nb_batches_per_iter", "+=", "1", "\n", "X", "=", "data", "[", ":", ",", "train_pos", ":", "train_pos", "+", "block_size", "]", ".", "contiguous", "(", ")", "\n", "Y", "=", "data", "[", ":", ",", "train_pos", "+", "1", ":", "train_pos", "+", "block_size", "+", "1", "]", ".", "contiguous", "(", ")", "\n", "\n", "loss", ",", "h_cache", "=", "_train_batch", "(", "\n", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "X", "=", "X", ",", "Y", "=", "Y", ",", "\n", "h_cache", "=", "h_cache", ",", "\n", "eval_only", "=", "True", ",", "\n", "batch_split", "=", "1", ")", "\n", "loss_all", "+=", "loss", "\n", "train_pos", "+=", "block_size", "\n", "if", "train_pos", ">=", "data", ".", "size", "(", "1", ")", "-", "block_size", ":", "\n", "# Skip the remaining tokens as it can't make a whole block.", "\n", "# An effect on performance should be negligable for a large data.", "\n", "            ", "break", "\n", "\n", "", "", "loss_all", "=", "loss_all", "/", "actual_nb_batches_per_iter", "\n", "return", "loss_all", "\n", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data.Dictionary.__init__": [[15, 38], ["os.path.exists", "open", "range", "sorted", "len", "data.Dictionary.idx2word.append", "line.split", "data.Dictionary.word2count.items", "data.Dictionary.word2count.get", "len", "data.Dictionary.idx2word.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "sort_dict", "=", "False", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "word2count", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "[", "]", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "if", "sort_dict", ":", "\n", "                        ", "self", ".", "word2count", "[", "word", "]", "=", "self", ".", "word2count", ".", "get", "(", "word", ",", "0", ")", "+", "1", "\n", "", "elif", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "                        ", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "idx2word", ")", "\n", "self", ".", "idx2word", ".", "append", "(", "word", ")", "\n", "", "", "", "", "if", "sort_dict", ":", "\n", "# Sort dictionary by count and build indices accordingly:", "\n", "            ", "sorted_dict", "=", "sorted", "(", "self", ".", "word2count", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sorted_dict", ")", ")", ":", "\n", "                ", "word", "=", "sorted_dict", "[", "i", "]", "[", "0", "]", "\n", "self", ".", "word2idx", "[", "word", "]", "=", "i", "\n", "self", ".", "idx2word", ".", "append", "(", "word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data.Dictionary.__len__": [[39, 41], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data.Corpus.__init__": [[61, 74], ["print", "data.Dictionary", "data._tokenize", "data._tokenize", "data._tokenize", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._tokenize", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._tokenize", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._tokenize"], ["    ", "def", "__init__", "(", "self", ",", "data_path", ",", "sort_dict", ")", ":", "\n", "        ", "print", "(", "'Building dictionary'", ")", "\n", "self", ".", "_dictionary", "=", "Dictionary", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'train.txt'", ")", ",", "sort_dict", ")", "\n", "\n", "self", ".", "train", "=", "_tokenize", "(", "\n", "text_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "'train.txt'", ")", ",", "\n", "dictionary", "=", "self", ".", "_dictionary", ".", "word2idx", ")", "\n", "self", ".", "valid", "=", "_tokenize", "(", "\n", "text_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "'valid.txt'", ")", ",", "\n", "dictionary", "=", "self", ".", "_dictionary", ".", "word2idx", ")", "\n", "self", ".", "test", "=", "_tokenize", "(", "\n", "text_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "'test.txt'", ")", ",", "\n", "dictionary", "=", "self", ".", "_dictionary", ".", "word2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data.Corpus.vocab_size": [[75, 78], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._tokenize": [[43, 58], ["print", "os.path.exists", "torch.LongTensor", "open", "line.split", "torch.LongTensor.append"], "function", ["None"], ["", "", "def", "_tokenize", "(", "text_path", ",", "dictionary", ")", ":", "\n", "    ", "\"\"\"Tokenizes a text file.\"\"\"", "\n", "print", "(", "'Tokenizing {}'", ".", "format", "(", "text_path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "text_path", ")", "\n", "\n", "# Assign to each token its identifier", "\n", "ids", "=", "[", "]", "\n", "with", "open", "(", "text_path", ",", "'r'", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "tokens", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "                ", "ids", ".", "append", "(", "dictionary", "[", "token", "]", ")", "\n", "", "", "", "ids", "=", "torch", ".", "LongTensor", "(", "ids", ")", "\n", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._batchify": [[80, 86], ["data_tensor.view().contiguous.narrow", "data_tensor.view().contiguous.view().contiguous", "data_tensor.view().contiguous.size", "data_tensor.view().contiguous.view"], "function", ["None"], ["", "", "def", "_batchify", "(", "data_tensor", ",", "batch_size", ")", ":", "\n", "    ", "nb_batches", "=", "data_tensor", ".", "size", "(", "0", ")", "//", "batch_size", "\n", "# trim away some tokens to make whole batches", "\n", "data_tensor", "=", "data_tensor", ".", "narrow", "(", "0", ",", "0", ",", "nb_batches", "*", "batch_size", ")", "\n", "data_tensor", "=", "data_tensor", ".", "view", "(", "batch_size", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "return", "data_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._build_corpus": [[88, 115], ["os.path.exists", "os.path.join", "os.path.join", "print", "torch.load", "print", "data.Corpus", "torch.save", "data.Corpus", "torch.save", "torch.distributed.broadcast", "print", "torch.distributed.broadcast", "torch.load", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "def", "_build_corpus", "(", "data_path", ",", "env_params", ",", "sort_dict", ")", ":", "\n", "# save the corpus to a file so that it's faster next time", "\n", "    ", "if", "sort_dict", ":", "\n", "        ", "corpus_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "'corpus_sorted.pt'", ")", "\n", "", "else", ":", "\n", "        ", "corpus_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "'corpus.pt'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "corpus_path", ")", ":", "\n", "        ", "print", "(", "'Loading an existing corpus file from {}'", ".", "format", "(", "corpus_path", ")", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "corpus_path", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Creating a corpus file at {}'", ".", "format", "(", "corpus_path", ")", ")", "\n", "if", "env_params", "[", "'distributed'", "]", ":", "\n", "# only one process need to create a corpus file", "\n", "            ", "if", "env_params", "[", "'rank'", "]", "==", "0", ":", "\n", "                ", "corpus", "=", "Corpus", "(", "data_path", ",", "sort_dict", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "corpus_path", ")", "\n", "# sync with other processes", "\n", "torch", ".", "distributed", ".", "broadcast", "(", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", ",", "src", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Waiting rank0 to create a corpus file.'", ")", "\n", "# sync with rank0", "\n", "torch", ".", "distributed", ".", "broadcast", "(", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", ",", "src", "=", "0", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "corpus_path", ")", "\n", "", "", "else", ":", "\n", "            ", "corpus", "=", "Corpus", "(", "data_path", ",", "sort_dict", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "corpus_path", ")", "\n", "", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._get_train_val_test_data": [[117, 122], ["data._batchify", "data._batchify", "data._batchify"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._batchify", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._batchify", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._batchify"], ["", "def", "_get_train_val_test_data", "(", "corpus", ",", "batch_size", ")", ":", "\n", "    ", "return", "[", "\n", "_batchify", "(", "corpus", ".", "train", ",", "batch_size", ")", ",", "\n", "_batchify", "(", "corpus", ".", "valid", ",", "batch_size", ")", ",", "\n", "_batchify", "(", "corpus", ".", "test", ",", "batch_size", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data.get_train_val_test_data": [[125, 146], ["data._build_corpus", "data._get_train_val_test_data", "train_data.to.to", "val_data.to.to", "test_data.to.to", "slice"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._build_corpus", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.data._get_train_val_test_data"], ["", "def", "get_train_val_test_data", "(", "data_params", ",", "env_params", ",", "batch_size", ",", "device", ",", "sort_dict", ")", ":", "\n", "    ", "corpus", "=", "_build_corpus", "(", "data_params", "[", "'data_path'", "]", ",", "env_params", ",", "sort_dict", ")", "\n", "data_params", "[", "'vocab_size'", "]", "=", "corpus", ".", "vocab_size", "\n", "train_data", ",", "val_data", ",", "test_data", "=", "_get_train_val_test_data", "(", "\n", "corpus", "=", "corpus", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "if", "env_params", "[", "'distributed'", "]", ":", "\n", "# split the data into equal parts", "\n", "        ", "assert", "batch_size", "%", "env_params", "[", "'world_size'", "]", "==", "0", "\n", "device_batch_size", "=", "batch_size", "//", "env_params", "[", "'world_size'", "]", "\n", "slice_data", "=", "slice", "(", "\n", "device_batch_size", "*", "env_params", "[", "'rank'", "]", ",", "\n", "device_batch_size", "*", "(", "env_params", "[", "'rank'", "]", "+", "1", ")", ")", "\n", "train_data", "=", "train_data", "[", "slice_data", "]", "\n", "val_data", "=", "val_data", "[", "slice_data", "]", "\n", "test_data", "=", "test_data", "[", "slice_data", "]", "\n", "\n", "", "train_data", "=", "train_data", ".", "to", "(", "device", ")", "\n", "val_data", "=", "val_data", ".", "to", "(", "device", ")", "\n", "test_data", "=", "test_data", ".", "to", "(", "device", ")", "\n", "return", "train_data", ",", "val_data", ",", "test_data", "\n", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adagrad_with_grad_clip.AdagradWithGradClip.__init__": [[23, 38], ["torch.optim.Adagrad.__init__", "adagrad_with_grad_clip.AdagradWithGradClip.param_groups[].setdefault"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["def", "__init__", "(", "self", ",", "\n", "params", ",", "\n", "lr", "=", "1e-2", ",", "\n", "lr_decay", "=", "0", ",", "\n", "weight_decay", "=", "0", ",", "\n", "initial_accumulator_value", "=", "0", ",", "\n", "grad_clip", "=", "0", ")", ":", "\n", "        ", "Adagrad", ".", "__init__", "(", "self", ",", "\n", "params", ",", "\n", "lr", "=", "lr", ",", "\n", "lr_decay", "=", "lr_decay", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "initial_accumulator_value", "=", "initial_accumulator_value", ")", "\n", "self", ".", "defaults", "[", "'grad_clip'", "]", "=", "grad_clip", "\n", "self", ".", "param_groups", "[", "0", "]", ".", "setdefault", "(", "'grad_clip'", ",", "grad_clip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adagrad_with_grad_clip.AdagradWithGradClip.step": [[39, 91], ["closure", "adagrad_with_grad_clip._clip_grad", "grad.coalesce.coalesce.add", "grad.coalesce.coalesce.coalesce", "grad.coalesce.coalesce._indices", "grad.coalesce.coalesce._values", "grad.coalesce.coalesce.size", "state[].add_", "state[]._sparse_mask", "state[].sqrt().add_._values().sqrt_().add_", "p.data.add_", "state[].addcmul_", "state[].sqrt().add_", "p.data.addcdiv_", "RuntimeError", "constructor", "adagrad_with_grad_clip.AdagradWithGradClip.step.make_sparse"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adagrad_with_grad_clip._clip_grad", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.None.replayBuffer.ReplayBuffer.add"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "if", "p", ".", "grad", ".", "data", ".", "is_sparse", ":", "\n", "                        ", "raise", "RuntimeError", "(", "\"weight_decay option is \"", "\n", "\"not compatible with sparse \"", "\n", "\"gradients\"", ")", "\n", "", "grad", "=", "grad", ".", "add", "(", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "clr", "=", "(", "group", "[", "'lr'", "]", "/", "\n", "(", "1", "+", "(", "state", "[", "'step'", "]", "-", "1", ")", "*", "group", "[", "'lr_decay'", "]", ")", ")", "\n", "\n", "# clip", "\n", "clr", "=", "_clip_grad", "(", "clr", "=", "clr", ",", "\n", "grad", "=", "grad", ",", "\n", "group_grad_clip", "=", "group", "[", "'grad_clip'", "]", ")", "\n", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "# the update is non-linear so indices must be unique", "\n", "                    ", "grad", "=", "grad", ".", "coalesce", "(", ")", "\n", "grad_indices", "=", "grad", ".", "_indices", "(", ")", "\n", "grad_values", "=", "grad", ".", "_values", "(", ")", "\n", "size", "=", "grad", ".", "size", "(", ")", "\n", "\n", "def", "make_sparse", "(", "values", ")", ":", "\n", "                        ", "constructor", "=", "grad", ".", "new", "\n", "if", "grad_indices", ".", "dim", "(", ")", "==", "0", "or", "values", ".", "dim", "(", ")", "==", "0", ":", "\n", "                            ", "return", "constructor", "(", ")", ".", "resize_as_", "(", "grad", ")", "\n", "", "return", "constructor", "(", "grad_indices", ",", "values", ",", "size", ")", "\n", "", "state", "[", "'sum'", "]", ".", "add_", "(", "make_sparse", "(", "grad_values", ".", "pow", "(", "2", ")", ")", ")", "\n", "std", "=", "state", "[", "'sum'", "]", ".", "_sparse_mask", "(", "grad", ")", "\n", "std_values", "=", "std", ".", "_values", "(", ")", ".", "sqrt_", "(", ")", ".", "add_", "(", "1e-10", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "clr", ",", "make_sparse", "(", "grad_values", "/", "std_values", ")", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'sum'", "]", ".", "addcmul_", "(", "1", ",", "grad", ",", "grad", ")", "\n", "std", "=", "state", "[", "'sum'", "]", ".", "sqrt", "(", ")", ".", "add_", "(", "1e-10", ")", "\n", "p", ".", "data", ".", "addcdiv_", "(", "-", "clr", ",", "grad", ",", "std", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adagrad_with_grad_clip._clip_grad": [[13, 19], ["grad.norm().item", "grad.norm"], "function", ["None"], ["def", "_clip_grad", "(", "clr", ",", "grad", ",", "group_grad_clip", ")", ":", "\n", "    ", "if", "group_grad_clip", ">", "0", ":", "\n", "        ", "norm", "=", "grad", ".", "norm", "(", "2", ")", ".", "item", "(", ")", "\n", "if", "norm", ">", "group_grad_clip", ":", "\n", "            ", "clr", "*=", "group_grad_clip", "/", "(", "norm", "+", "1e-10", ")", "\n", "", "", "return", "clr", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.persistent_memory.PersistentMemory.__init__": [[19, 29], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "math.sqrt", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "nb_heads", ",", "head_dim", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "PersistentMemory", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "nb_heads", "=", "nb_heads", "\n", "self", ".", "head_dim", "=", "head_dim", "\n", "# different heads have different vectors", "\n", "self", ".", "key", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "nb_heads", ",", "self", ".", "head_dim", ",", "self", ".", "size", ")", "/", "math", ".", "sqrt", "(", "self", ".", "head_dim", ")", ")", "\n", "self", ".", "val", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "self", ".", "nb_heads", ",", "self", ".", "size", ",", "self", ".", "head_dim", ")", "/", "math", ".", "sqrt", "(", "self", ".", "size", ")", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "adaptive_span", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.persistent_memory.PersistentMemory.forward": [[30, 60], ["persistent_memory.PersistentMemory.key.unsqueeze", "persistent_memory.PersistentMemory.val.unsqueeze", "query.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "attn_pers.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "persistent_memory.PersistentMemory.dropout", "attn_pers.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "out.view.view.view", "math.sqrt", "persistent_memory.PersistentMemory.adaptive_span", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "math.sqrt", "math.sqrt", "query.view.view.size", "attn_pers.view.view.size", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "attn_pers.view.view.size", "out.view.view.size", "persistent_memory.PersistentMemory.size", "persistent_memory.PersistentMemory.size", "persistent_memory.PersistentMemory.size", "persistent_memory.PersistentMemory.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "attn", ")", ":", "\n", "        ", "key", "=", "self", ".", "key", ".", "unsqueeze", "(", "0", ")", "\n", "val", "=", "self", ".", "val", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "query", "=", "query", ".", "view", "(", "(", "-", "1", ",", "self", ".", "nb_heads", ")", "+", "query", ".", "size", "(", ")", "[", "1", ":", "]", ")", "\n", "attn_pers", "=", "torch", ".", "matmul", "(", "query", ",", "key", "*", "math", ".", "sqrt", "(", "self", ".", "head_dim", ")", ")", "\n", "attn_pers", "=", "attn_pers", ".", "view", "(", "(", "-", "1", ",", ")", "+", "attn_pers", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "\n", "# compute softmax jointly", "\n", "attn", "=", "torch", ".", "cat", "(", "(", "attn", ",", "attn_pers", ")", ",", "dim", "=", "-", "1", ")", "\n", "attn", "=", "attn", "/", "math", ".", "sqrt", "(", "self", ".", "head_dim", ")", "# B x M X L_total", "\n", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", "\n", "attn_pers", "=", "attn", "[", ":", ",", ":", ",", "-", "key", ".", "size", "(", "-", "1", ")", ":", "]", "\n", "attn", "=", "attn", "[", ":", ",", ":", ",", ":", "-", "key", ".", "size", "(", "-", "1", ")", "]", "# B x M X L", "\n", "\n", "# adapt attention span", "\n", "if", "self", ".", "adaptive_span", "is", "not", "None", ":", "\n", "            ", "attn", "=", "self", ".", "adaptive_span", "(", "attn", ",", "normalize", "=", "False", ")", "\n", "# normalize the sum jointly!", "\n", "attn", "=", "torch", ".", "cat", "(", "(", "attn", ",", "attn_pers", ")", ",", "dim", "=", "-", "1", ")", "\n", "attn", "=", "attn", "/", "(", "attn", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "attn_pers", "=", "attn", "[", ":", ",", ":", ",", "-", "key", ".", "size", "(", "-", "1", ")", ":", "]", "\n", "attn", "=", "attn", "[", ":", ",", ":", ",", ":", "-", "key", ".", "size", "(", "-", "1", ")", "]", "# B x M X L", "\n", "\n", "", "attn_pers", "=", "self", ".", "dropout", "(", "attn_pers", ")", "# B x M X L", "\n", "\n", "attn_pers", "=", "attn_pers", ".", "view", "(", "(", "-", "1", ",", "self", ".", "nb_heads", ")", "+", "attn_pers", ".", "size", "(", ")", "[", "1", ":", "]", ")", "\n", "out", "=", "torch", ".", "matmul", "(", "attn_pers", ",", "val", "*", "math", ".", "sqrt", "(", "self", ".", "size", ")", ")", "\n", "out", "=", "out", ".", "view", "(", "(", "-", "1", ",", ")", "+", "out", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "return", "attn", ",", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveMask.__init__": [[30, 37], ["torch.Module.__init__", "torch.Module.__init__", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "adaptive_span.AdaptiveMask.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["def", "__init__", "(", "self", ",", "max_size", ",", "ramp_size", ",", "init_val", "=", "0", ",", "shape", "=", "(", "1", ",", ")", ")", ":", "\n", "        ", "nn", ".", "Module", ".", "__init__", "(", "self", ")", "\n", "self", ".", "_max_size", "=", "max_size", "\n", "self", ".", "_ramp_size", "=", "ramp_size", "\n", "self", ".", "current_val", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "*", "shape", ")", "+", "init_val", ")", "\n", "mask_template", "=", "torch", ".", "linspace", "(", "1", "-", "max_size", ",", "0", ",", "steps", "=", "max_size", ")", "\n", "self", ".", "register_buffer", "(", "'mask_template'", ",", "mask_template", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveMask.forward": [[38, 47], ["mask.clamp.clamp.clamp", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mask", "=", "self", ".", "mask_template", "+", "self", ".", "current_val", "*", "self", ".", "_max_size", "\n", "mask", "=", "mask", "/", "self", ".", "_ramp_size", "+", "1", "\n", "mask", "=", "mask", ".", "clamp", "(", "0", ",", "1", ")", "\n", "if", "x", ".", "size", "(", "-", "1", ")", "<", "self", ".", "_max_size", ":", "\n", "# the input could have been trimmed beforehand to save computation", "\n", "            ", "mask", "=", "mask", "[", ":", ",", ":", ",", "-", "x", ".", "size", "(", "-", "1", ")", ":", "]", "\n", "", "x", "=", "x", "*", "mask", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveMask.get_current_max_size": [[48, 54], ["math.ceil", "max", "min", "adaptive_span.AdaptiveMask.current_val.max().item", "adaptive_span.AdaptiveMask.current_val.max"], "methods", ["None"], ["", "def", "get_current_max_size", "(", "self", ",", "include_ramp", "=", "True", ")", ":", "\n", "        ", "current_size", "=", "math", ".", "ceil", "(", "self", ".", "current_val", ".", "max", "(", ")", ".", "item", "(", ")", "*", "self", ".", "_max_size", ")", "\n", "if", "include_ramp", ":", "\n", "            ", "current_size", "+=", "self", ".", "_ramp_size", "\n", "", "current_size", "=", "max", "(", "0", ",", "min", "(", "self", ".", "_max_size", ",", "current_size", ")", ")", "\n", "return", "current_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveMask.get_current_avg_size": [[55, 61], ["math.ceil", "max", "min", "adaptive_span.AdaptiveMask.current_val.mean().item", "adaptive_span.AdaptiveMask.current_val.mean"], "methods", ["None"], ["", "def", "get_current_avg_size", "(", "self", ",", "include_ramp", "=", "True", ")", ":", "\n", "        ", "current_size", "=", "math", ".", "ceil", "(", "self", ".", "current_val", ".", "mean", "(", ")", ".", "item", "(", ")", "*", "self", ".", "_max_size", ")", "\n", "if", "include_ramp", ":", "\n", "            ", "current_size", "+=", "self", ".", "_ramp_size", "\n", "", "current_size", "=", "max", "(", "0", ",", "min", "(", "self", ".", "_max_size", ",", "current_size", ")", ")", "\n", "return", "current_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveMask.clamp_param": [[62, 65], ["adaptive_span.AdaptiveMask.current_val.data.clamp_"], "methods", ["None"], ["", "def", "clamp_param", "(", "self", ")", ":", "\n", "        ", "\"\"\"this need to be called after each update\"\"\"", "\n", "self", ".", "current_val", ".", "data", ".", "clamp_", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.__init__": [[79, 90], ["torch.Module.__init__", "torch.Module.__init__", "torch.Module.__init__", "adaptive_span.AdaptiveMask"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["def", "__init__", "(", "self", ",", "attn_span", ",", "adapt_span_loss", ",", "adapt_span_ramp", ",", "\n", "adapt_span_init", ",", "adapt_span_cache", ",", "nb_heads", ",", "**", "kargs", ")", ":", "\n", "        ", "nn", ".", "Module", ".", "__init__", "(", "self", ")", "\n", "self", ".", "_adapt_cache", "=", "adapt_span_cache", "\n", "self", ".", "_max_span", "=", "attn_span", "\n", "self", ".", "_loss_coeff", "=", "adapt_span_loss", "\n", "self", ".", "_nb_heads", "=", "nb_heads", "\n", "self", ".", "_mask", "=", "AdaptiveMask", "(", "max_size", "=", "self", ".", "_max_span", ",", "\n", "ramp_size", "=", "adapt_span_ramp", ",", "\n", "init_val", "=", "adapt_span_init", ",", "\n", "shape", "=", "(", "nb_heads", ",", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.forward": [[91, 104], ["attn.view.view.size", "attn.view.view.size", "attn.view.view.reshape", "adaptive_span.AdaptiveSpan._mask", "attn.view.view.view", "attn.view.view.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "attn", ",", "normalize", "=", "True", ")", ":", "\n", "        ", "\"\"\"mask attention with the right span\"\"\"", "\n", "# batch and head dimensions are merged together, so separate them first", "\n", "B", "=", "attn", ".", "size", "(", "0", ")", "# batch size", "\n", "M", "=", "attn", ".", "size", "(", "1", ")", "# block size", "\n", "attn", "=", "attn", ".", "reshape", "(", "B", "//", "self", ".", "_nb_heads", ",", "self", ".", "_nb_heads", ",", "M", ",", "-", "1", ")", "\n", "\n", "attn", "=", "self", ".", "_mask", "(", "attn", ")", "\n", "if", "normalize", ":", "\n", "            ", "attn", "=", "attn", "/", "(", "attn", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "# normalize so sum is 1", "\n", "\n", "", "attn", "=", "attn", ".", "view", "(", "B", ",", "M", ",", "-", "1", ")", "\n", "return", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_trim_len": [[105, 112], ["min", "math.floor", "adaptive_span.AdaptiveSpan._mask.get_current_max_size"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveMask.get_current_max_size"], ["", "def", "get_trim_len", "(", "self", ")", ":", "\n", "        ", "\"\"\"how much of memory can be trimmed to reduce computation\"\"\"", "\n", "L", "=", "self", ".", "_max_span", "\n", "trim_len", "=", "min", "(", "L", "-", "1", ",", "L", "-", "self", ".", "_mask", ".", "get_current_max_size", "(", ")", ")", "\n", "# too fine granularity might be bad for the memory management", "\n", "trim_len", "=", "math", ".", "floor", "(", "trim_len", "/", "64", ")", "*", "64", "\n", "return", "trim_len", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.trim_memory": [[113, 130], ["adaptive_span.AdaptiveSpan.get_trim_len", "torch.pad.size", "query.size", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_trim_len"], ["", "def", "trim_memory", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_pe", ")", ":", "\n", "        ", "\"\"\"trim out unnecessary memory beforehand to reduce computation\"\"\"", "\n", "trim_len", "=", "self", ".", "get_trim_len", "(", ")", "\n", "cache_size", "=", "key", ".", "size", "(", "1", ")", "-", "query", ".", "size", "(", "1", ")", "\n", "trim_len_cache", "=", "trim_len", "-", "(", "self", ".", "_max_span", "-", "cache_size", ")", "\n", "if", "trim_len_cache", ">", "0", ":", "\n", "            ", "key", "=", "key", "[", ":", ",", "trim_len_cache", ":", ",", ":", "]", "\n", "value", "=", "value", "[", ":", ",", "trim_len_cache", ":", ",", ":", "]", "\n", "", "elif", "trim_len_cache", "<", "0", ":", "\n", "# cache is too short! this happens when validation resumes", "\n", "# after a lot of updates.", "\n", "            ", "key", "=", "F", ".", "pad", "(", "key", ",", "[", "0", ",", "0", ",", "-", "trim_len_cache", ",", "0", "]", ")", "\n", "value", "=", "F", ".", "pad", "(", "value", ",", "[", "0", ",", "0", ",", "-", "trim_len_cache", ",", "0", "]", ")", "\n", "", "if", "trim_len", ">", "0", ":", "\n", "            ", "if", "key_pe", "is", "not", "None", ":", "\n", "                ", "key_pe", "=", "key_pe", "[", ":", ",", ":", ",", "trim_len", ":", "]", "\n", "", "", "return", "key", ",", "value", ",", "key_pe", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_cache_size": [[131, 140], ["adaptive_span.AdaptiveSpan.get_trim_len", "min"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_trim_len"], ["", "def", "get_cache_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"determine how long the cache should be\"\"\"", "\n", "if", "self", ".", "_adapt_cache", ":", "\n", "            ", "trim_len", "=", "self", ".", "get_trim_len", "(", ")", "\n", "# give a buffer of 64 steps since a span might increase", "\n", "# in future updates", "\n", "return", "min", "(", "self", ".", "_max_span", ",", "self", ".", "_max_span", "-", "trim_len", "+", "64", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_max_span", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_loss": [[141, 144], ["adaptive_span.AdaptiveSpan._mask.current_val.mean"], "methods", ["None"], ["", "", "def", "get_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"a loss term for regularizing the span length\"\"\"", "\n", "return", "self", ".", "_loss_coeff", "*", "self", ".", "_max_span", "*", "self", ".", "_mask", ".", "current_val", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_current_max_span": [[145, 147], ["adaptive_span.AdaptiveSpan._mask.get_current_max_size"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveMask.get_current_max_size"], ["", "def", "get_current_max_span", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_mask", ".", "get_current_max_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_current_avg_span": [[148, 150], ["adaptive_span.AdaptiveSpan._mask.get_current_avg_size"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveMask.get_current_avg_size"], ["", "def", "get_current_avg_span", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_mask", ".", "get_current_avg_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.clamp_param": [[151, 153], ["adaptive_span.AdaptiveSpan._mask.clamp_param"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.clamp_param"], ["", "def", "clamp_param", "(", "self", ")", ":", "\n", "        ", "self", ".", "_mask", ".", "clamp_param", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.__init__": [[180, 183], ["dict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_unit", ")", ":", "\n", "        ", "self", ".", "data_unit", "=", "data_unit", "\n", "self", ".", "_state_dict", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict": [[184, 186], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "_state_dict", "=", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict": [[187, 189], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger._log": [[190, 194], ["utils.Logger._state_dict[].append"], "methods", ["None"], ["", "def", "_log", "(", "self", ",", "title", ",", "value", ")", ":", "\n", "        ", "if", "title", "not", "in", "self", ".", "_state_dict", ":", "\n", "            ", "self", ".", "_state_dict", "[", "title", "]", "=", "[", "]", "\n", "", "self", ".", "_state_dict", "[", "title", "]", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.log_iter": [[195, 229], ["utils.Logger._log", "print", "float", "float", "utils.Logger._log", "utils.Logger._log", "math.exp", "math.exp", "utils.Logger._log", "utils.Logger._log", "float", "utils.Logger._log", "utils.Logger._log", "avg_spans.append", "max_spans.append", "float", "len", "max", "math.log", "math.log", "layer.attn.attn.adaptive_span.get_current_avg_span", "layer.attn.attn.adaptive_span.get_current_max_span", "sum"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger._log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger._log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger._log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger._log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger._log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger._log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger._log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_current_avg_span", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.adaptive_span.AdaptiveSpan.get_current_max_span"], ["", "def", "log_iter", "(", "self", ",", "iter_no", ",", "nb_batches_per_iter", ",", "loss_train", ",", "loss_val", ",", "\n", "elapsed", ",", "model", ")", ":", "\n", "        ", "step", "=", "(", "iter_no", "+", "1", ")", "*", "nb_batches_per_iter", "\n", "self", ".", "_log", "(", "title", "=", "'step'", ",", "value", "=", "step", ")", "\n", "msg", "=", "'steps: {}'", ".", "format", "(", "step", ")", "\n", "if", "self", ".", "data_unit", "==", "'bpc'", ":", "\n", "            ", "train_bpc", "=", "float", "(", "loss_train", "/", "math", ".", "log", "(", "2", ")", ")", "\n", "val_bpc", "=", "float", "(", "loss_val", "/", "math", ".", "log", "(", "2", ")", ")", "\n", "msg", "+=", "'\\ttrain: {:.3f}bpc\\tval: {:.3f}bpc'", ".", "format", "(", "train_bpc", ",", "val_bpc", ")", "\n", "self", ".", "_log", "(", "title", "=", "'train_bpc'", ",", "value", "=", "train_bpc", ")", "\n", "self", ".", "_log", "(", "title", "=", "'val_bpc'", ",", "value", "=", "val_bpc", ")", "\n", "", "else", ":", "\n", "            ", "train_ppl", "=", "math", ".", "exp", "(", "loss_train", ")", "\n", "val_ppl", "=", "math", ".", "exp", "(", "loss_val", ")", "\n", "msg", "+=", "'\\ttrain: {:.2f}ppl\\tval: {:.2f}ppl'", ".", "format", "(", "train_ppl", ",", "val_ppl", ")", "\n", "self", ".", "_log", "(", "title", "=", "'train_ppl'", ",", "value", "=", "train_ppl", ")", "\n", "self", ".", "_log", "(", "title", "=", "'val_ppl'", ",", "value", "=", "val_ppl", ")", "\n", "", "msg", "+=", "'\\tms/batch: {:.1f}'", ".", "format", "(", "elapsed", ")", "\n", "\n", "if", "model", ".", "module", ".", "layers", "[", "0", "]", ".", "attn", ".", "attn", ".", "adapt_span_enabled", ":", "\n", "            ", "avg_spans", "=", "[", "]", "\n", "max_spans", "=", "[", "]", "\n", "for", "layer", "in", "model", ".", "module", ".", "layers", ":", "\n", "                ", "avg_spans", ".", "append", "(", "\n", "layer", ".", "attn", ".", "attn", ".", "adaptive_span", ".", "get_current_avg_span", "(", ")", ")", "\n", "max_spans", ".", "append", "(", "\n", "layer", ".", "attn", ".", "attn", ".", "adaptive_span", ".", "get_current_max_span", "(", ")", ")", "\n", "", "span_avg", "=", "float", "(", "sum", "(", "avg_spans", ")", ")", "/", "len", "(", "avg_spans", ")", "\n", "span_max", "=", "float", "(", "max", "(", "max_spans", ")", ")", "\n", "self", ".", "_log", "(", "'span_avg'", ",", "span_avg", ")", "\n", "self", ".", "_log", "(", "'span_max'", ",", "span_max", ")", "\n", "msg", "+=", "\"\\tspan_avg: {:.0f}\\tspan_max: {:.0f}\"", ".", "format", "(", "span_avg", ",", "span_max", ")", "\n", "\n", "", "print", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._parse_args": [[18, 25], ["argparse.ArgumentParser", "argparse.ArgumentParser.parse_args", "params_config[].items", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "_parse_args", "(", "params_config", ",", "args", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "for", "params_category", "in", "params_config", ":", "# e.g., 'model_params'", "\n", "        ", "for", "param_flag", ",", "param_config", "in", "params_config", "[", "params_category", "]", ".", "items", "(", ")", ":", "\n", "# e.g., param_flag = '--block-sz'", "\n", "            ", "parser", ".", "add_argument", "(", "param_flag", ",", "**", "param_config", ")", "\n", "", "", "return", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.get_params": [[27, 36], ["utils._parse_args", "_parse_args.__getattribute__", "params_config[].values"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._parse_args"], ["", "def", "get_params", "(", "params_config", ",", "args", "=", "None", ")", ":", "\n", "    ", "namespace", "=", "_parse_args", "(", "params_config", ",", "args", ")", "\n", "return", "{", "\n", "params_category", ":", "{", "\n", "param_config", "[", "'dest'", "]", ":", "\n", "namespace", ".", "__getattribute__", "(", "param_config", "[", "'dest'", "]", ")", "\n", "for", "param_config", "in", "params_config", "[", "params_category", "]", ".", "values", "(", ")", "\n", "}", "\n", "for", "params_category", "in", "params_config", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._torch_distributed_init_process_group": [[43, 55], ["torch.distributed.init_process_group", "torch.distributed.get_rank", "torch.distributed.get_world_size", "print", "torch.cuda.set_device"], "function", ["None"], ["", "def", "_torch_distributed_init_process_group", "(", "local_rank", ")", ":", "\n", "    ", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "'nccl'", ",", "\n", "init_method", "=", "'env://'", "\n", ")", "\n", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "print", "(", "'my rank={} local_rank={}'", ".", "format", "(", "rank", ",", "local_rank", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "return", "{", "\n", "'rank'", ":", "rank", ",", "\n", "'world_size'", ":", "world_size", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.set_up_env": [[57, 64], ["torch.cuda.is_available", "torch.device", "env_params.update", "utils._torch_distributed_init_process_group"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._torch_distributed_init_process_group"], ["", "def", "set_up_env", "(", "env_params", ")", ":", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "env_params", "[", "'distributed'", "]", ":", "\n", "        ", "env_params", ".", "update", "(", "\n", "_torch_distributed_init_process_group", "(", "\n", "local_rank", "=", "env_params", "[", "'local_rank'", "]", ")", ")", "\n", "", "env_params", "[", "'device'", "]", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._get_grad_requiring_params": [[70, 79], ["model.parameters", "print", "param.numel", "grad_requiring_params.append"], "function", ["None"], ["", "def", "_get_grad_requiring_params", "(", "model", ")", ":", "\n", "    ", "nb_parameters", "=", "0", "\n", "grad_requiring_params", "=", "[", "]", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "requires_grad", ":", "\n", "            ", "nb_parameters", "+=", "param", ".", "numel", "(", ")", "\n", "grad_requiring_params", ".", "append", "(", "param", ")", "\n", "", "", "print", "(", "'nb_parameters={:.2f}M'", ".", "format", "(", "nb_parameters", "/", "1e6", ")", ")", "\n", "return", "grad_requiring_params", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._get_optimizer": [[81, 105], ["torch.optim.SGD", "utils._get_grad_requiring_params", "adagrad_with_grad_clip.AdagradWithGradClip", "utils._get_grad_requiring_params", "torch.optim.Adam", "RuntimeError", "utils._get_grad_requiring_params"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._get_grad_requiring_params", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._get_grad_requiring_params", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._get_grad_requiring_params"], ["", "def", "_get_optimizer", "(", "model", ",", "\n", "optim", ",", "\n", "lr", ":", "float", ",", "\n", "momentum", ":", "float", ",", "\n", "grad_clip", ":", "float", ")", ":", "\n", "    ", "if", "optim", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "_get_grad_requiring_params", "(", "model", ")", ",", "\n", "lr", "=", "lr", ",", "\n", "momentum", "=", "momentum", ")", "\n", "optimizer", ".", "grad_clip", "=", "grad_clip", "\n", "return", "optimizer", "\n", "", "elif", "optim", "==", "'adagrad'", ":", "\n", "        ", "optimizer", "=", "AdagradWithGradClip", "(", "_get_grad_requiring_params", "(", "model", ")", ",", "\n", "lr", "=", "lr", ",", "\n", "grad_clip", "=", "grad_clip", ")", "\n", "optimizer", ".", "grad_clip", "=", "0", "# done internally", "\n", "return", "optimizer", "\n", "", "elif", "optim", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "_get_grad_requiring_params", "(", "model", ")", ",", "\n", "lr", "=", "lr", ")", "\n", "optimizer", ".", "grad_clip", "=", "grad_clip", "\n", "return", "optimizer", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"wrong type of optimizer \"", "\n", "\"- must be 'sgd', 'adagrad' or 'adam'\"", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._get_scheduler": [[108, 113], ["torch.optim.lr_scheduler.LambdaLR", "min"], "function", ["None"], ["", "", "def", "_get_scheduler", "(", "optimizer", ",", "lr_warmup", ")", ":", "\n", "    ", "if", "lr_warmup", ">", "0", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "\n", "optimizer", ",", "lambda", "ep", ":", "min", "(", "1", ",", "ep", "/", "lr_warmup", ")", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.get_optimizer_and_scheduler": [[115, 124], ["utils._get_optimizer", "utils._get_scheduler"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._get_optimizer", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._get_scheduler"], ["", "def", "get_optimizer_and_scheduler", "(", "model", ",", "optim_params", ")", ":", "\n", "    ", "optimizer", "=", "_get_optimizer", "(", "model", "=", "model", ",", "\n", "optim", "=", "optim_params", "[", "'optim'", "]", ",", "\n", "lr", "=", "optim_params", "[", "'lr'", "]", ",", "\n", "momentum", "=", "optim_params", "[", "'momentum'", "]", ",", "\n", "grad_clip", "=", "optim_params", "[", "'grad_clip'", "]", ")", "\n", "scheduler", "=", "_get_scheduler", "(", "optimizer", "=", "optimizer", ",", "\n", "lr_warmup", "=", "optim_params", "[", "'lr_warmup'", "]", ")", "\n", "return", "optimizer", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._load_checkpoint": [[130, 147], ["print", "model.load_state_dict", "optimizer.load_state_dict", "logger.load_state_dict", "torch.load", "torch.load", "scheduler.step"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "_load_checkpoint", "(", "checkpoint_path", ",", "model", ",", "optimizer", ",", "scheduler", ",", "logger", ",", "\n", "distributed", ")", ":", "\n", "    ", "print", "(", "'loading from a checkpoint at {}'", ".", "format", "(", "checkpoint_path", ")", ")", "\n", "if", "distributed", ":", "\n", "# the model is saved from gpu0 so we need to map it to CPU first", "\n", "        ", "checkpoint_state", "=", "torch", ".", "load", "(", "\n", "checkpoint_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint_state", "=", "torch", ".", "load", "(", "checkpoint_path", ")", "\n", "", "iter_init", "=", "checkpoint_state", "[", "'iter_no'", "]", "+", "1", "# next iteration", "\n", "model", ".", "load_state_dict", "(", "checkpoint_state", "[", "'model'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint_state", "[", "'optimizer'", "]", ")", "\n", "logger", ".", "load_state_dict", "(", "checkpoint_state", "[", "'logger'", "]", ")", "\n", "if", "'scheduler_iter'", "in", "checkpoint_state", ":", "\n", "# we only need the step count", "\n", "        ", "scheduler", ".", "step", "(", "checkpoint_state", "[", "'scheduler_iter'", "]", ")", "\n", "", "return", "iter_init", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.load_checkpoint": [[149, 159], ["os.path.exists", "utils._load_checkpoint"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils._load_checkpoint"], ["", "def", "load_checkpoint", "(", "checkpoint_path", ",", "model", ",", "optimizer", ",", "scheduler", ",", "logger", ",", "\n", "distributed", ")", ":", "\n", "    ", "if", "checkpoint_path", "and", "os", ".", "path", ".", "exists", "(", "checkpoint_path", ")", ":", "\n", "        ", "return", "_load_checkpoint", "(", "checkpoint_path", "=", "checkpoint_path", ",", "\n", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "logger", "=", "logger", ",", "\n", "distributed", "=", "distributed", ")", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.save_checkpoint": [[161, 173], ["torch.save", "model.state_dict", "logger.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict"], ["", "def", "save_checkpoint", "(", "checkpoint_path", ",", "iter_no", ",", "model", ",", "\n", "optimizer", ",", "scheduler", ",", "logger", ")", ":", "\n", "    ", "if", "checkpoint_path", ":", "\n", "        ", "checkpoint_state", "=", "{", "\n", "'iter_no'", ":", "iter_no", ",", "# last completed iteration", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'logger'", ":", "logger", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "if", "scheduler", "is", "not", "None", ":", "\n", "            ", "checkpoint_state", "[", "'scheduler_iter'", "]", "=", "scheduler", ".", "last_epoch", "\n", "", "torch", ".", "save", "(", "checkpoint_state", ",", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.DistRLOrig.algorithm1.DistRLAgent.__init__": [[17, 24], ["torch.arange"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "quantile_net", ",", "N", ",", "k", ",", "discount", "=", "1", ")", ":", "\n", "        ", "self", ".", "quantile_net", "=", "quantile_net", "\n", "self", ".", "N", "=", "N", "#number of quantiles to use", "\n", "self", ".", "k", "=", "k", "#distance from origin to smooth in huber loss (see equation 9: https://arxiv.org/pdf/1710.10044.pdf)", "\n", "self", ".", "discount", "=", "discount", "\n", "self", ".", "tau", "=", "torch", ".", "arange", "(", "0.0", ",", "1.0", ",", "1", "/", "(", "self", ".", "N", "+", "1", ")", ")", "\n", "self", ".", "tau_hat", "=", "(", "self", ".", "tau", "[", "1", ":", "]", "-", "self", ".", "tau", "[", ":", "-", "1", "]", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.DistRLOrig.algorithm1.DistRLAgent.compute_loss": [[28, 49], ["theta_x.mean", "theta_x.mean.argmax", "torch.abs", "torch.sum", "torch.no_grad", "theta_targ.view", "theta_x.view", "torch.abs", "algorithm1.DistRLAgent.tau_hat.view", "torch.abs", "torch.abs", "algorithm1.DistRLAgent.tau_hat.view"], "methods", ["None"], ["def", "compute_loss", "(", "self", ",", "x", ",", "a", ",", "r", ",", "x_prime", ",", "theta_xprime", ",", "theta_x", ")", ":", "\n", "#first computing this for a single example", "\n", "\n", "#get Q(x,a) for all a then take arg max over the actions to get next action", "\n", "        ", "Q", "=", "theta_x", ".", "mean", "(", "axis", "=", "1", ")", "\n", "a_prime", "=", "Q", ".", "argmax", "(", ")", "\n", "\n", "#now detach from computation graph", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "theta_targ", "=", "r", "+", "self", ".", "discount", "*", "theta_xprime", "[", "a_prime", ",", ":", "]", "\n", "\n", "#now compute quantile regression loss", "\n", "", "u", "=", "theta_targ", ".", "view", "(", "1", ",", "-", "1", ")", "-", "theta_x", ".", "view", "(", "-", "1", ",", "1", ")", "#subtract all of theta_x from each element of theta_targ", "\n", "\n", "term1", "=", "torch", ".", "abs", "(", "self", ".", "tau_hat", ".", "view", "(", "-", "1", ",", "1", ")", "-", "(", "u", "<", "0", ")", ")", "\n", "term2", "=", "self", ".", "k", "*", "(", "torch", ".", "abs", "(", "u", ")", "-", "k", "/", "2", ")", "\n", "mask", "=", "(", "torch", ".", "abs", "(", "u", ")", "<", "self", ".", "k", ")", "\n", "term2", "[", "mask", "]", "=", "(", "u", "[", "mask", "]", "**", "2", ")", "/", "2", "\n", "loss", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "self", ".", "tau_hat", ".", "view", "(", "-", "1", ",", "1", ")", "-", "(", "u", "<", "0", ")", ")", "*", "term2", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.DistRLOrig.algorithm1.DistRLAgent.compute_loss_multi": [[50, 53], ["None"], "methods", ["None"], ["", "def", "compute_loss_multi", "(", "self", ",", "x", ",", "a", ",", "r", ",", "x_prime", ",", "theta_xprime", ",", "theta_x", ")", ":", "\n", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.AtariNet.__init__": [[348, 375], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LSTM"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "observation_shape", ",", "num_actions", ",", "use_lstm", "=", "False", ")", ":", "\n", "        ", "super", "(", "AtariNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "observation_shape", "=", "observation_shape", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "\n", "# Feature extraction.", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "self", ".", "observation_shape", "[", "0", "]", ",", "\n", "out_channels", "=", "32", ",", "\n", "kernel_size", "=", "8", ",", "\n", "stride", "=", "4", ",", "\n", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "# Fully connected layer.", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3136", ",", "512", ")", "\n", "\n", "# FC output size + one-hot of last action + last reward.", "\n", "core_output_size", "=", "self", ".", "fc", ".", "out_features", "+", "num_actions", "+", "1", "\n", "\n", "self", ".", "use_lstm", "=", "use_lstm", "\n", "if", "use_lstm", ":", "\n", "            ", "self", ".", "core", "=", "nn", ".", "LSTM", "(", "core_output_size", ",", "core_output_size", ",", "2", ")", "\n", "\n", "", "self", ".", "policy", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "baseline", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.AtariNet.initial_state": [[376, 382], ["tuple", "tuple", "torch.zeros", "range"], "methods", ["None"], ["", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "not", "self", ".", "use_lstm", ":", "\n", "            ", "return", "tuple", "(", ")", "\n", "", "return", "tuple", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "core", ".", "num_layers", ",", "batch_size", ",", "self", ".", "core", ".", "hidden_size", ")", "\n", "for", "_", "in", "range", "(", "2", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.AtariNet.forward": [[384, 434], ["torch.flatten", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu.view", "torch.nn.functional.relu", "torch.nn.functional.one_hot().float", "torch.clamp().view", "torch.cat", "monobeast_single_proc.AtariNet.policy", "monobeast_single_proc.AtariNet.baseline", "policy_logits.view.view.view", "baseline.view.view.view", "torch.argmax.view", "torch.nn.functional.relu.float", "monobeast_single_proc.AtariNet.conv1", "monobeast_single_proc.AtariNet.conv2", "monobeast_single_proc.AtariNet.conv3", "monobeast_single_proc.AtariNet.fc", "core_input.view.view.view", "zip", "torch.flatten", "tuple", "torch.multinomial", "torch.argmax", "dict", "torch.nn.functional.one_hot", "torch.clamp", "core_input.view.view.unbind", "notdone.unbind", "nd.view.view.view", "tuple", "monobeast_single_proc.AtariNet.core", "core_output_list.append", "torch.cat", "torch.nn.functional.softmax", "inputs[].view", "input.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "core_state", "=", "(", ")", ")", ":", "\n", "        ", "x", "=", "inputs", "[", "\"frame\"", "]", "# [T, B, C, H, W].", "\n", "T", ",", "B", ",", "*", "_", "=", "x", ".", "shape", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "0", ",", "1", ")", "# Merge time and batch.", "\n", "x", "=", "x", ".", "float", "(", ")", "/", "255.0", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv3", "(", "x", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n", "one_hot_last_action", "=", "F", ".", "one_hot", "(", "\n", "inputs", "[", "\"last_action\"", "]", ".", "view", "(", "T", "*", "B", ")", ",", "self", ".", "num_actions", "\n", ")", ".", "float", "(", ")", "\n", "clipped_reward", "=", "torch", ".", "clamp", "(", "inputs", "[", "\"reward\"", "]", ",", "-", "1", ",", "1", ")", ".", "view", "(", "T", "*", "B", ",", "1", ")", "\n", "core_input", "=", "torch", ".", "cat", "(", "[", "x", ",", "clipped_reward", ",", "one_hot_last_action", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "use_lstm", ":", "\n", "            ", "core_input", "=", "core_input", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "\n", "core_output_list", "=", "[", "]", "\n", "notdone", "=", "(", "~", "inputs", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "\n", "for", "input", ",", "nd", "in", "zip", "(", "core_input", ".", "unbind", "(", ")", ",", "notdone", ".", "unbind", "(", ")", ")", ":", "\n", "# Reset core state to zero whenever an episode ended.", "\n", "# Make `done` broadcastable with (num_layers, B, hidden_size)", "\n", "# states:", "\n", "                ", "nd", "=", "nd", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "core_state", "=", "tuple", "(", "nd", "*", "s", "for", "s", "in", "core_state", ")", "\n", "output", ",", "core_state", "=", "self", ".", "core", "(", "input", ".", "unsqueeze", "(", "0", ")", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "output", ")", "\n", "", "core_output", "=", "torch", ".", "flatten", "(", "torch", ".", "cat", "(", "core_output_list", ")", ",", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "core_output", "=", "core_input", "\n", "core_state", "=", "tuple", "(", ")", "\n", "\n", "", "policy_logits", "=", "self", ".", "policy", "(", "core_output", ")", "\n", "baseline", "=", "self", ".", "baseline", "(", "core_output", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "action", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "policy_logits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "# Don't sample when testing.", "\n", "            ", "action", "=", "torch", ".", "argmax", "(", "policy_logits", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_logits", "=", "policy_logits", ".", "view", "(", "T", ",", "B", ",", "self", ".", "num_actions", ")", "\n", "baseline", "=", "baseline", ".", "view", "(", "T", ",", "B", ")", "\n", "action", "=", "action", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "return", "(", "\n", "dict", "(", "policy_logits", "=", "policy_logits", ",", "baseline", "=", "baseline", ",", "action", "=", "action", ")", ",", "\n", "core_state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.compute_baseline_loss": [[93, 95], ["torch.sum"], "function", ["None"], ["def", "compute_baseline_loss", "(", "advantages", ")", ":", "\n", "    ", "return", "0.5", "*", "torch", ".", "sum", "(", "advantages", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.compute_entropy_loss": [[97, 102], ["torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.sum"], "function", ["None"], ["", "def", "compute_entropy_loss", "(", "logits", ")", ":", "\n", "    ", "\"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"", "\n", "policy", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "log_policy", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "sum", "(", "policy", "*", "log_policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.compute_policy_gradient_loss": [[104, 112], ["torch.nn.functional.nll_loss", "cross_entropy.view_as.view_as", "torch.sum", "torch.nn.functional.log_softmax", "torch.flatten", "torch.flatten", "advantages.detach"], "function", ["None"], ["", "def", "compute_policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ")", ":", "\n", "    ", "cross_entropy", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "logits", ",", "0", ",", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "torch", ".", "flatten", "(", "actions", ",", "0", ",", "1", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", "\n", "cross_entropy", "=", "cross_entropy", ".", "view_as", "(", "advantages", ")", "\n", "return", "torch", ".", "sum", "(", "cross_entropy", "*", "advantages", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.act": [[114, 181], ["logging.info", "Model.core.prof.Timings", "monobeast_single_proc.create_env", "create_env.seed", "Model.core.environment.Environment", "environment.Environment.initial", "model.initial_state", "model", "int.from_bytes", "enumerate", "range", "full_queue.put", "logging.info", "logging.error", "traceback.print_exc", "print", "os.urandom", "free_queue.get", "prof.Timings.reset", "prof.Timings.time", "environment.Environment.step", "prof.Timings.time", "prof.Timings.time", "prof.Timings.summary", "print", "torch.no_grad", "model"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary"], ["", "def", "act", "(", "\n", "flags", ",", "\n", "actor_index", ":", "int", ",", "\n", "free_queue", ":", "queue", ".", "Queue", ",", "\n", "full_queue", ":", "queue", ".", "Queue", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"Actor %i started.\"", ",", "actor_index", ")", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "# Keep track of how fast things are.", "\n", "\n", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "seed", "=", "actor_index", "^", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "4", ")", ",", "byteorder", "=", "\"little\"", ")", "\n", "gym_env", ".", "seed", "(", "seed", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "env_output", "=", "env", ".", "initial", "(", ")", "\n", "agent_state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "agent_output", ",", "unused_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "index", "=", "free_queue", ".", "get", "(", "False", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# if index is None:", "\n", "                ", "print", "(", "'actor raised exception maybe due to free_queeue'", ",", "e", ")", "\n", "break", "\n", "\n", "# Write old rollout end.", "\n", "", "for", "key", "in", "env_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "agent_state", ")", ":", "\n", "                ", "initial_agent_state_buffers", "[", "index", "]", "[", "i", "]", "[", "...", "]", "=", "tensor", "\n", "\n", "# Do new rollout.", "\n", "", "for", "t", "in", "range", "(", "flags", ".", "unroll_length", ")", ":", "\n", "                ", "timings", ".", "reset", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "agent_output", ",", "agent_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "\n", "", "timings", ".", "time", "(", "\"model\"", ")", "\n", "\n", "env_output", "=", "env", ".", "step", "(", "agent_output", "[", "\"action\"", "]", ")", "\n", "\n", "timings", ".", "time", "(", "\"step\"", ")", "\n", "\n", "for", "key", "in", "env_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "\n", "", "timings", ".", "time", "(", "\"write\"", ")", "\n", "", "full_queue", ".", "put", "(", "index", ")", "\n", "\n", "", "if", "actor_index", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Actor %i: %s\"", ",", "actor_index", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# Return silently.", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logging", ".", "error", "(", "\"Exception in worker process %i\"", ",", "actor_index", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "print", "(", ")", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.get_batch": [[184, 214], ["timings.time", "timings.time", "timings.time", "timings.time", "tuple", "timings.time", "full_queue.get", "torch.stack", "torch.cat", "free_queue.put", "t.to", "range", "zip", "batch.items", "t.to"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["", "", "def", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ":", "queue", ".", "Queue", ",", "\n", "full_queue", ":", "queue", ".", "Queue", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", "\n", "# lock=threading.Lock(),", "\n", ")", ":", "\n", "# with lock:", "\n", "    ", "timings", ".", "time", "(", "\"lock\"", ")", "\n", "indices", "=", "[", "full_queue", ".", "get", "(", "False", ")", "for", "_", "in", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "timings", ".", "time", "(", "\"dequeue\"", ")", "\n", "batch", "=", "{", "\n", "key", ":", "torch", ".", "stack", "(", "[", "buffers", "[", "key", "]", "[", "m", "]", "for", "m", "in", "indices", "]", ",", "dim", "=", "1", ")", "for", "key", "in", "buffers", "\n", "}", "\n", "initial_agent_state", "=", "(", "\n", "torch", ".", "cat", "(", "ts", ",", "dim", "=", "1", ")", "\n", "for", "ts", "in", "zip", "(", "*", "[", "initial_agent_state_buffers", "[", "m", "]", "for", "m", "in", "indices", "]", ")", "\n", ")", "\n", "timings", ".", "time", "(", "\"batch\"", ")", "\n", "for", "m", "in", "indices", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "", "timings", ".", "time", "(", "\"enqueue\"", ")", "\n", "batch", "=", "{", "k", ":", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "k", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "initial_agent_state", "=", "tuple", "(", "\n", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "t", "in", "initial_agent_state", "\n", ")", "\n", "timings", ".", "time", "(", "\"device\"", ")", "\n", "return", "batch", ",", "initial_agent_state", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.learn": [[216, 288], ["model", "Model.core.vtrace.from_logits", "monobeast_single_proc.compute_policy_gradient_loss", "logging.info", "optimizer.zero_grad", "total_loss.backward", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "actor_model.load_state_dict", "torch.clamp", "monobeast_single_proc.compute_baseline_loss", "monobeast_single_proc.compute_entropy_loss", "tuple", "torch.mean().item", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "model.parameters", "model.state_dict", "batch.items", "learner_outputs.items", "episode_returns.cpu().numpy", "torch.mean", "episode_returns.cpu"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict"], ["", "def", "learn", "(", "\n", "flags", ",", "\n", "actor_model", ",", "\n", "model", ",", "\n", "batch", ",", "\n", "initial_agent_state", ",", "\n", "optimizer", ",", "\n", "scheduler", "\n", "# lock=threading.Lock(),  # noqa: B008", "\n", ")", ":", "\n", "    ", "\"\"\"Performs a learning (optimization) step.\"\"\"", "\n", "# with lock:", "\n", "learner_outputs", ",", "unused_state", "=", "model", "(", "batch", ",", "initial_agent_state", ")", "\n", "\n", "# Take final value function slice for bootstrapping.", "\n", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "-", "1", "]", "\n", "\n", "# Move from obs[t] -> action[t] to action[t] -> obs[t].", "\n", "batch", "=", "{", "key", ":", "tensor", "[", "1", ":", "]", "for", "key", ",", "tensor", "in", "batch", ".", "items", "(", ")", "}", "\n", "learner_outputs", "=", "{", "key", ":", "tensor", "[", ":", "-", "1", "]", "for", "key", ",", "tensor", "in", "learner_outputs", ".", "items", "(", ")", "}", "\n", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "\n", "if", "flags", ".", "reward_clipping", "==", "\"abs_one\"", ":", "\n", "        ", "clipped_rewards", "=", "torch", ".", "clamp", "(", "rewards", ",", "-", "1", ",", "1", ")", "\n", "", "elif", "flags", ".", "reward_clipping", "==", "\"none\"", ":", "\n", "        ", "clipped_rewards", "=", "rewards", "\n", "\n", "", "discounts", "=", "(", "~", "batch", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "*", "flags", ".", "discounting", "\n", "\n", "vtrace_returns", "=", "vtrace", ".", "from_logits", "(", "\n", "behavior_policy_logits", "=", "batch", "[", "\"policy_logits\"", "]", ",", "\n", "target_policy_logits", "=", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "actions", "=", "batch", "[", "\"action\"", "]", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "clipped_rewards", ",", "\n", "values", "=", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", ")", "\n", "\n", "pg_loss", "=", "compute_policy_gradient_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "batch", "[", "\"action\"", "]", ",", "\n", "vtrace_returns", ".", "pg_advantages", ",", "\n", ")", "\n", "baseline_loss", "=", "flags", ".", "baseline_cost", "*", "compute_baseline_loss", "(", "\n", "vtrace_returns", ".", "vs", "-", "learner_outputs", "[", "\"baseline\"", "]", "\n", ")", "\n", "entropy_loss", "=", "flags", ".", "entropy_cost", "*", "compute_entropy_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", "\n", ")", "\n", "\n", "total_loss", "=", "pg_loss", "+", "baseline_loss", "+", "entropy_loss", "\n", "\n", "episode_returns", "=", "batch", "[", "\"episode_return\"", "]", "[", "batch", "[", "\"done\"", "]", "]", "\n", "logging", ".", "info", "(", "'Episode returns : %s'", ",", "episode_returns", ")", "\n", "stats", "=", "{", "\n", "\"episode_returns\"", ":", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "\"mean_episode_return\"", ":", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ",", "\n", "\"total_loss\"", ":", "total_loss", ".", "item", "(", ")", ",", "\n", "\"pg_loss\"", ":", "pg_loss", ".", "item", "(", ")", ",", "\n", "\"baseline_loss\"", ":", "baseline_loss", ".", "item", "(", ")", ",", "\n", "\"entropy_loss\"", ":", "entropy_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "flags", ".", "grad_norm_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "actor_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.create_buffers": [[290, 308], ["dict", "range", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "buffers[].append", "torch.empty().share_memory_", "torch.empty"], "function", ["None"], ["", "def", "create_buffers", "(", "flags", ",", "obs_shape", ",", "num_actions", ")", "->", "Buffers", ":", "\n", "    ", "T", "=", "flags", ".", "unroll_length", "\n", "specs", "=", "dict", "(", "\n", "frame", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "*", "obs_shape", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "reward", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "done", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "\n", "episode_return", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "episode_step", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "policy_logits", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "num_actions", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "baseline", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "last_action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", ")", "\n", "buffers", ":", "Buffers", "=", "{", "key", ":", "[", "]", "for", "key", "in", "specs", "}", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "for", "key", "in", "buffers", ":", "\n", "            ", "buffers", "[", "key", "]", ".", "append", "(", "torch", ".", "empty", "(", "**", "specs", "[", "key", "]", ")", ".", "share_memory_", "(", ")", ")", "\n", "", "", "return", "buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.test": [[310, 344], ["monobeast_single_proc.create_env", "Model.core.environment.Environment", "Net", "Net.eval", "torch.load", "Net.load_state_dict", "environment.Environment.initial", "environment.Environment.close", "logging.info", "os.path.expandvars", "len", "Net.", "environment.Environment.step", "observation[].item", "os.path.expanduser", "environment.Environment.gym_env.render", "returns.append", "logging.info", "sum", "len", "observation[].item", "observation[].item", "observation[].item"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "test", "(", "flags", ",", "num_episodes", ":", "int", "=", "10", ")", ":", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "checkpointpath", "=", "\"./latest/model.tar\"", "\n", "", "else", ":", "\n", "        ", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "model", "=", "Net", "(", "gym_env", ".", "observation_space", ".", "shape", ",", "gym_env", ".", "action_space", ".", "n", ",", "flags", ".", "use_lstm", ")", "\n", "model", ".", "eval", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpointpath", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "\n", "observation", "=", "env", ".", "initial", "(", ")", "\n", "returns", "=", "[", "]", "\n", "\n", "while", "len", "(", "returns", ")", "<", "num_episodes", ":", "\n", "        ", "if", "flags", ".", "mode", "==", "\"test_render\"", ":", "\n", "            ", "env", ".", "gym_env", ".", "render", "(", ")", "\n", "", "agent_outputs", "=", "model", "(", "observation", ")", "\n", "policy_outputs", ",", "_", "=", "agent_outputs", "\n", "observation", "=", "env", ".", "step", "(", "policy_outputs", "[", "\"action\"", "]", ")", "\n", "if", "observation", "[", "\"done\"", "]", ".", "item", "(", ")", ":", "\n", "            ", "returns", ".", "append", "(", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Episode ended after %d steps. Return: %.1f\"", ",", "\n", "observation", "[", "\"episode_step\"", "]", ".", "item", "(", ")", ",", "\n", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Average returns over %i steps: %.1f\"", ",", "num_episodes", ",", "sum", "(", "returns", ")", "/", "len", "(", "returns", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.create_env": [[439, 446], ["Model.atari_wrappers.wrap_pytorch", "Model.atari_wrappers.wrap_deepmind", "Model.atari_wrappers.make_atari"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_pytorch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.make_atari"], ["def", "create_env", "(", "flags", ")", ":", "\n", "    ", "return", "atari_wrappers", ".", "wrap_pytorch", "(", "\n", "atari_wrappers", ".", "wrap_deepmind", "(", "\n", "atari_wrappers", ".", "make_atari", "(", "flags", ".", "env", ")", ",", "\n", "clip_rewards", "=", "False", ",", "\n", "frame_stack", "=", "True", ",", "\n", "scale", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.lr_lambda": [[543, 545], ["min"], "function", ["None"], ["def", "lr_lambda", "(", "epoch", ")", ":", "\n", "    ", "return", "1", "-", "min", "(", "epoch", "*", "T", "*", "B", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.batch_and_learn": [[560, 587], ["threading.Lock", "Model.core.prof.Timings", "prof.Timings.reset", "monobeast_single_proc.get_batch", "monobeast_single_proc.learn", "prof.Timings.time", "dict", "dict.update", "plogger.log", "logging.info", "prof.Timings.summary"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_batch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.learn", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.log", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary"], ["def", "batch_and_learn", "(", "i", ",", "lock", "=", "threading", ".", "Lock", "(", ")", ")", ":", "\n", "    ", "\"\"\"Thread target for the learning process.\"\"\"", "\n", "# nonlocal non_local_step, non_local_stats", "\n", "non_local_step", ",", "non_local_stats", "=", "0", ",", "{", "}", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "\n", "while", "non_local_step", "<", "flags", ".", "total_steps", ":", "\n", "        ", "timings", ".", "reset", "(", ")", "\n", "batch", ",", "agent_state", "=", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", ")", "\n", "non_local_stats", "=", "learn", "(", "\n", "flags", ",", "model", ",", "learner_model", ",", "batch", ",", "agent_state", ",", "optimizer", ",", "scheduler", "\n", ")", "\n", "timings", ".", "time", "(", "\"learn\"", ")", "\n", "# with lock:", "\n", "to_log", "=", "dict", "(", "step", "=", "non_local_step", ")", "\n", "to_log", ".", "update", "(", "{", "k", ":", "non_local_stats", "[", "k", "]", "for", "k", "in", "stat_keys", "}", ")", "\n", "plogger", ".", "log", "(", "to_log", ")", "\n", "non_local_step", "+=", "T", "*", "B", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "        ", "logging", ".", "info", "(", "\"Batch and learn: %s\"", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.checkpoint": [[613, 625], ["logging.info", "torch.save", "model.state_dict", "optimizer.state_dict", "scheduler.state_dict", "vars"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.vars"], ["def", "checkpoint", "(", ")", ":", "\n", "    ", "if", "flags", ".", "disable_checkpoint", ":", "\n", "        ", "return", "\n", "", "logging", ".", "info", "(", "\"Saving checkpoint to %s\"", ",", "checkpointpath", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"flags\"", ":", "vars", "(", "flags", ")", ",", "\n", "}", ",", "\n", "checkpointpath", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.AtariNet.__init__": [[546, 573], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LSTM"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["logging", ".", "info", "(", "\n", "\"Average returns over %i steps: %.1f\"", ",", "num_episodes", ",", "sum", "(", "returns", ")", "/", "len", "(", "returns", ")", "\n", ")", "\n", "\n", "\n", "", "class", "AtariNet", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "observation_shape", ",", "num_actions", ",", "use_lstm", "=", "False", ")", ":", "\n", "        ", "super", "(", "AtariNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "observation_shape", "=", "observation_shape", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "\n", "# Feature extraction.", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "self", ".", "observation_shape", "[", "0", "]", ",", "\n", "out_channels", "=", "32", ",", "\n", "kernel_size", "=", "8", ",", "\n", "stride", "=", "4", ",", "\n", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "# Fully connected layer.", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "2560", ",", "512", ")", "\n", "\n", "# FC output size + one-hot of last action + last reward.", "\n", "core_output_size", "=", "self", ".", "fc", ".", "out_features", "+", "num_actions", "+", "1", "\n", "\n", "self", ".", "use_lstm", "=", "use_lstm", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.AtariNet.initial_state": [[574, 580], ["tuple", "tuple", "torch.zeros", "range"], "methods", ["None"], ["if", "use_lstm", ":", "\n", "            ", "self", ".", "core", "=", "nn", ".", "LSTM", "(", "core_output_size", ",", "core_output_size", ",", "2", ")", "\n", "\n", "", "self", ".", "policy", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "baseline", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "1", ")", "\n", "\n", "", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.AtariNet.forward": [[582, 632], ["torch.flatten", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu.view", "torch.nn.functional.relu", "torch.nn.functional.one_hot().float", "torch.clamp().view", "torch.cat", "monobeast.AtariNet.policy", "monobeast.AtariNet.baseline", "policy_logits.view.view.view", "baseline.view.view.view", "torch.argmax.view", "torch.nn.functional.relu.float", "monobeast.AtariNet.conv1", "monobeast.AtariNet.conv2", "monobeast.AtariNet.conv3", "monobeast.AtariNet.fc", "core_input.view.view.view", "zip", "torch.flatten", "tuple", "torch.multinomial", "torch.argmax", "dict", "torch.nn.functional.one_hot", "torch.clamp", "core_input.view.view.unbind", "notdone.unbind", "nd.view.view.view", "tuple", "monobeast.AtariNet.core", "core_output_list.append", "torch.cat", "torch.nn.functional.softmax", "inputs[].view", "input.unsqueeze"], "methods", ["None"], ["            ", "return", "tuple", "(", ")", "\n", "", "return", "tuple", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "core", ".", "num_layers", ",", "batch_size", ",", "self", ".", "core", ".", "hidden_size", ")", "\n", "for", "_", "in", "range", "(", "2", ")", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "inputs", ",", "core_state", "=", "(", ")", ")", ":", "\n", "        ", "x", "=", "inputs", "[", "\"frame\"", "]", "# [T, B, C, H, W].", "\n", "T", ",", "B", ",", "*", "_", "=", "x", ".", "shape", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "0", ",", "1", ")", "# Merge time and batch.", "\n", "x", "=", "x", ".", "float", "(", ")", "/", "255.0", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv3", "(", "x", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n", "one_hot_last_action", "=", "F", ".", "one_hot", "(", "\n", "inputs", "[", "\"last_action\"", "]", ".", "view", "(", "T", "*", "B", ")", ",", "self", ".", "num_actions", "\n", ")", ".", "float", "(", ")", "\n", "clipped_reward", "=", "torch", ".", "clamp", "(", "inputs", "[", "\"reward\"", "]", ",", "-", "1", ",", "1", ")", ".", "view", "(", "T", "*", "B", ",", "1", ")", "\n", "core_input", "=", "torch", ".", "cat", "(", "[", "x", ",", "clipped_reward", ",", "one_hot_last_action", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "use_lstm", ":", "\n", "            ", "core_input", "=", "core_input", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "\n", "core_output_list", "=", "[", "]", "\n", "notdone", "=", "(", "~", "inputs", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "\n", "for", "input", ",", "nd", "in", "zip", "(", "core_input", ".", "unbind", "(", ")", ",", "notdone", ".", "unbind", "(", ")", ")", ":", "\n", "# Reset core state to zero whenever an episode ended.", "\n", "# Make `done` broadcastable with (num_layers, B, hidden_size)", "\n", "# states:", "\n", "                ", "nd", "=", "nd", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "core_state", "=", "tuple", "(", "nd", "*", "s", "for", "s", "in", "core_state", ")", "\n", "output", ",", "core_state", "=", "self", ".", "core", "(", "input", ".", "unsqueeze", "(", "0", ")", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "output", ")", "\n", "", "core_output", "=", "torch", ".", "flatten", "(", "torch", ".", "cat", "(", "core_output_list", ")", ",", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "core_output", "=", "core_input", "\n", "core_state", "=", "tuple", "(", ")", "\n", "\n", "", "policy_logits", "=", "self", ".", "policy", "(", "core_output", ")", "\n", "baseline", "=", "self", ".", "baseline", "(", "core_output", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "action", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "policy_logits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "# Don't sample when testing.", "\n", "            ", "action", "=", "torch", ".", "argmax", "(", "policy_logits", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_logits", "=", "policy_logits", ".", "view", "(", "T", ",", "B", ",", "self", ".", "num_actions", ")", "\n", "baseline", "=", "baseline", ".", "view", "(", "T", ",", "B", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.compute_baseline_loss": [[107, 109], ["torch.sum"], "function", ["None"], ["\n", "Buffers", "=", "typing", ".", "Dict", "[", "str", ",", "typing", ".", "List", "[", "torch", ".", "Tensor", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.compute_entropy_loss": [[111, 116], ["torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.sum"], "function", ["None"], ["def", "compute_baseline_loss", "(", "advantages", ")", ":", "\n", "    ", "return", "0.5", "*", "torch", ".", "sum", "(", "advantages", "**", "2", ")", "\n", "\n", "\n", "", "def", "compute_entropy_loss", "(", "logits", ")", ":", "\n", "    ", "\"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.compute_policy_gradient_loss": [[118, 126], ["torch.nn.functional.nll_loss", "cross_entropy.view_as.view_as", "torch.sum", "torch.nn.functional.log_softmax", "torch.flatten", "torch.flatten", "advantages.detach"], "function", ["None"], ["log_policy", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "sum", "(", "policy", "*", "log_policy", ")", "\n", "\n", "\n", "", "def", "compute_policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ")", ":", "\n", "    ", "cross_entropy", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "logits", ",", "0", ",", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "torch", ".", "flatten", "(", "actions", ",", "0", ",", "1", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.act": [[128, 192], ["logging.info", "Model.core.prof.Timings", "monobeast.create_env", "create_env.seed", "Model.core.environment.Environment", "environment.Environment.initial", "model.initial_state", "model", "int.from_bytes", "free_queue.get", "enumerate", "range", "full_queue.put", "logging.info", "logging.error", "traceback.print_exc", "print", "os.urandom", "os.urandom", "prof.Timings.reset", "prof.Timings.time", "environment.Environment.step", "prof.Timings.time", "prof.Timings.time", "prof.Timings.summary", "torch.no_grad", "model"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary"], ["cross_entropy", "=", "cross_entropy", ".", "view_as", "(", "advantages", ")", "\n", "return", "torch", ".", "sum", "(", "cross_entropy", "*", "advantages", ".", "detach", "(", ")", ")", "\n", "\n", "\n", "######changes function input with level name", "\n", "", "def", "act", "(", "\n", "flags", ",", "\n", "actor_index", ":", "int", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "level_name", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"Actor %i started.\"", ",", "actor_index", ")", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "# Keep track of how fast things are.", "\n", "seed", "=", "actor_index", "^", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "4", ")", ",", "byteorder", "=", "\"little\"", ")", "\n", "######changed next line", "\n", "gym_env", "=", "create_env", "(", "flags", ",", "level_name", ",", "seed", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "env_output", "=", "env", ".", "initial", "(", ")", "\n", "agent_state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "agent_output", ",", "unused_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "while", "True", ":", "\n", "            ", "index", "=", "free_queue", ".", "get", "(", ")", "\n", "if", "index", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "# Write old rollout end.", "\n", "", "for", "key", "in", "env_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "agent_state", ")", ":", "\n", "                ", "initial_agent_state_buffers", "[", "index", "]", "[", "i", "]", "[", "...", "]", "=", "tensor", "\n", "\n", "# Do new rollout.", "\n", "", "for", "t", "in", "range", "(", "flags", ".", "unroll_length", ")", ":", "\n", "                ", "timings", ".", "reset", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "agent_output", ",", "agent_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "\n", "", "timings", ".", "time", "(", "\"model\"", ")", "\n", "\n", "env_output", "=", "env", ".", "step", "(", "agent_output", "[", "\"action\"", "]", ")", "\n", "\n", "timings", ".", "time", "(", "\"step\"", ")", "\n", "\n", "for", "key", "in", "env_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "\n", "", "timings", ".", "time", "(", "\"write\"", ")", "\n", "", "full_queue", ".", "put", "(", "index", ")", "\n", "\n", "", "if", "actor_index", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Actor %i: %s\"", ",", "actor_index", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# Return silently.", "\n", "", "except", "Exception", "as", "e", ":", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.get_batch": [[194, 224], ["threading.Lock", "timings.time", "timings.time", "tuple", "timings.time", "timings.time", "timings.time", "torch.stack", "torch.cat", "free_queue.put", "t.to", "full_queue.get", "zip", "batch.items", "t.to", "range"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["traceback", ".", "print_exc", "(", ")", "\n", "print", "(", ")", "\n", "raise", "e", "\n", "\n", "\n", "", "", "def", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "\n", ")", ":", "\n", "    ", "with", "lock", ":", "\n", "        ", "timings", ".", "time", "(", "\"lock\"", ")", "\n", "indices", "=", "[", "full_queue", ".", "get", "(", ")", "for", "_", "in", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "timings", ".", "time", "(", "\"dequeue\"", ")", "\n", "", "batch", "=", "{", "\n", "key", ":", "torch", ".", "stack", "(", "[", "buffers", "[", "key", "]", "[", "m", "]", "for", "m", "in", "indices", "]", ",", "dim", "=", "1", ")", "for", "key", "in", "buffers", "\n", "}", "\n", "initial_agent_state", "=", "(", "\n", "torch", ".", "cat", "(", "ts", ",", "dim", "=", "1", ")", "\n", "for", "ts", "in", "zip", "(", "*", "[", "initial_agent_state_buffers", "[", "m", "]", "for", "m", "in", "indices", "]", ")", "\n", ")", "\n", "timings", ".", "time", "(", "\"batch\"", ")", "\n", "for", "m", "in", "indices", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "", "timings", ".", "time", "(", "\"enqueue\"", ")", "\n", "batch", "=", "{", "k", ":", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "k", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "initial_agent_state", "=", "tuple", "(", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.learn": [[226, 297], ["threading.Lock", "model", "Model.core.vtrace.from_logits", "monobeast.compute_policy_gradient_loss", "optimizer.zero_grad", "total_loss.backward", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "actor_model.load_state_dict", "torch.clamp", "monobeast.compute_baseline_loss", "monobeast.compute_entropy_loss", "tuple", "torch.mean().item", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "model.parameters", "model.state_dict", "batch.items", "learner_outputs.items", "episode_returns.cpu().numpy", "torch.mean", "episode_returns.cpu"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict"], [")", "\n", "timings", ".", "time", "(", "\"device\"", ")", "\n", "return", "batch", ",", "initial_agent_state", "\n", "\n", "\n", "", "def", "learn", "(", "\n", "flags", ",", "\n", "actor_model", ",", "\n", "model", ",", "\n", "batch", ",", "\n", "initial_agent_state", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "# noqa: B008", "\n", ")", ":", "\n", "    ", "\"\"\"Performs a learning (optimization) step.\"\"\"", "\n", "with", "lock", ":", "\n", "        ", "learner_outputs", ",", "unused_state", "=", "model", "(", "batch", ",", "initial_agent_state", ")", "\n", "\n", "# Take final value function slice for bootstrapping.", "\n", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "-", "1", "]", "\n", "\n", "# Move from obs[t] -> action[t] to action[t] -> obs[t].", "\n", "batch", "=", "{", "key", ":", "tensor", "[", "1", ":", "]", "for", "key", ",", "tensor", "in", "batch", ".", "items", "(", ")", "}", "\n", "learner_outputs", "=", "{", "key", ":", "tensor", "[", ":", "-", "1", "]", "for", "key", ",", "tensor", "in", "learner_outputs", ".", "items", "(", ")", "}", "\n", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "\n", "if", "flags", ".", "reward_clipping", "==", "\"abs_one\"", ":", "\n", "            ", "clipped_rewards", "=", "torch", ".", "clamp", "(", "rewards", ",", "-", "1", ",", "1", ")", "\n", "", "elif", "flags", ".", "reward_clipping", "==", "\"none\"", ":", "\n", "            ", "clipped_rewards", "=", "rewards", "\n", "\n", "", "discounts", "=", "(", "~", "batch", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "*", "flags", ".", "discounting", "\n", "\n", "vtrace_returns", "=", "vtrace", ".", "from_logits", "(", "\n", "behavior_policy_logits", "=", "batch", "[", "\"policy_logits\"", "]", ",", "\n", "target_policy_logits", "=", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "actions", "=", "batch", "[", "\"action\"", "]", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "clipped_rewards", ",", "\n", "values", "=", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", ")", "\n", "\n", "pg_loss", "=", "compute_policy_gradient_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "batch", "[", "\"action\"", "]", ",", "\n", "vtrace_returns", ".", "pg_advantages", ",", "\n", ")", "\n", "baseline_loss", "=", "flags", ".", "baseline_cost", "*", "compute_baseline_loss", "(", "\n", "vtrace_returns", ".", "vs", "-", "learner_outputs", "[", "\"baseline\"", "]", "\n", ")", "\n", "entropy_loss", "=", "flags", ".", "entropy_cost", "*", "compute_entropy_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", "\n", ")", "\n", "\n", "total_loss", "=", "pg_loss", "+", "baseline_loss", "+", "entropy_loss", "\n", "\n", "episode_returns", "=", "batch", "[", "\"episode_return\"", "]", "[", "batch", "[", "\"done\"", "]", "]", "\n", "stats", "=", "{", "\n", "\"episode_returns\"", ":", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "\"mean_episode_return\"", ":", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ",", "\n", "\"total_loss\"", ":", "total_loss", ".", "item", "(", ")", ",", "\n", "\"pg_loss\"", ":", "pg_loss", ".", "item", "(", ")", ",", "\n", "\"baseline_loss\"", ":", "baseline_loss", ".", "item", "(", ")", ",", "\n", "\"entropy_loss\"", ":", "entropy_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "flags", ".", "grad_norm_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.create_buffers": [[299, 317], ["dict", "range", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "buffers[].append", "torch.empty().share_memory_", "torch.empty"], "function", ["None"], ["\n", "actor_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "stats", "\n", "\n", "\n", "", "", "def", "create_buffers", "(", "flags", ",", "obs_shape", ",", "num_actions", ")", "->", "Buffers", ":", "\n", "    ", "T", "=", "flags", ".", "unroll_length", "\n", "specs", "=", "dict", "(", "\n", "frame", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "*", "obs_shape", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "reward", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "done", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "\n", "episode_return", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "episode_step", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "policy_logits", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "num_actions", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "baseline", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "last_action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", ")", "\n", "buffers", ":", "Buffers", "=", "{", "key", ":", "[", "]", "for", "key", "in", "specs", "}", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.train": [[319, 506], ["Model.core.file_writer.FileWriter", "os.path.expandvars", "os.path.expandvars", "monobeast.create_env", "Net", "monobeast.create_buffers", "Net.share_memory", "range", "torch.multiprocessing.get_context", "mp.get_context.SimpleQueue", "mp.get_context.SimpleQueue", "range", "Net().to", "torch.optim.RMSprop", "torch.optim.lr_scheduler.LambdaLR", "logging.getLogger", "logging.getLogger.info", "range", "range", "monobeast.train.checkpoint"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_buffers", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.checkpoint"], ["        ", "for", "key", "in", "buffers", ":", "\n", "            ", "buffers", "[", "key", "]", ".", "append", "(", "torch", ".", "empty", "(", "**", "specs", "[", "key", "]", ")", ".", "share_memory_", "(", ")", ")", "\n", "", "", "return", "buffers", "\n", "\n", "\n", "####changed function input", "\n", "", "def", "train", "(", "flags", ")", ":", "# pylint: disable=too-many-branches, too-many-statements", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "flags", ".", "xpid", "=", "\"torchbeast-%s\"", "%", "time", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "", "plogger", "=", "file_writer", ".", "FileWriter", "(", "\n", "xpid", "=", "flags", ".", "xpid", ",", "xp_args", "=", "flags", ".", "__dict__", ",", "rootdir", "=", "flags", ".", "savedir", "\n", ")", "\n", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "if", "flags", ".", "num_buffers", "is", "None", ":", "# Set sensible default for num_buffers.", "\n", "        ", "flags", ".", "num_buffers", "=", "max", "(", "2", "*", "flags", ".", "num_actors", ",", "flags", ".", "batch_size", ")", "\n", "", "if", "flags", ".", "num_actors", ">=", "flags", ".", "num_buffers", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than num_actors\"", ")", "\n", "", "if", "flags", ".", "num_buffers", "<", "flags", ".", "batch_size", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than batch_size\"", ")", "\n", "\n", "", "T", "=", "flags", ".", "unroll_length", "\n", "B", "=", "flags", ".", "batch_size", "\n", "\n", "flags", ".", "device", "=", "None", "\n", "if", "not", "flags", ".", "disable_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Not using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "######I changed the next two line with level name and env.initial", "\n", "", "env", "=", "create_env", "(", "flags", ",", "flags", ".", "level_name", ",", "1", ")", "\n", "model", "=", "Net", "(", "env", ".", "initial", "(", ")", ".", "shape", ",", "len", "(", "environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", ".", "use_lstm", ")", "\n", "buffers", "=", "create_buffers", "(", "flags", ",", "env", ".", "_observation", "(", ")", ".", "shape", ",", "model", ".", "num_actions", ")", "\n", "print", "(", "env", ".", "_observation", "(", ")", ".", "shape", ")", "\n", "model", ".", "share_memory", "(", ")", "\n", "\n", "# Add initial RNN state.", "\n", "initial_agent_state_buffers", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "for", "t", "in", "state", ":", "\n", "            ", "t", ".", "share_memory_", "(", ")", "\n", "", "initial_agent_state_buffers", ".", "append", "(", "state", ")", "\n", "\n", "", "actor_processes", "=", "[", "]", "\n", "ctx", "=", "mp", ".", "get_context", "(", "\"fork\"", ")", "\n", "free_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "full_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "##########I changed this part", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "        ", "actor", "=", "ctx", ".", "Process", "(", "\n", "target", "=", "act", ",", "\n", "args", "=", "(", "\n", "flags", ",", "\n", "i", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "model", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "flags", ".", "level_name", "\n", ")", ",", "\n", ")", "\n", "actor", ".", "start", "(", ")", "\n", "actor_processes", ".", "append", "(", "actor", ")", "\n", "\n", "", "learner_model", "=", "Net", "(", "\n", "env", ".", "_observation", "(", ")", ".", "shape", ",", "len", "(", "environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", ".", "use_lstm", "\n", ")", ".", "to", "(", "device", "=", "flags", ".", "device", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "\n", "learner_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "flags", ".", "learning_rate", ",", "\n", "momentum", "=", "flags", ".", "momentum", ",", "\n", "eps", "=", "flags", ".", "epsilon", ",", "\n", "alpha", "=", "flags", ".", "alpha", ",", "\n", ")", "\n", "\n", "def", "lr_lambda", "(", "epoch", ")", ":", "\n", "        ", "return", "1", "-", "min", "(", "epoch", "*", "T", "*", "B", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "\n", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"logfile\"", ")", "\n", "stat_keys", "=", "[", "\n", "\"total_loss\"", ",", "\n", "\"mean_episode_return\"", ",", "\n", "\"pg_loss\"", ",", "\n", "\"baseline_loss\"", ",", "\n", "\"entropy_loss\"", ",", "\n", "]", "\n", "logger", ".", "info", "(", "\"# Step\\t%s\"", ",", "\"\\t\"", ".", "join", "(", "stat_keys", ")", ")", "\n", "\n", "step", ",", "stats", "=", "0", ",", "{", "}", "\n", "\n", "def", "batch_and_learn", "(", "i", ",", "lock", "=", "threading", ".", "Lock", "(", ")", ")", ":", "\n", "        ", "\"\"\"Thread target for the learning process.\"\"\"", "\n", "nonlocal", "step", ",", "stats", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "timings", ".", "reset", "(", ")", "\n", "batch", ",", "agent_state", "=", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", ")", "\n", "stats", "=", "learn", "(", "\n", "flags", ",", "model", ",", "learner_model", ",", "batch", ",", "agent_state", ",", "optimizer", ",", "scheduler", "\n", ")", "\n", "timings", ".", "time", "(", "\"learn\"", ")", "\n", "with", "lock", ":", "\n", "                ", "to_log", "=", "dict", "(", "step", "=", "step", ")", "\n", "to_log", ".", "update", "(", "{", "k", ":", "stats", "[", "k", "]", "for", "k", "in", "stat_keys", "}", ")", "\n", "plogger", ".", "log", "(", "to_log", ")", "\n", "step", "+=", "T", "*", "B", "\n", "\n", "", "", "if", "i", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Batch and learn: %s\"", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "for", "m", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_learner_threads", ")", ":", "\n", "        ", "thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "batch_and_learn", ",", "name", "=", "\"batch-and-learn-%d\"", "%", "i", ",", "args", "=", "(", "i", ",", ")", "\n", ")", "\n", "thread", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "thread", ")", "\n", "\n", "", "def", "checkpoint", "(", ")", ":", "\n", "        ", "if", "flags", ".", "disable_checkpoint", ":", "\n", "            ", "return", "\n", "", "logging", ".", "info", "(", "\"Saving checkpoint to %s\"", ",", "checkpointpath", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"flags\"", ":", "vars", "(", "flags", ")", ",", "\n", "}", ",", "\n", "checkpointpath", ",", "\n", ")", "\n", "\n", "", "timer", "=", "timeit", ".", "default_timer", "\n", "try", ":", "\n", "        ", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "start_step", "=", "step", "\n", "start_time", "=", "timer", "(", ")", "\n", "time", ".", "sleep", "(", "5", ")", "\n", "\n", "if", "timer", "(", ")", "-", "last_checkpoint_time", ">", "10", "*", "60", ":", "# Save every 10 min.", "\n", "                ", "checkpoint", "(", ")", "\n", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "\n", "", "sps", "=", "(", "step", "-", "start_step", ")", "/", "(", "timer", "(", ")", "-", "start_time", ")", "\n", "if", "stats", ".", "get", "(", "\"episode_returns\"", ",", "None", ")", ":", "\n", "                ", "mean_return", "=", "(", "\n", "\"Return per episode: %.1f. \"", "%", "stats", "[", "\"mean_episode_return\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "mean_return", "=", "\"\"", "\n", "", "total_loss", "=", "stats", ".", "get", "(", "\"total_loss\"", ",", "float", "(", "\"inf\"", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Steps %i @ %.1f SPS. Loss %f. %sStats:\\n%s\"", ",", "\n", "step", ",", "\n", "sps", ",", "\n", "total_loss", ",", "\n", "mean_return", ",", "\n", "pprint", ".", "pformat", "(", "stats", ")", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "return", "# Try joining actors then quit.", "\n", "", "else", ":", "\n", "        ", "for", "thread", "in", "threads", ":", "\n", "            ", "thread", ".", "join", "(", ")", "\n", "", "logging", ".", "info", "(", "\"Learning finished after %d steps.\"", ",", "step", ")", "\n", "", "finally", ":", "\n", "        ", "for", "_", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "            ", "free_queue", ".", "put", "(", "None", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.test": [[508, 542], ["monobeast.create_env", "Model.core.environment.Environment", "Net", "Net.eval", "torch.load", "Net.load_state_dict", "environment.Environment.initial", "environment.Environment.close", "logging.info", "os.path.expandvars", "os.path.expandvars", "len", "Net.", "environment.Environment.step", "observation[].item", "os.path.expanduser", "os.path.expanduser", "environment.Environment.gym_env.render", "returns.append", "logging.info", "sum", "len", "observation[].item", "observation[].item", "observation[].item"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["            ", "actor", ".", "join", "(", "timeout", "=", "1", ")", "\n", "\n", "", "", "checkpoint", "(", ")", "\n", "plogger", ".", "close", "(", ")", "\n", "\n", "\n", "", "def", "test", "(", "flags", ",", "num_episodes", ":", "int", "=", "10", ")", ":", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "checkpointpath", "=", "\"./latest/model.tar\"", "\n", "", "else", ":", "\n", "        ", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "", "gym_env", "=", "create_env", "(", "flags", ",", "flags", ".", "level_name", ",", "1", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "model", "=", "Net", "(", "gym_env", ".", "_observation", "(", ")", ".", "shape", ",", "len", "(", "environment", ".", "DEFAULT_ACTION_SET", ")", ",", "flags", ".", "use_lstm", ")", "\n", "model", ".", "eval", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpointpath", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "\n", "observation", "=", "env", ".", "initial", "(", ")", "\n", "returns", "=", "[", "]", "\n", "\n", "while", "len", "(", "returns", ")", "<", "num_episodes", ":", "\n", "# if flags.mode == \"test_render\":", "\n", "# env.gym_env.render()", "\n", "        ", "agent_outputs", "=", "model", "(", "observation", ")", "\n", "policy_outputs", ",", "_", "=", "agent_outputs", "\n", "observation", "=", "env", ".", "step", "(", "policy_outputs", "[", "\"action\"", "]", ")", "\n", "if", "observation", "[", "\"done\"", "]", ".", "item", "(", ")", ":", "\n", "            ", "returns", ".", "append", "(", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Episode ended after %d steps. Return: %.1f\"", ",", "\n", "observation", "[", "\"episode_step\"", "]", ".", "item", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.create_env": [[638, 645], ["Model.atari_wrappers.wrap_pytorch", "Model.atari_wrappers.wrap_deepmind", "Model.atari_wrappers.make_atari"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_pytorch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.make_atari"], [")", "\n", "\n", "\n", "", "", "Net", "=", "AtariNet", "\n", "\n", "\n", "#######I changed the create_env function to match dmlab", "\n", "def", "create_env", "(", "flags", ",", "level_name", ",", "seed", "=", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast.main": [[649, 654], ["monobeast.train", "monobeast.test"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.test"], ["'height'", ":", "72", ",", "\n", "'logLevel'", ":", "'WARN'", ",", "\n", "}", "\n", "return", "dmlab_wrappers", ".", "createDmLab", "(", "level_name", ",", "config", ",", "seed", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.AtariNet.__init__": [[553, 627], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "feats_convs.append", "feats_convs.append", "monobeast_baseline.AtariNet.feat_convs.append", "range", "torch.nn.LSTM", "monobeast_baseline.AtariNet.core.parameters", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "torch.nn.Sequential", "resnet_block.append", "resnet_block.append", "resnet_block.append", "resnet_block.append", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "monobeast_baseline.AtariNet.resnet1.append", "monobeast_baseline.AtariNet.resnet2.append", "param.dim", "torch.nn.init.xavier_normal_", "torch.nn.Sequential", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "observation_shape", ",", "num_actions", ",", "use_lstm", "=", "False", ",", "lstm_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "AtariNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "observation_shape", "=", "observation_shape", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "\n", "self", ".", "feat_convs", "=", "[", "]", "\n", "self", ".", "resnet1", "=", "[", "]", "\n", "self", ".", "resnet2", "=", "[", "]", "\n", "\n", "self", ".", "convs", "=", "[", "]", "\n", "input_channels", "=", "self", ".", "observation_shape", "[", "0", "]", "\n", "for", "num_ch", "in", "[", "16", ",", "32", ",", "32", "]", ":", "\n", "            ", "feats_convs", "=", "[", "]", "\n", "feats_convs", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "feats_convs", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "self", ".", "feat_convs", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "feats_convs", ")", ")", "\n", "\n", "input_channels", "=", "num_ch", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "                ", "resnet_block", "=", "[", "]", "\n", "resnet_block", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "resnet_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "resnet_block", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "resnet_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "self", ".", "resnet1", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "resnet_block", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "resnet2", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "resnet_block", ")", ")", "\n", "\n", "", "", "", "self", ".", "feat_convs", "=", "nn", ".", "ModuleList", "(", "self", ".", "feat_convs", ")", "\n", "self", ".", "resnet1", "=", "nn", ".", "ModuleList", "(", "self", ".", "resnet1", ")", "\n", "self", ".", "resnet2", "=", "nn", ".", "ModuleList", "(", "self", ".", "resnet2", ")", "\n", "\n", "# Fully connected layer.", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3872", ",", "256", ")", "\n", "\n", "# FC output size + one-hot of last action + last reward.", "\n", "core_output_size", "=", "self", ".", "fc", ".", "out_features", "+", "num_actions", "+", "1", "\n", "###############################################################transformer", "\n", "self", ".", "use_lstm", "=", "use_lstm", "\n", "if", "use_lstm", ":", "\n", "            ", "self", ".", "core", "=", "nn", ".", "LSTM", "(", "core_output_size", ",", "core_output_size", ",", "lstm_layers", ")", "\n", "#initialize parameters", "\n", "for", "param", "in", "self", ".", "core", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "nn", ".", "init", ".", "xavier_normal_", "(", "param", ")", "\n", "\n", "", "", "", "self", ".", "policy", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "baseline", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.AtariNet.initial_state": [[628, 634], ["tuple", "tuple", "torch.zeros", "range"], "methods", ["None"], ["", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "not", "self", ".", "use_lstm", ":", "\n", "            ", "return", "tuple", "(", ")", "\n", "", "return", "tuple", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "core", ".", "num_layers", ",", "batch_size", ",", "self", ".", "core", ".", "hidden_size", ")", "\n", "for", "_", "in", "range", "(", "2", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.AtariNet.forward": [[636, 697], ["torch.flatten", "enumerate", "torch.nn.functional.relu", "fconv.view", "torch.nn.functional.relu", "torch.nn.functional.one_hot().float", "torch.clamp().view", "torch.cat", "monobeast_baseline.AtariNet.policy", "monobeast_baseline.AtariNet.baseline", "policy_logits.view.view.view", "baseline.view.view.view", "torch.argmax.view", "fconv.float", "fconv", "monobeast_baseline.AtariNet.fc", "core_input.view.view.view", "zip", "torch.flatten", "tuple", "torch.multinomial", "torch.argmax", "dict", "torch.nn.functional.one_hot", "torch.clamp", "core_input.view.view.unbind", "notdone.unbind", "nd.view.view.view", "tuple", "monobeast_baseline.AtariNet.core", "core_output_list.append", "torch.cat", "torch.nn.functional.softmax", "inputs[].view", "input.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "core_state", "=", "(", ")", ")", ":", "\n", "\n", "        ", "x", "=", "inputs", "[", "\"frame\"", "]", "\n", "T", ",", "B", ",", "*", "_", "=", "x", ".", "shape", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "0", ",", "1", ")", "# Merge time and batch.", "\n", "x", "=", "x", ".", "float", "(", ")", "/", "255.0", "\n", "\n", "res_input", "=", "None", "\n", "for", "i", ",", "fconv", "in", "enumerate", "(", "self", ".", "feat_convs", ")", ":", "\n", "            ", "x", "=", "fconv", "(", "x", ")", "\n", "res_input", "=", "x", "\n", "x", "=", "self", ".", "resnet1", "[", "i", "]", "(", "x", ")", "\n", "x", "+=", "res_input", "\n", "res_input", "=", "x", "\n", "x", "=", "self", ".", "resnet2", "[", "i", "]", "(", "x", ")", "\n", "x", "+=", "res_input", "\n", "\n", "", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n", "one_hot_last_action", "=", "F", ".", "one_hot", "(", "\n", "inputs", "[", "\"last_action\"", "]", ".", "view", "(", "T", "*", "B", ")", ",", "self", ".", "num_actions", "\n", ")", ".", "float", "(", ")", "\n", "clipped_reward", "=", "torch", ".", "clamp", "(", "inputs", "[", "\"reward\"", "]", ",", "-", "1", ",", "1", ")", ".", "view", "(", "T", "*", "B", ",", "1", ")", "\n", "core_input", "=", "torch", ".", "cat", "(", "[", "x", ",", "clipped_reward", ",", "one_hot_last_action", "]", ",", "dim", "=", "-", "1", ")", "\n", "###############################################################transformer", "\n", "if", "self", ".", "use_lstm", ":", "\n", "            ", "core_input", "=", "core_input", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "\n", "core_output_list", "=", "[", "]", "\n", "notdone", "=", "(", "~", "inputs", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "\n", "for", "input", ",", "nd", "in", "zip", "(", "core_input", ".", "unbind", "(", ")", ",", "notdone", ".", "unbind", "(", ")", ")", ":", "\n", "# Reset core state to zero whenever an episode ended.", "\n", "# Make `done` broadcastable with (num_layers, B, hidden_size)", "\n", "# states:", "\n", "                ", "nd", "=", "nd", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "core_state", "=", "tuple", "(", "nd", "*", "s", "for", "s", "in", "core_state", ")", "\n", "output", ",", "core_state", "=", "self", ".", "core", "(", "input", ".", "unsqueeze", "(", "0", ")", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "output", ")", "\n", "", "core_output", "=", "torch", ".", "flatten", "(", "torch", ".", "cat", "(", "core_output_list", ")", ",", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "core_output", "=", "core_input", "\n", "core_state", "=", "tuple", "(", ")", "\n", "\n", "", "policy_logits", "=", "self", ".", "policy", "(", "core_output", ")", "\n", "baseline", "=", "self", ".", "baseline", "(", "core_output", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "# print('core input : {} policy logits : {} T : {} B : {}'.format(core_output.shape, policy_logits.shape, T, B))", "\n", "            ", "action", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "policy_logits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "# Don't sample when testing.", "\n", "            ", "action", "=", "torch", ".", "argmax", "(", "policy_logits", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_logits", "=", "policy_logits", ".", "view", "(", "T", ",", "B", ",", "self", ".", "num_actions", ")", "\n", "baseline", "=", "baseline", ".", "view", "(", "T", ",", "B", ")", "\n", "action", "=", "action", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "return", "(", "\n", "dict", "(", "policy_logits", "=", "policy_logits", ",", "baseline", "=", "baseline", ",", "action", "=", "action", ")", ",", "\n", "core_state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.compute_baseline_loss": [[103, 105], ["torch.sum"], "function", ["None"], ["def", "compute_baseline_loss", "(", "advantages", ")", ":", "\n", "    ", "return", "0.5", "*", "torch", ".", "sum", "(", "advantages", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.compute_entropy_loss": [[107, 112], ["torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.sum"], "function", ["None"], ["", "def", "compute_entropy_loss", "(", "logits", ")", ":", "\n", "    ", "\"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"", "\n", "policy", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "log_policy", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "sum", "(", "policy", "*", "log_policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.compute_policy_gradient_loss": [[114, 122], ["torch.nn.functional.nll_loss", "cross_entropy.view_as.view_as", "torch.sum", "torch.nn.functional.log_softmax", "torch.flatten", "torch.flatten", "advantages.detach"], "function", ["None"], ["", "def", "compute_policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ")", ":", "\n", "    ", "cross_entropy", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "logits", ",", "0", ",", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "torch", ".", "flatten", "(", "actions", ",", "0", ",", "1", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", "\n", "cross_entropy", "=", "cross_entropy", ".", "view_as", "(", "advantages", ")", "\n", "return", "torch", ".", "sum", "(", "cross_entropy", "*", "advantages", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.act": [[124, 188], ["logging.info", "Model.core.prof.Timings", "monobeast_baseline.create_env", "create_env.seed", "Model.core.environment.Environment", "environment.Environment.initial", "model.initial_state", "model", "int.from_bytes", "free_queue.get", "enumerate", "range", "full_queue.put", "logging.info", "logging.error", "traceback.print_exc", "print", "os.urandom", "prof.Timings.reset", "prof.Timings.time", "environment.Environment.step", "prof.Timings.time", "prof.Timings.time", "prof.Timings.summary", "torch.no_grad", "model"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary"], ["", "def", "act", "(", "\n", "flags", ",", "\n", "actor_index", ":", "int", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"Actor %i started.\"", ",", "actor_index", ")", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "# Keep track of how fast things are.", "\n", "\n", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "seed", "=", "actor_index", "^", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "4", ")", ",", "byteorder", "=", "\"little\"", ")", "\n", "gym_env", ".", "seed", "(", "seed", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "env_output", "=", "env", ".", "initial", "(", ")", "\n", "agent_state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "agent_output", ",", "unused_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "while", "True", ":", "\n", "            ", "index", "=", "free_queue", ".", "get", "(", ")", "\n", "if", "index", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "# Write old rollout end.", "\n", "", "for", "key", "in", "env_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "agent_state", ")", ":", "\n", "                ", "initial_agent_state_buffers", "[", "index", "]", "[", "i", "]", "[", "...", "]", "=", "tensor", "\n", "\n", "# Do new rollout.", "\n", "", "for", "t", "in", "range", "(", "flags", ".", "unroll_length", ")", ":", "\n", "                ", "timings", ".", "reset", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "agent_output", ",", "agent_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "\n", "", "timings", ".", "time", "(", "\"model\"", ")", "\n", "\n", "env_output", "=", "env", ".", "step", "(", "agent_output", "[", "\"action\"", "]", ")", "\n", "\n", "timings", ".", "time", "(", "\"step\"", ")", "\n", "\n", "for", "key", "in", "env_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "\n", "", "timings", ".", "time", "(", "\"write\"", ")", "\n", "", "full_queue", ".", "put", "(", "index", ")", "\n", "\n", "", "if", "actor_index", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Actor %i: %s\"", ",", "actor_index", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# Return silently.", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logging", ".", "error", "(", "\"Exception in worker process %i\"", ",", "actor_index", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "print", "(", ")", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.get_batch": [[190, 220], ["threading.Lock", "timings.time", "timings.time", "tuple", "timings.time", "timings.time", "timings.time", "torch.stack", "torch.cat", "free_queue.put", "t.to", "full_queue.get", "zip", "batch.items", "t.to", "range"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["", "", "def", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "\n", ")", ":", "\n", "    ", "with", "lock", ":", "\n", "        ", "timings", ".", "time", "(", "\"lock\"", ")", "\n", "indices", "=", "[", "full_queue", ".", "get", "(", ")", "for", "_", "in", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "timings", ".", "time", "(", "\"dequeue\"", ")", "\n", "", "batch", "=", "{", "\n", "key", ":", "torch", ".", "stack", "(", "[", "buffers", "[", "key", "]", "[", "m", "]", "for", "m", "in", "indices", "]", ",", "dim", "=", "1", ")", "for", "key", "in", "buffers", "\n", "}", "\n", "initial_agent_state", "=", "(", "\n", "torch", ".", "cat", "(", "ts", ",", "dim", "=", "1", ")", "\n", "for", "ts", "in", "zip", "(", "*", "[", "initial_agent_state_buffers", "[", "m", "]", "for", "m", "in", "indices", "]", ")", "\n", ")", "\n", "timings", ".", "time", "(", "\"batch\"", ")", "\n", "for", "m", "in", "indices", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "", "timings", ".", "time", "(", "\"enqueue\"", ")", "\n", "batch", "=", "{", "k", ":", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "k", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "initial_agent_state", "=", "tuple", "(", "\n", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "t", "in", "initial_agent_state", "\n", ")", "\n", "timings", ".", "time", "(", "\"device\"", ")", "\n", "return", "batch", ",", "initial_agent_state", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.learn": [[222, 299], ["threading.Lock", "model", "Model.core.vtrace.from_logits", "monobeast_baseline.compute_policy_gradient_loss", "optimizer.zero_grad", "total_loss.backward", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "actor_model.load_state_dict", "torch.clamp", "monobeast_baseline.compute_baseline_loss", "monobeast_baseline.compute_entropy_loss", "tuple", "torch.mean().item", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "model.parameters", "model.state_dict", "batch.items", "learner_outputs.items", "episode_returns.cpu().numpy", "torch.mean", "episode_returns.cpu"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict"], ["", "def", "learn", "(", "\n", "flags", ",", "\n", "actor_model", ",", "\n", "model", ",", "\n", "batch", ",", "\n", "initial_agent_state", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "# noqa: B008", "\n", ")", ":", "\n", "    ", "\"\"\"Performs a learning (optimization) step.\"\"\"", "\n", "with", "lock", ":", "\n", "        ", "\"\"\"\n        put a lock on the central learner,\n        send the trajectories to it.\n        Update the parameters of the central learner,\n        copy the parameters of the central learner back to the actors\n        \"\"\"", "\n", "learner_outputs", ",", "unused_state", "=", "model", "(", "batch", ",", "initial_agent_state", ")", "\n", "\n", "# Take final value function slice for bootstrapping.", "\n", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "-", "1", "]", "\n", "\n", "# Move from obs[t] -> action[t] to action[t] -> obs[t].", "\n", "batch", "=", "{", "key", ":", "tensor", "[", "1", ":", "]", "for", "key", ",", "tensor", "in", "batch", ".", "items", "(", ")", "}", "\n", "learner_outputs", "=", "{", "key", ":", "tensor", "[", ":", "-", "1", "]", "for", "key", ",", "tensor", "in", "learner_outputs", ".", "items", "(", ")", "}", "\n", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "\n", "if", "flags", ".", "reward_clipping", "==", "\"abs_one\"", ":", "\n", "            ", "clipped_rewards", "=", "torch", ".", "clamp", "(", "rewards", ",", "-", "1", ",", "1", ")", "\n", "", "elif", "flags", ".", "reward_clipping", "==", "\"none\"", ":", "\n", "            ", "clipped_rewards", "=", "rewards", "\n", "\n", "", "discounts", "=", "(", "~", "batch", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "*", "flags", ".", "discounting", "\n", "\n", "vtrace_returns", "=", "vtrace", ".", "from_logits", "(", "\n", "behavior_policy_logits", "=", "batch", "[", "\"policy_logits\"", "]", ",", "\n", "target_policy_logits", "=", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "actions", "=", "batch", "[", "\"action\"", "]", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "clipped_rewards", ",", "\n", "values", "=", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", ")", "\n", "\n", "pg_loss", "=", "compute_policy_gradient_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "batch", "[", "\"action\"", "]", ",", "\n", "vtrace_returns", ".", "pg_advantages", ",", "\n", ")", "\n", "baseline_loss", "=", "flags", ".", "baseline_cost", "*", "compute_baseline_loss", "(", "\n", "vtrace_returns", ".", "vs", "-", "learner_outputs", "[", "\"baseline\"", "]", "\n", ")", "\n", "entropy_loss", "=", "flags", ".", "entropy_cost", "*", "compute_entropy_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", "\n", ")", "\n", "\n", "total_loss", "=", "pg_loss", "+", "baseline_loss", "+", "entropy_loss", "\n", "\n", "episode_returns", "=", "batch", "[", "\"episode_return\"", "]", "[", "batch", "[", "\"done\"", "]", "]", "\n", "stats", "=", "{", "\n", "\"episode_returns\"", ":", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "\"mean_episode_return\"", ":", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ",", "\n", "\"total_loss\"", ":", "total_loss", ".", "item", "(", ")", ",", "\n", "\"pg_loss\"", ":", "pg_loss", ".", "item", "(", ")", ",", "\n", "\"baseline_loss\"", ":", "baseline_loss", ".", "item", "(", ")", ",", "\n", "\"entropy_loss\"", ":", "entropy_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "flags", ".", "grad_norm_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "actor_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.create_buffers": [[301, 319], ["dict", "range", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "buffers[].append", "torch.empty().share_memory_", "torch.empty"], "function", ["None"], ["", "", "def", "create_buffers", "(", "flags", ",", "obs_shape", ",", "num_actions", ")", "->", "Buffers", ":", "\n", "    ", "T", "=", "flags", ".", "unroll_length", "\n", "specs", "=", "dict", "(", "\n", "frame", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "*", "obs_shape", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "reward", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "done", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "\n", "episode_return", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "episode_step", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "policy_logits", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "num_actions", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "baseline", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "last_action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", ")", "\n", "buffers", ":", "Buffers", "=", "{", "key", ":", "[", "]", "for", "key", "in", "specs", "}", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "for", "key", "in", "buffers", ":", "\n", "            ", "buffers", "[", "key", "]", ".", "append", "(", "torch", ".", "empty", "(", "**", "specs", "[", "key", "]", ")", ".", "share_memory_", "(", ")", ")", "\n", "", "", "return", "buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.train": [[321, 512], ["Model.core.file_writer.FileWriter", "os.path.expandvars", "monobeast_baseline.create_env", "Net", "monobeast_baseline.create_buffers", "Net.share_memory", "range", "torch.multiprocessing.get_context", "mp.get_context.SimpleQueue", "mp.get_context.SimpleQueue", "range", "Net().to", "torch.optim.RMSprop", "torch.optim.lr_scheduler.LambdaLR", "logging.getLogger", "logging.getLogger.info", "range", "range", "monobeast_baseline.train.checkpoint"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_buffers", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.checkpoint"], ["", "def", "train", "(", "flags", ")", ":", "# pylint: disable=too-many-branches, too-many-statements", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "flags", ".", "xpid", "=", "\"torchbeast-%s\"", "%", "time", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "", "plogger", "=", "file_writer", ".", "FileWriter", "(", "\n", "xpid", "=", "flags", ".", "xpid", ",", "xp_args", "=", "flags", ".", "__dict__", ",", "rootdir", "=", "flags", ".", "savedir", "\n", ")", "\n", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "if", "flags", ".", "num_buffers", "is", "None", ":", "# Set sensible default for num_buffers.", "\n", "        ", "flags", ".", "num_buffers", "=", "max", "(", "2", "*", "flags", ".", "num_actors", ",", "flags", ".", "batch_size", ")", "\n", "", "if", "flags", ".", "num_actors", ">=", "flags", ".", "num_buffers", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than num_actors\"", ")", "\n", "", "if", "flags", ".", "num_buffers", "<", "flags", ".", "batch_size", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than batch_size\"", ")", "\n", "\n", "", "T", "=", "flags", ".", "unroll_length", "\n", "B", "=", "flags", ".", "batch_size", "\n", "\n", "flags", ".", "device", "=", "None", "\n", "if", "not", "flags", ".", "disable_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Not using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "env", "=", "create_env", "(", "flags", ")", "\n", "\n", "\"\"\"model is each of the actors, running parallel. The upcoming block ctx.Process(...)\"\"\"", "\n", "model", "=", "Net", "(", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ",", "\n", "flags", ".", "use_lstm", ",", "flags", ".", "lstm_layers", ")", "\n", "buffers", "=", "create_buffers", "(", "flags", ",", "env", ".", "observation_space", ".", "shape", ",", "model", ".", "num_actions", ")", "\n", "\n", "model", ".", "share_memory", "(", ")", "\n", "\n", "# Add initial RNN state.", "\n", "initial_agent_state_buffers", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "for", "t", "in", "state", ":", "\n", "            ", "t", ".", "share_memory_", "(", ")", "\n", "", "initial_agent_state_buffers", ".", "append", "(", "state", ")", "\n", "\n", "", "actor_processes", "=", "[", "]", "\n", "ctx", "=", "mp", ".", "get_context", "(", "\"fork\"", ")", "\n", "free_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "full_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "        ", "actor", "=", "ctx", ".", "Process", "(", "\n", "target", "=", "act", ",", "\n", "args", "=", "(", "\n", "flags", ",", "\n", "i", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "model", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ",", "\n", ")", "\n", "actor", ".", "start", "(", ")", "\n", "actor_processes", ".", "append", "(", "actor", ")", "\n", "\n", "", "\"\"\"learner_model is the central learner, which takes in the experiences and updates itself\"\"\"", "\n", "learner_model", "=", "Net", "(", "\n", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ",", "flags", ".", "use_lstm", ",", "\n", "flags", ".", "lstm_layers", "\n", ")", ".", "to", "(", "device", "=", "flags", ".", "device", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "\n", "learner_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "flags", ".", "learning_rate", ",", "\n", "momentum", "=", "flags", ".", "momentum", ",", "\n", "eps", "=", "flags", ".", "epsilon", ",", "\n", "alpha", "=", "flags", ".", "alpha", ",", "\n", ")", "\n", "\n", "def", "lr_lambda", "(", "epoch", ")", ":", "\n", "        ", "return", "1", "-", "min", "(", "epoch", "*", "T", "*", "B", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "\n", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"logfile\"", ")", "\n", "stat_keys", "=", "[", "\n", "\"total_loss\"", ",", "\n", "\"mean_episode_return\"", ",", "\n", "\"pg_loss\"", ",", "\n", "\"baseline_loss\"", ",", "\n", "\"entropy_loss\"", ",", "\n", "]", "\n", "logger", ".", "info", "(", "\"# Step\\t%s\"", ",", "\"\\t\"", ".", "join", "(", "stat_keys", ")", ")", "\n", "\n", "step", ",", "stats", "=", "0", ",", "{", "}", "\n", "\n", "def", "batch_and_learn", "(", "i", ",", "lock", "=", "threading", ".", "Lock", "(", ")", ")", ":", "\n", "        ", "\"\"\"Thread target for the learning process.\"\"\"", "\n", "nonlocal", "step", ",", "stats", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "timings", ".", "reset", "(", ")", "\n", "batch", ",", "agent_state", "=", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", ")", "\n", "stats", "=", "learn", "(", "\n", "flags", ",", "model", ",", "learner_model", ",", "batch", ",", "agent_state", ",", "optimizer", ",", "scheduler", "\n", ")", "\n", "timings", ".", "time", "(", "\"learn\"", ")", "\n", "with", "lock", ":", "\n", "                ", "to_log", "=", "dict", "(", "step", "=", "step", ")", "\n", "to_log", ".", "update", "(", "{", "k", ":", "stats", "[", "k", "]", "for", "k", "in", "stat_keys", "}", ")", "\n", "plogger", ".", "log", "(", "to_log", ")", "\n", "step", "+=", "T", "*", "B", "\n", "\n", "", "", "if", "i", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Batch and learn: %s\"", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "for", "m", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_learner_threads", ")", ":", "\n", "        ", "thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "batch_and_learn", ",", "name", "=", "\"batch-and-learn-%d\"", "%", "i", ",", "args", "=", "(", "i", ",", ")", "\n", ")", "\n", "thread", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "thread", ")", "\n", "\n", "", "def", "checkpoint", "(", ")", ":", "\n", "        ", "if", "flags", ".", "disable_checkpoint", ":", "\n", "            ", "return", "\n", "", "logging", ".", "info", "(", "\"Saving checkpoint to %s\"", ",", "checkpointpath", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"flags\"", ":", "vars", "(", "flags", ")", ",", "\n", "}", ",", "\n", "checkpointpath", ",", "\n", ")", "\n", "\n", "", "timer", "=", "timeit", ".", "default_timer", "\n", "try", ":", "\n", "        ", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "start_step", "=", "step", "\n", "start_time", "=", "timer", "(", ")", "\n", "time", ".", "sleep", "(", "5", ")", "\n", "\n", "if", "timer", "(", ")", "-", "last_checkpoint_time", ">", "10", "*", "60", ":", "# Save every 10 min.", "\n", "                ", "checkpoint", "(", ")", "\n", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "\n", "", "sps", "=", "(", "step", "-", "start_step", ")", "/", "(", "timer", "(", ")", "-", "start_time", ")", "\n", "if", "stats", ".", "get", "(", "\"episode_returns\"", ",", "None", ")", ":", "\n", "                ", "mean_return", "=", "(", "\n", "\"Return per episode: %.1f. \"", "%", "stats", "[", "\"mean_episode_return\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "mean_return", "=", "\"\"", "\n", "", "total_loss", "=", "stats", ".", "get", "(", "\"total_loss\"", ",", "float", "(", "\"inf\"", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Steps %i @ %.1f SPS. Loss %f. %sStats:\\n%s\"", ",", "\n", "step", ",", "\n", "sps", ",", "\n", "total_loss", ",", "\n", "mean_return", ",", "\n", "pprint", ".", "pformat", "(", "stats", ")", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "return", "# Try joining actors then quit.", "\n", "", "else", ":", "\n", "        ", "for", "thread", "in", "threads", ":", "\n", "            ", "thread", ".", "join", "(", ")", "\n", "", "logging", ".", "info", "(", "\"Learning finished after %d steps.\"", ",", "step", ")", "\n", "", "finally", ":", "\n", "        ", "for", "_", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "            ", "free_queue", ".", "put", "(", "None", ")", "\n", "", "for", "actor", "in", "actor_processes", ":", "\n", "            ", "actor", ".", "join", "(", "timeout", "=", "1", ")", "\n", "\n", "", "", "checkpoint", "(", ")", "\n", "plogger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.test": [[514, 549], ["monobeast_baseline.create_env", "Model.core.environment.Environment", "Net", "Net.eval", "torch.load", "Net.load_state_dict", "environment.Environment.initial", "environment.Environment.close", "logging.info", "os.path.expandvars", "len", "Net.", "environment.Environment.step", "observation[].item", "os.path.expanduser", "environment.Environment.gym_env.render", "returns.append", "logging.info", "sum", "len", "observation[].item", "observation[].item", "observation[].item"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "test", "(", "flags", ",", "num_episodes", ":", "int", "=", "10", ")", ":", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "checkpointpath", "=", "\"./latest/model.tar\"", "\n", "", "else", ":", "\n", "        ", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "model", "=", "Net", "(", "gym_env", ".", "observation_space", ".", "shape", ",", "gym_env", ".", "action_space", ".", "n", ",", "\n", "flags", ".", "use_lstm", ",", "flags", ".", "lstm_layers", ")", "\n", "model", ".", "eval", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpointpath", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "\n", "observation", "=", "env", ".", "initial", "(", ")", "\n", "returns", "=", "[", "]", "\n", "\n", "while", "len", "(", "returns", ")", "<", "num_episodes", ":", "\n", "        ", "if", "flags", ".", "mode", "==", "\"test_render\"", ":", "\n", "            ", "env", ".", "gym_env", ".", "render", "(", ")", "\n", "", "agent_outputs", "=", "model", "(", "observation", ")", "\n", "policy_outputs", ",", "_", "=", "agent_outputs", "\n", "observation", "=", "env", ".", "step", "(", "policy_outputs", "[", "\"action\"", "]", ")", "\n", "if", "observation", "[", "\"done\"", "]", ".", "item", "(", ")", ":", "\n", "            ", "returns", ".", "append", "(", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Episode ended after %d steps. Return: %.1f\"", ",", "\n", "observation", "[", "\"episode_step\"", "]", ".", "item", "(", ")", ",", "\n", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Average returns over %i steps: %.1f\"", ",", "num_episodes", ",", "sum", "(", "returns", ")", "/", "len", "(", "returns", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.create_env": [[703, 710], ["Model.atari_wrappers.wrap_pytorch", "Model.atari_wrappers.wrap_deepmind", "Model.atari_wrappers.make_atari"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_pytorch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.make_atari"], ["def", "create_env", "(", "flags", ")", ":", "\n", "    ", "return", "atari_wrappers", ".", "wrap_pytorch", "(", "\n", "atari_wrappers", ".", "wrap_deepmind", "(", "\n", "atari_wrappers", ".", "make_atari", "(", "flags", ".", "env", ")", ",", "\n", "clip_rewards", "=", "False", ",", "\n", "frame_stack", "=", "True", ",", "\n", "scale", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_baseline.main": [[714, 719], ["monobeast_baseline.train", "monobeast_baseline.test"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.test"], ["", "def", "main", "(", "flags", ")", ":", "\n", "    ", "if", "flags", ".", "mode", "==", "\"train\"", ":", "\n", "        ", "train", "(", "flags", ")", "\n", "", "else", ":", "\n", "        ", "test", "(", "flags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.NoopResetEnv.__init__": [[36, 45], ["gym.Wrapper.__init__", "env.unwrapped.get_action_meanings"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "noop_max", "=", "30", ")", ":", "\n", "        ", "\"\"\"Sample initial states by taking random number of no-ops on reset.\n        No-op is assumed to be action 0.\n        \"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "noop_max", "=", "noop_max", "\n", "self", ".", "override_num_noops", "=", "None", "\n", "self", ".", "noop_action", "=", "0", "\n", "assert", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", "[", "0", "]", "==", "'NOOP'", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.NoopResetEnv.reset": [[46, 60], ["atari_wrappers.NoopResetEnv.env.reset", "range", "atari_wrappers.NoopResetEnv.unwrapped.np_random.randint", "atari_wrappers.NoopResetEnv.env.step", "atari_wrappers.NoopResetEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"", "\n", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "if", "self", ".", "override_num_noops", "is", "not", "None", ":", "\n", "            ", "noops", "=", "self", ".", "override_num_noops", "\n", "", "else", ":", "\n", "            ", "noops", "=", "self", ".", "unwrapped", ".", "np_random", ".", "randint", "(", "1", ",", "self", ".", "noop_max", "+", "1", ")", "#pylint: disable=E1101", "\n", "", "assert", "noops", ">", "0", "\n", "obs", "=", "None", "\n", "for", "_", "in", "range", "(", "noops", ")", ":", "\n", "            ", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "self", ".", "noop_action", ")", "\n", "if", "done", ":", "\n", "                ", "obs", "=", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.NoopResetEnv.step": [[61, 63], ["atari_wrappers.NoopResetEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "step", "(", "self", ",", "ac", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "step", "(", "ac", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FireResetEnv.__init__": [[65, 70], ["gym.Wrapper.__init__", "len", "env.unwrapped.get_action_meanings", "env.unwrapped.get_action_meanings"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "\"\"\"Take action on reset for environments that are fixed until firing.\"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "assert", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", "[", "1", "]", "==", "'FIRE'", "\n", "assert", "len", "(", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", ")", ">=", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FireResetEnv.reset": [[71, 80], ["atari_wrappers.FireResetEnv.env.reset", "atari_wrappers.FireResetEnv.env.step", "atari_wrappers.FireResetEnv.env.step", "atari_wrappers.FireResetEnv.env.reset", "atari_wrappers.FireResetEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "1", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "2", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FireResetEnv.step": [[81, 83], ["atari_wrappers.FireResetEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "step", "(", "self", ",", "ac", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "step", "(", "ac", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.EpisodicLifeEnv.__init__": [[85, 92], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "\"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n        Done by DeepMind for the DQN and co. since it helps value estimation.\n        \"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "lives", "=", "0", "\n", "self", ".", "was_real_done", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.EpisodicLifeEnv.step": [[93, 106], ["atari_wrappers.EpisodicLifeEnv.env.step", "atari_wrappers.EpisodicLifeEnv.env.unwrapped.ale.lives"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "was_real_done", "=", "done", "\n", "# check current lives, make loss of life terminal,", "\n", "# then update lives to handle bonus lives", "\n", "lives", "=", "self", ".", "env", ".", "unwrapped", ".", "ale", ".", "lives", "(", ")", "\n", "if", "lives", "<", "self", ".", "lives", "and", "lives", ">", "0", ":", "\n", "# for Qbert sometimes we stay in lives == 0 condition for a few frames", "\n", "# so it's important to keep lives > 0, so that we only reset once", "\n", "# the environment advertises done.", "\n", "            ", "done", "=", "True", "\n", "", "self", ".", "lives", "=", "lives", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.EpisodicLifeEnv.reset": [[107, 119], ["atari_wrappers.EpisodicLifeEnv.env.unwrapped.ale.lives", "atari_wrappers.EpisodicLifeEnv.env.reset", "atari_wrappers.EpisodicLifeEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Reset only when lives are exhausted.\n        This way all states are still reachable even though lives are episodic,\n        and the learner need not know about any of this behind-the-scenes.\n        \"\"\"", "\n", "if", "self", ".", "was_real_done", ":", "\n", "            ", "obs", "=", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# no-op step to advance from terminal/lost life state", "\n", "            ", "obs", ",", "_", ",", "_", ",", "_", "=", "self", ".", "env", ".", "step", "(", "0", ")", "\n", "", "self", ".", "lives", "=", "self", ".", "env", ".", "unwrapped", ".", "ale", ".", "lives", "(", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.MaxAndSkipEnv.__init__": [[121, 127], ["gym.Wrapper.__init__", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "skip", "=", "4", ")", ":", "\n", "        ", "\"\"\"Return only every `skip`-th frame\"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "# most recent raw observations (for max pooling across time steps)", "\n", "self", ".", "_obs_buffer", "=", "np", ".", "zeros", "(", "(", "2", ",", ")", "+", "env", ".", "observation_space", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "self", ".", "_skip", "=", "skip", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.MaxAndSkipEnv.step": [[128, 144], ["range", "atari_wrappers.MaxAndSkipEnv._obs_buffer.max", "atari_wrappers.MaxAndSkipEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"Repeat action, sum reward, and max over last observations.\"\"\"", "\n", "total_reward", "=", "0.0", "\n", "done", "=", "None", "\n", "for", "i", "in", "range", "(", "self", ".", "_skip", ")", ":", "\n", "            ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "i", "==", "self", ".", "_skip", "-", "2", ":", "self", ".", "_obs_buffer", "[", "0", "]", "=", "obs", "\n", "if", "i", "==", "self", ".", "_skip", "-", "1", ":", "self", ".", "_obs_buffer", "[", "1", "]", "=", "obs", "\n", "total_reward", "+=", "reward", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "# Note that the observation on the done=True frame", "\n", "# doesn't matter", "\n", "", "", "max_frame", "=", "self", ".", "_obs_buffer", ".", "max", "(", "axis", "=", "0", ")", "\n", "\n", "return", "max_frame", ",", "total_reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.MaxAndSkipEnv.reset": [[145, 147], ["atari_wrappers.MaxAndSkipEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.ClipRewardEnv.__init__": [[149, 151], ["gym.RewardWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "gym", ".", "RewardWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.ClipRewardEnv.reward": [[152, 155], ["numpy.sign"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "\"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"", "\n", "return", "np", ".", "sign", "(", "reward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.WarpFrame.__init__": [[158, 188], ["gym.ObservationWrapper.__init__", "gym.spaces.Box", "len"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "width", "=", "84", ",", "height", "=", "84", ",", "grayscale", "=", "True", ",", "dict_space_key", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Warp frames to 84x84 as done in the Nature paper and later work.\n\n        If the environment uses dictionary observations, `dict_space_key` can be specified which indicates which\n        observation should be warped.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "_width", "=", "width", "\n", "self", ".", "_height", "=", "height", "\n", "self", ".", "_grayscale", "=", "grayscale", "\n", "self", ".", "_key", "=", "dict_space_key", "\n", "if", "self", ".", "_grayscale", ":", "\n", "            ", "num_colors", "=", "1", "\n", "", "else", ":", "\n", "            ", "num_colors", "=", "3", "\n", "\n", "", "new_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "255", ",", "\n", "shape", "=", "(", "self", ".", "_height", ",", "self", ".", "_width", ",", "num_colors", ")", ",", "\n", "dtype", "=", "np", ".", "uint8", ",", "\n", ")", "\n", "if", "self", ".", "_key", "is", "None", ":", "\n", "            ", "original_space", "=", "self", ".", "observation_space", "\n", "self", ".", "observation_space", "=", "new_space", "\n", "", "else", ":", "\n", "            ", "original_space", "=", "self", ".", "observation_space", ".", "spaces", "[", "self", ".", "_key", "]", "\n", "self", ".", "observation_space", ".", "spaces", "[", "self", ".", "_key", "]", "=", "new_space", "\n", "", "assert", "original_space", ".", "dtype", "==", "np", ".", "uint8", "and", "len", "(", "original_space", ".", "shape", ")", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.WarpFrame.observation": [[189, 209], ["cv2.resize", "cv2.cvtColor", "numpy.expand_dims", "obs.copy.copy.copy"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "if", "self", ".", "_key", "is", "None", ":", "\n", "            ", "frame", "=", "obs", "\n", "", "else", ":", "\n", "            ", "frame", "=", "obs", "[", "self", ".", "_key", "]", "\n", "\n", "", "if", "self", ".", "_grayscale", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "", "frame", "=", "cv2", ".", "resize", "(", "\n", "frame", ",", "(", "self", ".", "_width", ",", "self", ".", "_height", ")", ",", "interpolation", "=", "cv2", ".", "INTER_AREA", "\n", ")", "\n", "if", "self", ".", "_grayscale", ":", "\n", "            ", "frame", "=", "np", ".", "expand_dims", "(", "frame", ",", "-", "1", ")", "\n", "\n", "", "if", "self", ".", "_key", "is", "None", ":", "\n", "            ", "obs", "=", "frame", "\n", "", "else", ":", "\n", "            ", "obs", "=", "obs", ".", "copy", "(", ")", "\n", "obs", "[", "self", ".", "_key", "]", "=", "frame", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.__init__": [[212, 226], ["gym.Wrapper.__init__", "collections.deque", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "k", ")", ":", "\n", "        ", "\"\"\"Stack k last frames.\n\n        Returns lazy array, which is much more memory efficient.\n\n        See Also\n        --------\n        baselines.common.atari_wrappers.LazyFrames\n        \"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "frames", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "k", ")", "\n", "shp", "=", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "(", "shp", "[", ":", "-", "1", "]", "+", "(", "shp", "[", "-", "1", "]", "*", "k", ",", ")", ")", ",", "dtype", "=", "env", ".", "observation_space", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset": [[227, 232], ["atari_wrappers.FrameStack.env.reset", "range", "atari_wrappers.FrameStack._get_ob", "atari_wrappers.FrameStack.frames.append"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack._get_ob"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "ob", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "            ", "self", ".", "frames", ".", "append", "(", "ob", ")", "\n", "", "return", "self", ".", "_get_ob", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.step": [[233, 237], ["atari_wrappers.FrameStack.env.step", "atari_wrappers.FrameStack.frames.append", "atari_wrappers.FrameStack._get_ob"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack._get_ob"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "ob", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "frames", ".", "append", "(", "ob", ")", "\n", "return", "self", ".", "_get_ob", "(", ")", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack._get_ob": [[238, 241], ["atari_wrappers.LazyFrames", "len", "list"], "methods", ["None"], ["", "def", "_get_ob", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "frames", ")", "==", "self", ".", "k", "\n", "return", "LazyFrames", "(", "list", "(", "self", ".", "frames", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.ScaledFloatFrame.__init__": [[243, 246], ["gym.ObservationWrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "gym", ".", "ObservationWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "1", ",", "shape", "=", "env", ".", "observation_space", ".", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.ScaledFloatFrame.observation": [[247, 251], ["numpy.array().astype", "numpy.array"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "# careful! This undoes the memory optimization, use", "\n", "# with smaller replay buffers only.", "\n", "        ", "return", "np", ".", "array", "(", "observation", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.0", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames.__init__": [[253, 263], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "frames", ")", ":", "\n", "        ", "\"\"\"This object ensures that common frames between the observations are only stored once.\n        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n        buffers.\n\n        This object should only be converted to numpy array before being passed to the model.\n\n        You'd not believe how complex the previous solution was.\"\"\"", "\n", "self", ".", "_frames", "=", "frames", "\n", "self", ".", "_out", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames._force": [[264, 269], ["numpy.concatenate"], "methods", ["None"], ["", "def", "_force", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_out", "is", "None", ":", "\n", "            ", "self", ".", "_out", "=", "np", ".", "concatenate", "(", "self", ".", "_frames", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "_frames", "=", "None", "\n", "", "return", "self", ".", "_out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames.__array__": [[270, 275], ["atari_wrappers.LazyFrames._force", "out.astype.astype.astype"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames._force"], ["", "def", "__array__", "(", "self", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "out", "=", "self", ".", "_force", "(", ")", "\n", "if", "dtype", "is", "not", "None", ":", "\n", "            ", "out", "=", "out", ".", "astype", "(", "dtype", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames.__len__": [[276, 278], ["len", "atari_wrappers.LazyFrames._force"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames._force"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_force", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames.__getitem__": [[279, 281], ["atari_wrappers.LazyFrames._force"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames._force"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "_force", "(", ")", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames.count": [[282, 285], ["atari_wrappers.LazyFrames._force"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames._force"], ["", "def", "count", "(", "self", ")", ":", "\n", "        ", "frames", "=", "self", ".", "_force", "(", ")", "\n", "return", "frames", ".", "shape", "[", "frames", ".", "ndim", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames.frame": [[286, 288], ["atari_wrappers.LazyFrames._force"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.LazyFrames._force"], ["", "def", "frame", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "_force", "(", ")", "[", "...", ",", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.ImageToPyTorch.__init__": [[321, 329], ["gym.ObservationWrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "super", "(", "ImageToPyTorch", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "old_shape", "=", "self", ".", "observation_space", ".", "shape", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0.0", ",", "\n", "high", "=", "1.0", ",", "\n", "shape", "=", "(", "old_shape", "[", "-", "1", "]", ",", "old_shape", "[", "0", "]", ",", "old_shape", "[", "1", "]", ")", ",", "\n", "dtype", "=", "np", ".", "uint8", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.ImageToPyTorch.observation": [[331, 333], ["numpy.transpose"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "        ", "return", "np", ".", "transpose", "(", "observation", ",", "axes", "=", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.make_atari": [[289, 298], ["gym.make", "atari_wrappers.NoopResetEnv", "atari_wrappers.MaxAndSkipEnv"], "function", ["None"], ["", "", "def", "make_atari", "(", "env_id", ",", "max_episode_steps", "=", "None", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "env_id", ")", "\n", "assert", "'NoFrameskip'", "in", "env", ".", "spec", ".", "id", "\n", "env", "=", "NoopResetEnv", "(", "env", ",", "noop_max", "=", "30", ")", "\n", "env", "=", "MaxAndSkipEnv", "(", "env", ",", "skip", "=", "4", ")", "\n", "\n", "assert", "max_episode_steps", "is", "None", "\n", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_deepmind": [[299, 314], ["atari_wrappers.WarpFrame", "atari_wrappers.EpisodicLifeEnv", "FrameStack.unwrapped.get_action_meanings", "atari_wrappers.FireResetEnv", "atari_wrappers.ScaledFloatFrame", "atari_wrappers.ClipRewardEnv", "atari_wrappers.FrameStack"], "function", ["None"], ["", "def", "wrap_deepmind", "(", "env", ",", "episode_life", "=", "True", ",", "clip_rewards", "=", "True", ",", "frame_stack", "=", "False", ",", "scale", "=", "False", ")", ":", "\n", "    ", "\"\"\"Configure environment for DeepMind-style Atari.\n    \"\"\"", "\n", "if", "episode_life", ":", "\n", "        ", "env", "=", "EpisodicLifeEnv", "(", "env", ")", "\n", "", "if", "'FIRE'", "in", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", ":", "\n", "        ", "env", "=", "FireResetEnv", "(", "env", ")", "\n", "", "env", "=", "WarpFrame", "(", "env", ")", "\n", "if", "scale", ":", "\n", "        ", "env", "=", "ScaledFloatFrame", "(", "env", ")", "\n", "", "if", "clip_rewards", ":", "\n", "        ", "env", "=", "ClipRewardEnv", "(", "env", ")", "\n", "", "if", "frame_stack", ":", "\n", "        ", "env", "=", "FrameStack", "(", "env", ",", "4", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_pytorch": [[335, 337], ["atari_wrappers.ImageToPyTorch"], "function", ["None"], ["", "", "def", "wrap_pytorch", "(", "env", ")", ":", "\n", "    ", "return", "ImageToPyTorch", "(", "env", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.AtariNet.__init__": [[552, 585], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LSTM", "monobeast_fb.AtariNet.lstm_init"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.AtariNet.lstm_init"], ["    ", "def", "__init__", "(", "self", ",", "observation_shape", ",", "num_actions", ",", "use_lstm", "=", "False", ",", "\n", "init_method", "=", "None", ",", "lstm_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "AtariNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "observation_shape", "=", "observation_shape", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "\n", "# Feature extraction.", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "self", ".", "observation_shape", "[", "0", "]", ",", "\n", "out_channels", "=", "32", ",", "\n", "kernel_size", "=", "8", ",", "\n", "stride", "=", "4", ",", "\n", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "# Fully connected layer.", "\n", "if", "use_lstm", ":", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3136", ",", "256", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3136", ",", "512", ")", "\n", "\n", "# FC output size + one-hot of last action + last reward.", "\n", "", "core_output_size", "=", "self", ".", "fc", ".", "out_features", "+", "num_actions", "+", "1", "\n", "\n", "self", ".", "use_lstm", "=", "use_lstm", "\n", "if", "use_lstm", ":", "\n", "            ", "self", ".", "core", "=", "nn", ".", "LSTM", "(", "core_output_size", ",", "core_output_size", ",", "lstm_layers", ")", "\n", "if", "not", "init_method", ":", "\n", "                ", "self", ".", "lstm_init", "(", "init_method", ")", "\n", "\n", "", "", "self", ".", "policy", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "baseline", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.AtariNet.lstm_init": [[586, 593], ["monobeast_fb.AtariNet.core.parameters", "param.dim", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_normal_"], "methods", ["None"], ["", "def", "lstm_init", "(", "self", ",", "method", ")", ":", "\n", "        ", "for", "param", "in", "self", ".", "core", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "if", "method", "==", "'xavier_uniform'", ":", "\n", "                    ", "nn", ".", "init", ".", "xavier_uniform_", "(", "param", ")", "\n", "", "elif", "method", "==", "'xavier_normal'", ":", "\n", "                    ", "nn", ".", "init", ".", "xavier_normal_", "(", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.AtariNet.initial_state": [[594, 600], ["tuple", "tuple", "torch.zeros", "range"], "methods", ["None"], ["", "", "", "", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "not", "self", ".", "use_lstm", ":", "\n", "            ", "return", "tuple", "(", ")", "\n", "", "return", "tuple", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "core", ".", "num_layers", ",", "batch_size", ",", "self", ".", "core", ".", "hidden_size", ")", "\n", "for", "_", "in", "range", "(", "2", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.AtariNet.forward": [[602, 652], ["torch.flatten", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu.view", "torch.nn.functional.relu", "torch.nn.functional.one_hot().float", "torch.clamp().view", "torch.cat", "monobeast_fb.AtariNet.policy", "monobeast_fb.AtariNet.baseline", "policy_logits.view.view.view", "baseline.view.view.view", "torch.argmax.view", "torch.nn.functional.relu.float", "monobeast_fb.AtariNet.conv1", "monobeast_fb.AtariNet.conv2", "monobeast_fb.AtariNet.conv3", "monobeast_fb.AtariNet.fc", "core_input.view.view.view", "zip", "torch.flatten", "tuple", "torch.multinomial", "torch.argmax", "dict", "torch.nn.functional.one_hot", "torch.clamp", "core_input.view.view.unbind", "notdone.unbind", "nd.view.view.view", "tuple", "monobeast_fb.AtariNet.core", "core_output_list.append", "torch.cat", "torch.nn.functional.softmax", "inputs[].view", "input.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "core_state", "=", "(", ")", ")", ":", "\n", "        ", "x", "=", "inputs", "[", "\"frame\"", "]", "# [T, B, C, H, W].", "\n", "T", ",", "B", ",", "*", "_", "=", "x", ".", "shape", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "0", ",", "1", ")", "# Merge time and batch.", "\n", "x", "=", "x", ".", "float", "(", ")", "/", "255.0", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv3", "(", "x", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n", "one_hot_last_action", "=", "F", ".", "one_hot", "(", "\n", "inputs", "[", "\"last_action\"", "]", ".", "view", "(", "T", "*", "B", ")", ",", "self", ".", "num_actions", "\n", ")", ".", "float", "(", ")", "\n", "clipped_reward", "=", "torch", ".", "clamp", "(", "inputs", "[", "\"reward\"", "]", ",", "-", "1", ",", "1", ")", ".", "view", "(", "T", "*", "B", ",", "1", ")", "\n", "core_input", "=", "torch", ".", "cat", "(", "[", "x", ",", "clipped_reward", ",", "one_hot_last_action", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "use_lstm", ":", "\n", "            ", "core_input", "=", "core_input", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "\n", "core_output_list", "=", "[", "]", "\n", "notdone", "=", "(", "~", "inputs", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "\n", "for", "input", ",", "nd", "in", "zip", "(", "core_input", ".", "unbind", "(", ")", ",", "notdone", ".", "unbind", "(", ")", ")", ":", "\n", "# Reset core state to zero whenever an episode ended.", "\n", "# Make `done` broadcastable with (num_layers, B, hidden_size)", "\n", "# states:", "\n", "                ", "nd", "=", "nd", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "core_state", "=", "tuple", "(", "nd", "*", "s", "for", "s", "in", "core_state", ")", "\n", "output", ",", "core_state", "=", "self", ".", "core", "(", "input", ".", "unsqueeze", "(", "0", ")", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "output", ")", "\n", "", "core_output", "=", "torch", ".", "flatten", "(", "torch", ".", "cat", "(", "core_output_list", ")", ",", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "core_output", "=", "core_input", "\n", "core_state", "=", "tuple", "(", ")", "\n", "\n", "", "policy_logits", "=", "self", ".", "policy", "(", "core_output", ")", "\n", "baseline", "=", "self", ".", "baseline", "(", "core_output", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "action", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "policy_logits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "# Don't sample when testing.", "\n", "            ", "action", "=", "torch", ".", "argmax", "(", "policy_logits", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_logits", "=", "policy_logits", ".", "view", "(", "T", ",", "B", ",", "self", ".", "num_actions", ")", "\n", "baseline", "=", "baseline", ".", "view", "(", "T", ",", "B", ")", "\n", "action", "=", "action", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "return", "(", "\n", "dict", "(", "policy_logits", "=", "policy_logits", ",", "baseline", "=", "baseline", ",", "action", "=", "action", ")", ",", "\n", "core_state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.compute_baseline_loss": [[110, 112], ["torch.sum"], "function", ["None"], ["def", "compute_baseline_loss", "(", "advantages", ")", ":", "\n", "    ", "return", "0.5", "*", "torch", ".", "sum", "(", "advantages", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.compute_entropy_loss": [[114, 119], ["torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.sum"], "function", ["None"], ["", "def", "compute_entropy_loss", "(", "logits", ")", ":", "\n", "    ", "\"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"", "\n", "policy", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "log_policy", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "sum", "(", "policy", "*", "log_policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.compute_policy_gradient_loss": [[121, 129], ["torch.nn.functional.nll_loss", "cross_entropy.view_as.view_as", "torch.sum", "torch.nn.functional.log_softmax", "torch.flatten", "torch.flatten", "advantages.detach"], "function", ["None"], ["", "def", "compute_policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ")", ":", "\n", "    ", "cross_entropy", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "logits", ",", "0", ",", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "torch", ".", "flatten", "(", "actions", ",", "0", ",", "1", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", "\n", "cross_entropy", "=", "cross_entropy", ".", "view_as", "(", "advantages", ")", "\n", "return", "torch", ".", "sum", "(", "cross_entropy", "*", "advantages", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.act": [[131, 195], ["logging.info", "Model.core.prof.Timings", "monobeast_fb.create_env", "create_env.seed", "Model.core.environment.Environment", "environment.Environment.initial", "model.initial_state", "model", "int.from_bytes", "free_queue.get", "enumerate", "range", "full_queue.put", "logging.info", "logging.error", "traceback.print_exc", "print", "os.urandom", "prof.Timings.reset", "prof.Timings.time", "environment.Environment.step", "prof.Timings.time", "prof.Timings.time", "prof.Timings.summary", "torch.no_grad", "model"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary"], ["", "def", "act", "(", "\n", "flags", ",", "\n", "actor_index", ":", "int", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"Actor %i started.\"", ",", "actor_index", ")", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "# Keep track of how fast things are.", "\n", "\n", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "seed", "=", "actor_index", "^", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "4", ")", ",", "byteorder", "=", "\"little\"", ")", "\n", "gym_env", ".", "seed", "(", "seed", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "env_output", "=", "env", ".", "initial", "(", ")", "\n", "agent_state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "agent_output", ",", "unused_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "while", "True", ":", "\n", "            ", "index", "=", "free_queue", ".", "get", "(", ")", "\n", "if", "index", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "# Write old rollout end.", "\n", "", "for", "key", "in", "env_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "agent_state", ")", ":", "\n", "                ", "initial_agent_state_buffers", "[", "index", "]", "[", "i", "]", "[", "...", "]", "=", "tensor", "\n", "\n", "# Do new rollout.", "\n", "", "for", "t", "in", "range", "(", "flags", ".", "unroll_length", ")", ":", "\n", "                ", "timings", ".", "reset", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "agent_output", ",", "agent_state", "=", "model", "(", "env_output", ",", "agent_state", ")", "\n", "\n", "", "timings", ".", "time", "(", "\"model\"", ")", "\n", "\n", "env_output", "=", "env", ".", "step", "(", "agent_output", "[", "\"action\"", "]", ")", "\n", "\n", "timings", ".", "time", "(", "\"step\"", ")", "\n", "\n", "for", "key", "in", "env_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "\n", "", "timings", ".", "time", "(", "\"write\"", ")", "\n", "", "full_queue", ".", "put", "(", "index", ")", "\n", "\n", "", "if", "actor_index", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Actor %i: %s\"", ",", "actor_index", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# Return silently.", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logging", ".", "error", "(", "\"Exception in worker process %i\"", ",", "actor_index", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "print", "(", ")", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.get_batch": [[197, 227], ["threading.Lock", "timings.time", "timings.time", "tuple", "timings.time", "timings.time", "timings.time", "torch.stack", "torch.cat", "free_queue.put", "t.to", "full_queue.get", "zip", "batch.items", "t.to", "range"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["", "", "def", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "\n", ")", ":", "\n", "    ", "with", "lock", ":", "\n", "        ", "timings", ".", "time", "(", "\"lock\"", ")", "\n", "indices", "=", "[", "full_queue", ".", "get", "(", ")", "for", "_", "in", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "timings", ".", "time", "(", "\"dequeue\"", ")", "\n", "", "batch", "=", "{", "\n", "key", ":", "torch", ".", "stack", "(", "[", "buffers", "[", "key", "]", "[", "m", "]", "for", "m", "in", "indices", "]", ",", "dim", "=", "1", ")", "for", "key", "in", "buffers", "\n", "}", "\n", "initial_agent_state", "=", "(", "\n", "torch", ".", "cat", "(", "ts", ",", "dim", "=", "1", ")", "\n", "for", "ts", "in", "zip", "(", "*", "[", "initial_agent_state_buffers", "[", "m", "]", "for", "m", "in", "indices", "]", ")", "\n", ")", "\n", "timings", ".", "time", "(", "\"batch\"", ")", "\n", "for", "m", "in", "indices", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "", "timings", ".", "time", "(", "\"enqueue\"", ")", "\n", "batch", "=", "{", "k", ":", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "k", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "initial_agent_state", "=", "tuple", "(", "\n", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "t", "in", "initial_agent_state", "\n", ")", "\n", "timings", ".", "time", "(", "\"device\"", ")", "\n", "return", "batch", ",", "initial_agent_state", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.learn": [[229, 300], ["threading.Lock", "model", "Model.core.vtrace.from_logits", "monobeast_fb.compute_policy_gradient_loss", "optimizer.zero_grad", "total_loss.backward", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "actor_model.load_state_dict", "torch.clamp", "monobeast_fb.compute_baseline_loss", "monobeast_fb.compute_entropy_loss", "tuple", "torch.mean().item", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "model.parameters", "model.state_dict", "batch.items", "learner_outputs.items", "episode_returns.cpu().numpy", "torch.mean", "episode_returns.cpu"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict"], ["", "def", "learn", "(", "\n", "flags", ",", "\n", "actor_model", ",", "\n", "model", ",", "\n", "batch", ",", "\n", "initial_agent_state", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "# noqa: B008", "\n", ")", ":", "\n", "    ", "\"\"\"Performs a learning (optimization) step.\"\"\"", "\n", "with", "lock", ":", "\n", "        ", "learner_outputs", ",", "unused_state", "=", "model", "(", "batch", ",", "initial_agent_state", ")", "\n", "\n", "# Take final value function slice for bootstrapping.", "\n", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "-", "1", "]", "\n", "\n", "# Move from obs[t] -> action[t] to action[t] -> obs[t].", "\n", "batch", "=", "{", "key", ":", "tensor", "[", "1", ":", "]", "for", "key", ",", "tensor", "in", "batch", ".", "items", "(", ")", "}", "\n", "learner_outputs", "=", "{", "key", ":", "tensor", "[", ":", "-", "1", "]", "for", "key", ",", "tensor", "in", "learner_outputs", ".", "items", "(", ")", "}", "\n", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "\n", "if", "flags", ".", "reward_clipping", "==", "\"abs_one\"", ":", "\n", "            ", "clipped_rewards", "=", "torch", ".", "clamp", "(", "rewards", ",", "-", "1", ",", "1", ")", "\n", "", "elif", "flags", ".", "reward_clipping", "==", "\"none\"", ":", "\n", "            ", "clipped_rewards", "=", "rewards", "\n", "\n", "", "discounts", "=", "(", "~", "batch", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "*", "flags", ".", "discounting", "\n", "\n", "vtrace_returns", "=", "vtrace", ".", "from_logits", "(", "\n", "behavior_policy_logits", "=", "batch", "[", "\"policy_logits\"", "]", ",", "\n", "target_policy_logits", "=", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "actions", "=", "batch", "[", "\"action\"", "]", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "clipped_rewards", ",", "\n", "values", "=", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", ")", "\n", "\n", "pg_loss", "=", "compute_policy_gradient_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "batch", "[", "\"action\"", "]", ",", "\n", "vtrace_returns", ".", "pg_advantages", ",", "\n", ")", "\n", "baseline_loss", "=", "flags", ".", "baseline_cost", "*", "compute_baseline_loss", "(", "\n", "vtrace_returns", ".", "vs", "-", "learner_outputs", "[", "\"baseline\"", "]", "\n", ")", "\n", "entropy_loss", "=", "flags", ".", "entropy_cost", "*", "compute_entropy_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", "\n", ")", "\n", "\n", "total_loss", "=", "pg_loss", "+", "baseline_loss", "+", "entropy_loss", "\n", "\n", "episode_returns", "=", "batch", "[", "\"episode_return\"", "]", "[", "batch", "[", "\"done\"", "]", "]", "\n", "stats", "=", "{", "\n", "\"episode_returns\"", ":", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "\"mean_episode_return\"", ":", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ",", "\n", "\"total_loss\"", ":", "total_loss", ".", "item", "(", ")", ",", "\n", "\"pg_loss\"", ":", "pg_loss", ".", "item", "(", ")", ",", "\n", "\"baseline_loss\"", ":", "baseline_loss", ".", "item", "(", ")", ",", "\n", "\"entropy_loss\"", ":", "entropy_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "flags", ".", "grad_norm_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "actor_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.create_buffers": [[302, 320], ["dict", "range", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "buffers[].append", "torch.empty().share_memory_", "torch.empty"], "function", ["None"], ["", "", "def", "create_buffers", "(", "flags", ",", "obs_shape", ",", "num_actions", ")", "->", "Buffers", ":", "\n", "    ", "T", "=", "flags", ".", "unroll_length", "\n", "specs", "=", "dict", "(", "\n", "frame", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "*", "obs_shape", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "reward", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "done", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "\n", "episode_return", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "episode_step", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "policy_logits", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "num_actions", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "baseline", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "last_action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", ")", "\n", "buffers", ":", "Buffers", "=", "{", "key", ":", "[", "]", "for", "key", "in", "specs", "}", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "for", "key", "in", "buffers", ":", "\n", "            ", "buffers", "[", "key", "]", ".", "append", "(", "torch", ".", "empty", "(", "**", "specs", "[", "key", "]", ")", ".", "share_memory_", "(", ")", ")", "\n", "", "", "return", "buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.train": [[322, 511], ["Model.core.file_writer.FileWriter", "os.path.expandvars", "monobeast_fb.create_env", "Net", "monobeast_fb.create_buffers", "Net.share_memory", "range", "torch.multiprocessing.get_context", "mp.get_context.SimpleQueue", "mp.get_context.SimpleQueue", "range", "Net().to", "torch.optim.RMSprop", "torch.optim.lr_scheduler.LambdaLR", "logging.getLogger", "logging.getLogger.info", "range", "range", "monobeast_fb.train.checkpoint"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_buffers", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.checkpoint"], ["", "def", "train", "(", "flags", ")", ":", "# pylint: disable=too-many-branches, too-many-statements", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "flags", ".", "xpid", "=", "\"torchbeast-%s\"", "%", "time", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "", "plogger", "=", "file_writer", ".", "FileWriter", "(", "\n", "xpid", "=", "flags", ".", "xpid", ",", "xp_args", "=", "flags", ".", "__dict__", ",", "rootdir", "=", "flags", ".", "savedir", "\n", ")", "\n", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "if", "flags", ".", "num_buffers", "is", "None", ":", "# Set sensible default for num_buffers.", "\n", "        ", "flags", ".", "num_buffers", "=", "max", "(", "2", "*", "flags", ".", "num_actors", ",", "flags", ".", "batch_size", ")", "\n", "", "if", "flags", ".", "num_actors", ">=", "flags", ".", "num_buffers", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than num_actors\"", ")", "\n", "", "if", "flags", ".", "num_buffers", "<", "flags", ".", "batch_size", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than batch_size\"", ")", "\n", "\n", "", "T", "=", "flags", ".", "unroll_length", "\n", "B", "=", "flags", ".", "batch_size", "\n", "\n", "flags", ".", "device", "=", "None", "\n", "if", "not", "flags", ".", "disable_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Not using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "env", "=", "create_env", "(", "flags", ")", "\n", "\n", "model", "=", "Net", "(", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ",", "flags", ".", "use_lstm", ",", "\n", "flags", ".", "init_method", ",", "flags", ".", "lstm_layers", ")", "\n", "buffers", "=", "create_buffers", "(", "flags", ",", "env", ".", "observation_space", ".", "shape", ",", "model", ".", "num_actions", ")", "\n", "\n", "model", ".", "share_memory", "(", ")", "\n", "\n", "# Add initial RNN state.", "\n", "initial_agent_state_buffers", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "for", "t", "in", "state", ":", "\n", "            ", "t", ".", "share_memory_", "(", ")", "\n", "", "initial_agent_state_buffers", ".", "append", "(", "state", ")", "\n", "\n", "", "actor_processes", "=", "[", "]", "\n", "ctx", "=", "mp", ".", "get_context", "(", "\"fork\"", ")", "\n", "free_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "full_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "        ", "actor", "=", "ctx", ".", "Process", "(", "\n", "target", "=", "act", ",", "\n", "args", "=", "(", "\n", "flags", ",", "\n", "i", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "model", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ",", "\n", ")", "\n", "actor", ".", "start", "(", ")", "\n", "actor_processes", ".", "append", "(", "actor", ")", "\n", "\n", "", "learner_model", "=", "Net", "(", "\n", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ",", "flags", ".", "use_lstm", ",", "\n", "flags", ".", "init_method", ",", "flags", ".", "lstm_layers", "\n", ")", ".", "to", "(", "device", "=", "flags", ".", "device", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "\n", "learner_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "flags", ".", "learning_rate", ",", "\n", "momentum", "=", "flags", ".", "momentum", ",", "\n", "eps", "=", "flags", ".", "epsilon", ",", "\n", "alpha", "=", "flags", ".", "alpha", ",", "\n", "weight_decay", "=", "flags", ".", "weight_decay", "\n", ")", "\n", "\n", "def", "lr_lambda", "(", "epoch", ")", ":", "\n", "        ", "return", "1", "-", "min", "(", "epoch", "*", "T", "*", "B", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "\n", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"logfile\"", ")", "\n", "stat_keys", "=", "[", "\n", "\"total_loss\"", ",", "\n", "\"mean_episode_return\"", ",", "\n", "\"pg_loss\"", ",", "\n", "\"baseline_loss\"", ",", "\n", "\"entropy_loss\"", ",", "\n", "]", "\n", "logger", ".", "info", "(", "\"# Step\\t%s\"", ",", "\"\\t\"", ".", "join", "(", "stat_keys", ")", ")", "\n", "\n", "step", ",", "stats", "=", "0", ",", "{", "}", "\n", "\n", "def", "batch_and_learn", "(", "i", ",", "lock", "=", "threading", ".", "Lock", "(", ")", ")", ":", "\n", "        ", "\"\"\"Thread target for the learning process.\"\"\"", "\n", "nonlocal", "step", ",", "stats", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "timings", ".", "reset", "(", ")", "\n", "batch", ",", "agent_state", "=", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", ")", "\n", "stats", "=", "learn", "(", "\n", "flags", ",", "model", ",", "learner_model", ",", "batch", ",", "agent_state", ",", "optimizer", ",", "scheduler", "\n", ")", "\n", "timings", ".", "time", "(", "\"learn\"", ")", "\n", "with", "lock", ":", "\n", "                ", "to_log", "=", "dict", "(", "step", "=", "step", ")", "\n", "to_log", ".", "update", "(", "{", "k", ":", "stats", "[", "k", "]", "for", "k", "in", "stat_keys", "}", ")", "\n", "plogger", ".", "log", "(", "to_log", ")", "\n", "step", "+=", "T", "*", "B", "\n", "\n", "", "", "if", "i", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Batch and learn: %s\"", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "for", "m", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_learner_threads", ")", ":", "\n", "        ", "thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "batch_and_learn", ",", "name", "=", "\"batch-and-learn-%d\"", "%", "i", ",", "args", "=", "(", "i", ",", ")", "\n", ")", "\n", "thread", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "thread", ")", "\n", "\n", "", "def", "checkpoint", "(", ")", ":", "\n", "        ", "if", "flags", ".", "disable_checkpoint", ":", "\n", "            ", "return", "\n", "", "logging", ".", "info", "(", "\"Saving checkpoint to %s\"", ",", "checkpointpath", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"flags\"", ":", "vars", "(", "flags", ")", ",", "\n", "}", ",", "\n", "checkpointpath", ",", "\n", ")", "\n", "\n", "", "timer", "=", "timeit", ".", "default_timer", "\n", "try", ":", "\n", "        ", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "start_step", "=", "step", "\n", "start_time", "=", "timer", "(", ")", "\n", "time", ".", "sleep", "(", "5", ")", "\n", "\n", "if", "timer", "(", ")", "-", "last_checkpoint_time", ">", "10", "*", "60", ":", "# Save every 10 min.", "\n", "                ", "checkpoint", "(", ")", "\n", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "\n", "", "sps", "=", "(", "step", "-", "start_step", ")", "/", "(", "timer", "(", ")", "-", "start_time", ")", "\n", "if", "stats", ".", "get", "(", "\"episode_returns\"", ",", "None", ")", ":", "\n", "                ", "mean_return", "=", "(", "\n", "\"Return per episode: %.1f. \"", "%", "stats", "[", "\"mean_episode_return\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "mean_return", "=", "\"\"", "\n", "", "total_loss", "=", "stats", ".", "get", "(", "\"total_loss\"", ",", "float", "(", "\"inf\"", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Steps %i @ %.1f SPS. Loss %f. %sStats:\\n%s\"", ",", "\n", "step", ",", "\n", "sps", ",", "\n", "total_loss", ",", "\n", "mean_return", ",", "\n", "pprint", ".", "pformat", "(", "stats", ")", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "return", "# Try joining actors then quit.", "\n", "", "else", ":", "\n", "        ", "for", "thread", "in", "threads", ":", "\n", "            ", "thread", ".", "join", "(", ")", "\n", "", "logging", ".", "info", "(", "\"Learning finished after %d steps.\"", ",", "step", ")", "\n", "", "finally", ":", "\n", "        ", "for", "_", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "            ", "free_queue", ".", "put", "(", "None", ")", "\n", "", "for", "actor", "in", "actor_processes", ":", "\n", "            ", "actor", ".", "join", "(", "timeout", "=", "1", ")", "\n", "\n", "", "", "checkpoint", "(", ")", "\n", "plogger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.test": [[513, 548], ["monobeast_fb.create_env", "Model.core.environment.Environment", "Net", "Net.eval", "torch.load", "Net.load_state_dict", "environment.Environment.initial", "environment.Environment.close", "logging.info", "os.path.expandvars", "len", "Net.", "environment.Environment.step", "observation[].item", "os.path.expanduser", "environment.Environment.gym_env.render", "returns.append", "logging.info", "sum", "len", "observation[].item", "observation[].item", "observation[].item"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "test", "(", "flags", ",", "num_episodes", ":", "int", "=", "10", ")", ":", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "checkpointpath", "=", "\"./latest/model.tar\"", "\n", "", "else", ":", "\n", "        ", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "model", "=", "Net", "(", "gym_env", ".", "observation_space", ".", "shape", ",", "gym_env", ".", "action_space", ".", "n", ",", "\n", "flags", ".", "use_lstm", ",", "None", ",", "flags", ".", "lstm_layers", ")", "\n", "model", ".", "eval", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpointpath", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "\n", "observation", "=", "env", ".", "initial", "(", ")", "\n", "returns", "=", "[", "]", "\n", "\n", "while", "len", "(", "returns", ")", "<", "num_episodes", ":", "\n", "        ", "if", "flags", ".", "mode", "==", "\"test_render\"", ":", "\n", "            ", "env", ".", "gym_env", ".", "render", "(", ")", "\n", "", "agent_outputs", "=", "model", "(", "observation", ")", "\n", "policy_outputs", ",", "_", "=", "agent_outputs", "\n", "observation", "=", "env", ".", "step", "(", "policy_outputs", "[", "\"action\"", "]", ")", "\n", "if", "observation", "[", "\"done\"", "]", ".", "item", "(", ")", ":", "\n", "            ", "returns", ".", "append", "(", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Episode ended after %d steps. Return: %.1f\"", ",", "\n", "observation", "[", "\"episode_step\"", "]", ".", "item", "(", ")", ",", "\n", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Average returns over %i steps: %.1f\"", ",", "num_episodes", ",", "sum", "(", "returns", ")", "/", "len", "(", "returns", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.create_env": [[658, 665], ["Model.atari_wrappers.wrap_pytorch", "Model.atari_wrappers.wrap_deepmind", "Model.atari_wrappers.make_atari"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_pytorch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.make_atari"], ["def", "create_env", "(", "flags", ")", ":", "\n", "    ", "return", "atari_wrappers", ".", "wrap_pytorch", "(", "\n", "atari_wrappers", ".", "wrap_deepmind", "(", "\n", "atari_wrappers", ".", "make_atari", "(", "flags", ".", "env", ")", ",", "\n", "clip_rewards", "=", "False", ",", "\n", "frame_stack", "=", "True", ",", "\n", "scale", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_fb.main": [[669, 674], ["monobeast_fb.train", "monobeast_fb.test"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.test"], ["", "def", "main", "(", "flags", ")", ":", "\n", "    ", "if", "flags", ".", "mode", "==", "\"train\"", ":", "\n", "        ", "train", "(", "flags", ")", "\n", "", "else", ":", "\n", "        ", "test", "(", "flags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.__init__": [[866, 942], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear", "StableTransformersReplication.transformer_xl.MemTransformerLM", "monobeast_test.AtariNet.core.apply", "torch.nn.Linear", "torch.nn.Linear", "feats_convs.append", "feats_convs.append", "monobeast_test.AtariNet.feat_convs.append", "range", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "torch.nn.Sequential", "resnet_block.append", "resnet_block.append", "resnet_block.append", "resnet_block.append", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "monobeast_test.AtariNet.resnet1.append", "monobeast_test.AtariNet.resnet2.append", "torch.nn.Sequential", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "observation_shape", ",", "num_actions", ")", ":", "\n", "        ", "super", "(", "AtariNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "observation_shape", "=", "observation_shape", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "\n", "self", ".", "feat_convs", "=", "[", "]", "\n", "self", ".", "resnet1", "=", "[", "]", "\n", "self", ".", "resnet2", "=", "[", "]", "\n", "\n", "self", ".", "convs", "=", "[", "]", "\n", "input_channels", "=", "self", ".", "observation_shape", "[", "0", "]", "\n", "for", "num_ch", "in", "[", "16", ",", "32", ",", "32", "]", ":", "\n", "            ", "feats_convs", "=", "[", "]", "\n", "feats_convs", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "feats_convs", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "self", ".", "feat_convs", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "feats_convs", ")", ")", "\n", "\n", "input_channels", "=", "num_ch", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "                ", "resnet_block", "=", "[", "]", "\n", "resnet_block", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "resnet_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "resnet_block", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "resnet_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "num_ch", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "self", ".", "resnet1", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "resnet_block", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "resnet2", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "resnet_block", ")", ")", "\n", "\n", "", "", "", "self", ".", "feat_convs", "=", "nn", ".", "ModuleList", "(", "self", ".", "feat_convs", ")", "\n", "self", ".", "resnet1", "=", "nn", ".", "ModuleList", "(", "self", ".", "resnet1", ")", "\n", "self", ".", "resnet2", "=", "nn", ".", "ModuleList", "(", "self", ".", "resnet2", ")", "\n", "\n", "\n", "# Fully connected layer.", "\n", "# Changed the FC output to match the transformer output which should be divisible by number of heads", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3872", ",", "256", "-", "num_actions", "-", "1", ")", "\n", "\n", "# FC output size + one-hot of last action + last reward.", "\n", "core_output_size", "=", "self", ".", "fc", ".", "out_features", "+", "num_actions", "+", "1", "\n", "###############################################################transformer", "\n", "# TODO : 1st replacement, sanity check the parameters", "\n", "# TODO : play around with d_inner, this is the dimension for positionwise feedforward hidden projection", "\n", "# TODO : Change the n_layer=1 to 12", "\n", "self", ".", "core", "=", "MemTransformerLM", "(", "n_token", "=", "None", ",", "n_layer", "=", "1", ",", "n_head", "=", "8", ",", "d_head", "=", "core_output_size", "//", "8", ",", "\n", "d_model", "=", "core_output_size", ",", "d_inner", "=", "2048", ",", "\n", "dropout", "=", "0.1", ",", "dropatt", "=", "0.0", ",", "tgt_len", "=", "512", ",", "mem_len", "=", "1", ",", "ext_len", "=", "0", ",", "\n", "use_stable_version", "=", "True", ",", "use_gate", "=", "False", ")", "\n", "self", ".", "core", ".", "apply", "(", "weights_init", ")", "\n", "self", ".", "policy", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "baseline", "=", "nn", ".", "Linear", "(", "core_output_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state": [[943, 950], ["tuple", "torch.zeros", "range"], "methods", ["None"], ["", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "# if not self.use_lstm:", "\n", "#     return tuple()", "\n", "        ", "return", "tuple", "(", "\n", "# torch.zeros(self.core.num_layers, batch_size, self.core.hidden_size)", "\n", "torch", ".", "zeros", "(", "self", ".", "core", ".", "n_layer", ",", "batch_size", ",", "self", ".", "core", ".", "d_model", ")", "\n", "for", "_", "in", "range", "(", "2", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.forward": [[952, 1037], ["torch.flatten", "enumerate", "torch.nn.functional.relu", "fconv.view", "torch.nn.functional.relu", "torch.nn.functional.one_hot().float", "torch.clamp().view", "torch.cat", "core_input.view.view.view", "torch.clone", "padding_mask.unsqueeze.unsqueeze.unsqueeze", "monobeast_test.AtariNet.core", "monobeast_test.AtariNet.policy", "monobeast_test.AtariNet.baseline", "policy_logits.view.view.reshape", "policy_logits.view.view.view", "baseline.view.view.view", "torch.argmax.view", "fconv.float", "fconv", "monobeast_test.AtariNet.fc", "padding_mask.unsqueeze.unsqueeze.dim", "torch.clone", "padding_mask.unsqueeze.unsqueeze.any().item", "torch.multinomial", "torch.argmax", "dict", "torch.nn.functional.one_hot", "torch.clamp", "padding_mask.unsqueeze.unsqueeze.long().argmin", "torch.nn.functional.softmax", "inputs[].view", "padding_mask.unsqueeze.unsqueeze.any", "padding_mask.unsqueeze.unsqueeze.long", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "core_state", "=", "(", ")", ",", "mems", "=", "None", ",", "mem_padding", "=", "None", ")", ":", "\n", "\n", "        ", "x", "=", "inputs", "[", "\"frame\"", "]", "\n", "T", ",", "B", ",", "*", "_", "=", "x", ".", "shape", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "0", ",", "1", ")", "# Merge time and batch.", "\n", "x", "=", "x", ".", "float", "(", ")", "/", "255.0", "\n", "\n", "for", "i", ",", "fconv", "in", "enumerate", "(", "self", ".", "feat_convs", ")", ":", "\n", "            ", "x", "=", "fconv", "(", "x", ")", "\n", "res_input", "=", "x", "\n", "x", "=", "self", ".", "resnet1", "[", "i", "]", "(", "x", ")", "\n", "x", "+=", "res_input", "\n", "res_input", "=", "x", "\n", "x", "=", "self", ".", "resnet2", "[", "i", "]", "(", "x", ")", "\n", "x", "+=", "res_input", "\n", "", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "B", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "\n", "#print('inputs: ', inputs)", "\n", "#print('inputs last action', inputs['last_action'])", "\n", "one_hot_last_action", "=", "F", ".", "one_hot", "(", "\n", "inputs", "[", "\"last_action\"", "]", ".", "view", "(", "T", "*", "B", ")", ",", "self", ".", "num_actions", "\n", ")", ".", "float", "(", ")", "\n", "\n", "clipped_reward", "=", "torch", ".", "clamp", "(", "inputs", "[", "\"reward\"", "]", ",", "-", "1", ",", "1", ")", ".", "view", "(", "T", "*", "B", ",", "1", ")", "\n", "core_input", "=", "torch", ".", "cat", "(", "[", "x", ",", "clipped_reward", ",", "one_hot_last_action", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "core_input", "=", "core_input", ".", "view", "(", "T", ",", "B", ",", "-", "1", ")", "\n", "\n", "padding_mask", "=", "torch", ".", "clone", "(", "inputs", "[", "'done'", "]", ")", "\n", "\n", "ind_first_done", "=", "None", "\n", "if", "padding_mask", ".", "dim", "(", ")", ">", "1", ":", "#This only seems to not happen on first state ever in env.initialize()", "\n", "# this block just tries to push the dones one position down so that the loss calculation does account", "\n", "# for that step and not ignores it as mask", "\n", "            ", "ind_first_done", "=", "padding_mask", ".", "long", "(", ")", ".", "argmin", "(", "0", ")", "+", "1", "# will be index of first 1 in each column", "\n", "orig_first_row", "=", "torch", ".", "clone", "(", "padding_mask", "[", "0", ",", ":", "]", ")", "\n", "ind_first_done", "[", "padding_mask", "[", "0", ",", ":", "]", "==", "1", "]", "=", "0", "# If there aren't any 0's in the whole inputs['done'] then set ind_first_done to 0", "\n", "ind_first_done", "[", "ind_first_done", ">=", "padding_mask", ".", "shape", "[", "0", "]", "]", "=", "-", "1", "# choosing -1 helps in learn function", "\n", "padding_mask", "[", "ind_first_done", ",", "range", "(", "B", ")", "]", "=", "False", "\n", "padding_mask", "[", "0", ",", ":", "]", "=", "orig_first_row", "\n", "\n", "", "padding_mask", "=", "padding_mask", ".", "unsqueeze", "(", "0", ")", "\n", "if", "not", "padding_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "#In this case no need for padding_mask", "\n", "            ", "padding_mask", "=", "None", "\n", "\n", "", "core_output", ",", "mems", "=", "self", ".", "core", "(", "core_input", ",", "mems", ",", "padding_mask", "=", "padding_mask", ",", "mem_padding", "=", "mem_padding", ")", "# core_input is of shape (T, B, ...)", "\n", "# core_output is (B, ...)", "\n", "\n", "policy_logits", "=", "self", ".", "policy", "(", "core_output", ")", "\n", "baseline", "=", "self", ".", "baseline", "(", "core_output", ")", "\n", "\n", "policy_logits", "=", "policy_logits", ".", "reshape", "(", "T", "*", "B", ",", "self", ".", "num_actions", ")", "\n", "# # if policy_logits.shape[0] == 32 and policy_logits.shape[1] == 6:", "\n", "# if not torch.all(policy_logits == policy_logits).item():", "\n", "#     # nans only come when the learner_model calls this forward", "\n", "#     print('from monobeast 921\\n', policy_logits)", "\n", "#     print('core output : ',core_output.shape, '\\n', core_output)", "\n", "#     print('core input : \\n', core_input)", "\n", "#     print('mask : \\n', padding_mask)", "\n", "#     print('mems : \\n', mems)", "\n", "#     torch.save(core_input, './core_input.pt')", "\n", "#     torch.save(padding_mask, './padding_mask.pt')", "\n", "#     torch.save(mems, './mems.pt')", "\n", "\n", "if", "self", ".", "training", ":", "\n", "# Sample from multinomial distribution for exploration", "\n", "# if not (padding_mask is None) and padding_mask.shape[1] > 1:", "\n", "#     print('Padding shape: {}, logits shape: {}'.format(padding_mask.shape, policy_logits.shape))", "\n", "#     print('PADDING: ', padding_mask)", "\n", "#     print(\"LOGITS: \", policy_logits)", "\n", "            ", "action", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "policy_logits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ")", "\n", "", "else", ":", "\n", "# Don't sample when testing.", "\n", "            ", "action", "=", "torch", ".", "argmax", "(", "policy_logits", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_logits", "=", "policy_logits", ".", "view", "(", "T", ",", "B", ",", "self", ".", "num_actions", ")", "\n", "baseline", "=", "baseline", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "action", "=", "action", ".", "view", "(", "T", ",", "B", ")", "\n", "\n", "return", "(", "\n", "dict", "(", "policy_logits", "=", "policy_logits", ",", "baseline", "=", "baseline", ",", "action", "=", "action", ")", ",", "\n", "core_state", ",", "mems", ",", "padding_mask", ",", "ind_first_done", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss": [[139, 143], ["torch.sum"], "function", ["None"], ["def", "compute_baseline_loss", "(", "advantages", ",", "padding_mask", ")", ":", "\n", "    ", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "advantages", "=", "advantages", "*", "padding_mask", "\n", "", "return", "0.5", "*", "torch", ".", "sum", "(", "advantages", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss": [[145, 156], ["torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.sum", "padding_mask.unsqueeze"], "function", ["None"], ["", "def", "compute_entropy_loss", "(", "logits", ",", "padding_mask", ")", ":", "\n", "    ", "\"\"\"Return the entropy loss, i.e., the negative entropy of the policy.\"\"\"", "\n", "policy", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "log_policy", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "#print('log_policyshape: ', log_policy.shape)", "\n", "#print('padding mask: ', padding_mask.shape)", "\n", "        ", "log_policy", "=", "log_policy", "*", "padding_mask", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "", "return", "torch", ".", "sum", "(", "policy", "*", "log_policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss": [[158, 168], ["torch.nn.functional.nll_loss", "cross_entropy.view_as.view_as", "torch.sum", "torch.nn.functional.log_softmax", "torch.flatten", "torch.flatten", "advantages.detach"], "function", ["None"], ["", "def", "compute_policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ",", "padding_mask", ")", ":", "\n", "    ", "cross_entropy", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "torch", ".", "flatten", "(", "logits", ",", "0", ",", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "torch", ".", "flatten", "(", "actions", ",", "0", ",", "1", ")", ",", "\n", "reduction", "=", "\"none\"", ",", "\n", ")", "\n", "cross_entropy", "=", "cross_entropy", ".", "view_as", "(", "advantages", ")", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "cross_entropy", "=", "cross_entropy", "*", "padding_mask", "\n", "", "return", "torch", ".", "sum", "(", "cross_entropy", "*", "advantages", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.act": [[170, 267], ["logging.info", "Model.core.prof.Timings", "monobeast_test.create_env", "create_env.seed", "Model.core.environment.Environment", "environment.Environment.initial", "torch.tensor", "model.initial_state", "model", "int.from_bytes", "free_queue.get", "enumerate", "env_output[].item", "full_queue.put", "logging.info", "logging.error", "traceback.print_exc", "os.urandom", "prof.Timings.reset", "prof.Timings.time", "torch.randint().item", "range", "prof.Timings.time", "prof.Timings.time", "environment.Environment.step", "torch.tensor().repeat", "prof.Timings.summary", "env_output[].item", "torch.no_grad", "model", "environment.Environment.step", "env_output[].item", "torch.tensor", "torch.randint", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.AtariNet.initial_state", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.FrameStack.reset", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.summary", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "act", "(", "\n", "flags", ",", "\n", "actor_index", ":", "int", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"Actor %i started.\"", ",", "actor_index", ")", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "# Keep track of how fast things are.", "\n", "\n", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "seed", "=", "actor_index", "^", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "4", ")", ",", "byteorder", "=", "\"little\"", ")", "\n", "gym_env", ".", "seed", "(", "seed", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "env_output", "=", "env", ".", "initial", "(", ")", "\n", "env_output", "[", "'done'", "]", "=", "torch", ".", "tensor", "(", "[", "[", "0", "]", "]", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "agent_state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "mems", ",", "mem_padding", "=", "None", ",", "None", "\n", "agent_output", ",", "unused_state", ",", "mems", ",", "mem_padding", ",", "_", "=", "model", "(", "env_output", ",", "agent_state", ",", "mems", ",", "mem_padding", ")", "\n", "while", "True", ":", "\n", "            ", "index", "=", "free_queue", ".", "get", "(", ")", "\n", "if", "index", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "# explicitly make done False to allow the loop to run", "\n", "#Don't need to set 'done' to true since now take step out of done state", "\n", "#when do arrive at 'done'", "\n", "#env_output['done'] = torch.tensor([0], dtype=torch.uint8)", "\n", "\n", "# Write old rollout end.", "\n", "", "for", "key", "in", "env_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                ", "buffers", "[", "key", "]", "[", "index", "]", "[", "0", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "", "for", "i", ",", "tensor", "in", "enumerate", "(", "agent_state", ")", ":", "\n", "                ", "initial_agent_state_buffers", "[", "index", "]", "[", "i", "]", "[", "...", "]", "=", "tensor", "\n", "\n", "# Do one new rollout, untill flags.unroll_length", "\n", "", "t", "=", "0", "\n", "while", "t", "<", "flags", ".", "unroll_length", "and", "not", "env_output", "[", "'done'", "]", ".", "item", "(", ")", ":", "\n", "# for t in range(flags.unroll_length):", "\n", "                ", "timings", ".", "reset", "(", ")", "\n", "#REmoved since never this will never be true (MOVED TO AFTER FOR LOOP)", "\n", "#if env_output['done'].item():", "\n", "#    mems = None", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "agent_output", ",", "agent_state", ",", "mems", ",", "mem_padding", ",", "_", "=", "model", "(", "env_output", ",", "agent_state", ",", "mems", ",", "mem_padding", ")", "\n", "\n", "", "timings", ".", "time", "(", "\"model\"", ")", "\n", "\n", "#TODO: can this be done more efficiently?", "\n", "repeat_times", "=", "torch", ".", "randint", "(", "low", "=", "2", ",", "high", "=", "flags", ".", "action_repeat", "+", "1", ",", "size", "=", "(", "1", ",", ")", ")", ".", "item", "(", ")", "\n", "for", "el", "in", "range", "(", "repeat_times", ")", ":", "\n", "                    ", "env_output", "=", "env", ".", "step", "(", "agent_output", "[", "\"action\"", "]", ")", "\n", "if", "env_output", "[", "'done'", "]", ".", "item", "(", ")", ":", "\n", "                        ", "break", "\n", "\n", "", "", "timings", ".", "time", "(", "\"step\"", ")", "\n", "\n", "for", "key", "in", "env_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "env_output", "[", "key", "]", "\n", "", "for", "key", "in", "agent_output", ":", "\n", "                    ", "buffers", "[", "key", "]", "[", "index", "]", "[", "t", "+", "1", ",", "...", "]", "=", "agent_output", "[", "key", "]", "\n", "\n", "", "timings", ".", "time", "(", "\"write\"", ")", "\n", "t", "+=", "1", "\n", "\n", "", "if", "env_output", "[", "'done'", "]", ".", "item", "(", ")", ":", "\n", "                ", "mems", "=", "None", "\n", "#Take arbitrary step to reset environment", "\n", "env_output", "=", "env", ".", "step", "(", "torch", ".", "tensor", "(", "[", "2", "]", ")", ")", "\n", "\n", "", "buffers", "[", "'len_traj'", "]", "[", "index", "]", "[", "0", "]", "=", "t", "\n", "\n", "if", "t", "!=", "flags", ".", "unroll_length", ":", "\n", "#TODO I checked and seems good but Shakti can you check as well?", "\n", "#TODO: Does this still work now that inputs['done'] not getting changed behind scenes from rpevious bug?", "\n", "                ", "buffers", "[", "'done'", "]", "[", "index", "]", "[", "t", "+", "1", ":", "]", "=", "torch", ".", "tensor", "(", "[", "True", "]", ")", ".", "repeat", "(", "flags", ".", "unroll_length", "-", "t", ")", "\n", "\n", "\n", "", "full_queue", ".", "put", "(", "index", ")", "\n", "\n", "", "if", "actor_index", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Actor %i: %s\"", ",", "actor_index", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# Return silently.", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logging", ".", "error", "(", "\"Exception in worker process %i\"", ",", "actor_index", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "# print()", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_batch": [[269, 305], ["threading.Lock", "timings.time", "timings.time", "tuple", "timings.time", "timings.time", "timings.time", "torch.stack", "torch.cat", "free_queue.put", "t.to", "full_queue.get", "zip", "batch.items", "t.to", "range"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.prof.Timings.time"], ["", "", "def", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "full_queue", ":", "mp", ".", "SimpleQueue", ",", "\n", "buffers", ":", "Buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "\n", ")", ":", "\n", "    ", "with", "lock", ":", "\n", "        ", "timings", ".", "time", "(", "\"lock\"", ")", "\n", "indices", "=", "[", "full_queue", ".", "get", "(", ")", "for", "_", "in", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "\n", "# TODO: Check if emptying full_queue and then readding to it takes very long,", "\n", "#       seems like the only way to ensure a batch of similar length elements", "\n", "# One problem with doing this is that if get a really short trajectory, may never end up", "\n", "# using it. DONT CHANGE THIS FOR NOW.", "\n", "\n", "timings", ".", "time", "(", "\"dequeue\"", ")", "\n", "", "batch", "=", "{", "\n", "key", ":", "torch", ".", "stack", "(", "[", "buffers", "[", "key", "]", "[", "m", "]", "for", "m", "in", "indices", "]", ",", "dim", "=", "1", ")", "for", "key", "in", "buffers", "\n", "}", "\n", "initial_agent_state", "=", "(", "\n", "torch", ".", "cat", "(", "ts", ",", "dim", "=", "1", ")", "\n", "for", "ts", "in", "zip", "(", "*", "[", "initial_agent_state_buffers", "[", "m", "]", "for", "m", "in", "indices", "]", ")", "\n", ")", "\n", "timings", ".", "time", "(", "\"batch\"", ")", "\n", "for", "m", "in", "indices", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "", "timings", ".", "time", "(", "\"enqueue\"", ")", "\n", "batch", "=", "{", "k", ":", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "k", ",", "t", "in", "batch", ".", "items", "(", ")", "}", "\n", "initial_agent_state", "=", "tuple", "(", "\n", "t", ".", "to", "(", "device", "=", "flags", ".", "device", ",", "non_blocking", "=", "True", ")", "for", "t", "in", "initial_agent_state", "\n", ")", "\n", "timings", ".", "time", "(", "\"device\"", ")", "\n", "return", "batch", ",", "initial_agent_state", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.learn": [[307, 445], ["threading.Lock", "range", "actor_model.load_state_dict", "torch.zeros_like().bool", "model", "Model.core.vtrace.from_logits", "monobeast_test.compute_policy_gradient_loss", "optimizer.zero_grad", "total_loss.backward", "optimizer.step", "model.state_dict", "torch.clamp", "monobeast_test.compute_baseline_loss", "monobeast_test.compute_entropy_loss", "enumerate", "tuple", "torch.mean().item", "total_loss.item", "compute_policy_gradient_loss.item", "baseline_loss.item", "entropy_loss.item", "optimizer.clip_master_grads", "torch.nn.utils.clip_grad_norm_", "torch.zeros_like", "mini_batch.items", "learner_outputs.items", "episode_returns.cpu().numpy", "model.parameters", "rows_to_use.append", "cols_to_use.append", "torch.mean", "range", "episode_returns.cpu", "mem_padding.squeeze"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.vtrace.from_logits", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_policy_gradient_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_baseline_loss", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.compute_entropy_loss"], ["", "def", "learn", "(", "\n", "flags", ",", "\n", "actor_model", ",", "\n", "model", ",", "\n", "batch", ",", "\n", "initial_agent_state", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "lock", "=", "threading", ".", "Lock", "(", ")", ",", "# noqa: B008", "\n", ")", ":", "\n", "    ", "\"\"\"Performs a learning (optimization) step.\"\"\"", "\n", "with", "lock", ":", "\n", "        ", "\"\"\"\n        put a lock on the central learner,\n        send the trajectories to it.\n        Update the parameters of the central learner,\n        copy the parameters of the central learner back to the actors\n        \"\"\"", "\n", "\n", "# TODO: Chop up batch into smaller pieces to run through TXL one at a time (caching previous as memory)", "\n", "# TODO: Change batch function to look for trajectories of similar lengths", "\n", "# TODO: Add in adaptive attention (and think of how things change (for ex no memory))", "\n", "#print({key: batch[key].shape for key in batch})", "\n", "mems", ",", "mem_padding", "=", "None", ",", "None", "\n", "for", "i", "in", "range", "(", "0", ",", "flags", ".", "unroll_length", "+", "1", ",", "flags", ".", "chunk_size", ")", ":", "\n", "            ", "mini_batch", "=", "{", "key", ":", "batch", "[", "key", "]", "[", "i", ":", "i", "+", "flags", ".", "chunk_size", "]", "for", "key", "in", "batch", "if", "key", "!=", "'len_traj'", "}", "\n", "#Note that initial agent state isn't used by transformer (I think this is hidden state)", "\n", "#Will need to change if want to use this with LSTM", "\n", "\n", "#TODO : Need to change batch->minibatch (batch name gets overwritten)", "\n", "tmp_mask", "=", "torch", ".", "zeros_like", "(", "mini_batch", "[", "\"done\"", "]", ")", ".", "bool", "(", ")", "\n", "\n", "learner_outputs", ",", "unused_state", ",", "mems", ",", "mem_padding", ",", "ind_first_done", "=", "model", "(", "mini_batch", ",", "initial_agent_state", ",", "\n", "mems", "=", "mems", ",", "mem_padding", "=", "mem_padding", ")", "\n", "#Here mem_padding is same as \"batch\" padding for this iteration so can use", "\n", "#for masking loss", "\n", "\n", "#if mini_batch[\"done\"].any().item():", "\n", "#    print('Indfirstdone: ',ind_first_done)", "\n", "#    print('miniBATCH DONE: ', mini_batch[\"done\"])", "\n", "#    print('Mem padding: ', mem_padding)", "\n", "\n", "# Take final value function slice for bootstrapping.", "\n", "# this is the final value from this trajectory", "\n", "if", "ind_first_done", "is", "not", "None", ":", "\n", "# B dimensional tensor", "\n", "                ", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "ind_first_done", ",", "range", "(", "flags", ".", "batch_size", ")", "]", "\n", "", "else", ":", "\n", "                ", "bootstrap_value", "=", "learner_outputs", "[", "\"baseline\"", "]", "[", "-", "1", "]", "\n", "\n", "# Move from obs[t] -> action[t] to action[t] -> obs[t].", "\n", "", "mini_batch", "=", "{", "key", ":", "tensor", "[", "1", ":", "]", "for", "key", ",", "tensor", "in", "mini_batch", ".", "items", "(", ")", "}", "\n", "learner_outputs", "=", "{", "key", ":", "tensor", "[", ":", "-", "1", "]", "for", "key", ",", "tensor", "in", "learner_outputs", ".", "items", "(", ")", "}", "\n", "\n", "#Using learner_outputs to predict batch since batch is always one ahead of learner_outputs?", "\n", "\n", "rewards", "=", "mini_batch", "[", "\"reward\"", "]", "\n", "if", "flags", ".", "reward_clipping", "==", "\"abs_one\"", ":", "\n", "                ", "clipped_rewards", "=", "torch", ".", "clamp", "(", "rewards", ",", "-", "1", ",", "1", ")", "\n", "", "elif", "flags", ".", "reward_clipping", "==", "\"none\"", ":", "\n", "                ", "clipped_rewards", "=", "rewards", "\n", "\n", "", "discounts", "=", "(", "~", "mini_batch", "[", "\"done\"", "]", ")", ".", "float", "(", ")", "*", "flags", ".", "discounting", "\n", "\n", "vtrace_returns", "=", "vtrace", ".", "from_logits", "(", "\n", "behavior_policy_logits", "=", "mini_batch", "[", "\"policy_logits\"", "]", ",", "\n", "target_policy_logits", "=", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "#WHY IS THIS THE TARGET?", "\n", "actions", "=", "mini_batch", "[", "\"action\"", "]", ",", "\n", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "clipped_rewards", ",", "\n", "values", "=", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ",", "\n", ")", "\n", "\n", "# TODO Next Step: the losses also have to be computed with the padding, think on a structure of mask", "\n", "#                   to do this efficiently", "\n", "# Advantages are [rollout_len, batch_size]", "\n", "\n", "# First we mask out vtrace_returns.pg_advantages where there is padding which fixes pg_loss", "\n", "pad_mask", "=", "(", "~", "(", "mem_padding", ".", "squeeze", "(", "0", ")", "[", "1", ":", "]", ")", ")", ".", "float", "(", ")", "if", "mem_padding", "is", "not", "None", "else", "None", "\n", "\n", "pg_loss", "=", "compute_policy_gradient_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "mini_batch", "[", "\"action\"", "]", ",", "\n", "vtrace_returns", ".", "pg_advantages", ",", "\n", "pad_mask", "\n", ")", "\n", "baseline_loss", "=", "flags", ".", "baseline_cost", "*", "compute_baseline_loss", "(", "\n", "vtrace_returns", ".", "vs", "-", "learner_outputs", "[", "\"baseline\"", "]", ",", "\n", "pad_mask", "\n", ")", "\n", "entropy_loss", "=", "flags", ".", "entropy_cost", "*", "compute_entropy_loss", "(", "\n", "learner_outputs", "[", "\"policy_logits\"", "]", ",", "\n", "pad_mask", "\n", ")", "\n", "\n", "total_loss", "=", "pg_loss", "+", "baseline_loss", "+", "entropy_loss", "\n", "\n", "#tmp_mask is defined above", "\n", "if", "ind_first_done", "is", "not", "None", ":", "\n", "                ", "rows_to_use", "=", "[", "]", "\n", "cols_to_use", "=", "[", "]", "\n", "for", "i", ",", "val", "in", "enumerate", "(", "ind_first_done", ")", ":", "\n", "                    ", "if", "val", "!=", "-", "1", ":", "\n", "                        ", "rows_to_use", ".", "append", "(", "val", ")", "\n", "cols_to_use", ".", "append", "(", "i", ")", "\n", "\n", "", "", "tmp_mask", "[", "rows_to_use", ",", "cols_to_use", "]", "=", "True", "#NOT RIGHT FOR COLS THAT DIDNT FINISH", "\n", "tmp_mask", "=", "tmp_mask", "[", "1", ":", "]", "#This is how they initially had it so will keep like this", "\n", "#if mini_batch[\"done\"].any().item():", "\n", "#    print('TMP MASK: ',tmp_mask)", "\n", "#    print('BATCH DONE: ', mini_batch[\"done\"])", "\n", "#    print('shape1: {}, shape2: {}'.format(tmp_mask.shape, mini_batch['done'].shape))", "\n", "\n", "#episode_returns = mini_batch[\"episode_return\"][mini_batch[\"done\"]]", "\n", "", "episode_returns", "=", "mini_batch", "[", "\"episode_return\"", "]", "[", "tmp_mask", "]", "\n", "\n", "stats", "=", "{", "\n", "\"episode_returns\"", ":", "tuple", "(", "episode_returns", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "\"mean_episode_return\"", ":", "torch", ".", "mean", "(", "episode_returns", ")", ".", "item", "(", ")", ",", "\n", "\"total_loss\"", ":", "total_loss", ".", "item", "(", ")", ",", "\n", "\"pg_loss\"", ":", "pg_loss", ".", "item", "(", ")", ",", "\n", "\"baseline_loss\"", ":", "baseline_loss", ".", "item", "(", ")", ",", "\n", "\"entropy_loss\"", ":", "entropy_loss", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "if", "flags", ".", "fp16", ":", "\n", "                ", "optimizer", ".", "clip_master_grads", "(", "flags", ".", "grad_norm_clipping", ")", "\n", "", "else", ":", "\n", "                ", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "flags", ".", "grad_norm_clipping", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "# scheduler is being stepped in the lock of batch_and_learn itself", "\n", "# scheduler.step()", "\n", "\n", "", "actor_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_buffers": [[447, 466], ["dict", "range", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "buffers[].append", "torch.empty().share_memory_", "torch.empty"], "function", ["None"], ["", "", "def", "create_buffers", "(", "flags", ",", "obs_shape", ",", "num_actions", ")", "->", "Buffers", ":", "\n", "    ", "T", "=", "flags", ".", "unroll_length", "\n", "specs", "=", "dict", "(", "\n", "frame", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "*", "obs_shape", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "reward", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "done", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "\n", "episode_return", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "episode_step", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ",", "\n", "policy_logits", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", "num_actions", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "baseline", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "last_action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "action", "=", "dict", "(", "size", "=", "(", "T", "+", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "\n", "len_traj", "=", "dict", "(", "size", "=", "(", "1", ",", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "#is min(length til trajectory is done, T)", "\n", ")", "\n", "buffers", ":", "Buffers", "=", "{", "key", ":", "[", "]", "for", "key", "in", "specs", "}", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "for", "key", "in", "buffers", ":", "\n", "            ", "buffers", "[", "key", "]", ".", "append", "(", "torch", ".", "empty", "(", "**", "specs", "[", "key", "]", ")", ".", "share_memory_", "(", ")", ")", "\n", "", "", "return", "buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_optimizer": [[468, 477], ["flags.optim.lower", "torch.optim.SGD", "flags.optim.lower", "torch.optim.Adam", "flags.optim.lower", "torch.optim.Adagrad"], "function", ["None"], ["", "def", "get_optimizer", "(", "flags", ",", "parameters", ")", ":", "\n", "    ", "optimizer", "=", "None", "\n", "if", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ",", "momentum", "=", "flags", ".", "momentum", ")", "\n", "", "elif", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ")", "\n", "", "elif", "flags", ".", "optim", ".", "lower", "(", ")", "==", "'adagrad'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "parameters", ",", "lr", "=", "flags", ".", "learning_rate", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_scheduler": [[479, 505], ["torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.ReduceLROnPlateau"], "function", ["None"], ["", "def", "get_scheduler", "(", "flags", ",", "optimizer", ")", ":", "\n", "    ", "scheduler", "=", "None", "\n", "if", "flags", ".", "scheduler", "==", "'cosine'", ":", "\n", "# here we do not set eta_min to lr_min to be backward compatible", "\n", "# because in previous versions eta_min is default to 0", "\n", "# rather than the default value of lr_min 1e-6", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "\n", "flags", ".", "max_step", ",", "eta_min", "=", "flags", ".", "eta_min", ")", "\n", "", "elif", "flags", ".", "scheduler", "==", "'inv_sqrt'", ":", "\n", "# originally used for Transformer (in Attention is all you need)", "\n", "        ", "def", "lr_lambda", "(", "step", ")", ":", "\n", "# return a multiplier instead of a learning rate", "\n", "            ", "if", "step", "==", "0", "and", "flags", ".", "warmup_step", "==", "0", ":", "\n", "                ", "return", "1.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "/", "(", "step", "**", "0.5", ")", "if", "step", ">", "flags", ".", "warmup_step", "else", "step", "/", "(", "flags", ".", "warmup_step", "**", "1.5", ")", "\n", "", "", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lr_lambda", ")", "\n", "\n", "", "elif", "flags", ".", "scheduler", "==", "'dev_perf'", ":", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "\n", "factor", "=", "flags", ".", "decay_rate", ",", "patience", "=", "flags", ".", "patience", ",", "\n", "min_lr", "=", "flags", ".", "lr_min", ")", "\n", "", "elif", "flags", ".", "scheduler", "==", "'constant'", ":", "\n", "        ", "pass", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train": [[507, 772], ["Model.core.file_writer.FileWriter", "os.path.expandvars", "monobeast_test.create_env", "Net", "monobeast_test.create_buffers", "Net.share_memory", "range", "torch.multiprocessing.get_context", "mp.get_context.SimpleQueue", "mp.get_context.SimpleQueue", "range", "Net().to", "monobeast_test.get_optimizer", "monobeast_test.get_scheduler", "logging.getLogger", "logging.getLogger.info", "range", "range", "monobeast_test.train.checkpoint"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_buffers", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_optimizer", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.get_scheduler", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_single_proc.checkpoint"], ["", "def", "train", "(", "flags", ")", ":", "# pylint: disable=too-many-branches, too-many-statements", "\n", "\n", "# load the previous config if use_pretrained is true", "\n", "    ", "if", "flags", ".", "use_pretrained", ":", "\n", "        ", "logging", ".", "info", "(", "'Using Pretrained Model'", ")", "\n", "class", "Bunch", "(", "object", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "adict", ")", ":", "\n", "                ", "self", ".", "__dict__", ".", "update", "(", "adict", ")", "\n", "", "", "model_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "'logs/torchbeast/'", "+", "flags", ".", "xpid", "+", "'/model.tar'", ")", "\n", "pretrained_model", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "'cpu'", "if", "flags", ".", "disable_cuda", "else", "'gpu'", ")", "\n", "flags", "=", "Bunch", "(", "pretrained_model", "[", "'flags'", "]", ")", "\n", "flags", ".", "use_pretrained", "=", "True", "\n", "\n", "", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "flags", ".", "xpid", "=", "\"torchbeast-%s\"", "%", "time", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "", "plogger", "=", "file_writer", ".", "FileWriter", "(", "\n", "xpid", "=", "flags", ".", "xpid", ",", "xp_args", "=", "flags", ".", "__dict__", ",", "rootdir", "=", "flags", ".", "savedir", "\n", ")", "\n", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "if", "flags", ".", "num_buffers", "is", "None", ":", "# Set sensible default for num_buffers.", "\n", "        ", "flags", ".", "num_buffers", "=", "max", "(", "2", "*", "flags", ".", "num_actors", ",", "flags", ".", "batch_size", ")", "\n", "", "if", "flags", ".", "num_actors", ">=", "flags", ".", "num_buffers", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than num_actors\"", ")", "\n", "", "if", "flags", ".", "num_buffers", "<", "flags", ".", "batch_size", ":", "\n", "        ", "raise", "ValueError", "(", "\"num_buffers should be larger than batch_size\"", ")", "\n", "\n", "", "T", "=", "flags", ".", "unroll_length", "\n", "B", "=", "flags", ".", "batch_size", "\n", "\n", "flags", ".", "device", "=", "None", "\n", "if", "not", "flags", ".", "disable_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Not using CUDA.\"", ")", "\n", "flags", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "env", "=", "create_env", "(", "flags", ")", "\n", "\n", "\"\"\"model is each of the actors, running parallel. The upcoming block ctx.Process(...)\"\"\"", "\n", "model", "=", "Net", "(", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ")", "\n", "buffers", "=", "create_buffers", "(", "flags", ",", "env", ".", "observation_space", ".", "shape", ",", "model", ".", "num_actions", ")", "\n", "\n", "model", ".", "share_memory", "(", ")", "\n", "\n", "# Add initial RNN state.", "\n", "initial_agent_state_buffers", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "state", "=", "model", ".", "initial_state", "(", "batch_size", "=", "1", ")", "\n", "for", "t", "in", "state", ":", "\n", "            ", "t", ".", "share_memory_", "(", ")", "\n", "", "initial_agent_state_buffers", ".", "append", "(", "state", ")", "\n", "\n", "", "actor_processes", "=", "[", "]", "\n", "ctx", "=", "mp", ".", "get_context", "(", "\"fork\"", ")", "\n", "free_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "full_queue", "=", "ctx", ".", "SimpleQueue", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "        ", "actor", "=", "ctx", ".", "Process", "(", "\n", "target", "=", "act", ",", "\n", "args", "=", "(", "\n", "flags", ",", "\n", "i", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "model", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", ")", ",", "\n", ")", "\n", "actor", ".", "start", "(", ")", "\n", "actor_processes", ".", "append", "(", "actor", ")", "\n", "\n", "", "\"\"\"learner_model is the central learner, which takes in the experiences and updates itself\"\"\"", "\n", "learner_model", "=", "Net", "(", "\n", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "action_space", ".", "n", ")", ".", "to", "(", "device", "=", "flags", ".", "device", ")", "\n", "\n", "optimizer", "=", "get_optimizer", "(", "flags", ",", "learner_model", ".", "parameters", "(", ")", ")", "\n", "if", "optimizer", "is", "None", ":", "\n", "# Use the default optimizer used in monobeast", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "\n", "learner_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "flags", ".", "learning_rate", ",", "\n", "momentum", "=", "flags", ".", "momentum", ",", "\n", "eps", "=", "flags", ".", "epsilon", ",", "\n", "alpha", "=", "flags", ".", "alpha", ",", "\n", "weight_decay", "=", "flags", ".", "weight_decay", "\n", ")", "\n", "\n", "", "try", ":", "\n", "        ", "from", "apex", ".", "fp16_utils", "import", "FP16_Optimizer", "\n", "", "except", ":", "\n", "        ", "print", "(", "'WARNING: apex not installed, ignoring --fp16 option'", ")", "\n", "flags", ".", "fp16", "=", "False", "\n", "\n", "", "if", "not", "flags", ".", "disable_cuda", "and", "flags", ".", "fp16", ":", "\n", "# If args.dynamic_loss_scale is False, static_loss_scale will be used.", "\n", "# If args.dynamic_loss_scale is True, it will take precedence over static_loss_scale.", "\n", "        ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "\n", "static_loss_scale", "=", "flags", ".", "static_loss_scale", ",", "\n", "dynamic_loss_scale", "=", "flags", ".", "dynamic_loss_scale", ",", "\n", "dynamic_loss_args", "=", "{", "'init_scale'", ":", "2", "**", "16", "}", ")", "\n", "\n", "", "def", "lr_lambda", "(", "epoch", ")", ":", "\n", "        ", "return", "1", "-", "min", "(", "epoch", "*", "T", "*", "B", ",", "flags", ".", "total_steps", ")", "/", "flags", ".", "total_steps", "\n", "\n", "", "scheduler", "=", "get_scheduler", "(", "flags", ",", "optimizer", ")", "\n", "if", "scheduler", "is", "None", ":", "\n", "# use the default scheduler as used in monobeast", "\n", "        ", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ")", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "\"logfile\"", ")", "\n", "stat_keys", "=", "[", "\n", "\"total_loss\"", ",", "\n", "\"mean_episode_return\"", ",", "\n", "\"pg_loss\"", ",", "\n", "\"baseline_loss\"", ",", "\n", "\"entropy_loss\"", ",", "\n", "]", "\n", "logger", ".", "info", "(", "\"# Step\\t%s\"", ",", "\"\\t\"", ".", "join", "(", "stat_keys", ")", ")", "\n", "\n", "step", ",", "stats", "=", "0", ",", "{", "}", "\n", "\n", "if", "flags", ".", "use_pretrained", ":", "\n", "        ", "logging", ".", "info", "(", "'Using Pretrained Model -> loading learner_model, optimizer, scheduler states'", ")", "\n", "learner_model", ".", "load_state_dict", "(", "pretrained_model", "[", "'model_state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "pretrained_model", "[", "'optimizer_state_dict'", "]", ")", "\n", "scheduler", ".", "load_state_dict", "(", "pretrained_model", "[", "'scheduler_state_dict'", "]", ")", "\n", "\n", "", "def", "batch_and_learn", "(", "i", ",", "lock", "=", "threading", ".", "Lock", "(", ")", ")", ":", "\n", "        ", "\"\"\"Thread target for the learning process.\"\"\"", "\n", "nonlocal", "step", ",", "stats", "\n", "timings", "=", "prof", ".", "Timings", "(", ")", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "timings", ".", "reset", "(", ")", "\n", "batch", ",", "agent_state", "=", "get_batch", "(", "\n", "flags", ",", "\n", "free_queue", ",", "\n", "full_queue", ",", "\n", "buffers", ",", "\n", "initial_agent_state_buffers", ",", "\n", "timings", ",", "\n", ")", "\n", "# print('Before Learn')", "\n", "stats", "=", "learn", "(", "\n", "flags", ",", "model", ",", "learner_model", ",", "batch", ",", "agent_state", ",", "optimizer", ",", "scheduler", "\n", ")", "\n", "# print('After Learn')", "\n", "timings", ".", "time", "(", "\"learn\"", ")", "\n", "with", "lock", ":", "\n", "# step-wise learning rate annealing", "\n", "# TODO : How to perform annealing here exactly, we dont have access to the train_step !", "\n", "                ", "if", "flags", ".", "scheduler", "in", "[", "'cosine'", ",", "'constant'", ",", "'dev_perf'", "]", ":", "\n", "# linear warmup stage", "\n", "                    ", "if", "step", "<", "flags", ".", "warmup_step", ":", "\n", "                        ", "curr_lr", "=", "flags", ".", "lr", "*", "step", "/", "flags", ".", "warmup_step", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "curr_lr", "\n", "", "else", ":", "\n", "                        ", "if", "flags", ".", "scheduler", "==", "'cosine'", ":", "\n", "                            ", "scheduler", ".", "step", "(", ")", "\n", "", "", "", "elif", "flags", ".", "scheduler", "==", "'inv_sqrt'", ":", "\n", "                    ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "to_log", "=", "dict", "(", "step", "=", "step", ")", "\n", "to_log", ".", "update", "(", "{", "k", ":", "stats", "[", "k", "]", "for", "k", "in", "stat_keys", "}", ")", "\n", "plogger", ".", "log", "(", "to_log", ")", "\n", "# print('updating step from {} to {}'.format(step, step+(T*B)))", "\n", "step", "+=", "T", "*", "B", "\n", "\n", "\n", "", "", "if", "i", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\"Batch and learn: %s\"", ",", "timings", ".", "summary", "(", ")", ")", "\n", "\n", "", "", "for", "m", "in", "range", "(", "flags", ".", "num_buffers", ")", ":", "\n", "        ", "free_queue", ".", "put", "(", "m", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "flags", ".", "num_learner_threads", ")", ":", "\n", "        ", "thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "batch_and_learn", ",", "name", "=", "\"batch-and-learn-%d\"", "%", "i", ",", "args", "=", "(", "i", ",", ")", "\n", ")", "\n", "thread", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "thread", ")", "\n", "\n", "", "def", "checkpoint", "(", ")", ":", "\n", "        ", "if", "flags", ".", "disable_checkpoint", ":", "\n", "            ", "return", "\n", "", "logging", ".", "info", "(", "\"Saving checkpoint to %s\"", ",", "checkpointpath", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"flags\"", ":", "vars", "(", "flags", ")", ",", "\n", "}", ",", "\n", "checkpointpath", ",", "\n", ")", "\n", "\n", "", "timer", "=", "timeit", ".", "default_timer", "\n", "try", ":", "\n", "        ", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "last_n_episode_returns", "=", "torch", ".", "zeros", "(", "(", "flags", ".", "stats_episodes", ")", ")", "\n", "curr_index", "=", "-", "1", "\n", "while", "step", "<", "flags", ".", "total_steps", ":", "\n", "            ", "start_step", "=", "step", "\n", "start_time", "=", "timer", "(", ")", "\n", "time", ".", "sleep", "(", "5", ")", "\n", "\n", "if", "timer", "(", ")", "-", "last_checkpoint_time", ">", "10", "*", "60", ":", "# Save every 10 min.", "\n", "                ", "checkpoint", "(", ")", "\n", "last_checkpoint_time", "=", "timer", "(", ")", "\n", "\n", "", "sps", "=", "(", "step", "-", "start_step", ")", "/", "(", "timer", "(", ")", "-", "start_time", ")", "\n", "episode_returns", "=", "stats", ".", "get", "(", "\"episode_returns\"", ",", "None", ")", "\n", "if", "episode_returns", ":", "\n", "                ", "mean_return", "=", "(", "\n", "\"Return per episode: %.1f. \"", "%", "stats", "[", "\"mean_episode_return\"", "]", "\n", ")", "\n", "#print(episode_returns)", "\n", "#print(type(episode_returns[0]))", "\n", "#torch.save(episode_returns, './ep_return.pt')", "\n", "for", "el", "in", "episode_returns", ":", "\n", "                    ", "last_n_episode_returns", "[", "(", "curr_index", "+", "1", ")", "%", "flags", ".", "stats_episodes", "]", "=", "el", ".", "item", "(", ")", "\n", "curr_index", "+=", "1", "\n", "", "", "else", ":", "\n", "                ", "mean_return", "=", "\"\"", "\n", "", "total_loss", "=", "stats", ".", "get", "(", "\"total_loss\"", ",", "float", "(", "\"inf\"", ")", ")", "\n", "# TODO : We also should save the model if the loss is the best loss seen so far", "\n", "# TODO : call checkpoint() here with some differen prefix", "\n", "# if not best_val_loss or val_loss < best_val_loss:", "\n", "#     if not args.debug:", "\n", "#         with open(os.path.join(args.work_dir, 'model.pt'), 'wb') as f:", "\n", "#             torch.save(model, f)", "\n", "#         with open(os.path.join(args.work_dir, 'optimizer.pt'), 'wb') as f:", "\n", "#             torch.save(optimizer.state_dict(), f)", "\n", "#     best_val_loss = val_loss", "\n", "\n", "logging", ".", "info", "(", "\n", "\"Steps %i @ %.1f SPS. Loss %f. Last %i episode returns %.2f %sStats:\\n%s\"", ",", "\n", "step", ",", "\n", "sps", ",", "\n", "total_loss", ",", "\n", "flags", ".", "stats_episodes", ",", "\n", "last_n_episode_returns", ".", "mean", "(", ")", ",", "\n", "mean_return", ",", "\n", "pprint", ".", "pformat", "(", "stats", ")", ",", "\n", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "return", "# Try joining actors then quit.", "\n", "", "else", ":", "\n", "        ", "for", "thread", "in", "threads", ":", "\n", "            ", "thread", ".", "join", "(", ")", "\n", "", "logging", ".", "info", "(", "\"Learning finished after %d steps.\"", ",", "step", ")", "\n", "", "finally", ":", "\n", "        ", "for", "_", "in", "range", "(", "flags", ".", "num_actors", ")", ":", "\n", "            ", "free_queue", ".", "put", "(", "None", ")", "\n", "", "for", "actor", "in", "actor_processes", ":", "\n", "            ", "actor", ".", "join", "(", "timeout", "=", "1", ")", "\n", "\n", "", "", "checkpoint", "(", ")", "\n", "plogger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.test": [[774, 810], ["monobeast_test.create_env", "Model.core.environment.Environment", "Net", "Net.eval", "torch.load", "Net.load_state_dict", "environment.Environment.initial", "environment.Environment.close", "logging.info", "os.path.expandvars", "len", "Net.", "environment.Environment.step", "observation[].item", "os.path.expanduser", "environment.Environment.gym_env.render", "returns.append", "logging.info", "sum", "len", "observation[].item", "observation[].item", "observation[].item"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.adaptive_span2.utils.Logger.load_state_dict", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.initial", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.environment.Environment.close", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "test", "(", "flags", ",", "num_episodes", ":", "int", "=", "10", ")", ":", "\n", "    ", "if", "flags", ".", "xpid", "is", "None", ":", "\n", "        ", "checkpointpath", "=", "\"./latest/model.tar\"", "\n", "", "else", ":", "\n", "        ", "checkpointpath", "=", "os", ".", "path", ".", "expandvars", "(", "\n", "os", ".", "path", ".", "expanduser", "(", "\"%s/%s/%s\"", "%", "(", "flags", ".", "savedir", ",", "flags", ".", "xpid", ",", "\"model.tar\"", ")", ")", "\n", ")", "\n", "\n", "", "gym_env", "=", "create_env", "(", "flags", ")", "\n", "env", "=", "environment", ".", "Environment", "(", "gym_env", ")", "\n", "model", "=", "Net", "(", "gym_env", ".", "observation_space", ".", "shape", ",", "gym_env", ".", "action_space", ".", "n", ")", "\n", "model", ".", "eval", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpointpath", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state_dict\"", "]", ")", "\n", "\n", "observation", "=", "env", ".", "initial", "(", ")", "\n", "returns", "=", "[", "]", "\n", "\n", "mems", "=", "None", "\n", "mem_padding", "=", "None", "\n", "while", "len", "(", "returns", ")", "<", "num_episodes", ":", "\n", "        ", "if", "flags", ".", "mode", "==", "\"test_render\"", ":", "\n", "            ", "env", ".", "gym_env", ".", "render", "(", ")", "\n", "\n", "", "agent_outputs", ",", "core_state", ",", "mems", ",", "mem_padding", ",", "ind_first_done", "=", "model", "(", "observation", ",", "mems", "=", "mems", ",", "mem_padding", "=", "mem_padding", ")", "\n", "observation", "=", "env", ".", "step", "(", "agent_outputs", "[", "\"action\"", "]", ")", "\n", "if", "observation", "[", "\"done\"", "]", ".", "item", "(", ")", ":", "\n", "            ", "returns", ".", "append", "(", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ")", "\n", "logging", ".", "info", "(", "\n", "\"Episode ended after %d steps. Return: %.1f\"", ",", "\n", "observation", "[", "\"episode_step\"", "]", ".", "item", "(", ")", ",", "\n", "observation", "[", "\"episode_return\"", "]", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"Average returns over %i steps: %.1f\"", ",", "num_episodes", ",", "sum", "(", "returns", ")", "/", "len", "(", "returns", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight": [[814, 819], ["torch.nn.init.normal_"], "function", ["None"], ["", "def", "init_weight", "(", "weight", ")", ":", "\n", "#if args.init == 'uniform':", "\n", "#    nn.init.uniform_(weight, -args.init_range, args.init_range)", "\n", "#elif args.init == 'normal':", "\n", "    ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "0.02", ")", "#args.init_std)", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_bias": [[820, 822], ["torch.nn.init.constant_"], "function", ["None"], ["", "def", "init_bias", "(", "bias", ")", ":", "\n", "    ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.weights_init": [[823, 862], ["classname.find", "hasattr", "monobeast_test.init_weight", "hasattr", "monobeast_test.init_bias", "classname.find", "hasattr", "range", "classname.find", "hasattr", "len", "monobeast_test.init_weight", "classname.find", "hasattr", "torch.nn.init.normal_", "hasattr", "monobeast_test.init_weight", "hasattr", "monobeast_test.init_bias", "range", "classname.find", "hasattr", "len", "torch.nn.init.normal_", "hasattr", "monobeast_test.init_bias", "classname.find", "hasattr", "hasattr", "hasattr", "hasattr", "torch.nn.init.normal_", "monobeast_test.init_weight", "monobeast_test.init_weight", "monobeast_test.init_weight", "monobeast_test.init_bias"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.init_weight", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias"], ["", "def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "            ", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'AdaptiveEmbedding'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'emb_projs'", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "0.01", ")", "#args.proj_init_std)", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'Embedding'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'ProjectedAdaptiveLogSoftmax'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'cluster_weight'", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "            ", "init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'cluster_bias'", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'out_projs'", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "0.01", ")", "#args.proj_init_std)", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'LayerNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "0.02", ")", "#args.init_std)", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'TransformerLM'", ")", "!=", "-", "1", ":", "\n", "# print('FOUND TRNASFORMER LM')", "\n", "        ", "if", "hasattr", "(", "m", ",", "'r_emb'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_w_bias'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_r_bias'", ")", ":", "\n", "            ", "init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_bias'", ")", ":", "\n", "            ", "init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.create_env": [[1043, 1050], ["Model.atari_wrappers.wrap_pytorch", "Model.atari_wrappers.wrap_deepmind", "Model.atari_wrappers.make_atari"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_pytorch", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.atari_wrappers.make_atari"], ["def", "create_env", "(", "flags", ")", ":", "\n", "    ", "return", "atari_wrappers", ".", "wrap_pytorch", "(", "\n", "atari_wrappers", ".", "wrap_deepmind", "(", "\n", "atari_wrappers", ".", "make_atari", "(", "flags", ".", "env", ")", ",", "\n", "clip_rewards", "=", "False", ",", "\n", "frame_stack", "=", "True", ",", "\n", "scale", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.main": [[1054, 1059], ["monobeast_test.train", "monobeast_test.test"], "function", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.train", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.Model.monobeast_test.test"], ["", "def", "main", "(", "flags", ")", ":", "\n", "    ", "if", "flags", ".", "mode", "==", "\"train\"", ":", "\n", "        ", "train", "(", "flags", ")", "\n", "", "else", ":", "\n", "        ", "test", "(", "flags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.GRUGate.__init__": [[51, 61], ["torch.nn.Module.__init__", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ")", ":", "\n", "#d_model is dimension of embedding for each token as input to layer (want to maintain this in the gate)", "\n", "        ", "super", "(", "GRUGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear_w_r", "=", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_u_r", "=", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_w_z", "=", "Linear", "(", "d_model", ",", "d_model", ")", "### Giving bias to this layer (will count as b_g so can just initialize negative)", "\n", "self", ".", "linear_u_z", "=", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_w_g", "=", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_u_g", "=", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.GRUGate.forward": [[62, 69], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "vanillaTransformer.GRUGate.linear_w_z", "vanillaTransformer.GRUGate.linear_u_z", "vanillaTransformer.GRUGate.linear_w_r", "vanillaTransformer.GRUGate.linear_u_r", "vanillaTransformer.GRUGate.linear_w_g", "vanillaTransformer.GRUGate.linear_u_g"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "### Here x,y follow from notation in paper", "\n", "\n", "        ", "z", "=", "F", ".", "sigmoid", "(", "self", ".", "linear_w_z", "(", "y", ")", "+", "self", ".", "linear_u_z", "(", "x", ")", ")", "#MAKE SURE THIS IS APPLIED ON PROPER AXIS", "\n", "r", "=", "F", ".", "sigmoid", "(", "self", ".", "linear_w_r", "(", "y", ")", "+", "self", ".", "linear_u_r", "(", "x", ")", ")", "\n", "h_hat", "=", "F", ".", "tanh", "(", "self", ".", "linear_w_g", "(", "y", ")", "+", "self", ".", "linear_u_g", "(", "r", "*", "x", ")", ")", "#Note elementwise multiplication of r and x", "\n", "return", "(", "1.", "-", "z", ")", "*", "x", "+", "z", "*", "h_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.StableTransformerLayer.__init__": [[72, 92], ["torch.nn.Module.__init__", "vanillaTransformer.GRUGate", "vanillaTransformer.GRUGate", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "nhead", ",", "dim_feedforward", "=", "2048", ",", "dropout", "=", "0.1", ",", "use_gate", "=", "False", ")", ":", "\n", "#fill in reordering of operations as done in https://arxiv.org/pdf/1910.06764.pdf", "\n", "#d_model: dimension of embedding for each input", "\n", "        ", "super", "(", "StableTransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "use_gate", "=", "use_gate", "\n", "self", ".", "gate_mha", "=", "GRUGate", "(", "d_model", ")", "\n", "self", ".", "gate_mlp", "=", "GRUGate", "(", "d_model", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "linear1", "=", "Linear", "(", "d_model", ",", "dim_feedforward", ")", "\n", "self", ".", "dropout", "=", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear2", "=", "Linear", "(", "dim_feedforward", ",", "d_model", ")", "\n", "\n", "self", ".", "norm1", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout1", "=", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "activation", "=", "F", ".", "relu", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.StableTransformerLayer.forward": [[93, 127], ["vanillaTransformer.StableTransformerLayer.norm1", "vanillaTransformer.StableTransformerLayer.norm2", "vanillaTransformer.StableTransformerLayer.linear2", "vanillaTransformer.StableTransformerLayer.self_attn", "vanillaTransformer.StableTransformerLayer.gate_mha", "vanillaTransformer.StableTransformerLayer.dropout", "vanillaTransformer.StableTransformerLayer.gate_mlp", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "vanillaTransformer.StableTransformerLayer.activation", "vanillaTransformer.StableTransformerLayer.dropout2", "vanillaTransformer.StableTransformerLayer.dropout2", "vanillaTransformer.StableTransformerLayer.dropout1", "vanillaTransformer.StableTransformerLayer.dropout1", "vanillaTransformer.StableTransformerLayer.linear1", "torch.relu", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "src_mask", "=", "None", ",", "src_key_padding_mask", "=", "None", ")", ":", "\n", "\n", "        ", "'''\n        #ORIGINAL TRANSFORMER ORDERING\n        src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n                              key_padding_mask=src_key_padding_mask)[0]\n        src = src + self.dropout1(src2)\n        src = self.norm1(src)\n        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n        src = src + self.dropout2(src2)\n        src = self.norm2(src)\n        '''", "\n", "\n", "#HOW SHOULD THE DROPOUT BE APPLIED, it seems like dropout is completely missing the original source that residually connects?", "\n", "#This doesn't perfectly correspond to dropout used in TransformerXL I believe. (to do: read their code)", "\n", "\n", "\n", "src2", "=", "self", ".", "norm1", "(", "src", ")", "\n", "src2", "=", "self", ".", "self_attn", "(", "src2", ",", "src2", ",", "src2", ",", "attn_mask", "=", "src_mask", ",", "\n", "key_padding_mask", "=", "src_key_padding_mask", ")", "[", "0", "]", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "src2", "=", "self", ".", "gate_mha", "(", "src", ",", "F", ".", "relu", "(", "self", ".", "dropout1", "(", "src2", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "src2", "=", "src", "+", "F", ".", "relu", "(", "self", ".", "dropout1", "(", "src2", ")", ")", "\n", "\n", "", "src3", "=", "self", ".", "norm2", "(", "src2", ")", "\n", "src3", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "src3", ")", ")", ")", ")", "\n", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "src3", "=", "self", ".", "gate_mlp", "(", "src2", ",", "self", ".", "dropout2", "(", "F", ".", "relu", "(", "src3", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "src3", "=", "self", ".", "dropout2", "(", "F", ".", "relu", "(", "src3", ")", ")", "+", "src2", "\n", "\n", "", "return", "src3", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.StableTransformerEncoder.__init__": [[135, 152], ["torch.nn.Module.__init__", "vanillaTransformer.PositionalEncoding", "torch.nn.modules.TransformerEncoderLayer", "torch.nn.modules.TransformerEncoderLayer", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.TransformerEncoder", "torch.nn.modules.TransformerEncoder", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "Transformer", "embedding_layer", "vanillaTransformer.StableTransformerEncoder._reset_parameters"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.StableTransformerEncoder._reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "nhead", ",", "num_encoder_layers", ",", "num_decoder_layers", ",", "\n", "dim_feedforward", ",", "dropout", ",", "activation", ",", "embedding_layer", ")", ":", "\n", "        ", "super", "(", "TransformerModelEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pos_encoder", "=", "PositionalEncoding", "(", "d_model", "=", "d_model", ",", "dropout", "=", "0.1", ")", "# , max_len=100)", "\n", "encoder_layer", "=", "TransformerEncoderLayer", "(", "d_model", ",", "nhead", ",", "dim_feedforward", ",", "dropout", ",", "activation", ")", "\n", "encoder_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "encoder", "=", "TransformerEncoder", "(", "encoder_layer", ",", "num_encoder_layers", ",", "encoder_norm", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "nhead", "=", "nhead", "\n", "self", ".", "linear", "=", "Linear", "(", "d_model", ",", "tgt_vocab_size", ")", "\n", "self", ".", "transformer", "=", "Transformer", "(", "d_model", "=", "d_model", ",", "nhead", "=", "nhead", ",", "num_encoder_layers", "=", "num_encoder_layers", ",", "\n", "num_decoder_layers", "=", "num_decoder_layers", ",", "dim_feedforward", "=", "dim_feedforward", ",", "\n", "dropout", "=", "dropout", ",", "activation", "=", "activation", ")", "\n", "\n", "self", ".", "encoder_embedding", "=", "embedding_layer", "(", "d_model", ")", "#nn.Embedding(src_vocab_size, d_model)", "\n", "self", ".", "_reset_parameters", "(", ")", "# initialize all the parameters randomly", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.StableTransformerEncoder._reset_parameters": [[153, 158], ["vanillaTransformer.StableTransformerEncoder.parameters", "p.dim", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["None"], ["", "def", "_reset_parameters", "(", "self", ")", ":", "\n", "# Initiate parameters in the transformer model.", "\n", "        ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "xavier_uniform_", "(", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.StableTransformerEncoder.change_to_value_net": [[159, 162], ["torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.init.xavier_uniform", "torch.nn.init.xavier_uniform", "torch.nn.init.xavier_uniform", "torch.nn.init.xavier_uniform"], "methods", ["None"], ["", "", "", "def", "change_to_value_net", "(", "self", ")", ":", "\n", "        ", "self", ".", "linear", "=", "Linear", "(", "self", ".", "d_model", ",", "1", ")", "# now doing regression", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "linear", ".", "weight", ")", "# initialize new weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.StableTransformerEncoder.forward": [[172, 196], ["vanillaTransformer.StableTransformerEncoder.pos_encoder", "vanillaTransformer.StableTransformerEncoder.decoder", "vanillaTransformer.StableTransformerEncoder.linear", "vanillaTransformer.StableTransformerEncoder.pos_encoder().double", "vanillaTransformer.StableTransformerEncoder.encoder", "vanillaTransformer.StableTransformerEncoder.decoder_embedding().double", "math.sqrt", "vanillaTransformer.StableTransformerEncoder.encoder_embedding().double", "math.sqrt", "vanillaTransformer.StableTransformerEncoder.pos_encoder", "vanillaTransformer.StableTransformerEncoder.decoder_embedding", "vanillaTransformer.StableTransformerEncoder.encoder_embedding"], "methods", ["None"], ["def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "src_key_padding_mask", "=", "None", ",", "tgt_mask", "=", "None", ",", "tgt_key_padding_mask", "=", "None", ",", "\n", "memory_key_padding_mask", "=", "None", ",", "memory", "=", "None", ",", "only_return_last_col", "=", "False", ")", ":", "\n", "\n", "        ", "'''\n        First embed src and tgt, then add positional encoding, then run encoder,\n        then decoder.\n        '''", "\n", "if", "memory", "is", "None", ":", "\n", "# here we reuse encoder output from previous decoding step", "\n", "            ", "memory", "=", "self", ".", "encoder_embedding", "(", "src", ")", ".", "double", "(", ")", "*", "math", ".", "sqrt", "(", "self", ".", "d_model", ")", "\n", "memory", "=", "self", ".", "pos_encoder", "(", "memory", ")", ".", "double", "(", ")", "\n", "memory", "=", "self", ".", "encoder", "(", "memory", ",", "src_key_padding_mask", "=", "src_key_padding_mask", ")", "\n", "\n", "", "tgt2", "=", "self", ".", "decoder_embedding", "(", "tgt", ")", ".", "double", "(", ")", "*", "math", ".", "sqrt", "(", "self", ".", "d_model", ")", "\n", "tgt2", "=", "self", ".", "pos_encoder", "(", "tgt2", ")", "\n", "\n", "output", "=", "self", ".", "decoder", "(", "tgt2", ",", "memory", ",", "tgt_mask", "=", "tgt_mask", ",", "\n", "tgt_key_padding_mask", "=", "tgt_key_padding_mask", ",", "\n", "memory_key_padding_mask", "=", "memory_key_padding_mask", ")", "\n", "\n", "# linear layer increases embedding dimension to size of vocab (then can feed through softmax)", "\n", "# If value_net, then linear layer will reduce embedding dim to size 1 since just regression", "\n", "output", "=", "self", ".", "linear", "(", "output", ")", "# The cross entropy loss will take in the unnormalized outputs", "\n", "return", "output", ",", "memory", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.PositionalEncoding.__init__": [[208, 219], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "vanillaTransformer.PositionalEncoding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().double", "torch.arange().double", "torch.arange().double", "torch.arange().double", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.core.file_writer.FileWriter.log"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "dropout", "=", "0.1", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "dtype", "=", "torch", ".", "float64", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ")", ".", "double", "(", ")", "*", "(", "-", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.PositionalEncoding.forward": [[220, 223], ["vanillaTransformer.PositionalEncoding.dropout", "torch.autograd.Variable", "torch.autograd.Variable", "vanillaTransformer.PositionalEncoding.pe.transpose", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "Variable", "(", "self", ".", "pe", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", "x", ".", "size", "(", "0", ")", ",", ":", "]", ",", "requires_grad", "=", "False", ")", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.__init__": [[230, 237], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_size", ",", "factor", ",", "warmup", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "warmup", "=", "warmup", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "model_size", "=", "model_size", "\n", "self", ".", "_rate", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step": [[238, 246], ["vanillaTransformer.NoamOpt.rate", "vanillaTransformer.NoamOpt.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.rate", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Update parameters and rate\"", "\n", "self", ".", "_step", "+=", "1", "\n", "rate", "=", "self", ".", "rate", "(", ")", "\n", "for", "p", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "p", "[", "'lr'", "]", "=", "rate", "\n", "", "self", ".", "_rate", "=", "rate", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.NoamOpt.rate": [[247, 254], ["min"], "methods", ["None"], ["", "def", "rate", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"Implement `lrate` above\"", "\n", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "", "return", "self", ".", "factor", "*", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "self", ".", "warmup", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.generate_square_subsequent_mask": [[198, 204], ["mask.float().masked_fill().masked_fill.float().masked_fill().masked_fill", "float", "mask.float().masked_fill().masked_fill.float().masked_fill", "float", "mask.float().masked_fill().masked_fill.float", "torch.triu", "torch.triu", "torch.ones", "torch.ones"], "function", ["None"], ["", "", "def", "generate_square_subsequent_mask", "(", "sz", ")", ":", "\n", "# Generate a square mask for the sequence. The masked positions are filled with float('-inf').", "\n", "# Unmasked positions are filled with float(0.0).", "\n", "    ", "mask", "=", "(", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "sz", ",", "sz", ")", ")", "==", "1", ")", ".", "float", "(", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "mask", "=", "mask", ".", "float", "(", ")", ".", "masked_fill", "(", "mask", "==", "0", ",", "float", "(", "'-inf'", ")", ")", ".", "masked_fill", "(", "mask", "==", "1", ",", "float", "(", "0.0", ")", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.vanillaTransformer.get_std_opt": [[256, 259], ["vanillaTransformer.NoamOpt", "torch.optim.Adam", "torch.optim.Adam", "model.parameters"], "function", ["None"], ["", "", "def", "get_std_opt", "(", "model", ")", ":", "\n", "    ", "return", "NoamOpt", "(", "model", ".", "d_model", ",", "1", ",", "4000", ",", "\n", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "5e-4", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-9", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.PositionalEmbedding.__init__": [[36, 43], ["torch.Module.__init__", "transformer_xl.PositionalEmbedding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ")", ":", "\n", "        ", "super", "(", "PositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "demb", "=", "demb", "\n", "\n", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "torch", ".", "arange", "(", "0.0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "self", ".", "register_buffer", "(", "'inv_freq'", ",", "inv_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.PositionalEmbedding.forward": [[44, 52], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_emb[].expand", "torch.ger.sin", "torch.ger.sin", "torch.ger.sin", "torch.ger.cos", "torch.ger.cos", "torch.ger.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "ger", "(", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "sinusoid_inp", ".", "sin", "(", ")", ",", "sinusoid_inp", ".", "cos", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.__init__": [[61, 74], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "transformer_xl.GRUGate.init_bias"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ")", ":", "\n", "#d_model is dimension of embedding for each token as input to layer (want to maintain this in the gate)", "\n", "        ", "super", "(", "GRUGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# TODO: DEBUG Make sure intitialize bias of linear_w_z to -3", "\n", "self", ".", "linear_w_r", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_u_r", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_w_z", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ")", "### Giving bias to this layer (will count as b_g so can just initialize negative)", "\n", "self", ".", "linear_u_z", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_w_g", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_u_g", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_bias", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias": [[75, 78], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "transformer_xl.GRUGate.linear_w_z.bias.fill_"], "methods", ["None"], ["", "def", "init_bias", "(", "self", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "linear_w_z", ".", "bias", ".", "fill_", "(", "-", "2", ")", "# Manually setting this bias to allow starting with markov process", "\n", "# Note -2 is the setting used in the paper stable transformers", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.forward": [[80, 87], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "transformer_xl.GRUGate.linear_w_z", "transformer_xl.GRUGate.linear_u_z", "transformer_xl.GRUGate.linear_w_r", "transformer_xl.GRUGate.linear_u_r", "transformer_xl.GRUGate.linear_w_g", "transformer_xl.GRUGate.linear_u_g"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "### Here x,y follow from notation in paper", "\n", "# TODO: DEBUG MAKE SURE THIS IS APPLIED ON PROPER AXIS", "\n", "        ", "z", "=", "torch", ".", "sigmoid", "(", "self", ".", "linear_w_z", "(", "y", ")", "+", "self", ".", "linear_u_z", "(", "x", ")", ")", "#MAKE SURE THIS IS APPLIED ON PROPER AXIS", "\n", "r", "=", "torch", ".", "sigmoid", "(", "self", ".", "linear_w_r", "(", "y", ")", "+", "self", ".", "linear_u_r", "(", "x", ")", ")", "\n", "h_hat", "=", "torch", ".", "tanh", "(", "self", ".", "linear_w_g", "(", "y", ")", "+", "self", ".", "linear_u_g", "(", "r", "*", "x", ")", ")", "#Note elementwise multiplication of r and x", "\n", "return", "(", "1.", "-", "z", ")", "*", "x", "+", "z", "*", "h_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.PositionwiseFF.__init__": [[90, 102], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "PositionwiseFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "CoreNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "d_model", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.PositionwiseFF.forward": [[106, 112], ["transformer_xl.PositionwiseFF.CoreNet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "\n", "##### positionwise feed-forward (this is what's used in original transformer)", "\n", "        ", "core_out", "=", "self", ".", "CoreNet", "(", "inp", ")", "\n", "\n", "return", "core_out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.__init__": [[115, 134], ["torch.Module.__init__", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "torch.nn.modules.normalization.LayerNorm", "transformer_xl.RelPartialLearnableMultiHeadAttn", "transformer_xl.PositionwiseFF", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "transformer_xl.GRUGate", "transformer_xl.GRUGate"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "use_gate", ",", "use_stable_version", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "use_gate", "=", "use_gate", "\n", "self", ".", "use_stable_version", "=", "use_stable_version", "\n", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "self", ".", "gate_mha", "=", "GRUGate", "(", "d_model", ")", "\n", "self", ".", "gate_mlp", "=", "GRUGate", "(", "d_model", ")", "\n", "\n", "", "self", ".", "norm1", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelPartialLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "\n", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ")", "\n", "self", ".", "layer_norm1", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "layer_norm2", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward_orig": [[135, 144], ["transformer_xl.RelPartialLearnableDecoderLayer.dec_attn", "transformer_xl.RelPartialLearnableDecoderLayer.layer_norm1", "transformer_xl.RelPartialLearnableDecoderLayer.pos_ff", "transformer_xl.RelPartialLearnableDecoderLayer.layer_norm2"], "methods", ["None"], ["", "def", "forward_orig", "(", "self", ",", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "layer_norm1", "(", "dec_inp", "+", "output", ")", "\n", "output2", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "output2", "=", "self", ".", "layer_norm2", "(", "output", "+", "output2", ")", "\n", "return", "output2", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward_stable": [[146, 172], ["transformer_xl.RelPartialLearnableDecoderLayer.dec_attn", "transformer_xl.RelPartialLearnableDecoderLayer.layer_norm2", "transformer_xl.RelPartialLearnableDecoderLayer.pos_ff", "transformer_xl.RelPartialLearnableDecoderLayer.gate_mha", "transformer_xl.RelPartialLearnableDecoderLayer.gate_mlp", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "def", "forward_stable", "(", "self", ",", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "#Layer norm will be applied at start of MHA module on both dec_inp2 and mems", "\n", "#dec_inp2 = self.layer_norm1(dec_inp)", "\n", "#First Layer norm will be applied within dec_attn", "\n", "\n", "        ", "dec_inp2", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ",", "use_stable_version", "=", "self", ".", "use_stable_version", ")", "\n", "\n", "#NOTE: In stable transformer they apply Relu before the layernorm/gate (in appendix C.3)", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "dec_inp2", "=", "self", ".", "gate_mha", "(", "dec_inp", ",", "F", ".", "relu", "(", "dec_inp2", ")", ")", "\n", "", "else", ":", "\n", "            ", "dec_inp2", "=", "dec_inp", "+", "F", ".", "relu", "(", "dec_inp2", ")", "\n", "\n", "", "dec_inp3", "=", "self", ".", "layer_norm2", "(", "dec_inp2", ")", "\n", "\n", "dec_inp3", "=", "self", ".", "pos_ff", "(", "dec_inp3", ")", "\n", "\n", "if", "self", ".", "use_gate", ":", "\n", "            ", "dec_inp3", "=", "self", ".", "gate_mlp", "(", "dec_inp2", ",", "F", ".", "relu", "(", "dec_inp3", ")", ")", "\n", "", "else", ":", "\n", "            ", "dec_inp3", "=", "F", ".", "relu", "(", "dec_inp3", ")", "+", "dec_inp2", "\n", "\n", "", "return", "dec_inp3", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward": [[174, 180], ["transformer_xl.RelPartialLearnableDecoderLayer.forward_orig", "transformer_xl.RelPartialLearnableDecoderLayer.forward_stable"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward_orig", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableDecoderLayer.forward_stable"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "if", "self", ".", "use_stable_version", ":", "\n", "            ", "return", "self", ".", "forward_stable", "(", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", ",", "mems", ")", "\n", "\n", "", "return", "self", ".", "forward_orig", "(", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", ",", "mems", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelMultiHeadAttn.__init__": [[185, 207], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "None", ",", "pre_lnorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "RelMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "#Get query, key and value for each token (NOTE SOME Inefficiency since", "\n", "#don't need query for any of the memory. Parallelization must make up for it", "\n", "self", ".", "qkv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "3", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelMultiHeadAttn._parallelogram_mask": [[208, 222], ["torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "torch.ones().bool", "min", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones().bool.flip", "torch.ones().bool.flip", "torch.ones().bool.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "_parallelogram_mask", "(", "self", ",", "h", ",", "w", ",", "left", "=", "False", ")", ":", "\n", "# UserWarning: masked_fill_ received a mask with dtype torch.uint8,", "\n", "# this behavior is now deprecated,please use a mask with dtype torch.bool instead.", "\n", "# changed .byte() to .bool()", "\n", "# mask = torch.ones((h, w)).byte()", "\n", "        ", "mask", "=", "torch", ".", "ones", "(", "(", "h", ",", "w", ")", ")", ".", "bool", "(", ")", "\n", "m", "=", "min", "(", "h", ",", "w", ")", "\n", "mask", "[", ":", "m", ",", ":", "m", "]", "=", "torch", ".", "triu", "(", "mask", "[", ":", "m", ",", ":", "m", "]", ")", "\n", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", "=", "torch", ".", "tril", "(", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", ")", "\n", "\n", "if", "left", ":", "\n", "            ", "return", "mask", "\n", "", "else", ":", "\n", "            ", "return", "mask", ".", "flip", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelMultiHeadAttn._shift": [[223, 240], ["torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mask.flip.flip.flip", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "_shift", "(", "self", ",", "x", ",", "qlen", ",", "klen", ",", "mask", ",", "left", "=", "False", ")", ":", "\n", "        ", "if", "qlen", ">", "1", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "qlen", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "0", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n", "", "if", "left", ":", "\n", "            ", "mask", "=", "mask", ".", "flip", "(", "1", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_padded", "=", "torch", ".", "cat", "(", "[", "x", ",", "zero_pad", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "x", "=", "x_padded", ".", "masked_select", "(", "mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ".", "view", "(", "qlen", ",", "klen", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelMultiHeadAttn._rel_shift": [[241, 255], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_padded.view.view.view", "x_padded[].view_as", "x_padded[].view_as.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size"], "methods", ["None"], ["", "def", "_rel_shift", "(", "self", ",", "x", ",", "zero_triu", "=", "False", ")", ":", "\n", "        ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "*", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "x", ".", "size", "(", "1", ")", "+", "1", ",", "x", ".", "size", "(", "0", ")", ",", "*", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "\n", "x", "=", "x_padded", "[", "1", ":", "]", ".", "view_as", "(", "x", ")", "\n", "\n", "if", "zero_triu", ":", "\n", "            ", "ones", "=", "torch", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", ")", "\n", "x", "=", "x", "*", "torch", ".", "tril", "(", "ones", ",", "x", ".", "size", "(", "1", ")", "-", "x", ".", "size", "(", "0", ")", ")", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelMultiHeadAttn.forward": [[256, 258], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableMultiHeadAttn.__init__": [[263, 267], ["transformer_xl.RelMultiHeadAttn.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "r_net", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelPartialLearnableMultiHeadAttn.forward": [[268, 339], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "transformer_xl.RelPartialLearnableMultiHeadAttn.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "transformer_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "transformer_xl.RelPartialLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "transformer_xl.RelPartialLearnableMultiHeadAttn.o_net", "transformer_xl.RelPartialLearnableMultiHeadAttn.drop", "w.size", "r.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "transformer_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "transformer_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "transformer_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "transformer_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "transformer_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_vec.contiguous().view.contiguous().view.contiguous", "transformer_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "transformer_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "attn_mask.any", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "float"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.RelMultiHeadAttn._rel_shift"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ",", "use_stable_version", "=", "False", ")", ":", "\n", "        ", "qlen", ",", "rlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "r", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "#if using stable version, then want layernorm of memory as well before MHA", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "\n", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "if", "not", "use_stable_version", "else", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "if", "not", "use_stable_version", "else", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "r_head_k", ".", "view", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x n_head x d_head", "\n", "\n", "#### compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "r_r_bias", "\n", "BD", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "rr_head_q", ",", "r_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "#THIS IS WHAT IS Usually executed", "\n", "#print('Attentionscore shape: ',attn_score.shape)", "\n", "#print('MASK SHAPE: ', attn_mask[:,:,:,None].shape)", "\n", "#print('MASK EL 1: ', attn_mask[:,:,0])", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", ".", "type_as", "(", "attn_score", ")", "\n", "\n", "#print('ATTENTION SCORE: ', attn_score)", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "#### compute attention vector", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "##### residual connection + layer normalization", "\n", "#output = self.layer_norm(w + attn_out)", "\n", "\n", "return", "attn_out", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__": [[343, 387], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "transformer_xl.MemTransformerLM._create_params", "transformer_xl.MemTransformerLM.layers.append", "transformer_xl.RelPartialLearnableDecoderLayer"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.__init__", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._create_params"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "n_layer", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "\n", "dropout", ",", "dropatt", ",", "tie_weight", "=", "True", ",", "d_embed", "=", "None", ",", "\n", "div_val", "=", "1", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "0", ",", "mem_len", "=", "1", ",", "\n", "cutoffs", "=", "[", "]", ",", "adapt_inp", "=", "False", ",", "\n", "same_length", "=", "False", ",", "clamp_len", "=", "-", "1", ",", "\n", "use_gate", "=", "True", ",", "use_stable_version", "=", "True", ")", ":", "\n", "        ", "super", "(", "MemTransformerLM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_token", "=", "n_token", "# TODO : Check this is not being used anywhere", "\n", "\n", "self", ".", "d_embed", "=", "d_model", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_head", "=", "d_head", "\n", "\n", "# self.state_emb = State_Embedder()", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "#self.max_klen = tgt_len + ext_len + mem_len", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_layer", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "RelPartialLearnableDecoderLayer", "(", "\n", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "use_stable_version", "=", "use_stable_version", ",", "use_gate", "=", "use_gate", ",", "\n", "tgt_len", "=", "tgt_len", ",", "ext_len", "=", "ext_len", ",", "mem_len", "=", "mem_len", ",", "\n", "dropatt", "=", "dropatt", ")", "\n", ")", "\n", "\n", "#To do: Look into sample softmax and adaptive softmax for future, not relevant here though", "\n", "# are useful when need fast softmax over many classes", "\n", "\n", "", "self", ".", "same_length", "=", "same_length", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "\n", "self", ".", "_create_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.init_gru_bias": [[388, 392], ["l.gate_mha.init_bias", "l.gate_mlp.init_bias"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.GRUGate.init_bias"], ["", "def", "init_gru_bias", "(", "self", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "layers", ":", "\n", "            ", "l", ".", "gate_mha", ".", "init_bias", "(", ")", "\n", "l", ".", "gate_mlp", ".", "init_bias", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.backward_compatible": [[393, 395], ["None"], "methods", ["None"], ["", "", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._create_params": [[396, 400], ["transformer_xl.PositionalEmbedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "_create_params", "(", "self", ")", ":", "\n", "        ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.reset_length": [[401, 405], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.init_mems": [[406, 417], ["next", "range", "transformer_xl.MemTransformerLM.parameters", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "mems.append"], "methods", ["None"], ["", "def", "init_mems", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", "+", "1", ")", ":", "\n", "                ", "empty", "=", "torch", ".", "empty", "(", "0", ",", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._update_mems": [[420, 450], ["len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "range", "max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_mems.append", "cat[].detach"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "return", "None", "\n", "\n", "# mems is not None", "\n", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "'len(hids) != len(mems)'", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "# ext_len looks to usually be 0 (in their experiments anyways", "\n", "\n", "# TODO: I have changed beg_idx to 0 since want to use all memory, may want to change", "\n", "#       this once move to larger environments (THIS HAS NOW BEEN CHANGED)", "\n", "\n", "#HERE IS THE PROBLEM.", "\n", "#print('hids shape: ', hids[0].shape)", "\n", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "#if hids[0].shape[0] > 1 else 0", "\n", "#print('BEG IND: ', beg_idx)", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "dim", "=", "0", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ".", "detach", "(", ")", ")", "\n", "\n", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._forward": [[455, 501], ["obs_emb.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "transformer_xl.MemTransformerLM.pos_emb", "transformer_xl.MemTransformerLM.drop", "transformer_xl.MemTransformerLM.drop", "hids.append", "enumerate", "transformer_xl.MemTransformerLM.drop", "transformer_xl.MemTransformerLM._update_mems", "mems[].size", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.triu().bool", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "layer", "hids.append", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "obs_emb.new_ones"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._update_mems"], ["", "def", "_forward", "(", "self", ",", "obs_emb", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "qlen", ",", "bsz", ",", "_", "=", "obs_emb", ".", "size", "(", ")", "#qlen is number of characters in input ex", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "# print('HERE: mlen: {}, len mems: {}, mems[0] shape: {}'.format(mlen, len(mems),mems[0].shape))", "\n", "", "else", ":", "\n", "            ", "mlen", "=", "0", "\n", "# mlen = mems[0].size(0) if mems is not None else 0", "\n", "\n", "", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "# create the mask taking in consideration the mlen as well. All memory should be attended by the first query", "\n", "dec_attn_mask", "=", "torch", ".", "triu", "(", "\n", "obs_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", ",", "diagonal", "=", "1", "+", "mlen", ")", ".", "bool", "(", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "hids", "=", "[", "]", "\n", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "obs_emb", ".", "device", ",", "\n", "dtype", "=", "obs_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "            ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "obs_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "hids", ".", "append", "(", "core_out", ")", "\n", "#SEEMS THAT THEY store memory per layer which makes sense to attend to (for ex if at first layer, if we were", "\n", "#applying attention to memory and this new data, this would give us the same result.", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "#print('HIDDEN iter: {}, output: {}'.format(i, core_out[-1,0, :10]))", "\n", "\n", "# TODO : The memory should be the same hidden layer's state of the previous T timesteps", "\n", "            ", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "# print('from txl483 shapes : ', core_out.shape, pos_emb.shape, self.r_w_bias.shape, self.r_r_bias.shape, dec_attn_mask.shape, mems_i.shape)", "\n", "core_out", "=", "layer", "(", "core_out", ",", "pos_emb", ",", "self", ".", "r_w_bias", ",", "\n", "self", ".", "r_r_bias", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ")", "\n", "hids", ".", "append", "(", "core_out", ")", "\n", "\n", "\n", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "#print('before update mems hids shape: {}, mems shape {}'.format(hids[0].shape,mems[0].shape if mems else None))", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "return", "core_out", ",", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.forward": [[503, 512], ["transformer_xl.MemTransformerLM._forward", "transformer_xl.MemTransformerLM.init_mems"], "methods", ["home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM._forward", "home.repos.pwc.inspect_result.jerrodparker20_adaptive-transformers-in-rl.StableTransformersReplication.transformer_xl.MemTransformerLM.init_mems"], ["", "def", "forward", "(", "self", ",", "data", ",", "mems", ")", ":", "\n", "\n", "        ", "if", "not", "mems", ":", "\n", "# print('INITIALIZED MEMS')", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", ")", "\n", "\n", "", "hidden", ",", "new_mems", "=", "self", ".", "_forward", "(", "data", ",", "mems", "=", "mems", ")", "\n", "\n", "return", "hidden", ",", "new_mems", "\n", "\n"]]}