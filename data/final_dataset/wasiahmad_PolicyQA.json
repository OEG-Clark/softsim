{"home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.set_seed": [[62, 68], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.to_list": [[70, 72], ["tensor.detach().cpu().tolist", "tensor.detach().cpu", "tensor.detach"], "function", ["None"], ["", "", "def", "to_list", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.train": [[74, 268], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.exists", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_squad.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "[].split", "logger.info", "inputs.update", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "len", "len", "t.to", "inputs.update", "hasattr", "hasattr", "inputs.update", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_squad.evaluate", "evaluate.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "args.model_name_or_path.split", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr", "torch.ones"], "function", ["home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.set_seed", "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.train", "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "1", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "# Added here for reproductibility", "\n", "set_seed", "(", "args", ")", "\n", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ",", "\n", "\"start_positions\"", ":", "batch", "[", "3", "]", ",", "\n", "\"end_positions\"", ":", "batch", "[", "4", "]", ",", "\n", "}", "\n", "\n", "if", "args", ".", "model_type", "in", "[", "\"xlm\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", ",", "\"bart\"", "]", ":", "\n", "                ", "del", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "                ", "inputs", ".", "update", "(", "{", "\"cls_index\"", ":", "batch", "[", "5", "]", ",", "\"p_mask\"", ":", "batch", "[", "6", "]", "}", ")", "\n", "if", "args", ".", "version_2_with_negative", ":", "\n", "                    ", "inputs", ".", "update", "(", "{", "\"is_impossible\"", ":", "batch", "[", "7", "]", "}", ")", "\n", "", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "and", "hasattr", "(", "model", ".", "config", ",", "\"lang2id\"", ")", ":", "\n", "                    ", "inputs", ".", "update", "(", "\n", "{", "\"langs\"", ":", "(", "torch", ".", "ones", "(", "batch", "[", "0", "]", ".", "shape", ",", "dtype", "=", "torch", ".", "int64", ")", "*", "args", ".", "lang_id", ")", ".", "to", "(", "args", ".", "device", ")", "}", "\n", ")", "\n", "\n", "", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# model outputs are always tuple in transformers (see doc)", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel (not distributed) training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "# Log metrics", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "# Save model checkpoint", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                      ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "# Take care of distributed/parallel training", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.evaluate": [[270, 402], ["run_squad.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "timeit.default_timer", "tqdm.tqdm", "logger.info", "os.path.join", "os.path.join", "transformers.data.metrics.squad_metrics.squad_evaluate", "os.makedirs", "max", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "enumerate", "timeit.default_timer", "os.path.join", "transformers.data.metrics.squad_metrics.compute_predictions_log_probs", "transformers.data.metrics.squad_metrics.compute_predictions_logits", "os.path.exists", "isinstance", "torch.no_grad", "torch.nn.DataParallel.", "int", "all_results.append", "len", "hasattr", "hasattr", "t.to", "inputs.update", "run_squad.to_list", "len", "transformers.data.processors.squad.SquadResult", "transformers.data.processors.squad.SquadResult", "hasattr", "hasattr", "inputs.update", "feature_index.item", "torch.ones"], "function", ["home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.load_and_cache_examples", "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.to_list"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "dataset", ",", "examples", ",", "features", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ",", "output_examples", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "all_results", "=", "[", "]", "\n", "start_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ",", "\n", "}", "\n", "\n", "if", "args", ".", "model_type", "in", "[", "\"xlm\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", ",", "\"bart\"", "]", ":", "\n", "                ", "del", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "", "feature_indices", "=", "batch", "[", "3", "]", "\n", "\n", "# XLNet and XLM use more arguments for their predictions", "\n", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "                ", "inputs", ".", "update", "(", "{", "\"cls_index\"", ":", "batch", "[", "4", "]", ",", "\"p_mask\"", ":", "batch", "[", "5", "]", "}", ")", "\n", "# for lang_id-sensitive xlm models", "\n", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "and", "hasattr", "(", "model", ".", "config", ",", "\"lang2id\"", ")", ":", "\n", "                    ", "inputs", ".", "update", "(", "\n", "{", "\"langs\"", ":", "(", "torch", ".", "ones", "(", "batch", "[", "0", "]", ".", "shape", ",", "dtype", "=", "torch", ".", "int64", ")", "*", "args", ".", "lang_id", ")", ".", "to", "(", "args", ".", "device", ")", "}", "\n", ")", "\n", "", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "", "for", "i", ",", "feature_index", "in", "enumerate", "(", "feature_indices", ")", ":", "\n", "            ", "eval_feature", "=", "features", "[", "feature_index", ".", "item", "(", ")", "]", "\n", "unique_id", "=", "int", "(", "eval_feature", ".", "unique_id", ")", "\n", "\n", "output", "=", "[", "to_list", "(", "output", "[", "i", "]", ")", "for", "output", "in", "outputs", "]", "\n", "\n", "# Some models (XLNet, XLM) use 5 arguments for their predictions, while the other \"simpler\"", "\n", "# models only use two.", "\n", "if", "len", "(", "output", ")", ">=", "5", ":", "\n", "                ", "start_logits", "=", "output", "[", "0", "]", "\n", "start_top_index", "=", "output", "[", "1", "]", "\n", "end_logits", "=", "output", "[", "2", "]", "\n", "end_top_index", "=", "output", "[", "3", "]", "\n", "cls_logits", "=", "output", "[", "4", "]", "\n", "\n", "result", "=", "SquadResult", "(", "\n", "unique_id", ",", "\n", "start_logits", ",", "\n", "end_logits", ",", "\n", "start_top_index", "=", "start_top_index", ",", "\n", "end_top_index", "=", "end_top_index", ",", "\n", "cls_logits", "=", "cls_logits", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "start_logits", ",", "end_logits", "=", "output", "\n", "result", "=", "SquadResult", "(", "unique_id", ",", "start_logits", ",", "end_logits", ")", "\n", "\n", "", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "evalTime", "=", "timeit", ".", "default_timer", "(", ")", "-", "start_time", "\n", "logger", ".", "info", "(", "\"  Evaluation done in total %f secs (%f sec per example)\"", ",", "evalTime", ",", "evalTime", "/", "len", "(", "dataset", ")", ")", "\n", "\n", "# Compute predictions", "\n", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "output_nbest_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"nbest_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "\n", "if", "args", ".", "version_2_with_negative", ":", "\n", "        ", "output_null_log_odds_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"null_odds_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "", "else", ":", "\n", "        ", "output_null_log_odds_file", "=", "None", "\n", "\n", "# XLNet and XLM use a more complex post-processing procedure", "\n", "", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "        ", "start_n_top", "=", "model", ".", "config", ".", "start_n_top", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "else", "model", ".", "module", ".", "config", ".", "start_n_top", "\n", "end_n_top", "=", "model", ".", "config", ".", "end_n_top", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "else", "model", ".", "module", ".", "config", ".", "end_n_top", "\n", "\n", "predictions", "=", "compute_predictions_log_probs", "(", "\n", "examples", ",", "\n", "features", ",", "\n", "all_results", ",", "\n", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "start_n_top", ",", "\n", "end_n_top", ",", "\n", "args", ".", "version_2_with_negative", ",", "\n", "tokenizer", ",", "\n", "args", ".", "verbose_logging", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "predictions", "=", "compute_predictions_logits", "(", "\n", "examples", ",", "\n", "features", ",", "\n", "all_results", ",", "\n", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "\n", "args", ".", "do_lower_case", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "args", ".", "verbose_logging", ",", "\n", "args", ".", "version_2_with_negative", ",", "\n", "args", ".", "null_score_diff_threshold", ",", "\n", "tokenizer", ",", "\n", ")", "\n", "\n", "# Compute the F1 and exact scores.", "\n", "", "results", "=", "squad_evaluate", "(", "examples", ",", "predictions", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.load_and_cache_examples": [[404, 472], ["os.path.join", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "transformers.squad_convert_examples_to_features", "torch.distributed.barrier", "list().pop", "str", "tfds.load", "transformers.data.processors.squad.SquadV1Processor().get_examples_from_dataset", "logger.info", "torch.save", "logger.warn", "transformers.data.processors.squad.SquadV2Processor", "transformers.data.processors.squad.SquadV1Processor", "processor.get_dev_examples", "processor.get_train_examples", "list", "ImportError", "transformers.data.processors.squad.SquadV1Processor", "filter", "args.model_name_or_path.split"], "function", ["None"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "output_examples", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "# Load data features from cache or dataset file", "\n", "", "input_dir", "=", "args", ".", "data_dir", "if", "args", ".", "data_dir", "else", "\".\"", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "input_dir", ",", "\n", "\"cached_{}_{}_{}\"", ".", "format", "(", "\n", "\"dev\"", "if", "evaluate", "else", "\"train\"", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# Init features and dataset from cache if it exists", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features_and_dataset", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "features", ",", "dataset", ",", "examples", "=", "(", "\n", "features_and_dataset", "[", "\"features\"", "]", ",", "\n", "features_and_dataset", "[", "\"dataset\"", "]", ",", "\n", "features_and_dataset", "[", "\"examples\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "input_dir", ")", "\n", "\n", "if", "not", "args", ".", "data_dir", "and", "(", "(", "evaluate", "and", "not", "args", ".", "predict_file", ")", "or", "(", "not", "evaluate", "and", "not", "args", ".", "train_file", ")", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "import", "tensorflow_datasets", "as", "tfds", "\n", "", "except", "ImportError", ":", "\n", "                ", "raise", "ImportError", "(", "\"If not data_dir is specified, tensorflow_datasets needs to be installed.\"", ")", "\n", "\n", "", "if", "args", ".", "version_2_with_negative", ":", "\n", "                ", "logger", ".", "warn", "(", "\"tensorflow_datasets does not handle version 2 of SQuAD.\"", ")", "\n", "\n", "", "tfds_examples", "=", "tfds", ".", "load", "(", "\"squad\"", ")", "\n", "examples", "=", "SquadV1Processor", "(", ")", ".", "get_examples_from_dataset", "(", "tfds_examples", ",", "evaluate", "=", "evaluate", ")", "\n", "", "else", ":", "\n", "            ", "processor", "=", "SquadV2Processor", "(", ")", "if", "args", ".", "version_2_with_negative", "else", "SquadV1Processor", "(", ")", "\n", "if", "evaluate", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "filename", "=", "args", ".", "predict_file", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "filename", "=", "args", ".", "train_file", ")", "\n", "\n", "", "", "features", ",", "dataset", "=", "squad_convert_examples_to_features", "(", "\n", "examples", "=", "examples", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_seq_length", "=", "args", ".", "max_seq_length", ",", "\n", "doc_stride", "=", "args", ".", "doc_stride", ",", "\n", "max_query_length", "=", "args", ".", "max_query_length", ",", "\n", "is_training", "=", "not", "evaluate", ",", "\n", "return_dataset", "=", "\"pt\"", ",", "\n", "threads", "=", "args", ".", "threads", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "{", "\"features\"", ":", "features", ",", "\"dataset\"", ":", "dataset", ",", "\"examples\"", ":", "examples", "}", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "if", "output_examples", ":", "\n", "        ", "return", "dataset", ",", "examples", ",", "features", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.main": [[474, 819], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_squad.set_seed", "parser.parse_args.model_type.lower", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForQuestionAnswering.from_pretrained", "AutoModelForQuestionAnswering.from_pretrained.to", "logger.info", "logger.info", "logger.warning", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "run_squad.load_and_cache_examples", "run_squad.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "AutoTokenizer.from_pretrained.save_pretrained", "torch.save", "transformers.AutoModelForQuestionAnswering.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "AutoModelForQuestionAnswering.from_pretrained.to", "logger.info", "torch.cuda.device_count", "bool", "apex.amp.register_half_function", "hasattr", "os.path.join", "logger.info", "logger.info", "transformers.AutoModelForQuestionAnswering.from_pretrained", "AutoModelForQuestionAnswering.from_pretrained.to", "run_squad.evaluate", "dict", "results.update", "ImportError", "torch.distributed.get_rank", "list", "torch.cuda.is_available", "len", "checkpoint.split", "os.path.dirname", "dict.items", "sorted", "glob.glob"], "function", ["home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.set_seed", "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.load_and_cache_examples", "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.train", "home.repos.pwc.inspect_result.wasiahmad_PolicyQA.None.run_squad.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_TYPES", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model checkpoints and predictions will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The input data dir. Should contain the .json files for the task.\"", "\n", "+", "\"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The input training file. If a data dir is specified, will look for the file there\"", "\n", "+", "\"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--predict_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The input evaluation file. If a data dir is specified, will look for the file there\"", "\n", "+", "\"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--version_2_with_negative\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, the SQuAD examples contain some that do not have an answer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--null_score_diff_threshold\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.0", ",", "\n", "help", "=", "\"If null_score - best_non_null is greater than the threshold predict null.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "384", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. Sequences \"", "\n", "\"longer than this will be truncated, and sequences shorter than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--doc_stride\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"When splitting up a long document into chunks, how much stride to take between chunks.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_query_length\"", ",", "\n", "default", "=", "64", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum number of tokens for the question. Questions longer than this will \"", "\n", "\"be truncated to this length.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_best_size\"", ",", "\n", "default", "=", "20", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The total number of n-best predictions to generate in the nbest_predictions.json output file.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_answer_length\"", ",", "\n", "default", "=", "30", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum length of an answer that can be generated. This is needed because the start \"", "\n", "\"and end predictions are not conditioned on one another.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--verbose_logging\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, all of the warnings related to data processing will be printed. \"", "\n", "\"A number of warnings are expected for a normal SQuAD evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lang_id\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"language id of input for language-specific xlm models (see tokenization_xlm.PRETRAINED_INIT_CONFIGURATION)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--threads\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"multiple threads for converting example to features\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "doc_stride", ">=", "args", ".", "max_seq_length", "-", "args", ".", "max_query_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"WARNING - You've set a doc stride which may be superior to the document length in some \"", "\n", "\"examples. This could result in errors when building features from the examples. Please reduce the doc \"", "\n", "\"stride or increase the maximum length to ensure the features are correctly built.\"", "\n", ")", "\n", "\n", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# Make sure only the first process in distributed training will download model & vocab", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "# Make sure only the first process in distributed training will download model & vocab", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Before we do anything with models, we want to ensure that we get fp16 execution of torch.einsum if args.fp16 is set.", "\n", "# Otherwise it'll default to \"promote\" mode, and we'll get fp32 operations. Note that running `--fp16_opt_level=\"O2\"` will", "\n", "# remove the need for this code, but it is still valid.", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "apex", "\n", "\n", "apex", ".", "amp", ".", "register_half_function", "(", "torch", ",", "\"einsum\"", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "# Training", "\n", "", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "output_examples", "=", "False", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Save the trained model and the tokenizer", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "# Take care of distributed/parallel training", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "# , force_download=True)", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "args", ".", "do_train", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading checkpoints saved during training for evaluation\"", ")", "\n", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "                ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "\n", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading checkpoint %s for evaluation\"", ",", "args", ".", "model_name_or_path", ")", "\n", "checkpoints", "=", "[", "args", ".", "model_name_or_path", "]", "\n", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "# Reload the model", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "checkpoint", ")", "# , force_download=True)", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluate", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "global_step", ")", "\n", "\n", "result", "=", "dict", "(", "(", "k", "+", "(", "\"_{}\"", ".", "format", "(", "global_step", ")", "if", "global_step", "else", "\"\"", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Results: {}\"", ".", "format", "(", "results", ")", ")", "\n", "\n", "return", "results", "\n", "\n"]]}