{"home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.__init__": [[46, 50], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "processor", "=", "None", ")", ":", "\n", "        ", "self", ".", "processor", "=", "processor", "\n", "self", ".", "training", "=", "False", "\n", "self", ".", "step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.get_config": [[51, 58], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"Configuration of the agent for serialization.\n\n        # Returns\n            Dictionnary with agent configuration\n        \"\"\"", "\n", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.fit": [[59, 254], ["keras.callbacks.History", "rl.callbacks.CallbackList", "hasattr", "rl.callbacks.CallbackList._set_env", "hasattr", "core.Agent._on_train_begin", "rl.callbacks.CallbackList.on_train_begin", "numpy.int16", "numpy.int16", "rl.callbacks.CallbackList.on_train_end", "core.Agent._on_train_end", "RuntimeError", "ValueError", "rl.callbacks.CallbackList.set_model", "rl.callbacks.CallbackList._set_model", "rl.callbacks.CallbackList.set_params", "rl.callbacks.CallbackList._set_params", "rl.callbacks.TrainIntervalLogger", "rl.callbacks.Visualizer", "rl.callbacks.CallbackList.on_step_begin", "core.Agent.forward", "numpy.float32", "range", "rl.callbacks.CallbackList.on_step_end", "rl.callbacks.TrainEpisodeLogger", "rl.callbacks.CallbackList.on_episode_begin", "numpy.int16", "numpy.float32", "core.Agent.reset_states", "copy.deepcopy", "range", "core.Agent.processor.process_action", "rl.callbacks.CallbackList.on_action_begin", "env.step", "copy.deepcopy", "accumulated_info.update", "rl.callbacks.CallbackList.on_action_end", "core.Agent.backward", "core.Agent.backward", "core.Agent.forward", "core.Agent.backward", "numpy.isnan().all", "enumerate", "rl.callbacks.CallbackList.on_episode_end", "env.reset", "core.Agent.processor.process_observation", "numpy.random.randint", "rl.callbacks.CallbackList.on_action_begin", "env.step", "copy.deepcopy", "rl.callbacks.CallbackList.on_action_end", "core.Agent.processor.process_step", "env.action_space.sample", "start_step_policy", "core.Agent.processor.process_action", "core.Agent.processor.process_step", "warnings.warn", "copy.deepcopy", "type", "numpy.isnan", "env.reset", "core.Agent.processor.process_observation", "numpy.array", "numpy.nanmean", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent._on_train_begin", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent._on_train_end", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.StoreTestEpisodeData.on_step_end", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.UpdateActiveModelCallback.on_episode_begin", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.EvaluateAgent.on_episode_end", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_observation", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_observation"], ["", "def", "fit", "(", "self", ",", "env", ",", "nb_steps", ",", "action_repetition", "=", "1", ",", "callbacks", "=", "None", ",", "verbose", "=", "1", ",", "\n", "visualize", "=", "False", ",", "nb_max_start_steps", "=", "0", ",", "start_step_policy", "=", "None", ",", "log_interval", "=", "10000", ",", "\n", "nb_max_episode_steps", "=", "None", ")", ":", "\n", "        ", "\"\"\"Trains the agent on the given environment.\n\n        # Arguments\n            env: (`Env` instance): Environment that the agent interacts with. See [Env](#env) for details.\n            nb_steps (integer): Number of training steps to be performed.\n            action_repetition (integer): Number of times the agent repeats the same action without\n                observing the environment again. Setting this to a value > 1 can be useful\n                if a single action only has a very small effect on the environment.\n            callbacks (list of `keras.callbacks.Callback` or `rl.callbacks.Callback` instances):\n                List of callbacks to apply during training. See [callbacks](/callbacks) for details.\n            verbose (integer): 0 for no logging, 1 for interval logging (compare `log_interval`), 2 for episode logging\n            visualize (boolean): If `True`, the environment is visualized during training. However,\n                this is likely going to slow down training significantly and is thus intended to be\n                a debugging instrument.\n            nb_max_start_steps (integer): Number of maximum steps that the agent performs at the beginning\n                of each episode using `start_step_policy`. Notice that this is an upper limit since\n                the exact number of steps to be performed is sampled uniformly from [0, max_start_steps]\n                at the beginning of each episode.\n            start_step_policy (`lambda observation: action`): The policy\n                to follow if `nb_max_start_steps` > 0. If set to `None`, a random action is performed.\n            log_interval (integer): If `verbose` = 1, the number of steps that are considered to be an interval.\n            nb_max_episode_steps (integer): Number of steps per episode that the agent performs before\n                automatically resetting the environment. Set to `None` if each episode should run\n                (potentially indefinitely) until the environment signals a terminal state.\n\n        # Returns\n            A `keras.callbacks.History` instance that recorded the entire training process.\n        \"\"\"", "\n", "if", "not", "self", ".", "compiled", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Your tried to fit your agent but it hasn\\'t been compiled yet. Please call `compile()` '", "\n", "'before `fit()`.'", ")", "\n", "", "if", "action_repetition", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'action_repetition must be >= 1, is {}'", ".", "format", "(", "action_repetition", ")", ")", "\n", "\n", "", "self", ".", "training", "=", "True", "\n", "\n", "callbacks", "=", "[", "]", "if", "not", "callbacks", "else", "callbacks", "[", ":", "]", "\n", "\n", "if", "verbose", "==", "1", ":", "\n", "            ", "callbacks", "+=", "[", "TrainIntervalLogger", "(", "interval", "=", "log_interval", ")", "]", "\n", "", "elif", "verbose", ">", "1", ":", "\n", "            ", "callbacks", "+=", "[", "TrainEpisodeLogger", "(", ")", "]", "\n", "", "if", "visualize", ":", "\n", "            ", "callbacks", "+=", "[", "Visualizer", "(", ")", "]", "\n", "", "history", "=", "History", "(", ")", "\n", "callbacks", "+=", "[", "history", "]", "\n", "callbacks", "=", "CallbackList", "(", "callbacks", ")", "\n", "if", "hasattr", "(", "callbacks", ",", "'set_model'", ")", ":", "\n", "            ", "callbacks", ".", "set_model", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "callbacks", ".", "_set_model", "(", "self", ")", "\n", "", "callbacks", ".", "_set_env", "(", "env", ")", "\n", "params", "=", "{", "\n", "'nb_steps'", ":", "nb_steps", ",", "\n", "}", "\n", "if", "hasattr", "(", "callbacks", ",", "'set_params'", ")", ":", "\n", "            ", "callbacks", ".", "set_params", "(", "params", ")", "\n", "", "else", ":", "\n", "            ", "callbacks", ".", "_set_params", "(", "params", ")", "\n", "", "self", ".", "_on_train_begin", "(", ")", "\n", "callbacks", ".", "on_train_begin", "(", ")", "\n", "\n", "episode", "=", "np", ".", "int16", "(", "0", ")", "\n", "self", ".", "step", "=", "np", ".", "int16", "(", "0", ")", "\n", "observation", "=", "None", "\n", "episode_reward", "=", "None", "\n", "episode_step", "=", "None", "\n", "did_abort", "=", "False", "\n", "try", ":", "\n", "            ", "while", "self", ".", "step", "<", "nb_steps", ":", "\n", "                ", "if", "observation", "is", "None", ":", "# start of a new episode", "\n", "                    ", "callbacks", ".", "on_episode_begin", "(", "episode", ")", "\n", "episode_step", "=", "np", ".", "int16", "(", "0", ")", "\n", "episode_reward", "=", "np", ".", "float32", "(", "0", ")", "\n", "\n", "# Obtain the initial observation by resetting the environment.", "\n", "self", ".", "reset_states", "(", ")", "\n", "observation", "=", "deepcopy", "(", "env", ".", "reset", "(", ")", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                        ", "observation", "=", "self", ".", "processor", ".", "process_observation", "(", "observation", ")", "\n", "", "assert", "observation", "is", "not", "None", "\n", "\n", "# Perform random starts at beginning of episode and do not record them into the experience.", "\n", "# This slightly changes the start position between games.", "\n", "nb_random_start_steps", "=", "0", "if", "nb_max_start_steps", "==", "0", "else", "np", ".", "random", ".", "randint", "(", "nb_max_start_steps", ")", "\n", "for", "_", "in", "range", "(", "nb_random_start_steps", ")", ":", "\n", "                        ", "if", "start_step_policy", "is", "None", ":", "\n", "                            ", "action", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "", "else", ":", "\n", "                            ", "action", "=", "start_step_policy", "(", "observation", ")", "\n", "", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                            ", "action", "=", "self", ".", "processor", ".", "process_action", "(", "action", ")", "\n", "", "callbacks", ".", "on_action_begin", "(", "action", ")", "\n", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "observation", "=", "deepcopy", "(", "observation", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "processor", ".", "process_step", "(", "observation", ",", "reward", ",", "done", ",", "info", ")", "\n", "", "callbacks", ".", "on_action_end", "(", "action", ")", "\n", "if", "done", ":", "\n", "                            ", "warnings", ".", "warn", "(", "'Env ended before {} random steps could be performed at the start. '", "\n", "'You should probably lower the `nb_max_start_steps` '", "\n", "'parameter.'", ".", "format", "(", "nb_random_start_steps", ")", ")", "\n", "observation", "=", "deepcopy", "(", "env", ".", "reset", "(", ")", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                                ", "observation", "=", "self", ".", "processor", ".", "process_observation", "(", "observation", ")", "\n", "", "break", "\n", "\n", "# At this point, we expect to be fully initialized.", "\n", "", "", "", "assert", "episode_reward", "is", "not", "None", "\n", "assert", "episode_step", "is", "not", "None", "\n", "assert", "observation", "is", "not", "None", "\n", "\n", "# Run a single step.", "\n", "callbacks", ".", "on_step_begin", "(", "episode_step", ")", "\n", "# This is were all of the work happens. We first perceive and compute the action", "\n", "# (forward step) and then use the reward to improve (backward step).", "\n", "action", ",", "action_info", "=", "self", ".", "forward", "(", "observation", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                    ", "action", "=", "self", ".", "processor", ".", "process_action", "(", "action", ")", "\n", "", "reward", "=", "np", ".", "float32", "(", "0", ")", "\n", "accumulated_info", "=", "{", "}", "\n", "done", "=", "False", "\n", "for", "_", "in", "range", "(", "action_repetition", ")", ":", "\n", "                    ", "callbacks", ".", "on_action_begin", "(", "action", ")", "\n", "observation", ",", "r", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "observation", "=", "deepcopy", "(", "observation", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                        ", "observation", ",", "r", ",", "done", ",", "info", "=", "self", ".", "processor", ".", "process_step", "(", "observation", ",", "r", ",", "done", ",", "info", ")", "\n", "", "accumulated_info", ".", "update", "(", "info", ")", "\n", "callbacks", ".", "on_action_end", "(", "action", ")", "\n", "reward", "+=", "r", "\n", "if", "done", ":", "\n", "                        ", "break", "\n", "", "", "if", "nb_max_episode_steps", "and", "episode_step", ">=", "nb_max_episode_steps", "-", "1", ":", "\n", "# Force a terminal state.", "\n", "                    ", "done", "=", "True", "\n", "", "if", "done", "and", "'Max steps'", "in", "info", ":", "# If done==True due to maximum number of steps, report as not terminal", "\n", "                    ", "metrics", "=", "self", ".", "backward", "(", "reward", ",", "terminal", "=", "False", ")", "\n", "", "else", ":", "\n", "                    ", "metrics", "=", "self", ".", "backward", "(", "reward", ",", "terminal", "=", "done", ")", "\n", "", "episode_reward", "+=", "reward", "\n", "\n", "step_logs", "=", "{", "\n", "'action'", ":", "action", ",", "\n", "'observation'", ":", "observation", ",", "\n", "'reward'", ":", "reward", ",", "\n", "'metrics'", ":", "metrics", ",", "\n", "'episode'", ":", "episode", ",", "\n", "'info'", ":", "accumulated_info", ",", "\n", "}", "\n", "callbacks", ".", "on_step_end", "(", "episode_step", ",", "step_logs", ")", "\n", "episode_step", "+=", "1", "\n", "self", ".", "step", "+=", "1", "\n", "\n", "if", "done", ":", "\n", "# We are in a terminal state but the agent hasn't yet seen it. We therefore", "\n", "# perform one more forward-backward call and simply ignore the action before", "\n", "# resetting the environment. We need to pass in `terminal=False` here since", "\n", "# the *next* state, that is the state of the newly reset environment, is", "\n", "# always non-terminal by convention.", "\n", "                    ", "self", ".", "forward", "(", "observation", ")", "\n", "self", ".", "backward", "(", "0.", ",", "terminal", "=", "False", ")", "\n", "\n", "# This episode is finished, report and reset.", "\n", "episode_logs", "=", "{", "\n", "'episode_reward'", ":", "episode_reward", ",", "\n", "'nb_episode_steps'", ":", "episode_step", ",", "\n", "'nb_steps'", ":", "self", ".", "step", ",", "\n", "'mean_reward'", ":", "episode_reward", "/", "episode_step", ",", "\n", "}", "\n", "# Added extra items to episode logs here for plotting in tensorflow", "\n", "for", "callback", "in", "callbacks", ":", "\n", "                        ", "if", "type", "(", "callback", ")", "is", "TrainEpisodeLogger", ":", "\n", "                            ", "logger_callback", "=", "callback", "\n", "", "", "only_nans", "=", "np", ".", "isnan", "(", "np", ".", "array", "(", "logger_callback", ".", "metrics", "[", "episode", "]", ")", ")", ".", "all", "(", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "logger_callback", ".", "metrics_names", ")", ":", "\n", "                        ", "episode_logs", "[", "name", "]", "=", "np", ".", "nanmean", "(", "np", ".", "array", "(", "logger_callback", ".", "metrics", "[", "episode", "]", ")", ",", "axis", "=", "0", ")", "[", "i", "]", "if", "not", "only_nans", "else", "np", ".", "nan", "\n", "", "callbacks", ".", "on_episode_end", "(", "episode", ",", "episode_logs", ")", "\n", "\n", "episode", "+=", "1", "\n", "observation", "=", "None", "\n", "episode_step", "=", "None", "\n", "episode_reward", "=", "None", "\n", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "# We catch keyboard interrupts here so that training can be be safely aborted.", "\n", "# This is so common that we've built this right into this function, which ensures that", "\n", "# the `on_train_end` method is properly called.", "\n", "            ", "did_abort", "=", "True", "\n", "", "callbacks", ".", "on_train_end", "(", "logs", "=", "{", "'did_abort'", ":", "did_abort", "}", ")", "\n", "self", ".", "_on_train_end", "(", ")", "\n", "\n", "return", "history", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.test": [[255, 449], ["keras.callbacks.History", "rl.callbacks.CallbackList", "hasattr", "rl.callbacks.CallbackList._set_env", "hasattr", "core.Agent._on_test_begin", "rl.callbacks.CallbackList.on_train_begin", "range", "rl.callbacks.CallbackList.on_train_end", "core.Agent._on_test_end", "RuntimeError", "ValueError", "rl.callbacks.CallbackList.set_model", "rl.callbacks.CallbackList._set_model", "rl.callbacks.CallbackList.set_params", "rl.callbacks.CallbackList._set_params", "numpy.random.get_state", "numpy.random.seed", "rl.callbacks.CallbackList.on_episode_begin", "numpy.zeros", "core.Agent.reset_states", "copy.deepcopy", "range", "core.Agent.forward", "core.Agent.backward", "rl.callbacks.CallbackList.on_episode_end", "numpy.random.set_state", "rl.callbacks.TestLogger", "rl.callbacks.Visualizer", "env.reset", "core.Agent.processor.process_observation", "numpy.random.randint", "rl.callbacks.CallbackList.on_action_begin", "env.step", "copy.deepcopy", "rl.callbacks.CallbackList.on_action_end", "rl.callbacks.CallbackList.on_step_begin", "core.Agent.forward", "range", "core.Agent.backward", "episode_info.update", "rl.callbacks.CallbackList.on_step_end", "hasattr", "env.action_space.sample", "start_step_policy", "core.Agent.processor.process_action", "core.Agent.processor.process_step", "warnings.warn", "copy.deepcopy", "core.Agent.processor.process_action", "rl.callbacks.CallbackList.on_action_begin", "env.step", "copy.deepcopy", "rl.callbacks.CallbackList.on_action_end", "accumulated_info.update", "env.reset", "core.Agent.processor.process_observation", "core.Agent.processor.process_step", "numpy.sum", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent._on_test_begin", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent._on_test_end", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.UpdateActiveModelCallback.on_episode_begin", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.EvaluateAgent.on_episode_end", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_observation", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.StoreTestEpisodeData.on_step_end", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_observation", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_step"], ["", "def", "test", "(", "self", ",", "env", ",", "nb_episodes", "=", "1", ",", "action_repetition", "=", "1", ",", "callbacks", "=", "None", ",", "visualize", "=", "True", ",", "\n", "nb_max_episode_steps", "=", "None", ",", "nb_max_start_steps", "=", "0", ",", "start_step_policy", "=", "None", ",", "verbose", "=", "1", ")", ":", "\n", "        ", "\"\"\"Callback that is called before training begins.\n\n        # Arguments\n            env: (`Env` instance): Environment that the agent interacts with. See [Env](#env) for details.\n            nb_episodes (integer): Number of episodes to perform.\n            action_repetition (integer): Number of times the agent repeats the same action without\n                observing the environment again. Setting this to a value > 1 can be useful\n                if a single action only has a very small effect on the environment.\n            callbacks (list of `keras.callbacks.Callback` or `rl.callbacks.Callback` instances):\n                List of callbacks to apply during training. See [callbacks](/callbacks) for details.\n            verbose (integer): 0 for no logging, 1 for interval logging (compare `log_interval`), 2 for episode logging\n            visualize (boolean): If `True`, the environment is visualized during training. However,\n                this is likely going to slow down training significantly and is thus intended to be\n                a debugging instrument.\n            nb_max_start_steps (integer): Number of maximum steps that the agent performs at the beginning\n                of each episode using `start_step_policy`. Notice that this is an upper limit since\n                the exact number of steps to be performed is sampled uniformly from [0, max_start_steps]\n                at the beginning of each episode.\n            start_step_policy (`lambda observation: action`): The policy\n                to follow if `nb_max_start_steps` > 0. If set to `None`, a random action is performed.\n            log_interval (integer): If `verbose` = 1, the number of steps that are considered to be an interval.\n            nb_max_episode_steps (integer): Number of steps per episode that the agent performs before\n                automatically resetting the environment. Set to `None` if each episode should run\n                (potentially indefinitely) until the environment signals a terminal state.\n\n        # Returns\n            A `keras.callbacks.History` instance that recorded the entire training process.\n        \"\"\"", "\n", "if", "not", "self", ".", "compiled", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Your tried to test your agent but it hasn\\'t been compiled yet. Please call `compile()` '", "\n", "'before `test()`.'", ")", "\n", "", "if", "action_repetition", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'action_repetition must be >= 1, is {}'", ".", "format", "(", "action_repetition", ")", ")", "\n", "\n", "", "self", ".", "training", "=", "False", "\n", "self", ".", "test_step", "=", "0", "\n", "\n", "callbacks", "=", "[", "]", "if", "not", "callbacks", "else", "callbacks", "[", ":", "]", "\n", "\n", "if", "verbose", ">=", "1", ":", "\n", "            ", "callbacks", "+=", "[", "TestLogger", "(", ")", "]", "\n", "", "if", "visualize", ":", "\n", "            ", "callbacks", "+=", "[", "Visualizer", "(", ")", "]", "\n", "", "history", "=", "History", "(", ")", "\n", "callbacks", "+=", "[", "history", "]", "\n", "callbacks", "=", "CallbackList", "(", "callbacks", ")", "\n", "if", "hasattr", "(", "callbacks", ",", "'set_model'", ")", ":", "\n", "            ", "callbacks", ".", "set_model", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "callbacks", ".", "_set_model", "(", "self", ")", "\n", "", "callbacks", ".", "_set_env", "(", "env", ")", "\n", "params", "=", "{", "\n", "'nb_episodes'", ":", "nb_episodes", ",", "\n", "}", "\n", "if", "hasattr", "(", "callbacks", ",", "'set_params'", ")", ":", "\n", "            ", "callbacks", ".", "set_params", "(", "params", ")", "\n", "", "else", ":", "\n", "            ", "callbacks", ".", "_set_params", "(", "params", ")", "\n", "\n", "", "self", ".", "_on_test_begin", "(", ")", "\n", "callbacks", ".", "on_train_begin", "(", ")", "\n", "for", "episode", "in", "range", "(", "nb_episodes", ")", ":", "\n", "            ", "internal_random_state", "=", "np", ".", "random", ".", "get_state", "(", ")", "# Store internal random state and reset it after testing is done", "\n", "np", ".", "random", ".", "seed", "(", "episode", ")", "\n", "\n", "callbacks", ".", "on_episode_begin", "(", "episode", ")", "\n", "episode_reward", "=", "0.", "\n", "episode_step", "=", "0", "\n", "total_actions", "=", "np", ".", "zeros", "(", "env", ".", "action_space", ".", "n", "if", "hasattr", "(", "env", ",", "'action_space'", ")", "else", "env", ".", "nb_actions", ")", "\n", "mean_aleatoric_std_dev_chosen_action", "=", "0", "\n", "max_aleatoric_std_dev_chosen_action", "=", "0", "\n", "mean_epistemic_std_dev_chosen_action", "=", "0", "\n", "max_epistemic_std_dev_chosen_action", "=", "0", "\n", "episode_info", "=", "{", "}", "\n", "\n", "# Obtain the initial observation by resetting the environment.", "\n", "self", ".", "reset_states", "(", ")", "\n", "observation", "=", "deepcopy", "(", "env", ".", "reset", "(", ")", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                ", "observation", "=", "self", ".", "processor", ".", "process_observation", "(", "observation", ")", "\n", "", "assert", "observation", "is", "not", "None", "\n", "\n", "# Perform random starts at beginning of episode and do not record them into the experience.", "\n", "# This slightly changes the start position between games.", "\n", "nb_random_start_steps", "=", "0", "if", "nb_max_start_steps", "==", "0", "else", "np", ".", "random", ".", "randint", "(", "nb_max_start_steps", ")", "\n", "for", "_", "in", "range", "(", "nb_random_start_steps", ")", ":", "\n", "                ", "if", "start_step_policy", "is", "None", ":", "\n", "                    ", "action", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "", "else", ":", "\n", "                    ", "action", "=", "start_step_policy", "(", "observation", ")", "\n", "", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                    ", "action", "=", "self", ".", "processor", ".", "process_action", "(", "action", ")", "\n", "", "callbacks", ".", "on_action_begin", "(", "action", ")", "\n", "observation", ",", "r", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "observation", "=", "deepcopy", "(", "observation", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                    ", "observation", ",", "r", ",", "done", ",", "info", "=", "self", ".", "processor", ".", "process_step", "(", "observation", ",", "r", ",", "done", ",", "info", ")", "\n", "", "callbacks", ".", "on_action_end", "(", "action", ")", "\n", "if", "done", ":", "\n", "                    ", "warnings", ".", "warn", "(", "'Env ended before {} random steps could be performed at the start. '", "\n", "'You should probably lower the `nb_max_start_steps` '", "\n", "'parameter.'", ".", "format", "(", "nb_random_start_steps", ")", ")", "\n", "observation", "=", "deepcopy", "(", "env", ".", "reset", "(", ")", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                        ", "observation", "=", "self", ".", "processor", ".", "process_observation", "(", "observation", ")", "\n", "", "break", "\n", "\n", "# Run the episode until we're done.", "\n", "", "", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "                ", "callbacks", ".", "on_step_begin", "(", "episode_step", ")", "\n", "\n", "action", ",", "action_info", "=", "self", ".", "forward", "(", "observation", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                    ", "action", "=", "self", ".", "processor", ".", "process_action", "(", "action", ")", "\n", "", "reward", "=", "0.", "\n", "accumulated_info", "=", "{", "}", "\n", "for", "_", "in", "range", "(", "action_repetition", ")", ":", "\n", "                    ", "callbacks", ".", "on_action_begin", "(", "action", ")", "\n", "observation", ",", "r", ",", "d", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "observation", "=", "deepcopy", "(", "observation", ")", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                        ", "observation", ",", "r", ",", "d", ",", "info", "=", "self", ".", "processor", ".", "process_step", "(", "observation", ",", "r", ",", "d", ",", "info", ")", "\n", "", "callbacks", ".", "on_action_end", "(", "action", ")", "\n", "reward", "+=", "r", "\n", "accumulated_info", ".", "update", "(", "info", ")", "\n", "if", "d", ":", "\n", "                        ", "done", "=", "True", "\n", "break", "\n", "", "", "if", "nb_max_episode_steps", "and", "episode_step", ">=", "nb_max_episode_steps", "-", "1", ":", "\n", "                    ", "done", "=", "True", "\n", "", "self", ".", "backward", "(", "reward", ",", "terminal", "=", "done", ")", "\n", "episode_reward", "+=", "reward", "\n", "total_actions", "[", "action", "]", "+=", "1", "\n", "accumulated_info", "[", "'total_actions'", "]", "=", "total_actions", "\n", "episode_info", ".", "update", "(", "accumulated_info", ")", "\n", "\n", "step_logs", "=", "{", "\n", "'action'", ":", "action", ",", "\n", "'observation'", ":", "observation", ",", "\n", "'reward'", ":", "reward", ",", "\n", "'episode'", ":", "episode", ",", "\n", "'info'", ":", "accumulated_info", ",", "\n", "}", "\n", "if", "'q_values_all_nets'", "in", "action_info", ":", "\n", "                    ", "step_logs", "[", "'q_values_of_chosen_action'", "]", "=", "action_info", "[", "'q_values_all_nets'", "]", "[", ":", ",", "action", "]", "\n", "", "if", "'aleatoric_std_dev'", "in", "action_info", ":", "\n", "                    ", "mean_aleatoric_std_dev_chosen_action", "=", "mean_aleatoric_std_dev_chosen_action", "+", "(", "action_info", "[", "'aleatoric_std_dev'", "]", "[", "action", "]", "-", "\n", "mean_aleatoric_std_dev_chosen_action", ")", "/", "np", ".", "sum", "(", "total_actions", ")", "\n", "if", "action_info", "[", "'aleatoric_std_dev'", "]", "[", "action", "]", ">", "max_aleatoric_std_dev_chosen_action", ":", "\n", "                        ", "max_aleatoric_std_dev_chosen_action", "=", "action_info", "[", "'aleatoric_std_dev'", "]", "[", "action", "]", "\n", "", "", "if", "'epistemic_std_dev'", "in", "action_info", ":", "\n", "                    ", "mean_epistemic_std_dev_chosen_action", "=", "mean_epistemic_std_dev_chosen_action", "+", "(", "action_info", "[", "'epistemic_std_dev'", "]", "[", "action", "]", "-", "\n", "mean_epistemic_std_dev_chosen_action", ")", "/", "np", ".", "sum", "(", "total_actions", ")", "\n", "if", "action_info", "[", "'epistemic_std_dev'", "]", "[", "action", "]", ">", "max_epistemic_std_dev_chosen_action", ":", "\n", "                        ", "max_epistemic_std_dev_chosen_action", "=", "action_info", "[", "'epistemic_std_dev'", "]", "[", "action", "]", "\n", "", "", "callbacks", ".", "on_step_end", "(", "episode_step", ",", "step_logs", ")", "\n", "episode_step", "+=", "1", "\n", "self", ".", "test_step", "+=", "1", "\n", "\n", "# We are in a terminal state but the agent hasn't yet seen it. We therefore", "\n", "# perform one more forward-backward call and simply ignore the action before", "\n", "# resetting the environment. We need to pass in `terminal=False` here since", "\n", "# the *next* state, that is the state of the newly reset environment, is", "\n", "# always non-terminal by convention.", "\n", "", "self", ".", "forward", "(", "observation", ")", "\n", "self", ".", "backward", "(", "0.", ",", "terminal", "=", "False", ")", "\n", "\n", "if", "'aleatoric_std_dev'", "in", "action_info", ":", "\n", "                ", "episode_info", "[", "'mean_aleatoric_std_dev_chosen_action'", "]", "=", "mean_aleatoric_std_dev_chosen_action", "\n", "episode_info", "[", "'max_aleatoric_std_dev_chosen_action'", "]", "=", "max_aleatoric_std_dev_chosen_action", "\n", "", "if", "'epistemic_std_dev'", "in", "action_info", ":", "\n", "                ", "episode_info", "[", "'mean_epistemic_std_dev_chosen_action'", "]", "=", "mean_epistemic_std_dev_chosen_action", "\n", "episode_info", "[", "'max_epistemic_std_dev_chosen_action'", "]", "=", "max_epistemic_std_dev_chosen_action", "\n", "\n", "# Report end of episode.", "\n", "", "episode_logs", "=", "{", "\n", "'episode_reward'", ":", "episode_reward", ",", "\n", "'nb_steps'", ":", "episode_step", ",", "\n", "'info'", ":", "episode_info", "\n", "}", "\n", "callbacks", ".", "on_episode_end", "(", "episode", ",", "episode_logs", ")", "\n", "\n", "np", ".", "random", ".", "set_state", "(", "internal_random_state", ")", "\n", "", "callbacks", ".", "on_train_end", "(", ")", "\n", "self", ".", "_on_test_end", "(", ")", "\n", "\n", "return", "history", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.reset_states": [[450, 454], ["None"], "methods", ["None"], ["", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets all internally kept states after an episode is completed.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.forward": [[455, 466], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "\"\"\"Takes the an observation from the environment and returns the action to be taken next.\n        If the policy is implemented by a neural network, this corresponds to a forward (inference) pass.\n\n        # Argument\n            observation (object): The current observation from the environment.\n\n        # Returns\n            The next action to be executed in the environment.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.backward": [[467, 479], ["NotImplementedError"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "reward", ",", "terminal", ")", ":", "\n", "        ", "\"\"\"Updates the agent after having executed the action returned by `forward`.\n        If the policy is implemented by a neural network, this corresponds to a weight update using back-prop.\n\n        # Argument\n            reward (float): The observed reward after executing the action returned by `forward`.\n            terminal (boolean): `True` if the new state of the environment is terminal.\n\n        # Returns\n            List of metrics values\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.compile": [[480, 488], ["NotImplementedError"], "methods", ["None"], ["", "def", "compile", "(", "self", ",", "optimizer", ",", "metrics", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"Compiles an agent and the underlaying models to be used for training and testing.\n\n        # Arguments\n            optimizer (`keras.optimizers.Optimizer` instance): The optimizer to be used during training.\n            metrics (list of functions `lambda y_true, y_pred: metric`): The metrics to run during training.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.load_weights": [[489, 496], ["NotImplementedError"], "methods", ["None"], ["", "def", "load_weights", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "\"\"\"Loads the weights of an agent from an HDF5 file.\n\n        # Arguments\n            filepath (str): The path to the HDF5 file.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.save_weights": [[497, 505], ["NotImplementedError"], "methods", ["None"], ["", "def", "save_weights", "(", "self", ",", "filepath", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "\"\"\"Saves the weights of an agent as an HDF5 file.\n\n        # Arguments\n            filepath (str): The path to where the weights should be saved.\n            overwrite (boolean): If `False` and `filepath` already exists, raises an error.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.layers": [[506, 517], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns all layers of the underlying model(s).\n\n        If the concrete implementation uses multiple internal models,\n        this method returns them in a concatenated list.\n\n        # Returns\n            A list of the model's layers\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.metrics_names": [[518, 527], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"The human-readable names of the agent's metrics. Must return as many names as there\n        are metrics (see also `compile`).\n\n        # Returns\n            A list of metric's names (string)\n        \"\"\"", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent._on_train_begin": [[528, 532], ["None"], "methods", ["None"], ["", "def", "_on_train_begin", "(", "self", ")", ":", "\n", "        ", "\"\"\"Callback that is called before training begins.\"\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent._on_train_end": [[533, 537], ["None"], "methods", ["None"], ["", "def", "_on_train_end", "(", "self", ")", ":", "\n", "        ", "\"\"\"Callback that is called after training ends.\"\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent._on_test_begin": [[538, 542], ["None"], "methods", ["None"], ["", "def", "_on_test_begin", "(", "self", ")", ":", "\n", "        ", "\"\"\"Callback that is called before testing begins.\"\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent._on_test_end": [[543, 547], ["None"], "methods", ["None"], ["", "def", "_on_test_end", "(", "self", ")", ":", "\n", "        ", "\"\"\"Callback that is called after testing ends.\"\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_step": [[562, 578], ["core.Processor.process_observation", "core.Processor.process_reward", "core.Processor.process_info"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_observation", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_reward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_info"], ["def", "process_step", "(", "self", ",", "observation", ",", "reward", ",", "done", ",", "info", ")", ":", "\n", "        ", "\"\"\"Processes an entire step by applying the processor to the observation, reward, and info arguments.\n\n        # Arguments\n            observation (object): An observation as obtained by the environment.\n            reward (float): A reward as obtained by the environment.\n            done (boolean): `True` if the environment is in a terminal state, `False` otherwise.\n            info (dict): The debug info dictionary as obtained by the environment.\n\n        # Returns\n            The tupel (observation, reward, done, reward) with with all elements after being processed.\n        \"\"\"", "\n", "observation", "=", "self", ".", "process_observation", "(", "observation", ")", "\n", "reward", "=", "self", ".", "process_reward", "(", "reward", ")", "\n", "info", "=", "self", ".", "process_info", "(", "info", ")", "\n", "return", "observation", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_observation": [[579, 590], ["None"], "methods", ["None"], ["", "def", "process_observation", "(", "self", ",", "observation", ")", ":", "\n", "        ", "\"\"\"Processes the observation as obtained from the environment for use in an agent and\n        returns it.\n\n        # Arguments\n            observation (object): An observation as obtained by the environment\n\n        # Returns\n            Observation obtained by the environment processed\n        \"\"\"", "\n", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_reward": [[591, 602], ["None"], "methods", ["None"], ["", "def", "process_reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "\"\"\"Processes the reward as obtained from the environment for use in an agent and\n        returns it.\n\n        # Arguments\n            reward (float): A reward as obtained by the environment\n\n        # Returns\n            Reward obtained by the environment processed\n        \"\"\"", "\n", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_info": [[603, 614], ["None"], "methods", ["None"], ["", "def", "process_info", "(", "self", ",", "info", ")", ":", "\n", "        ", "\"\"\"Processes the info as obtained from the environment for use in an agent and\n        returns it.\n\n        # Arguments\n            info (dict): An info as obtained by the environment\n\n        # Returns\n            Info obtained by the environment processed\n        \"\"\"", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_action": [[615, 625], ["None"], "methods", ["None"], ["", "def", "process_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"Processes an action predicted by an agent but before execution in an environment.\n\n        # Arguments\n            action (int): Action given to the environment\n\n        #\u00a0Returns\n            Processed action given to the environment\n        \"\"\"", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.process_state_batch": [[626, 636], ["None"], "methods", ["None"], ["", "def", "process_state_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Processes an entire batch of states and returns it.\n\n        # Arguments\n            batch (list): List of states\n\n        # Returns\n            Processed list of states\n        \"\"\"", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.metrics": [[637, 645], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"The metrics of the processor, which will be reported during training.\n\n        # Returns\n            List of `lambda y_true, y_pred: metric` functions.\n        \"\"\"", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Processor.metrics_names": [[646, 652], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"The human-readable names of the agent's metrics. Must return as many names as there\n        are metrics (see also `compile`).\n        \"\"\"", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.step": [[677, 691], ["NotImplementedError"], "methods", ["None"], ["def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"Run one timestep of the environment's dynamics.\n        Accepts an action and returns a tuple (observation, reward, done, info).\n\n        # Arguments\n            action (object): An action provided by the environment.\n\n        # Returns\n            observation (object): Agent's observation of the current environment.\n            reward (float) : Amount of reward returned after previous action.\n            done (boolean): Whether the episode has ended, in which case further step() calls will return undefined results.\n            info (dict): Contains auxiliary diagnostic information (helpful for debugging, and sometimes learning).\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.reset": [[692, 700], ["NotImplementedError"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Resets the state of the environment and returns an initial observation.\n\n        # Returns\n            observation (object): The initial observation of the space. Initial reward is assumed to be 0.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.render": [[701, 711], ["NotImplementedError"], "methods", ["None"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "close", "=", "False", ")", ":", "\n", "        ", "\"\"\"Renders the environment.\n        The set of supported modes varies per environment. (And some\n        environments do not support rendering at all.)\n\n        # Arguments\n            mode (str): The mode to render with.\n            close (bool): Close all open renderings.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close": [[712, 718], ["NotImplementedError"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"Override in your subclass to perform any necessary cleanup.\n        Environments will automatically close() themselves when\n        garbage collected or when the program exits.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed": [[719, 726], ["NotImplementedError"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Sets the seed for this env's random number generator(s).\n\n        # Returns\n            Returns the list of seeds used in this env's random number generators\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.configure": [[727, 735], ["NotImplementedError"], "methods", ["None"], ["", "def", "configure", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Provides runtime configuration to the environment.\n        This configuration should consist of data that tells your\n        environment how to run (such as an address of a remote server,\n        or path to your ImageNet data). It should not affect the\n        semantics of the environment.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.__del__": [[736, 738], ["core.Env.close"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.__str__": [[739, 741], ["type"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'<{} instance>'", ".", "format", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Space.sample": [[750, 754], ["NotImplementedError"], "methods", ["None"], ["def", "sample", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Uniformly randomly sample a random element of this space.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Space.contains": [[755, 759], ["NotImplementedError"], "methods", ["None"], ["", "def", "contains", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Return boolean specifying if x is a valid member of this space\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.EnsembleTestPolicy.__init__": [[17, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "safety_threshold", "=", "None", ")", ":", "\n", "        ", "self", ".", "safety_threshold", "=", "safety_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.EnsembleTestPolicy.select_action": [[20, 32], ["numpy.mean", "numpy.argmax", "numpy.std", "len"], "methods", ["None"], ["", "def", "select_action", "(", "self", ",", "q_values_all_nets", ")", ":", "\n", "        ", "mean_q_values", "=", "np", ".", "mean", "(", "q_values_all_nets", ",", "axis", "=", "0", ")", "\n", "action", "=", "np", ".", "argmax", "(", "mean_q_values", ")", "\n", "if", "self", ".", "safety_threshold", "is", "None", ":", "\n", "            ", "return", "action", ",", "{", "}", "\n", "", "else", ":", "\n", "            ", "safety_level", "=", "np", ".", "std", "(", "q_values_all_nets", "[", ":", ",", "action", "]", ")", "\n", "if", "safety_level", ">", "self", ".", "safety_threshold", ":", "\n", "# Safe action defined as one step higher than normal action range", "\n", "                ", "return", "len", "(", "mean_q_values", ")", ",", "{", "'safe_action'", ":", "True", ",", "'original_action'", ":", "action", "}", "\n", "", "else", ":", "\n", "                ", "return", "action", ",", "{", "'safe_action'", ":", "False", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.EnsembleTestPolicy.get_config": [[33, 37], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "EnsembleTestPolicy", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", "[", "'safety_threshold'", "]", "=", "self", ".", "safety_threshold", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalTestPolicy.__init__": [[52, 54], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "safety_threshold", "=", "None", ")", ":", "\n", "        ", "self", ".", "safety_threshold", "=", "safety_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalTestPolicy.select_action": [[55, 68], ["numpy.mean", "numpy.argmax", "numpy.std", "len"], "methods", ["None"], ["", "def", "select_action", "(", "self", ",", "z_values", ")", ":", "\n", "        ", "q_values", "=", "np", ".", "mean", "(", "z_values", ",", "axis", "=", "0", ")", "\n", "action", "=", "np", ".", "argmax", "(", "q_values", ")", "\n", "\n", "if", "self", ".", "safety_threshold", "is", "None", ":", "\n", "            ", "return", "action", ",", "{", "}", "\n", "", "else", ":", "\n", "            ", "safety_level", "=", "np", ".", "std", "(", "z_values", "[", ":", ",", "action", "]", ")", "\n", "if", "safety_level", ">", "self", ".", "safety_threshold", ":", "\n", "# Safe action defined as one step higher than normal action range", "\n", "                ", "return", "len", "(", "q_values", ")", ",", "{", "'safe_action'", ":", "True", ",", "'original_action'", ":", "action", "}", "\n", "", "else", ":", "\n", "                ", "return", "action", ",", "{", "'safe_action'", ":", "False", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalTestPolicy.get_config": [[69, 73], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "DistributionalTestPolicy", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", "[", "'safety_threshold'", "]", "=", "self", ".", "safety_threshold", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEpsGreedyPolicy.__init__": [[85, 87], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "eps", ")", ":", "\n", "        ", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEpsGreedyPolicy.select_action": [[88, 97], ["numpy.random.randint", "numpy.argmax", "numpy.random.uniform", "numpy.sum"], "methods", ["None"], ["", "def", "select_action", "(", "self", ",", "z_values", ")", ":", "\n", "        ", "nb_actions", "=", "z_values", ".", "shape", "[", "-", "1", "]", "\n", "\n", "# First argument (self.eps > 0) avoids call to np.random for greedy policy. Needed for repeatability.", "\n", "if", "self", ".", "eps", ">", "0", "and", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "eps", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "nb_actions", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "argmax", "(", "np", ".", "sum", "(", "z_values", ",", "axis", "=", "-", "2", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "return", "action", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEpsGreedyPolicy.get_config": [[98, 102], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "DistributionalEpsGreedyPolicy", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", "[", "'eps'", "]", "=", "self", ".", "eps", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.__init__": [[118, 121], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "aleatoric_threshold", "=", "None", ",", "epistemic_threshold", "=", "None", ")", ":", "\n", "        ", "self", ".", "aleatoric_threshold", "=", "aleatoric_threshold", "\n", "self", ".", "epistemic_threshold", "=", "epistemic_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action": [[122, 150], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.argmax", "numpy.std", "len", "numpy.std", "len", "numpy.std", "numpy.std", "len"], "methods", ["None"], ["", "def", "select_action", "(", "self", ",", "z_values_all_nets", ")", ":", "\n", "        ", "mean_z_values", "=", "np", ".", "mean", "(", "z_values_all_nets", ",", "axis", "=", "-", "3", ")", "\n", "q_values_all_nets", "=", "np", ".", "mean", "(", "z_values_all_nets", ",", "axis", "=", "-", "2", ")", "\n", "mean_q_values", "=", "np", ".", "mean", "(", "mean_z_values", ",", "axis", "=", "-", "2", ")", "\n", "action", "=", "np", ".", "argmax", "(", "mean_q_values", ",", "axis", "=", "-", "1", ")", "\n", "\n", "if", "not", "(", "self", ".", "aleatoric_threshold", "or", "self", ".", "epistemic_threshold", ")", ":", "\n", "            ", "return", "action", ",", "{", "}", "\n", "", "elif", "self", ".", "aleatoric_threshold", "and", "not", "self", ".", "epistemic_threshold", ":", "\n", "            ", "if", "np", ".", "std", "(", "mean_z_values", "[", ":", ",", "action", "]", ")", ">", "self", ".", "aleatoric_threshold", ":", "\n", "# Safe action defined as one step higher than normal action range", "\n", "                ", "return", "len", "(", "mean_q_values", ")", ",", "{", "'safe_action'", ":", "True", ",", "'original_action'", ":", "action", "}", "\n", "", "else", ":", "\n", "                ", "return", "action", ",", "{", "'safe_action'", ":", "False", "}", "\n", "", "", "elif", "self", ".", "epistemic_threshold", "and", "not", "self", ".", "aleatoric_threshold", ":", "\n", "            ", "if", "np", ".", "std", "(", "q_values_all_nets", "[", ":", ",", "action", "]", ")", ">", "self", ".", "epistemic_threshold", ":", "\n", "# Safe action defined as one step higher than normal action range", "\n", "                ", "return", "len", "(", "mean_q_values", ")", ",", "{", "'safe_action'", ":", "True", ",", "'original_action'", ":", "action", "}", "\n", "", "else", ":", "\n", "                ", "return", "action", ",", "{", "'safe_action'", ":", "False", "}", "\n", "", "", "else", ":", "\n", "            ", "if", "np", ".", "std", "(", "mean_z_values", "[", ":", ",", "action", "]", ")", ">", "self", ".", "aleatoric_threshold", "or", "np", ".", "std", "(", "q_values_all_nets", "[", ":", ",", "action", "]", ")", ">", "self", ".", "epistemic_threshold", ":", "\n", "# Safe action defined as one step higher than normal action range", "\n", "                ", "return", "len", "(", "mean_q_values", ")", ",", "{", "'safe_action'", ":", "True", ",", "'original_action'", ":", "action", "}", "\n", "", "else", ":", "\n", "                ", "return", "action", ",", "{", "'safe_action'", ":", "False", "}", "\n", "", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.get_config": [[151, 156], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "DistributionalEnsembleTestPolicy", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", "[", "'aleatoric_threshold'", "]", "=", "self", ".", "aleatoric_threshold", "\n", "config", "[", "'epistemic_threshold'", "]", "=", "self", ".", "epistemic_threshold", "\n", "return", "config", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.__init__": [[37, 85], ["core.Agent.__init__", "int", "len", "numpy.random.randint", "iqn_ensemble.IqnRpfAgent.reset_states", "ValueError", "hasattr", "ValueError", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states"], ["def", "__init__", "(", "self", ",", "models", ",", "nb_actions", ",", "memory", ",", "gamma", ",", "batch_size", ",", "nb_steps_warmup", ",", "train_interval", ",", "memory_interval", ",", "\n", "target_model_update", ",", "delta_clip", ",", "policy", ",", "test_policy", ",", "enable_double_dqn", ",", "nb_samples_policy", ",", "\n", "nb_sampled_quantiles", ",", "cvar_eta", ",", "custom_model_objects", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "IqnRpfAgent", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Parameters.", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "nb_steps_warmup", "=", "nb_steps_warmup", "\n", "self", ".", "train_interval", "=", "train_interval", "\n", "self", ".", "memory_interval", "=", "memory_interval", "\n", "self", ".", "target_model_update", "=", "int", "(", "target_model_update", ")", "\n", "self", ".", "delta_clip", "=", "delta_clip", "\n", "self", ".", "custom_model_objects", "=", "{", "}", "if", "custom_model_objects", "is", "None", "else", "custom_model_objects", "\n", "self", ".", "enable_double_dqn", "=", "enable_double_dqn", "\n", "self", ".", "nb_samples_policy", "=", "nb_samples_policy", "\n", "self", ".", "nb_sampled_quantiles", "=", "nb_sampled_quantiles", "\n", "self", ".", "cvar_eta", "=", "cvar_eta", "\n", "\n", "# Related objects.", "\n", "self", ".", "memory", "=", "memory", "\n", "self", ".", "models", "=", "models", "\n", "self", ".", "nb_models", "=", "len", "(", "self", ".", "models", ")", "\n", "self", ".", "active_model", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "nb_models", ")", "\n", "self", ".", "policy", "=", "policy", "\n", "self", ".", "test_policy", "=", "test_policy", "\n", "self", ".", "trainable_models", "=", "[", "]", "\n", "self", ".", "target_models", "=", "None", "\n", "\n", "# State.", "\n", "self", ".", "compiled", "=", "False", "\n", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "self", ".", "reset_states", "(", ")", "\n", "self", ".", "parallel", "=", "False", "\n", "\n", "# Validate (important) input.", "\n", "if", "models", "[", "0", "]", "is", "not", "None", ":", "# For parallel case", "\n", "            ", "if", "hasattr", "(", "models", "[", "0", "]", ".", "output", ",", "'__len__'", ")", "and", "len", "(", "models", "[", "0", "]", ".", "output", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Model \"{}\" has more than one output. EQN expects a model that has a single output.'", ".", "format", "(", "models", "[", "0", "]", ")", ")", "\n", "", "if", "models", "[", "0", "]", ".", "output", ".", "_keras_shape", "!=", "(", "None", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Model output \"{}\" has invalid shape.'", ")", "\n", "", "", "if", "not", "self", ".", "nb_samples_policy", "==", "self", ".", "nb_sampled_quantiles", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'For practical reasons, for now, nb_samples_policy and nb_sampled_quantiles have to be equal'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.quantile_huber_loss": [[86, 121], ["keras.concatenate", "keras.concatenate", "numpy.isinf", "keras.repeat", "keras.permute_dimensions", "hasattr", "keras.backend", "hasattr", "keras.squeeze", "tf.select", "tf.where", "tf.roll", "keras.square", "keras.abs", "keras.square", "tf.select", "tf.where", "keras.int_shape", "tf.roll", "range", "range", "keras.abs", "keras.int_shape", "keras.int_shape"], "methods", ["None"], ["", "", "def", "quantile_huber_loss", "(", "self", ",", "y_true", ",", "y_pred", ",", "tau", ",", "clip_value", ")", ":", "\n", "        ", "\"\"\" Calculate the quantile huber loss, see the paper for details. \"\"\"", "\n", "assert", "K", ".", "backend", "(", ")", "==", "'tensorflow'", "# Only works with tensorflow for now. Minor changes are required to support other backends.", "\n", "import", "tensorflow", "as", "tf", "\n", "assert", "clip_value", ">", "0.", "\n", "\n", "# x = y_true - y_pred", "\n", "x", "=", "K", ".", "concatenate", "(", "[", "y_true", "-", "tf", ".", "roll", "(", "y_pred", ",", "axis", "=", "1", ",", "shift", "=", "i", ")", "for", "i", "in", "range", "(", "K", ".", "int_shape", "(", "y_pred", ")", "[", "-", "2", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "tau_expanded", "=", "K", ".", "concatenate", "(", "[", "tf", ".", "roll", "(", "tau", ",", "axis", "=", "2", ",", "shift", "=", "i", ")", "for", "i", "in", "range", "(", "K", ".", "int_shape", "(", "y_pred", ")", "[", "-", "2", "]", ")", "]", ",", "axis", "=", "2", ")", "\n", "\n", "if", "np", ".", "isinf", "(", "clip_value", ")", ":", "\n", "# Special case for infinity since Tensorflow does have problems", "\n", "# if we compare `K.abs(x) < np.inf`.", "\n", "            ", "huber_loss", "=", ".5", "*", "K", ".", "square", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "condition", "=", "K", ".", "abs", "(", "x", ")", "<", "clip_value", "\n", "squared_loss", "=", ".5", "*", "K", ".", "square", "(", "x", ")", "\n", "linear_loss", "=", "clip_value", "*", "(", "K", ".", "abs", "(", "x", ")", "-", ".5", "*", "clip_value", ")", "\n", "if", "hasattr", "(", "tf", ",", "'select'", ")", ":", "\n", "                ", "huber_loss", "=", "tf", ".", "select", "(", "condition", ",", "squared_loss", ",", "linear_loss", ")", "# condition, true, false", "\n", "", "else", ":", "\n", "                ", "huber_loss", "=", "tf", ".", "where", "(", "condition", ",", "squared_loss", ",", "linear_loss", ")", "# condition, true, false", "\n", "\n", "", "", "quantile_regression_condition", "=", "x", "<", "0", "\n", "tau_expanded", "=", "K", ".", "repeat", "(", "K", ".", "squeeze", "(", "tau_expanded", ",", "axis", "=", "1", ")", ",", "K", ".", "int_shape", "(", "y_pred", ")", "[", "-", "1", "]", ")", "\n", "tau_expanded", "=", "K", ".", "permute_dimensions", "(", "tau_expanded", ",", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "quantile_minus_loss", "=", "(", "1", "-", "tau_expanded", ")", "*", "huber_loss", "/", "clip_value", "\n", "quantile_plus_loss", "=", "tau_expanded", "*", "huber_loss", "/", "clip_value", "\n", "\n", "if", "hasattr", "(", "tf", ",", "'select'", ")", ":", "\n", "            ", "return", "tf", ".", "select", "(", "quantile_regression_condition", ",", "quantile_minus_loss", ",", "\n", "quantile_plus_loss", ")", "# condition, true, false", "\n", "", "else", ":", "\n", "            ", "return", "tf", ".", "where", "(", "quantile_regression_condition", ",", "quantile_minus_loss", ",", "\n", "quantile_plus_loss", ")", "# condition, true, false", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.clipped_masked_quantile_error": [[122, 128], ["iqn_ensemble.IqnRpfAgent.quantile_huber_loss", "keras.repeat", "keras.sum", "keras.int_shape", "keras.sum", "keras.int_shape"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.quantile_huber_loss"], ["", "", "def", "clipped_masked_quantile_error", "(", "self", ",", "args", ")", ":", "\n", "        ", "y_true", ",", "y_pred", ",", "tau", ",", "mask", "=", "args", "\n", "loss", "=", "self", ".", "quantile_huber_loss", "(", "y_true", ",", "y_pred", ",", "tau", ",", "self", ".", "delta_clip", ")", "\n", "mask_expanded", "=", "K", ".", "repeat", "(", "mask", ",", "K", ".", "int_shape", "(", "loss", ")", "[", "-", "2", "]", ")", "\n", "loss", "*=", "mask_expanded", "# apply element-wise mask", "\n", "return", "K", ".", "sum", "(", "K", ".", "sum", "(", "loss", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "-", "1", ")", "/", "K", ".", "int_shape", "(", "y_true", ")", "[", "-", "2", "]", "# Divide by N'", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.max_q": [[129, 131], ["keras.mean", "keras.max", "keras.mean"], "methods", ["None"], ["", "def", "max_q", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "# Returns average maximum Q-value of training batch", "\n", "        ", "return", "K", ".", "mean", "(", "K", ".", "max", "(", "K", ".", "mean", "(", "y_pred", ",", "axis", "=", "-", "2", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.mean_q": [[132, 134], ["keras.mean", "keras.mean", "keras.mean"], "methods", ["None"], ["", "def", "mean_q", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "# Returns average Q-value of training batch", "\n", "        ", "return", "K", ".", "mean", "(", "K", ".", "mean", "(", "K", ".", "mean", "(", "y_pred", ",", "axis", "=", "-", "2", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.change_active_model": [[135, 139], ["numpy.random.randint"], "methods", ["None"], ["", "def", "change_active_model", "(", "self", ")", ":", "\n", "        ", "\"\"\" Change which ensemble member that chooses the actions for each training episode.\"\"\"", "\n", "# Note, UpdateActiveModelCallback from dqn_ensemble.py is used to call this function.", "\n", "self", ".", "active_model", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "nb_models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.compile": [[140, 174], ["range", "rl.util.clone_model", "iqn_ensemble.IqnRpfAgent.target_models[].compile", "iqn_ensemble.IqnRpfAgent.models[].compile", "keras.layers.Input", "keras.layers.Input", "keras.models.Model", "keras.models.Model.compile", "iqn_ensemble.IqnRpfAgent.trainable_models.append", "keras.layers.Lambda", "len", "type", "keras.zeros_like"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "compile", "(", "self", ",", "optimizer", ",", "metrics", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\" Calculate the quantile huber loss, see the paper for details. \"\"\"", "\n", "metrics", "+=", "[", "self", ".", "mean_q", "]", "# register default metrics", "\n", "metrics", "+=", "[", "self", ".", "max_q", "]", "\n", "\n", "# We never train the target model, hence we can set the optimizer and loss arbitrarily.", "\n", "self", ".", "target_models", "=", "[", "clone_model", "(", "model", ",", "self", ".", "custom_model_objects", ")", "for", "model", "in", "self", ".", "models", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "self", ".", "target_models", "[", "i", "]", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "self", ".", "models", "[", "i", "]", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "\n", "# Compile model.", "\n", "# Create trainable model. The problem is that we need to mask the output since we only", "\n", "# ever want to update the Q values for a certain action. The way we achieve this is by", "\n", "# using a custom Lambda layer that computes the loss. This gives us the necessary flexibility", "\n", "# to mask out certain parameters by passing in multiple inputs to the Lambda layer.", "\n", "", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "y_pred", "=", "model", ".", "output", "\n", "tau", "=", "model", ".", "input", "[", "1", "]", "\n", "y_true", "=", "Input", "(", "name", "=", "'y_true'", ",", "shape", "=", "(", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ",", ")", ")", "\n", "mask", "=", "Input", "(", "name", "=", "'mask'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "loss_out", "=", "Lambda", "(", "self", ".", "clipped_masked_quantile_error", ",", "output_shape", "=", "(", "1", ",", ")", ",", "name", "=", "'loss'", ")", "(", "[", "y_true", ",", "y_pred", ",", "tau", ",", "mask", "]", ")", "\n", "ins", "=", "[", "model", ".", "input", "]", "if", "type", "(", "model", ".", "input", ")", "is", "not", "list", "else", "model", ".", "input", "\n", "trainable_model", "=", "Model", "(", "inputs", "=", "ins", "+", "[", "y_true", ",", "mask", "]", ",", "outputs", "=", "[", "loss_out", ",", "y_pred", "]", ")", "\n", "assert", "len", "(", "trainable_model", ".", "output_names", ")", "==", "2", "\n", "combined_metrics", "=", "{", "trainable_model", ".", "output_names", "[", "1", "]", ":", "metrics", "}", "\n", "losses", "=", "[", "\n", "lambda", "y_true", ",", "y_pred", ":", "y_pred", ",", "# loss is computed in Lambda layer", "\n", "lambda", "y_true", ",", "y_pred", ":", "K", ".", "zeros_like", "(", "y_pred", ")", ",", "# we only include this for the metrics", "\n", "]", "\n", "trainable_model", ".", "compile", "(", "optimizer", "=", "optimizer", ",", "loss", "=", "losses", ",", "metrics", "=", "combined_metrics", ")", "\n", "self", ".", "trainable_models", ".", "append", "(", "trainable_model", ")", "\n", "\n", "", "self", ".", "compiled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.load_weights": [[175, 179], ["enumerate", "iqn_ensemble.IqnRpfAgent.update_target_models_hard", "model.load_weights", "str"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.update_target_models_hard", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.load_weights"], ["", "def", "load_weights", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "model", ".", "load_weights", "(", "filepath", "+", "'_'", "+", "str", "(", "i", ")", ")", "\n", "", "self", ".", "update_target_models_hard", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.save_weights": [[180, 183], ["enumerate", "model.save_weights", "str"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.save_weights"], ["", "def", "save_weights", "(", "self", ",", "filepath", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "model", ".", "save_weights", "(", "filepath", "+", "\"_\"", "+", "str", "(", "i", ")", ",", "overwrite", "=", "overwrite", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.reset_states": [[184, 191], ["range", "iqn_ensemble.IqnRpfAgent.models[].reset_states", "iqn_ensemble.IqnRpfAgent.target_models[].reset_states"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states"], ["", "", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "                ", "self", ".", "models", "[", "i", "]", ".", "reset_states", "(", ")", "\n", "self", ".", "target_models", "[", "i", "]", ".", "reset_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.update_target_models_hard": [[192, 196], ["enumerate", "target_model.set_weights", "iqn_ensemble.IqnRpfAgent.models[].get_weights"], "methods", ["None"], ["", "", "", "def", "update_target_models_hard", "(", "self", ")", ":", "\n", "        ", "\"\"\" Copy current network parameters to the target network. \"\"\"", "\n", "for", "i", ",", "target_model", "in", "enumerate", "(", "self", ".", "target_models", ")", ":", "\n", "            ", "target_model", ".", "set_weights", "(", "self", ".", "models", "[", "i", "]", ".", "get_weights", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.compute_batch_z_values": [[197, 202], ["iqn_ensemble.IqnRpfAgent.process_state_batch", "iqn_ensemble.IqnRpfAgent.models[].predict_on_batch", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "", "def", "compute_batch_z_values", "(", "self", ",", "state_batch", ",", "tau_batch", ",", "net", ")", ":", "\n", "        ", "batch", "=", "self", ".", "process_state_batch", "(", "state_batch", ")", "\n", "z_values", "=", "self", ".", "models", "[", "net", "]", ".", "predict_on_batch", "(", "[", "batch", ",", "tau_batch", "]", ")", "\n", "assert", "z_values", ".", "shape", "==", "(", "len", "(", "state_batch", ")", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "return", "z_values", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.compute_sampled_z_values": [[203, 208], ["iqn_ensemble.IqnRpfAgent.sample_tau_values", "iqn_ensemble.IqnRpfAgent.compute_batch_z_values"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_batch_z_values"], ["", "def", "compute_sampled_z_values", "(", "self", ",", "state", ",", "max_tau", ",", "net", ")", ":", "\n", "        ", "tau", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "max_tau", ")", "\n", "z_values", "=", "self", ".", "compute_batch_z_values", "(", "[", "state", "]", ",", "tau", ",", "net", ")", "\n", "assert", "z_values", ".", "shape", "==", "(", "1", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "return", "z_values", ",", "tau", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.compute_z_values_all_nets": [[209, 217], ["iqn_ensemble.IqnRpfAgent.sample_tau_values", "range", "numpy.array", "numpy.array.append", "numpy.squeeze", "iqn_ensemble.IqnRpfAgent.compute_batch_z_values"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_batch_z_values"], ["", "def", "compute_z_values_all_nets", "(", "self", ",", "state", ",", "max_tau", ")", ":", "\n", "        ", "tau", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "max_tau", ",", "uniform", "=", "True", ")", "\n", "z_values_all_nets", "=", "[", "]", "\n", "for", "net", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "z_values_all_nets", ".", "append", "(", "np", ".", "squeeze", "(", "self", ".", "compute_batch_z_values", "(", "[", "state", "]", ",", "tau", ",", "net", ")", ",", "axis", "=", "0", ")", ")", "\n", "", "z_values_all_nets", "=", "np", ".", "array", "(", "z_values_all_nets", ")", "\n", "assert", "z_values_all_nets", ".", "shape", "==", "(", "self", ".", "nb_models", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "return", "z_values_all_nets", ",", "tau", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.sample_tau_values": [[218, 223], ["numpy.linspace", "numpy.random.rand"], "methods", ["None"], ["", "def", "sample_tau_values", "(", "self", ",", "max_tau", ",", "batch_size", "=", "1", ",", "uniform", "=", "False", ")", ":", "\n", "        ", "if", "uniform", ":", "\n", "            ", "return", "np", ".", "linspace", "(", "0", ",", "max_tau", ",", "self", ".", "nb_sampled_quantiles", ")", "[", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "1", ",", "self", ".", "nb_sampled_quantiles", ")", "*", "max_tau", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.forward": [[224, 263], ["iqn_ensemble.IqnRpfAgent.memory.get_recent_state", "iqn_ensemble.IqnRpfAgent.compute_sampled_z_values", "numpy.squeeze", "numpy.squeeze", "iqn_ensemble.IqnRpfAgent.policy.select_action", "numpy.mean", "info.update", "iqn_ensemble.IqnRpfAgent.compute_z_values_all_nets", "iqn_ensemble.IqnRpfAgent.test_policy.select_action", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "numpy.std", "info.update"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.compute_z_values_all_nets", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["", "", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "\"\"\"\n        Ask the agent to choose an action based on the current observation.\n        Args:\n            observation (ndarray): Current observation.\n\n        Returns:\n            action (int): Index of chosen action\n            info (dict): Information about the Q-values of the chosen action.\n        \"\"\"", "\n", "info", "=", "{", "}", "\n", "# Select an action.", "\n", "state", "=", "self", ".", "memory", ".", "get_recent_state", "(", "observation", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "z_values", ",", "tau", "=", "self", ".", "compute_sampled_z_values", "(", "state", ",", "max_tau", "=", "self", ".", "cvar_eta", ",", "net", "=", "self", ".", "active_model", ")", "\n", "tau", "=", "np", ".", "squeeze", "(", "tau", ")", "\n", "z_values", "=", "np", ".", "squeeze", "(", "z_values", ",", "axis", "=", "0", ")", "\n", "action", ",", "policy_info", "=", "self", ".", "policy", ".", "select_action", "(", "z_values", "=", "z_values", ")", "\n", "info", "[", "'z_values'", "]", "=", "z_values", "\n", "info", "[", "'quantiles'", "]", "=", "tau", "\n", "info", "[", "'q_values'", "]", "=", "np", ".", "mean", "(", "z_values", ",", "axis", "=", "-", "2", ")", "\n", "info", ".", "update", "(", "policy_info", ")", "\n", "", "else", ":", "\n", "            ", "z_values_all_nets", ",", "tau", "=", "self", ".", "compute_z_values_all_nets", "(", "state", ",", "max_tau", "=", "self", ".", "cvar_eta", ")", "\n", "action", ",", "policy_info", "=", "self", ".", "test_policy", ".", "select_action", "(", "z_values_all_nets", "=", "z_values_all_nets", ")", "\n", "info", "[", "'z_values_all_nets'", "]", "=", "z_values_all_nets", "\n", "info", "[", "'quantiles'", "]", "=", "tau", "\n", "info", "[", "'q_values_all_nets'", "]", "=", "np", ".", "mean", "(", "z_values_all_nets", ",", "axis", "=", "-", "2", ")", "\n", "info", "[", "'q_values'", "]", "=", "np", ".", "mean", "(", "z_values_all_nets", ",", "axis", "=", "(", "0", ",", "1", ")", ")", "\n", "info", "[", "'z_values'", "]", "=", "np", ".", "mean", "(", "z_values_all_nets", ",", "axis", "=", "0", ")", "\n", "info", "[", "'aleatoric_std_dev'", "]", "=", "np", ".", "std", "(", "info", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", "\n", "info", "[", "'epistemic_std_dev'", "]", "=", "np", ".", "std", "(", "info", "[", "'q_values_all_nets'", "]", ",", "axis", "=", "0", ")", "\n", "info", ".", "update", "(", "policy_info", ")", "\n", "\n", "# Book-keeping.", "\n", "", "self", ".", "recent_observation", "=", "observation", "\n", "self", ".", "recent_action", "=", "action", "\n", "\n", "return", "action", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.backward": [[264, 280], ["range", "iqn_ensemble.IqnRpfAgent.memory.append", "iqn_ensemble.IqnRpfAgent.train_single_net", "iqn_ensemble.IqnRpfAgent.update_target_models_hard"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.train_single_net", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.update_target_models_hard"], ["", "def", "backward", "(", "self", ",", "reward", ",", "terminal", ")", ":", "\n", "        ", "\"\"\" Store the most recent experience in the replay memory and update all ensemble networks. \"\"\"", "\n", "\n", "# Store most recent experience in memory.", "\n", "if", "self", ".", "step", "%", "self", ".", "memory_interval", "==", "0", ":", "\n", "            ", "self", ".", "memory", ".", "append", "(", "self", ".", "recent_observation", ",", "self", ".", "recent_action", ",", "reward", ",", "terminal", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "metrics", "=", "None", "\n", "for", "active_net", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "metrics", "=", "self", ".", "train_single_net", "(", "active_net", ")", "\n", "\n", "", "if", "self", ".", "target_model_update", ">=", "1", "and", "self", ".", "step", "%", "self", ".", "target_model_update", "==", "0", ":", "\n", "            ", "self", ".", "update_target_models_hard", "(", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.train_single_net": [[281, 364], ["iqn_ensemble.IqnRpfAgent.memory.sample", "iqn_ensemble.IqnRpfAgent.process_state_batch", "iqn_ensemble.IqnRpfAgent.process_state_batch", "numpy.array", "numpy.array", "iqn_ensemble.IqnRpfAgent.sample_tau_values", "iqn_ensemble.IqnRpfAgent.policy.select_action", "iqn_ensemble.IqnRpfAgent.sample_tau_values", "iqn_ensemble.IqnRpfAgent.target_models[].predict_on_batch", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.array().astype", "numpy.array().astype", "iqn_ensemble.IqnRpfAgent.sample_tau_values", "iqn_ensemble.IqnRpfAgent.trainable_models[].train_on_batch", "len", "iqn_ensemble.IqnRpfAgent.append", "iqn_ensemble.IqnRpfAgent.append", "numpy.array.append", "action_batch.append", "numpy.array.append", "len", "len", "iqn_ensemble.IqnRpfAgent.models[].predict_on_batch", "iqn_ensemble.IqnRpfAgent.target_models[].predict_on_batch", "zip", "numpy.array", "numpy.array", "enumerate", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "train_single_net", "(", "self", ",", "active_net", ")", ":", "\n", "        ", "\"\"\" Retrieve a batch of experiences from the replay memory of the specified ensemble member and update\n        the network weights. \"\"\"", "\n", "\n", "metrics", "=", "[", "np", ".", "nan", "for", "_", "in", "self", ".", "metrics_names", "]", "\n", "if", "not", "self", ".", "training", ":", "\n", "# We're done here. No need to update the experience memory since we only use the working", "\n", "# memory to obtain the state over the most recent observations.", "\n", "            ", "return", "metrics", "\n", "\n", "# Train the network on a single stochastic batch.", "\n", "", "if", "self", ".", "step", ">", "self", ".", "nb_steps_warmup", "and", "self", ".", "step", "%", "self", ".", "train_interval", "==", "0", ":", "\n", "            ", "experiences", "=", "self", ".", "memory", ".", "sample", "(", "active_net", ",", "self", ".", "batch_size", ")", "\n", "assert", "len", "(", "experiences", ")", "==", "self", ".", "batch_size", "\n", "\n", "# Start by extracting the necessary parameters (we use a vectorized implementation).", "\n", "state0_batch", "=", "[", "]", "\n", "reward_batch", "=", "[", "]", "\n", "action_batch", "=", "[", "]", "\n", "terminal1_batch", "=", "[", "]", "\n", "state1_batch", "=", "[", "]", "\n", "for", "e", "in", "experiences", ":", "\n", "                ", "state0_batch", ".", "append", "(", "e", ".", "state0", ")", "\n", "state1_batch", ".", "append", "(", "e", ".", "state1", ")", "\n", "reward_batch", ".", "append", "(", "e", ".", "reward", ")", "\n", "action_batch", ".", "append", "(", "e", ".", "action", ")", "\n", "terminal1_batch", ".", "append", "(", "0.", "if", "e", ".", "terminal1", "else", "1.", ")", "\n", "\n", "# Prepare and validate parameters.", "\n", "", "state0_batch", "=", "self", ".", "process_state_batch", "(", "state0_batch", ")", "\n", "state1_batch", "=", "self", ".", "process_state_batch", "(", "state1_batch", ")", "\n", "terminal1_batch", "=", "np", ".", "array", "(", "terminal1_batch", ")", "\n", "reward_batch", "=", "np", ".", "array", "(", "reward_batch", ")", "\n", "assert", "reward_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "assert", "terminal1_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "assert", "len", "(", "action_batch", ")", "==", "len", "(", "reward_batch", ")", "\n", "\n", "# Compute Z values for mini-batch update.", "\n", "tau_values_policy", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "self", ".", "cvar_eta", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "if", "self", ".", "enable_double_dqn", ":", "\n", "                ", "z_values", "=", "self", ".", "models", "[", "active_net", "]", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_policy", "]", ")", "\n", "", "else", ":", "\n", "                ", "z_values", "=", "self", ".", "target_models", "[", "active_net", "]", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_policy", "]", ")", "\n", "", "assert", "z_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "actions", ",", "policy_info", "=", "self", ".", "policy", ".", "select_action", "(", "z_values", "=", "z_values", ")", "\n", "assert", "actions", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "tau_values_targets", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "1", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "target_z_values", "=", "self", ".", "target_models", "[", "active_net", "]", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_targets", "]", ")", "\n", "assert", "target_z_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "z_batch", "=", "target_z_values", "[", "range", "(", "self", ".", "batch_size", ")", ",", ":", ",", "actions", "]", "\n", "assert", "z_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ")", "\n", "\n", "targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", ")", "\n", "dummy_targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", ")", ")", "\n", "masks", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "\n", "# Compute r_t + gamma * max_a Q(s_t+1, a) and update the target targets accordingly,", "\n", "# but only for the affected output units (as given by action_batch).", "\n", "discounted_reward_batch", "=", "self", ".", "gamma", "*", "z_batch", "\n", "# Set discounted reward to zero for all states that were terminal.", "\n", "discounted_reward_batch", "*=", "terminal1_batch", "[", ":", ",", "None", "]", "\n", "assert", "discounted_reward_batch", ".", "shape", "[", "0", "]", "==", "reward_batch", ".", "shape", "[", "0", "]", "\n", "Rs", "=", "reward_batch", "[", ":", ",", "None", "]", "+", "discounted_reward_batch", "\n", "for", "idx", ",", "(", "target", ",", "mask", ",", "R", ",", "action", ")", "in", "enumerate", "(", "zip", "(", "targets", ",", "masks", ",", "Rs", ",", "action_batch", ")", ")", ":", "\n", "                ", "target", "[", ":", ",", "action", "]", "=", "R", "# update action with estimated accumulated reward", "\n", "dummy_targets", "[", "idx", ",", ":", "]", "=", "R", "\n", "mask", "[", "action", "]", "=", "1.", "# enable loss for this specific action", "\n", "", "targets", "=", "np", ".", "array", "(", "targets", ")", ".", "astype", "(", "'float32'", ")", "\n", "masks", "=", "np", ".", "array", "(", "masks", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "# Finally, perform a single update on the entire batch. We use a dummy target since", "\n", "# the actual loss is computed in a Lambda layer that needs more complex input. However,", "\n", "# it is still useful to know the actual target to compute metrics properly.", "\n", "tau_values", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "1", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "ins", "=", "[", "state0_batch", ",", "tau_values", "]", "\n", "metrics", "=", "self", ".", "trainable_models", "[", "active_net", "]", ".", "train_on_batch", "(", "ins", "+", "[", "targets", ",", "masks", "]", ",", "[", "dummy_targets", ",", "targets", "]", ")", "\n", "metrics", "=", "[", "metric", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "if", "\n", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "# throw away individual losses", "\n", "metrics", "+=", "self", ".", "policy", ".", "metrics", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                ", "metrics", "+=", "self", ".", "processor", ".", "metrics", "\n", "\n", "", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.process_state_batch": [[365, 370], ["numpy.array", "iqn_ensemble.IqnRpfAgent.processor.process_state_batch"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "process_state_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch", "=", "np", ".", "array", "(", "batch", ")", "\n", "if", "self", ".", "processor", "is", "None", ":", "\n", "            ", "return", "batch", "\n", "", "return", "self", ".", "processor", ".", "process_state_batch", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.get_config": [[371, 392], ["rl.util.get_object_config", "rl.util.get_object_config", "rl.util.get_object_config", "rl.util.get_object_config", "rl.util.get_object_config"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "'nb_actions'", ":", "self", ".", "nb_actions", ",", "\n", "'gamma'", ":", "self", ".", "gamma", ",", "\n", "'batch_size'", ":", "self", ".", "batch_size", ",", "\n", "'nb_steps_warmup'", ":", "self", ".", "nb_steps_warmup", ",", "\n", "'train_interval'", ":", "self", ".", "train_interval", ",", "\n", "'memory_interval'", ":", "self", ".", "memory_interval", ",", "\n", "'target_model_update'", ":", "self", ".", "target_model_update", ",", "\n", "'delta_clip'", ":", "self", ".", "delta_clip", ",", "\n", "'memory'", ":", "get_object_config", "(", "self", ".", "memory", ")", ",", "\n", "'enable_double_dqn'", ":", "self", ".", "enable_double_dqn", ",", "\n", "'nb_samples_policy'", ":", "self", ".", "nb_samples_policy", ",", "\n", "'nb_sampled_quantiles'", ":", "self", ".", "nb_sampled_quantiles", ",", "\n", "'models'", ":", "[", "get_object_config", "(", "model", ")", "for", "model", "in", "self", ".", "models", "]", ",", "\n", "'policy'", ":", "get_object_config", "(", "self", ".", "policy", ")", ",", "\n", "'test_policy'", ":", "get_object_config", "(", "self", ".", "test_policy", ")", ",", "\n", "}", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "config", "[", "'target_models'", "]", "=", "[", "get_object_config", "(", "target_model", ")", "for", "target_model", "in", "self", ".", "target_models", "]", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.layers": [[393, 397], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "'Not updated for ensemble!'", ")", "\n", "return", "self", ".", "model", ".", "layers", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.metrics_names": [[398, 410], ["len", "name.replace", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics_names", "(", "self", ")", ":", "\n", "# Throw away individual losses and replace output name since this is hidden from the user.", "\n", "        ", "assert", "len", "(", "self", ".", "trainable_models", "[", "0", "]", ".", "output_names", ")", "==", "2", "\n", "dummy_output_name", "=", "self", ".", "trainable_models", "[", "0", "]", ".", "output_names", "[", "1", "]", "\n", "model_metrics", "=", "[", "name", "for", "idx", ",", "name", "in", "enumerate", "(", "self", ".", "trainable_models", "[", "0", "]", ".", "metrics_names", ")", "if", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "\n", "model_metrics", "=", "[", "name", ".", "replace", "(", "dummy_output_name", "+", "'_'", ",", "''", ")", "for", "name", "in", "model_metrics", "]", "\n", "\n", "names", "=", "model_metrics", "+", "self", ".", "policy", ".", "metrics_names", "[", ":", "]", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "            ", "names", "+=", "self", ".", "processor", ".", "metrics_names", "[", ":", "]", "\n", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.policy": [[415, 419], ["iqn_ensemble.IqnRpfAgent.__policy._set_agent"], "methods", ["None"], ["", "@", "policy", ".", "setter", "\n", "def", "policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__policy", "=", "policy", "\n", "self", ".", "__policy", ".", "_set_agent", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.test_policy": [[424, 428], ["iqn_ensemble.IqnRpfAgent.__test_policy._set_agent"], "methods", ["None"], ["", "@", "test_policy", ".", "setter", "\n", "def", "test_policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__test_policy", "=", "policy", "\n", "self", ".", "__test_policy", ".", "_set_agent", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.__init__": [[477, 533], ["iqn_ensemble.IqnRpfAgent.__init__", "numpy.random.randint", "iqn_ensemble.IqnRpfAgentParallel.reset_states", "iqn_ensemble.IqnRpfAgentParallel.init_parallel_execution", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.init_parallel_execution"], ["def", "__init__", "(", "self", ",", "nb_models", ",", "nb_actions", ",", "memory", ",", "cnn_architecture", ",", "learning_rate", ",", "nb_ego_states", ",", "\n", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_conv_layers", ",", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "\n", "nb_hidden_neurons", ",", "nb_cos_embeddings", ",", "network_seed", ",", "prior_scale_factor", ",", "nb_samples_policy", ",", "\n", "nb_sampled_quantiles", ",", "cvar_eta", ",", "gamma", ",", "batch_size", ",", "nb_steps_warmup", ",", "train_interval", ",", "memory_interval", ",", "\n", "target_model_update", ",", "delta_clip", ",", "window_length", ",", "policy", ",", "test_policy", ",", "enable_double_dqn", ",", "\n", "enable_dueling_dqn", ",", "custom_model_objects", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "IqnRpfAgentParallel", ",", "self", ")", ".", "__init__", "(", "models", "=", "[", "None", "for", "_", "in", "range", "(", "nb_models", ")", "]", ",", "\n", "nb_actions", "=", "nb_actions", ",", "\n", "memory", "=", "memory", ",", "\n", "gamma", "=", "gamma", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "nb_steps_warmup", "=", "nb_steps_warmup", ",", "\n", "train_interval", "=", "train_interval", ",", "\n", "memory_interval", "=", "memory_interval", ",", "\n", "target_model_update", "=", "target_model_update", ",", "\n", "delta_clip", "=", "delta_clip", ",", "\n", "custom_model_objects", "=", "custom_model_objects", ",", "\n", "policy", "=", "policy", ",", "\n", "test_policy", "=", "test_policy", ",", "\n", "enable_double_dqn", "=", "enable_double_dqn", ",", "\n", "nb_samples_policy", "=", "nb_samples_policy", ",", "\n", "nb_sampled_quantiles", "=", "nb_sampled_quantiles", ",", "\n", "cvar_eta", "=", "cvar_eta", ",", "\n", ")", "\n", "\n", "# Parameters.", "\n", "self", ".", "enable_dueling_dqn", "=", "enable_dueling_dqn", "\n", "\n", "# Related objects.", "\n", "self", ".", "nb_models", "=", "nb_models", "\n", "self", ".", "active_model", "=", "np", ".", "random", ".", "randint", "(", "nb_models", ")", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "\n", "# Network parameters", "\n", "self", ".", "cnn_architecture", "=", "cnn_architecture", "\n", "self", ".", "nb_ego_states", "=", "nb_ego_states", "\n", "self", ".", "nb_states_per_vehicle", "=", "nb_states_per_vehicle", "\n", "self", ".", "nb_vehicles", "=", "nb_vehicles", "\n", "self", ".", "nb_conv_layers", "=", "nb_conv_layers", "\n", "self", ".", "nb_conv_filters", "=", "nb_conv_filters", "\n", "self", ".", "nb_hidden_fc_layers", "=", "nb_hidden_fc_layers", "\n", "self", ".", "nb_hidden_neurons", "=", "nb_hidden_neurons", "\n", "self", ".", "network_seed", "=", "network_seed", "\n", "self", ".", "prior_scale_factor", "=", "prior_scale_factor", "\n", "self", ".", "window_length", "=", "window_length", "\n", "self", ".", "nb_cos_embeddings", "=", "nb_cos_embeddings", "\n", "\n", "# State.", "\n", "self", ".", "reset_states", "(", ")", "\n", "\n", "self", ".", "parallel", "=", "True", "\n", "self", ".", "input_queues", "=", "None", "\n", "self", ".", "output_queues", "=", "None", "\n", "\n", "self", ".", "init_parallel_execution", "(", ")", "\n", "self", ".", "compiled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.init_parallel_execution": [[534, 559], ["range", "multiprocessing.Queue", "multiprocessing.Queue", "iqn_ensemble.Worker", "iqn_ensemble.IqnRpfAgentParallel.workers.append", "Worker.start", "range", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "init_parallel_execution", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initalize one worker for each ensemble member and set up corresponding queues. \"\"\"", "\n", "self", ".", "input_queues", "=", "[", "mp", ".", "Queue", "(", ")", "for", "_", "in", "range", "(", "self", ".", "nb_models", ")", "]", "\n", "self", ".", "output_queues", "=", "[", "mp", ".", "Queue", "(", ")", "for", "_", "in", "range", "(", "self", ".", "nb_models", ")", "]", "\n", "self", ".", "workers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "worker", "=", "Worker", "(", "self", ".", "network_seed", "+", "i", ",", "self", ".", "input_queues", "[", "i", "]", ",", "self", ".", "output_queues", "[", "i", "]", ",", "\n", "cnn_architecture", "=", "self", ".", "cnn_architecture", ",", "\n", "nb_ego_states", "=", "self", ".", "nb_ego_states", ",", "nb_states_per_vehicle", "=", "self", ".", "nb_states_per_vehicle", ",", "\n", "nb_vehicles", "=", "self", ".", "nb_vehicles", ",", "nb_actions", "=", "self", ".", "nb_actions", ",", "\n", "nb_conv_layers", "=", "self", ".", "nb_conv_layers", ",", "nb_conv_filters", "=", "self", ".", "nb_conv_filters", ",", "\n", "nb_hidden_fc_layers", "=", "self", ".", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", "=", "self", ".", "nb_hidden_neurons", ",", "\n", "nb_sampled_quantiles", "=", "self", ".", "nb_sampled_quantiles", ",", "nb_cos_embeddings", "=", "self", ".", "nb_cos_embeddings", ",", "\n", "cvar_eta", "=", "self", ".", "cvar_eta", ",", "\n", "duel", "=", "self", ".", "enable_dueling_dqn", ",", "prior_scale_factor", "=", "self", ".", "prior_scale_factor", ",", "\n", "window_length", "=", "self", ".", "window_length", ",", "\n", "processor", "=", "self", ".", "processor", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "enable_double_dqn", "=", "self", ".", "enable_double_dqn", ",", "gamma", "=", "self", ".", "gamma", ",", "lr", "=", "self", ".", "lr", ",", "\n", "delta_clip", "=", "self", ".", "delta_clip", ",", "target_model_update", "=", "self", ".", "target_model_update", ",", "\n", "policy", "=", "self", ".", "policy", ",", "mean_q", "=", "self", ".", "mean_q", ",", "max_q", "=", "self", ".", "max_q", ",", "\n", "clipped_masked_quantile_error", "=", "self", ".", "clipped_masked_quantile_error", ",", "\n", "sample_tau_values", "=", "self", ".", "sample_tau_values", ")", "\n", "self", ".", "workers", ".", "append", "(", "worker", ")", "\n", "", "for", "worker", "in", "self", ".", "workers", ":", "\n", "            ", "worker", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.get_config": [[560, 580], ["rl.util.get_object_config", "rl.util.get_object_config", "rl.util.get_object_config"], "methods", ["None"], ["", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "'nb_actions'", ":", "self", ".", "nb_actions", ",", "\n", "'gamma'", ":", "self", ".", "gamma", ",", "\n", "'batch_size'", ":", "self", ".", "batch_size", ",", "\n", "'nb_steps_warmup'", ":", "self", ".", "nb_steps_warmup", ",", "\n", "'train_interval'", ":", "self", ".", "train_interval", ",", "\n", "'memory_interval'", ":", "self", ".", "memory_interval", ",", "\n", "'target_model_update'", ":", "self", ".", "target_model_update", ",", "\n", "'delta_clip'", ":", "self", ".", "delta_clip", ",", "\n", "'memory'", ":", "get_object_config", "(", "self", ".", "memory", ")", ",", "\n", "'enable_double_dqn'", ":", "self", ".", "enable_double_dqn", ",", "\n", "'enable_dueling_dqn'", ":", "self", ".", "enable_dueling_dqn", ",", "\n", "'nb_samples_policy'", ":", "self", ".", "nb_samples_policy", ",", "\n", "'nb_sampled_quantiles'", ":", "self", ".", "nb_sampled_quantiles", ",", "\n", "# 'models':  [get_object_config(model) for model in self.models],", "\n", "'policy'", ":", "get_object_config", "(", "self", ".", "policy", ")", ",", "\n", "'test_policy'", ":", "get_object_config", "(", "self", ".", "test_policy", ")", ",", "\n", "}", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.get_model_as_string": [[581, 584], ["iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get"], "methods", ["None"], ["", "def", "get_model_as_string", "(", "self", ")", ":", "\n", "        ", "self", ".", "input_queues", "[", "0", "]", ".", "put", "(", "[", "'model_as_string'", "]", ")", "# All models are the same, so enough to get one of them", "\n", "return", "self", ".", "output_queues", "[", "0", "]", ".", "get", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.load_weights": [[585, 592], ["range", "iqn_ensemble.IqnRpfAgentParallel.update_target_model_hard", "iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get", "str"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard"], ["", "def", "load_weights", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "self", ".", "input_queues", "[", "i", "]", ".", "put", "(", "[", "'load_weights'", ",", "filepath", "+", "\"_\"", "+", "str", "(", "i", ")", "]", ")", "\n", "output", "=", "self", ".", "output_queues", "[", "i", "]", ".", "get", "(", ")", "\n", "proc_name", "=", "self", ".", "workers", "[", "i", "]", ".", "name", "\n", "assert", "(", "output", "==", "'weights_loaded_'", "+", "proc_name", ")", "\n", "", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.save_weights": [[593, 599], ["range", "iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get", "str"], "methods", ["None"], ["", "def", "save_weights", "(", "self", ",", "filepath", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "self", ".", "input_queues", "[", "i", "]", ".", "put", "(", "[", "'save_weights'", ",", "filepath", "+", "\"_\"", "+", "str", "(", "i", ")", ",", "overwrite", "]", ")", "\n", "output", "=", "self", ".", "output_queues", "[", "i", "]", ".", "get", "(", ")", "\n", "proc_name", "=", "self", ".", "workers", "[", "i", "]", ".", "name", "\n", "assert", "(", "output", "==", "'weights_saved_'", "+", "proc_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.reset_states": [[600, 609], ["range", "iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get"], "methods", ["None"], ["", "", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "                ", "self", ".", "input_queues", "[", "i", "]", ".", "put", "(", "[", "'reset_states'", "]", ")", "\n", "out", "=", "self", ".", "output_queues", "[", "i", "]", ".", "get", "(", ")", "\n", "proc_name", "=", "self", ".", "workers", "[", "i", "]", ".", "name", "\n", "assert", "(", "out", "==", "'reset_states_done_'", "+", "proc_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.update_target_model_hard": [[610, 617], ["range", "iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get"], "methods", ["None"], ["", "", "", "def", "update_target_model_hard", "(", "self", ")", ":", "\n", "        ", "\"\"\" Copy current network parameters to the target network. \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "self", ".", "input_queues", "[", "i", "]", ".", "put", "(", "[", "'update_target_model'", "]", ")", "\n", "output", "=", "self", ".", "output_queues", "[", "i", "]", ".", "get", "(", ")", "\n", "proc_name", "=", "self", ".", "workers", "[", "i", "]", ".", "name", "\n", "assert", "(", "output", "==", "'target_model_updated_'", "+", "proc_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.backward": [[618, 646], ["iqn_ensemble.IqnRpfAgentParallel.memory.append", "iqn_ensemble.IqnRpfAgentParallel.update_target_model_hard", "range", "range", "iqn_ensemble.IqnRpfAgentParallel.memory.sample", "iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample"], ["", "", "def", "backward", "(", "self", ",", "reward", ",", "terminal", ")", ":", "\n", "        ", "\"\"\" Store the most recent experience in the replay memory and update all ensemble networks. \"\"\"", "\n", "# Store most recent experience in memory.", "\n", "if", "self", ".", "step", "%", "self", ".", "memory_interval", "==", "0", ":", "\n", "            ", "self", ".", "memory", ".", "append", "(", "self", ".", "recent_observation", ",", "self", ".", "recent_action", ",", "reward", ",", "terminal", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "metrics", "=", "[", "np", ".", "nan", "for", "_", "in", "self", ".", "metrics_names", "]", "\n", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "step", ">", "self", ".", "nb_steps_warmup", "and", "self", ".", "step", "%", "self", ".", "train_interval", "==", "0", ":", "\n", "                ", "for", "net", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "                    ", "experiences", "=", "self", ".", "memory", ".", "sample", "(", "net", ",", "self", ".", "batch_size", ")", "\n", "assert", "len", "(", "experiences", ")", "==", "self", ".", "batch_size", "\n", "self", ".", "input_queues", "[", "net", "]", ".", "put", "(", "[", "'train'", ",", "experiences", "]", ")", "\n", "\n", "", "for", "net", "in", "range", "(", "self", ".", "nb_models", ")", ":", "# Wait for all workers to finish", "\n", "                    ", "output", "=", "self", ".", "output_queues", "[", "net", "]", ".", "get", "(", ")", "\n", "if", "net", "==", "self", ".", "nb_models", "-", "1", ":", "# Store the metrics of the last agent", "\n", "                        ", "metrics", "=", "output", "[", "1", "]", "\n", "", "proc_name", "=", "self", ".", "workers", "[", "net", "]", ".", "name", "\n", "assert", "(", "output", "[", "0", "]", "==", "'training_done_'", "+", "proc_name", ")", "\n", "\n", "metrics", "+=", "[", "self", ".", "active_model", "]", "\n", "\n", "", "", "", "if", "self", ".", "target_model_update", ">=", "1", "and", "self", ".", "step", "%", "self", ".", "target_model_update", "==", "0", ":", "\n", "            ", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n", "", "return", "metrics", "# This is only the metrics of the last agent.", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.compute_batch_z_values": [[647, 653], ["iqn_ensemble.IqnRpfAgentParallel.process_state_batch", "iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "compute_batch_z_values", "(", "self", ",", "state_batch", ",", "tau_batch", ",", "net", ")", ":", "\n", "        ", "batch", "=", "self", ".", "process_state_batch", "(", "state_batch", ")", "\n", "self", ".", "input_queues", "[", "net", "]", ".", "put", "(", "[", "'predict'", ",", "[", "batch", ",", "tau_batch", "]", "]", ")", "\n", "z_values", "=", "self", ".", "output_queues", "[", "net", "]", ".", "get", "(", ")", "\n", "assert", "z_values", ".", "shape", "==", "(", "len", "(", "state_batch", ")", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "return", "z_values", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgentParallel.metrics_names": [[654, 671], ["iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get", "iqn_ensemble.IqnRpfAgentParallel.input_queues[].put", "iqn_ensemble.IqnRpfAgentParallel.output_queues[].get", "len", "name.replace", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics_names", "(", "self", ")", ":", "\n", "# Throw away individual losses and replace output name since this is hidden from the user.", "\n", "        ", "self", ".", "input_queues", "[", "0", "]", ".", "put", "(", "[", "'output_names'", "]", ")", "\n", "output_names", "=", "self", ".", "output_queues", "[", "0", "]", ".", "get", "(", ")", "\n", "assert", "len", "(", "output_names", ")", "==", "2", "\n", "dummy_output_name", "=", "output_names", "[", "1", "]", "\n", "self", ".", "input_queues", "[", "0", "]", ".", "put", "(", "[", "'metrics_names'", "]", ")", "\n", "metrics_names_", "=", "self", ".", "output_queues", "[", "0", "]", ".", "get", "(", ")", "\n", "model_metrics", "=", "[", "name", "for", "idx", ",", "name", "in", "enumerate", "(", "metrics_names_", ")", "if", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "\n", "model_metrics", "=", "[", "name", ".", "replace", "(", "dummy_output_name", "+", "'_'", ",", "''", ")", "for", "name", "in", "model_metrics", "]", "\n", "\n", "names", "=", "model_metrics", "+", "self", ".", "policy", ".", "metrics_names", "[", ":", "]", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "            ", "names", "+=", "self", ".", "processor", ".", "metrics_names", "[", ":", "]", "\n", "", "names", "+=", "[", "\"active_model\"", "]", "\n", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.Worker.__init__": [[705, 748], ["multiprocessing.Process.__init__"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "seed", ",", "input_queue", ",", "output_queue", ",", "cnn_architecture", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "\n", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "duel", ",", "\n", "prior_scale_factor", ",", "nb_sampled_quantiles", ",", "nb_cos_embeddings", ",", "cvar_eta", ",", "window_length", ",", "processor", ",", "\n", "batch_size", ",", "enable_double_dqn", ",", "gamma", ",", "lr", ",", "delta_clip", ",", "target_model_update", ",", "policy", ",", "mean_q", ",", "max_q", ",", "\n", "clipped_masked_quantile_error", ",", "sample_tau_values", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "mp", ".", "Process", ".", "__init__", "(", "self", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "input_queue", "=", "input_queue", "\n", "self", ".", "output_queue", "=", "output_queue", "\n", "self", ".", "cnn_architecture", "=", "cnn_architecture", "\n", "self", ".", "nb_ego_states", "=", "nb_ego_states", "\n", "self", ".", "nb_states_per_vehicle", "=", "nb_states_per_vehicle", "\n", "self", ".", "nb_vehicles", "=", "nb_vehicles", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "self", ".", "nb_conv_layers", "=", "nb_conv_layers", "\n", "self", ".", "nb_conv_filters", "=", "nb_conv_filters", "\n", "self", ".", "nb_hidden_fc_layers", "=", "nb_hidden_fc_layers", "\n", "self", ".", "nb_hidden_neurons", "=", "nb_hidden_neurons", "\n", "self", ".", "nb_sampled_quantiles", "=", "nb_sampled_quantiles", "\n", "self", ".", "nb_cos_embeddings", "=", "nb_cos_embeddings", "\n", "self", ".", "cvar_eta", "=", "cvar_eta", "\n", "self", ".", "duel", "=", "duel", "\n", "self", ".", "prior_scale_factor", "=", "prior_scale_factor", "\n", "self", ".", "window_length", "=", "window_length", "\n", "\n", "self", ".", "processor", "=", "processor", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "enable_double_dqn", "=", "enable_double_dqn", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "target_model_update", "=", "target_model_update", "\n", "self", ".", "delta_clip", "=", "delta_clip", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "policy", "=", "policy", "\n", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "model", "=", "None", "\n", "self", ".", "target_model", "=", "None", "\n", "self", ".", "trainable_model", "=", "None", "\n", "\n", "self", ".", "mean_q", "=", "mean_q", "\n", "self", ".", "max_q", "=", "max_q", "\n", "self", ".", "clipped_masked_quantile_error", "=", "clipped_masked_quantile_error", "\n", "self", ".", "sample_tau_values", "=", "sample_tau_values", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.Worker.run": [[749, 811], ["numpy.random.seed", "iqn_ensemble.Worker.compile", "network_architecture_distributional.NetworkCNNDistributional", "network_architecture_distributional.NetworkMLPDistributional", "iqn_ensemble.Worker.input_queue.get", "iqn_ensemble.Worker.output_queue.put", "print", "iqn_ensemble.Worker.model.predict_on_batch", "iqn_ensemble.Worker.train_single_net", "iqn_ensemble.Worker.model.reset_states", "iqn_ensemble.Worker.target_model.reset_states", "iqn_ensemble.Worker.target_model.set_weights", "iqn_ensemble.Worker.model.get_weights", "iqn_ensemble.Worker.model.save_weights", "iqn_ensemble.Worker.model.load_weights", "iqn_ensemble.Worker.model.to_json", "Exception"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.train_single_net", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.save_weights", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.load_weights"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initializes individual networks and starts the workers for each ensemble member. \"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "proc_name", "=", "self", ".", "name", "\n", "if", "self", ".", "cnn_architecture", ":", "\n", "            ", "n", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "self", ".", "nb_ego_states", ",", "nb_states_per_vehicle", "=", "self", ".", "nb_states_per_vehicle", ",", "\n", "nb_vehicles", "=", "self", ".", "nb_vehicles", ",", "nb_actions", "=", "self", ".", "nb_actions", ",", "nb_conv_layers", "=", "self", ".", "nb_conv_layers", ",", "\n", "nb_conv_filters", "=", "self", ".", "nb_conv_filters", ",", "nb_hidden_fc_layers", "=", "self", ".", "nb_hidden_fc_layers", ",", "\n", "nb_hidden_neurons", "=", "self", ".", "nb_hidden_neurons", ",", "nb_quantiles", "=", "self", ".", "nb_sampled_quantiles", ",", "\n", "nb_cos_embeddings", "=", "self", ".", "nb_cos_embeddings", ",", "duel", "=", "self", ".", "duel", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "self", ".", "prior_scale_factor", ",", "window_length", "=", "self", ".", "window_length", ",", "\n", "activation", "=", "'relu'", ",", "duel_type", "=", "'avg'", ")", "\n", "", "else", ":", "\n", "            ", "n", "=", "NetworkMLPDistributional", "(", "nb_inputs", "=", "self", ".", "nb_ego_states", "+", "self", ".", "nb_vehicles", "*", "self", ".", "nb_states_per_vehicle", ",", "\n", "nb_outputs", "=", "self", ".", "nb_actions", ",", "\n", "nb_hidden_layers", "=", "self", ".", "nb_hidden_fc_layers", ",", "\n", "nb_hidden_neurons", "=", "self", ".", "nb_hidden_neurons", ",", "duel", "=", "self", ".", "duel", ",", "\n", "prior", "=", "True", ",", "nb_quantiles", "=", "self", ".", "nb_sampled_quantiles", ",", "\n", "nb_cos_embeddings", "=", "self", ".", "nb_cos_embeddings", ",", "\n", "activation", "=", "'relu'", ",", "\n", "prior_scale_factor", "=", "self", ".", "prior_scale_factor", ",", "duel_type", "=", "'avg'", ",", "\n", "window_length", "=", "self", ".", "window_length", ")", "\n", "", "self", ".", "model", "=", "n", ".", "model", "\n", "self", ".", "compile", "(", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "input_", "=", "self", ".", "input_queue", ".", "get", "(", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Read input proc \"", "+", "proc_name", "+", "' '", "+", "input_", "[", "0", "]", ")", "\n", "", "if", "input_", "is", "None", ":", "# If sending None, the process is killed", "\n", "                ", "break", "\n", "\n", "", "if", "input_", "[", "0", "]", "==", "'predict'", ":", "\n", "                ", "output", "=", "self", ".", "model", ".", "predict_on_batch", "(", "input_", "[", "1", "]", ")", "\n", "", "elif", "input_", "[", "0", "]", "==", "'train'", ":", "\n", "                ", "metrics", "=", "self", ".", "train_single_net", "(", "experiences", "=", "input_", "[", "1", "]", ")", "\n", "output", "=", "[", "'training_done_'", "+", "proc_name", ",", "metrics", "]", "\n", "", "elif", "input_", "[", "0", "]", "==", "'reset_states'", ":", "\n", "                ", "self", ".", "model", ".", "reset_states", "(", ")", "\n", "self", ".", "target_model", ".", "reset_states", "(", ")", "\n", "output", "=", "'reset_states_done_'", "+", "proc_name", "\n", "", "elif", "input_", "[", "0", "]", "==", "'update_target_model'", ":", "\n", "                ", "self", ".", "target_model", ".", "set_weights", "(", "self", ".", "model", ".", "get_weights", "(", ")", ")", "\n", "output", "=", "'target_model_updated_'", "+", "proc_name", "\n", "", "elif", "input_", "[", "0", "]", "==", "'save_weights'", ":", "\n", "                ", "self", ".", "model", ".", "save_weights", "(", "input_", "[", "1", "]", ",", "overwrite", "=", "input_", "[", "2", "]", ")", "\n", "output", "=", "'weights_saved_'", "+", "proc_name", "\n", "", "elif", "input_", "[", "0", "]", "==", "'load_weights'", ":", "\n", "                ", "self", ".", "model", ".", "load_weights", "(", "input_", "[", "1", "]", ")", "\n", "output", "=", "'weights_loaded_'", "+", "proc_name", "\n", "", "elif", "input_", "[", "0", "]", "==", "'output_names'", ":", "\n", "                ", "output", "=", "self", ".", "trainable_model", ".", "output_names", "\n", "", "elif", "input_", "[", "0", "]", "==", "'metrics_names'", ":", "\n", "                ", "output", "=", "self", ".", "trainable_model", ".", "metrics_names", "\n", "", "elif", "input_", "[", "0", "]", "==", "'model_as_string'", ":", "\n", "                ", "output", "=", "self", ".", "model", ".", "to_json", "(", ")", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'input command not defined'", ")", "\n", "\n", "", "self", ".", "output_queue", ".", "put", "(", "output", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.Worker.compile": [[812, 849], ["rl.util.clone_model", "iqn_ensemble.Worker.target_model.compile", "iqn_ensemble.Worker.model.compile", "keras.layers.Input", "keras.layers.Input", "keras.models.Model", "iqn_ensemble.Worker.trainable_model.compile", "Exception", "keras.layers.Lambda", "len", "type", "keras.zeros_like", "keras.optimizers.Adam"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "compile", "(", "self", ",", "metrics", "=", "None", ")", ":", "\n", "        ", "\"\"\" Set up the training of the neural network.\"\"\"", "\n", "if", "metrics", "is", "None", ":", "\n", "            ", "metrics", "=", "[", "]", "\n", "", "metrics", "+=", "[", "self", ".", "mean_q", "]", "# register default metrics", "\n", "metrics", "+=", "[", "self", ".", "max_q", "]", "\n", "\n", "# We never train the target model, hence we can set the optimizer and loss arbitrarily.", "\n", "self", ".", "target_model", "=", "clone_model", "(", "self", ".", "model", ")", "\n", "self", ".", "target_model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "self", ".", "model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "\n", "# Compile model.", "\n", "if", "self", ".", "target_model_update", "<", "1.", ":", "\n", "            ", "raise", "Exception", "(", "\"Soft target model updates not implemented yet\"", ")", "\n", "# # We use the `AdditionalUpdatesOptimizer` to efficiently soft-update the target model.", "\n", "# updates = get_soft_target_model_updates(self.target_model, self.model, self.target_model_update)", "\n", "# optimizer = AdditionalUpdatesOptimizer(optimizer, updates)", "\n", "\n", "# Create trainable model. The problem is that we need to mask the output since we only", "\n", "# ever want to update the Q values for a certain action. The way we achieve this is by", "\n", "# using a custom Lambda layer that computes the loss. This gives us the necessary flexibility", "\n", "# to mask out certain parameters by passing in multiple inputs to the Lambda layer.", "\n", "", "y_pred", "=", "self", ".", "model", ".", "output", "\n", "tau", "=", "self", ".", "model", ".", "input", "[", "1", "]", "\n", "y_true", "=", "Input", "(", "name", "=", "'y_true'", ",", "shape", "=", "(", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ",", ")", ")", "\n", "mask", "=", "Input", "(", "name", "=", "'mask'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "loss_out", "=", "Lambda", "(", "self", ".", "clipped_masked_quantile_error", ",", "output_shape", "=", "(", "1", ",", ")", ",", "name", "=", "'loss'", ")", "(", "[", "y_true", ",", "y_pred", ",", "tau", ",", "mask", "]", ")", "\n", "ins", "=", "[", "self", ".", "model", ".", "input", "]", "if", "type", "(", "self", ".", "model", ".", "input", ")", "is", "not", "list", "else", "self", ".", "model", ".", "input", "\n", "self", ".", "trainable_model", "=", "Model", "(", "inputs", "=", "ins", "+", "[", "y_true", ",", "mask", "]", ",", "outputs", "=", "[", "loss_out", ",", "y_pred", "]", ")", "\n", "assert", "len", "(", "self", ".", "trainable_model", ".", "output_names", ")", "==", "2", "\n", "combined_metrics", "=", "{", "self", ".", "trainable_model", ".", "output_names", "[", "1", "]", ":", "metrics", "}", "\n", "losses", "=", "[", "\n", "lambda", "y_true", ",", "y_pred", ":", "y_pred", ",", "# loss is computed in Lambda layer", "\n", "lambda", "y_true", ",", "y_pred", ":", "K", ".", "zeros_like", "(", "y_pred", ")", ",", "# we only include this for the metrics", "\n", "]", "\n", "self", ".", "trainable_model", ".", "compile", "(", "optimizer", "=", "Adam", "(", "lr", "=", "self", ".", "lr", ")", ",", "loss", "=", "losses", ",", "metrics", "=", "combined_metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.Worker.train_single_net": [[850, 921], ["iqn_ensemble.Worker.process_state_batch", "iqn_ensemble.Worker.process_state_batch", "numpy.array", "numpy.array", "iqn_ensemble.Worker.sample_tau_values", "iqn_ensemble.Worker.policy.select_action", "iqn_ensemble.Worker.sample_tau_values", "iqn_ensemble.Worker.target_model.predict_on_batch", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.array().astype", "numpy.array().astype", "iqn_ensemble.Worker.sample_tau_values", "iqn_ensemble.Worker.trainable_model.train_on_batch", "iqn_ensemble.Worker.append", "iqn_ensemble.Worker.append", "numpy.array.append", "action_batch.append", "numpy.array.append", "len", "len", "iqn_ensemble.Worker.model.predict_on_batch", "iqn_ensemble.Worker.target_model.predict_on_batch", "zip", "numpy.array", "numpy.array", "enumerate", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "train_single_net", "(", "self", ",", "experiences", ")", ":", "\n", "        ", "\"\"\" Retrieve a batch of experiences from the replay memory of the ensemble member and update\n        the network weights. \"\"\"", "\n", "# Start by extracting the necessary parameters (we use a vectorized implementation).", "\n", "state0_batch", "=", "[", "]", "\n", "reward_batch", "=", "[", "]", "\n", "action_batch", "=", "[", "]", "\n", "terminal1_batch", "=", "[", "]", "\n", "state1_batch", "=", "[", "]", "\n", "for", "e", "in", "experiences", ":", "\n", "            ", "state0_batch", ".", "append", "(", "e", ".", "state0", ")", "\n", "state1_batch", ".", "append", "(", "e", ".", "state1", ")", "\n", "reward_batch", ".", "append", "(", "e", ".", "reward", ")", "\n", "action_batch", ".", "append", "(", "e", ".", "action", ")", "\n", "terminal1_batch", ".", "append", "(", "0.", "if", "e", ".", "terminal1", "else", "1.", ")", "\n", "\n", "# Prepare and validate parameters.", "\n", "", "state0_batch", "=", "self", ".", "process_state_batch", "(", "state0_batch", ")", "\n", "state1_batch", "=", "self", ".", "process_state_batch", "(", "state1_batch", ")", "\n", "terminal1_batch", "=", "np", ".", "array", "(", "terminal1_batch", ")", "\n", "reward_batch", "=", "np", ".", "array", "(", "reward_batch", ")", "\n", "assert", "reward_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "assert", "terminal1_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "assert", "len", "(", "action_batch", ")", "==", "len", "(", "reward_batch", ")", "\n", "\n", "# Compute Z values for mini-batch update.", "\n", "tau_values_policy", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "self", ".", "cvar_eta", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "if", "self", ".", "enable_double_dqn", ":", "\n", "            ", "z_values", "=", "self", ".", "model", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_policy", "]", ")", "\n", "", "else", ":", "\n", "            ", "z_values", "=", "self", ".", "target_model", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_policy", "]", ")", "\n", "", "assert", "z_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "actions", ",", "policy_info", "=", "self", ".", "policy", ".", "select_action", "(", "z_values", "=", "z_values", ")", "\n", "assert", "actions", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "tau_values_targets", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "1", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "target_z_values", "=", "self", ".", "target_model", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_targets", "]", ")", "\n", "assert", "target_z_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "z_batch", "=", "target_z_values", "[", "range", "(", "self", ".", "batch_size", ")", ",", ":", ",", "actions", "]", "\n", "assert", "z_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ")", "\n", "\n", "targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", ")", "\n", "dummy_targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", ")", ")", "\n", "masks", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "\n", "# Compute r_t + gamma * max_a Q(s_t+1, a) and update the target targets accordingly,", "\n", "# but only for the affected output units (as given by action_batch).", "\n", "discounted_reward_batch", "=", "self", ".", "gamma", "*", "z_batch", "\n", "# Set discounted reward to zero for all states that were terminal.", "\n", "discounted_reward_batch", "*=", "terminal1_batch", "[", ":", ",", "None", "]", "\n", "assert", "discounted_reward_batch", ".", "shape", "[", "0", "]", "==", "reward_batch", ".", "shape", "[", "0", "]", "\n", "Rs", "=", "reward_batch", "[", ":", ",", "None", "]", "+", "discounted_reward_batch", "\n", "for", "idx", ",", "(", "target", ",", "mask", ",", "R", ",", "action", ")", "in", "enumerate", "(", "zip", "(", "targets", ",", "masks", ",", "Rs", ",", "action_batch", ")", ")", ":", "\n", "            ", "target", "[", ":", ",", "action", "]", "=", "R", "# update action with estimated accumulated reward", "\n", "dummy_targets", "[", "idx", ",", ":", "]", "=", "R", "\n", "mask", "[", "action", "]", "=", "1.", "# enable loss for this specific action", "\n", "", "targets", "=", "np", ".", "array", "(", "targets", ")", ".", "astype", "(", "'float32'", ")", "\n", "masks", "=", "np", ".", "array", "(", "masks", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "# Finally, perform a single update on the entire batch. We use a dummy target since", "\n", "# the actual loss is computed in a Lambda layer that needs more complex input. However,", "\n", "# it is still useful to know the actual target to compute metrics properly.", "\n", "tau_values", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "1", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "ins", "=", "[", "state0_batch", ",", "tau_values", "]", "\n", "metrics", "=", "self", ".", "trainable_model", ".", "train_on_batch", "(", "ins", "+", "[", "targets", ",", "masks", "]", ",", "[", "dummy_targets", ",", "targets", "]", ")", "\n", "metrics", "=", "[", "metric", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "if", "\n", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "# throw away individual losses", "\n", "metrics", "+=", "self", ".", "policy", ".", "metrics", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "            ", "metrics", "+=", "self", ".", "processor", ".", "metrics", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.Worker.process_state_batch": [[922, 928], ["numpy.array", "iqn_ensemble.Worker.processor.process_state_batch"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "process_state_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\" Heritage from keras-rl, not used here. \"\"\"", "\n", "batch", "=", "np", ".", "array", "(", "batch", ")", "\n", "if", "self", ".", "processor", "is", "None", ":", "\n", "            ", "return", "batch", "\n", "", "return", "self", ".", "processor", ".", "process_state_batch", "(", "batch", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.time_series_visualization.TimeSeriesVisualization.__init__": [[10, 40], ["range", "time_series_visualization.TimeSeriesVisualization.values.append", "time_series_visualization.TimeSeriesVisualization.fig.append", "time_series_visualization.TimeSeriesVisualization.ax.append", "time_series_visualization.TimeSeriesVisualization.ax[].axis", "range", "time_series_visualization.TimeSeriesVisualization.lines.append", "time_series_visualization.TimeSeriesVisualization.ax[].legend", "matplotlib.get_current_fig_manager", "matplotlib.get_current_fig_manager.window.wm_geometry", "time_series_visualization.TimeSeriesVisualization.fig[].canvas.draw", "time_series_visualization.TimeSeriesVisualization.axbackground.append", "matplotlib.show", "numpy.full", "matplotlib.figure", "matplotlib.gca", "lines.append", "time_series_visualization.TimeSeriesVisualization.fig[].canvas.copy_from_bbox", "time_series_visualization.TimeSeriesVisualization.ax[].plot", "range", "str", "int", "time_series_visualization.TimeSeriesVisualization.ax[].axis"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.plot_decision_map.DecisionMap.plot"], ["    ", "def", "__init__", "(", "self", ",", "nb_plots", ",", "nb_lines_per_plot", ",", "y_range", ",", "x_range", "=", "(", "0", ",", "100", ")", ",", "labels", "=", "None", ",", "titles", "=", "None", ")", ":", "\n", "        ", "self", ".", "x_range", "=", "x_range", "\n", "self", ".", "y_range", "=", "y_range", "\n", "self", ".", "fig", "=", "[", "]", "\n", "self", ".", "values", "=", "[", "]", "\n", "for", "n", "in", "nb_lines_per_plot", ":", "\n", "            ", "self", ".", "values", ".", "append", "(", "np", ".", "full", "(", "[", "n", ",", "self", ".", "x_range", "[", "1", "]", "+", "1", "]", ",", "np", ".", "nan", ")", ")", "\n", "", "self", ".", "ax", "=", "[", "]", "\n", "self", ".", "axbackground", "=", "[", "]", "\n", "self", ".", "lines", "=", "[", "]", "\n", "color", "=", "[", "'b'", ",", "'y'", ",", "'g'", ",", "'r'", ",", "'k'", "*", "10", "]", "\n", "\n", "for", "i", "in", "range", "(", "nb_plots", ")", ":", "\n", "            ", "self", ".", "fig", ".", "append", "(", "plt", ".", "figure", "(", ")", ")", "\n", "self", ".", "ax", ".", "append", "(", "plt", ".", "gca", "(", ")", ")", "\n", "self", ".", "ax", "[", "i", "]", ".", "axis", "(", "[", "self", ".", "x_range", "[", "0", "]", ",", "self", ".", "x_range", "[", "1", "]", ",", "self", ".", "y_range", "[", "i", "]", "[", "0", "]", ",", "self", ".", "y_range", "[", "i", "]", "[", "1", "]", "]", ")", "\n", "lines", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "nb_lines_per_plot", "[", "i", "]", ")", ":", "\n", "                ", "label", "=", "labels", "[", "i", "]", "[", "j", "]", "if", "labels", "else", "None", "\n", "lines", ".", "append", "(", "self", ".", "ax", "[", "i", "]", ".", "plot", "(", "range", "(", "int", "(", "self", ".", "ax", "[", "i", "]", ".", "axis", "(", ")", "[", "1", "]", "+", "1", ")", ")", ",", "self", ".", "values", "[", "i", "]", "[", "j", ",", ":", "]", ",", "\n", "label", "=", "label", ",", "c", "=", "color", "[", "j", "]", ")", ")", "\n", "", "self", ".", "lines", ".", "append", "(", "lines", ")", "\n", "self", ".", "ax", "[", "i", "]", ".", "legend", "(", ")", "\n", "if", "titles", ":", "\n", "                ", "self", ".", "ax", "[", "i", "]", ".", "title", ".", "_text", "=", "titles", "[", "i", "]", "\n", "", "mngr", "=", "plt", ".", "get_current_fig_manager", "(", ")", "\n", "mngr", ".", "window", ".", "wm_geometry", "(", "\"+\"", "+", "str", "(", "500", "+", "i", "*", "600", ")", "+", "\"+00\"", ")", "\n", "self", ".", "fig", "[", "i", "]", ".", "canvas", ".", "draw", "(", ")", "\n", "self", ".", "axbackground", ".", "append", "(", "self", ".", "fig", "[", "i", "]", ".", "canvas", ".", "copy_from_bbox", "(", "self", ".", "ax", "[", "i", "]", ".", "bbox", ")", ")", "\n", "plt", ".", "show", "(", "block", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.time_series_visualization.TimeSeriesVisualization.clear_plots": [[41, 44], ["range", "len"], "methods", ["None"], ["", "", "def", "clear_plots", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "values", ")", ")", ":", "\n", "            ", "self", ".", "values", "[", "i", "]", "*=", "np", ".", "nan", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.time_series_visualization.TimeSeriesVisualization.update_plots": [[45, 56], ["enumerate", "enumerate", "time_series_visualization.TimeSeriesVisualization.fig[].canvas.restore_region", "enumerate", "line[].set_ydata", "time_series_visualization.TimeSeriesVisualization.ax[].draw_artist", "time_series_visualization.TimeSeriesVisualization.fig[].canvas.blit", "time_series_visualization.TimeSeriesVisualization.fig[].canvas.flush_events", "numpy.argwhere", "numpy.isnan"], "methods", ["None"], ["", "", "def", "update_plots", "(", "self", ",", "new_values", ")", ":", "\n", "        ", "for", "i", ",", "values", "in", "enumerate", "(", "new_values", ")", ":", "\n", "            ", "add_idx", "=", "np", ".", "argwhere", "(", "np", ".", "isnan", "(", "self", ".", "values", "[", "i", "]", ")", ")", "[", "0", "]", "[", "1", "]", "\n", "self", ".", "values", "[", "i", "]", "[", ":", ",", "add_idx", "]", "=", "values", "\n", "", "for", "i", ",", "lines", "in", "enumerate", "(", "self", ".", "lines", ")", ":", "\n", "            ", "self", ".", "fig", "[", "i", "]", ".", "canvas", ".", "restore_region", "(", "self", ".", "axbackground", "[", "i", "]", ")", "\n", "for", "j", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "line", "[", "0", "]", ".", "set_ydata", "(", "self", ".", "values", "[", "i", "]", "[", "j", ",", ":", "]", ")", "\n", "self", ".", "ax", "[", "i", "]", ".", "draw_artist", "(", "line", "[", "0", "]", ")", "\n", "self", ".", "fig", "[", "i", "]", ".", "canvas", ".", "blit", "(", "self", ".", "ax", "[", "i", "]", ".", "bbox", ")", "\n", "self", ".", "fig", "[", "i", "]", ".", "canvas", ".", "flush_events", "(", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.AbstractDQNAgent.__init__": [[39, 69], ["core.Agent.__init__", "ValueError", "int", "float"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "nb_actions", ",", "memory", ",", "gamma", ",", "batch_size", ",", "nb_steps_warmup", ",", "train_interval", ",", "memory_interval", ",", "\n", "target_model_update", ",", "delta_clip", ",", "custom_model_objects", "=", "{", "}", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "AbstractDQNAgent", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "# Soft vs hard target model updates.", "\n", "if", "target_model_update", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'`target_model_update` must be >= 0.'", ")", "\n", "", "elif", "target_model_update", ">=", "1", ":", "\n", "# Hard update every `target_model_update` steps.", "\n", "            ", "target_model_update", "=", "int", "(", "target_model_update", ")", "\n", "", "else", ":", "\n", "# Soft update with `(1 - target_model_update) * old + target_model_update * new`.", "\n", "            ", "target_model_update", "=", "float", "(", "target_model_update", ")", "\n", "\n", "# Parameters.", "\n", "", "self", ".", "nb_actions", "=", "nb_actions", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "nb_steps_warmup", "=", "nb_steps_warmup", "\n", "self", ".", "train_interval", "=", "train_interval", "\n", "self", ".", "memory_interval", "=", "memory_interval", "\n", "self", ".", "target_model_update", "=", "target_model_update", "\n", "self", ".", "delta_clip", "=", "delta_clip", "\n", "self", ".", "custom_model_objects", "=", "custom_model_objects", "\n", "\n", "# Related objects.", "\n", "self", ".", "memory", "=", "memory", "\n", "\n", "# State.", "\n", "self", ".", "compiled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.AbstractDQNAgent.process_state_batch": [[70, 75], ["np.array", "dqn_standard.AbstractDQNAgent.processor.process_state_batch"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "process_state_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch", "=", "np", ".", "array", "(", "batch", ")", "\n", "if", "self", ".", "processor", "is", "None", ":", "\n", "            ", "return", "batch", "\n", "", "return", "self", ".", "processor", ".", "process_state_batch", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.AbstractDQNAgent.compute_batch_q_values": [[76, 81], ["dqn_standard.AbstractDQNAgent.process_state_batch", "dqn_standard.AbstractDQNAgent.model.predict_on_batch", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "compute_batch_q_values", "(", "self", ",", "state_batch", ")", ":", "\n", "        ", "batch", "=", "self", ".", "process_state_batch", "(", "state_batch", ")", "\n", "q_values", "=", "self", ".", "model", ".", "predict_on_batch", "(", "batch", ")", "\n", "assert", "q_values", ".", "shape", "==", "(", "len", "(", "state_batch", ")", ",", "self", ".", "nb_actions", ")", "\n", "return", "q_values", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.AbstractDQNAgent.compute_q_values": [[82, 86], ["dqn_standard.AbstractDQNAgent.compute_batch_q_values().flatten", "dqn_standard.AbstractDQNAgent.compute_batch_q_values"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_batch_q_values"], ["", "def", "compute_q_values", "(", "self", ",", "state", ")", ":", "\n", "        ", "q_values", "=", "self", ".", "compute_batch_q_values", "(", "[", "state", "]", ")", ".", "flatten", "(", ")", "\n", "assert", "q_values", ".", "shape", "==", "(", "self", ".", "nb_actions", ",", ")", "\n", "return", "q_values", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.AbstractDQNAgent.get_config": [[87, 98], ["get_object_config"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "'nb_actions'", ":", "self", ".", "nb_actions", ",", "\n", "'gamma'", ":", "self", ".", "gamma", ",", "\n", "'batch_size'", ":", "self", ".", "batch_size", ",", "\n", "'nb_steps_warmup'", ":", "self", ".", "nb_steps_warmup", ",", "\n", "'train_interval'", ":", "self", ".", "train_interval", ",", "\n", "'memory_interval'", ":", "self", ".", "memory_interval", ",", "\n", "'target_model_update'", ":", "self", ".", "target_model_update", ",", "\n", "'delta_clip'", ":", "self", ".", "delta_clip", ",", "\n", "'memory'", ":", "get_object_config", "(", "self", ".", "memory", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.__init__": [[114, 135], ["dqn_standard.AbstractDQNAgent.__init__", "dqn_standard.DQNAgent.reset_states", "hasattr", "ValueError", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states"], ["def", "__init__", "(", "self", ",", "model", ",", "policy", ",", "test_policy", ",", "enable_double_dqn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DQNAgent", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Validate (important) input.", "\n", "if", "hasattr", "(", "model", ".", "output", ",", "'__len__'", ")", "and", "len", "(", "model", ".", "output", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Model \"{}\" has more than one output. DQN expects a model that has a single output.'", ".", "format", "(", "model", ")", ")", "\n", "", "if", "model", ".", "output", ".", "_keras_shape", "!=", "(", "None", ",", "self", ".", "nb_actions", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Model output \"{}\" has invalid shape. DQN expects a model that has one dimension '", "\n", "'for each action, in this case {}.'", ".", "format", "(", "model", ".", "output", ",", "self", ".", "nb_actions", ")", ")", "\n", "\n", "# Parameters.", "\n", "", "self", ".", "enable_double_dqn", "=", "enable_double_dqn", "\n", "\n", "# Related objects.", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "policy", "=", "policy", "\n", "self", ".", "test_policy", "=", "test_policy", "\n", "\n", "# State.", "\n", "self", ".", "reset_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.get_config": [[136, 145], ["dqn_standard.AbstractDQNAgent.get_config", "get_object_config", "get_object_config", "get_object_config", "get_object_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "DQNAgent", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", "[", "'enable_double_dqn'", "]", "=", "self", ".", "enable_double_dqn", "\n", "config", "[", "'model'", "]", "=", "get_object_config", "(", "self", ".", "model", ")", "\n", "config", "[", "'policy'", "]", "=", "get_object_config", "(", "self", ".", "policy", ")", "\n", "config", "[", "'test_policy'", "]", "=", "get_object_config", "(", "self", ".", "test_policy", ")", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "config", "[", "'target_model'", "]", "=", "get_object_config", "(", "self", ".", "target_model", ")", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.compile": [[146, 188], ["clone_model", "dqn_standard.DQNAgent.target_model.compile", "dqn_standard.DQNAgent.model.compile", "keras.layers.Input", "keras.layers.Input", "Model", "Model.compile", "get_soft_target_model_updates", "AdditionalUpdatesOptimizer", "huber_loss", "K.sum", "keras.layers.Lambda", "len", "type", "K.zeros_like"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "compile", "(", "self", ",", "optimizer", ",", "metrics", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\" Set up the training of the neural network.\"\"\"", "\n", "metrics", "+=", "[", "mean_q", "]", "# register default metrics", "\n", "metrics", "+=", "[", "max_q", "]", "\n", "\n", "# We never train the target model, hence we can set the optimizer and loss arbitrarily.", "\n", "self", ".", "target_model", "=", "clone_model", "(", "self", ".", "model", ",", "self", ".", "custom_model_objects", ")", "\n", "self", ".", "target_model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "self", ".", "model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "\n", "# Compile model.", "\n", "if", "self", ".", "target_model_update", "<", "1.", ":", "\n", "# We use the `AdditionalUpdatesOptimizer` to efficiently soft-update the target model.", "\n", "            ", "updates", "=", "get_soft_target_model_updates", "(", "self", ".", "target_model", ",", "self", ".", "model", ",", "self", ".", "target_model_update", ")", "\n", "optimizer", "=", "AdditionalUpdatesOptimizer", "(", "optimizer", ",", "updates", ")", "\n", "\n", "", "def", "clipped_masked_error", "(", "args", ")", ":", "\n", "            ", "y_true", ",", "y_pred", ",", "mask", "=", "args", "\n", "loss", "=", "huber_loss", "(", "y_true", ",", "y_pred", ",", "self", ".", "delta_clip", ")", "\n", "loss", "*=", "mask", "# apply element-wise mask", "\n", "return", "K", ".", "sum", "(", "loss", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Create trainable model. The problem is that we need to mask the output since we only", "\n", "# ever want to update the Q values for a certain action. The way we achieve this is by", "\n", "# using a custom Lambda layer that computes the loss. This gives us the necessary flexibility", "\n", "# to mask out certain parameters by passing in multiple inputs to the Lambda layer.", "\n", "", "y_pred", "=", "self", ".", "model", ".", "output", "\n", "y_true", "=", "Input", "(", "name", "=", "'y_true'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "mask", "=", "Input", "(", "name", "=", "'mask'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "loss_out", "=", "Lambda", "(", "clipped_masked_error", ",", "output_shape", "=", "(", "1", ",", ")", ",", "name", "=", "'loss'", ")", "(", "[", "y_true", ",", "y_pred", ",", "mask", "]", ")", "\n", "ins", "=", "[", "self", ".", "model", ".", "input", "]", "if", "type", "(", "self", ".", "model", ".", "input", ")", "is", "not", "list", "else", "self", ".", "model", ".", "input", "\n", "trainable_model", "=", "Model", "(", "inputs", "=", "ins", "+", "[", "y_true", ",", "mask", "]", ",", "outputs", "=", "[", "loss_out", ",", "y_pred", "]", ")", "\n", "assert", "len", "(", "trainable_model", ".", "output_names", ")", "==", "2", "\n", "combined_metrics", "=", "{", "trainable_model", ".", "output_names", "[", "1", "]", ":", "metrics", "}", "\n", "losses", "=", "[", "\n", "lambda", "y_true", ",", "y_pred", ":", "y_pred", ",", "# loss is computed in Lambda layer", "\n", "lambda", "y_true", ",", "y_pred", ":", "K", ".", "zeros_like", "(", "y_pred", ")", ",", "# we only include this for the metrics", "\n", "]", "\n", "trainable_model", ".", "compile", "(", "optimizer", "=", "optimizer", ",", "loss", "=", "losses", ",", "metrics", "=", "combined_metrics", ")", "\n", "self", ".", "trainable_model", "=", "trainable_model", "\n", "\n", "self", ".", "compiled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.load_weights": [[189, 192], ["dqn_standard.DQNAgent.model.load_weights", "dqn_standard.DQNAgent.update_target_model_hard"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.load_weights", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard"], ["", "def", "load_weights", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "self", ".", "model", ".", "load_weights", "(", "filepath", ")", "\n", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.save_weights": [[193, 195], ["dqn_standard.DQNAgent.model.save_weights"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.save_weights"], ["", "def", "save_weights", "(", "self", ",", "filepath", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "self", ".", "model", ".", "save_weights", "(", "filepath", ",", "overwrite", "=", "overwrite", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.reset_states": [[196, 202], ["dqn_standard.DQNAgent.model.reset_states", "dqn_standard.DQNAgent.target_model.reset_states"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states"], ["", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "self", ".", "model", ".", "reset_states", "(", ")", "\n", "self", ".", "target_model", ".", "reset_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.update_target_model_hard": [[203, 205], ["dqn_standard.DQNAgent.target_model.set_weights", "dqn_standard.DQNAgent.model.get_weights"], "methods", ["None"], ["", "", "def", "update_target_model_hard", "(", "self", ")", ":", "\n", "        ", "self", ".", "target_model", ".", "set_weights", "(", "self", ".", "model", ".", "get_weights", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.forward": [[206, 228], ["dqn_standard.DQNAgent.memory.get_recent_state", "dqn_standard.DQNAgent.compute_q_values", "dqn_standard.DQNAgent.policy.select_action", "dqn_standard.DQNAgent.test_policy.select_action"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "\"\"\"\n        Ask the agent to choose an action based on the current observation.\n        Args:\n            observation (ndarray): Current observation.\n\n        Returns:\n            action (int): Index of chosen action\n            info (dict): Information about the Q-values of the chosen action.\n        \"\"\"", "\n", "state", "=", "self", ".", "memory", ".", "get_recent_state", "(", "observation", ")", "\n", "q_values", "=", "self", ".", "compute_q_values", "(", "state", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "action", "=", "self", ".", "policy", ".", "select_action", "(", "q_values", "=", "q_values", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "self", ".", "test_policy", ".", "select_action", "(", "q_values", "=", "q_values", ")", "\n", "\n", "# Book-keeping.", "\n", "", "self", ".", "recent_observation", "=", "observation", "\n", "self", ".", "recent_action", "=", "action", "\n", "\n", "return", "action", ",", "{", "'q_values'", ":", "q_values", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.backward": [[229, 325], ["dqn_standard.DQNAgent.memory.append", "dqn_standard.DQNAgent.memory.sample", "dqn_standard.DQNAgent.process_state_batch", "dqn_standard.DQNAgent.process_state_batch", "np.array", "np.array", "np.zeros", "np.zeros", "np.zeros", "enumerate", "np.array().astype", "np.array().astype", "dqn_standard.DQNAgent.trainable_model.train_on_batch", "dqn_standard.DQNAgent.update_target_model_hard", "len", "dqn_standard.DQNAgent.append", "dqn_standard.DQNAgent.append", "np.array.append", "action_batch.append", "np.array.append", "len", "len", "dqn_standard.DQNAgent.model.predict_on_batch", "np.argmax", "dqn_standard.DQNAgent.target_model.predict_on_batch", "dqn_standard.DQNAgent.target_model.predict_on_batch", "np.max().flatten", "zip", "np.array", "np.array", "type", "enumerate", "np.max", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "backward", "(", "self", ",", "reward", ",", "terminal", ")", ":", "\n", "        ", "\"\"\" Store the most recent experience in the replay memory and update all ensemble networks. \"\"\"", "\n", "if", "self", ".", "step", "%", "self", ".", "memory_interval", "==", "0", ":", "\n", "            ", "self", ".", "memory", ".", "append", "(", "self", ".", "recent_observation", ",", "self", ".", "recent_action", ",", "reward", ",", "terminal", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "metrics", "=", "[", "np", ".", "nan", "for", "_", "in", "self", ".", "metrics_names", "]", "\n", "if", "not", "self", ".", "training", ":", "\n", "# We're done here. No need to update the experience memory since we only use the working", "\n", "# memory to obtain the state over the most recent observations.", "\n", "            ", "return", "metrics", "\n", "\n", "# Train the network on a single stochastic batch.", "\n", "", "if", "self", ".", "step", ">", "self", ".", "nb_steps_warmup", "and", "self", ".", "step", "%", "self", ".", "train_interval", "==", "0", ":", "\n", "            ", "experiences", "=", "self", ".", "memory", ".", "sample", "(", "self", ".", "batch_size", ")", "\n", "assert", "len", "(", "experiences", ")", "==", "self", ".", "batch_size", "\n", "\n", "# Start by extracting the necessary parameters (we use a vectorized implementation).", "\n", "state0_batch", "=", "[", "]", "\n", "reward_batch", "=", "[", "]", "\n", "action_batch", "=", "[", "]", "\n", "terminal1_batch", "=", "[", "]", "\n", "state1_batch", "=", "[", "]", "\n", "for", "e", "in", "experiences", ":", "\n", "                ", "state0_batch", ".", "append", "(", "e", ".", "state0", ")", "\n", "state1_batch", ".", "append", "(", "e", ".", "state1", ")", "\n", "reward_batch", ".", "append", "(", "e", ".", "reward", ")", "\n", "action_batch", ".", "append", "(", "e", ".", "action", ")", "\n", "terminal1_batch", ".", "append", "(", "0.", "if", "e", ".", "terminal1", "else", "1.", ")", "\n", "\n", "# Prepare and validate parameters.", "\n", "", "state0_batch", "=", "self", ".", "process_state_batch", "(", "state0_batch", ")", "\n", "state1_batch", "=", "self", ".", "process_state_batch", "(", "state1_batch", ")", "\n", "terminal1_batch", "=", "np", ".", "array", "(", "terminal1_batch", ")", "\n", "reward_batch", "=", "np", ".", "array", "(", "reward_batch", ")", "\n", "assert", "reward_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "assert", "terminal1_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "assert", "len", "(", "action_batch", ")", "==", "len", "(", "reward_batch", ")", "\n", "\n", "# Compute Q values for mini-batch update.", "\n", "if", "self", ".", "enable_double_dqn", ":", "\n", "# According to the paper \"Deep Reinforcement Learning with Double Q-learning\"", "\n", "# (van Hasselt et al., 2015), in Double DQN, the online network predicts the actions", "\n", "# while the target network is used to estimate the Q value.", "\n", "                ", "q_values", "=", "self", ".", "model", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "actions", "=", "np", ".", "argmax", "(", "q_values", ",", "axis", "=", "1", ")", "\n", "assert", "actions", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "\n", "# Now, estimate Q values using the target network but select the values with the", "\n", "# highest Q value wrt to the online model (as computed above).", "\n", "target_q_values", "=", "self", ".", "target_model", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "target_q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "q_batch", "=", "target_q_values", "[", "range", "(", "self", ".", "batch_size", ")", ",", "actions", "]", "\n", "", "else", ":", "\n", "# Compute the q_values given state1, and extract the maximum for each sample in the batch.", "\n", "# We perform this prediction on the target_model instead of the model for reasons", "\n", "# outlined in Mnih (2015). In short: it makes the algorithm more stable.", "\n", "                ", "target_q_values", "=", "self", ".", "target_model", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "target_q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "q_batch", "=", "np", ".", "max", "(", "target_q_values", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "", "assert", "q_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "\n", "targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "dummy_targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "masks", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "\n", "# Compute r_t + gamma * max_a Q(s_t+1, a) and update the target targets accordingly,", "\n", "# but only for the affected output units (as given by action_batch).", "\n", "discounted_reward_batch", "=", "self", ".", "gamma", "*", "q_batch", "\n", "# Set discounted reward to zero for all states that were terminal.", "\n", "discounted_reward_batch", "*=", "terminal1_batch", "\n", "assert", "discounted_reward_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "Rs", "=", "reward_batch", "+", "discounted_reward_batch", "\n", "for", "idx", ",", "(", "target", ",", "mask", ",", "R", ",", "action", ")", "in", "enumerate", "(", "zip", "(", "targets", ",", "masks", ",", "Rs", ",", "action_batch", ")", ")", ":", "\n", "                ", "target", "[", "action", "]", "=", "R", "# update action with estimated accumulated reward", "\n", "dummy_targets", "[", "idx", "]", "=", "R", "\n", "mask", "[", "action", "]", "=", "1.", "# enable loss for this specific action", "\n", "", "targets", "=", "np", ".", "array", "(", "targets", ")", ".", "astype", "(", "'float32'", ")", "\n", "masks", "=", "np", ".", "array", "(", "masks", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "# Finally, perform a single update on the entire batch. We use a dummy target since", "\n", "# the actual loss is computed in a Lambda layer that needs more complex input. However,", "\n", "# it is still useful to know the actual target to compute metrics properly.", "\n", "ins", "=", "[", "state0_batch", "]", "if", "type", "(", "self", ".", "model", ".", "input", ")", "is", "not", "list", "else", "state0_batch", "\n", "metrics", "=", "self", ".", "trainable_model", ".", "train_on_batch", "(", "ins", "+", "[", "targets", ",", "masks", "]", ",", "[", "dummy_targets", ",", "targets", "]", ")", "\n", "metrics", "=", "[", "metric", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "if", "\n", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "# throw away individual losses", "\n", "metrics", "+=", "self", ".", "policy", ".", "metrics", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                ", "metrics", "+=", "self", ".", "processor", ".", "metrics", "\n", "\n", "", "", "if", "self", ".", "target_model_update", ">=", "1", "and", "self", ".", "step", "%", "self", ".", "target_model_update", "==", "0", ":", "\n", "            ", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.layers": [[326, 329], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "layers", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.metrics_names": [[330, 342], ["len", "name.replace", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics_names", "(", "self", ")", ":", "\n", "# Throw away individual losses and replace output name since this is hidden from the user.", "\n", "        ", "assert", "len", "(", "self", ".", "trainable_model", ".", "output_names", ")", "==", "2", "\n", "dummy_output_name", "=", "self", ".", "trainable_model", ".", "output_names", "[", "1", "]", "\n", "model_metrics", "=", "[", "name", "for", "idx", ",", "name", "in", "enumerate", "(", "self", ".", "trainable_model", ".", "metrics_names", ")", "if", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "\n", "model_metrics", "=", "[", "name", ".", "replace", "(", "dummy_output_name", "+", "'_'", ",", "''", ")", "for", "name", "in", "model_metrics", "]", "\n", "\n", "names", "=", "model_metrics", "+", "self", ".", "policy", ".", "metrics_names", "[", ":", "]", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "            ", "names", "+=", "self", ".", "processor", ".", "metrics_names", "[", ":", "]", "\n", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.policy": [[347, 351], ["dqn_standard.DQNAgent.__policy._set_agent"], "methods", ["None"], ["", "@", "policy", ".", "setter", "\n", "def", "policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__policy", "=", "policy", "\n", "self", ".", "__policy", ".", "_set_agent", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.DQNAgent.test_policy": [[356, 360], ["dqn_standard.DQNAgent.__test_policy._set_agent"], "methods", ["None"], ["", "@", "test_policy", ".", "setter", "\n", "def", "test_policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__test_policy", "=", "policy", "\n", "self", ".", "__test_policy", ".", "_set_agent", "(", "self", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.max_q": [[13, 15], ["K.mean", "K.max"], "function", ["None"], ["def", "max_q", "(", "y_true", ",", "y_pred", ")", ":", "# Returns average maximum Q-value of training batch", "\n", "    ", "return", "K", ".", "mean", "(", "K", ".", "max", "(", "y_pred", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_standard.mean_q": [[17, 19], ["K.mean", "K.mean"], "function", ["None"], ["", "def", "mean_q", "(", "y_true", ",", "y_pred", ")", ":", "# Returns average Q-value of training batch", "\n", "    ", "return", "K", ".", "mean", "(", "K", ".", "mean", "(", "y_pred", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkMLPDistributional.__init__": [[32, 54], ["network_architecture_distributional.NetworkMLPDistributional.build_mlp", "network_architecture_distributional.NetworkMLPDistributional.build_mlp_dueling", "network_architecture_distributional.NetworkMLPDistributional.build_mlp_with_prior", "network_architecture_distributional.NetworkMLPDistributional.build_mlp_dueling_with_prior", "Exception"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_mlp", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_mlp_dueling", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkMLPDistributional.build_mlp_with_prior", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkMLPDistributional.build_mlp_dueling_with_prior"], ["def", "__init__", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "duel", ",", "prior", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "prior_scale_factor", "=", "None", ",", "duel_type", "=", "'avg'", ",", "activation", "=", "'relu'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "if", "prior", ":", "\n", "            ", "assert", "prior_scale_factor", "is", "not", "None", "\n", "", "self", ".", "model", "=", "None", "\n", "if", "not", "prior", "and", "not", "duel", ":", "\n", "            ", "self", ".", "build_mlp", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "nb_cos_embeddings", ",", "\n", "activation", "=", "activation", ",", "window_length", "=", "window_length", ")", "\n", "", "elif", "not", "prior", "and", "duel", ":", "\n", "            ", "self", ".", "build_mlp_dueling", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "dueling_type", "=", "duel_type", ",", "activation", "=", "activation", ",", "\n", "window_length", "=", "window_length", ")", "\n", "", "elif", "prior", "and", "not", "duel", ":", "\n", "            ", "self", ".", "build_mlp_with_prior", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "prior_scale_factor", ",", "activation", "=", "activation", ",", "\n", "window_length", "=", "window_length", ")", "\n", "", "elif", "prior", "and", "duel", ":", "\n", "            ", "self", ".", "build_mlp_dueling_with_prior", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "prior_scale_factor", ",", "activation", "=", "activation", ",", "\n", "dueling_type", "=", "duel_type", ",", "window_length", "=", "window_length", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Error in Network creation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkMLPDistributional.build_mlp": [[55, 92], ["keras.layers.Input", "range", "keras.layers.Input", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Reshape", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Dense", "keras.concatenate", "numpy.multiply", "str", "keras.cos", "range"], "methods", ["None"], ["", "", "def", "build_mlp", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Create the MLP network.\n\n        The input to the network, which consists of the state and the sampled tau values, is first split.\n        The state input is passed through fully connected layers. The tau values are expanded with the cosine embedding,\n        and then passed through 1D convolutional layers, which in practice means one fully connected layer,\n        with shared weights between the different samples of tau. The output of the state and tau parts of the network\n        are then multiplied together elementwise, before being passed to a joint fully connected net.\n        \"\"\"", "\n", "state_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'state_input'", ")", "\n", "flat_input", "=", "Flatten", "(", ")", "(", "state_input", ")", "\n", "state_fc_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'fc_state'", ")", "(", "flat_input", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "nb_hidden_layers", "-", "1", ")", ":", "\n", "            ", "state_fc_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'fc_state_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "state_fc_net", ")", "\n", "", "extra_dim_state_fc_net", "=", "Reshape", "(", "(", "1", ",", "nb_hidden_neurons", ",", ")", ",", "input_shape", "=", "(", "nb_hidden_neurons", ",", ")", ",", "\n", "name", "=", "'fc_state_extra_dim'", ")", "(", "state_fc_net", ")", "\n", "\n", "tau_input", "=", "Input", "(", "shape", "=", "(", "1", ",", "nb_quantiles", ")", ",", "name", "=", "'tau_input'", ")", "\n", "extra_dim_tau", "=", "Reshape", "(", "(", "nb_quantiles", ",", "1", ",", ")", ",", "input_shape", "=", "(", "nb_quantiles", ",", ")", ")", "(", "tau_input", ")", "\n", "cos_embedding", "=", "Lambda", "(", "lambda", "tau_", ":", "K", ".", "concatenate", "(", "[", "K", ".", "cos", "(", "n", "*", "np", ".", "pi", "*", "tau_", ")", "\n", "for", "n", "in", "range", "(", "0", ",", "nb_cos_embeddings", ")", "]", ")", ",", "\n", "name", "=", "'cos_tau'", ")", "(", "extra_dim_tau", ")", "\n", "tau_net", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'fc_tau'", ")", "(", "cos_embedding", ")", "\n", "\n", "merge", "=", "Lambda", "(", "lambda", "x", ":", "np", ".", "multiply", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "name", "=", "'merge'", ")", "(", "[", "extra_dim_state_fc_net", ",", "tau_net", "]", ")", "\n", "\n", "joint_net", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'joint_net'", ")", "(", "merge", ")", "\n", "output", "=", "Conv1D", "(", "nb_outputs", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'output'", ")", "(", "joint_net", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "[", "state_input", ",", "tau_input", "]", ",", "output", "=", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkMLPDistributional.build_mlp_dueling": [[93, 116], ["network_architecture_distributional.NetworkMLPDistributional.build_mlp", "keras.models.Model", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.mean", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.expand_dims"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_mlp"], ["", "def", "build_mlp_dueling", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "dueling_type", "=", "'avg'", ",", "activation", "=", "'relu'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Simply adds dueling architecture to MLP network.\n        \"\"\"", "\n", "self", ".", "build_mlp", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "nb_cos_embeddings", ",", "\n", "activation", "=", "activation", ",", "window_length", "=", "window_length", ")", "\n", "layer", "=", "self", ".", "model", ".", "layers", "[", "-", "2", "]", "\n", "y", "=", "Conv1D", "(", "nb_outputs", "+", "1", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "name", "=", "'dueling_output'", ")", "(", "layer", ".", "output", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "\n", "name", "=", "'output'", ")", "(", "y", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "name", "=", "'output'", ")", "(", "y", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "name", "=", "'output'", ")", "(", "y", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "", "self", ".", "model", "=", "Model", "(", "inputs", "=", "self", ".", "model", ".", "input", ",", "outputs", "=", "outputlayer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkMLPDistributional.build_mlp_with_prior": [[117, 179], ["keras.layers.Input", "range", "keras.layers.Input", "range", "keras.layers.add", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Reshape", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Dense", "keras.layers.Dense", "keras.concatenate", "numpy.multiply", "numpy.multiply", "str", "keras.cos", "str", "range"], "methods", ["None"], ["", "def", "build_mlp_with_prior", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "prior_scale_factor", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Two networks are created, with identical structure, see the description of build_mlp above. One of the networks\n        have trainable parameters and the other network has fixed parameters, i.e., they cannot be updated during the\n        training process. The final output is created as a linear combination of the output of the two networks.\n        \"\"\"", "\n", "# Trainable net", "\n", "state_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'state_input'", ")", "\n", "flat_input", "=", "Flatten", "(", ")", "(", "state_input", ")", "\n", "state_fc_net_trainable", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'fc_state_trainable'", ")", "(", "flat_input", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "nb_hidden_layers", "-", "1", ")", ":", "\n", "            ", "state_fc_net_trainable", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'fc_state_trainable'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "state_fc_net_trainable", ")", "\n", "", "extra_dim_state_fc_net_trainable", "=", "Reshape", "(", "(", "1", ",", "nb_hidden_neurons", ",", ")", ",", "input_shape", "=", "(", "nb_hidden_neurons", ",", ")", ",", "\n", "name", "=", "'fc_state_extra_dim_trainable'", ")", "(", "state_fc_net_trainable", ")", "\n", "\n", "tau_input", "=", "Input", "(", "shape", "=", "(", "1", ",", "nb_quantiles", ")", ",", "name", "=", "'tau_input'", ")", "\n", "extra_dim_tau", "=", "Reshape", "(", "(", "nb_quantiles", ",", "1", ",", ")", ",", "input_shape", "=", "(", "nb_quantiles", ",", ")", ")", "(", "tau_input", ")", "\n", "cos_embedding", "=", "Lambda", "(", "lambda", "tau_", ":", "K", ".", "concatenate", "(", "[", "K", ".", "cos", "(", "n", "*", "np", ".", "pi", "*", "tau_", ")", "\n", "for", "n", "in", "range", "(", "0", ",", "nb_cos_embeddings", ")", "]", ")", ",", "\n", "name", "=", "'cos_tau'", ")", "(", "extra_dim_tau", ")", "\n", "tau_net_trainable", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'fc_tau_trainable'", ")", "(", "cos_embedding", ")", "\n", "\n", "merge_trainable", "=", "Lambda", "(", "lambda", "x", ":", "np", ".", "multiply", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "\n", "name", "=", "'merge_trainable'", ")", "(", "[", "extra_dim_state_fc_net_trainable", ",", "tau_net_trainable", "]", ")", "\n", "\n", "joint_net_trainable", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'joint_net_trainable'", ")", "(", "merge_trainable", ")", "\n", "output_trainable", "=", "Conv1D", "(", "nb_outputs", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'output_trainable'", ")", "(", "joint_net_trainable", ")", "\n", "\n", "# Prior net", "\n", "state_fc_net_prior", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "trainable", "=", "False", ",", "name", "=", "'fc_state_prior'", ")", "(", "flat_input", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "nb_hidden_layers", "-", "1", ")", ":", "\n", "            ", "state_fc_net_prior", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "trainable", "=", "False", ",", "name", "=", "'fc_state_prior'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "state_fc_net_prior", ")", "\n", "", "extra_dim_state_fc_net_prior", "=", "Reshape", "(", "(", "1", ",", "nb_hidden_neurons", ",", ")", ",", "input_shape", "=", "(", "nb_hidden_neurons", ",", ")", ",", "\n", "name", "=", "'fc_state_extra_dim_prior'", ")", "(", "state_fc_net_prior", ")", "\n", "\n", "tau_net_prior", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'relu'", ",", "trainable", "=", "False", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'fc_tau_prior'", ")", "(", "cos_embedding", ")", "\n", "\n", "merge_prior", "=", "Lambda", "(", "lambda", "x", ":", "np", ".", "multiply", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "\n", "name", "=", "'merge_prior'", ")", "(", "[", "extra_dim_state_fc_net_prior", ",", "tau_net_prior", "]", ")", "\n", "\n", "joint_net_prior", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'joint_net_prior'", ")", "(", "merge_prior", ")", "\n", "output_prior", "=", "Conv1D", "(", "nb_outputs", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'output_prior'", ")", "(", "joint_net_prior", ")", "\n", "output_prior_scaled", "=", "Lambda", "(", "lambda", "x", ":", "x", "*", "prior_scale_factor", ",", "name", "=", "'output_prior_scaled'", ")", "(", "output_prior", ")", "\n", "\n", "# Merge trainable and prior net", "\n", "output_add", "=", "add", "(", "[", "output_trainable", ",", "output_prior_scaled", "]", ",", "name", "=", "'add'", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "[", "state_input", ",", "tau_input", "]", ",", "output", "=", "output_add", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkMLPDistributional.build_mlp_dueling_with_prior": [[180, 269], ["keras.layers.Input", "range", "keras.layers.Input", "range", "keras.layers.add", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Reshape", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Dense", "keras.layers.Lambda", "keras.concatenate", "numpy.multiply", "keras.layers.Lambda", "numpy.multiply", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "str", "keras.cos", "keras.mean", "str", "keras.mean", "range", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.expand_dims", "keras.expand_dims", "keras.expand_dims"], "methods", ["None"], ["", "def", "build_mlp_dueling_with_prior", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "prior_scale_factor", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ",", "dueling_type", "=", "'avg'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates the network architecture described in build_mlp_with_prior, with an additional dueling structure.\n        \"\"\"", "\n", "# Trainable net", "\n", "state_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'state_input'", ")", "\n", "flat_input", "=", "Flatten", "(", ")", "(", "state_input", ")", "\n", "state_fc_net_trainable", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'fc_state_trainable'", ")", "(", "flat_input", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "nb_hidden_layers", "-", "1", ")", ":", "\n", "            ", "state_fc_net_trainable", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'fc_state_trainable'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "state_fc_net_trainable", ")", "\n", "", "extra_dim_state_fc_net_trainable", "=", "Reshape", "(", "(", "1", ",", "nb_hidden_neurons", ",", ")", ",", "input_shape", "=", "(", "nb_hidden_neurons", ",", ")", ",", "\n", "name", "=", "'fc_state_extra_dim_trainable'", ")", "(", "state_fc_net_trainable", ")", "\n", "\n", "tau_input", "=", "Input", "(", "shape", "=", "(", "1", ",", "nb_quantiles", ")", ",", "name", "=", "'tau_input'", ")", "\n", "extra_dim_tau", "=", "Reshape", "(", "(", "nb_quantiles", ",", "1", ",", ")", ",", "input_shape", "=", "(", "nb_quantiles", ",", ")", ")", "(", "tau_input", ")", "\n", "cos_embedding", "=", "Lambda", "(", "lambda", "tau_", ":", "K", ".", "concatenate", "(", "[", "K", ".", "cos", "(", "n", "*", "np", ".", "pi", "*", "tau_", ")", "\n", "for", "n", "in", "range", "(", "0", ",", "nb_cos_embeddings", ")", "]", ")", ",", "\n", "name", "=", "'cos_tau'", ")", "(", "extra_dim_tau", ")", "\n", "tau_net_trainable", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'fc_tau_trainable'", ")", "(", "cos_embedding", ")", "\n", "\n", "merge_trainable", "=", "Lambda", "(", "lambda", "x", ":", "np", ".", "multiply", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "\n", "name", "=", "'merge_trainable'", ")", "(", "[", "extra_dim_state_fc_net_trainable", ",", "tau_net_trainable", "]", ")", "\n", "\n", "joint_net_trainable", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'joint_net_trainable'", ")", "(", "merge_trainable", ")", "\n", "output_trainable_wo_dueling", "=", "Conv1D", "(", "nb_outputs", "+", "1", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'output_trainable_wo_dueling'", ")", "(", "joint_net_trainable", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "output_trainable", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "\n", "name", "=", "'output_trainable'", ")", "(", "output_trainable_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "output_trainable", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "\n", "name", "=", "'output_trainable'", ")", "(", "output_trainable_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "output_trainable", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "\n", "name", "=", "'output_trainable'", ")", "(", "output_trainable_wo_dueling", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "\n", "# Prior net", "\n", "", "state_fc_net_prior", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "trainable", "=", "False", ",", "name", "=", "'fc_state_prior'", ")", "(", "flat_input", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "nb_hidden_layers", "-", "1", ")", ":", "\n", "            ", "state_fc_net_prior", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "trainable", "=", "False", ",", "name", "=", "'fc_state_prior'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "state_fc_net_prior", ")", "\n", "", "extra_dim_state_fc_net_prior", "=", "Reshape", "(", "(", "1", ",", "nb_hidden_neurons", ",", ")", ",", "input_shape", "=", "(", "nb_hidden_neurons", ",", ")", ",", "\n", "name", "=", "'fc_state_extra_dim_prior'", ")", "(", "state_fc_net_prior", ")", "\n", "\n", "tau_net_prior", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'relu'", ",", "trainable", "=", "False", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'fc_tau_prior'", ")", "(", "cos_embedding", ")", "\n", "\n", "merge_prior", "=", "Lambda", "(", "lambda", "x", ":", "np", ".", "multiply", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "\n", "name", "=", "'merge_prior'", ")", "(", "[", "extra_dim_state_fc_net_prior", ",", "tau_net_prior", "]", ")", "\n", "\n", "joint_net_prior", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'joint_net_prior'", ")", "(", "merge_prior", ")", "\n", "output_prior_wo_dueling", "=", "Conv1D", "(", "nb_outputs", "+", "1", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'output_prior_wo_dueling'", ")", "(", "joint_net_prior", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "output_prior", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "\n", "name", "=", "'output_prior'", ")", "(", "output_prior_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "output_prior", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "name", "=", "'output_prior'", ")", "(", "output_prior_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "output_prior", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_outputs", ",", ")", ",", "name", "=", "'output_prior'", ")", "(", "output_prior_wo_dueling", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "", "output_prior_scaled", "=", "Lambda", "(", "lambda", "x", ":", "x", "*", "prior_scale_factor", ",", "name", "=", "'output_prior_scaled'", ")", "(", "output_prior", ")", "\n", "\n", "# Merge trainable and prior net", "\n", "output_add", "=", "add", "(", "[", "output_trainable", ",", "output_prior_scaled", "]", ",", "name", "=", "'add'", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "[", "state_input", ",", "tau_input", "]", ",", "output", "=", "output_add", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkCNNDistributional.__init__": [[299, 322], ["network_architecture_distributional.NetworkCNNDistributional.build_cnn", "network_architecture_distributional.NetworkCNNDistributional.build_cnn_dueling", "network_architecture_distributional.NetworkCNNDistributional.build_cnn_dueling_prior", "Exception"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn_dueling", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn_dueling_prior"], ["def", "__init__", "(", "self", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "nb_conv_filters", ",", "\n", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "nb_cos_embeddings", ",", "duel", ",", "prior", ",", "\n", "prior_scale_factor", "=", "None", ",", "duel_type", "=", "'avg'", ",", "\n", "activation", "=", "'relu'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "if", "prior", ":", "\n", "            ", "assert", "prior_scale_factor", "is", "not", "None", "\n", "", "self", ".", "model", "=", "None", "\n", "if", "not", "prior", "and", "not", "duel", ":", "\n", "            ", "self", ".", "build_cnn", "(", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "nb_cos_embeddings", ",", "\n", "activation", "=", "activation", ",", "window_length", "=", "window_length", ")", "\n", "", "elif", "not", "prior", "and", "duel", ":", "\n", "            ", "self", ".", "build_cnn_dueling", "(", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "dueling_type", "=", "duel_type", ",", "activation", "=", "activation", ",", "\n", "window_length", "=", "window_length", ")", "\n", "", "elif", "prior", "and", "duel", ":", "\n", "            ", "self", ".", "build_cnn_dueling_prior", "(", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "\n", "nb_cos_embeddings", ",", "dueling_type", "=", "duel_type", ",", "activation", "=", "activation", ",", "\n", "prior_scale_factor", "=", "prior_scale_factor", ",", "window_length", "=", "window_length", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Error in Network creation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkCNNDistributional.build_cnn": [[323, 381], ["keras.layers.Input", "range", "range", "keras.layers.concatenate", "keras.layers.Input", "range", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Reshape", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.MaxPooling1D", "keras.layers.Reshape", "keras.layers.Reshape", "keras.layers.Reshape", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.concatenate", "numpy.multiply", "str", "str", "keras.cos", "str", "range"], "methods", ["None"], ["", "", "def", "build_cnn", "(", "self", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "nb_conv_filters", ",", "\n", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "nb_cos_embeddings", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        See the description of build_mlp, the same architecture is used here, except for that a\n        convolutional structure is applied to the input that describes the surrounding vehicles.\n        \"\"\"", "\n", "nb_inputs", "=", "nb_ego_states", "+", "nb_states_per_vehicle", "*", "nb_vehicles", "\n", "\n", "state_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'input'", ")", "\n", "flat_input", "=", "Flatten", "(", "data_format", "=", "'channels_first'", ")", "(", "state_input", ")", "\n", "\n", "input_ego", "=", "Lambda", "(", "lambda", "state", ":", "state", "[", ":", ",", ":", "nb_ego_states", "*", "window_length", "]", ",", "name", "=", "'input_ego'", ")", "(", "flat_input", ")", "\n", "input_others", "=", "Lambda", "(", "lambda", "state", ":", "state", "[", ":", ",", "nb_ego_states", "*", "window_length", ":", "]", ",", "name", "=", "'input_others'", ")", "(", "flat_input", ")", "\n", "input_others_reshaped", "=", "Reshape", "(", "(", "nb_vehicles", "*", "nb_states_per_vehicle", "*", "window_length", ",", "1", ",", ")", ",", "\n", "input_shape", "=", "(", "nb_vehicles", "*", "nb_states_per_vehicle", "*", "\n", "window_length", ",", ")", ",", "name", "=", "'input_others_reshaped'", ")", "(", "input_others", ")", "\n", "\n", "ego_net", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'ego_0'", ")", "(", "input_ego", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "ego_net", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'ego_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "ego_net", ")", "\n", "\n", "", "conv_net", "=", "Conv1D", "(", "nb_conv_filters", ",", "nb_states_per_vehicle", "*", "window_length", ",", "\n", "strides", "=", "nb_states_per_vehicle", "*", "window_length", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'conv_0'", ")", "(", "input_others_reshaped", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "conv_net", "=", "Conv1D", "(", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'conv_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "conv_net", ")", "\n", "", "pool", "=", "MaxPooling1D", "(", "pool_size", "=", "nb_vehicles", ")", "(", "conv_net", ")", "\n", "conv_net_out", "=", "Reshape", "(", "(", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "1", ",", "nb_conv_filters", ",", ")", ",", "name", "=", "'convnet_out'", ")", "(", "pool", ")", "\n", "\n", "merged_net", "=", "concatenate", "(", "[", "ego_net", ",", "conv_net_out", "]", ")", "\n", "\n", "extra_dim_merged_net", "=", "Reshape", "(", "(", "1", ",", "2", "*", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "nb_hidden_neurons", ",", ")", ",", "\n", "name", "=", "'merged_extra_dim'", ")", "(", "merged_net", ")", "\n", "\n", "tau_input", "=", "Input", "(", "shape", "=", "(", "1", ",", "nb_quantiles", ")", ",", "name", "=", "'tau_input'", ")", "\n", "extra_dim_tau", "=", "Reshape", "(", "(", "nb_quantiles", ",", "1", ",", ")", ",", "input_shape", "=", "(", "nb_quantiles", ",", ")", ")", "(", "tau_input", ")", "\n", "cos_embedding", "=", "Lambda", "(", "lambda", "tau_", ":", "K", ".", "concatenate", "(", "[", "K", ".", "cos", "(", "n", "*", "np", ".", "pi", "*", "tau_", ")", "\n", "for", "n", "in", "range", "(", "0", ",", "nb_cos_embeddings", ")", "]", ")", ",", "\n", "name", "=", "'cos_tau'", ")", "(", "extra_dim_tau", ")", "\n", "tau_net", "=", "Conv1D", "(", "2", "*", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'fc_tau'", ")", "(", "cos_embedding", ")", "\n", "\n", "merge", "=", "Lambda", "(", "lambda", "x", ":", "np", ".", "multiply", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "name", "=", "'merge'", ")", "(", "[", "extra_dim_merged_net", ",", "tau_net", "]", ")", "\n", "\n", "joint_net", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'joint_net_0'", ")", "(", "merge", ")", "\n", "for", "i", "in", "range", "(", "nb_hidden_fc_layers", "-", "1", ")", ":", "\n", "            ", "joint_net", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'joint_net_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "joint_net", ")", "\n", "\n", "", "output", "=", "Conv1D", "(", "nb_actions", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'output'", ")", "(", "joint_net", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "[", "state_input", ",", "tau_input", "]", ",", "outputs", "=", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkCNNDistributional.build_cnn_dueling": [[382, 413], ["network_architecture_distributional.NetworkCNNDistributional.build_cnn", "keras.models.Model", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.mean", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.expand_dims"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn"], ["", "def", "build_cnn_dueling", "(", "self", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "nb_cos_embeddings", ",", "\n", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "window_length", "=", "1", ",", "\n", "dueling_type", "=", "'avg'", ")", ":", "\n", "        ", "\"\"\"\n        See the description of build_mlp_dueling, the same architecture is used here, except for that a\n        convolutional structure is applied to the input that describes the surrounding vehicles.\n        \"\"\"", "\n", "self", ".", "build_cnn", "(", "nb_ego_states", "=", "nb_ego_states", ",", "nb_states_per_vehicle", "=", "nb_states_per_vehicle", ",", "\n", "nb_vehicles", "=", "nb_vehicles", ",", "nb_actions", "=", "nb_actions", ",", "nb_conv_layers", "=", "nb_conv_layers", ",", "\n", "nb_conv_filters", "=", "nb_conv_filters", ",", "nb_hidden_fc_layers", "=", "nb_hidden_fc_layers", ",", "\n", "nb_hidden_neurons", "=", "nb_hidden_neurons", ",", "nb_quantiles", "=", "nb_quantiles", ",", "\n", "nb_cos_embeddings", "=", "nb_cos_embeddings", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "window_length", "=", "window_length", ")", "\n", "layer", "=", "self", ".", "model", ".", "layers", "[", "-", "2", "]", "\n", "y", "=", "Conv1D", "(", "nb_actions", "+", "1", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "name", "=", "'dueling_output'", ")", "(", "layer", ".", "output", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "\n", "name", "=", "'output'", ")", "(", "y", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "name", "=", "'output'", ")", "(", "y", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "name", "=", "'output'", ")", "(", "y", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "", "self", ".", "model", "=", "Model", "(", "inputs", "=", "self", ".", "model", ".", "input", ",", "outputs", "=", "outputlayer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture_distributional.NetworkCNNDistributional.build_cnn_dueling_prior": [[414, 552], ["keras.layers.Input", "range", "range", "keras.layers.concatenate", "keras.layers.Input", "range", "range", "range", "keras.layers.concatenate", "range", "keras.layers.add", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Reshape", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.MaxPooling1D", "keras.layers.Reshape", "keras.layers.Reshape", "keras.layers.Reshape", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.MaxPooling1D", "keras.layers.Reshape", "keras.layers.Reshape", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.Conv1D", "keras.layers.Lambda", "keras.concatenate", "numpy.multiply", "keras.layers.Lambda", "numpy.multiply", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "str", "str", "keras.cos", "str", "keras.mean", "str", "str", "str", "keras.mean", "range", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.expand_dims", "keras.expand_dims", "keras.expand_dims"], "methods", ["None"], ["", "def", "build_cnn_dueling_prior", "(", "self", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "nb_quantiles", ",", "nb_cos_embeddings", ",", "\n", "activation", "=", "'relu'", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "prior_scale_factor", "=", "1.", ",", "\n", "window_length", "=", "1", ",", "dueling_type", "=", "'avg'", ")", ":", "\n", "        ", "\"\"\"\n        See the description of build_mlp_dueling_prior, the same architecture is used here, except for that a\n        convolutional structure is applied to the input that describes the surrounding vehicles.\n        \"\"\"", "\n", "nb_inputs", "=", "nb_ego_states", "+", "nb_states_per_vehicle", "*", "nb_vehicles", "\n", "\n", "state_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'state_input'", ")", "\n", "flat_input", "=", "Flatten", "(", "data_format", "=", "'channels_first'", ")", "(", "state_input", ")", "\n", "\n", "input_ego", "=", "Lambda", "(", "lambda", "state", ":", "state", "[", ":", ",", ":", "nb_ego_states", "*", "window_length", "]", ",", "name", "=", "'input_ego'", ")", "(", "flat_input", ")", "\n", "input_others", "=", "Lambda", "(", "lambda", "state", ":", "state", "[", ":", ",", "nb_ego_states", "*", "window_length", ":", "]", ",", "name", "=", "'input_others'", ")", "(", "flat_input", ")", "\n", "input_others_reshaped", "=", "Reshape", "(", "(", "nb_vehicles", "*", "nb_states_per_vehicle", "*", "window_length", ",", "1", ",", ")", ",", "\n", "input_shape", "=", "(", "nb_vehicles", "*", "nb_states_per_vehicle", "*", "\n", "window_length", ",", ")", ",", "name", "=", "'input_others_reshaped'", ")", "(", "input_others", ")", "\n", "\n", "ego_net_trainable", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'ego_trainable_0'", ")", "(", "input_ego", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "ego_net_trainable", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'ego_trainable_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "ego_net_trainable", ")", "\n", "\n", "", "conv_net_trainable", "=", "Conv1D", "(", "nb_conv_filters", ",", "nb_states_per_vehicle", "*", "window_length", ",", "\n", "strides", "=", "nb_states_per_vehicle", "*", "window_length", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'conv_trainable_0'", ")", "(", "input_others_reshaped", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "conv_net_trainable", "=", "Conv1D", "(", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'conv_trainable_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "conv_net_trainable", ")", "\n", "", "pool_trainable", "=", "MaxPooling1D", "(", "pool_size", "=", "nb_vehicles", ")", "(", "conv_net_trainable", ")", "\n", "conv_net_out_trainable", "=", "Reshape", "(", "(", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "1", ",", "nb_conv_filters", ",", ")", ",", "\n", "name", "=", "'convnet_out_trainable'", ")", "(", "pool_trainable", ")", "\n", "\n", "merged_trainable", "=", "concatenate", "(", "[", "ego_net_trainable", ",", "conv_net_out_trainable", "]", ")", "\n", "\n", "extra_dim_merged_net_trainable", "=", "Reshape", "(", "(", "1", ",", "2", "*", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "nb_hidden_neurons", ",", ")", ",", "\n", "name", "=", "'merged_extra_dim_trainable'", ")", "(", "merged_trainable", ")", "\n", "\n", "tau_input", "=", "Input", "(", "shape", "=", "(", "1", ",", "nb_quantiles", ")", ",", "name", "=", "'tau_input'", ")", "\n", "extra_dim_tau", "=", "Reshape", "(", "(", "nb_quantiles", ",", "1", ",", ")", ",", "input_shape", "=", "(", "nb_quantiles", ",", ")", ")", "(", "tau_input", ")", "\n", "cos_embedding", "=", "Lambda", "(", "lambda", "tau_", ":", "K", ".", "concatenate", "(", "[", "K", ".", "cos", "(", "n", "*", "np", ".", "pi", "*", "tau_", ")", "\n", "for", "n", "in", "range", "(", "0", ",", "nb_cos_embeddings", ")", "]", ")", ",", "\n", "name", "=", "'cos_tau'", ")", "(", "extra_dim_tau", ")", "\n", "tau_net_trainable", "=", "Conv1D", "(", "2", "*", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'fc_tau_trainable'", ")", "(", "cos_embedding", ")", "\n", "\n", "merge_trainable", "=", "Lambda", "(", "lambda", "x", ":", "np", ".", "multiply", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "\n", "name", "=", "'merge_trainable'", ")", "(", "[", "extra_dim_merged_net_trainable", ",", "tau_net_trainable", "]", ")", "\n", "\n", "joint_net_trainable", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "name", "=", "'joint_net_trainable_0'", ")", "(", "merge_trainable", ")", "\n", "for", "i", "in", "range", "(", "nb_hidden_fc_layers", "-", "1", ")", ":", "\n", "            ", "joint_net_trainable", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'joint_net_trainable_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "joint_net_trainable", ")", "\n", "\n", "", "output_trainable_wo_dueling", "=", "Conv1D", "(", "nb_actions", "+", "1", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "name", "=", "'output_trainable_wo_dueling'", ")", "(", "joint_net_trainable", ")", "\n", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "output_trainable", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "\n", "name", "=", "'output_trainable'", ")", "(", "output_trainable_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "output_trainable", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "\n", "name", "=", "'output_trainable'", ")", "(", "output_trainable_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "output_trainable", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "\n", "name", "=", "'output_trainable'", ")", "(", "output_trainable_wo_dueling", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "\n", "", "ego_net_prior", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "trainable", "=", "False", ",", "name", "=", "'ego_prior_0'", ")", "(", "input_ego", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "ego_net_prior", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "trainable", "=", "False", ",", "name", "=", "'ego_prior_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "ego_net_prior", ")", "\n", "\n", "", "conv_net_prior", "=", "Conv1D", "(", "nb_conv_filters", ",", "nb_states_per_vehicle", "*", "window_length", ",", "\n", "strides", "=", "nb_states_per_vehicle", "*", "window_length", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'conv_prior_0'", ")", "(", "input_others_reshaped", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "conv_net_prior", "=", "Conv1D", "(", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'conv_prior_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "conv_net_prior", ")", "\n", "", "pool_prior", "=", "MaxPooling1D", "(", "pool_size", "=", "nb_vehicles", ")", "(", "conv_net_prior", ")", "\n", "conv_net_out_prior", "=", "Reshape", "(", "(", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "1", ",", "nb_conv_filters", ",", ")", ",", "\n", "name", "=", "'convnet_out_prior'", ")", "(", "pool_prior", ")", "\n", "\n", "merged_prior", "=", "concatenate", "(", "[", "ego_net_prior", ",", "conv_net_out_prior", "]", ")", "\n", "\n", "extra_dim_merged_net_prior", "=", "Reshape", "(", "(", "1", ",", "2", "*", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "nb_hidden_neurons", ",", ")", ",", "\n", "name", "=", "'merged_extra_dim_prior'", ")", "(", "merged_prior", ")", "\n", "\n", "tau_net_prior", "=", "Conv1D", "(", "2", "*", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'relu'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "name", "=", "'fc_tau_prior'", ")", "(", "cos_embedding", ")", "\n", "\n", "merge_prior", "=", "Lambda", "(", "lambda", "x", ":", "np", ".", "multiply", "(", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ",", "\n", "name", "=", "'merge_prior'", ")", "(", "[", "extra_dim_merged_net_prior", ",", "tau_net_prior", "]", ")", "\n", "\n", "joint_net_prior", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'joint_net_prior_0'", ")", "(", "merge_prior", ")", "\n", "for", "i", "in", "range", "(", "nb_hidden_fc_layers", "-", "1", ")", ":", "\n", "            ", "joint_net_prior", "=", "Conv1D", "(", "nb_hidden_neurons", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'joint_net_prior'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "joint_net_prior", ")", "\n", "\n", "", "output_prior_wo_dueling", "=", "Conv1D", "(", "nb_actions", "+", "1", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "'linear'", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'output_prior_wo_dueling'", ")", "(", "joint_net_prior", ")", "\n", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "output_prior", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "\n", "name", "=", "'output_prior'", ")", "(", "output_prior_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "output_prior", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "name", "=", "'output_prior'", ")", "(", "output_prior_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "output_prior", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", ":", ",", "1", ":", "]", ",", "\n", "output_shape", "=", "(", "nb_quantiles", ",", "nb_actions", ",", ")", ",", "name", "=", "'output_prior'", ")", "(", "output_prior_wo_dueling", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "\n", "", "prior_scale", "=", "Lambda", "(", "lambda", "x", ":", "x", "*", "prior_scale_factor", ",", "name", "=", "'prior_scale'", ")", "(", "output_prior", ")", "\n", "add_output", "=", "add", "(", "[", "output_trainable", ",", "prior_scale", "]", ",", "name", "=", "'final_output'", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "[", "state_input", ",", "tau_input", "]", ",", "outputs", "=", "add_output", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.__init__": [[33, 73], ["core.Agent.__init__", "int", "iqn.IQNAgent.reset_states", "hasattr", "ValueError", "ValueError", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states"], ["def", "__init__", "(", "self", ",", "model", ",", "nb_actions", ",", "memory", ",", "gamma", ",", "batch_size", ",", "nb_steps_warmup", ",", "train_interval", ",", "memory_interval", ",", "\n", "target_model_update", ",", "delta_clip", ",", "policy", ",", "test_policy", ",", "enable_double_dqn", ",", "nb_samples_policy", ",", "\n", "nb_sampled_quantiles", ",", "cvar_eta", ",", "custom_model_objects", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "IQNAgent", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Parameters.", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "nb_steps_warmup", "=", "nb_steps_warmup", "\n", "self", ".", "train_interval", "=", "train_interval", "\n", "self", ".", "memory_interval", "=", "memory_interval", "\n", "self", ".", "target_model_update", "=", "int", "(", "target_model_update", ")", "\n", "self", ".", "delta_clip", "=", "delta_clip", "\n", "self", ".", "custom_model_objects", "=", "{", "}", "if", "custom_model_objects", "is", "None", "else", "custom_model_objects", "\n", "self", ".", "enable_double_dqn", "=", "enable_double_dqn", "\n", "self", ".", "nb_samples_policy", "=", "nb_samples_policy", "\n", "self", ".", "nb_sampled_quantiles", "=", "nb_sampled_quantiles", "\n", "self", ".", "cvar_eta", "=", "cvar_eta", "\n", "\n", "# Related objects.", "\n", "self", ".", "memory", "=", "memory", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "policy", "=", "policy", "\n", "self", ".", "test_policy", "=", "test_policy", "\n", "\n", "# State.", "\n", "self", ".", "compiled", "=", "False", "\n", "self", ".", "reset_states", "(", ")", "\n", "\n", "# Validate (important) input.", "\n", "if", "hasattr", "(", "model", ".", "output", ",", "'__len__'", ")", "and", "len", "(", "model", ".", "output", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Model \"{}\" has more than one output. IQN expects a model that has a single output.'", ".", "format", "(", "model", ")", ")", "\n", "", "if", "model", ".", "output", ".", "_keras_shape", "!=", "(", "None", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Model output \"{}\" has invalid shape.'", ")", "\n", "", "if", "not", "self", ".", "nb_samples_policy", "==", "self", ".", "nb_sampled_quantiles", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'For practical reasons, for now, nb_samples_policy and nb sampled_quantiles have to be equal'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.quantile_huber_loss": [[74, 109], ["keras.concatenate", "keras.concatenate", "numpy.isinf", "keras.repeat", "keras.permute_dimensions", "hasattr", "keras.backend", "hasattr", "keras.squeeze", "tf.select", "tf.where", "tf.roll", "keras.square", "keras.abs", "keras.square", "tf.select", "tf.where", "keras.int_shape", "tf.roll", "range", "range", "keras.abs", "keras.int_shape", "keras.int_shape"], "methods", ["None"], ["", "", "def", "quantile_huber_loss", "(", "self", ",", "y_true", ",", "y_pred", ",", "tau", ",", "clip_value", ")", ":", "\n", "        ", "\"\"\" Calculate the quantile huber loss, see the paper for details. \"\"\"", "\n", "assert", "K", ".", "backend", "(", ")", "==", "'tensorflow'", "# Only works with tensorflow for now. Minor changes are required to support other backends.", "\n", "import", "tensorflow", "as", "tf", "\n", "assert", "clip_value", ">", "0.", "\n", "\n", "# x = y_true - y_pred", "\n", "x", "=", "K", ".", "concatenate", "(", "[", "y_true", "-", "tf", ".", "roll", "(", "y_pred", ",", "axis", "=", "1", ",", "shift", "=", "i", ")", "for", "i", "in", "range", "(", "K", ".", "int_shape", "(", "y_pred", ")", "[", "-", "2", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "tau_expanded", "=", "K", ".", "concatenate", "(", "[", "tf", ".", "roll", "(", "tau", ",", "axis", "=", "2", ",", "shift", "=", "i", ")", "for", "i", "in", "range", "(", "K", ".", "int_shape", "(", "y_pred", ")", "[", "-", "2", "]", ")", "]", ",", "axis", "=", "2", ")", "\n", "\n", "if", "np", ".", "isinf", "(", "clip_value", ")", ":", "\n", "# Special case for infinity since Tensorflow does have problems", "\n", "# if we compare `K.abs(x) < np.inf`.", "\n", "            ", "huber_loss", "=", ".5", "*", "K", ".", "square", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "condition", "=", "K", ".", "abs", "(", "x", ")", "<", "clip_value", "\n", "squared_loss", "=", ".5", "*", "K", ".", "square", "(", "x", ")", "\n", "linear_loss", "=", "clip_value", "*", "(", "K", ".", "abs", "(", "x", ")", "-", ".5", "*", "clip_value", ")", "\n", "if", "hasattr", "(", "tf", ",", "'select'", ")", ":", "\n", "                ", "huber_loss", "=", "tf", ".", "select", "(", "condition", ",", "squared_loss", ",", "linear_loss", ")", "# condition, true, false", "\n", "", "else", ":", "\n", "                ", "huber_loss", "=", "tf", ".", "where", "(", "condition", ",", "squared_loss", ",", "linear_loss", ")", "# condition, true, false", "\n", "\n", "", "", "quantile_regression_condition", "=", "x", "<", "0", "\n", "tau_expanded", "=", "K", ".", "repeat", "(", "K", ".", "squeeze", "(", "tau_expanded", ",", "axis", "=", "1", ")", ",", "K", ".", "int_shape", "(", "y_pred", ")", "[", "-", "1", "]", ")", "\n", "tau_expanded", "=", "K", ".", "permute_dimensions", "(", "tau_expanded", ",", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "quantile_minus_loss", "=", "(", "1", "-", "tau_expanded", ")", "*", "huber_loss", "/", "clip_value", "\n", "quantile_plus_loss", "=", "tau_expanded", "*", "huber_loss", "/", "clip_value", "\n", "\n", "if", "hasattr", "(", "tf", ",", "'select'", ")", ":", "\n", "            ", "return", "tf", ".", "select", "(", "quantile_regression_condition", ",", "quantile_minus_loss", ",", "\n", "quantile_plus_loss", ")", "# condition, true, false", "\n", "", "else", ":", "\n", "            ", "return", "tf", ".", "where", "(", "quantile_regression_condition", ",", "quantile_minus_loss", ",", "\n", "quantile_plus_loss", ")", "# condition, true, false", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.clipped_masked_quantile_error": [[110, 116], ["iqn.IQNAgent.quantile_huber_loss", "keras.repeat", "keras.sum", "keras.int_shape", "keras.sum", "keras.int_shape"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.quantile_huber_loss"], ["", "", "def", "clipped_masked_quantile_error", "(", "self", ",", "args", ")", ":", "\n", "        ", "y_true", ",", "y_pred", ",", "tau", ",", "mask", "=", "args", "\n", "loss", "=", "self", ".", "quantile_huber_loss", "(", "y_true", ",", "y_pred", ",", "tau", ",", "self", ".", "delta_clip", ")", "\n", "mask_expanded", "=", "K", ".", "repeat", "(", "mask", ",", "K", ".", "int_shape", "(", "loss", ")", "[", "-", "2", "]", ")", "\n", "loss", "*=", "mask_expanded", "# apply element-wise mask", "\n", "return", "K", ".", "sum", "(", "K", ".", "sum", "(", "loss", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "-", "1", ")", "/", "K", ".", "int_shape", "(", "y_true", ")", "[", "-", "2", "]", "# Divide by N'", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.max_q": [[117, 119], ["keras.mean", "keras.max", "keras.mean"], "methods", ["None"], ["", "def", "max_q", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "# Returns average maximum Q-value of training batch", "\n", "        ", "return", "K", ".", "mean", "(", "K", ".", "max", "(", "K", ".", "mean", "(", "y_pred", ",", "axis", "=", "-", "2", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.mean_q": [[120, 122], ["keras.mean", "keras.mean", "keras.mean"], "methods", ["None"], ["", "def", "mean_q", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "# Returns average Q-value of training batch", "\n", "        ", "return", "K", ".", "mean", "(", "K", ".", "mean", "(", "K", ".", "mean", "(", "y_pred", ",", "axis", "=", "-", "2", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compile": [[123, 155], ["rl.util.clone_model", "iqn.IQNAgent.target_model.compile", "iqn.IQNAgent.model.compile", "keras.layers.Input", "keras.layers.Input", "keras.models.Model", "keras.models.Model.compile", "keras.layers.Lambda", "len", "type", "keras.zeros_like"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "compile", "(", "self", ",", "optimizer", ",", "metrics", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\" Calculate the quantile huber loss, see the paper for details. \"\"\"", "\n", "metrics", "+=", "[", "self", ".", "mean_q", "]", "# register default metrics", "\n", "metrics", "+=", "[", "self", ".", "max_q", "]", "\n", "\n", "# We never train the target model, hence we can set the optimizer and loss arbitrarily.", "\n", "self", ".", "target_model", "=", "clone_model", "(", "self", ".", "model", ",", "self", ".", "custom_model_objects", ")", "\n", "self", ".", "target_model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "self", ".", "model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "\n", "# Compile model.", "\n", "# Create trainable model. The problem is that we need to mask the output since we only", "\n", "# ever want to update the Q values for a certain action. The way we achieve this is by", "\n", "# using a custom Lambda layer that computes the loss. This gives us the necessary flexibility", "\n", "# to mask out certain parameters by passing in multiple inputs to the Lambda layer.", "\n", "y_pred", "=", "self", ".", "model", ".", "output", "\n", "tau", "=", "self", ".", "model", ".", "input", "[", "1", "]", "\n", "y_true", "=", "Input", "(", "name", "=", "'y_true'", ",", "shape", "=", "(", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ",", ")", ")", "\n", "mask", "=", "Input", "(", "name", "=", "'mask'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "loss_out", "=", "Lambda", "(", "self", ".", "clipped_masked_quantile_error", ",", "output_shape", "=", "(", "1", ",", ")", ",", "name", "=", "'loss'", ")", "(", "[", "y_true", ",", "y_pred", ",", "tau", ",", "mask", "]", ")", "\n", "ins", "=", "[", "self", ".", "model", ".", "input", "]", "if", "type", "(", "self", ".", "model", ".", "input", ")", "is", "not", "list", "else", "self", ".", "model", ".", "input", "\n", "trainable_model", "=", "Model", "(", "inputs", "=", "ins", "+", "[", "y_true", ",", "mask", "]", ",", "outputs", "=", "[", "loss_out", ",", "y_pred", "]", ")", "\n", "assert", "len", "(", "trainable_model", ".", "output_names", ")", "==", "2", "\n", "combined_metrics", "=", "{", "trainable_model", ".", "output_names", "[", "1", "]", ":", "metrics", "}", "\n", "losses", "=", "[", "\n", "lambda", "y_true", ",", "y_pred", ":", "y_pred", ",", "# loss is computed in Lambda layer", "\n", "lambda", "y_true", ",", "y_pred", ":", "K", ".", "zeros_like", "(", "y_pred", ")", ",", "# we only include this for the metrics", "\n", "]", "\n", "trainable_model", ".", "compile", "(", "optimizer", "=", "optimizer", ",", "loss", "=", "losses", ",", "metrics", "=", "combined_metrics", ")", "\n", "self", ".", "trainable_model", "=", "trainable_model", "\n", "\n", "self", ".", "compiled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.load_weights": [[156, 159], ["iqn.IQNAgent.model.load_weights", "iqn.IQNAgent.update_target_model_hard"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.load_weights", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard"], ["", "def", "load_weights", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "self", ".", "model", ".", "load_weights", "(", "filepath", ")", "\n", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.save_weights": [[160, 162], ["iqn.IQNAgent.model.save_weights"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.save_weights"], ["", "def", "save_weights", "(", "self", ",", "filepath", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "self", ".", "model", ".", "save_weights", "(", "filepath", ",", "overwrite", "=", "overwrite", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.reset_states": [[163, 169], ["iqn.IQNAgent.model.reset_states", "iqn.IQNAgent.target_model.reset_states"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states"], ["", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "self", ".", "model", ".", "reset_states", "(", ")", "\n", "self", ".", "target_model", ".", "reset_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.update_target_model_hard": [[170, 173], ["iqn.IQNAgent.target_model.set_weights", "iqn.IQNAgent.model.get_weights"], "methods", ["None"], ["", "", "def", "update_target_model_hard", "(", "self", ")", ":", "\n", "        ", "\"\"\" Copy current network parameters to the target network. \"\"\"", "\n", "self", ".", "target_model", ".", "set_weights", "(", "self", ".", "model", ".", "get_weights", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_batch_z_values": [[174, 179], ["iqn.IQNAgent.process_state_batch", "iqn.IQNAgent.model.predict_on_batch", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "compute_batch_z_values", "(", "self", ",", "state_batch", ",", "tau_batch", ")", ":", "\n", "        ", "batch", "=", "self", ".", "process_state_batch", "(", "state_batch", ")", "\n", "z_values", "=", "self", ".", "model", ".", "predict_on_batch", "(", "[", "batch", ",", "tau_batch", "]", ")", "\n", "assert", "z_values", ".", "shape", "==", "(", "len", "(", "state_batch", ")", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "return", "z_values", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values": [[180, 188], ["iqn.IQNAgent.compute_batch_z_values", "iqn.IQNAgent.sample_tau_values", "iqn.IQNAgent.sample_tau_values"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_batch_z_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values"], ["", "def", "compute_sampled_z_values", "(", "self", ",", "state", ",", "max_tau", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "tau", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "max_tau", ")", "\n", "", "else", ":", "\n", "            ", "tau", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "max_tau", ",", "uniform", "=", "True", ")", "\n", "", "z_values", "=", "self", ".", "compute_batch_z_values", "(", "[", "state", "]", ",", "tau", ")", "\n", "assert", "z_values", ".", "shape", "==", "(", "1", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "return", "z_values", ",", "tau", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values": [[189, 194], ["numpy.linspace", "numpy.random.rand"], "methods", ["None"], ["", "def", "sample_tau_values", "(", "self", ",", "max_tau", ",", "batch_size", "=", "1", ",", "uniform", "=", "False", ")", ":", "\n", "        ", "if", "uniform", ":", "\n", "            ", "return", "np", ".", "linspace", "(", "0", ",", "max_tau", ",", "self", ".", "nb_sampled_quantiles", ")", "[", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "1", ",", "self", ".", "nb_sampled_quantiles", ")", "*", "max_tau", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.forward": [[195, 222], ["iqn.IQNAgent.memory.get_recent_state", "iqn.IQNAgent.compute_sampled_z_values", "numpy.squeeze", "numpy.squeeze", "info.update", "iqn.IQNAgent.policy.select_action", "iqn.IQNAgent.test_policy.select_action", "numpy.mean", "numpy.std"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["", "", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "\"\"\"\n        Ask the agent to choose an action based on the current observation.\n        Args:\n            observation (ndarray): Current observation.\n\n        Returns:\n            action (int): Index of chosen action\n            info (dict): Information about the Q-values of the chosen action.\n        \"\"\"", "\n", "state", "=", "self", ".", "memory", ".", "get_recent_state", "(", "observation", ")", "\n", "z_values", ",", "tau", "=", "self", ".", "compute_sampled_z_values", "(", "state", ",", "max_tau", "=", "self", ".", "cvar_eta", ")", "\n", "tau", "=", "np", ".", "squeeze", "(", "tau", ")", "\n", "z_values", "=", "np", ".", "squeeze", "(", "z_values", ",", "axis", "=", "0", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "action", ",", "policy_info", "=", "self", ".", "policy", ".", "select_action", "(", "z_values", "=", "z_values", ")", "\n", "", "else", ":", "\n", "            ", "action", ",", "policy_info", "=", "self", ".", "test_policy", ".", "select_action", "(", "z_values", "=", "z_values", ")", "\n", "\n", "# Book-keeping.", "\n", "", "self", ".", "recent_observation", "=", "observation", "\n", "self", ".", "recent_action", "=", "action", "\n", "\n", "info", "=", "{", "'z_values'", ":", "z_values", ",", "'quantiles'", ":", "tau", ",", "'q_values'", ":", "np", ".", "mean", "(", "z_values", ",", "axis", "=", "-", "2", ")", ",", "\n", "'aleatoric_std_dev'", ":", "np", ".", "std", "(", "z_values", ",", "axis", "=", "0", ")", "}", "\n", "info", ".", "update", "(", "policy_info", ")", "\n", "return", "action", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.backward": [[223, 313], ["iqn.IQNAgent.memory.append", "iqn.IQNAgent.memory.sample", "iqn.IQNAgent.process_state_batch", "iqn.IQNAgent.process_state_batch", "numpy.array", "numpy.array", "iqn.IQNAgent.sample_tau_values", "numpy.argmax", "iqn.IQNAgent.sample_tau_values", "iqn.IQNAgent.target_model.predict_on_batch", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.array().astype", "numpy.array().astype", "iqn.IQNAgent.sample_tau_values", "iqn.IQNAgent.trainable_model.train_on_batch", "iqn.IQNAgent.update_target_model_hard", "len", "iqn.IQNAgent.append", "iqn.IQNAgent.append", "numpy.array.append", "action_batch.append", "numpy.array.append", "len", "len", "iqn.IQNAgent.model.predict_on_batch", "iqn.IQNAgent.target_model.predict_on_batch", "numpy.mean", "zip", "numpy.array", "numpy.array", "enumerate", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "backward", "(", "self", ",", "reward", ",", "terminal", ")", ":", "\n", "        ", "\"\"\" Store the most recent experience in the replay memory and update all ensemble networks. \"\"\"", "\n", "\n", "# Store most recent experience in memory.", "\n", "if", "self", ".", "step", "%", "self", ".", "memory_interval", "==", "0", ":", "\n", "            ", "self", ".", "memory", ".", "append", "(", "self", ".", "recent_observation", ",", "self", ".", "recent_action", ",", "reward", ",", "terminal", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "metrics", "=", "[", "np", ".", "nan", "for", "_", "in", "self", ".", "metrics_names", "]", "\n", "if", "not", "self", ".", "training", ":", "\n", "# We're done here. No need to update the experience memory since we only use the working", "\n", "# memory to obtain the state over the most recent observations.", "\n", "            ", "return", "metrics", "\n", "\n", "# Train the network on a single stochastic batch.", "\n", "", "if", "self", ".", "step", ">", "self", ".", "nb_steps_warmup", "and", "self", ".", "step", "%", "self", ".", "train_interval", "==", "0", ":", "\n", "            ", "experiences", "=", "self", ".", "memory", ".", "sample", "(", "self", ".", "batch_size", ")", "\n", "assert", "len", "(", "experiences", ")", "==", "self", ".", "batch_size", "\n", "\n", "# Start by extracting the necessary parameters (we use a vectorized implementation).", "\n", "state0_batch", "=", "[", "]", "\n", "reward_batch", "=", "[", "]", "\n", "action_batch", "=", "[", "]", "\n", "terminal1_batch", "=", "[", "]", "\n", "state1_batch", "=", "[", "]", "\n", "for", "e", "in", "experiences", ":", "\n", "                ", "state0_batch", ".", "append", "(", "e", ".", "state0", ")", "\n", "state1_batch", ".", "append", "(", "e", ".", "state1", ")", "\n", "reward_batch", ".", "append", "(", "e", ".", "reward", ")", "\n", "action_batch", ".", "append", "(", "e", ".", "action", ")", "\n", "terminal1_batch", ".", "append", "(", "0.", "if", "e", ".", "terminal1", "else", "1.", ")", "\n", "\n", "# Prepare and validate parameters.", "\n", "", "state0_batch", "=", "self", ".", "process_state_batch", "(", "state0_batch", ")", "\n", "state1_batch", "=", "self", ".", "process_state_batch", "(", "state1_batch", ")", "\n", "terminal1_batch", "=", "np", ".", "array", "(", "terminal1_batch", ")", "\n", "reward_batch", "=", "np", ".", "array", "(", "reward_batch", ")", "\n", "assert", "reward_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "assert", "terminal1_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "assert", "len", "(", "action_batch", ")", "==", "len", "(", "reward_batch", ")", "\n", "\n", "# Compute Z values for mini-batch update.", "\n", "tau_values_policy", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "self", ".", "cvar_eta", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "if", "self", ".", "enable_double_dqn", ":", "\n", "                ", "z_values", "=", "self", ".", "model", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_policy", "]", ")", "\n", "", "else", ":", "\n", "                ", "z_values", "=", "self", ".", "target_model", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_policy", "]", ")", "\n", "", "assert", "z_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "actions", "=", "np", ".", "argmax", "(", "np", ".", "mean", "(", "z_values", ",", "axis", "=", "-", "2", ")", ",", "axis", "=", "-", "1", ")", "\n", "assert", "actions", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "tau_values_targets", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "1", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "target_z_values", "=", "self", ".", "target_model", ".", "predict_on_batch", "(", "[", "state1_batch", ",", "tau_values_targets", "]", ")", "\n", "assert", "target_z_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", "\n", "z_batch", "=", "target_z_values", "[", "range", "(", "self", ".", "batch_size", ")", ",", ":", ",", "actions", "]", "\n", "assert", "z_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ")", "\n", "\n", "targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", "self", ".", "nb_actions", ")", ")", "\n", "dummy_targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_sampled_quantiles", ",", ")", ")", "\n", "masks", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "\n", "# Compute r_t + gamma * max_a Q(s_t+1, a) and update the target targets accordingly,", "\n", "# but only for the affected output units (as given by action_batch).", "\n", "discounted_reward_batch", "=", "self", ".", "gamma", "*", "z_batch", "\n", "# Set discounted reward to zero for all states that were terminal.", "\n", "discounted_reward_batch", "*=", "terminal1_batch", "[", ":", ",", "None", "]", "\n", "assert", "discounted_reward_batch", ".", "shape", "[", "0", "]", "==", "reward_batch", ".", "shape", "[", "0", "]", "\n", "Rs", "=", "reward_batch", "[", ":", ",", "None", "]", "+", "discounted_reward_batch", "\n", "for", "idx", ",", "(", "target", ",", "mask", ",", "R", ",", "action", ")", "in", "enumerate", "(", "zip", "(", "targets", ",", "masks", ",", "Rs", ",", "action_batch", ")", ")", ":", "\n", "                ", "target", "[", ":", ",", "action", "]", "=", "R", "# update action with estimated accumulated reward", "\n", "dummy_targets", "[", "idx", ",", ":", "]", "=", "R", "\n", "mask", "[", "action", "]", "=", "1.", "# enable loss for this specific action", "\n", "", "targets", "=", "np", ".", "array", "(", "targets", ")", ".", "astype", "(", "'float32'", ")", "\n", "masks", "=", "np", ".", "array", "(", "masks", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "# Finally, perform a single update on the entire batch. We use a dummy target since", "\n", "# the actual loss is computed in a Lambda layer that needs more complex input. However,", "\n", "# it is still useful to know the actual target to compute metrics properly.", "\n", "tau_values", "=", "self", ".", "sample_tau_values", "(", "max_tau", "=", "1", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "ins", "=", "[", "state0_batch", ",", "tau_values", "]", "\n", "metrics", "=", "self", ".", "trainable_model", ".", "train_on_batch", "(", "ins", "+", "[", "targets", ",", "masks", "]", ",", "[", "dummy_targets", ",", "targets", "]", ")", "\n", "metrics", "=", "[", "metric", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "if", "\n", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "# throw away individual losses", "\n", "metrics", "+=", "self", ".", "policy", ".", "metrics", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                ", "metrics", "+=", "self", ".", "processor", ".", "metrics", "\n", "\n", "", "", "if", "self", ".", "target_model_update", ">=", "1", "and", "self", ".", "step", "%", "self", ".", "target_model_update", "==", "0", ":", "\n", "            ", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.process_state_batch": [[314, 319], ["numpy.array", "iqn.IQNAgent.processor.process_state_batch"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "process_state_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch", "=", "np", ".", "array", "(", "batch", ")", "\n", "if", "self", ".", "processor", "is", "None", ":", "\n", "            ", "return", "batch", "\n", "", "return", "self", ".", "processor", ".", "process_state_batch", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.get_config": [[320, 341], ["rl.util.get_object_config", "rl.util.get_object_config", "rl.util.get_object_config", "rl.util.get_object_config", "rl.util.get_object_config"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "'nb_actions'", ":", "self", ".", "nb_actions", ",", "\n", "'gamma'", ":", "self", ".", "gamma", ",", "\n", "'batch_size'", ":", "self", ".", "batch_size", ",", "\n", "'nb_steps_warmup'", ":", "self", ".", "nb_steps_warmup", ",", "\n", "'train_interval'", ":", "self", ".", "train_interval", ",", "\n", "'memory_interval'", ":", "self", ".", "memory_interval", ",", "\n", "'target_model_update'", ":", "self", ".", "target_model_update", ",", "\n", "'delta_clip'", ":", "self", ".", "delta_clip", ",", "\n", "'memory'", ":", "get_object_config", "(", "self", ".", "memory", ")", ",", "\n", "'enable_double_dqn'", ":", "self", ".", "enable_double_dqn", ",", "\n", "'nb_samples_policy'", ":", "self", ".", "nb_samples_policy", ",", "\n", "'nb_sampled_quantiles'", ":", "self", ".", "nb_sampled_quantiles", ",", "\n", "'model'", ":", "get_object_config", "(", "self", ".", "model", ")", ",", "\n", "'policy'", ":", "get_object_config", "(", "self", ".", "policy", ")", ",", "\n", "'test_policy'", ":", "get_object_config", "(", "self", ".", "test_policy", ")", ",", "\n", "}", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "config", "[", "'target_model'", "]", "=", "get_object_config", "(", "self", ".", "target_model", ")", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.layers": [[342, 345], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "layers", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.metrics_names": [[346, 358], ["len", "name.replace", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics_names", "(", "self", ")", ":", "\n", "# Throw away individual losses and replace output name since this is hidden from the user.", "\n", "        ", "assert", "len", "(", "self", ".", "trainable_model", ".", "output_names", ")", "==", "2", "\n", "dummy_output_name", "=", "self", ".", "trainable_model", ".", "output_names", "[", "1", "]", "\n", "model_metrics", "=", "[", "name", "for", "idx", ",", "name", "in", "enumerate", "(", "self", ".", "trainable_model", ".", "metrics_names", ")", "if", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "\n", "model_metrics", "=", "[", "name", ".", "replace", "(", "dummy_output_name", "+", "'_'", ",", "''", ")", "for", "name", "in", "model_metrics", "]", "\n", "\n", "names", "=", "model_metrics", "+", "self", ".", "policy", ".", "metrics_names", "[", ":", "]", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "            ", "names", "+=", "self", ".", "processor", ".", "metrics_names", "[", ":", "]", "\n", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.policy": [[363, 367], ["iqn.IQNAgent.__policy._set_agent"], "methods", ["None"], ["", "@", "policy", ".", "setter", "\n", "def", "policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__policy", "=", "policy", "\n", "self", ".", "__policy", ".", "_set_agent", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.test_policy": [[372, 376], ["iqn.IQNAgent.__test_policy._set_agent"], "methods", ["None"], ["", "@", "test_policy", ".", "setter", "\n", "def", "test_policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__test_policy", "=", "policy", "\n", "self", ".", "__test_policy", ".", "_set_agent", "(", "self", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.__init__": [[25, 46], ["network_architecture.NetworkMLP.build_mlp", "network_architecture.NetworkMLP.build_mlp_dueling", "network_architecture.NetworkMLP.build_prior_plus_trainable", "network_architecture.NetworkMLP.build_prior_plus_trainable_dueling", "Exception"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_mlp", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_mlp_dueling", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_prior_plus_trainable", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_prior_plus_trainable_dueling"], ["def", "__init__", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "duel", ",", "prior", ",", "prior_scale_factor", "=", "None", ",", "\n", "duel_type", "=", "'avg'", ",", "activation", "=", "'relu'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "if", "prior", ":", "\n", "            ", "assert", "prior_scale_factor", "is", "not", "None", "\n", "", "self", ".", "model", "=", "None", "\n", "if", "not", "prior", "and", "not", "duel", ":", "\n", "            ", "self", ".", "build_mlp", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "\n", "window_length", "=", "window_length", ")", "\n", "", "elif", "not", "prior", "and", "duel", ":", "\n", "            ", "self", ".", "build_mlp_dueling", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "dueling_type", "=", "duel_type", ",", "\n", "activation", "=", "activation", ",", "window_length", "=", "window_length", ")", "\n", "", "elif", "prior", "and", "not", "duel", ":", "\n", "            ", "self", ".", "build_prior_plus_trainable", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "\n", "activation", "=", "activation", ",", "prior_scale_factor", "=", "prior_scale_factor", ",", "\n", "window_length", "=", "window_length", ")", "\n", "", "elif", "prior", "and", "duel", ":", "\n", "            ", "self", ".", "build_prior_plus_trainable_dueling", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "\n", "dueling_type", "=", "duel_type", ",", "activation", "=", "activation", ",", "\n", "prior_scale_factor", "=", "prior_scale_factor", ",", "window_length", "=", "window_length", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Error in Network creation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_mlp": [[47, 54], ["keras.models.Sequential", "network_architecture.NetworkMLP.model.add", "range", "network_architecture.NetworkMLP.model.add", "keras.layers.Flatten", "network_architecture.NetworkMLP.model.add", "network_architecture.NetworkMLP.model.add", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Activation"], "methods", ["None"], ["", "", "def", "build_mlp", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "activation", "=", "'relu'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "self", ".", "model", "=", "Sequential", "(", ")", "\n", "self", ".", "model", ".", "add", "(", "Flatten", "(", "input_shape", "=", "(", "window_length", ",", "nb_inputs", ")", ")", ")", "\n", "for", "_", "in", "range", "(", "nb_hidden_layers", ")", ":", "\n", "            ", "self", ".", "model", ".", "add", "(", "Dense", "(", "nb_hidden_neurons", ")", ")", "\n", "self", ".", "model", ".", "add", "(", "Activation", "(", "activation", ")", ")", "\n", "", "self", ".", "model", ".", "add", "(", "Dense", "(", "nb_outputs", ",", "activation", "=", "'linear'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_mlp_dueling": [[55, 74], ["network_architecture.NetworkMLP.build_mlp", "keras.models.Model", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.mean", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.expand_dims"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_mlp"], ["", "def", "build_mlp_dueling", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "dueling_type", "=", "'avg'", ",", "\n", "activation", "=", "'relu'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "self", ".", "build_mlp", "(", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "\n", "window_length", "=", "window_length", ")", "\n", "layer", "=", "self", ".", "model", ".", "layers", "[", "-", "2", "]", "\n", "y", "=", "Dense", "(", "nb_outputs", "+", "1", ",", "activation", "=", "'linear'", ")", "(", "layer", ".", "output", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_outputs", ",", ")", ")", "(", "y", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_outputs", ",", ")", ")", "(", "y", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", ",", "output_shape", "=", "(", "nb_outputs", ",", ")", ")", "(", "y", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "", "self", ".", "model", "=", "Model", "(", "inputs", "=", "self", ".", "model", ".", "input", ",", "outputs", "=", "outputlayer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_prior_plus_trainable": [[75, 95], ["keras.layers.Input", "range", "range", "keras.layers.add", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Dense"], "methods", ["None"], ["", "def", "build_prior_plus_trainable", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "activation", "=", "'relu'", ",", "\n", "prior_scale_factor", "=", "1.", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "net_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'input'", ")", "\n", "\n", "prior_net", "=", "Flatten", "(", ")", "(", "net_input", ")", "\n", "for", "_", "in", "range", "(", "nb_hidden_layers", ")", ":", "\n", "            ", "prior_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "False", ")", "(", "prior_net", ")", "\n", "", "prior_out", "=", "Dense", "(", "nb_outputs", ",", "activation", "=", "'linear'", ",", "trainable", "=", "False", ",", "name", "=", "'prior_out'", ")", "(", "prior_net", ")", "\n", "prior_scale", "=", "Lambda", "(", "lambda", "x", ":", "x", "*", "prior_scale_factor", ",", "name", "=", "'prior_scale'", ")", "(", "prior_out", ")", "\n", "\n", "trainable_net", "=", "Flatten", "(", "input_shape", "=", "(", "window_length", ",", "nb_inputs", ")", ")", "(", "net_input", ")", "\n", "for", "_", "in", "range", "(", "nb_hidden_layers", ")", ":", "\n", "            ", "trainable_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "True", ")", "(", "trainable_net", ")", "\n", "", "trainable_out", "=", "Dense", "(", "nb_outputs", ",", "activation", "=", "'linear'", ",", "trainable", "=", "True", ",", "name", "=", "'trainable_out'", ")", "(", "trainable_net", ")", "\n", "\n", "add_output", "=", "add", "(", "[", "trainable_out", ",", "prior_scale", "]", ",", "name", "=", "'add'", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "net_input", ",", "outputs", "=", "add_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkMLP.build_prior_plus_trainable_dueling": [[96, 145], ["keras.layers.Input", "range", "range", "keras.layers.add", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.mean", "keras.mean", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.expand_dims", "keras.expand_dims", "keras.expand_dims"], "methods", ["None"], ["", "def", "build_prior_plus_trainable_dueling", "(", "self", ",", "nb_inputs", ",", "nb_outputs", ",", "nb_hidden_layers", ",", "nb_hidden_neurons", ",", "\n", "activation", "=", "'relu'", ",", "prior_scale_factor", "=", "1.", ",", "dueling_type", "=", "'avg'", ",", "\n", "window_length", "=", "1", ")", ":", "\n", "        ", "net_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'input'", ")", "\n", "\n", "prior_net", "=", "Flatten", "(", ")", "(", "net_input", ")", "\n", "for", "_", "in", "range", "(", "nb_hidden_layers", ")", ":", "\n", "            ", "prior_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "False", ")", "(", "prior_net", ")", "\n", "", "prior_out_wo_dueling", "=", "Dense", "(", "nb_outputs", "+", "1", ",", "activation", "=", "'linear'", ",", "trainable", "=", "False", ",", "\n", "name", "=", "'prior_out_wo_dueling'", ")", "(", "prior_net", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "prior_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_outputs", ",", ")", ",", "name", "=", "'prior_out'", ")", "(", "prior_out_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "prior_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_outputs", ",", ")", ",", "name", "=", "'prior_out'", ")", "(", "prior_out_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "prior_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", ",", "output_shape", "=", "(", "nb_outputs", ",", ")", ",", "\n", "name", "=", "'prior_out'", ")", "(", "prior_out_wo_dueling", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "", "prior_scale", "=", "Lambda", "(", "lambda", "x", ":", "x", "*", "prior_scale_factor", ",", "name", "=", "'prior_scale'", ")", "(", "prior_out", ")", "\n", "\n", "trainable_net", "=", "Flatten", "(", "input_shape", "=", "(", "window_length", ",", "nb_inputs", ")", ")", "(", "net_input", ")", "\n", "for", "_", "in", "range", "(", "nb_hidden_layers", ")", ":", "\n", "            ", "trainable_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "True", ")", "(", "trainable_net", ")", "\n", "", "trainable_out_wo_dueling", "=", "Dense", "(", "nb_outputs", "+", "1", ",", "activation", "=", "'linear'", ",", "trainable", "=", "True", ",", "\n", "name", "=", "'trainable_out_wo_dueling'", ")", "(", "trainable_net", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "trainable_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_outputs", ",", ")", ",", "name", "=", "'trainable_out'", ")", "(", "trainable_out_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "trainable_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_outputs", ",", ")", ",", "name", "=", "'trainable_out'", ")", "(", "trainable_out_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "trainable_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", ",", "output_shape", "=", "(", "nb_outputs", ",", ")", ",", "\n", "name", "=", "'trainable_out'", ")", "(", "trainable_out_wo_dueling", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "\n", "", "add_output", "=", "add", "(", "[", "trainable_out", ",", "prior_scale", "]", ",", "name", "=", "'add'", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "net_input", ",", "outputs", "=", "add_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.__init__": [[170, 191], ["network_architecture.NetworkCNN.build_cnn", "network_architecture.NetworkCNN.build_cnn_dueling", "network_architecture.NetworkCNN.build_cnn_dueling_prior", "Exception"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn_dueling", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn_dueling_prior"], ["def", "__init__", "(", "self", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "nb_conv_filters", ",", "\n", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "duel", ",", "prior", ",", "prior_scale_factor", "=", "None", ",", "duel_type", "=", "'avg'", ",", "\n", "activation", "=", "'relu'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "if", "prior", ":", "\n", "            ", "assert", "prior_scale_factor", "is", "not", "None", "\n", "", "self", ".", "model", "=", "None", "\n", "if", "not", "prior", "and", "not", "duel", ":", "\n", "            ", "self", ".", "build_cnn", "(", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "\n", "window_length", "=", "window_length", ")", "\n", "", "elif", "not", "prior", "and", "duel", ":", "\n", "            ", "self", ".", "build_cnn_dueling", "(", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "dueling_type", "=", "duel_type", ",", "\n", "activation", "=", "activation", ",", "window_length", "=", "window_length", ")", "\n", "", "elif", "prior", ":", "\n", "            ", "self", ".", "build_cnn_dueling_prior", "(", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "duel", ",", "\n", "dueling_type", "=", "duel_type", ",", "activation", "=", "activation", ",", "\n", "prior_scale_factor", "=", "prior_scale_factor", ",", "window_length", "=", "window_length", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Error in Network creation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn": [[192, 228], ["keras.layers.Input", "range", "range", "keras.layers.concatenate", "range", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Reshape", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.MaxPooling1D", "keras.layers.Reshape", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.Dense", "str"], "methods", ["None"], ["", "", "def", "build_cnn", "(", "self", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "nb_conv_filters", ",", "\n", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "activation", "=", "'relu'", ",", "window_length", "=", "1", ")", ":", "\n", "        ", "nb_inputs", "=", "nb_ego_states", "+", "nb_states_per_vehicle", "*", "nb_vehicles", "\n", "\n", "net_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'input'", ")", "\n", "flat_input", "=", "Flatten", "(", "data_format", "=", "'channels_first'", ")", "(", "net_input", ")", "\n", "\n", "input_ego", "=", "Lambda", "(", "lambda", "state", ":", "state", "[", ":", ",", ":", "nb_ego_states", "*", "window_length", "]", ")", "(", "flat_input", ")", "\n", "input_others", "=", "Lambda", "(", "lambda", "state", ":", "state", "[", ":", ",", "nb_ego_states", "*", "window_length", ":", "]", ")", "(", "flat_input", ")", "\n", "input_others_reshaped", "=", "Reshape", "(", "(", "nb_vehicles", "*", "nb_states_per_vehicle", "*", "window_length", ",", "1", ",", ")", ",", "\n", "input_shape", "=", "(", "nb_vehicles", "*", "nb_states_per_vehicle", "*", "\n", "window_length", ",", ")", ")", "(", "input_others", ")", "\n", "\n", "ego_net", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "name", "=", "'ego_0'", ")", "(", "input_ego", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "ego_net", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "name", "=", "'ego_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "ego_net", ")", "\n", "", "conv_net", "=", "Conv1D", "(", "nb_conv_filters", ",", "nb_states_per_vehicle", "*", "window_length", ",", "\n", "strides", "=", "nb_states_per_vehicle", "*", "window_length", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ")", "(", "input_others_reshaped", ")", "\n", "for", "_", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "conv_net", "=", "Conv1D", "(", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ")", "(", "conv_net", ")", "\n", "", "pool", "=", "MaxPooling1D", "(", "pool_size", "=", "nb_vehicles", ")", "(", "conv_net", ")", "\n", "conv_net_out", "=", "Reshape", "(", "(", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "1", ",", "nb_conv_filters", ",", ")", ",", "name", "=", "'convnet_out'", ")", "(", "pool", ")", "\n", "\n", "merged", "=", "concatenate", "(", "[", "ego_net", ",", "conv_net_out", "]", ")", "\n", "\n", "joint_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ")", "(", "merged", ")", "\n", "for", "_", "in", "range", "(", "nb_hidden_fc_layers", "-", "1", ")", ":", "\n", "            ", "joint_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ")", "(", "joint_net", ")", "\n", "\n", "", "output", "=", "Dense", "(", "nb_actions", ",", "activation", "=", "'linear'", ",", "name", "=", "'output'", ")", "(", "joint_net", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "net_input", ",", "outputs", "=", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn_dueling": [[229, 251], ["network_architecture.NetworkCNN.build_cnn", "keras.models.Model", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.mean", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.expand_dims"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn"], ["", "def", "build_cnn_dueling", "(", "self", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "activation", "=", "'relu'", ",", "window_length", "=", "1", ",", "\n", "dueling_type", "=", "'avg'", ")", ":", "\n", "        ", "self", ".", "build_cnn", "(", "nb_ego_states", "=", "nb_ego_states", ",", "nb_states_per_vehicle", "=", "nb_states_per_vehicle", ",", "\n", "nb_vehicles", "=", "nb_vehicles", ",", "nb_actions", "=", "nb_actions", ",", "nb_conv_layers", "=", "nb_conv_layers", ",", "\n", "nb_conv_filters", "=", "nb_conv_filters", ",", "nb_hidden_fc_layers", "=", "nb_hidden_fc_layers", ",", "\n", "nb_hidden_neurons", "=", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "window_length", "=", "window_length", ")", "\n", "layer", "=", "self", ".", "model", ".", "layers", "[", "-", "2", "]", "\n", "y", "=", "Dense", "(", "nb_actions", "+", "1", ",", "activation", "=", "'linear'", ")", "(", "layer", ".", "output", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_actions", ",", ")", ")", "(", "y", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_actions", ",", ")", ")", "(", "y", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "            ", "outputlayer", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", ",", "output_shape", "=", "(", "nb_actions", ",", ")", ")", "(", "y", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "", "self", ".", "model", "=", "Model", "(", "inputs", "=", "self", ".", "model", ".", "input", ",", "outputs", "=", "outputlayer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.network_architecture.NetworkCNN.build_cnn_dueling_prior": [[252, 348], ["keras.layers.Input", "range", "range", "keras.layers.concatenate", "range", "range", "range", "keras.layers.concatenate", "range", "keras.layers.add", "keras.models.Model", "keras.layers.Flatten", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Reshape", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.MaxPooling1D", "keras.layers.Reshape", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.MaxPooling1D", "keras.layers.Reshape", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Conv1D", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "str", "keras.layers.Lambda", "str", "keras.layers.Lambda", "keras.mean", "keras.mean", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.max", "keras.expand_dims", "keras.expand_dims", "keras.expand_dims", "keras.expand_dims"], "methods", ["None"], ["", "def", "build_cnn_dueling_prior", "(", "self", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "\n", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "duel", ",", "activation", "=", "'relu'", ",", "\n", "window_length", "=", "1", ",", "dueling_type", "=", "'avg'", ",", "prior_scale_factor", "=", "1.", ")", ":", "\n", "        ", "nb_inputs", "=", "nb_ego_states", "+", "nb_states_per_vehicle", "*", "nb_vehicles", "\n", "\n", "net_input", "=", "Input", "(", "shape", "=", "(", "window_length", ",", "nb_inputs", ")", ",", "name", "=", "'input'", ")", "\n", "flat_input", "=", "Flatten", "(", "data_format", "=", "'channels_first'", ")", "(", "net_input", ")", "\n", "input_ego", "=", "Lambda", "(", "lambda", "state", ":", "state", "[", ":", ",", ":", "nb_ego_states", "*", "window_length", "]", ")", "(", "flat_input", ")", "\n", "input_others", "=", "Lambda", "(", "lambda", "state", ":", "state", "[", ":", ",", "nb_ego_states", "*", "window_length", ":", "]", ")", "(", "flat_input", ")", "\n", "input_others_reshaped", "=", "Reshape", "(", "(", "nb_vehicles", "*", "nb_states_per_vehicle", "*", "window_length", ",", "1", ",", ")", ",", "\n", "input_shape", "=", "(", "nb_vehicles", "*", "nb_states_per_vehicle", "*", "\n", "window_length", ",", ")", ")", "(", "input_others", ")", "\n", "\n", "ego_net_prior", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "False", ",", "name", "=", "'ego_prior_0'", ")", "(", "input_ego", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "ego_net_prior", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "False", ",", "name", "=", "'ego_prior_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "ego_net_prior", ")", "\n", "", "prior_conv_net", "=", "Conv1D", "(", "nb_conv_filters", ",", "nb_states_per_vehicle", "*", "window_length", ",", "\n", "strides", "=", "nb_states_per_vehicle", "*", "window_length", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ",", "trainable", "=", "False", ")", "(", "input_others_reshaped", ")", "\n", "for", "_", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "prior_conv_net", "=", "Conv1D", "(", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ",", "trainable", "=", "False", ")", "(", "prior_conv_net", ")", "\n", "", "prior_pool", "=", "MaxPooling1D", "(", "pool_size", "=", "nb_vehicles", ")", "(", "prior_conv_net", ")", "\n", "prior_conv_net_out", "=", "Reshape", "(", "(", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "1", ",", "nb_conv_filters", ",", ")", ",", "\n", "name", "=", "'prior_convnet_out'", ")", "(", "prior_pool", ")", "\n", "prior_merged", "=", "concatenate", "(", "[", "ego_net_prior", ",", "prior_conv_net_out", "]", ")", "\n", "prior_joint_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "False", ")", "(", "prior_merged", ")", "\n", "for", "_", "in", "range", "(", "nb_hidden_fc_layers", "-", "1", ")", ":", "\n", "            ", "prior_joint_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "False", ")", "(", "prior_joint_net", ")", "\n", "", "if", "duel", ":", "\n", "            ", "prior_out_wo_dueling", "=", "Dense", "(", "nb_actions", "+", "1", ",", "activation", "=", "'linear'", ",", "name", "=", "'prior_out_wo_dueling'", ",", "\n", "trainable", "=", "False", ")", "(", "prior_joint_net", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "                ", "prior_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_actions", ",", ")", ",", "name", "=", "'prior_out'", ")", "(", "prior_out_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "                ", "prior_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_actions", ",", ")", ",", "name", "=", "'prior_out'", ")", "(", "prior_out_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "                ", "prior_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", ",", "\n", "output_shape", "=", "(", "nb_actions", ",", ")", ",", "name", "=", "'prior_out'", ")", "(", "prior_out_wo_dueling", ")", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "", "", "else", ":", "\n", "            ", "prior_out", "=", "Dense", "(", "nb_actions", ",", "activation", "=", "'linear'", ",", "name", "=", "'prior_out'", ",", "trainable", "=", "False", ")", "(", "prior_joint_net", ")", "\n", "", "prior_scale", "=", "Lambda", "(", "lambda", "x", ":", "x", "*", "prior_scale_factor", ",", "name", "=", "'prior_scale'", ")", "(", "prior_out", ")", "\n", "\n", "ego_net_trainable", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "name", "=", "'ego_trainable_0'", ")", "(", "input_ego", ")", "\n", "for", "i", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "ego_net_trainable", "=", "Dense", "(", "nb_conv_filters", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "name", "=", "'ego_trainable_'", "+", "str", "(", "i", "+", "1", ")", ")", "(", "ego_net_trainable", ")", "\n", "", "trainable_conv_net", "=", "Conv1D", "(", "nb_conv_filters", ",", "nb_states_per_vehicle", "*", "window_length", ",", "\n", "strides", "=", "nb_states_per_vehicle", "*", "window_length", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ",", "trainable", "=", "True", ")", "(", "input_others_reshaped", ")", "\n", "for", "_", "in", "range", "(", "nb_conv_layers", "-", "1", ")", ":", "\n", "            ", "trainable_conv_net", "=", "Conv1D", "(", "nb_conv_filters", ",", "1", ",", "strides", "=", "1", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "'glorot_normal'", ",", "trainable", "=", "True", ")", "(", "trainable_conv_net", ")", "\n", "", "trainable_pool", "=", "MaxPooling1D", "(", "pool_size", "=", "nb_vehicles", ")", "(", "trainable_conv_net", ")", "\n", "trainable_conv_net_out", "=", "Reshape", "(", "(", "nb_conv_filters", ",", ")", ",", "input_shape", "=", "(", "1", ",", "nb_conv_filters", ",", ")", ",", "\n", "name", "=", "'trainable_convnet_out'", ")", "(", "trainable_pool", ")", "\n", "trainable_merged", "=", "concatenate", "(", "[", "ego_net_trainable", ",", "trainable_conv_net_out", "]", ")", "\n", "trainable_joint_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "True", ")", "(", "trainable_merged", ")", "\n", "for", "_", "in", "range", "(", "nb_hidden_fc_layers", "-", "1", ")", ":", "\n", "            ", "trainable_joint_net", "=", "Dense", "(", "nb_hidden_neurons", ",", "activation", "=", "activation", ",", "kernel_initializer", "=", "'glorot_normal'", ",", "\n", "trainable", "=", "True", ")", "(", "trainable_joint_net", ")", "\n", "", "if", "duel", ":", "\n", "            ", "trainable_out_wo_dueling", "=", "Dense", "(", "nb_actions", "+", "1", ",", "activation", "=", "'linear'", ",", "name", "=", "'trainable_out_wo_dueling'", ",", "\n", "trainable", "=", "True", ")", "(", "trainable_joint_net", ")", "\n", "if", "dueling_type", "==", "'avg'", ":", "\n", "                ", "trainable_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "mean", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_actions", ",", ")", ",", "name", "=", "'trainable_out'", ")", "(", "trainable_out_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'max'", ":", "\n", "                ", "trainable_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", "-", "\n", "K", ".", "max", "(", "a", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "\n", "output_shape", "=", "(", "nb_actions", ",", ")", ",", "name", "=", "'trainable_out'", ")", "(", "trainable_out_wo_dueling", ")", "\n", "", "elif", "dueling_type", "==", "'naive'", ":", "\n", "                ", "trainable_out", "=", "Lambda", "(", "lambda", "a", ":", "K", ".", "expand_dims", "(", "a", "[", ":", ",", "0", "]", ",", "-", "1", ")", "+", "a", "[", ":", ",", "1", ":", "]", ",", "\n", "output_shape", "=", "(", "nb_actions", ",", ")", ",", "name", "=", "'trainable_out'", ")", "(", "trainable_out_wo_dueling", ")", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "\"dueling_type must be one of {'avg','max','naive'}\"", "\n", "", "", "else", ":", "\n", "            ", "trainable_out", "=", "Dense", "(", "nb_actions", ",", "activation", "=", "'linear'", ",", "name", "=", "'trainable_out'", ",", "\n", "trainable", "=", "True", ")", "(", "trainable_joint_net", ")", "\n", "\n", "", "add_output", "=", "add", "(", "[", "trainable_out", ",", "prior_scale", "]", ",", "name", "=", "'final_output'", ")", "\n", "\n", "self", ".", "model", "=", "Model", "(", "inputs", "=", "net_input", ",", "outputs", "=", "add_output", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_visualization.IQNVisualization.__init__": [[15, 77], ["matplotlib.figure", "matplotlib.gca", "iqn_visualization.IQNVisualization.ax1.axis", "numpy.arange", "iqn_visualization.IQNVisualization.ax1.bar", "iqn_visualization.IQNVisualization.ax1.bar", "matplotlib.get_current_fig_manager", "matplotlib.get_current_fig_manager.window.wm_geometry", "matplotlib.figure", "matplotlib.gca", "iqn_visualization.IQNVisualization.ax2.axis", "iqn_visualization.IQNVisualization.ax2.axvline", "iqn_visualization.IQNVisualization.ax2.legend", "matplotlib.get_current_fig_manager", "matplotlib.get_current_fig_manager.window.wm_geometry", "matplotlib.subplots", "iqn_visualization.IQNVisualization.ax31.axis", "iqn_visualization.IQNVisualization.ax31.hist", "iqn_visualization.IQNVisualization.ax32.axis", "iqn_visualization.IQNVisualization.ax32.hist", "iqn_visualization.IQNVisualization.ax31.legend", "iqn_visualization.IQNVisualization.ax32.legend", "matplotlib.get_current_fig_manager", "matplotlib.get_current_fig_manager.window.wm_geometry", "iqn_visualization.IQNVisualization.fig1.canvas.draw", "iqn_visualization.IQNVisualization.fig2.canvas.draw", "iqn_visualization.IQNVisualization.fig3.canvas.draw", "iqn_visualization.IQNVisualization.fig1.canvas.copy_from_bbox", "iqn_visualization.IQNVisualization.fig2.canvas.copy_from_bbox", "iqn_visualization.IQNVisualization.fig3.canvas.copy_from_bbox", "iqn_visualization.IQNVisualization.fig3.canvas.copy_from_bbox", "matplotlib.show", "numpy.zeros", "numpy.zeros", "iqn_visualization.IQNVisualization.ax1.text", "iqn_visualization.IQNVisualization.ax1.text", "iqn_visualization.IQNVisualization.ax1.text", "iqn_visualization.IQNVisualization.ax1.text", "iqn_visualization.IQNVisualization.ax2.plot", "range", "range", "range", "range", "zip", "numpy.ones", "numpy.ones", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.plot_decision_map.DecisionMap.plot"], ["def", "__init__", "(", "self", ",", "nb_actions", ",", "nb_quantiles", ",", "iqn", ",", "cvar_eta", "=", "1", ")", ":", "\n", "        ", "v_max", "=", "15", "\n", "v_min", "=", "-", "15", "\n", "\n", "self", ".", "iqn", "=", "iqn", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "self", ".", "nb_quantiles", "=", "nb_quantiles", "\n", "\n", "# Bars showing Q-values", "\n", "self", ".", "fig1", "=", "plt", ".", "figure", "(", ")", "\n", "self", ".", "ax1", "=", "plt", ".", "gca", "(", ")", "\n", "self", ".", "ax1", ".", "title", ".", "_text", "=", "'Q-values (cruise, go, stop)'", "\n", "self", ".", "ax1", ".", "axis", "(", "[", "-", "1", ",", "self", ".", "nb_actions", ",", "v_min", ",", "v_max", "]", ")", "\n", "labels", "=", "(", "'cruise'", ",", "'go'", ",", "'stop'", ")", "\n", "x", "=", "np", ".", "arange", "(", "self", ".", "nb_actions", ")", "\n", "self", ".", "bars_neutral", "=", "self", ".", "ax1", ".", "bar", "(", "x", ",", "np", ".", "zeros", "(", "self", ".", "nb_actions", ")", ",", "width", "=", "0.4", ")", "\n", "self", ".", "bars_risk", "=", "self", ".", "ax1", ".", "bar", "(", "x", "+", "0.5", ",", "np", ".", "zeros", "(", "self", ".", "nb_actions", ")", ",", "width", "=", "0.4", ")", "\n", "self", ".", "text_neutral", "=", "[", "self", ".", "ax1", ".", "text", "(", "i", "-", "0.2", ",", "0", ",", "''", ")", "for", "i", "in", "range", "(", "self", ".", "nb_actions", ")", "]", "\n", "self", ".", "text2_neutral", "=", "[", "self", ".", "ax1", ".", "text", "(", "i", "-", "0.2", ",", "5", ",", "''", ")", "for", "i", "in", "range", "(", "self", ".", "nb_actions", ")", "]", "\n", "self", ".", "text_risk", "=", "[", "self", ".", "ax1", ".", "text", "(", "i", "-", "0.2", "+", "0.5", ",", "0", ",", "''", ")", "for", "i", "in", "range", "(", "self", ".", "nb_actions", ")", "]", "\n", "self", ".", "text2_risk", "=", "[", "self", ".", "ax1", ".", "text", "(", "i", "-", "0.2", "+", "0.5", ",", "5", ",", "''", ")", "for", "i", "in", "range", "(", "self", ".", "nb_actions", ")", "]", "\n", "mngr", "=", "plt", ".", "get_current_fig_manager", "(", ")", "\n", "mngr", ".", "window", ".", "wm_geometry", "(", "\"+0+500\"", ")", "\n", "\n", "# quantile function", "\n", "self", ".", "fig2", "=", "plt", ".", "figure", "(", ")", "\n", "self", ".", "ax2", "=", "plt", ".", "gca", "(", ")", "\n", "self", ".", "ax2", ".", "title", ".", "_text", "=", "'Quantile function'", "\n", "self", ".", "ax2", ".", "axis", "(", "[", "0", ",", "1", ",", "v_min", ",", "v_max", "]", ")", "\n", "self", ".", "lines", "=", "[", "self", ".", "ax2", ".", "plot", "(", "[", "]", ",", "[", "]", ",", "'x'", ",", "c", "=", "color", ",", "label", "=", "labels", "[", "ii", "]", ")", "for", "(", "ii", ",", "color", ")", "\n", "in", "zip", "(", "range", "(", "self", ".", "nb_actions", ")", ",", "[", "'y'", ",", "'g'", ",", "'r'", "]", ")", "]", "\n", "self", ".", "ax2", ".", "axvline", "(", "cvar_eta", ",", "c", "=", "'k'", ")", "\n", "self", ".", "ax2", ".", "legend", "(", ")", "\n", "mngr2", "=", "plt", ".", "get_current_fig_manager", "(", ")", "\n", "mngr2", ".", "window", ".", "wm_geometry", "(", "\"+700+500\"", ")", "\n", "\n", "# histogram pdf", "\n", "z_min", "=", "v_min", "\n", "z_max", "=", "v_max", "\n", "p_max", "=", "self", ".", "nb_quantiles", "\n", "self", ".", "nb_bins", "=", "100", "\n", "self", ".", "fig3", ",", "(", "self", ".", "ax31", ",", "self", ".", "ax32", ")", "=", "plt", ".", "subplots", "(", "2", ")", "\n", "self", ".", "ax31", ".", "title", ".", "_text", "=", "'Histogram'", "\n", "self", ".", "ax31", ".", "axis", "(", "[", "z_min", ",", "z_max", ",", "0", ",", "p_max", "]", ")", "\n", "self", ".", "hist_neutral", "=", "self", ".", "ax31", ".", "hist", "(", "np", ".", "ones", "(", "(", "self", ".", "nb_quantiles", ",", "self", ".", "nb_actions", ")", ")", "*", "1000", ",", "bins", "=", "self", ".", "nb_bins", ",", "\n", "range", "=", "[", "z_min", ",", "z_max", "]", ",", "label", "=", "labels", ",", "color", "=", "[", "'y'", ",", "'g'", ",", "'r'", "]", ")", "\n", "self", ".", "ax32", ".", "axis", "(", "[", "z_min", ",", "z_max", ",", "0", ",", "p_max", "]", ")", "\n", "self", ".", "hist_risk", "=", "self", ".", "ax32", ".", "hist", "(", "np", ".", "ones", "(", "(", "self", ".", "nb_quantiles", ",", "self", ".", "nb_actions", ")", ")", "*", "1000", ",", "bins", "=", "self", ".", "nb_bins", ",", "\n", "range", "=", "[", "z_min", ",", "z_max", "]", ",", "label", "=", "labels", ",", "color", "=", "[", "'y'", ",", "'g'", ",", "'r'", "]", ")", "\n", "self", ".", "ax31", ".", "legend", "(", ")", "\n", "self", ".", "ax32", ".", "legend", "(", ")", "\n", "mngr3", "=", "plt", ".", "get_current_fig_manager", "(", ")", "\n", "mngr3", ".", "window", ".", "wm_geometry", "(", "\"+1400+500\"", ")", "\n", "\n", "self", ".", "fig1", ".", "canvas", ".", "draw", "(", ")", "\n", "self", ".", "fig2", ".", "canvas", ".", "draw", "(", ")", "\n", "self", ".", "fig3", ".", "canvas", ".", "draw", "(", ")", "\n", "self", ".", "ax1background", "=", "self", ".", "fig1", ".", "canvas", ".", "copy_from_bbox", "(", "self", ".", "ax1", ".", "bbox", ")", "\n", "self", ".", "ax2background", "=", "self", ".", "fig2", ".", "canvas", ".", "copy_from_bbox", "(", "self", ".", "ax2", ".", "bbox", ")", "\n", "self", ".", "ax31background", "=", "self", ".", "fig3", ".", "canvas", ".", "copy_from_bbox", "(", "self", ".", "ax31", ".", "bbox", ")", "\n", "self", ".", "ax32background", "=", "self", ".", "fig3", ".", "canvas", ".", "copy_from_bbox", "(", "self", ".", "ax32", ".", "bbox", ")", "\n", "plt", ".", "show", "(", "block", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_visualization.IQNVisualization.update_plots": [[78, 152], ["enumerate", "iqn_visualization.IQNVisualization.fig1.canvas.restore_region", "zip", "iqn_visualization.IQNVisualization.fig1.canvas.blit", "iqn_visualization.IQNVisualization.fig1.canvas.flush_events", "numpy.mean", "numpy.mean", "enumerate", "iqn_visualization.IQNVisualization.bars_neutral[].set_color", "range", "iqn_visualization.IQNVisualization.fig1.canvas.restore_region", "iqn_visualization.IQNVisualization.fig2.canvas.restore_region", "iqn_visualization.IQNVisualization.fig3.canvas.restore_region", "iqn_visualization.IQNVisualization.fig3.canvas.restore_region", "zip", "iqn_visualization.IQNVisualization.fig1.canvas.blit", "iqn_visualization.IQNVisualization.fig1.canvas.flush_events", "iqn_visualization.IQNVisualization.fig2.canvas.blit", "iqn_visualization.IQNVisualization.fig2.canvas.flush_events", "range", "iqn_visualization.IQNVisualization.fig3.canvas.blit", "iqn_visualization.IQNVisualization.fig3.canvas.blit", "iqn_visualization.IQNVisualization.fig3.canvas.flush_events", "zip", "bar.set_height", "bar.set_color", "iqn_visualization.IQNVisualization.text_neutral[].set_text", "iqn_visualization.IQNVisualization.text2_neutral[].set_text", "iqn_visualization.IQNVisualization.bars_neutral[].set_color", "iqn_visualization.IQNVisualization.ax1.draw_artist", "iqn_visualization.IQNVisualization.ax1.draw_artist", "iqn_visualization.IQNVisualization.ax1.draw_artist", "zip", "bar_neutral.set_height", "bar_neutral.set_color", "bar_risk.set_height", "bar_risk.set_color", "iqn_visualization.IQNVisualization.text_neutral[].set_text", "iqn_visualization.IQNVisualization.text2_neutral[].set_text", "iqn_visualization.IQNVisualization.text_risk[].set_text", "iqn_visualization.IQNVisualization.text2_risk[].set_text", "line[].set_xdata", "line[].set_ydata", "iqn_visualization.IQNVisualization.bars_risk[].set_color", "numpy.histogram", "numpy.histogram", "range", "iqn_visualization.IQNVisualization.ax1.draw_artist", "iqn_visualization.IQNVisualization.ax1.draw_artist", "iqn_visualization.IQNVisualization.ax1.draw_artist", "iqn_visualization.IQNVisualization.ax1.draw_artist", "iqn_visualization.IQNVisualization.ax1.draw_artist", "iqn_visualization.IQNVisualization.ax2.draw_artist", "range", "range", "range", "[].set_height", "[].set_height", "iqn_visualization.IQNVisualization.ax31.draw_artist", "iqn_visualization.IQNVisualization.ax32.draw_artist", "numpy.max", "numpy.max", "numpy.max", "numpy.argmax", "iqn_visualization.IQNVisualization.ax31.axis", "iqn_visualization.IQNVisualization.ax31.axis", "iqn_visualization.IQNVisualization.ax32.axis", "iqn_visualization.IQNVisualization.ax32.axis"], "methods", ["None"], ["", "def", "update_plots", "(", "self", ",", "action", ",", "z_values", "=", "None", ",", "quantiles", "=", "None", ",", "z_values_detailed", "=", "None", ",", "quantiles_detailed", "=", "None", ",", "\n", "q_values", "=", "None", ")", ":", "\n", "        ", "if", "not", "self", ".", "iqn", ":", "\n", "            ", "q_values", "=", "q_values", "\n", "for", "idx", ",", "(", "bar", ",", "line", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "bars_neutral", ",", "self", ".", "lines", ")", ")", ":", "\n", "                ", "bar", ".", "set_height", "(", "q_values", "[", "idx", "]", ")", "\n", "bar", ".", "set_color", "(", "'g'", ")", "\n", "self", ".", "text_neutral", "[", "idx", "]", ".", "set_text", "(", "'%.3f'", "%", "q_values", "[", "idx", "]", ")", "\n", "self", ".", "text2_neutral", "[", "idx", "]", ".", "set_text", "(", "'%.3f'", "%", "(", "q_values", "[", "idx", "]", "-", "np", ".", "max", "(", "q_values", ")", ")", ")", "\n", "", "if", "action", "<", "self", ".", "nb_actions", ":", "\n", "                ", "self", ".", "bars_neutral", "[", "action", "]", ".", "set_color", "(", "'r'", ")", "\n", "", "self", ".", "fig1", ".", "canvas", ".", "restore_region", "(", "self", ".", "ax1background", ")", "\n", "for", "(", "bar", ",", "text_", ",", "text2_", ")", "in", "zip", "(", "self", ".", "bars_neutral", ",", "self", ".", "text_neutral", ",", "self", ".", "text2_neutral", ")", ":", "\n", "                ", "self", ".", "ax1", ".", "draw_artist", "(", "bar", ")", "\n", "self", ".", "ax1", ".", "draw_artist", "(", "text_", ")", "\n", "self", ".", "ax1", ".", "draw_artist", "(", "text2_", ")", "\n", "", "self", ".", "fig1", ".", "canvas", ".", "blit", "(", "self", ".", "ax1", ".", "bbox", ")", "\n", "self", ".", "fig1", ".", "canvas", ".", "flush_events", "(", ")", "\n", "", "else", ":", "\n", "            ", "q_values_neutral", "=", "np", ".", "mean", "(", "z_values_detailed", ",", "axis", "=", "0", ")", "\n", "q_values_risk", "=", "np", ".", "mean", "(", "z_values", ",", "axis", "=", "0", ")", "\n", "for", "idx", ",", "(", "bar_neutral", ",", "bar_risk", ",", "line", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "bars_neutral", ",", "self", ".", "bars_risk", ",", "self", ".", "lines", ")", ")", ":", "\n", "                ", "bar_neutral", ".", "set_height", "(", "q_values_neutral", "[", "idx", "]", ")", "\n", "bar_neutral", ".", "set_color", "(", "'g'", ")", "\n", "bar_risk", ".", "set_height", "(", "q_values_risk", "[", "idx", "]", ")", "\n", "bar_risk", ".", "set_color", "(", "'g'", ")", "\n", "self", ".", "text_neutral", "[", "idx", "]", ".", "set_text", "(", "'%.3f'", "%", "q_values_neutral", "[", "idx", "]", ")", "\n", "self", ".", "text2_neutral", "[", "idx", "]", ".", "set_text", "(", "'%.3f'", "%", "(", "q_values_neutral", "[", "idx", "]", "-", "np", ".", "max", "(", "q_values_neutral", ")", ")", ")", "\n", "self", ".", "text_risk", "[", "idx", "]", ".", "set_text", "(", "'%.3f'", "%", "q_values_risk", "[", "idx", "]", ")", "\n", "self", ".", "text2_risk", "[", "idx", "]", ".", "set_text", "(", "'%.3f'", "%", "(", "q_values_risk", "[", "idx", "]", "-", "np", ".", "max", "(", "q_values_risk", ")", ")", ")", "\n", "line", "[", "0", "]", ".", "set_xdata", "(", "quantiles_detailed", ")", "\n", "line", "[", "0", "]", ".", "set_ydata", "(", "z_values_detailed", "[", ":", ",", "idx", "]", ")", "\n", "", "self", ".", "bars_neutral", "[", "np", ".", "argmax", "(", "q_values_neutral", ")", "]", ".", "set_color", "(", "'r'", ")", "\n", "if", "action", "<", "self", ".", "nb_actions", ":", "\n", "                ", "self", ".", "bars_risk", "[", "action", "]", ".", "set_color", "(", "'r'", ")", "\n", "\n", "", "np_hist_neutral", "=", "[", "np", ".", "histogram", "(", "z_values_detailed", "[", ":", ",", "i", "]", ",", "self", ".", "nb_bins", ",", "\n", "range", "=", "(", "self", ".", "ax31", ".", "axis", "(", ")", "[", "0", "]", ",", "self", ".", "ax31", ".", "axis", "(", ")", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_actions", ")", "]", "\n", "np_hist_risk", "=", "[", "np", ".", "histogram", "(", "z_values", "[", ":", ",", "i", "]", ",", "self", ".", "nb_bins", ",", "range", "=", "(", "self", ".", "ax32", ".", "axis", "(", ")", "[", "0", "]", ",", "self", ".", "ax32", ".", "axis", "(", ")", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_actions", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_actions", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "self", ".", "nb_bins", ")", ":", "\n", "                    ", "self", ".", "hist_neutral", "[", "-", "1", "]", "[", "i", "]", "[", "j", "]", ".", "set_height", "(", "np_hist_neutral", "[", "i", "]", "[", "0", "]", "[", "j", "]", ")", "\n", "self", ".", "hist_risk", "[", "-", "1", "]", "[", "i", "]", "[", "j", "]", ".", "set_height", "(", "np_hist_risk", "[", "i", "]", "[", "0", "]", "[", "j", "]", ")", "\n", "\n", "", "", "self", ".", "fig1", ".", "canvas", ".", "restore_region", "(", "self", ".", "ax1background", ")", "\n", "self", ".", "fig2", ".", "canvas", ".", "restore_region", "(", "self", ".", "ax2background", ")", "\n", "self", ".", "fig3", ".", "canvas", ".", "restore_region", "(", "self", ".", "ax31background", ")", "\n", "self", ".", "fig3", ".", "canvas", ".", "restore_region", "(", "self", ".", "ax32background", ")", "\n", "\n", "for", "(", "bar", ",", "text_neutral_", ",", "text2_neutral_", ",", "text_risk_", ",", "text2_risk_", ")", "in", "zip", "(", "self", ".", "bars_neutral", ",", "self", ".", "text_neutral", ",", "self", ".", "text2_neutral", ",", "self", ".", "text_risk", ",", "self", ".", "text2_risk", ")", ":", "\n", "                ", "self", ".", "ax1", ".", "draw_artist", "(", "bar", ")", "\n", "self", ".", "ax1", ".", "draw_artist", "(", "text_neutral_", ")", "\n", "self", ".", "ax1", ".", "draw_artist", "(", "text2_neutral_", ")", "\n", "self", ".", "ax1", ".", "draw_artist", "(", "text_risk_", ")", "\n", "self", ".", "ax1", ".", "draw_artist", "(", "text2_risk_", ")", "\n", "", "self", ".", "fig1", ".", "canvas", ".", "blit", "(", "self", ".", "ax1", ".", "bbox", ")", "\n", "self", ".", "fig1", ".", "canvas", ".", "flush_events", "(", ")", "\n", "\n", "for", "line", "in", "self", ".", "lines", ":", "\n", "                ", "self", ".", "ax2", ".", "draw_artist", "(", "line", "[", "0", "]", ")", "\n", "", "self", ".", "fig2", ".", "canvas", ".", "blit", "(", "self", ".", "ax2", ".", "bbox", ")", "\n", "self", ".", "fig2", ".", "canvas", ".", "flush_events", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_actions", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "self", ".", "nb_bins", ")", ":", "\n", "                    ", "self", ".", "ax31", ".", "draw_artist", "(", "self", ".", "hist_neutral", "[", "-", "1", "]", "[", "i", "]", "[", "j", "]", ")", "\n", "self", ".", "ax32", ".", "draw_artist", "(", "self", ".", "hist_risk", "[", "-", "1", "]", "[", "i", "]", "[", "j", "]", ")", "\n", "", "", "self", ".", "fig3", ".", "canvas", ".", "blit", "(", "self", ".", "ax31", ".", "bbox", ")", "\n", "self", ".", "fig3", ".", "canvas", ".", "blit", "(", "self", ".", "ax32", ".", "bbox", ")", "\n", "self", ".", "fig3", ".", "canvas", ".", "flush_events", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.__init__": [[18, 25], ["os.path.isdir", "os.mkdir"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "road_params", ",", "road_path", "=", "'../road/'", ",", "start_time", "=", "''", ")", ":", "\n", "        ", "self", ".", "road_params", "=", "road_params", "\n", "self", ".", "road_path", "=", "road_path", "\n", "self", ".", "name", "=", "self", ".", "road_params", "[", "'name'", "]", "+", "'_'", "+", "start_time", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "road_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "road_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.nodes": [[26, 36], ["open", "text_file.writelines", "enumerate", "enumerate", "text_file.writelines", "text_file.writelines", "text_file.writelines", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "", "def", "nodes", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.nod.xml'", ",", "'w'", ")", "as", "text_file", ":", "\n", "            ", "text_file", ".", "writelines", "(", "[", "'<nodes>\\n'", "]", ")", "\n", "for", "idx", ",", "node", "in", "enumerate", "(", "self", ".", "road_params", "[", "'nodes'", "]", ")", ":", "\n", "                ", "text_file", ".", "writelines", "(", "[", "'   <node id=\"'", "+", "str", "(", "idx", ")", "+", "'\" x=\"'", "+", "str", "(", "node", "[", "0", "]", ")", "+", "'\" y=\"'", "+", "str", "(", "node", "[", "1", "]", ")", "+", "\n", "'\" />\\n'", "]", ")", "\n", "", "for", "idx", ",", "node", "in", "enumerate", "(", "self", ".", "road_params", "[", "'nodes'", "]", ")", ":", "\n", "                ", "text_file", ".", "writelines", "(", "[", "'   <node id=\"ego_'", "+", "str", "(", "idx", ")", "+", "'\" x=\"'", "+", "str", "(", "node", "[", "0", "]", ")", "+", "'\" y=\"'", "+", "str", "(", "node", "[", "1", "]", ")", "+", "\n", "'\" />\\n'", "]", ")", "\n", "", "text_file", ".", "writelines", "(", "[", "'</nodes>\\n'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.edges": [[37, 62], ["open", "text_file.writelines", "enumerate", "text_file.writelines", "enumerate", "text_file.writelines", "text_file.writelines", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "", "def", "edges", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.edg.xml'", ",", "'w'", ")", "as", "text_file", ":", "\n", "            ", "text_file", ".", "writelines", "(", "[", "'<edges>\\n'", "]", ")", "\n", "for", "start_idx", ",", "node_edges", "in", "enumerate", "(", "self", ".", "road_params", "[", "'edges'", "]", ")", ":", "\n", "                ", "for", "stop_idx", ",", "edge", "in", "enumerate", "(", "node_edges", ")", ":", "\n", "                    ", "if", "edge", ":", "\n", "                        ", "text_file", ".", "writelines", "(", "[", "'   <edge from=\"'", "+", "str", "(", "start_idx", ")", "+", "\n", "'\" id=\"L'", "+", "str", "(", "start_idx", ")", "+", "str", "(", "stop_idx", ")", "+", "\n", "'\" to=\"'", "+", "str", "(", "stop_idx", ")", "+", "\n", "'\" numLanes=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'nb_lanes'", "]", ")", "+", "\n", "'\" width=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'lane_width'", "]", ")", "+", "\n", "'\" speed=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'max_road_speed'", "]", ")", "+", "\n", "'\" priority=\"'", "+", "str", "(", "\n", "self", ".", "road_params", "[", "'priority'", "]", "[", "start_idx", ",", "stop_idx", "]", ")", "+", "\n", "'\" />\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <edge from=\"ego_'", "+", "str", "(", "start_idx", ")", "+", "\n", "'\" id=\"ego_L'", "+", "str", "(", "start_idx", ")", "+", "str", "(", "stop_idx", ")", "+", "\n", "'\" to=\"ego_'", "+", "str", "(", "stop_idx", ")", "+", "\n", "'\" numLanes=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'nb_lanes'", "]", ")", "+", "\n", "'\" width=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'lane_width'", "]", ")", "+", "\n", "'\" speed=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'max_road_speed'", "]", ")", "+", "\n", "'\" priority=\"'", "+", "str", "(", "\n", "self", ".", "road_params", "[", "'priority'", "]", "[", "start_idx", ",", "stop_idx", "]", ")", "+", "\n", "'\" />\\n'", "]", ")", "\n", "", "", "", "text_file", ".", "writelines", "(", "[", "'</edges>\\n'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.routes": [[63, 84], ["open", "text_file.writelines", "enumerate", "enumerate", "text_file.writelines", "text_file.writelines", "vehicle.items", "text_file.writelines", "range", "text_file.writelines", "text_file.writelines", "text_file.writelines", "len", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "", "def", "routes", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.rou.xml'", ",", "'w'", ")", "as", "text_file", ":", "\n", "            ", "text_file", ".", "writelines", "(", "[", "'<routes>\\n'", "]", ")", "\n", "for", "idx", ",", "vehicle", "in", "enumerate", "(", "self", ".", "road_params", "[", "'vehicles'", "]", ")", ":", "\n", "                ", "text_file", ".", "writelines", "(", "[", "'   <vType '", "]", ")", "\n", "for", "key", ",", "value", "in", "vehicle", ".", "items", "(", ")", ":", "\n", "                    ", "text_file", ".", "writelines", "(", "[", "key", "+", "'=\"'", "+", "str", "(", "value", ")", "+", "'\" '", "]", ")", "\n", "", "text_file", ".", "writelines", "(", "[", "'/>\\n'", "]", ")", "\n", "", "for", "route_name", ",", "route", "in", "enumerate", "(", "self", ".", "road_params", "[", "'routes'", "]", ")", ":", "\n", "                ", "edges_string", "=", "''", "\n", "edges_string_ego", "=", "''", "\n", "for", "i", "in", "range", "(", "len", "(", "route", ")", "-", "1", ")", ":", "\n", "                    ", "edges_string", "+=", "'L'", "+", "str", "(", "route", "[", "i", "]", ")", "+", "str", "(", "route", "[", "i", "+", "1", "]", ")", "+", "' '", "\n", "edges_string_ego", "+=", "'ego_L'", "+", "str", "(", "route", "[", "i", "]", ")", "+", "str", "(", "route", "[", "i", "+", "1", "]", ")", "+", "' '", "\n", "", "edges_string", "=", "edges_string", "[", ":", "-", "1", "]", "\n", "edges_string_ego", "=", "edges_string_ego", "[", ":", "-", "1", "]", "\n", "text_file", ".", "writelines", "(", "\n", "[", "'   <route id=\"route'", "+", "str", "(", "route_name", ")", "+", "'\" edges=\"'", "+", "edges_string", "+", "'\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "\n", "[", "'   <route id=\"ego_route'", "+", "str", "(", "route_name", ")", "+", "'\" edges=\"'", "+", "edges_string_ego", "+", "'\"/>\\n'", "]", ")", "\n", "", "text_file", ".", "writelines", "(", "[", "'</routes>\\n'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.connections": [[85, 98], ["open", "text_file.writelines", "enumerate", "text_file.writelines", "text_file.writelines", "text_file.writelines", "str", "str", "str", "str"], "methods", ["None"], ["", "", "def", "connections", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.con.xml'", ",", "'w'", ")", "as", "text_file", ":", "\n", "            ", "text_file", ".", "writelines", "(", "[", "'<connections>\\n'", "]", ")", "\n", "for", "route_name", ",", "route", "in", "enumerate", "(", "self", ".", "road_params", "[", "'routes'", "]", ")", ":", "\n", "                ", "edge_start", "=", "'L'", "+", "str", "(", "route", "[", "0", "]", ")", "+", "str", "(", "route", "[", "1", "]", ")", "\n", "edge_stop", "=", "'L'", "+", "str", "(", "route", "[", "1", "]", ")", "+", "str", "(", "route", "[", "2", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <connection from=\"'", "+", "edge_start", "+", "'\" to=\"'", "+", "edge_stop", "+", "\n", "'\" fromLane=\"0\" toLane=\"0'", "+", "\n", "'\" />\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <connection from=\"ego_'", "+", "edge_start", "+", "'\" to=\"ego_'", "+", "edge_stop", "+", "\n", "'\" fromLane=\"0\" toLane=\"0'", "+", "\n", "'\" />\\n'", "]", ")", "\n", "", "text_file", ".", "writelines", "(", "[", "'</connections>\\n'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.config": [[99, 124], ["open", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "", "def", "config", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.sumocfg'", ",", "'w'", ")", "as", "text_file", ":", "\n", "            ", "text_file", ".", "writelines", "(", "[", "'<configuration>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <input>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <net-file value=\"'", "+", "self", ".", "name", "+", "'.net.xml\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <route-files value=\"'", "+", "self", ".", "name", "+", "'.rou.xml\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <gui-settings-file value=\"'", "+", "self", ".", "name", "+", "'.settings.xml\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   </input>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <time>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <begin value=\"0\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <end value=\"1e15\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   </time>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <processing>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <lanechange.duration value=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'lane_change_duration'", "]", ")", "+", "\n", "'\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <lanechange.overtake-right value=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'overtake_right'", "]", ")", "+", "\n", "'\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <emergencydecel.warning-threshold value=\"'", "+", "\n", "str", "(", "self", ".", "road_params", "[", "'emergency_decel_warn_threshold'", "]", ")", "+", "'\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <collision.action value=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'collision_action'", "]", ")", "+", "\n", "'\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <no-step-log value=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'no_display_step'", "]", ")", "+", "'\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <collision.check-junctions value=\"true\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   </processing>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'</configuration>\\n'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.gui_settings": [[125, 137], ["open", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "text_file.writelines", "str", "str", "str", "str"], "methods", ["None"], ["", "", "def", "gui_settings", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.settings.xml'", ",", "'w'", ")", "as", "text_file", ":", "\n", "            ", "text_file", ".", "writelines", "(", "[", "'<viewsettings>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <viewport x=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'view_position'", "]", "[", "0", "]", ")", "+", "'\" y=\"'", "+", "\n", "str", "(", "self", ".", "road_params", "[", "'view_position'", "]", "[", "1", "]", ")", "+", "'\" zoom=\"'", "+", "\n", "str", "(", "self", ".", "road_params", "[", "'zoom'", "]", ")", "+", "'\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <delay value=\"'", "+", "str", "(", "self", ".", "road_params", "[", "'view_delay'", "]", ")", "+", "'\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <scheme name=\"real world\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   <scheme>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'      <polys polyName_show=\"1\" polyName_color=\"0,0,0\" polyName_size=\"100.00\"/>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'   </scheme>\\n'", "]", ")", "\n", "text_file", ".", "writelines", "(", "[", "'</viewsettings>\\n'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.create_road": [[138, 151], ["road.Road.nodes", "road.Road.edges", "road.Road.routes", "road.Road.connections", "road.Road.config", "road.Road.gui_settings", "os.system"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.nodes", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.edges", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.routes", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.connections", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.config", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.gui_settings"], ["", "", "def", "create_road", "(", "self", ")", ":", "\n", "        ", "\"\"\" Creates the xml files that are needed by SUMO. \"\"\"", "\n", "self", ".", "nodes", "(", ")", "\n", "self", ".", "edges", "(", ")", "\n", "self", ".", "routes", "(", ")", "\n", "self", ".", "connections", "(", ")", "\n", "self", ".", "config", "(", ")", "\n", "self", ".", "gui_settings", "(", ")", "\n", "\n", "os", ".", "system", "(", "'netconvert --node-files='", "+", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.nod.xml '", "+", "\n", "'--edge-files='", "+", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.edg.xml '", "+", "\n", "'--output-file='", "+", "self", ".", "road_path", "+", "self", ".", "name", "+", "'.net.xml '", "+", "\n", "'--opposites.guess=true'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.__init__": [[35, 65], ["core.Agent.__init__", "ValueError", "int", "float"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "nb_actions", ",", "memory", ",", "gamma", ",", "batch_size", ",", "nb_steps_warmup", ",", "train_interval", ",", "memory_interval", ",", "\n", "target_model_update", ",", "delta_clip", ",", "custom_model_objects", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "AbstractDQNAgent", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "# Soft vs hard target model updates.", "\n", "if", "target_model_update", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'`target_model_update` must be >= 0.'", ")", "\n", "", "elif", "target_model_update", ">=", "1", ":", "\n", "# Hard update every `target_model_update` steps.", "\n", "            ", "target_model_update", "=", "int", "(", "target_model_update", ")", "\n", "", "else", ":", "\n", "# Soft update with `(1 - target_model_update) * old + target_model_update * new`.", "\n", "            ", "target_model_update", "=", "float", "(", "target_model_update", ")", "\n", "\n", "# Parameters.", "\n", "", "self", ".", "nb_actions", "=", "nb_actions", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "nb_steps_warmup", "=", "nb_steps_warmup", "\n", "self", ".", "train_interval", "=", "train_interval", "\n", "self", ".", "memory_interval", "=", "memory_interval", "\n", "self", ".", "target_model_update", "=", "target_model_update", "\n", "self", ".", "delta_clip", "=", "delta_clip", "\n", "self", ".", "custom_model_objects", "=", "{", "}", "if", "custom_model_objects", "is", "None", "else", "custom_model_objects", "\n", "\n", "# Related objects.", "\n", "self", ".", "memory", "=", "memory", "\n", "\n", "# State.", "\n", "self", ".", "compiled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.process_state_batch": [[66, 72], ["np.array", "dqn_ensemble.AbstractDQNAgent.processor.process_state_batch"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "process_state_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\" Heritage from keras-rl, not used here. \"\"\"", "\n", "batch", "=", "np", ".", "array", "(", "batch", ")", "\n", "if", "self", ".", "processor", "is", "None", ":", "\n", "            ", "return", "batch", "\n", "", "return", "self", ".", "processor", ".", "process_state_batch", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_batch_q_values": [[73, 82], ["dqn_ensemble.AbstractDQNAgent.process_state_batch", "dqn_ensemble.AbstractDQNAgent.input_queues[].put", "dqn_ensemble.AbstractDQNAgent.output_queues[].get", "dqn_ensemble.AbstractDQNAgent.models[].predict_on_batch", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "compute_batch_q_values", "(", "self", ",", "state_batch", ",", "net", ")", ":", "\n", "        ", "batch", "=", "self", ".", "process_state_batch", "(", "state_batch", ")", "\n", "if", "self", ".", "parallel", ":", "\n", "            ", "self", ".", "input_queues", "[", "net", "]", ".", "put", "(", "[", "'predict'", ",", "batch", "]", ")", "\n", "q_values", "=", "self", ".", "output_queues", "[", "net", "]", ".", "get", "(", ")", "\n", "", "else", ":", "\n", "            ", "q_values", "=", "self", ".", "models", "[", "net", "]", ".", "predict_on_batch", "(", "batch", ")", "\n", "", "assert", "q_values", ".", "shape", "==", "(", "len", "(", "state_batch", ")", ",", "self", ".", "nb_actions", ")", "\n", "return", "q_values", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values": [[83, 97], ["dqn_ensemble.AbstractDQNAgent.compute_batch_q_values().flatten", "dqn_ensemble.AbstractDQNAgent.compute_batch_q_values"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_batch_q_values"], ["", "def", "compute_q_values", "(", "self", ",", "state", ",", "net", ")", ":", "\n", "        ", "\"\"\"\n        Compute Q-values for a particular state for a single ensemble member.\n\n        Args:\n            state (list): Input to the neural networks.\n            net (int): Ensemble member index.\n\n        Returns:\n            q_values (list): Q-values for specified state and ensemble member\n        \"\"\"", "\n", "q_values", "=", "self", ".", "compute_batch_q_values", "(", "[", "state", "]", ",", "net", ")", ".", "flatten", "(", ")", "\n", "assert", "q_values", ".", "shape", "==", "(", "self", ".", "nb_actions", ",", ")", "\n", "return", "q_values", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values_all_nets": [[98, 121], ["np.array", "range", "range", "np.array.append", "len", "np.array.append", "dqn_ensemble.AbstractDQNAgent.compute_q_values", "dqn_ensemble.AbstractDQNAgent.compute_q_values", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values"], ["", "def", "compute_q_values_all_nets", "(", "self", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Compute Q-values for a particular state, for all ensemble members.\n\n        Args:\n            state (list): Input to the neural networks.\n\n        Returns:\n            q_values_all_nets (ndarray): Matrix that describe the Q-value for all actions for all ensemble members.\n        \"\"\"", "\n", "q_values_all_nets", "=", "[", "]", "\n", "if", "self", ".", "parallel", ":", "\n", "            ", "for", "net", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "                ", "q_values_all_nets", ".", "append", "(", "self", ".", "compute_q_values", "(", "state", ",", "net", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "net", "in", "range", "(", "len", "(", "self", ".", "models", ")", ")", ":", "\n", "                ", "q_values_all_nets", ".", "append", "(", "self", ".", "compute_q_values", "(", "state", ",", "net", ")", ")", "\n", "", "", "q_values_all_nets", "=", "np", ".", "array", "(", "q_values_all_nets", ")", "\n", "if", "self", ".", "parallel", ":", "\n", "            ", "assert", "q_values_all_nets", ".", "shape", "==", "(", "self", ".", "nb_models", ",", "self", ".", "nb_actions", ")", "\n", "", "else", ":", "\n", "            ", "assert", "q_values_all_nets", ".", "shape", "==", "(", "len", "(", "self", ".", "models", ")", ",", "self", ".", "nb_actions", ")", "\n", "", "return", "q_values_all_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.get_config": [[122, 133], ["get_object_config"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "'nb_actions'", ":", "self", ".", "nb_actions", ",", "\n", "'gamma'", ":", "self", ".", "gamma", ",", "\n", "'batch_size'", ":", "self", ".", "batch_size", ",", "\n", "'nb_steps_warmup'", ":", "self", ".", "nb_steps_warmup", ",", "\n", "'train_interval'", ":", "self", ".", "train_interval", ",", "\n", "'memory_interval'", ":", "self", ".", "memory_interval", ",", "\n", "'target_model_update'", ":", "self", ".", "target_model_update", ",", "\n", "'delta_clip'", ":", "self", ".", "delta_clip", ",", "\n", "'memory'", ":", "get_object_config", "(", "self", ".", "memory", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.__init__": [[149, 178], ["dqn_ensemble.AbstractDQNAgent.__init__", "np.random.randint", "dqn_ensemble.DQNAgentEnsemble.reset_states", "hasattr", "ValueError", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states"], ["def", "__init__", "(", "self", ",", "models", ",", "policy", ",", "test_policy", ",", "enable_double_dqn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DQNAgentEnsemble", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Validate (important) input.", "\n", "if", "hasattr", "(", "models", "[", "0", "]", ".", "output", ",", "'__len__'", ")", "and", "len", "(", "models", "[", "0", "]", ".", "output", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Model \"{}\" has more than one output. DQN expects a model that has a single output.'", ".", "format", "(", "models", "[", "0", "]", ")", ")", "\n", "", "if", "models", "[", "0", "]", ".", "output", ".", "_keras_shape", "!=", "(", "None", ",", "self", ".", "nb_actions", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Model output \"{}\" has invalid shape. DQN expects a model that has one dimension for each '", "\n", "'action, in this case {}.'", ".", "format", "(", "models", "[", "0", "]", ".", "output", ",", "self", ".", "nb_actions", ")", ")", "\n", "\n", "# Parameters.", "\n", "", "self", ".", "enable_double_dqn", "=", "enable_double_dqn", "\n", "\n", "# Related objects.", "\n", "self", ".", "models", "=", "models", "\n", "self", ".", "active_model", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "self", ".", "policy", "=", "policy", "\n", "self", ".", "test_policy", "=", "test_policy", "\n", "self", ".", "parallel", "=", "False", "\n", "\n", "# State.", "\n", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "self", ".", "reset_states", "(", ")", "\n", "\n", "# Models", "\n", "self", ".", "trainable_models", "=", "[", "]", "\n", "self", ".", "target_models", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.change_active_model": [[179, 182], ["np.random.randint", "len"], "methods", ["None"], ["", "def", "change_active_model", "(", "self", ")", ":", "\n", "        ", "\"\"\" Change which ensemble member that chooses the actions for each training episode.\"\"\"", "\n", "self", ".", "active_model", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.get_config": [[183, 192], ["dqn_ensemble.AbstractDQNAgent.get_config", "get_object_config", "get_object_config", "get_object_config", "get_object_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "DQNAgentEnsemble", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", "[", "'enable_double_dqn'", "]", "=", "self", ".", "enable_double_dqn", "\n", "config", "[", "'model'", "]", "=", "[", "get_object_config", "(", "model", ")", "for", "model", "in", "self", ".", "models", "]", "\n", "config", "[", "'policy'", "]", "=", "get_object_config", "(", "self", ".", "policy", ")", "\n", "config", "[", "'test_policy'", "]", "=", "get_object_config", "(", "self", ".", "test_policy", ")", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "config", "[", "'target_model'", "]", "=", "[", "get_object_config", "(", "target_model", ")", "for", "target_model", "in", "self", ".", "target_models", "]", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.compile": [[193, 240], ["range", "clone_model", "len", "dqn_ensemble.DQNAgentEnsemble.target_models[].compile", "dqn_ensemble.DQNAgentEnsemble.models[].compile", "Exception", "huber_loss", "K.sum", "keras.layers.Input", "keras.layers.Input", "Model", "Model.compile", "dqn_ensemble.DQNAgentEnsemble.trainable_models.append", "keras.layers.Lambda", "len", "type", "K.zeros_like"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "compile", "(", "self", ",", "optimizer", ",", "metrics", "=", "None", ")", ":", "\n", "        ", "\"\"\" Set up the training of the neural network.\"\"\"", "\n", "if", "metrics", "is", "None", ":", "\n", "            ", "metrics", "=", "[", "]", "\n", "", "metrics", "+=", "[", "mean_q", "]", "# register default metrics", "\n", "metrics", "+=", "[", "max_q", "]", "\n", "\n", "# We never train the target model, hence we can set the optimizer and loss arbitrarily.", "\n", "self", ".", "target_models", "=", "[", "clone_model", "(", "model", ",", "self", ".", "custom_model_objects", ")", "for", "model", "in", "self", ".", "models", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "models", ")", ")", ":", "\n", "            ", "self", ".", "target_models", "[", "i", "]", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "self", ".", "models", "[", "i", "]", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "\n", "# Compile model.", "\n", "", "if", "self", ".", "target_model_update", "<", "1.", ":", "\n", "            ", "raise", "Exception", "(", "\"Soft target model updates not implemented yet\"", ")", "\n", "# # We use the `AdditionalUpdatesOptimizer` to efficiently soft-update the target model.", "\n", "# updates = get_soft_target_model_updates(self.target_model, self.model, self.target_model_update)", "\n", "# optimizer = AdditionalUpdatesOptimizer(optimizer, updates)", "\n", "\n", "", "def", "clipped_masked_error", "(", "args", ")", ":", "\n", "            ", "y_true", ",", "y_pred", ",", "mask", "=", "args", "\n", "loss", "=", "huber_loss", "(", "y_true", ",", "y_pred", ",", "self", ".", "delta_clip", ")", "\n", "loss", "*=", "mask", "# apply element-wise mask", "\n", "return", "K", ".", "sum", "(", "loss", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Create trainable model. The problem is that we need to mask the output since we only", "\n", "# ever want to update the Q values for a certain action. The way we achieve this is by", "\n", "# using a custom Lambda layer that computes the loss. This gives us the necessary flexibility", "\n", "# to mask out certain parameters by passing in multiple inputs to the Lambda layer.", "\n", "", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "y_pred", "=", "model", ".", "output", "\n", "y_true", "=", "Input", "(", "name", "=", "'y_true'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "mask", "=", "Input", "(", "name", "=", "'mask'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "loss_out", "=", "Lambda", "(", "clipped_masked_error", ",", "output_shape", "=", "(", "1", ",", ")", ",", "name", "=", "'loss'", ")", "(", "[", "y_true", ",", "y_pred", ",", "mask", "]", ")", "\n", "ins", "=", "[", "model", ".", "input", "]", "if", "type", "(", "model", ".", "input", ")", "is", "not", "list", "else", "model", ".", "input", "\n", "trainable_model", "=", "Model", "(", "inputs", "=", "ins", "+", "[", "y_true", ",", "mask", "]", ",", "outputs", "=", "[", "loss_out", ",", "y_pred", "]", ")", "\n", "assert", "len", "(", "trainable_model", ".", "output_names", ")", "==", "2", "\n", "combined_metrics", "=", "{", "trainable_model", ".", "output_names", "[", "1", "]", ":", "metrics", "}", "\n", "losses", "=", "[", "\n", "lambda", "y_true", ",", "y_pred", ":", "y_pred", ",", "# loss is computed in Lambda layer", "\n", "lambda", "y_true", ",", "y_pred", ":", "K", ".", "zeros_like", "(", "y_pred", ")", ",", "# we only include this for the metrics", "\n", "]", "\n", "trainable_model", ".", "compile", "(", "optimizer", "=", "optimizer", ",", "loss", "=", "losses", ",", "metrics", "=", "combined_metrics", ")", "\n", "self", ".", "trainable_models", ".", "append", "(", "trainable_model", ")", "\n", "\n", "", "self", ".", "compiled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.load_weights": [[241, 245], ["enumerate", "dqn_ensemble.DQNAgentEnsemble.update_target_model_hard", "model.load_weights", "str"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.load_weights"], ["", "def", "load_weights", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "model", ".", "load_weights", "(", "filepath", "+", "\"_\"", "+", "str", "(", "i", ")", ")", "\n", "", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.save_weights": [[246, 249], ["enumerate", "model.save_weights", "str"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.save_weights"], ["", "def", "save_weights", "(", "self", ",", "filepath", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "model", ".", "save_weights", "(", "filepath", "+", "\"_\"", "+", "str", "(", "i", ")", ",", "overwrite", "=", "overwrite", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.reset_states": [[250, 257], ["range", "len", "dqn_ensemble.DQNAgentEnsemble.models[].reset_states", "dqn_ensemble.DQNAgentEnsemble.target_models[].reset_states"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states"], ["", "", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "models", ")", ")", ":", "\n", "                ", "self", ".", "models", "[", "i", "]", ".", "reset_states", "(", ")", "\n", "self", ".", "target_models", "[", "i", "]", ".", "reset_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.update_target_model_hard": [[258, 262], ["enumerate", "target_model.set_weights", "dqn_ensemble.DQNAgentEnsemble.models[].get_weights"], "methods", ["None"], ["", "", "", "def", "update_target_model_hard", "(", "self", ")", ":", "\n", "        ", "\"\"\" Copy current network parameters to the target network. \"\"\"", "\n", "for", "i", ",", "target_model", "in", "enumerate", "(", "self", ".", "target_models", ")", ":", "\n", "            ", "target_model", ".", "set_weights", "(", "self", ".", "models", "[", "i", "]", ".", "get_weights", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.forward": [[263, 293], ["dqn_ensemble.DQNAgentEnsemble.memory.get_recent_state", "dqn_ensemble.DQNAgentEnsemble.compute_q_values", "dqn_ensemble.DQNAgentEnsemble.policy.select_action", "dqn_ensemble.DQNAgentEnsemble.compute_q_values_all_nets", "dqn_ensemble.DQNAgentEnsemble.test_policy.select_action", "np.mean", "np.std", "info.update"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values_all_nets", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["", "", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "\"\"\"\n        Ask the agent to choose an action based on the current observation.\n        Args:\n            observation (ndarray): Current observation.\n\n        Returns:\n            action (int): Index of chosen action\n            info (dict): Information about the Q-values of the chosen action.\n        \"\"\"", "\n", "info", "=", "{", "}", "\n", "# Select an action.", "\n", "state", "=", "self", ".", "memory", ".", "get_recent_state", "(", "observation", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "q_values", "=", "self", ".", "compute_q_values", "(", "state", ",", "self", ".", "active_model", ")", "\n", "action", "=", "self", ".", "policy", ".", "select_action", "(", "q_values", "=", "q_values", ")", "\n", "info", "[", "'q_values'", "]", "=", "q_values", "\n", "", "else", ":", "\n", "            ", "q_values_all_nets", "=", "self", ".", "compute_q_values_all_nets", "(", "state", ")", "\n", "action", ",", "policy_info", "=", "self", ".", "test_policy", ".", "select_action", "(", "q_values_all_nets", "=", "q_values_all_nets", ")", "\n", "info", "[", "'q_values_all_nets'", "]", "=", "q_values_all_nets", "\n", "info", "[", "'q_values'", "]", "=", "np", ".", "mean", "(", "q_values_all_nets", "[", ":", ",", ":", "]", ",", "axis", "=", "0", ")", "\n", "info", "[", "'epistemic_std_dev'", "]", "=", "np", ".", "std", "(", "q_values_all_nets", "[", ":", ",", ":", "]", ",", "axis", "=", "0", ")", "\n", "info", ".", "update", "(", "policy_info", ")", "\n", "\n", "# Book-keeping.", "\n", "", "self", ".", "recent_observation", "=", "observation", "\n", "self", ".", "recent_action", "=", "action", "\n", "\n", "return", "action", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.backward": [[294, 309], ["range", "dqn_ensemble.DQNAgentEnsemble.memory.append", "len", "dqn_ensemble.DQNAgentEnsemble.train_single_net", "dqn_ensemble.DQNAgentEnsemble.update_target_model_hard"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.train_single_net", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard"], ["", "def", "backward", "(", "self", ",", "reward", ",", "terminal", ")", ":", "\n", "        ", "\"\"\" Store the most recent experience in the replay memory and update all ensemble networks. \"\"\"", "\n", "# Store most recent experience in memory.", "\n", "if", "self", ".", "step", "%", "self", ".", "memory_interval", "==", "0", ":", "\n", "            ", "self", ".", "memory", ".", "append", "(", "self", ".", "recent_observation", ",", "self", ".", "recent_action", ",", "reward", ",", "terminal", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "metrics", "=", "None", "\n", "for", "active_net", "in", "range", "(", "len", "(", "self", ".", "models", ")", ")", ":", "\n", "            ", "metrics", "=", "self", ".", "train_single_net", "(", "active_net", ")", "\n", "\n", "", "if", "self", ".", "target_model_update", ">=", "1", "and", "self", ".", "step", "%", "self", ".", "target_model_update", "==", "0", ":", "\n", "            ", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n", "", "return", "metrics", "# This is only the metrics of the last agent.", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.train_single_net": [[310, 403], ["dqn_ensemble.DQNAgentEnsemble.memory.sample", "dqn_ensemble.DQNAgentEnsemble.process_state_batch", "dqn_ensemble.DQNAgentEnsemble.process_state_batch", "np.array", "np.array", "np.zeros", "np.zeros", "np.zeros", "enumerate", "np.array().astype", "np.array().astype", "dqn_ensemble.DQNAgentEnsemble.trainable_models[].train_on_batch", "len", "dqn_ensemble.DQNAgentEnsemble.append", "dqn_ensemble.DQNAgentEnsemble.append", "np.array.append", "action_batch.append", "np.array.append", "len", "len", "dqn_ensemble.DQNAgentEnsemble.models[].predict_on_batch", "np.argmax", "dqn_ensemble.DQNAgentEnsemble.target_models[].predict_on_batch", "dqn_ensemble.DQNAgentEnsemble.target_models[].predict_on_batch", "np.max().flatten", "zip", "np.array", "np.array", "type", "enumerate", "np.max", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "train_single_net", "(", "self", ",", "active_net", ")", ":", "\n", "        ", "\"\"\" Retrieve a batch of experiences from the replay memory of the specified ensemble member and update\n        the network weights. \"\"\"", "\n", "\n", "metrics", "=", "[", "np", ".", "nan", "for", "_", "in", "self", ".", "metrics_names", "]", "\n", "if", "not", "self", ".", "training", ":", "\n", "# We're done here. No need to update the experience memory since we only use the working", "\n", "# memory to obtain the state over the most recent observations.", "\n", "            ", "return", "metrics", "\n", "\n", "# Train the network on a single stochastic batch.", "\n", "", "if", "self", ".", "step", ">", "self", ".", "nb_steps_warmup", "and", "self", ".", "step", "%", "self", ".", "train_interval", "==", "0", ":", "\n", "            ", "experiences", "=", "self", ".", "memory", ".", "sample", "(", "active_net", ",", "self", ".", "batch_size", ")", "\n", "assert", "len", "(", "experiences", ")", "==", "self", ".", "batch_size", "\n", "\n", "# Start by extracting the necessary parameters (we use a vectorized implementation).", "\n", "state0_batch", "=", "[", "]", "\n", "reward_batch", "=", "[", "]", "\n", "action_batch", "=", "[", "]", "\n", "terminal1_batch", "=", "[", "]", "\n", "state1_batch", "=", "[", "]", "\n", "for", "e", "in", "experiences", ":", "\n", "                ", "state0_batch", ".", "append", "(", "e", ".", "state0", ")", "\n", "state1_batch", ".", "append", "(", "e", ".", "state1", ")", "\n", "reward_batch", ".", "append", "(", "e", ".", "reward", ")", "\n", "action_batch", ".", "append", "(", "e", ".", "action", ")", "\n", "terminal1_batch", ".", "append", "(", "0.", "if", "e", ".", "terminal1", "else", "1.", ")", "\n", "\n", "# Prepare and validate parameters.", "\n", "", "state0_batch", "=", "self", ".", "process_state_batch", "(", "state0_batch", ")", "\n", "state1_batch", "=", "self", ".", "process_state_batch", "(", "state1_batch", ")", "\n", "terminal1_batch", "=", "np", ".", "array", "(", "terminal1_batch", ")", "\n", "reward_batch", "=", "np", ".", "array", "(", "reward_batch", ")", "\n", "assert", "reward_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "assert", "terminal1_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "assert", "len", "(", "action_batch", ")", "==", "len", "(", "reward_batch", ")", "\n", "\n", "# Compute Q values for mini-batch update.", "\n", "if", "self", ".", "enable_double_dqn", ":", "\n", "# According to the paper \"Deep Reinforcement Learning with Double Q-learning\"", "\n", "# (van Hasselt et al., 2015), in Double DQN, the online network predicts the actions", "\n", "# while the target network is used to estimate the Q value.", "\n", "                ", "q_values", "=", "self", ".", "models", "[", "active_net", "]", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "actions", "=", "np", ".", "argmax", "(", "q_values", ",", "axis", "=", "1", ")", "\n", "assert", "actions", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "\n", "# Now, estimate Q values using the target network but select the values with the", "\n", "# highest Q value wrt to the online model (as computed above).", "\n", "target_q_values", "=", "self", ".", "target_models", "[", "active_net", "]", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "target_q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "q_batch", "=", "target_q_values", "[", "range", "(", "self", ".", "batch_size", ")", ",", "actions", "]", "\n", "", "else", ":", "\n", "# Compute the q_values given state1, and extract the maximum for each sample in the batch.", "\n", "# We perform this prediction on the target_model instead of the model for reasons", "\n", "# outlined in Mnih (2015). In short: it makes the algorithm more stable.", "\n", "                ", "target_q_values", "=", "self", ".", "target_models", "[", "active_net", "]", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "target_q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "q_batch", "=", "np", ".", "max", "(", "target_q_values", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "", "assert", "q_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "\n", "targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "dummy_targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "masks", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "\n", "# Compute r_t + gamma * max_a Q(s_t+1, a) and update the target targets accordingly,", "\n", "# but only for the affected output units (as given by action_batch).", "\n", "discounted_reward_batch", "=", "self", ".", "gamma", "*", "q_batch", "\n", "# Set discounted reward to zero for all states that were terminal.", "\n", "discounted_reward_batch", "*=", "terminal1_batch", "\n", "assert", "discounted_reward_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "Rs", "=", "reward_batch", "+", "discounted_reward_batch", "\n", "for", "idx", ",", "(", "target", ",", "mask", ",", "R", ",", "action", ")", "in", "enumerate", "(", "zip", "(", "targets", ",", "masks", ",", "Rs", ",", "action_batch", ")", ")", ":", "\n", "                ", "target", "[", "action", "]", "=", "R", "# update action with estimated accumulated reward", "\n", "dummy_targets", "[", "idx", "]", "=", "R", "\n", "mask", "[", "action", "]", "=", "1.", "# enable loss for this specific action", "\n", "", "targets", "=", "np", ".", "array", "(", "targets", ")", ".", "astype", "(", "'float32'", ")", "\n", "masks", "=", "np", ".", "array", "(", "masks", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "# Finally, perform a single update on the entire batch. We use a dummy target since", "\n", "# the actual loss is computed in a Lambda layer that needs more complex input. However,", "\n", "# it is still useful to know the actual target to compute metrics properly.", "\n", "ins", "=", "[", "state0_batch", "]", "if", "type", "(", "self", ".", "models", "[", "active_net", "]", ".", "input", ")", "is", "not", "list", "else", "state0_batch", "\n", "metrics", "=", "self", ".", "trainable_models", "[", "active_net", "]", ".", "train_on_batch", "(", "ins", "+", "[", "targets", ",", "masks", "]", ",", "[", "dummy_targets", ",", "targets", "]", ")", "\n", "metrics", "=", "[", "metric", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "if", "\n", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "# throw away individual losses", "\n", "metrics", "+=", "self", ".", "policy", ".", "metrics", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "                ", "metrics", "+=", "self", ".", "processor", ".", "metrics", "\n", "\n", "", "metrics", "+=", "[", "self", ".", "active_model", "]", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.layers": [[404, 408], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"Using layers in dqn, which has not been updated to ensemble.\"", ")", "\n", "return", "self", ".", "model", ".", "layers", "[", ":", "]", "# Unsure how this function is used and therefore which model to use", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.metrics_names": [[409, 422], ["len", "name.replace", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics_names", "(", "self", ")", ":", "\n", "# Throw away individual losses and replace output name since this is hidden from the user.", "\n", "        ", "assert", "len", "(", "self", ".", "trainable_models", "[", "0", "]", ".", "output_names", ")", "==", "2", "\n", "dummy_output_name", "=", "self", ".", "trainable_models", "[", "0", "]", ".", "output_names", "[", "1", "]", "\n", "model_metrics", "=", "[", "name", "for", "idx", ",", "name", "in", "enumerate", "(", "self", ".", "trainable_models", "[", "0", "]", ".", "metrics_names", ")", "if", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "\n", "model_metrics", "=", "[", "name", ".", "replace", "(", "dummy_output_name", "+", "'_'", ",", "''", ")", "for", "name", "in", "model_metrics", "]", "\n", "\n", "names", "=", "model_metrics", "+", "self", ".", "policy", ".", "metrics_names", "[", ":", "]", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "            ", "names", "+=", "self", ".", "processor", ".", "metrics_names", "[", ":", "]", "\n", "", "names", "+=", "[", "\"active_model\"", "]", "\n", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.policy": [[427, 431], ["dqn_ensemble.DQNAgentEnsemble.__policy._set_agent"], "methods", ["None"], ["", "@", "policy", ".", "setter", "\n", "def", "policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__policy", "=", "policy", "\n", "self", ".", "__policy", ".", "_set_agent", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsemble.test_policy": [[436, 440], ["dqn_ensemble.DQNAgentEnsemble.__test_policy._set_agent"], "methods", ["None"], ["", "@", "test_policy", ".", "setter", "\n", "def", "test_policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__test_policy", "=", "policy", "\n", "self", ".", "__test_policy", ".", "_set_agent", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.__init__": [[469, 509], ["dqn_ensemble.AbstractDQNAgent.__init__", "np.random.randint", "dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "dqn_ensemble.DQNAgentEnsembleParallel.init_parallel_execution"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.init_parallel_execution"], ["def", "__init__", "(", "self", ",", "nb_models", ",", "cnn_architecture", ",", "learning_rate", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "nb_vehicles", ",", "\n", "nb_conv_layers", ",", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "network_seed", ",", "\n", "prior_scale_factor", ",", "window_length", ",", "policy", ",", "test_policy", ",", "enable_double_dqn", ",", "enable_dueling_network", ",", "\n", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DQNAgentEnsembleParallel", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Parameters.", "\n", "self", ".", "enable_double_dqn", "=", "enable_double_dqn", "\n", "self", ".", "enable_dueling_network", "=", "enable_dueling_network", "\n", "# Related objects.", "\n", "self", ".", "nb_models", "=", "nb_models", "\n", "self", ".", "active_model", "=", "np", ".", "random", ".", "randint", "(", "nb_models", ")", "\n", "self", ".", "policy", "=", "policy", "\n", "self", ".", "test_policy", "=", "test_policy", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "\n", "# Network parameters", "\n", "self", ".", "cnn_architecture", "=", "cnn_architecture", "\n", "self", ".", "nb_ego_states", "=", "nb_ego_states", "\n", "self", ".", "nb_states_per_vehicle", "=", "nb_states_per_vehicle", "\n", "self", ".", "nb_vehicles", "=", "nb_vehicles", "\n", "self", ".", "nb_conv_layers", "=", "nb_conv_layers", "\n", "self", ".", "nb_conv_filters", "=", "nb_conv_filters", "\n", "self", ".", "nb_hidden_fc_layers", "=", "nb_hidden_fc_layers", "\n", "self", ".", "nb_hidden_neurons", "=", "nb_hidden_neurons", "\n", "self", ".", "network_seed", "=", "network_seed", "\n", "self", ".", "prior_scale_factor", "=", "prior_scale_factor", "\n", "self", ".", "window_length", "=", "window_length", "\n", "\n", "# State.", "\n", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "self", ".", "reset_states", "(", ")", "\n", "\n", "self", ".", "parallel", "=", "True", "\n", "self", ".", "input_queues", "=", "None", "\n", "self", ".", "output_queues", "=", "None", "\n", "\n", "self", ".", "init_parallel_execution", "(", ")", "\n", "self", ".", "compiled", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.init_parallel_execution": [[510, 531], ["range", "multiprocessing.Queue", "multiprocessing.Queue", "dqn_ensemble.Worker", "dqn_ensemble.DQNAgentEnsembleParallel.workers.append", "Worker.start", "range", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "init_parallel_execution", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initalize one worker for each ensemble member and set up corresponding queues. \"\"\"", "\n", "self", ".", "input_queues", "=", "[", "mp", ".", "Queue", "(", ")", "for", "_", "in", "range", "(", "self", ".", "nb_models", ")", "]", "\n", "self", ".", "output_queues", "=", "[", "mp", ".", "Queue", "(", ")", "for", "_", "in", "range", "(", "self", ".", "nb_models", ")", "]", "\n", "self", ".", "workers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "worker", "=", "Worker", "(", "self", ".", "network_seed", "+", "i", ",", "self", ".", "input_queues", "[", "i", "]", ",", "self", ".", "output_queues", "[", "i", "]", ",", "\n", "cnn_architecture", "=", "self", ".", "cnn_architecture", ",", "\n", "nb_ego_states", "=", "self", ".", "nb_ego_states", ",", "nb_states_per_vehicle", "=", "self", ".", "nb_states_per_vehicle", ",", "\n", "nb_vehicles", "=", "self", ".", "nb_vehicles", ",", "nb_actions", "=", "self", ".", "nb_actions", ",", "\n", "nb_conv_layers", "=", "self", ".", "nb_conv_layers", ",", "nb_conv_filters", "=", "self", ".", "nb_conv_filters", ",", "\n", "nb_hidden_fc_layers", "=", "self", ".", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", "=", "self", ".", "nb_hidden_neurons", ",", "\n", "duel", "=", "self", ".", "enable_dueling_network", ",", "prior_scale_factor", "=", "self", ".", "prior_scale_factor", ",", "\n", "window_length", "=", "self", ".", "window_length", ",", "\n", "processor", "=", "self", ".", "processor", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "enable_double_dqn", "=", "self", ".", "enable_double_dqn", ",", "gamma", "=", "self", ".", "gamma", ",", "lr", "=", "self", ".", "lr", ",", "\n", "delta_clip", "=", "self", ".", "delta_clip", ",", "target_model_update", "=", "self", ".", "target_model_update", ",", "\n", "policy", "=", "self", ".", "policy", ")", "\n", "self", ".", "workers", ".", "append", "(", "worker", ")", "\n", "", "for", "worker", "in", "self", ".", "workers", ":", "\n", "            ", "worker", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.change_active_model": [[532, 535], ["np.random.randint"], "methods", ["None"], ["", "", "def", "change_active_model", "(", "self", ")", ":", "\n", "        ", "\"\"\" Change which ensemble member that chooses the actions for each training episode.\"\"\"", "\n", "self", ".", "active_model", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "nb_models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.get_config": [[536, 546], ["dqn_ensemble.AbstractDQNAgent.get_config", "get_object_config", "get_object_config", "get_object_config", "get_object_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "DQNAgentEnsemble", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", "[", "'enable_double_dqn'", "]", "=", "self", ".", "enable_double_dqn", "\n", "config", "[", "'enable_dueling_network'", "]", "=", "self", ".", "enable_dueling_network", "\n", "config", "[", "'model'", "]", "=", "[", "get_object_config", "(", "model", ")", "for", "model", "in", "self", ".", "nb_models", "]", "\n", "config", "[", "'policy'", "]", "=", "get_object_config", "(", "self", ".", "policy", ")", "\n", "config", "[", "'test_policy'", "]", "=", "get_object_config", "(", "self", ".", "test_policy", ")", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "config", "[", "'target_model'", "]", "=", "[", "get_object_config", "(", "target_model", ")", "for", "target_model", "in", "self", ".", "nb_models", "]", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.get_model_as_string": [[547, 550], ["dqn_ensemble.DQNAgentEnsembleParallel.input_queues[].put", "dqn_ensemble.DQNAgentEnsembleParallel.output_queues[].get"], "methods", ["None"], ["", "def", "get_model_as_string", "(", "self", ")", ":", "\n", "        ", "self", ".", "input_queues", "[", "0", "]", ".", "put", "(", "[", "'model_as_string'", "]", ")", "# All models are the same, so enough to get one of them", "\n", "return", "self", ".", "output_queues", "[", "0", "]", ".", "get", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.load_weights": [[551, 557], ["range", "dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard", "dqn_ensemble.DQNAgentEnsembleParallel.input_queues[].put", "dqn_ensemble.DQNAgentEnsembleParallel.output_queues[].get", "str"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard"], ["", "def", "load_weights", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "self", ".", "input_queues", "[", "i", "]", ".", "put", "(", "[", "'load_weights'", ",", "filepath", "+", "\"_\"", "+", "str", "(", "i", ")", "]", ")", "\n", "output", "=", "self", ".", "output_queues", "[", "i", "]", ".", "get", "(", ")", "\n", "assert", "(", "output", "==", "'weights_loaded_'", "+", "self", ".", "workers", "[", "i", "]", ".", "name", ")", "\n", "", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.save_weights": [[558, 563], ["range", "dqn_ensemble.DQNAgentEnsembleParallel.input_queues[].put", "dqn_ensemble.DQNAgentEnsembleParallel.output_queues[].get", "str"], "methods", ["None"], ["", "def", "save_weights", "(", "self", ",", "filepath", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "self", ".", "input_queues", "[", "i", "]", ".", "put", "(", "[", "'save_weights'", ",", "filepath", "+", "\"_\"", "+", "str", "(", "i", ")", ",", "overwrite", "]", ")", "\n", "output", "=", "self", ".", "output_queues", "[", "i", "]", ".", "get", "(", ")", "\n", "assert", "(", "output", "==", "'weights_saved_'", "+", "self", ".", "workers", "[", "i", "]", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states": [[564, 572], ["range", "dqn_ensemble.DQNAgentEnsembleParallel.input_queues[].put", "dqn_ensemble.DQNAgentEnsembleParallel.output_queues[].get"], "methods", ["None"], ["", "", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "recent_action", "=", "None", "\n", "self", ".", "recent_observation", "=", "None", "\n", "if", "self", ".", "compiled", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "                ", "self", ".", "input_queues", "[", "i", "]", ".", "put", "(", "[", "'reset_states'", "]", ")", "\n", "out", "=", "self", ".", "output_queues", "[", "i", "]", ".", "get", "(", ")", "\n", "assert", "(", "out", "==", "'reset_states_done_'", "+", "self", ".", "workers", "[", "i", "]", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard": [[573, 578], ["range", "dqn_ensemble.DQNAgentEnsembleParallel.input_queues[].put", "dqn_ensemble.DQNAgentEnsembleParallel.output_queues[].get"], "methods", ["None"], ["", "", "", "def", "update_target_model_hard", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "            ", "self", ".", "input_queues", "[", "i", "]", ".", "put", "(", "[", "'update_target_model'", "]", ")", "\n", "output", "=", "self", ".", "output_queues", "[", "i", "]", ".", "get", "(", ")", "\n", "assert", "(", "output", "==", "'target_model_updated_'", "+", "self", ".", "workers", "[", "i", "]", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward": [[579, 609], ["dqn_ensemble.DQNAgentEnsembleParallel.memory.get_recent_state", "dqn_ensemble.DQNAgentEnsembleParallel.compute_q_values", "dqn_ensemble.DQNAgentEnsembleParallel.policy.select_action", "dqn_ensemble.DQNAgentEnsembleParallel.compute_q_values_all_nets", "dqn_ensemble.DQNAgentEnsembleParallel.test_policy.select_action", "np.mean", "np.std", "info.update"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.AbstractDQNAgent.compute_q_values_all_nets", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["", "", "def", "forward", "(", "self", ",", "observation", ")", ":", "\n", "        ", "\"\"\"\n        Ask the agent to choose an action based on the current observation.\n        Args:\n            observation (ndarray): Current observation.\n\n        Returns:\n            action (int): Index of chosen action\n            info (dict): Information about the Q-values of the chosen action.\n        \"\"\"", "\n", "info", "=", "{", "}", "\n", "# Select an action.", "\n", "state", "=", "self", ".", "memory", ".", "get_recent_state", "(", "observation", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "q_values", "=", "self", ".", "compute_q_values", "(", "state", ",", "self", ".", "active_model", ")", "\n", "action", "=", "self", ".", "policy", ".", "select_action", "(", "q_values", "=", "q_values", ")", "\n", "info", "[", "'q_values'", "]", "=", "q_values", "\n", "", "else", ":", "\n", "            ", "q_values_all_nets", "=", "self", ".", "compute_q_values_all_nets", "(", "state", ")", "\n", "action", ",", "policy_info", "=", "self", ".", "test_policy", ".", "select_action", "(", "q_values_all_nets", "=", "q_values_all_nets", ")", "\n", "info", "[", "'q_values_all_nets'", "]", "=", "q_values_all_nets", "\n", "info", "[", "'q_values'", "]", "=", "np", ".", "mean", "(", "q_values_all_nets", "[", ":", ",", ":", "]", ",", "axis", "=", "0", ")", "\n", "info", "[", "'epistemic_std_dev'", "]", "=", "np", ".", "std", "(", "q_values_all_nets", "[", ":", ",", ":", "]", ",", "axis", "=", "0", ")", "\n", "info", ".", "update", "(", "policy_info", ")", "\n", "\n", "# Book-keeping.", "\n", "", "self", ".", "recent_observation", "=", "observation", "\n", "self", ".", "recent_action", "=", "action", "\n", "\n", "return", "action", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward": [[610, 637], ["dqn_ensemble.DQNAgentEnsembleParallel.memory.append", "dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard", "range", "range", "dqn_ensemble.DQNAgentEnsembleParallel.memory.sample", "dqn_ensemble.DQNAgentEnsembleParallel.input_queues[].put", "dqn_ensemble.DQNAgentEnsembleParallel.output_queues[].get", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.update_target_model_hard", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample"], ["", "def", "backward", "(", "self", ",", "reward", ",", "terminal", ")", ":", "\n", "        ", "\"\"\" Store the most recent experience in the replay memory and update all ensemble networks. \"\"\"", "\n", "# Store most recent experience in memory.", "\n", "if", "self", ".", "step", "%", "self", ".", "memory_interval", "==", "0", ":", "\n", "            ", "self", ".", "memory", ".", "append", "(", "self", ".", "recent_observation", ",", "self", ".", "recent_action", ",", "reward", ",", "terminal", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "metrics", "=", "[", "np", ".", "nan", "for", "_", "in", "self", ".", "metrics_names", "]", "\n", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "step", ">", "self", ".", "nb_steps_warmup", "and", "self", ".", "step", "%", "self", ".", "train_interval", "==", "0", ":", "\n", "                ", "for", "net", "in", "range", "(", "self", ".", "nb_models", ")", ":", "\n", "                    ", "experiences", "=", "self", ".", "memory", ".", "sample", "(", "net", ",", "self", ".", "batch_size", ")", "\n", "assert", "len", "(", "experiences", ")", "==", "self", ".", "batch_size", "\n", "self", ".", "input_queues", "[", "net", "]", ".", "put", "(", "[", "'train'", ",", "experiences", "]", ")", "\n", "\n", "", "for", "net", "in", "range", "(", "self", ".", "nb_models", ")", ":", "# Wait for all workers to finish", "\n", "                    ", "output", "=", "self", ".", "output_queues", "[", "net", "]", ".", "get", "(", ")", "\n", "if", "net", "==", "self", ".", "nb_models", "-", "1", ":", "# Store the metrics of the last agent", "\n", "                        ", "metrics", "=", "output", "[", "1", "]", "\n", "", "assert", "(", "output", "[", "0", "]", "==", "'training_done_'", "+", "self", ".", "workers", "[", "net", "]", ".", "name", ")", "\n", "\n", "metrics", "+=", "[", "self", ".", "active_model", "]", "\n", "\n", "", "", "", "if", "self", ".", "target_model_update", ">=", "1", "and", "self", ".", "step", "%", "self", ".", "target_model_update", "==", "0", ":", "\n", "            ", "self", ".", "update_target_model_hard", "(", ")", "\n", "\n", "", "return", "metrics", "# This is only the metrics of the last agent.", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.layers": [[638, 642], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "layers", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"Using layers in dqn, which has not been updated to ensemble.\"", ")", "\n", "return", "self", ".", "model", ".", "layers", "[", ":", "]", "# Unsure how this function is used and therefore which model to use", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.metrics_names": [[643, 660], ["dqn_ensemble.DQNAgentEnsembleParallel.input_queues[].put", "dqn_ensemble.DQNAgentEnsembleParallel.output_queues[].get", "dqn_ensemble.DQNAgentEnsembleParallel.input_queues[].put", "dqn_ensemble.DQNAgentEnsembleParallel.output_queues[].get", "len", "name.replace", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "metrics_names", "(", "self", ")", ":", "\n", "# Throw away individual losses and replace output name since this is hidden from the user.", "\n", "        ", "self", ".", "input_queues", "[", "0", "]", ".", "put", "(", "[", "'output_names'", "]", ")", "\n", "output_names", "=", "self", ".", "output_queues", "[", "0", "]", ".", "get", "(", ")", "\n", "assert", "len", "(", "output_names", ")", "==", "2", "\n", "dummy_output_name", "=", "output_names", "[", "1", "]", "\n", "self", ".", "input_queues", "[", "0", "]", ".", "put", "(", "[", "'metrics_names'", "]", ")", "\n", "metrics_names_", "=", "self", ".", "output_queues", "[", "0", "]", ".", "get", "(", ")", "\n", "model_metrics", "=", "[", "name", "for", "idx", ",", "name", "in", "enumerate", "(", "metrics_names_", ")", "if", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "\n", "model_metrics", "=", "[", "name", ".", "replace", "(", "dummy_output_name", "+", "'_'", ",", "''", ")", "for", "name", "in", "model_metrics", "]", "\n", "\n", "names", "=", "model_metrics", "+", "self", ".", "policy", ".", "metrics_names", "[", ":", "]", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "            ", "names", "+=", "self", ".", "processor", ".", "metrics_names", "[", ":", "]", "\n", "", "names", "+=", "[", "\"active_model\"", "]", "\n", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.policy": [[665, 669], ["dqn_ensemble.DQNAgentEnsembleParallel.__policy._set_agent"], "methods", ["None"], ["", "@", "policy", ".", "setter", "\n", "def", "policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__policy", "=", "policy", "\n", "self", ".", "__policy", ".", "_set_agent", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.test_policy": [[674, 678], ["dqn_ensemble.DQNAgentEnsembleParallel.__test_policy._set_agent"], "methods", ["None"], ["", "@", "test_policy", ".", "setter", "\n", "def", "test_policy", "(", "self", ",", "policy", ")", ":", "\n", "        ", "self", ".", "__test_policy", "=", "policy", "\n", "self", ".", "__test_policy", ".", "_set_agent", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.__init__": [[710, 744], ["multiprocessing.Process.__init__"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "seed", ",", "input_queue", ",", "output_queue", ",", "cnn_architecture", ",", "nb_ego_states", ",", "nb_states_per_vehicle", ",", "\n", "nb_vehicles", ",", "nb_actions", ",", "nb_conv_layers", ",", "nb_conv_filters", ",", "nb_hidden_fc_layers", ",", "nb_hidden_neurons", ",", "duel", ",", "\n", "prior_scale_factor", ",", "window_length", ",", "processor", ",", "batch_size", ",", "enable_double_dqn", ",", "gamma", ",", "lr", ",", "delta_clip", ",", "\n", "target_model_update", ",", "policy", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "mp", ".", "Process", ".", "__init__", "(", "self", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "input_queue", "=", "input_queue", "\n", "self", ".", "output_queue", "=", "output_queue", "\n", "self", ".", "cnn_architecture", "=", "cnn_architecture", "\n", "self", ".", "nb_ego_states", "=", "nb_ego_states", "\n", "self", ".", "nb_states_per_vehicle", "=", "nb_states_per_vehicle", "\n", "self", ".", "nb_vehicles", "=", "nb_vehicles", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "self", ".", "nb_conv_layers", "=", "nb_conv_layers", "\n", "self", ".", "nb_conv_filters", "=", "nb_conv_filters", "\n", "self", ".", "nb_hidden_fc_layers", "=", "nb_hidden_fc_layers", "\n", "self", ".", "nb_hidden_neurons", "=", "nb_hidden_neurons", "\n", "self", ".", "duel", "=", "duel", "\n", "self", ".", "prior_scale_factor", "=", "prior_scale_factor", "\n", "self", ".", "window_length", "=", "window_length", "\n", "\n", "self", ".", "processor", "=", "processor", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "enable_double_dqn", "=", "enable_double_dqn", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "target_model_update", "=", "target_model_update", "\n", "self", ".", "delta_clip", "=", "delta_clip", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "policy", "=", "policy", "\n", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "model", "=", "None", "\n", "self", ".", "target_model", "=", "None", "\n", "self", ".", "trainable_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.run": [[745, 804], ["np.random.seed", "dqn_ensemble.Worker.compile", "network_architecture.NetworkCNN", "network_architecture.NetworkMLP", "dqn_ensemble.Worker.input_queue.get", "dqn_ensemble.Worker.output_queue.put", "print", "dqn_ensemble.Worker.model.predict_on_batch", "dqn_ensemble.Worker.train_single_net", "dqn_ensemble.Worker.model.reset_states", "dqn_ensemble.Worker.target_model.reset_states", "dqn_ensemble.Worker.target_model.set_weights", "dqn_ensemble.Worker.model.get_weights", "dqn_ensemble.Worker.model.save_weights", "dqn_ensemble.Worker.model.load_weights", "dqn_ensemble.Worker.model.to_json", "Exception"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.train_single_net", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.reset_states", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.save_weights", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.load_weights"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initializes individual networks and starts the workers for each ensemble member. \"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "proc_name", "=", "self", ".", "name", "\n", "if", "self", ".", "cnn_architecture", ":", "\n", "            ", "n", "=", "NetworkCNN", "(", "nb_ego_states", "=", "self", ".", "nb_ego_states", ",", "nb_states_per_vehicle", "=", "self", ".", "nb_states_per_vehicle", ",", "\n", "nb_vehicles", "=", "self", ".", "nb_vehicles", ",", "nb_actions", "=", "self", ".", "nb_actions", ",", "nb_conv_layers", "=", "self", ".", "nb_conv_layers", ",", "\n", "nb_conv_filters", "=", "self", ".", "nb_conv_filters", ",", "nb_hidden_fc_layers", "=", "self", ".", "nb_hidden_fc_layers", ",", "\n", "nb_hidden_neurons", "=", "self", ".", "nb_hidden_neurons", ",", "duel", "=", "self", ".", "duel", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "self", ".", "prior_scale_factor", ",", "window_length", "=", "self", ".", "window_length", ",", "\n", "activation", "=", "'relu'", ",", "duel_type", "=", "'avg'", ")", "\n", "", "else", ":", "\n", "            ", "n", "=", "NetworkMLP", "(", "nb_inputs", "=", "self", ".", "nb_ego_states", "+", "self", ".", "nb_vehicles", "*", "self", ".", "nb_states_per_vehicle", ",", "\n", "nb_outputs", "=", "self", ".", "nb_actions", ",", "\n", "nb_hidden_layers", "=", "self", ".", "nb_hidden_fc_layers", ",", "\n", "nb_hidden_neurons", "=", "self", ".", "nb_hidden_neurons", ",", "duel", "=", "self", ".", "duel", ",", "\n", "prior", "=", "True", ",", "activation", "=", "'relu'", ",", "\n", "prior_scale_factor", "=", "self", ".", "prior_scale_factor", ",", "duel_type", "=", "'avg'", ",", "\n", "window_length", "=", "self", ".", "window_length", ")", "\n", "", "self", ".", "model", "=", "n", ".", "model", "\n", "self", ".", "compile", "(", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "input_", "=", "self", ".", "input_queue", ".", "get", "(", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Read input proc \"", "+", "proc_name", "+", "' '", "+", "input_", "[", "0", "]", ")", "\n", "", "if", "input_", "is", "None", ":", "# If sending None, the process is killed", "\n", "                ", "break", "\n", "\n", "", "if", "input_", "[", "0", "]", "==", "'predict'", ":", "\n", "                ", "output", "=", "self", ".", "model", ".", "predict_on_batch", "(", "input_", "[", "1", "]", ")", "\n", "", "elif", "input_", "[", "0", "]", "==", "'train'", ":", "\n", "                ", "metrics", "=", "self", ".", "train_single_net", "(", "experiences", "=", "input_", "[", "1", "]", ")", "\n", "output", "=", "[", "'training_done_'", "+", "proc_name", ",", "metrics", "]", "\n", "", "elif", "input_", "[", "0", "]", "==", "'reset_states'", ":", "\n", "                ", "self", ".", "model", ".", "reset_states", "(", ")", "\n", "self", ".", "target_model", ".", "reset_states", "(", ")", "\n", "output", "=", "'reset_states_done_'", "+", "proc_name", "\n", "", "elif", "input_", "[", "0", "]", "==", "'update_target_model'", ":", "\n", "                ", "self", ".", "target_model", ".", "set_weights", "(", "self", ".", "model", ".", "get_weights", "(", ")", ")", "\n", "output", "=", "'target_model_updated_'", "+", "proc_name", "\n", "", "elif", "input_", "[", "0", "]", "==", "'save_weights'", ":", "\n", "                ", "self", ".", "model", ".", "save_weights", "(", "input_", "[", "1", "]", ",", "overwrite", "=", "input_", "[", "2", "]", ")", "\n", "output", "=", "'weights_saved_'", "+", "proc_name", "\n", "", "elif", "input_", "[", "0", "]", "==", "'load_weights'", ":", "\n", "                ", "self", ".", "model", ".", "load_weights", "(", "input_", "[", "1", "]", ")", "\n", "output", "=", "'weights_loaded_'", "+", "proc_name", "\n", "", "elif", "input_", "[", "0", "]", "==", "'output_names'", ":", "\n", "                ", "output", "=", "self", ".", "trainable_model", ".", "output_names", "\n", "", "elif", "input_", "[", "0", "]", "==", "'metrics_names'", ":", "\n", "                ", "output", "=", "self", ".", "trainable_model", ".", "metrics_names", "\n", "", "elif", "input_", "[", "0", "]", "==", "'model_as_string'", ":", "\n", "                ", "output", "=", "self", ".", "model", ".", "to_json", "(", ")", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'input command not defined'", ")", "\n", "\n", "", "self", ".", "output_queue", ".", "put", "(", "output", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile": [[805, 847], ["clone_model", "dqn_ensemble.Worker.target_model.compile", "dqn_ensemble.Worker.model.compile", "keras.layers.Input", "keras.layers.Input", "Model", "dqn_ensemble.Worker.trainable_model.compile", "Exception", "huber_loss", "K.sum", "keras.layers.Lambda", "len", "type", "K.zeros_like", "keras.optimizers.Adam"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "compile", "(", "self", ",", "metrics", "=", "None", ")", ":", "\n", "        ", "\"\"\" Set up the training of the neural network.\"\"\"", "\n", "if", "metrics", "is", "None", ":", "\n", "            ", "metrics", "=", "[", "]", "\n", "", "metrics", "+=", "[", "mean_q", "]", "# register default metrics", "\n", "metrics", "+=", "[", "max_q", "]", "\n", "\n", "# We never train the target model, hence we can set the optimizer and loss arbitrarily.", "\n", "self", ".", "target_model", "=", "clone_model", "(", "self", ".", "model", ")", "\n", "self", ".", "target_model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "self", ".", "model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "\n", "# Compile model.", "\n", "if", "self", ".", "target_model_update", "<", "1.", ":", "\n", "            ", "raise", "Exception", "(", "\"Soft target model updates not implemented yet\"", ")", "\n", "# # We use the `AdditionalUpdatesOptimizer` to efficiently soft-update the target model.", "\n", "# updates = get_soft_target_model_updates(self.target_model, self.model, self.target_model_update)", "\n", "# optimizer = AdditionalUpdatesOptimizer(optimizer, updates)", "\n", "\n", "", "def", "clipped_masked_error", "(", "args", ")", ":", "\n", "            ", "y_true", ",", "y_pred", ",", "mask", "=", "args", "\n", "loss", "=", "huber_loss", "(", "y_true", ",", "y_pred", ",", "self", ".", "delta_clip", ")", "\n", "loss", "*=", "mask", "# apply element-wise mask", "\n", "return", "K", ".", "sum", "(", "loss", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Create trainable model. The problem is that we need to mask the output since we only", "\n", "# ever want to update the Q values for a certain action. The way we achieve this is by", "\n", "# using a custom Lambda layer that computes the loss. This gives us the necessary flexibility", "\n", "# to mask out certain parameters by passing in multiple inputs to the Lambda layer.", "\n", "", "y_pred", "=", "self", ".", "model", ".", "output", "\n", "y_true", "=", "Input", "(", "name", "=", "'y_true'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "mask", "=", "Input", "(", "name", "=", "'mask'", ",", "shape", "=", "(", "self", ".", "nb_actions", ",", ")", ")", "\n", "loss_out", "=", "Lambda", "(", "clipped_masked_error", ",", "output_shape", "=", "(", "1", ",", ")", ",", "name", "=", "'loss'", ")", "(", "[", "y_true", ",", "y_pred", ",", "mask", "]", ")", "\n", "ins", "=", "[", "self", ".", "model", ".", "input", "]", "if", "type", "(", "self", ".", "model", ".", "input", ")", "is", "not", "list", "else", "self", ".", "model", ".", "input", "\n", "self", ".", "trainable_model", "=", "Model", "(", "inputs", "=", "ins", "+", "[", "y_true", ",", "mask", "]", ",", "outputs", "=", "[", "loss_out", ",", "y_pred", "]", ")", "\n", "assert", "len", "(", "self", ".", "trainable_model", ".", "output_names", ")", "==", "2", "\n", "combined_metrics", "=", "{", "self", ".", "trainable_model", ".", "output_names", "[", "1", "]", ":", "metrics", "}", "\n", "losses", "=", "[", "\n", "lambda", "y_true", ",", "y_pred", ":", "y_pred", ",", "# loss is computed in Lambda layer", "\n", "lambda", "y_true", ",", "y_pred", ":", "K", ".", "zeros_like", "(", "y_pred", ")", ",", "# we only include this for the metrics", "\n", "]", "\n", "self", ".", "trainable_model", ".", "compile", "(", "optimizer", "=", "Adam", "(", "lr", "=", "self", ".", "lr", ")", ",", "loss", "=", "losses", ",", "metrics", "=", "combined_metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.train_single_net": [[848, 927], ["dqn_ensemble.Worker.process_state_batch", "dqn_ensemble.Worker.process_state_batch", "np.array", "np.array", "np.zeros", "np.zeros", "np.zeros", "enumerate", "np.array().astype", "np.array().astype", "dqn_ensemble.Worker.trainable_model.train_on_batch", "dqn_ensemble.Worker.append", "dqn_ensemble.Worker.append", "np.array.append", "action_batch.append", "np.array.append", "len", "len", "dqn_ensemble.Worker.model.predict_on_batch", "np.argmax", "dqn_ensemble.Worker.target_model.predict_on_batch", "dqn_ensemble.Worker.target_model.predict_on_batch", "np.max().flatten", "zip", "np.array", "np.array", "type", "enumerate", "np.max", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "train_single_net", "(", "self", ",", "experiences", ")", ":", "\n", "        ", "\"\"\" Retrieve a batch of experiences from the replay memory of the ensemble member and update\n        the network weights. \"\"\"", "\n", "# Start by extracting the necessary parameters (we use a vectorized implementation).", "\n", "state0_batch", "=", "[", "]", "\n", "reward_batch", "=", "[", "]", "\n", "action_batch", "=", "[", "]", "\n", "terminal1_batch", "=", "[", "]", "\n", "state1_batch", "=", "[", "]", "\n", "for", "e", "in", "experiences", ":", "\n", "            ", "state0_batch", ".", "append", "(", "e", ".", "state0", ")", "\n", "state1_batch", ".", "append", "(", "e", ".", "state1", ")", "\n", "reward_batch", ".", "append", "(", "e", ".", "reward", ")", "\n", "action_batch", ".", "append", "(", "e", ".", "action", ")", "\n", "terminal1_batch", ".", "append", "(", "0.", "if", "e", ".", "terminal1", "else", "1.", ")", "\n", "\n", "# Prepare and validate parameters.", "\n", "", "state0_batch", "=", "self", ".", "process_state_batch", "(", "state0_batch", ")", "\n", "state1_batch", "=", "self", ".", "process_state_batch", "(", "state1_batch", ")", "\n", "terminal1_batch", "=", "np", ".", "array", "(", "terminal1_batch", ")", "\n", "reward_batch", "=", "np", ".", "array", "(", "reward_batch", ")", "\n", "assert", "reward_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "assert", "terminal1_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "assert", "len", "(", "action_batch", ")", "==", "len", "(", "reward_batch", ")", "\n", "\n", "# Compute Q values for mini-batch update.", "\n", "if", "self", ".", "enable_double_dqn", ":", "\n", "# According to the paper \"Deep Reinforcement Learning with Double Q-learning\"", "\n", "# (van Hasselt et al., 2015), in Double DQN, the online network predicts the actions", "\n", "# while the target network is used to estimate the Q value.", "\n", "            ", "q_values", "=", "self", ".", "model", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "actions", "=", "np", ".", "argmax", "(", "q_values", ",", "axis", "=", "1", ")", "\n", "assert", "actions", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "\n", "# Now, estimate Q values using the target network but select the values with the", "\n", "# highest Q value wrt to the online model (as computed above).", "\n", "target_q_values", "=", "self", ".", "target_model", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "target_q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "q_batch", "=", "target_q_values", "[", "range", "(", "self", ".", "batch_size", ")", ",", "actions", "]", "\n", "", "else", ":", "\n", "# Compute the q_values given state1, and extract the maximum for each sample in the batch.", "\n", "# We perform this prediction on the target_model instead of the model for reasons", "\n", "# outlined in Mnih (2015). In short: it makes the algorithm more stable.", "\n", "            ", "target_q_values", "=", "self", ".", "target_model", ".", "predict_on_batch", "(", "state1_batch", ")", "\n", "assert", "target_q_values", ".", "shape", "==", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", "\n", "q_batch", "=", "np", ".", "max", "(", "target_q_values", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "", "assert", "q_batch", ".", "shape", "==", "(", "self", ".", "batch_size", ",", ")", "\n", "\n", "targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "dummy_targets", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "masks", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "nb_actions", ")", ")", "\n", "\n", "# Compute r_t + gamma * max_a Q(s_t+1, a) and update the target targets accordingly,", "\n", "# but only for the affected output units (as given by action_batch).", "\n", "discounted_reward_batch", "=", "self", ".", "gamma", "*", "q_batch", "\n", "# Set discounted reward to zero for all states that were terminal.", "\n", "discounted_reward_batch", "*=", "terminal1_batch", "\n", "assert", "discounted_reward_batch", ".", "shape", "==", "reward_batch", ".", "shape", "\n", "Rs", "=", "reward_batch", "+", "discounted_reward_batch", "\n", "for", "idx", ",", "(", "target", ",", "mask", ",", "R", ",", "action", ")", "in", "enumerate", "(", "zip", "(", "targets", ",", "masks", ",", "Rs", ",", "action_batch", ")", ")", ":", "\n", "            ", "target", "[", "action", "]", "=", "R", "# update action with estimated accumulated reward", "\n", "dummy_targets", "[", "idx", "]", "=", "R", "\n", "mask", "[", "action", "]", "=", "1.", "# enable loss for this specific action", "\n", "", "targets", "=", "np", ".", "array", "(", "targets", ")", ".", "astype", "(", "'float32'", ")", "\n", "masks", "=", "np", ".", "array", "(", "masks", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "# Finally, perform a single update on the entire batch. We use a dummy target since", "\n", "# the actual loss is computed in a Lambda layer that needs more complex input. However,", "\n", "# it is still useful to know the actual target to compute metrics properly.", "\n", "ins", "=", "[", "state0_batch", "]", "if", "type", "(", "self", ".", "model", ".", "input", ")", "is", "not", "list", "else", "state0_batch", "\n", "metrics", "=", "self", ".", "trainable_model", ".", "train_on_batch", "(", "ins", "+", "[", "targets", ",", "masks", "]", ",", "[", "dummy_targets", ",", "targets", "]", ")", "\n", "metrics", "=", "[", "metric", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "if", "\n", "idx", "not", "in", "(", "1", ",", "2", ")", "]", "# throw away individual losses", "\n", "metrics", "+=", "self", ".", "policy", ".", "metrics", "\n", "if", "self", ".", "processor", "is", "not", "None", ":", "\n", "            ", "metrics", "+=", "self", ".", "processor", ".", "metrics", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch": [[928, 934], ["np.array", "dqn_ensemble.Worker.processor.process_state_batch"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.process_state_batch"], ["", "def", "process_state_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\" Heritage from keras-rl, not used here. \"\"\"", "\n", "batch", "=", "np", ".", "array", "(", "batch", ")", "\n", "if", "self", ".", "processor", "is", "None", ":", "\n", "            ", "return", "batch", "\n", "", "return", "self", ".", "processor", ".", "process_state_batch", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.UpdateActiveModelCallback.__init__": [[947, 950], ["keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "dqn", ")", ":", "\n", "        ", "super", "(", "UpdateActiveModelCallback", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dqn", "=", "dqn", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.UpdateActiveModelCallback.on_episode_begin": [[951, 954], ["dqn_ensemble.UpdateActiveModelCallback.dqn.change_active_model"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.change_active_model"], ["", "def", "on_episode_begin", "(", "self", ",", "episode", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\" Change which ensemble member that is active. \"\"\"", "\n", "self", ".", "dqn", ".", "change_active_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.max_q": [[956, 959], ["K.mean", "K.max"], "function", ["None"], ["", "", "def", "max_q", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\" Returns average maximum Q-value of training batch. \"\"\"", "\n", "return", "K", ".", "mean", "(", "K", ".", "max", "(", "y_pred", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.mean_q": [[961, 964], ["K.mean", "K.mean"], "function", ["None"], ["", "def", "mean_q", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\" Returns average Q-value of training batch. \"\"\"", "\n", "return", "K", ".", "mean", "(", "K", ".", "mean", "(", "y_pred", ",", "axis", "=", "-", "1", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.SaveWeights.__init__": [[17, 22], ["rl.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "save_freq", "=", "10000", ",", "save_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "SaveWeights", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_freq", "=", "save_freq", "\n", "self", ".", "save_path", "=", "save_path", "\n", "self", ".", "nb_saves", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.SaveWeights.on_episode_end": [[23, 29], ["print", "callbacks.SaveWeights.model.save_weights", "str"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.save_weights"], ["", "def", "on_episode_end", "(", "self", ",", "episode_step", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "(", "self", ".", "nb_saves", "==", "0", "or", "self", ".", "model", ".", "step", "-", "(", "self", ".", "nb_saves", "-", "1", ")", "*", "self", ".", "save_freq", ">=", "self", ".", "save_freq", ")", "and", "self", ".", "save_path", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"Number of steps: \"", ",", "self", ".", "model", ".", "step", ")", "\n", "self", ".", "model", ".", "save_weights", "(", "self", ".", "save_path", "+", "\"/\"", "+", "str", "(", "self", ".", "model", ".", "step", ")", ")", "\n", "self", ".", "nb_saves", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.EvaluateAgent.__init__": [[40, 49], ["rl.callbacks.Callback.__init__", "callbacks.StoreTestEpisodeData", "tensorflow.summary.FileWriter"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "eval_freq", "=", "10000", ",", "nb_eval_eps", "=", "5", ",", "save_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "EvaluateAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eval_freq", "=", "eval_freq", "\n", "self", ".", "nb_eval_eps", "=", "nb_eval_eps", "\n", "self", ".", "save_path", "=", "save_path", "\n", "self", ".", "nb_evaluation_runs", "=", "0", "\n", "self", ".", "store_data_callback", "=", "StoreTestEpisodeData", "(", "save_path", ")", "\n", "self", ".", "env", "=", "None", "\n", "self", ".", "writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.EvaluateAgent.on_episode_end": [[50, 66], ["callbacks.EvaluateAgent.model.test", "callbacks.EvaluateAgent.__write_summary", "open", "numpy.savetxt", "f.write", "open", "numpy.savetxt", "f.write"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.test", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.EvaluateAgent.__write_summary"], ["", "def", "on_episode_end", "(", "self", ",", "episode_step", ",", "logs", "=", "None", ")", ":", "# Necessary to run testing at the end of an episode", "\n", "        ", "if", "(", "self", ".", "nb_evaluation_runs", "==", "0", "or", "\n", "self", ".", "model", ".", "step", "-", "(", "self", ".", "nb_evaluation_runs", "-", "1", ")", "*", "self", ".", "eval_freq", ">=", "self", ".", "eval_freq", ")", "and", "self", ".", "save_path", "is", "not", "None", ":", "\n", "            ", "test_result", "=", "self", ".", "model", ".", "test", "(", "self", ".", "env", ",", "nb_episodes", "=", "self", ".", "nb_eval_eps", ",", "\n", "callbacks", "=", "[", "self", ".", "store_data_callback", "]", ",", "\n", "visualize", "=", "False", ")", "\n", "with", "open", "(", "self", ".", "save_path", "+", "'/test_rewards.csv'", ",", "'ab'", ")", "as", "f", ":", "\n", "                ", "np", ".", "savetxt", "(", "f", ",", "test_result", ".", "history", "[", "'episode_reward'", "]", ",", "newline", "=", "' '", ")", "\n", "f", ".", "write", "(", "b'\\n'", ")", "\n", "", "with", "open", "(", "self", ".", "save_path", "+", "'/test_steps.csv'", ",", "'ab'", ")", "as", "f", ":", "\n", "                ", "np", ".", "savetxt", "(", "f", ",", "test_result", ".", "history", "[", "'nb_steps'", "]", ",", "newline", "=", "' '", ")", "\n", "f", ".", "write", "(", "b'\\n'", ")", "\n", "", "self", ".", "__write_summary", "(", "test_result", ".", "history", ")", "\n", "self", ".", "model", ".", "training", "=", "True", "# training is set to False in test function, so needs to be reset here", "\n", "self", ".", "nb_evaluation_runs", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.EvaluateAgent.__write_summary": [[67, 121], ["tensorflow.Summary", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "tensorflow.Summary.value.append", "tensorflow.Summary.value.append", "tensorflow.Summary.value.append", "tensorflow.Summary.value.append", "tensorflow.Summary.value.append", "tensorflow.Summary", "time.sleep", "callbacks.EvaluateAgent.writer.add_summary", "time.sleep", "callbacks.EvaluateAgent.writer.add_summary", "numpy.sum", "numpy.sum", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.value.append", "tensorflow.Summary.value.append", "tensorflow.Summary.value.append", "tensorflow.Summary.value.append", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "numpy.mean", "numpy.mean", "range", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "tensorflow.Summary.Value", "zip", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "range", "numpy.mean", "numpy.mean", "str"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "", "def", "__write_summary", "(", "self", ",", "history", ")", ":", "\n", "        ", "\"\"\" Create tensorboard logs of testing episodes. \"\"\"", "\n", "name", "=", "'evaluation'", "\n", "summary", "=", "tf", ".", "Summary", "(", "value", "=", "[", "\n", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/avg_return'", ",", "simple_value", "=", "np", ".", "mean", "(", "history", "[", "'episode_reward'", "]", ")", ")", ",", "\n", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/avg_nb_steps'", ",", "simple_value", "=", "np", ".", "mean", "(", "history", "[", "'nb_steps'", "]", ")", ")", ",", "\n", "]", ")", "\n", "avg_nb_near_collision", "=", "np", ".", "mean", "(", "[", "'near_collision'", "in", "ep_info", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", ")", "\n", "avg_nb_max_steps", "=", "np", ".", "mean", "(", "[", "ep_info", "[", "'terminal_reason'", "]", "==", "'Max steps'", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", ")", "\n", "avg_nb_collisions", "=", "np", ".", "mean", "(", "[", "'collision'", "in", "ep_info", "[", "'terminal_reason'", "]", "or", "'Outside of road'", "in", "\n", "ep_info", "[", "'terminal_reason'", "]", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", ")", "\n", "avg_nb_max_dist", "=", "np", ".", "mean", "(", "[", "ep_info", "[", "'terminal_reason'", "]", "==", "'Max dist'", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", ")", "\n", "non_collision_eps", "=", "[", "ep_info", "[", "'terminal_reason'", "]", "==", "'Max dist'", "or", "ep_info", "[", "'terminal_reason'", "]", "==", "'Max steps'", "\n", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", "\n", "avg_nb_steps_non_collision_eps", "=", "np", ".", "sum", "(", "[", "nb_steps", "if", "non_collision", "else", "0", "for", "nb_steps", ",", "non_collision", "\n", "in", "zip", "(", "history", "[", "'nb_steps'", "]", ",", "non_collision_eps", ")", "]", ")", "/", "np", ".", "sum", "(", "non_collision_eps", ")", "\n", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/avg_nb_near_collisions'", ",", "\n", "simple_value", "=", "avg_nb_near_collision", ")", ")", "\n", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/avg_nb_collisions'", ",", "\n", "simple_value", "=", "avg_nb_collisions", ")", ")", "\n", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/avg_nb_max_steps'", ",", "\n", "simple_value", "=", "avg_nb_max_steps", ")", ")", "\n", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/avg_nb_max_dist'", ",", "\n", "simple_value", "=", "avg_nb_max_dist", ")", ")", "\n", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/avg_nb_steps_non_collision_eps'", ",", "\n", "simple_value", "=", "avg_nb_steps_non_collision_eps", ")", ")", "\n", "if", "'mean_aleatoric_std_dev_chosen_action'", "in", "history", "[", "'info'", "]", "[", "0", "]", ":", "\n", "            ", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/mean_aleatoric_std_dev_chosen_action'", ",", "\n", "simple_value", "=", "np", ".", "mean", "(", "[", "ep_info", "[", "'mean_aleatoric_std_dev_chosen_action'", "]", "\n", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", ")", ")", ")", "\n", "", "if", "'max_aleatoric_std_dev_chosen_action'", "in", "history", "[", "'info'", "]", "[", "0", "]", ":", "\n", "            ", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/max_aleatoric_std_dev_chosen_action'", ",", "\n", "simple_value", "=", "np", ".", "mean", "(", "[", "ep_info", "[", "'max_aleatoric_std_dev_chosen_action'", "]", "\n", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", ")", ")", ")", "\n", "", "if", "'mean_epistemic_std_dev_chosen_action'", "in", "history", "[", "'info'", "]", "[", "0", "]", ":", "\n", "            ", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/mean_epistemic_std_dev_chosen_action'", ",", "\n", "simple_value", "=", "np", ".", "mean", "(", "[", "ep_info", "[", "'mean_epistemic_std_dev_chosen_action'", "]", "\n", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", ")", ")", ")", "\n", "", "if", "'max_epistemic_std_dev_chosen_action'", "in", "history", "[", "'info'", "]", "[", "0", "]", ":", "\n", "            ", "summary", ".", "value", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "name", "+", "'/max_epistemic_std_dev_chosen_action'", ",", "\n", "simple_value", "=", "np", ".", "mean", "(", "[", "ep_info", "[", "'max_epistemic_std_dev_chosen_action'", "]", "\n", "for", "ep_info", "in", "history", "[", "'info'", "]", "]", ")", ")", ")", "\n", "", "avg_action_prop", "=", "[", "np", ".", "mean", "(", "[", "ep_info", "[", "'total_actions'", "]", "[", "i", "]", "for", "ep_info", "in", "\n", "history", "[", "'info'", "]", "]", ")", "/", "np", ".", "mean", "(", "history", "[", "'nb_steps'", "]", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "env", ".", "nb_actions", ")", "]", "\n", "summary_actions", "=", "tf", ".", "Summary", "(", "value", "=", "[", "\n", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "'action_prop'", "+", "'/'", "+", "str", "(", "i", ")", ",", "simple_value", "=", "avg_action_prop", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "env", ".", "nb_actions", ")", "\n", "]", ")", "\n", "time", ".", "sleep", "(", "1", ")", "# Temporary fix for getting all tensorboard logs", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary_actions", ",", "self", ".", "nb_evaluation_runs", ")", "\n", "time", ".", "sleep", "(", "1", ")", "# Temporary fix for getting all tensorboard logs", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary", ",", "self", ".", "nb_evaluation_runs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.StoreTestEpisodeData.__init__": [[130, 137], ["rl.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "save_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "StoreTestEpisodeData", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_path", "=", "save_path", "\n", "self", ".", "episode", "=", "-", "1", "\n", "self", ".", "action_data", "=", "[", "]", "\n", "self", ".", "reward_data", "=", "[", "]", "\n", "self", ".", "q_values_data", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.callbacks.StoreTestEpisodeData.on_step_end": [[138, 169], ["callbacks.StoreTestEpisodeData.action_data.append", "callbacks.StoreTestEpisodeData.reward_data.append", "callbacks.StoreTestEpisodeData.action_data.append", "callbacks.StoreTestEpisodeData.reward_data.append", "callbacks.StoreTestEpisodeData.q_values_data.append", "callbacks.StoreTestEpisodeData.q_values_data.append", "open", "numpy.savetxt", "f.write", "open", "numpy.savetxt", "f.write", "open", "numpy.savetxt", "f.write"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "on_step_end", "(", "self", ",", "episode_step", ",", "logs", "=", "None", ")", ":", "\n", "        ", "assert", "(", "self", ".", "model", ".", "training", "is", "False", ")", "# This should only be done in testing mode", "\n", "if", "logs", "is", "None", ":", "\n", "            ", "logs", "=", "{", "}", "\n", "\n", "", "if", "self", ".", "save_path", "is", "not", "None", ":", "\n", "            ", "if", "not", "logs", "[", "'episode'", "]", "==", "self", ".", "episode", ":", "\n", "                ", "if", "not", "self", ".", "episode", "==", "-", "1", ":", "\n", "                    ", "with", "open", "(", "self", ".", "save_path", "+", "'/test_individual_reward_data.csv'", ",", "'ab'", ")", "as", "f", ":", "\n", "                        ", "np", ".", "savetxt", "(", "f", ",", "self", ".", "reward_data", ",", "newline", "=", "' '", ")", "\n", "f", ".", "write", "(", "b'\\n'", ")", "\n", "", "with", "open", "(", "self", ".", "save_path", "+", "'/test_individual_action_data.csv'", ",", "'ab'", ")", "as", "f", ":", "\n", "                        ", "np", ".", "savetxt", "(", "f", ",", "self", ".", "action_data", ",", "newline", "=", "' '", ")", "\n", "f", ".", "write", "(", "b'\\n'", ")", "\n", "", "if", "'q_values_of_chosen_action'", "in", "logs", ":", "\n", "                        ", "with", "open", "(", "self", ".", "save_path", "+", "'/test_individual_qvalues_data.csv'", ",", "'ab'", ")", "as", "f", ":", "\n", "                            ", "np", ".", "savetxt", "(", "f", ",", "self", ".", "q_values_data", ",", "newline", "=", "'\\n'", ")", "\n", "f", ".", "write", "(", "b'\\n'", ")", "\n", "", "", "", "self", ".", "episode", "=", "logs", "[", "'episode'", "]", "\n", "self", ".", "action_data", "=", "[", "]", "\n", "self", ".", "reward_data", "=", "[", "]", "\n", "self", ".", "action_data", ".", "append", "(", "logs", "[", "'action'", "]", ")", "\n", "self", ".", "reward_data", ".", "append", "(", "logs", "[", "'reward'", "]", ")", "\n", "if", "'q_values_of_chosen_action'", "in", "logs", ":", "\n", "                    ", "self", ".", "q_values_data", "=", "[", "]", "\n", "self", ".", "q_values_data", ".", "append", "(", "logs", "[", "'q_values_of_chosen_action'", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "action_data", ".", "append", "(", "logs", "[", "'action'", "]", ")", "\n", "self", ".", "reward_data", ".", "append", "(", "logs", "[", "'reward'", "]", ")", "\n", "if", "'q_values_of_chosen_action'", "in", "logs", ":", "\n", "                    ", "self", ".", "q_values_data", ".", "append", "(", "logs", "[", "'q_values_of_chosen_action'", "]", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.__init__": [[43, 120], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "road.Road", "intersection_env.IntersectionEnv.road.create_road", "sumolib.checkBinary", "sumolib.checkBinary", "traci.start", "traci.start"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.create_road"], ["def", "__init__", "(", "self", ",", "sim_params", ",", "road_params", ",", "gui_params", "=", "None", ",", "start_time", "=", "''", ")", ":", "\n", "        ", "self", ".", "step_", "=", "0", "\n", "\n", "# Parameters road", "\n", "self", ".", "intersection_pos", "=", "road_params", "[", "'intersection_position'", "]", "\n", "self", ".", "nb_lanes", "=", "road_params", "[", "'nb_lanes'", "]", "\n", "self", ".", "lane_width", "=", "road_params", "[", "'lane_width'", "]", "\n", "self", ".", "ego_length", "=", "road_params", "[", "'vehicles'", "]", "[", "0", "]", "[", "'length'", "]", "\n", "self", ".", "ego_width", "=", "road_params", "[", "'vehicles'", "]", "[", "0", "]", "[", "'width'", "]", "\n", "self", ".", "car_length", "=", "road_params", "[", "'vehicles'", "]", "[", "1", "]", "[", "'length'", "]", "\n", "self", ".", "car_width", "=", "road_params", "[", "'vehicles'", "]", "[", "1", "]", "[", "'width'", "]", "\n", "self", ".", "stop_line", "=", "road_params", "[", "'stop_line'", "]", "\n", "\n", "# Parameters scenario", "\n", "self", ".", "max_steps", "=", "sim_params", "[", "'max_steps'", "]", "\n", "self", ".", "start_pos", "=", "sim_params", "[", "'ego_start_position'", "]", "\n", "self", ".", "end_pos", "=", "sim_params", "[", "'ego_end_position'", "]", "\n", "self", ".", "start_route", "=", "sim_params", "[", "'ego_start_route'", "]", "\n", "self", ".", "start_lane", "=", "sim_params", "[", "'ego_start_lane'", "]", "\n", "self", ".", "init_steps", "=", "sim_params", "[", "'init_steps'", "]", "\n", "self", ".", "adding_prob", "=", "sim_params", "[", "'adding_prob'", "]", "\n", "self", ".", "max_nb_vehicles", "=", "sim_params", "[", "'nb_vehicles'", "]", "\n", "self", ".", "idm_params", "=", "sim_params", "[", "'idm_params'", "]", "\n", "self", ".", "max_speed", "=", "road_params", "[", "'speed_range'", "]", "[", "1", "]", "\n", "self", ".", "min_speed", "=", "road_params", "[", "'speed_range'", "]", "[", "0", "]", "\n", "self", ".", "max_ego_speed", "=", "road_params", "[", "'vehicles'", "]", "[", "0", "]", "[", "'maxSpeed'", "]", "\n", "self", ".", "safety_check", "=", "sim_params", "[", "'safety_check'", "]", "\n", "\n", "# Parameters sensing", "\n", "self", ".", "nb_ego_states", "=", "3", "\n", "self", ".", "nb_states_per_vehicle", "=", "4", "\n", "self", ".", "sensor_range", "=", "sim_params", "[", "'sensor_range'", "]", "\n", "self", ".", "occlusion_dist", "=", "sim_params", "[", "'occlusion_dist'", "]", "\n", "self", ".", "sensor_nb_vehicles", "=", "sim_params", "[", "'sensor_nb_vehicles'", "]", "\n", "self", ".", "sensor_noise", "=", "sim_params", "[", "'sensor_noise'", "]", "\n", "self", ".", "sensor_max_speed_scale", "=", "self", ".", "max_speed", "\n", "\n", "# Parameters reward", "\n", "self", ".", "goal_reward", "=", "sim_params", "[", "'goal_reward'", "]", "\n", "self", ".", "collision_penalty", "=", "sim_params", "[", "'collision_penalty'", "]", "\n", "self", ".", "near_collision_penalty", "=", "sim_params", "[", "'near_collision_penalty'", "]", "\n", "self", ".", "near_collision_margin", "=", "sim_params", "[", "'near_collision_margin'", "]", "\n", "\n", "# GUI parameters", "\n", "self", ".", "use_gui", "=", "gui_params", "[", "'use_gui'", "]", "if", "gui_params", "else", "False", "\n", "self", ".", "print_gui_info", "=", "gui_params", "[", "'print_gui_info'", "]", "if", "gui_params", "else", "False", "\n", "self", ".", "draw_sensor_range", "=", "gui_params", "[", "'draw_sensor_range'", "]", "if", "gui_params", "else", "False", "\n", "self", ".", "zoom_level", "=", "gui_params", "[", "'zoom_level'", "]", "if", "gui_params", "else", "False", "\n", "self", ".", "fix_vehicle_colors", "=", "False", "\n", "self", ".", "gui_state_info", "=", "[", "]", "\n", "self", ".", "gui_action_info", "=", "[", "]", "\n", "self", ".", "gui_occlusions", "=", "[", "]", "\n", "\n", "# Initialize state", "\n", "self", ".", "vehicles", "=", "[", "]", "\n", "self", ".", "positions", "=", "np", ".", "zeros", "(", "[", "self", ".", "max_nb_vehicles", ",", "2", "]", ")", "# Defined as center of vehicle", "\n", "self", ".", "speeds", "=", "np", ".", "zeros", "(", "[", "self", ".", "max_nb_vehicles", ",", "2", "]", ")", "\n", "self", ".", "accs", "=", "np", ".", "zeros", "(", "[", "self", ".", "max_nb_vehicles", "]", ")", "\n", "self", ".", "headings", "=", "np", ".", "zeros", "(", "[", "self", ".", "max_nb_vehicles", "]", ")", "\n", "self", ".", "ego_id", "=", "None", "\n", "self", ".", "previous_adding_node", "=", "None", "\n", "self", ".", "state_t0", "=", "None", "\n", "self", ".", "state_t1", "=", "None", "\n", "\n", "self", ".", "road", "=", "Road", "(", "road_params", ",", "start_time", "=", "start_time", ")", "\n", "self", ".", "road", ".", "create_road", "(", ")", "\n", "\n", "if", "self", ".", "use_gui", ":", "\n", "            ", "sumo_binary", "=", "checkBinary", "(", "'sumo-gui'", ")", "\n", "", "else", ":", "\n", "            ", "sumo_binary", "=", "checkBinary", "(", "'sumo'", ")", "\n", "\n", "", "if", "sim_params", "[", "'remove_sumo_warnings'", "]", ":", "\n", "            ", "traci", ".", "start", "(", "[", "sumo_binary", ",", "\"-c\"", ",", "self", ".", "road", ".", "road_path", "+", "self", ".", "road", ".", "name", "+", "\".sumocfg\"", ",", "\"--start\"", ",", "\n", "\"--no-warnings\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "traci", ".", "start", "(", "[", "sumo_binary", ",", "\"-c\"", ",", "self", ".", "road", ".", "road_path", "+", "self", ".", "road", ".", "name", "+", "\".sumocfg\"", ",", "\"--start\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset": [[121, 205], ["traci.simulationStep", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "traci.vehicle.add", "traci.vehicle.subscribe", "traci.simulationStep", "range", "traci.vehicle.moveTo", "intersection_env.IntersectionEnv.step", "traci.simulationStep", "traci.vehicle.remove", "traci.vehicle.highlight", "len", "intersection_env.IntersectionEnv.step", "traci.vehicle.setSpeed", "traci.vehicle.setSpeed", "traci.vehicle.moveTo", "intersection_env.IntersectionEnv.step", "traci.gui.setZoom", "intersection_env.IntersectionEnv.draw_occlusion", "tuple", "traci.vehicle.getIDList", "Exception", "warnings.warn", "int", "traci.vehicle.getIDList", "traci.vehicle.setSpeedMode", "traci.vehicle.setLaneChangeMode", "intersection_env.IntersectionEnv.print_state_info_in_gui", "len", "len", "numpy.ceil", "traci.vehicle.getIDList", "numpy.log10"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.draw_occlusion", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.print_state_info_in_gui"], ["", "", "def", "reset", "(", "self", ",", "ego_at_intersection", "=", "False", ",", "sumo_ctrl", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Resets the intersection driving environment to a new random initial state.\n\n        The ego vehicle starts in the south. A number of surrounding vehicles are added to random positions\n        in the east and west, with randomly selected driver model parameters, e.g., desired speed.\n\n        Args:\n            ego_at_intersection (bool): If true, the ego vehicle starts close to the intersection (see the paper\n                                        for description of specific tests)\n            sumo_ctrl (bool): For testing purposes, setting this True lets SUMO control the ego vehicle.\n\n        Returns:\n            observation (ndarray): The observation of the traffic situation, according to the sensor model.\n        \"\"\"", "\n", "# Remove all vehicles", "\n", "# In some cases, the last vehicle may not yet have been inserted, and therefore cannot be deleted.", "\n", "# Then, run a few extra simulation steps.", "\n", "i", "=", "0", "\n", "while", "not", "tuple", "(", "self", ".", "vehicles", ")", "==", "traci", ".", "vehicle", ".", "getIDList", "(", ")", ":", "\n", "            ", "if", "i", ">", "5", ":", "\n", "                ", "raise", "Exception", "(", "\"All vehicles could not be inserted, and therefore not reset.\"", ")", "\n", "", "if", "len", "(", "self", ".", "vehicles", ")", "-", "len", "(", "traci", ".", "vehicle", ".", "getIDList", "(", ")", ")", ">", "1", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"More than one vehicle missing during reset\"", ")", "\n", "", "traci", ".", "simulationStep", "(", ")", "\n", "i", "+=", "1", "\n", "", "for", "veh", "in", "self", ".", "vehicles", ":", "\n", "            ", "traci", ".", "vehicle", ".", "remove", "(", "veh", ")", "\n", "", "traci", ".", "simulationStep", "(", ")", "\n", "\n", "# Reset state", "\n", "self", ".", "vehicles", "=", "[", "]", "\n", "self", ".", "positions", "=", "np", ".", "zeros", "(", "[", "self", ".", "max_nb_vehicles", ",", "2", "]", ")", "\n", "self", ".", "speeds", "=", "np", ".", "zeros", "(", "[", "self", ".", "max_nb_vehicles", ",", "2", "]", ")", "\n", "self", ".", "accs", "=", "np", ".", "zeros", "(", "[", "self", ".", "max_nb_vehicles", "]", ")", "\n", "self", ".", "headings", "=", "np", ".", "zeros", "(", "[", "self", ".", "max_nb_vehicles", "]", ")", "\n", "self", ".", "previous_adding_node", "=", "None", "\n", "self", ".", "state_t0", "=", "None", "\n", "self", ".", "state_t1", "=", "None", "\n", "\n", "# Add ego vehicle", "\n", "self", ".", "ego_id", "=", "'veh'", "+", "'0'", ".", "zfill", "(", "int", "(", "np", ".", "ceil", "(", "np", ".", "log10", "(", "self", ".", "max_nb_vehicles", ")", ")", ")", ")", "# Add leading zeros to number", "\n", "traci", ".", "vehicle", ".", "add", "(", "self", ".", "ego_id", ",", "self", ".", "start_route", ",", "typeID", "=", "'truck'", ",", "depart", "=", "None", ",", "departLane", "=", "0", ",", "\n", "departPos", "=", "'base'", ",", "departSpeed", "=", "self", ".", "road", ".", "road_params", "[", "'vehicles'", "]", "[", "0", "]", "[", "'maxSpeed'", "]", ",", "\n", "arrivalLane", "=", "'current'", ",", "arrivalPos", "=", "'max'", ",", "arrivalSpeed", "=", "'current'", ",", "fromTaz", "=", "''", ",", "toTaz", "=", "''", ",", "\n", "line", "=", "''", ",", "personCapacity", "=", "0", ",", "personNumber", "=", "0", ")", "\n", "traci", ".", "vehicle", ".", "subscribe", "(", "self", ".", "ego_id", ",", "[", "POSITION", ",", "LONG_SPEED", ",", "LAT_SPEED", ",", "LONG_ACC", ",", "ANGLE", "]", ")", "\n", "traci", ".", "simulationStep", "(", ")", "\n", "if", "self", ".", "draw_sensor_range", ":", "\n", "            ", "traci", ".", "vehicle", ".", "highlight", "(", "self", ".", "ego_id", ",", "size", "=", "self", ".", "sensor_range", ")", "\n", "", "assert", "(", "len", "(", "traci", ".", "vehicle", ".", "getIDList", "(", ")", ")", "==", "1", ")", "\n", "self", ".", "vehicles", "=", "[", "self", ".", "ego_id", "]", "\n", "\n", "# Random init steps", "\n", "for", "i", "in", "range", "(", "self", ".", "init_steps", "-", "1", ")", ":", "\n", "            ", "self", ".", "step", "(", "action", "=", "0", ",", "sumo_ctrl", "=", "True", ")", "\n", "", "traci", ".", "vehicle", ".", "moveTo", "(", "self", ".", "ego_id", ",", "self", ".", "start_lane", ",", "0", ")", "\n", "observation", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "step", "(", "action", "=", "0", ",", "sumo_ctrl", "=", "True", ")", "\n", "\n", "# Turn off all internal lane changes and all safety checks for ego vehicle", "\n", "if", "not", "sumo_ctrl", ":", "\n", "            ", "if", "not", "self", ".", "safety_check", ":", "\n", "                ", "traci", ".", "vehicle", ".", "setSpeedMode", "(", "self", ".", "ego_id", ",", "0", ")", "\n", "traci", ".", "vehicle", ".", "setLaneChangeMode", "(", "self", ".", "ego_id", ",", "0", ")", "\n", "", "", "else", ":", "\n", "            ", "traci", ".", "vehicle", ".", "setSpeed", "(", "self", ".", "ego_id", ",", "-", "1", ")", "\n", "\n", "# Special case of ego vehicle starting close to the intersection", "\n", "", "if", "ego_at_intersection", ":", "\n", "            ", "traci", ".", "vehicle", ".", "setSpeed", "(", "self", ".", "ego_id", ",", "0", ")", "\n", "self", ".", "speeds", "[", "0", ",", "0", "]", "=", "7", "\n", "traci", ".", "vehicle", ".", "moveTo", "(", "self", ".", "ego_id", ",", "self", ".", "start_lane", ",", "-", "self", ".", "start_pos", "+", "self", ".", "max_ego_speed", "-", "self", ".", "lane_width", "\n", "-", "self", ".", "occlusion_dist", "-", "self", ".", "speeds", "[", "0", ",", "0", "]", ")", "\n", "observation", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "step", "(", "action", "=", "0", ")", "\n", "\n", "", "self", ".", "step_", "=", "0", "\n", "\n", "if", "self", ".", "use_gui", ":", "\n", "            ", "traci", ".", "gui", ".", "setZoom", "(", "'View #0'", ",", "self", ".", "zoom_level", ")", "\n", "self", ".", "draw_occlusion", "(", ")", "\n", "if", "self", ".", "print_gui_info", ":", "\n", "                ", "self", ".", "print_state_info_in_gui", "(", "info", "=", "'Start'", ")", "\n", "\n", "", "", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step": [[206, 334], ["numpy.copy", "len", "intersection_env.IntersectionEnv.action_model", "traci.simulationStep", "intersection_env.IntersectionEnv.collision_detection", "copy.deepcopy", "intersection_env.IntersectionEnv.sensor_model", "intersection_env.IntersectionEnv.reward_model", "info.update", "intersection_env.IntersectionEnv.print_action_info_in_gui", "traci.vehicle.setSpeed", "int", "int", "traci.vehicle.getSubscriptionResults", "intersection_env.IntersectionEnv.occlusion_model", "traci.simulation.getCollidingVehiclesNumber", "warnings.warn", "str", "intersection_env.IntersectionEnv.print_state_info_in_gui", "numpy.random.rand", "numpy.random.randint", "traci.vehicle.add", "traci.vehicle.setMaxSpeed", "traci.vehicle.setLaneChangeMode", "traci.vehicle.subscribe", "intersection_env.IntersectionEnv.vehicles.append", "traci.vehicle.setColor", "numpy.floor", "str().zfill", "numpy.random.randint", "traci.vehicle.setColor", "numpy.log10", "numpy.mod", "numpy.cos", "numpy.sin", "traci.vehicle.setColor", "int", "int", "numpy.random.rand", "str", "traci.vehicle.setColor", "int", "int", "traci.vehicle.setColor", "traci.vehicle.setColor", "str", "numpy.ceil", "traci.vehicle.setColor", "max", "numpy.log10", "int"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.action_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.sensor_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reward_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.print_action_info_in_gui", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.print_state_info_in_gui", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "step", "(", "self", ",", "action", ",", "action_info", "=", "None", ",", "sumo_ctrl", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Transition the environment to the next state with the specified action.\n\n        Args:\n            action (int): Action index, which is translated to an acceleration through\n                          the Intelligent Driver Model (IDM).\n                          0 - cruise, 1 - go, 2 - stop.\n            action_info (dict): Used to display information in the GUI.\n            sumo_ctrl (bool): For testing purposes, setting this True lets SUMO control the ego vehicle\n                              (ignoring the surrounding vehicles).\n\n        Returns:\n            tuple, containing:\n                observation (ndarray): Observation of the environment, given by the sensor model.\n                reward (float): Reward of the current time step.\n                done (bool): True if terminal state is reached, otherwise False\n                info (dict): Dictionary with simulation information.\n        \"\"\"", "\n", "self", ".", "state_t0", "=", "np", ".", "copy", "(", "self", ".", "state_t1", ")", "\n", "\n", "if", "self", ".", "use_gui", "and", "self", ".", "print_gui_info", ":", "\n", "            ", "self", ".", "print_action_info_in_gui", "(", "action", ",", "action_info", ")", "\n", "\n", "# Add more vehicles if possible", "\n", "", "nb_vehicles", "=", "len", "(", "self", ".", "vehicles", ")", "\n", "if", "nb_vehicles", "<", "self", ".", "max_nb_vehicles", ":", "\n", "            ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "adding_prob", ":", "\n", "                ", "veh_id", "=", "'veh'", "+", "str", "(", "nb_vehicles", ")", ".", "zfill", "(", "int", "(", "np", ".", "ceil", "(", "np", ".", "log10", "(", "self", ".", "max_nb_vehicles", ")", ")", ")", ")", "# Add leading zeros to number", "\n", "route_id", "=", "np", ".", "random", ".", "randint", "(", "4", ")", "\n", "node", "=", "0", "if", "route_id", "in", "[", "0", ",", "1", "]", "else", "2", "\n", "while", "node", "==", "self", ".", "previous_adding_node", ":", "# To avoid adding a vehicle to an already occupied spot", "\n", "                    ", "route_id", "=", "np", ".", "random", ".", "randint", "(", "4", ")", "\n", "node", "=", "0", "if", "route_id", "in", "[", "0", ",", "1", "]", "else", "2", "\n", "", "self", ".", "previous_adding_node", "=", "node", "\n", "speed", "=", "self", ".", "min_speed", "+", "np", ".", "random", ".", "rand", "(", ")", "*", "(", "self", ".", "max_speed", "-", "self", ".", "min_speed", ")", "\n", "traci", ".", "vehicle", ".", "add", "(", "veh_id", ",", "'route'", "+", "str", "(", "route_id", ")", ",", "typeID", "=", "'car'", ",", "depart", "=", "None", ",", "departLane", "=", "0", ",", "\n", "departPos", "=", "'base'", ",", "departSpeed", "=", "speed", ",", "\n", "arrivalLane", "=", "'current'", ",", "arrivalPos", "=", "'max'", ",", "arrivalSpeed", "=", "'current'", ",", "fromTaz", "=", "''", ",", "toTaz", "=", "''", ",", "\n", "line", "=", "''", ",", "personCapacity", "=", "0", ",", "personNumber", "=", "0", ")", "\n", "traci", ".", "vehicle", ".", "setMaxSpeed", "(", "veh_id", ",", "speed", ")", "\n", "traci", ".", "vehicle", ".", "setLaneChangeMode", "(", "veh_id", ",", "0", ")", "# Turn off lane changes", "\n", "traci", ".", "vehicle", ".", "subscribe", "(", "veh_id", ",", "[", "POSITION", ",", "LONG_SPEED", ",", "LAT_SPEED", ",", "LONG_ACC", ",", "ANGLE", "]", ")", "# position, speed", "\n", "self", ".", "vehicles", ".", "append", "(", "veh_id", ")", "\n", "\n", "# Take one simulation step", "\n", "", "", "acc", "=", "self", ".", "action_model", "(", "action", ",", "action_info", ")", "\n", "if", "self", ".", "use_gui", "and", "not", "self", ".", "fix_vehicle_colors", ":", "\n", "            ", "if", "action", "==", "0", ":", "\n", "                ", "traci", ".", "vehicle", ".", "setColor", "(", "self", ".", "vehicles", "[", "0", "]", ",", "(", "255", ",", "255", ",", "0", ")", ")", "\n", "", "elif", "action", "==", "1", ":", "\n", "                ", "traci", ".", "vehicle", ".", "setColor", "(", "self", ".", "vehicles", "[", "0", "]", ",", "(", "0", ",", "255", ",", "0", ")", ")", "\n", "", "elif", "action", "==", "2", ":", "\n", "                ", "traci", ".", "vehicle", ".", "setColor", "(", "self", ".", "vehicles", "[", "0", "]", ",", "(", "255", ",", "0", ",", "0", ")", ")", "\n", "", "elif", "action", "==", "3", ":", "\n", "                ", "traci", ".", "vehicle", ".", "setColor", "(", "self", ".", "vehicles", "[", "0", "]", ",", "(", "0", ",", "0", ",", "255", ")", ")", "\n", "", "", "if", "not", "sumo_ctrl", ":", "\n", "            ", "traci", ".", "vehicle", ".", "setSpeed", "(", "self", ".", "ego_id", ",", "self", ".", "speeds", "[", "0", ",", "0", "]", "+", "acc", ")", "\n", "", "traci", ".", "simulationStep", "(", ")", "\n", "self", ".", "step_", "+=", "1", "\n", "\n", "# Get state information", "\n", "nb_digits", "=", "int", "(", "np", ".", "floor", "(", "np", ".", "log10", "(", "self", ".", "max_nb_vehicles", ")", ")", ")", "+", "1", "# Number of digits in vehicle name.", "\n", "for", "veh", "in", "self", ".", "vehicles", ":", "\n", "            ", "i", "=", "int", "(", "veh", "[", "-", "nb_digits", ":", "]", ")", "# See comment above", "\n", "out", "=", "traci", ".", "vehicle", ".", "getSubscriptionResults", "(", "veh", ")", "\n", "self", ".", "speeds", "[", "i", ",", "0", "]", "=", "out", "[", "LONG_SPEED", "]", "\n", "self", ".", "speeds", "[", "i", ",", "1", "]", "=", "out", "[", "LAT_SPEED", "]", "\n", "self", ".", "accs", "[", "i", "]", "=", "out", "[", "LONG_ACC", "]", "\n", "self", ".", "headings", "[", "i", "]", "=", "np", ".", "mod", "(", "-", "out", "[", "ANGLE", "]", "+", "90", ",", "360", ")", "/", "180", "*", "np", ".", "pi", "\n", "if", "i", "==", "0", ":", "\n", "                ", "vehicle_length", "=", "self", ".", "ego_length", "\n", "", "else", ":", "\n", "                ", "vehicle_length", "=", "self", ".", "car_length", "\n", "", "self", ".", "positions", "[", "i", ",", "0", "]", "=", "out", "[", "POSITION", "]", "[", "0", "]", "-", "vehicle_length", "/", "2", "*", "np", ".", "cos", "(", "self", ".", "headings", "[", "i", "]", ")", "\n", "self", ".", "positions", "[", "i", ",", "1", "]", "=", "out", "[", "POSITION", "]", "[", "1", "]", "-", "vehicle_length", "/", "2", "*", "np", ".", "sin", "(", "self", ".", "headings", "[", "i", "]", ")", "\n", "", "if", "self", ".", "use_gui", ":", "\n", "            ", "non_occluded_vehicles", "=", "self", ".", "occlusion_model", "(", "\n", "self", ".", "positions", "[", "0", ",", "1", "]", "+", "self", ".", "ego_length", "/", "2", "-", "self", ".", "intersection_pos", "[", "1", "]", ")", "\n", "for", "veh", "in", "self", ".", "vehicles", "[", "1", ":", "]", ":", "\n", "                ", "if", "self", ".", "fix_vehicle_colors", ":", "\n", "                    ", "traci", ".", "vehicle", ".", "setColor", "(", "veh", ",", "(", "255", ",", "255", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                    ", "i", "=", "int", "(", "veh", "[", "-", "nb_digits", ":", "]", ")", "\n", "color_speed_range", "=", "[", "10", ",", "15", "]", "\n", "speed_factor", "=", "(", "self", ".", "speeds", "[", "i", ",", "0", "]", "-", "color_speed_range", "[", "0", "]", ")", "/", "(", "color_speed_range", "[", "1", "]", "-", "color_speed_range", "[", "0", "]", ")", "\n", "if", "speed_factor", ">", "1", ":", "\n", "                        ", "r", "=", "int", "(", "255", "*", "(", "1", "-", "(", "speed_factor", "-", "1", ")", "/", "4", ")", ")", "\n", "g", "=", "0", "\n", "b", "=", "int", "(", "255", "*", "(", "speed_factor", "-", "1", ")", "/", "2", ")", "\n", "", "else", ":", "\n", "                        ", "r", "=", "255", "\n", "g", "=", "255", "-", "max", "(", "int", "(", "255", "*", "speed_factor", ")", ",", "0", ")", "\n", "b", "=", "0", "\n", "", "if", "non_occluded_vehicles", "[", "i", "-", "1", "]", ":", "\n", "                        ", "traci", ".", "vehicle", ".", "setColor", "(", "veh", ",", "(", "r", ",", "g", ",", "b", ")", ")", "\n", "", "else", ":", "\n", "                        ", "traci", ".", "vehicle", ".", "setColor", "(", "veh", ",", "(", "155", ",", ")", "*", "3", ")", "\n", "# traci.vehicle.setColor(veh, (r, g, b))", "\n", "\n", "", "", "", "", "if", "traci", ".", "simulation", ".", "getCollidingVehiclesNumber", "(", ")", ">", "0", ":", "\n", "            ", "warnings", ".", "warn", "(", "'Collision between surrounding cars. This should normally not happen.'", ")", "\n", "\n", "# Check terminal state", "\n", "", "info", "=", "{", "}", "\n", "done", "=", "False", "\n", "collision", ",", "near_collision", ",", "collision_info", "=", "self", ".", "collision_detection", "(", ")", "\n", "if", "collision", ":", "\n", "            ", "done", "=", "True", "\n", "info", "[", "'terminal_reason'", "]", "=", "str", "(", "collision_info", ")", "\n", "", "if", "self", ".", "step_", "==", "self", ".", "max_steps", ":", "\n", "            ", "done", "=", "True", "\n", "info", "[", "'terminal_reason'", "]", "=", "'Max steps'", "\n", "", "if", "self", ".", "positions", "[", "0", ",", "1", "]", "-", "self", ".", "intersection_pos", "[", "1", "]", ">=", "self", ".", "end_pos", ":", "\n", "            ", "done", "=", "True", "\n", "info", "[", "'terminal_reason'", "]", "=", "'Max dist'", "\n", "", "goal_reached", "=", "done", "and", "info", "[", "'terminal_reason'", "]", "==", "'Max dist'", "\n", "\n", "# Create observation and get reward", "\n", "self", ".", "state_t1", "=", "copy", ".", "deepcopy", "(", "[", "self", ".", "positions", ",", "self", ".", "speeds", ",", "self", ".", "headings", ",", "done", "]", ")", "\n", "observation", "=", "self", ".", "sensor_model", "(", "self", ".", "state_t1", ")", "\n", "reward", ",", "reward_info", "=", "self", ".", "reward_model", "(", "goal_reached", "=", "goal_reached", ",", "collision", "=", "collision", ",", "\n", "near_collision", "=", "near_collision", ")", "\n", "info", ".", "update", "(", "reward_info", ")", "\n", "if", "self", ".", "use_gui", "and", "self", ".", "print_gui_info", ":", "\n", "            ", "self", ".", "print_state_info_in_gui", "(", "reward", "=", "reward", ",", "info", "=", "info", ")", "\n", "\n", "", "return", "observation", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection": [[335, 463], ["numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.insert", "numpy.concatenate", "possib_col_idx_east.any", "possib_col_idx_west.any", "possib_near_col_idx_east.any", "possib_near_col_idx_west.any", "numpy.concatenate", "numpy.isclose", "numpy.isclose", "numpy.abs", "numpy.argwhere", "numpy.abs", "numpy.argwhere", "len", "col_idx_east.any", "col_idx_west.any", "numpy.concatenate", "len", "numpy.concatenate", "len", "numpy.abs", "numpy.argwhere", "numpy.abs", "numpy.argwhere", "len", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.argwhere", "numpy.abs", "numpy.argwhere", "numpy.abs", "numpy.argwhere", "numpy.abs", "numpy.abs", "numpy.argwhere", "numpy.abs", "numpy.abs", "numpy.abs", "str", "str", "str", "str", "str", "str", "str", "str", "numpy.squeeze", "str", "str", "str", "str", "numpy.squeeze", "east_heading.astype", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "numpy.argwhere", "numpy.argwhere"], "methods", ["None"], ["", "def", "collision_detection", "(", "self", ")", ":", "\n", "        ", "\"\"\" Only works for this specific case with crossing traffic, simplified for speed of execution.\n        Ignores vehicles turning to the south. \"\"\"", "\n", "\n", "# Remove simple non-collision cases", "\n", "if", "self", ".", "intersection_pos", "[", "1", "]", "-", "(", "self", ".", "positions", "[", "0", ",", "1", "]", "+", "self", ".", "ego_length", "/", "2", ")", ">", "self", ".", "lane_width", "+", "self", ".", "near_collision_margin", "[", "1", "]", ":", "\n", "            ", "return", "False", ",", "False", ",", "'Ego before_intersection'", "\n", "\n", "# Classification of vehicles", "\n", "", "atol", "=", "3e-2", "\n", "east_heading", "=", "np", ".", "isclose", "(", "self", ".", "headings", ",", "0", ",", "atol", "=", "atol", ",", "rtol", "=", "0", ")", "|", "np", ".", "isclose", "(", "self", ".", "headings", ",", "2", "*", "np", ".", "pi", ",", "atol", "=", "atol", ",", "rtol", "=", "0", ")", "\n", "west_heading", "=", "np", ".", "isclose", "(", "self", ".", "headings", ",", "np", ".", "pi", ",", "atol", "=", "atol", ",", "rtol", "=", "0", ")", "\n", "north_turning", "=", "(", "np", ".", "pi", "/", "2", "+", "atol", "<=", "self", ".", "headings", ")", "&", "(", "self", ".", "headings", "<=", "np", ".", "pi", "-", "atol", ")", "\n", "south_turning", "=", "(", "3", "*", "np", ".", "pi", "/", "2", "+", "atol", "<=", "self", ".", "headings", ")", "&", "(", "self", ".", "headings", "<=", "2", "*", "np", ".", "pi", "-", "atol", ")", "\n", "north_heading", "=", "np", ".", "isclose", "(", "self", ".", "headings", ",", "np", ".", "pi", "/", "2", ",", "atol", "=", "atol", ",", "rtol", "=", "0", ")", "\n", "south_heading", "=", "np", ".", "isclose", "(", "self", ".", "headings", ",", "3", "*", "np", ".", "pi", "/", "2", ",", "atol", "=", "atol", ",", "rtol", "=", "0", ")", "\n", "assert", "(", "east_heading", ".", "astype", "(", "int", ")", "+", "west_heading", "+", "north_heading", "+", "south_heading", "+", "north_turning", "+", "\n", "south_turning", "==", "1", ")", ".", "all", "(", ")", "\n", "\n", "dx", "=", "self", ".", "positions", "[", "1", ":", ",", "0", "]", "-", "self", ".", "positions", "[", "0", ",", "0", "]", "\n", "dx", "=", "np", ".", "insert", "(", "dx", ",", "0", ",", "np", ".", "inf", ")", "\n", "\n", "# Collision", "\n", "# Crossing vehicles and turning to the north", "\n", "possib_col_idx", "=", "(", "np", ".", "abs", "(", "dx", ")", "<", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", ")", "&", "(", "east_heading", "|", "west_heading", "|", "north_turning", ")", "\n", "col_idx", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_col_idx", ",", "1", "]", "-", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_width", "/", "2", "\n", "id_cross", "=", "np", ".", "argwhere", "(", "possib_col_idx", ")", "[", "col_idx", "]", "\n", "# North bound vehicles", "\n", "possib_col_idx", "=", "(", "np", ".", "abs", "(", "dx", ")", "<", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", ")", "&", "north_heading", "\n", "col_idx", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_col_idx", ",", "1", "]", "-", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_length", "/", "2", "\n", "id_north", "=", "np", ".", "argwhere", "(", "possib_col_idx", ")", "[", "col_idx", "]", "\n", "ids", "=", "np", ".", "concatenate", "(", "(", "id_cross", ",", "id_north", ")", ")", "\n", "if", "len", "(", "ids", ")", ">", "0", ":", "\n", "            ", "return", "True", ",", "False", ",", "[", "'collision'", ",", "'id: '", "+", "str", "(", "np", ".", "squeeze", "(", "ids", ")", ")", "+", "' pos: '", "+", "str", "(", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "]", "\n", "\n", "# Collision between time steps", "\n", "", "possib_col_idx_east", "=", "(", "dx", "<", "self", ".", "speeds", "[", ":", ",", "0", "]", ")", "&", "(", "dx", ">", "0", ")", "&", "east_heading", "\n", "if", "possib_col_idx_east", ".", "any", "(", ")", ":", "\n", "            ", "time_possib_collision_east", "=", "(", "self", ".", "positions", "[", "possib_col_idx_east", ",", "0", "]", "-", "self", ".", "positions", "[", "0", ",", "0", "]", ")", "/", "self", ".", "speeds", "[", "possib_col_idx_east", ",", "0", "]", "\n", "ego_y_pos_at_possib_time_col_east", "=", "self", ".", "positions", "[", "0", ",", "1", "]", "-", "self", ".", "speeds", "[", "0", ",", "0", "]", "*", "time_possib_collision_east", "\n", "col_idx_east", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_col_idx_east", ",", "1", "]", "-", "ego_y_pos_at_possib_time_col_east", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_width", "/", "2", "\n", "if", "col_idx_east", ".", "any", "(", ")", ":", "\n", "                ", "return", "True", ",", "False", ",", "[", "'collision'", ",", "\n", "'id: '", "+", "str", "(", "np", ".", "squeeze", "(", "np", ".", "argwhere", "(", "possib_col_idx_east", ")", "[", "col_idx_east", "]", ")", ")", "+", "\n", "' pos: '", "+", "str", "(", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "]", "\n", "", "", "possib_col_idx_west", "=", "(", "np", ".", "abs", "(", "dx", ")", "<", "self", ".", "speeds", "[", ":", ",", "0", "]", ")", "&", "(", "dx", "<", "0", ")", "&", "west_heading", "\n", "if", "possib_col_idx_west", ".", "any", "(", ")", ":", "\n", "            ", "time_possib_collision_west", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_col_idx_west", ",", "0", "]", "-", "self", ".", "positions", "[", "0", ",", "0", "]", ")", "/", "self", ".", "speeds", "[", "possib_col_idx_west", ",", "0", "]", "\n", "ego_y_pos_at_possib_time_col_west", "=", "self", ".", "positions", "[", "0", ",", "1", "]", "-", "self", ".", "speeds", "[", "0", ",", "0", "]", "*", "time_possib_collision_west", "\n", "col_idx_west", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_col_idx_west", ",", "1", "]", "-", "ego_y_pos_at_possib_time_col_west", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_width", "/", "2", "\n", "if", "col_idx_west", ".", "any", "(", ")", ":", "\n", "                ", "return", "True", ",", "False", ",", "[", "'collision'", ",", "\n", "'id: '", "+", "str", "(", "np", ".", "squeeze", "(", "np", ".", "argwhere", "(", "possib_col_idx_west", ")", "[", "col_idx_west", "]", ")", ")", "+", "\n", "' pos: '", "+", "str", "(", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "]", "\n", "", "", "possib_near_col_idx_east", "=", "(", "dx", "<", "self", ".", "speeds", "[", ":", ",", "0", "]", "-", "(", "self", ".", "near_collision_margin", "[", "0", "]", "+", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", ")", ")", "&", "(", "dx", ">", "-", "(", "self", ".", "near_collision_margin", "[", "0", "]", "+", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", ")", ")", "&", "east_heading", "\n", "if", "possib_near_col_idx_east", ".", "any", "(", ")", ":", "\n", "# x margin", "\n", "            ", "time_possib_near_collision_east", "=", "(", "dx", "[", "possib_near_col_idx_east", "]", "+", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", "+", "\n", "self", ".", "near_collision_margin", "[", "0", "]", ")", "/", "self", ".", "speeds", "[", "possib_near_col_idx_east", ",", "0", "]", "\n", "ego_y_pos_at_possib_time_col_east", "=", "self", ".", "positions", "[", "0", ",", "1", "]", "-", "self", ".", "speeds", "[", "0", ",", "0", "]", "*", "time_possib_near_collision_east", "\n", "near_col_idx_east_x", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_near_col_idx_east", ",", "1", "]", "-", "ego_y_pos_at_possib_time_col_east", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_width", "/", "2", "+", "self", ".", "near_collision_margin", "[", "1", "]", "\n", "id_x", "=", "np", ".", "argwhere", "(", "possib_near_col_idx_east", ")", "[", "near_col_idx_east_x", "]", "\n", "# y margin", "\n", "time_possib_near_collision_east", "=", "dx", "[", "possib_near_col_idx_east", "]", "/", "self", ".", "speeds", "[", "possib_near_col_idx_east", ",", "0", "]", "\n", "ego_y_pos_at_possib_time_col_east", "=", "self", ".", "positions", "[", "0", ",", "1", "]", "-", "self", ".", "speeds", "[", "0", ",", "0", "]", "*", "time_possib_near_collision_east", "\n", "near_col_idx_east_y", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_near_col_idx_east", ",", "1", "]", "-", "ego_y_pos_at_possib_time_col_east", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_width", "/", "2", "+", "self", ".", "near_collision_margin", "[", "1", "]", "\n", "id_y", "=", "np", ".", "argwhere", "(", "possib_near_col_idx_east", ")", "[", "near_col_idx_east_y", "]", "\n", "ids", "=", "np", ".", "concatenate", "(", "(", "id_x", ",", "id_y", ")", ")", "\n", "if", "len", "(", "ids", ")", ":", "\n", "                ", "return", "False", ",", "True", ",", "[", "'near_collision'", ",", "'id: '", "+", "str", "(", "np", ".", "squeeze", "(", "ids", ")", ")", "\n", "+", "' pos: '", "+", "str", "(", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "]", "\n", "", "", "possib_near_col_idx_west", "=", "(", "dx", "<", "self", ".", "near_collision_margin", "[", "0", "]", "+", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", ")", "&", "(", "dx", ">", "-", "self", ".", "speeds", "[", ":", ",", "0", "]", "+", "self", ".", "near_collision_margin", "[", "0", "]", "+", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", ")", "&", "west_heading", "\n", "if", "possib_near_col_idx_west", ".", "any", "(", ")", ":", "\n", "# x margin", "\n", "            ", "time_possib_near_collision_west", "=", "(", "-", "dx", "[", "possib_near_col_idx_west", "]", "+", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", "+", "\n", "self", ".", "near_collision_margin", "[", "0", "]", ")", "/", "self", ".", "speeds", "[", "possib_near_col_idx_west", ",", "0", "]", "\n", "ego_y_pos_at_possib_time_col_west", "=", "self", ".", "positions", "[", "0", ",", "1", "]", "-", "self", ".", "speeds", "[", "0", ",", "0", "]", "*", "time_possib_near_collision_west", "\n", "near_col_idx_west_x", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_near_col_idx_west", ",", "1", "]", "-", "ego_y_pos_at_possib_time_col_west", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_width", "/", "2", "+", "self", ".", "near_collision_margin", "[", "1", "]", "\n", "id_x", "=", "np", ".", "argwhere", "(", "possib_near_col_idx_west", ")", "[", "near_col_idx_west_x", "]", "\n", "# y margin", "\n", "time_possib_near_collision_west", "=", "np", ".", "abs", "(", "dx", "[", "possib_near_col_idx_west", "]", ")", "/", "self", ".", "speeds", "[", "possib_near_col_idx_west", ",", "0", "]", "\n", "ego_y_pos_at_possib_time_col_west", "=", "self", ".", "positions", "[", "0", ",", "1", "]", "-", "self", ".", "speeds", "[", "0", ",", "0", "]", "*", "time_possib_near_collision_west", "\n", "near_col_idx_west_y", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_near_col_idx_west", ",", "1", "]", "-", "ego_y_pos_at_possib_time_col_west", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_width", "/", "2", "+", "self", ".", "near_collision_margin", "[", "1", "]", "\n", "id_y", "=", "np", ".", "argwhere", "(", "possib_near_col_idx_west", ")", "[", "near_col_idx_west_y", "]", "\n", "ids", "=", "np", ".", "concatenate", "(", "(", "id_x", ",", "id_y", ")", ")", "\n", "if", "len", "(", "ids", ")", ":", "\n", "                ", "return", "False", ",", "True", ",", "[", "'near_collision'", ",", "'id: '", "+", "str", "(", "np", ".", "squeeze", "(", "ids", ")", ")", "+", "\n", "' pos: '", "+", "str", "(", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "]", "\n", "\n", "# Near collision", "\n", "# Crossing vehicles and turning to the north", "\n", "", "", "possib_near_col_idx", "=", "(", "np", ".", "abs", "(", "dx", ")", "<", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", "+", "self", ".", "near_collision_margin", "[", "0", "]", ")", "&", "(", "east_heading", "|", "west_heading", "|", "north_turning", ")", "\n", "near_col_idx", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_near_col_idx", ",", "1", "]", "-", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_width", "/", "2", "+", "self", ".", "near_collision_margin", "[", "1", "]", "\n", "id_cross", "=", "np", ".", "argwhere", "(", "possib_near_col_idx", ")", "[", "near_col_idx", "]", "\n", "# North bound vehicles", "\n", "possib_near_col_idx", "=", "(", "np", ".", "abs", "(", "dx", ")", "<", "self", ".", "ego_width", "/", "2", "+", "self", ".", "car_length", "/", "2", "+", "self", ".", "near_collision_margin", "[", "0", "]", ")", "&", "north_heading", "\n", "near_col_idx", "=", "np", ".", "abs", "(", "self", ".", "positions", "[", "possib_near_col_idx", ",", "1", "]", "-", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "<", "self", ".", "ego_length", "/", "2", "+", "self", ".", "car_length", "/", "2", "+", "self", ".", "near_collision_margin", "[", "1", "]", "\n", "id_north", "=", "np", ".", "argwhere", "(", "possib_near_col_idx", ")", "[", "near_col_idx", "]", "\n", "ids", "=", "np", ".", "concatenate", "(", "(", "id_cross", ",", "id_north", ")", ")", "\n", "if", "len", "(", "ids", ")", ">", "0", ":", "\n", "            ", "return", "False", ",", "True", ",", "[", "'near_collision'", ",", "'id: '", "+", "str", "(", "np", ".", "squeeze", "(", "ids", ")", ")", "+", "' pos: '", "+", "str", "(", "self", ".", "positions", "[", "0", ",", "1", "]", ")", "]", "\n", "\n", "", "return", "False", ",", "False", ",", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.action_model": [[464, 508], ["int", "sum", "intersection_env.IntersectionEnv.idm_acc", "intersection_env.IntersectionEnv.idm_acc", "numpy.abs", "range", "intersection_env.IntersectionEnv.idm_acc", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.idm_acc", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.idm_acc", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.idm_acc"], ["", "def", "action_model", "(", "self", ",", "action", ",", "action_info", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Translate action into setpoint of IDM model.\n\n        Args:\n            action (int): Action index, which is translated to an acceleration through\n                          the Intelligent Driver Model (IDM).\n                          0 - cruise, 1 - go, 2 - stop, 3 - safety action.\n            action_info (dict): Information about currently selected action.\n\n        Returns:\n            acc (float): Acceleration of the ego vehicle\n        \"\"\"", "\n", "a_min", "=", "self", ".", "idm_params", "[", "'a_min'", "]", "\n", "# If selected action is above normal range of actions, a \"safety action\" is selected.", "\n", "if", "action", "==", "self", ".", "nb_actions", ":", "# Safety policy", "\n", "            ", "dt", "=", "1", "\n", "ego_stopping_steps", "=", "int", "(", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "//", "np", ".", "abs", "(", "a_min", ")", ")", "\n", "ego_stopping_dist", "=", "sum", "(", "(", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "-", "(", "k", "+", "1", ")", "*", "np", ".", "abs", "(", "a_min", ")", ")", "*", "dt", "\n", "for", "k", "in", "range", "(", "ego_stopping_steps", ")", ")", "\n", "# if ego vehicle can stop before the intersection", "\n", "if", "self", ".", "positions", "[", "0", "]", "[", "1", "]", "<", "self", ".", "intersection_pos", "[", "1", "]", "-", "self", ".", "stop_line", "-", "self", ".", "ego_length", "/", "2", "-", "ego_stopping_dist", ":", "\n", "                ", "acc", "=", "self", ".", "idm_acc", "(", "self", ".", "intersection_pos", "[", "1", "]", "-", "self", ".", "stop_line", ",", "0", ",", "self", ".", "idm_params", ")", "\n", "# else follow decision by agent", "\n", "", "else", ":", "\n", "                ", "action", "=", "action_info", "[", "'original_action'", "]", "\n", "", "", "if", "action", "==", "0", ":", "# Maintain speed", "\n", "            ", "acc", "=", "0", "\n", "", "elif", "action", "==", "1", ":", "# Continue through intersection", "\n", "            ", "acc", "=", "self", ".", "idm_acc", "(", "None", ",", "None", ",", "self", ".", "idm_params", ")", "\n", "", "elif", "action", "==", "2", ":", "# Stop at intersection", "\n", "# If vehicle has already entered the intersection", "\n", "            ", "if", "self", ".", "positions", "[", "0", "]", "[", "1", "]", "+", "self", ".", "ego_length", "/", "2", ">", "self", ".", "intersection_pos", "[", "1", "]", "-", "self", ".", "stop_line", ":", "\n", "                ", "acc", "=", "a_min", "\n", "", "else", ":", "\n", "                ", "acc", "=", "self", ".", "idm_acc", "(", "self", ".", "intersection_pos", "[", "1", "]", "-", "self", ".", "stop_line", ",", "0", ",", "self", ".", "idm_params", ")", "\n", "\n", "# Limit speed to physical limits", "\n", "", "", "if", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "+", "acc", ">", "self", ".", "max_ego_speed", ":", "\n", "            ", "acc", "=", "self", ".", "max_ego_speed", "-", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "", "elif", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "+", "acc", "<", "0", ":", "\n", "            ", "acc", "=", "0", "-", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.idm_acc": [[509, 539], ["numpy.clip", "numpy.max", "numpy.sqrt"], "methods", ["None"], ["", "def", "idm_acc", "(", "self", ",", "pos_target", ",", "v_target", ",", "idm_params", ")", ":", "\n", "        ", "\"\"\"\n        IDM model, see e.g. https://en.wikipedia.org/wiki/Intelligent_driver_model\n\n        Used to let the ego vehicle either stop at the intersection or accelerate up to its desired speed.\n\n        Args:\n            pos_target (float): Distance to preceding vehicle\n            v_target (float): Speed of preceding vehicle\n            idm_params (dict): Parameters of the IDM model\n\n        Returns:\n            acc (float): Acceleration of the ego vehicle\n        \"\"\"", "\n", "a", "=", "idm_params", "[", "'a'", "]", "\n", "b", "=", "idm_params", "[", "'b'", "]", "\n", "s0", "=", "idm_params", "[", "'s0'", "]", "\n", "T", "=", "idm_params", "[", "'T'", "]", "\n", "a_min", "=", "idm_params", "[", "'a_min'", "]", "\n", "a_max", "=", "idm_params", "[", "'a_max'", "]", "\n", "if", "pos_target", "is", "None", ":", "\n", "            ", "out", "=", "a", "*", "(", "1", "-", "(", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "/", "self", ".", "max_ego_speed", ")", "**", "4", ")", "\n", "", "else", ":", "\n", "            ", "approach_rate", "=", "np", ".", "max", "(", "[", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "-", "v_target", ",", "0", "]", ")", "# Only allow positive approach rates", "\n", "out", "=", "a", "*", "(", "1", "-", "(", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "/", "self", ".", "max_ego_speed", ")", "**", "4", "-", "\n", "(", "(", "s0", "+", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "*", "T", "+", "\n", "self", ".", "speeds", "[", "0", "]", "[", "0", "]", "*", "approach_rate", "/", "(", "2", "*", "np", ".", "sqrt", "(", "a", "*", "b", ")", ")", ")", "/", "\n", "(", "pos_target", "-", "(", "self", ".", "positions", "[", "0", "]", "[", "1", "]", "+", "self", ".", "ego_length", "/", "2", ")", ")", ")", "**", "2", ")", "\n", "", "out", "=", "np", ".", "clip", "(", "out", ",", "a_min", ",", "a_max", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reward_model": [[540, 563], ["None"], "methods", ["None"], ["", "def", "reward_model", "(", "self", ",", "goal_reached", "=", "False", ",", "collision", "=", "False", ",", "near_collision", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Reward model of the intersection environment.\n\n        Args:\n            goal_reached (bool): True if the ego vehicle reached the goal to the north of the intersection.\n            collision (bool): True if a collision occurred.\n            near_collision(bool): True if a near collision occurred.\n\n        Returns:\n            reward (float): Reward for the current environment step.\n            info (dict): Information about what caused the reward.\n        \"\"\"", "\n", "info", "=", "{", "}", "\n", "reward", "=", "0", "\n", "if", "goal_reached", ":", "\n", "            ", "reward", "=", "self", ".", "goal_reward", "\n", "", "elif", "collision", ":", "\n", "            ", "reward", "=", "self", ".", "collision_penalty", "\n", "", "elif", "near_collision", ":", "\n", "            ", "reward", "=", "self", ".", "near_collision_penalty", "\n", "info", "[", "'near_collision'", "]", "=", "True", "\n", "", "return", "reward", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.sensor_model": [[564, 617], ["numpy.array().all", "intersection_env.IntersectionEnv.occlusion_model", "numpy.zeros", "enumerate", "range", "numpy.sum", "warnings.warn", "numpy.random.get_state", "numpy.random.set_state", "numpy.array", "numpy.logical_not", "numpy.random.normal", "numpy.linalg.norm", "numpy.array().all", "numpy.random.normal", "numpy.random.normal", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model"], ["", "def", "sensor_model", "(", "self", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Sensor model of the ego vehicle.\n\n        Creates an observation vector from the current state of the environment. All observations are normalized.\n        Only surrounding vehicles that are not occluded and that are within the sensor range\n        are included in the observation.\n\n        Args:\n            state (list): Current state of the environment.\n\n        Returns:\n            observation( (ndarray): Current observation of the environment.\n        \"\"\"", "\n", "# Vehicle in range and not in [0,0]", "\n", "vehicles_in_range", "=", "np", ".", "array", "(", "[", "np", ".", "linalg", ".", "norm", "(", "state", "[", "0", "]", "[", "1", ":", "]", "-", "state", "[", "0", "]", "[", "0", "]", ",", "axis", "=", "1", ")", "<=", "self", ".", "sensor_range", ",", "\n", "np", ".", "logical_not", "(", "np", ".", "array", "(", "[", "state", "[", "0", "]", "[", "1", ":", ",", "0", "]", "==", "0", ",", "state", "[", "0", "]", "[", "1", ":", ",", "1", "]", "==", "0", "]", ")", ".", "all", "(", "0", ")", ")", "]", ")", ".", "all", "(", "0", ")", "\n", "non_occluded_vehicles", "=", "self", ".", "occlusion_model", "(", "self", ".", "positions", "[", "0", ",", "1", "]", "+", "self", ".", "ego_length", "/", "2", "-", "self", ".", "intersection_pos", "[", "1", "]", ")", "\n", "observed_vehicles", "=", "vehicles_in_range", "&", "non_occluded_vehicles", "\n", "if", "np", ".", "sum", "(", "observed_vehicles", ")", ">", "self", ".", "sensor_nb_vehicles", ":", "\n", "            ", "warnings", ".", "warn", "(", "'More vehicles within range than sensor can represent'", ")", "\n", "\n", "", "observation", "=", "np", ".", "zeros", "(", "self", ".", "nb_ego_states", "+", "self", ".", "nb_states_per_vehicle", "*", "self", ".", "sensor_nb_vehicles", ")", "\n", "observation", "[", "0", "]", "=", "2", "*", "(", "state", "[", "0", "]", "[", "0", ",", "1", "]", "-", "(", "self", ".", "intersection_pos", "[", "1", "]", "+", "self", ".", "end_pos", ")", ")", "/", "(", "self", ".", "end_pos", "-", "self", ".", "start_pos", ")", "+", "1", "# Ego pos", "\n", "observation", "[", "1", "]", "=", "2", "*", "state", "[", "1", "]", "[", "0", ",", "0", "]", "/", "self", ".", "max_ego_speed", "-", "1", "# Long speed", "\n", "observation", "[", "2", "]", "=", "1", "if", "state", "[", "3", "]", "else", "-", "1", "# Terminal state", "\n", "assert", "(", "self", ".", "nb_ego_states", "==", "3", ")", "\n", "idx", "=", "0", "\n", "for", "i", ",", "in_range", "in", "enumerate", "(", "observed_vehicles", ")", ":", "\n", "            ", "if", "not", "in_range", ":", "\n", "                ", "continue", "\n", "", "internal_random_state", "=", "np", ".", "random", ".", "get_state", "(", ")", "# Quick fix for repeatability of episodes, improve later", "\n", "observation", "[", "3", "+", "idx", "*", "4", ":", "5", "+", "idx", "*", "4", "]", "=", "(", "state", "[", "0", "]", "[", "i", "+", "1", "]", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "sensor_noise", "[", "'pos'", "]", ",", "2", ")", "\n", "-", "self", ".", "intersection_pos", ")", "/", "self", ".", "sensor_range", "# Pos", "\n", "observation", "[", "5", "+", "idx", "*", "4", "]", "=", "2", "*", "(", "state", "[", "1", "]", "[", "i", "+", "1", ",", "0", "]", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "sensor_noise", "[", "'speed'", "]", ")", ")", "/", "self", ".", "sensor_max_speed_scale", "-", "1", "# Speed", "\n", "observation", "[", "6", "+", "idx", "*", "4", "]", "=", "2", "*", "(", "state", "[", "2", "]", "[", "i", "+", "1", "]", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "sensor_noise", "[", "'heading'", "]", ")", ")", "/", "(", "2", "*", "np", ".", "pi", ")", "-", "1", "# Heading", "\n", "np", ".", "random", ".", "set_state", "(", "internal_random_state", ")", "# Second part of quick fix", "\n", "idx", "+=", "1", "\n", "if", "idx", ">=", "self", ".", "sensor_nb_vehicles", ":", "\n", "                ", "break", "\n", "# Default values for empty slots", "\n", "", "", "for", "i", "in", "range", "(", "idx", ",", "self", ".", "sensor_nb_vehicles", ")", ":", "\n", "            ", "observation", "[", "3", "+", "idx", "*", "4", "]", "=", "-", "1", "\n", "observation", "[", "4", "+", "idx", "*", "4", "]", "=", "-", "1", "\n", "observation", "[", "5", "+", "idx", "*", "4", "]", "=", "-", "1", "\n", "observation", "[", "6", "+", "idx", "*", "4", "]", "=", "-", "1", "\n", "idx", "+=", "1", "\n", "", "assert", "(", "self", ".", "nb_states_per_vehicle", "==", "4", ")", "\n", "\n", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model": [[618, 630], ["numpy.ones", "numpy.abs", "numpy.abs", "numpy.cos"], "methods", ["None"], ["", "def", "occlusion_model", "(", "self", ",", "d", ")", ":", "\n", "        ", "\"\"\"\n        Creates mask of observed and occluded vehicles.\n        \"\"\"", "\n", "if", "d", ">", "-", "(", "self", ".", "lane_width", "+", "self", ".", "occlusion_dist", ")", ":", "# Full visibility", "\n", "            ", "return", "np", ".", "ones", "(", "self", ".", "max_nb_vehicles", "-", "1", ",", "dtype", "=", "bool", ")", "\n", "", "else", ":", "\n", "            ", "d", "=", "np", ".", "abs", "(", "d", ")", "\n", "return", "np", ".", "abs", "(", "self", ".", "positions", "[", "1", ":", ",", "0", "]", "+", "self", ".", "car_length", "/", "2", "*", "np", ".", "cos", "(", "self", ".", "headings", "[", "1", ":", "]", ")", "-", "\n", "self", ".", "intersection_pos", "[", "0", "]", ")", "<", "self", ".", "lane_width", "/", "2", "+", "(", "d", "+", "self", ".", "lane_width", "/", "2", ")", "*", "(", "self", ".", "lane_width", "/", "2", "+", "self", ".", "occlusion_dist", ")", "/", "(", "d", "-", "(", "self", ".", "lane_width", "+", "self", ".", "occlusion_dist", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.print_state_info_in_gui": [[631, 646], ["enumerate", "traci.polygon.remove", "str", "traci.polygon.add", "str", "str"], "methods", ["None"], ["", "", "def", "print_state_info_in_gui", "(", "self", ",", "reward", "=", "None", ",", "info", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Prints information in the GUI.\n        \"\"\"", "\n", "for", "item", "in", "self", ".", "gui_state_info", ":", "\n", "            ", "traci", ".", "polygon", ".", "remove", "(", "item", ")", "\n", "", "dy", "=", "15", "\n", "self", ".", "gui_state_info", "=", "[", "'Position: {0:.1f}'", ".", "format", "(", "self", ".", "positions", "[", "0", ",", "1", "]", "-", "self", ".", "intersection_pos", "[", "1", "]", ")", ",", "\n", "'Speed: {0:.1f}'", ".", "format", "(", "self", ".", "speeds", "[", "0", ",", "0", "]", ")", ",", "\n", "'Reward: '", "+", "str", "(", "reward", ")", ",", "\n", "str", "(", "info", ")", ",", "\n", "'Step: '", "+", "str", "(", "self", ".", "step_", ")", "]", "\n", "for", "idx", ",", "text", "in", "enumerate", "(", "self", ".", "gui_state_info", ")", ":", "\n", "            ", "traci", ".", "polygon", ".", "add", "(", "text", ",", "[", "self", ".", "road", ".", "road_params", "[", "'info_pos'", "]", ",", "\n", "self", ".", "road", ".", "road_params", "[", "'info_pos'", "]", "+", "[", "1", ",", "-", "idx", "*", "dy", "]", "]", ",", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.draw_occlusion": [[647, 661], ["traci.polygon.add", "traci.polygon.add", "traci.polygon.remove", "rect", "rect", "numpy.array", "numpy.array"], "methods", ["None"], ["", "", "def", "draw_occlusion", "(", "self", ",", "width", "=", "200", ",", "height", "=", "200", ")", ":", "\n", "        ", "\"\"\"\n        Draws the occluding objects in the GUI.\n        \"\"\"", "\n", "for", "item", "in", "self", ".", "gui_occlusions", ":", "\n", "            ", "traci", ".", "polygon", ".", "remove", "(", "item", ")", "\n", "", "self", ".", "gui_occlusions", "=", "[", "' '", ",", "'  '", "]", "\n", "rect", "=", "lambda", "x", ",", "y", ":", "[", "(", "x", ",", "y", ")", ",", "(", "x", "+", "width", ",", "y", ")", ",", "(", "x", "+", "width", ",", "y", "+", "height", ")", ",", "(", "x", ",", "y", "+", "height", ")", "]", "\n", "left_occlusion_pos", "=", "np", ".", "array", "(", "self", ".", "intersection_pos", ")", "-", "[", "self", ".", "lane_width", ",", "self", ".", "lane_width", "]", "-", "[", "self", ".", "occlusion_dist", ",", "self", ".", "occlusion_dist", "]", "-", "[", "width", ",", "height", "]", "\n", "right_occlusion_pos", "=", "np", ".", "array", "(", "self", ".", "intersection_pos", ")", "-", "[", "-", "self", ".", "lane_width", ",", "self", ".", "lane_width", "]", "-", "[", "-", "self", ".", "occlusion_dist", ",", "self", ".", "occlusion_dist", "]", "-", "[", "0", ",", "height", "]", "\n", "traci", ".", "polygon", ".", "add", "(", "self", ".", "gui_occlusions", "[", "0", "]", ",", "rect", "(", "*", "left_occlusion_pos", ")", ",", "(", "150", ",", "150", ",", "150", ",", "255", ")", ",", "fill", "=", "True", ")", "\n", "traci", ".", "polygon", ".", "add", "(", "self", ".", "gui_occlusions", "[", "1", "]", ",", "rect", "(", "*", "right_occlusion_pos", ")", ",", "(", "150", ",", "150", ",", "150", ",", "255", ")", ",", "fill", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.print_action_info_in_gui": [[662, 713], ["traci.polygon.add", "traci.polygon.remove", "intersection_env.IntersectionEnv.gui_action_info.append", "traci.polygon.add", "intersection_env.IntersectionEnv.gui_action_info.append", "traci.polygon.add", "intersection_env.IntersectionEnv.gui_action_info.append", "traci.polygon.add", "intersection_env.IntersectionEnv.gui_action_info.append", "traci.polygon.add"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "print_action_info_in_gui", "(", "self", ",", "action", "=", "None", ",", "action_info", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Prints information in the GUI.\n        \"\"\"", "\n", "if", "action", "==", "0", ":", "\n", "            ", "action_str", "=", "'cruise'", "\n", "", "elif", "action", "==", "1", ":", "\n", "            ", "action_str", "=", "'go'", "\n", "", "elif", "action", "==", "2", ":", "\n", "            ", "action_str", "=", "'stop'", "\n", "", "else", ":", "\n", "            ", "action_str", "=", "'backup'", "\n", "", "for", "item", "in", "self", ".", "gui_action_info", ":", "\n", "            ", "traci", ".", "polygon", ".", "remove", "(", "item", ")", "\n", "", "dy", "=", "15", "\n", "self", ".", "gui_action_info", "=", "[", "'Action: '", "+", "action_str", "]", "\n", "traci", ".", "polygon", ".", "add", "(", "self", ".", "gui_action_info", "[", "0", "]", ",", "\n", "[", "self", ".", "road", ".", "road_params", "[", "'info_pos'", "]", ",", "self", ".", "road", ".", "road_params", "[", "'info_pos'", "]", "+", "[", "1", ",", "dy", "]", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "if", "action_info", "is", "not", "None", ":", "\n", "# Uncomment below to print Q-values of all networks in GUI", "\n", "# if 'q_values_all_nets' in action_info:", "\n", "#     for i, row in enumerate(action_info['q_values_all_nets']):", "\n", "#         self.gui_action_info.append('                                   ' +", "\n", "#                                     '  | '.join(['{:6.3f}'.format(element) for element in row]))", "\n", "#         traci.polygon.add(self.gui_action_info[-1], [self.road.road_params['action_info_pos'],", "\n", "#                           self.road.road_params['action_info_pos'] + [1, -(i+4)*dy]], [0, 0, 0, 0])", "\n", "            ", "if", "'q_values'", "in", "action_info", ":", "\n", "                ", "self", ".", "gui_action_info", ".", "append", "(", "'                                  cruise  |    go      |   stop  '", ")", "\n", "traci", ".", "polygon", ".", "add", "(", "self", ".", "gui_action_info", "[", "-", "1", "]", ",", "[", "self", ".", "road", ".", "road_params", "[", "'action_info_pos'", "]", ",", "\n", "self", ".", "road", ".", "road_params", "[", "'action_info_pos'", "]", "+", "[", "1", ",", "1", "*", "dy", "]", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "self", ".", "gui_action_info", ".", "append", "(", "'Q-values:                 '", "+", "\n", "'  | '", ".", "join", "(", "[", "'{:6.3f}'", ".", "format", "(", "element", ")", "for", "element", "\n", "in", "action_info", "[", "'q_values'", "]", "]", ")", ")", "\n", "traci", ".", "polygon", ".", "add", "(", "self", ".", "gui_action_info", "[", "-", "1", "]", ",", "[", "self", ".", "road", ".", "road_params", "[", "'action_info_pos'", "]", ",", "\n", "self", ".", "road", ".", "road_params", "[", "'action_info_pos'", "]", "+", "[", "1", ",", "0", "]", "]", ",", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "", "if", "'aleatoric_std_dev'", "in", "action_info", ":", "\n", "                ", "self", ".", "gui_action_info", ".", "append", "(", "'Aleatoric std dev:   '", "+", "\n", "'  | '", ".", "join", "(", "[", "'{:6.3f}'", ".", "format", "(", "element", ")", "for", "element", "in", "\n", "action_info", "[", "'aleatoric_std_dev'", "]", "]", ")", ")", "\n", "traci", ".", "polygon", ".", "add", "(", "self", ".", "gui_action_info", "[", "-", "1", "]", ",", "[", "self", ".", "road", ".", "road_params", "[", "'action_info_pos'", "]", ",", "\n", "self", ".", "road", ".", "road_params", "[", "'action_info_pos'", "]", "+", "[", "1", ",", "-", "1", "*", "dy", "]", "]", ",", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "", "if", "'epistemic_std_dev'", "in", "action_info", ":", "\n", "                ", "self", ".", "gui_action_info", ".", "append", "(", "'Epistemic std dev:  '", "+", "\n", "'  | '", ".", "join", "(", "[", "'{:6.3f}'", ".", "format", "(", "element", ")", "for", "element", "in", "\n", "action_info", "[", "'epistemic_std_dev'", "]", "]", ")", ")", "\n", "traci", ".", "polygon", ".", "add", "(", "self", ".", "gui_action_info", "[", "-", "1", "]", ",", "[", "self", ".", "road", ".", "road_params", "[", "'action_info_pos'", "]", ",", "\n", "self", ".", "road", ".", "road_params", "[", "'action_info_pos'", "]", "+", "[", "1", ",", "-", "2", "*", "dy", "]", "]", ",", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.nb_actions": [[714, 717], ["None"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "nb_actions", "(", "self", ")", ":", "\n", "        ", "return", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.nb_observations": [[718, 721], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "nb_observations", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "nb_ego_states", "+", "self", ".", "nb_states_per_vehicle", "*", "self", ".", "sensor_nb_vehicles", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.__init__": [[31, 44], ["rl.memory.Memory.__init__", "rl.memory.RingBuffer", "rl.memory.RingBuffer", "rl.memory.RingBuffer", "rl.memory.RingBuffer", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["def", "__init__", "(", "self", ",", "nb_nets", ",", "limit", ",", "adding_prob", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BootstrappingMemory", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "nb_nets", "=", "nb_nets", "\n", "self", ".", "adding_prob", "=", "adding_prob", "\n", "self", ".", "limit", "=", "limit", "\n", "self", ".", "index_refs", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "nb_nets", ")", "]", "\n", "\n", "# Do not use deque to implement the memory. This data structure may seem convenient but", "\n", "# it is way too slow on random access. Instead, we use our own ring buffer implementation.", "\n", "self", ".", "actions", "=", "RingBuffer", "(", "limit", ")", "\n", "self", ".", "rewards", "=", "RingBuffer", "(", "limit", ")", "\n", "self", ".", "terminals", "=", "RingBuffer", "(", "limit", ")", "\n", "self", ".", "observations", "=", "RingBuffer", "(", "limit", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample": [[45, 113], ["memory.BootstrappingMemory.sample_batch_idxs", "numpy.min", "numpy.max", "len", "range", "state1.append", "experiences.append", "len", "state0.insert", "len", "state0.insert", "numpy.copy", "len", "len", "len", "Experience", "memory.BootstrappingMemory.sample_batch_idxs", "rl.memory.zeroed_observation"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample_batch_idxs", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample_batch_idxs"], ["", "def", "sample", "(", "self", ",", "net", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Returns a randomized batch of experiences for an ensemble member\n        Args:\n            net (int): Index of ensemble member\n            batch_size (int): Size of the batch\n\n        Returns:\n            A list of random experiences\n        \"\"\"", "\n", "# It is not possible to tell whether the first state in the memory is terminal, because it", "\n", "# would require access to the \"terminal\" flag associated to the previous state. As a result", "\n", "# we will never return this first state (only using `self.terminals[0]` to know whether the", "\n", "# second state is terminal).", "\n", "# In addition we need enough entries to fill the desired window length.", "\n", "assert", "self", ".", "nb_entries", ">=", "self", ".", "window_length", "+", "2", ",", "'not enough entries in the memory'", "\n", "\n", "# Sample random indexes for the specified ensemble member", "\n", "batch_idxs", "=", "self", ".", "sample_batch_idxs", "(", "net", ",", "batch_size", ")", "\n", "\n", "assert", "np", ".", "min", "(", "batch_idxs", ")", ">=", "self", ".", "window_length", "+", "1", "\n", "assert", "np", ".", "max", "(", "batch_idxs", ")", "<", "self", ".", "nb_entries", "\n", "assert", "len", "(", "batch_idxs", ")", "==", "batch_size", "\n", "\n", "# Create experiences", "\n", "experiences", "=", "[", "]", "\n", "for", "idx", "in", "batch_idxs", ":", "\n", "            ", "terminal0", "=", "self", ".", "terminals", "[", "idx", "-", "2", "]", "\n", "while", "terminal0", ":", "\n", "# Skip this transition because the environment was reset here. Select a new, random", "\n", "# transition and use this instead. This may cause the batch to contain the same", "\n", "# transition twice.", "\n", "# idx = sample_batch_indexes(self.window_length + 1, self.nb_entries, size=1)[0]", "\n", "                ", "idx", "=", "self", ".", "sample_batch_idxs", "(", "net", ",", "1", ")", "[", "0", "]", "\n", "terminal0", "=", "self", ".", "terminals", "[", "idx", "-", "2", "]", "\n", "", "assert", "self", ".", "window_length", "+", "1", "<=", "idx", "<", "self", ".", "nb_entries", "\n", "\n", "# This code is slightly complicated by the fact that subsequent observations might be", "\n", "# from different episodes. We ensure that an experience never spans multiple episodes.", "\n", "# This is probably not that important in practice but it seems cleaner.", "\n", "state0", "=", "[", "self", ".", "observations", "[", "idx", "-", "1", "]", "]", "\n", "for", "offset", "in", "range", "(", "0", ",", "self", ".", "window_length", "-", "1", ")", ":", "\n", "                ", "current_idx", "=", "idx", "-", "2", "-", "offset", "\n", "assert", "current_idx", ">=", "1", "\n", "current_terminal", "=", "self", ".", "terminals", "[", "current_idx", "-", "1", "]", "\n", "if", "current_terminal", "and", "not", "self", ".", "ignore_episode_boundaries", ":", "\n", "# The previously handled observation was terminal, don't add the current one.", "\n", "# Otherwise we would leak into a different episode.", "\n", "                    ", "break", "\n", "", "state0", ".", "insert", "(", "0", ",", "self", ".", "observations", "[", "current_idx", "]", ")", "\n", "", "while", "len", "(", "state0", ")", "<", "self", ".", "window_length", ":", "\n", "                ", "state0", ".", "insert", "(", "0", ",", "zeroed_observation", "(", "state0", "[", "0", "]", ")", ")", "\n", "", "action", "=", "self", ".", "actions", "[", "idx", "-", "1", "]", "\n", "reward", "=", "self", ".", "rewards", "[", "idx", "-", "1", "]", "\n", "terminal1", "=", "self", ".", "terminals", "[", "idx", "-", "1", "]", "\n", "\n", "# Okay, now we need to create the follow-up state. This is state0 shifted on timestep", "\n", "# to the right. Again, we need to be careful to not include an observation from the next", "\n", "# episode if the last state is terminal.", "\n", "state1", "=", "[", "np", ".", "copy", "(", "x", ")", "for", "x", "in", "state0", "[", "1", ":", "]", "]", "\n", "state1", ".", "append", "(", "self", ".", "observations", "[", "idx", "]", ")", "\n", "\n", "assert", "len", "(", "state0", ")", "==", "self", ".", "window_length", "\n", "assert", "len", "(", "state1", ")", "==", "len", "(", "state0", ")", "\n", "experiences", ".", "append", "(", "Experience", "(", "state0", "=", "state0", ",", "action", "=", "action", ",", "reward", "=", "reward", ",", "\n", "state1", "=", "state1", ",", "terminal1", "=", "terminal1", ")", ")", "\n", "", "assert", "len", "(", "experiences", ")", "==", "batch_size", "\n", "return", "experiences", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample_batch_idxs": [[114, 133], ["len", "numpy.random.randint", "warnings.warn", "len"], "methods", ["None"], ["", "def", "sample_batch_idxs", "(", "self", ",", "net", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Sample random replay memory indexes from the list of replay memory indexes of the specified ensemble member.\n\n        Args:\n            net (int): Index of ensemble member\n            batch_size (int): Size of the batch\n\n        Returns:\n            A list of replay memory indexes.\n        \"\"\"", "\n", "memory_size", "=", "len", "(", "self", ".", "index_refs", "[", "net", "]", ")", "\n", "assert", "memory_size", ">", "self", ".", "window_length", "+", "1", "\n", "if", "batch_size", ">", "memory_size", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"Less samples in memory than batch size.\"", ")", "\n", "", "ref_idxs", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "memory_size", ",", "batch_size", ")", "\n", "batch_idxs", "=", "[", "self", ".", "index_refs", "[", "net", "]", "[", "idx", "]", "for", "idx", "in", "ref_idxs", "]", "\n", "assert", "len", "(", "batch_idxs", ")", "==", "batch_size", "\n", "return", "batch_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.append": [[134, 164], ["super().append", "memory.BootstrappingMemory.observations.append", "memory.BootstrappingMemory.actions.append", "memory.BootstrappingMemory.rewards.append", "memory.BootstrappingMemory.terminals.append", "range", "numpy.random.rand", "memory.BootstrappingMemory.index_refs[].append"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "append", "(", "self", ",", "observation", ",", "action", ",", "reward", ",", "terminal", ",", "training", "=", "True", ")", ":", "\n", "        ", "\"\"\"Append an observation to the replay memory.\n\n        With probability self.adding_prob, the index of the added experience will be added to the index list of each\n        ensemble replay memory.\n\n        Args:\n            observation (dict): Observation returned by environment\n            action (int): Action taken to obtain this observation\n            reward (float): Reward obtained by taking this action\n            terminal (boolean): Is the state terminal\n            training (boolean): True during training episodes, false during testing episodes.\n        \"\"\"", "\n", "super", "(", "BootstrappingMemory", ",", "self", ")", ".", "append", "(", "observation", ",", "action", ",", "reward", ",", "terminal", ",", "training", "=", "training", ")", "\n", "\n", "if", "training", ":", "\n", "            ", "if", "self", ".", "nb_entries", "<", "self", ".", "limit", ":", "# One more entry will be added after this loop", "\n", "# There should be enough experiences before the chosen sample to fill the window length + 1", "\n", "                ", "if", "self", ".", "nb_entries", ">", "self", ".", "window_length", "+", "1", ":", "\n", "                    ", "for", "i", "in", "range", "(", "self", ".", "nb_nets", ")", ":", "\n", "                        ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "adding_prob", ":", "\n", "                            ", "self", ".", "index_refs", "[", "i", "]", ".", "append", "(", "self", ".", "nb_entries", ")", "\n", "\n", "# This needs to be understood as follows: in `observation`, take `action`, obtain `reward`", "\n", "# and weather the next state is `terminal` or not.", "\n", "", "", "", "", "", "if", "training", ":", "\n", "            ", "self", ".", "observations", ".", "append", "(", "observation", ")", "\n", "self", ".", "actions", ".", "append", "(", "action", ")", "\n", "self", ".", "rewards", ".", "append", "(", "reward", ")", "\n", "self", ".", "terminals", ".", "append", "(", "terminal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.nb_entries": [[165, 173], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "nb_entries", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return number of observations\n\n        Returns:\n            Number of observations\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "observations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config": [[174, 183], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return configurations of SequentialMemory\n\n        Returns:\n            Dict of config\n        \"\"\"", "\n", "config", "=", "super", "(", "BootstrappingMemory", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", "[", "'limit'", "]", "=", "self", ".", "limit", "\n", "return", "config", "\n", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.plot_decision_map.DecisionMap.__init__": [[13, 33], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "agent", ",", "traci", ",", "intersection_pos", ",", "start_pos", ",", "end_pos", ",", "nb_actions", ",", "dy", "=", "2", ",", "value_range", "=", "(", "-", "10", ",", "10", ")", ",", "\n", "uncertainty_range", "=", "(", "0", ",", "5", ")", ",", "x_range_action", "=", "(", "0.2", ",", "3", ")", ",", "x_range_value", "=", "(", "-", "3", ",", "-", "0.2", ")", ",", "\n", "x_range_aleatoric_uncertainty", "=", "(", "-", "6", ",", "-", "3.2", ")", ",", "x_range_epistemic_uncertainty", "=", "(", "-", "8.8", ",", "-", "6", ")", ")", ":", "\n", "        ", "self", ".", "agent", "=", "agent", "\n", "self", ".", "traci", "=", "traci", "\n", "self", ".", "intersection_pos", "=", "intersection_pos", "\n", "self", ".", "end_pos", "=", "end_pos", "\n", "self", ".", "start_pos", "=", "start_pos", "\n", "self", ".", "y_range", "=", "np", ".", "array", "(", "[", "start_pos", ",", "end_pos", "]", ")", "+", "self", ".", "intersection_pos", "[", "1", "]", "\n", "self", ".", "dy", "=", "dy", "\n", "self", ".", "x_range_action", "=", "np", ".", "array", "(", "intersection_pos", ")", "+", "np", ".", "array", "(", "x_range_action", ")", "\n", "self", ".", "x_range_value", "=", "np", ".", "array", "(", "intersection_pos", ")", "+", "np", ".", "array", "(", "x_range_value", ")", "\n", "self", ".", "x_range_aleatoric_uncertainty", "=", "np", ".", "array", "(", "intersection_pos", ")", "+", "np", ".", "array", "(", "x_range_aleatoric_uncertainty", ")", "\n", "self", ".", "x_range_epistemic_uncertainty", "=", "np", ".", "array", "(", "intersection_pos", ")", "+", "np", ".", "array", "(", "x_range_epistemic_uncertainty", ")", "\n", "self", ".", "value_range", "=", "value_range", "\n", "self", ".", "uncertainty_range", "=", "uncertainty_range", "\n", "c_max", "=", "150", "\n", "self", ".", "action_colors", "=", "[", "(", "c_max", ",", "c_max", ",", "0", ",", "255", ")", ",", "(", "0", ",", "c_max", ",", "0", ",", "255", ")", ",", "(", "c_max", ",", "0", ",", "0", ",", "255", ")", ",", "(", "0", ",", "0", ",", "c_max", ",", "255", ")", "]", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "self", ".", "polygon_names", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.plot_decision_map.DecisionMap.plot": [[34, 97], ["enumerate", "plot_decision_map.DecisionMap.traci.polygon.remove", "range", "plot_decision_map.DecisionMap.agent.forward", "plot_decision_map.DecisionMap.polygon_names.append", "plot_decision_map.DecisionMap.traci.polygon.add", "plot_decision_map.DecisionMap.polygon_names.append", "plot_decision_map.DecisionMap.traci.polygon.add", "Exception", "numpy.clip", "numpy.clip", "numpy.clip", "plot_decision_map.DecisionMap.polygon_names.append", "plot_decision_map.DecisionMap.traci.polygon.add", "numpy.clip", "plot_decision_map.DecisionMap.polygon_names.append", "plot_decision_map.DecisionMap.traci.polygon.add", "numpy.max", "numpy.argmax", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "plot", "(", "self", ",", "obs", ")", ":", "\n", "        ", "for", "item", "in", "self", ".", "polygon_names", ":", "\n", "            ", "self", ".", "traci", ".", "polygon", ".", "remove", "(", "item", ")", "\n", "", "self", ".", "polygon_names", "=", "[", "]", "\n", "for", "idx", ",", "y", "in", "enumerate", "(", "range", "(", "self", ".", "y_range", "[", "0", "]", ",", "self", ".", "y_range", "[", "1", "]", ",", "self", ".", "dy", ")", ")", ":", "\n", "# This code should match the sensor model in intersection_env.py", "\n", "            ", "obs", "[", "0", "]", "=", "2", "*", "(", "y", "-", "(", "self", ".", "intersection_pos", "[", "1", "]", "+", "self", ".", "end_pos", ")", ")", "/", "(", "self", ".", "end_pos", "-", "self", ".", "start_pos", ")", "+", "1", "\n", "action", ",", "action_info", "=", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "if", "'q_values'", "in", "action_info", ":", "\n", "                ", "if", "action", "<", "self", ".", "nb_actions", ":", "\n", "                    ", "value", "=", "action_info", "[", "'q_values'", "]", "[", "action", "]", "\n", "", "else", ":", "\n", "                    ", "value", "=", "np", ".", "max", "(", "action_info", "[", "'q_values'", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Error in decision map plot.'", ")", "\n", "", "if", "value", ">", "0", ":", "\n", "                ", "color_scale", "=", "value", "/", "self", ".", "value_range", "[", "1", "]", "\n", "color_scale", "=", "np", ".", "clip", "(", "color_scale", ",", "0", ",", "1", ")", "\n", "color_value", "=", "(", "0", ",", "color_scale", "*", "255", ",", "0", ",", "255", ")", "\n", "", "else", ":", "\n", "                ", "color_scale", "=", "(", "value", "-", "self", ".", "value_range", "[", "0", "]", ")", "/", "(", "0", "-", "self", ".", "value_range", "[", "0", "]", ")", "\n", "color_scale", "=", "np", ".", "clip", "(", "color_scale", ",", "0", ",", "1", ")", "\n", "color_value", "=", "(", "(", "1", "-", "color_scale", ")", "*", "255", ",", "0", ",", "0", ",", "255", ")", "\n", "", "self", ".", "polygon_names", ".", "append", "(", "' '", "*", "(", "idx", "*", "5", "+", "3", ")", ")", "\n", "self", ".", "traci", ".", "polygon", ".", "add", "(", "' '", "*", "(", "idx", "*", "5", "+", "3", ")", ",", "[", "(", "self", ".", "x_range_action", "[", "0", "]", ",", "y", "-", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_action", "[", "1", "]", ",", "y", "-", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_action", "[", "1", "]", ",", "y", "+", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_action", "[", "0", "]", ",", "y", "+", "self", ".", "dy", "/", "2", ")", "]", ",", "\n", "self", ".", "action_colors", "[", "action", "]", ",", "fill", "=", "True", ",", "layer", "=", "5", ")", "\n", "self", ".", "polygon_names", ".", "append", "(", "' '", "*", "(", "idx", "*", "5", "+", "4", ")", ")", "\n", "self", ".", "traci", ".", "polygon", ".", "add", "(", "' '", "*", "(", "idx", "*", "5", "+", "4", ")", ",", "[", "(", "self", ".", "x_range_value", "[", "0", "]", ",", "y", "-", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_value", "[", "1", "]", ",", "y", "-", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_value", "[", "1", "]", ",", "y", "+", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_value", "[", "0", "]", ",", "y", "+", "self", ".", "dy", "/", "2", ")", "]", ",", "\n", "color_value", ",", "fill", "=", "True", ",", "layer", "=", "5", ")", "\n", "if", "'aleatoric_std_dev'", "in", "action_info", ":", "\n", "                ", "if", "action", "<", "self", ".", "nb_actions", ":", "\n", "                    ", "color_scale", "=", "action_info", "[", "'aleatoric_std_dev'", "]", "[", "action", "]", "/", "self", ".", "uncertainty_range", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "color_scale", "=", "action_info", "[", "'aleatoric_std_dev'", "]", "[", "np", ".", "argmax", "(", "action_info", "[", "'q_values'", "]", ")", "]", "/", "self", ".", "uncertainty_range", "[", "1", "]", "\n", "", "color_scale", "=", "np", ".", "clip", "(", "color_scale", ",", "0", ",", "1", ")", "\n", "color_value", "=", "(", "color_scale", "*", "255", ",", "0", ",", "0", ",", "255", ")", "\n", "self", ".", "polygon_names", ".", "append", "(", "' '", "*", "(", "idx", "*", "5", "+", "5", ")", ")", "\n", "self", ".", "traci", ".", "polygon", ".", "add", "(", "' '", "*", "(", "idx", "*", "5", "+", "5", ")", ",", "[", "(", "self", ".", "x_range_aleatoric_uncertainty", "[", "0", "]", ",", "y", "-", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_aleatoric_uncertainty", "[", "1", "]", ",", "y", "-", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_aleatoric_uncertainty", "[", "1", "]", ",", "y", "+", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_aleatoric_uncertainty", "[", "0", "]", ",", "y", "+", "self", ".", "dy", "/", "2", ")", "]", ",", "\n", "color_value", ",", "fill", "=", "True", ",", "layer", "=", "5", ")", "\n", "", "if", "'epistemic_std_dev'", "in", "action_info", ":", "\n", "                ", "if", "action", "<", "self", ".", "nb_actions", ":", "\n", "                    ", "color_scale", "=", "action_info", "[", "'epistemic_std_dev'", "]", "[", "action", "]", "/", "self", ".", "uncertainty_range", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "color_scale", "=", "action_info", "[", "'epistemic_std_dev'", "]", "[", "np", ".", "argmax", "(", "action_info", "[", "'q_values'", "]", ")", "]", "/", "self", ".", "uncertainty_range", "[", "1", "]", "\n", "", "color_scale", "=", "np", ".", "clip", "(", "color_scale", ",", "0", ",", "1", ")", "\n", "color_value", "=", "(", "color_scale", "*", "255", ",", "0", ",", "0", ",", "255", ")", "\n", "self", ".", "polygon_names", ".", "append", "(", "' '", "*", "(", "idx", "*", "5", "+", "6", ")", ")", "\n", "self", ".", "traci", ".", "polygon", ".", "add", "(", "' '", "*", "(", "idx", "*", "5", "+", "6", ")", ",", "[", "(", "self", ".", "x_range_epistemic_uncertainty", "[", "0", "]", ",", "y", "-", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_epistemic_uncertainty", "[", "1", "]", ",", "y", "-", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_epistemic_uncertainty", "[", "1", "]", ",", "y", "+", "self", ".", "dy", "/", "2", ")", ",", "\n", "(", "self", ".", "x_range_epistemic_uncertainty", "[", "0", "]", ",", "y", "+", "self", ".", "dy", "/", "2", ")", "]", ",", "\n", "color_value", ",", "fill", "=", "True", ",", "layer", "=", "5", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_quantile_regression.Tester.__init__": [[16, 40], ["unittest.TestCase.__init__", "rl.policy.LinearAnnealedPolicy", "policy.DistributionalEpsGreedyPolicy", "rl.memory.SequentialMemory", "iqn.IQNAgent", "network_architecture_distributional.NetworkMLPDistributional", "policy.DistributionalEpsGreedyPolicy"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "model", "=", "NetworkMLPDistributional", "(", "nb_inputs", "=", "10", ",", "nb_outputs", "=", "4", ",", "nb_hidden_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "nb_quantiles", "=", "32", ",", "\n", "nb_cos_embeddings", "=", "64", ",", "duel", "=", "True", ",", "\n", "prior", "=", "False", ",", "activation", "=", "'relu'", ",", "duel_type", "=", "'avg'", ",", "\n", "window_length", "=", "1", ")", ".", "model", "\n", "self", ".", "policy", "=", "LinearAnnealedPolicy", "(", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "None", ")", ",", "attr", "=", "'eps'", ",", "value_max", "=", "1.", ",", "\n", "value_min", "=", "0.1", ",", "value_test", "=", ".0", ",", "\n", "nb_steps", "=", "10000", ")", "\n", "self", ".", "test_policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0", ")", "\n", "self", ".", "memory", "=", "SequentialMemory", "(", "limit", "=", "10000", ",", "window_length", "=", "1", ")", "\n", "self", ".", "agent", "=", "IQNAgent", "(", "model", "=", "self", ".", "model", ",", "policy", "=", "self", ".", "policy", ",", "test_policy", "=", "self", ".", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "nb_samples_policy", "=", "32", ",", "\n", "nb_sampled_quantiles", "=", "32", ",", "\n", "cvar_eta", "=", "1", ",", "\n", "nb_actions", "=", "4", ",", "memory", "=", "self", ".", "memory", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "32", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_quantile_regression.Tester.test_quantile_regression": [[41, 105], ["rl.policy.LinearAnnealedPolicy", "rl.policy.LinearAnnealedPolicy.DistributionalEpsGreedyPolicy", "rl.memory.SequentialMemory", "iqn.IQNAgent", "iqn.IQNAgent.compile", "keras.utils.plot_model", "numpy.random.rand", "numpy.random.randint", "numpy.linspace", "iqn.IQNAgent.model.predict_on_batch", "range", "test_quantile_regression.Tester.assertTrue", "test_quantile_regression.Tester.assertTrue", "test_quantile_regression.Tester.assertTrue", "network_architecture_distributional.NetworkMLPDistributional", "rl.policy.LinearAnnealedPolicy.DistributionalEpsGreedyPolicy", "keras.optimizers.Adam", "numpy.random.rand", "numpy.random.choice", "numpy.repeat", "iqn.IQNAgent.model.predict_on_batch", "numpy.zeros", "numpy.zeros", "iqn.IQNAgent.trainable_model.predict_on_batch", "iqn.IQNAgent.trainable_model.train_on_batch", "numpy.mod", "numpy.linspace", "iqn.IQNAgent.model.predict_on_batch", "numpy.abs", "numpy.abs", "numpy.abs", "range", "range", "range", "numpy.mean", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "test_quantile_regression", "(", "self", ")", ":", "\n", "        ", "nb_inputs", "=", "10", "\n", "nb_actions", "=", "3", "\n", "nb_quantiles", "=", "32", "\n", "batch_size", "=", "64", "\n", "delta_clip", "=", "1", "\n", "model", "=", "NetworkMLPDistributional", "(", "nb_inputs", "=", "nb_inputs", ",", "nb_outputs", "=", "nb_actions", ",", "nb_hidden_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "nb_quantiles", "=", "nb_quantiles", ",", "\n", "nb_cos_embeddings", "=", "64", ",", "duel", "=", "True", ",", "\n", "prior", "=", "False", ",", "activation", "=", "'relu'", ",", "duel_type", "=", "'avg'", ",", "\n", "window_length", "=", "1", ")", ".", "model", "\n", "policy", "=", "LinearAnnealedPolicy", "(", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "1", ")", ",", "attr", "=", "'eps'", ",", "value_max", "=", "1.", ",", "\n", "value_min", "=", "0.1", ",", "value_test", "=", ".0", ",", "\n", "nb_steps", "=", "10000", ")", "\n", "test_policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0", ")", "\n", "memory", "=", "SequentialMemory", "(", "limit", "=", "10000", ",", "window_length", "=", "1", ")", "\n", "agent", "=", "IQNAgent", "(", "model", "=", "model", ",", "policy", "=", "policy", ",", "test_policy", "=", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "nb_samples_policy", "=", "nb_quantiles", ",", "\n", "nb_sampled_quantiles", "=", "nb_quantiles", ",", "\n", "cvar_eta", "=", "1", ",", "\n", "nb_actions", "=", "nb_actions", ",", "memory", "=", "memory", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "batch_size", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "delta_clip", ")", "\n", "\n", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.0001", ")", ")", "\n", "plot_model", "(", "agent", ".", "trainable_model", ",", "to_file", "=", "'trainable_model_2.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n", "# Test input", "\n", "states", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "1", ",", "nb_inputs", ")", "\n", "actions", "=", "np", ".", "random", ".", "randint", "(", "nb_actions", ",", "size", "=", "batch_size", ")", "\n", "test_quantiles", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "nb_quantiles", ")", "\n", "z_values", "=", "agent", ".", "model", ".", "predict_on_batch", "(", "[", "states", ",", "test_quantiles", "[", "None", ",", "None", ",", ":", "]", "]", ")", "\n", "# print(z_values[0])", "\n", "\n", "for", "i", "in", "range", "(", "3000", ")", ":", "\n", "            ", "quantiles", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "1", ",", "nb_quantiles", ")", "\n", "# targets = np.random.choice([1, 2, 3], batch_size)", "\n", "targets", "=", "np", ".", "random", ".", "choice", "(", "[", "10", ",", "22", ",", "35", "]", ",", "batch_size", ")", "\n", "targets", "=", "np", ".", "repeat", "(", "targets", "[", ":", ",", "None", "]", ",", "nb_quantiles", ",", "axis", "=", "1", ")", "\n", "\n", "predictions", "=", "agent", ".", "model", ".", "predict_on_batch", "(", "[", "states", ",", "quantiles", "]", ")", "\n", "\n", "masks", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "nb_actions", ")", ")", "\n", "masks", "[", "range", "(", "batch_size", ")", ",", "actions", "]", "=", "1", "\n", "targets_expanded", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "nb_quantiles", ",", "nb_actions", ")", ")", "\n", "targets_expanded", "[", "range", "(", "batch_size", ")", ",", ":", ",", "actions", "]", "=", "targets", "[", "range", "(", "batch_size", ")", ",", ":", "]", "\n", "\n", "loss", "=", "agent", ".", "trainable_model", ".", "predict_on_batch", "(", "[", "states", ",", "quantiles", ",", "targets_expanded", ",", "masks", "]", ")", "\n", "\n", "metrics", "=", "agent", ".", "trainable_model", ".", "train_on_batch", "(", "[", "states", ",", "quantiles", ",", "targets_expanded", ",", "masks", "]", ",", "\n", "[", "targets", ",", "targets_expanded", "]", ")", "\n", "\n", "if", "np", ".", "mod", "(", "i", ",", "100", ")", "==", "0", ":", "\n", "                ", "test_quantiles", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "nb_quantiles", ")", "\n", "z_values", "=", "agent", ".", "model", ".", "predict_on_batch", "(", "[", "states", ",", "test_quantiles", "[", "None", ",", "None", ",", ":", "]", "]", ")", "\n", "\n", "", "", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "np", ".", "mean", "(", "z_values", "[", ":", ",", "1", ":", "10", ",", ":", "]", ")", "-", "10", ")", "<", "1.0", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "np", ".", "mean", "(", "z_values", "[", ":", ",", "12", ":", "20", ",", ":", "]", ")", "-", "22", ")", "<", "1.0", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "np", ".", "mean", "(", "z_values", "[", ":", ",", "23", ":", "31", ",", ":", "]", ")", "-", "35", ")", "<", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_training.Tester.__init__": [[17, 65], ["unittest.TestCase.__init__", "rl.policy.LinearAnnealedPolicy", "policy.DistributionalEpsGreedyPolicy", "rl.memory.SequentialMemory", "iqn.IQNAgent", "network_architecture_distributional.NetworkMLPDistributional", "policy.DistributionalEpsGreedyPolicy", "rl.policy.LinearAnnealedPolicy", "rl.policy.EpsGreedyQPolicy", "rl.memory.SequentialMemory", "dqn_standard.DQNAgent", "network_architecture.NetworkMLP", "rl.policy.EpsGreedyQPolicy"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "agent_name", "=", "'iqn'", "\n", "self", ".", "verbose", "=", "False", "\n", "\n", "if", "self", ".", "agent_name", "==", "'iqn'", ":", "\n", "            ", "self", ".", "nb_quantiles", "=", "32", "\n", "self", ".", "model", "=", "NetworkMLPDistributional", "(", "nb_inputs", "=", "10", ",", "nb_outputs", "=", "4", ",", "nb_hidden_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "nb_quantiles", "=", "self", ".", "nb_quantiles", ",", "\n", "nb_cos_embeddings", "=", "64", ",", "duel", "=", "True", ",", "\n", "prior", "=", "False", ",", "activation", "=", "'relu'", ",", "duel_type", "=", "'avg'", ",", "\n", "window_length", "=", "1", ")", ".", "model", "\n", "self", ".", "policy", "=", "LinearAnnealedPolicy", "(", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "None", ")", ",", "attr", "=", "'eps'", ",", "value_max", "=", "1.", ",", "\n", "value_min", "=", "0.1", ",", "value_test", "=", ".0", ",", "\n", "nb_steps", "=", "10000", ")", "\n", "self", ".", "test_policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0", ")", "\n", "self", ".", "memory", "=", "SequentialMemory", "(", "limit", "=", "10000", ",", "window_length", "=", "1", ")", "\n", "self", ".", "agent", "=", "IQNAgent", "(", "model", "=", "self", ".", "model", ",", "policy", "=", "self", ".", "policy", ",", "test_policy", "=", "self", ".", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "nb_samples_policy", "=", "self", ".", "nb_quantiles", ",", "\n", "nb_sampled_quantiles", "=", "self", ".", "nb_quantiles", ",", "\n", "cvar_eta", "=", "1", ",", "\n", "nb_actions", "=", "4", ",", "memory", "=", "self", ".", "memory", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "48", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "1", ")", "\n", "", "elif", "self", ".", "agent_name", "==", "'dqn'", ":", "\n", "            ", "self", ".", "model", "=", "NetworkMLP", "(", "nb_inputs", "=", "10", ",", "nb_outputs", "=", "4", ",", "nb_hidden_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "True", ",", "\n", "prior", "=", "False", ",", "activation", "=", "'relu'", ",", "duel_type", "=", "'avg'", ",", "\n", "window_length", "=", "1", ")", ".", "model", "\n", "self", ".", "policy", "=", "LinearAnnealedPolicy", "(", "EpsGreedyQPolicy", "(", ")", ",", "attr", "=", "'eps'", ",", "value_max", "=", "1.", ",", "\n", "value_min", "=", "0.1", ",", "value_test", "=", ".0", ",", "\n", "nb_steps", "=", "10000", ")", "\n", "self", ".", "test_policy", "=", "EpsGreedyQPolicy", "(", "eps", "=", "0", ")", "\n", "self", ".", "memory", "=", "SequentialMemory", "(", "limit", "=", "10000", ",", "window_length", "=", "1", ")", "\n", "self", ".", "agent", "=", "DQNAgent", "(", "model", "=", "self", ".", "model", ",", "policy", "=", "self", ".", "policy", ",", "test_policy", "=", "self", ".", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "nb_actions", "=", "4", ",", "memory", "=", "self", ".", "memory", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "48", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_training.Tester.test_simple_iqn_training": [[66, 122], ["test_iqn_training.Tester.agent.compile", "numpy.ones", "range", "range", "range", "keras.optimizers.Adam", "test_iqn_training.Tester.agent.forward", "test_iqn_training.Tester.agent.backward", "test_iqn_training.Tester.agent.forward", "test_iqn_training.Tester.agent.backward", "test_iqn_training.Tester.agent.forward", "test_iqn_training.Tester.agent.backward", "test_iqn_training.Tester.agent.forward", "test_iqn_training.Tester.agent.backward", "range", "numpy.linspace", "test_iqn_training.Tester.agent.model.predict", "test_iqn_training.Tester.assertTrue", "test_iqn_training.Tester.assertTrue", "test_iqn_training.Tester.agent.forward", "test_iqn_training.Tester.agent.backward", "test_iqn_training.Tester.agent.forward", "test_iqn_training.Tester.agent.backward", "test_iqn_training.Tester.agent.forward", "test_iqn_training.Tester.agent.backward", "test_iqn_training.Tester.agent.forward", "test_iqn_training.Tester.agent.backward", "print", "numpy.linspace", "test_iqn_training.Tester.agent.model.predict", "print", "print", "print", "test_iqn_training.Tester.agent.model.predict", "print", "test_iqn_training.Tester.agent.model.predict", "numpy.abs", "numpy.abs", "print", "print", "numpy.abs", "numpy.abs", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "", "def", "test_simple_iqn_training", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "# obs = np.zeros(10)", "\n", "obs", "=", "np", ".", "ones", "(", "10", ")", "\n", "for", "_", "in", "range", "(", "0", ",", "500", ")", ":", "# Fill up buffer", "\n", "            ", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "True", ")", "\n", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "False", ")", "\n", "", "for", "_", "in", "range", "(", "0", ",", "500", ")", ":", "# Fill up buffer", "\n", "            ", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "True", ")", "\n", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "for", "b", "in", "range", "(", "10", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "                ", "action1", ",", "action_info1", "=", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "metrics", "=", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "True", ")", "\n", "action1", ",", "action_info1", "=", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "metrics", "=", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "False", ")", "\n", "self", ".", "agent", ".", "step", "+=", "1", "\n", "\n", "action2", ",", "action_info2", "=", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "metrics", "=", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "True", ")", "\n", "action2", ",", "action_info2", "=", "self", ".", "agent", ".", "forward", "(", "obs", ")", "\n", "metrics", "=", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "self", ".", "agent", ".", "step", "+=", "1", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "b", ")", "\n", "", "if", "self", ".", "agent_name", "==", "'iqn'", ":", "\n", "                ", "test_quantiles", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "self", ".", "nb_quantiles", ")", "\n", "z_values", "=", "self", ".", "agent", ".", "model", ".", "predict", "(", "[", "obs", "[", "None", ",", "None", ",", ":", "]", ",", "test_quantiles", "[", "None", ",", "None", ",", ":", "]", "]", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "z_values", ")", "\n", "", "", "elif", "self", ".", "agent_name", "==", "'dqn'", ":", "\n", "                ", "q_values", "=", "self", ".", "agent", ".", "model", ".", "predict", "(", "obs", "[", "None", ",", "None", ",", ":", "]", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "q_values", ")", "\n", "\n", "", "", "", "if", "self", ".", "agent_name", "==", "'iqn'", ":", "\n", "            ", "test_quantiles", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "self", ".", "nb_quantiles", ")", "\n", "z_values", "=", "self", ".", "agent", ".", "model", ".", "predict", "(", "[", "obs", "[", "None", ",", "None", ",", ":", "]", ",", "test_quantiles", "[", "None", ",", "None", ",", ":", "]", "]", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "z_values", ")", "\n", "print", "(", "np", ".", "abs", "(", "np", ".", "mean", "(", "z_values", "[", ":", ",", ":", "15", ",", ":", "]", ")", "-", "0", ")", "<", "0.5", ")", "\n", "print", "(", "np", ".", "abs", "(", "np", ".", "mean", "(", "z_values", "[", ":", ",", "17", ":", ",", ":", "]", ")", "-", "10", ")", "<", "0.5", ")", "\n", "\n", "", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "np", ".", "mean", "(", "z_values", "[", ":", ",", ":", "15", ",", ":", "]", ")", "-", "0", ")", "<", "0.5", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "np", ".", "mean", "(", "z_values", "[", ":", ",", "17", ":", ",", ":", "]", ")", "-", "10", ")", "<", "1.0", ")", "\n", "\n", "", "elif", "self", ".", "agent_name", "==", "'dqn'", ":", "\n", "            ", "q_values", "=", "self", ".", "agent", ".", "model", ".", "predict", "(", "obs", "[", "None", ",", "None", ",", ":", "]", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "q_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.__init__": [[17, 21], ["unittest.TestCase.__init__", "shutil.copy"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "test_duration", "=", "30", "\n", "copy", "(", "'../src/parameters.py'", ",", "'tmp_parameters_original.py'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent": [[22, 34], ["multiprocessing.Process", "multiprocessing.Process.start", "time.sleep", "multiprocessing.Process.is_alive", "multiprocessing.Process.join", "psutil.Process().children", "multiprocessing.Process.terminate", "Exception", "psutil.Process", "child_process.send_signal"], "methods", ["None"], ["", "def", "run_train_agent", "(", "self", ")", ":", "\n", "        ", "process", "=", "mp", ".", "Process", "(", "target", "=", "exec_train_agent", ")", "\n", "process", ".", "start", "(", ")", "\n", "time", ".", "sleep", "(", "self", ".", "test_duration", ")", "\n", "if", "process", ".", "is_alive", "(", ")", ":", "\n", "            ", "for", "child_process", "in", "psutil", ".", "Process", "(", "process", ".", "pid", ")", ".", "children", "(", ")", ":", "\n", "                ", "if", "child_process", ".", "_name", "!=", "'sumo'", ":", "\n", "                    ", "child_process", ".", "send_signal", "(", "15", ")", "\n", "", "", "process", ".", "terminate", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Process died'", ")", "\n", "", "process", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.test_dqn": [[35, 63], ["open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "test_train_agent.Tester.run_train_agent", "shutil.copy", "test_train_agent.Tester.run_train_agent", "shutil.copy"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent"], ["", "def", "test_dqn", "(", "self", ")", ":", "\n", "        ", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['env'] = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n", "", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.test_ensemble": [[64, 120], ["open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "test_train_agent.Tester.run_train_agent", "shutil.copy", "test_train_agent.Tester.run_train_agent", "shutil.copy", "test_train_agent.Tester.run_train_agent", "shutil.copy", "test_train_agent.Tester.run_train_agent", "shutil.copy"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent"], ["", "", "def", "test_ensemble", "(", "self", ")", ":", "\n", "        ", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n", "", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n", "", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n", "", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.test_iqn": [[121, 149], ["open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "test_train_agent.Tester.run_train_agent", "shutil.copy", "test_train_agent.Tester.run_train_agent", "shutil.copy"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent"], ["", "", "def", "test_iqn", "(", "self", ")", ":", "\n", "        ", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n", "", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.test_iqn_ensemble": [[150, 206], ["open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "open", "open.write", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.writelines", "open.close", "test_train_agent.Tester.run_train_agent", "shutil.copy", "test_train_agent.Tester.run_train_agent", "shutil.copy", "test_train_agent.Tester.run_train_agent", "shutil.copy", "test_train_agent.Tester.run_train_agent", "shutil.copy"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.Tester.run_train_agent"], ["", "", "def", "test_iqn_ensemble", "(", "self", ")", ":", "\n", "        ", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n", "", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n", "", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = False\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n", "", "f", "=", "open", "(", "'../src/parameters.py'", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "f", ".", "writelines", "(", "\"env = 'intersection'\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['distributional'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['ensemble'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['parallel'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['cnn'] = True\\n\"", ")", "\n", "f", ".", "writelines", "(", "\"agent_par['learning_starts'] = 500\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "run_train_agent", "(", ")", "\n", "", "finally", ":", "\n", "            ", "copy", "(", "'tmp_parameters_original.py'", ",", "'../src/parameters.py'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_train_agent.exec_train_agent": [[11, 13], ["exec", "open().read", "open"], "function", ["None"], ["def", "exec_train_agent", "(", ")", ":", "\n", "    ", "exec", "(", "open", "(", "\"../src/train_agent.py\"", ")", ".", "read", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_distributional_policy.Tester.test_policy": [[11, 40], ["policy.DistributionalEpsGreedyPolicy.DistributionalEpsGreedyPolicy", "range", "policy.DistributionalEpsGreedyPolicy.DistributionalEpsGreedyPolicy", "range", "test_distributional_policy.Tester.assertTrue", "test_distributional_policy.Tester.assertTrue", "test_distributional_policy.Tester.assertTrue", "test_distributional_policy.Tester.assertTrue", "policy.DistributionalEpsGreedyPolicy.DistributionalEpsGreedyPolicy", "numpy.random.rand", "numpy.random.randint", "range", "policy.DistributionalEpsGreedyPolicy.DistributionalEpsGreedyPolicy.select_action", "test_distributional_policy.Tester.assertTrue", "numpy.random.rand", "policy.DistributionalEpsGreedyPolicy.DistributionalEpsGreedyPolicy.select_action", "test_distributional_policy.Tester.assertEqual", "numpy.random.rand", "policy.DistributionalEpsGreedyPolicy.DistributionalEpsGreedyPolicy.select_action", "action_vec.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["    ", "def", "test_policy", "(", "self", ")", ":", "\n", "        ", "policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0.", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "100", ")", ":", "\n", "            ", "z_values", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "4", ")", "\n", "z_values", "[", ":", ",", "0", "]", "+=", "1", "# Action 0 should then be 'best'", "\n", "action", ",", "info", "=", "policy", ".", "select_action", "(", "z_values", "=", "z_values", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "0", ")", "\n", "\n", "", "policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0.5", ")", "\n", "action_vec", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "100", ")", ":", "\n", "            ", "z_values", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "4", ")", "\n", "z_values", "[", ":", ",", "0", "]", "+=", "1", "# Action 0 should then be 'best'", "\n", "action", "=", "policy", ".", "select_action", "(", "z_values", "=", "z_values", ")", "\n", "action_vec", ".", "append", "(", "action", ")", "\n", "", "self", ".", "assertTrue", "(", "(", "np", ".", "array", "(", "action_vec", ")", "==", "0", ")", ".", "any", "(", ")", ")", "# All actions should be chosen sometimes", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "array", "(", "action_vec", ")", "==", "1", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "array", "(", "action_vec", ")", "==", "2", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "array", "(", "action_vec", ")", "==", "3", ")", ".", "any", "(", ")", ")", "\n", "\n", "# Test for batch", "\n", "policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0.", ")", "\n", "z_values", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "32", ",", "4", ")", "\n", "best_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "4", ",", "32", ")", "\n", "for", "batch", "in", "range", "(", "0", ",", "32", ")", ":", "\n", "            ", "idx", "=", "best_idx", "[", "batch", "]", "\n", "z_values", "[", "batch", ",", ":", ",", "idx", "]", "+=", "1", "\n", "", "action", ",", "info", "=", "policy", ".", "select_action", "(", "z_values", "=", "z_values", ")", "\n", "self", ".", "assertTrue", "(", "(", "action", "==", "best_idx", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_distributional_policy.Tester.test_safe_policy": [[41, 64], ["policy.DistributionalTestPolicy.DistributionalTestPolicy", "numpy.ones", "policy.DistributionalTestPolicy.DistributionalTestPolicy.select_action", "test_distributional_policy.Tester.assertEqual", "test_distributional_policy.Tester.assertFalse", "numpy.ones", "policy.DistributionalTestPolicy.DistributionalTestPolicy.select_action", "test_distributional_policy.Tester.assertEqual", "test_distributional_policy.Tester.assertTrue", "numpy.ones", "policy.DistributionalTestPolicy.DistributionalTestPolicy.select_action", "test_distributional_policy.Tester.assertEqual", "test_distributional_policy.Tester.assertTrue"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["", "def", "test_safe_policy", "(", "self", ")", ":", "\n", "        ", "safety_threshold", "=", "0.1", "\n", "nb_actions", "=", "8", "\n", "\n", "policy", "=", "DistributionalTestPolicy", "(", "safety_threshold", "=", "safety_threshold", ")", "\n", "\n", "z_values", "=", "np", ".", "ones", "(", "[", "32", ",", "nb_actions", "]", ")", "# nb quantiles, nb actions", "\n", "z_values", "[", "5", ":", ",", "2", "]", "*=", "1.01", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "2", ")", "\n", "self", ".", "assertFalse", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "z_values", "=", "np", ".", "ones", "(", "[", "32", ",", "nb_actions", "]", ")", "\n", "z_values", "[", ":", "10", ",", ":", "]", "*=", "0.5", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "nb_actions", ")", "\n", "self", ".", "assertTrue", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "z_values", "=", "np", ".", "ones", "(", "[", "32", ",", "nb_actions", "]", ")", "\n", "z_values", "[", "0", ",", ":", "]", "*=", "-", "10", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "nb_actions", ")", "\n", "self", ".", "assertTrue", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_road_creation.Tester.__init__": [[10, 58], ["unittest.TestCase.__init__", "vehicles.append", "vehicles.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "road.Road"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "vehicles", "=", "[", "]", "\n", "vehicles", ".", "append", "(", "{", "}", ")", "\n", "vehicles", "[", "0", "]", "[", "'id'", "]", "=", "'truck'", "\n", "vehicles", "[", "0", "]", "[", "'vClass'", "]", "=", "'truck'", "\n", "vehicles", "[", "0", "]", "[", "'length'", "]", "=", "15.0", "\n", "vehicles", "[", "0", "]", "[", "'maxSpeed'", "]", "=", "90.0", "\n", "vehicles", "[", "0", "]", "[", "'accel'", "]", "=", "1.0", "\n", "vehicles", "[", "0", "]", "[", "'decel'", "]", "=", "5.0", "\n", "vehicles", "[", "0", "]", "[", "'sigma'", "]", "=", "0.0", "\n", "vehicles", ".", "append", "(", "{", "}", ")", "\n", "vehicles", "[", "1", "]", "[", "'id'", "]", "=", "'car'", "\n", "vehicles", "[", "1", "]", "[", "'vClass'", "]", "=", "'passenger'", "\n", "vehicles", "[", "1", "]", "[", "'length'", "]", "=", "4.0", "\n", "vehicles", "[", "1", "]", "[", "'maxSpeed'", "]", "=", "120.0", "\n", "vehicles", "[", "1", "]", "[", "'accel'", "]", "=", "1.0", "\n", "vehicles", "[", "1", "]", "[", "'decel'", "]", "=", "5.0", "\n", "vehicles", "[", "1", "]", "[", "'sigma'", "]", "=", "0.0", "\n", "\n", "road_params", "=", "{", "}", "\n", "road_params", "[", "'road_type'", "]", "=", "'intersection'", "\n", "road_params", "[", "'name'", "]", "=", "'intersection_test'", "\n", "road_params", "[", "'nb_lanes'", "]", "=", "1", "\n", "road_params", "[", "'nodes'", "]", "=", "np", ".", "array", "(", "[", "[", "-", "200.", ",", "0.", "]", ",", "[", "0.", ",", "0.", "]", ",", "[", "200.", ",", "0.", "]", ",", "[", "0.", ",", "-", "200.", "]", ",", "[", "0.", ",", "200.", "]", ",", "[", "-", "1000", ",", "0", "]", ",", "[", "1000", ",", "0", "]", ",", "[", "0", ",", "-", "1000", "]", ",", "[", "0", ",", "1000", "]", "]", ")", "\n", "road_params", "[", "'priority'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "5", ",", "0", ",", "0", ",", "0", ",", "5", ",", "0", ",", "0", ",", "0", "]", ",", "[", "5", ",", "0", ",", "5", ",", "3", ",", "3", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "5", ",", "0", ",", "0", ",", "0", ",", "0", ",", "5", ",", "0", ",", "0", "]", ",", "[", "0", ",", "3", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "3", ",", "0", "]", ",", "\n", "[", "0", ",", "3", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "3", "]", ",", "[", "5", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "5", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", ",", "3", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "3", ",", "0", ",", "0", ",", "0", ",", "0", "]", "]", ")", "\n", "road_params", "[", "'edges'", "]", "=", "np", ".", "array", "(", "road_params", "[", "'priority'", "]", ">", "0", ",", "dtype", "=", "int", ")", "\n", "road_params", "[", "'routes'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "2", ",", "6", "]", ",", "[", "0", ",", "1", ",", "3", ",", "7", "]", ",", "[", "2", ",", "1", ",", "0", ",", "5", "]", ",", "[", "2", ",", "1", ",", "4", ",", "8", "]", ",", "[", "3", ",", "1", ",", "4", ",", "8", "]", "]", ")", "\n", "road_params", "[", "'vehicles'", "]", "=", "vehicles", "\n", "road_params", "[", "'lane_change_duration'", "]", "=", "4", "\n", "road_params", "[", "'max_road_speed'", "]", "=", "35", "\n", "road_params", "[", "'overtake_right'", "]", "=", "True", "\n", "road_params", "[", "'lane_width'", "]", "=", "3.2", "\n", "road_params", "[", "'emergency_decel_warn_threshold'", "]", "=", "10", "\n", "\n", "road_params", "[", "'collision_action'", "]", "=", "'warn'", "\n", "road_params", "[", "'no_display_step'", "]", "=", "'true'", "\n", "\n", "road_params", "[", "'view_position'", "]", "=", "np", ".", "array", "(", "[", "200", ",", "200", "]", ")", "\n", "road_params", "[", "'view_delay'", "]", "=", "100", "\n", "road_params", "[", "'zoom'", "]", "=", "250", "\n", "\n", "self", ".", "road", "=", "Road", "(", "road_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_road_creation.Tester.test_nodes": [[59, 61], ["test_intersection_road_creation.Tester.road.nodes"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.nodes"], ["", "def", "test_nodes", "(", "self", ")", ":", "\n", "        ", "self", ".", "road", ".", "nodes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_road_creation.Tester.test_edges": [[62, 64], ["test_intersection_road_creation.Tester.road.edges"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.edges"], ["", "def", "test_edges", "(", "self", ")", ":", "\n", "        ", "self", ".", "road", ".", "edges", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_road_creation.Tester.test_routes": [[65, 67], ["test_intersection_road_creation.Tester.road.routes"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.routes"], ["", "def", "test_routes", "(", "self", ")", ":", "\n", "        ", "self", ".", "road", ".", "routes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_road_creation.Tester.test_config": [[68, 70], ["test_intersection_road_creation.Tester.road.config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.config"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "road", ".", "config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_road_creation.Tester.test_gui_settings": [[71, 73], ["test_intersection_road_creation.Tester.road.gui_settings"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.gui_settings"], ["", "def", "test_gui_settings", "(", "self", ")", ":", "\n", "        ", "self", ".", "road", ".", "gui_settings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_road_creation.Tester.test_create_road_files": [[74, 76], ["test_intersection_road_creation.Tester.road.create_road"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.road.Road.create_road"], ["", "def", "test_create_road_files", "(", "self", ")", ":", "\n", "        ", "self", ".", "road", ".", "create_road", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.__init__": [[14, 16], ["unittest.TestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_mlp_network": [[17, 23], ["network_architecture.NetworkMLP", "test_network_architecture.Tester.assertTrue", "network_architecture.NetworkMLP.model.predict", "test_network_architecture.Tester.assertEqual", "keras.utils.plot_model", "numpy.random.rand", "numpy.shape"], "methods", ["None"], ["", "def", "test_mlp_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLP", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "False", ",", "prior", "=", "False", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "4", ")", ")", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_mlp_dueling_network": [[24, 38], ["network_architecture.NetworkMLP", "test_network_architecture.Tester.assertTrue", "numpy.random.rand", "network_architecture.NetworkMLP.model.predict", "test_network_architecture.Tester.assertEqual", "keras.models.Model", "keras.models.Model.predict", "test_network_architecture.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.mean", "numpy.isclose().all", "numpy.isclose"], "methods", ["None"], ["", "def", "test_mlp_dueling_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLP", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "False", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "net_input", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "3", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "4", ")", ")", "\n", "\n", "before_dueling_layer", "=", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "layers", "[", "-", "2", "]", ".", "output", ")", "\n", "before_dueling_output", "=", "before_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "true_output", "=", "before_dueling_output", "[", ":", ",", "0", ",", "None", "]", "+", "before_dueling_output", "[", ":", ",", "1", ":", "]", "-", "np", ".", "mean", "(", "before_dueling_output", "[", ":", ",", "1", ":", ",", "None", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "out", ",", "true_output", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_duel.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_combined_network": [[39, 50], ["network_architecture.NetworkMLP", "test_network_architecture.Tester.assertFalse", "network_architecture.NetworkMLP.model.predict", "test_network_architecture.Tester.assertEqual", "network_architecture.NetworkMLP.model.get_config", "keras.utils.plot_model", "trainable.append", "all", "numpy.random.rand", "numpy.shape"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "test_combined_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLP", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "False", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ")", "\n", "trainable", "=", "[", "]", "\n", "for", "layer", "in", "net", ".", "model", ".", "layers", ":", "\n", "            ", "trainable", ".", "append", "(", "layer", ".", "trainable", ")", "\n", "", "self", ".", "assertFalse", "(", "all", "(", "trainable", ")", ")", "# All layers should not be trainable", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "4", ")", ")", "\n", "net", ".", "model", ".", "get_config", "(", ")", "# This crashes for custom lambda layers", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_prior.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_combined_network_dueling": [[51, 72], ["network_architecture.NetworkMLP", "test_network_architecture.Tester.assertFalse", "numpy.random.rand", "network_architecture.NetworkMLP.model.predict", "test_network_architecture.Tester.assertEqual", "network_architecture.NetworkMLP.model.get_config", "keras.models.Model", "keras.models.Model.predict", "keras.models.Model", "keras.models.Model.predict", "test_network_architecture.Tester.assertTrue", "keras.utils.plot_model", "trainable.append", "all", "numpy.shape", "numpy.mean", "numpy.isclose().all", "network_architecture.NetworkMLP.model.get_layer", "network_architecture.NetworkMLP.model.get_layer", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "test_combined_network_dueling", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLP", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ")", "\n", "trainable", "=", "[", "]", "\n", "for", "layer", "in", "net", ".", "model", ".", "layers", ":", "\n", "            ", "trainable", ".", "append", "(", "layer", ".", "trainable", ")", "\n", "", "self", ".", "assertFalse", "(", "all", "(", "trainable", ")", ")", "# All layers should not be trainable", "\n", "net_input", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "3", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "4", ")", ")", "\n", "net", ".", "model", ".", "get_config", "(", ")", "# This crashes for custom lambda layers", "\n", "\n", "before_dueling_layer", "=", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "\n", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'trainable_out_wo_dueling'", ")", ".", "output", ")", "\n", "before_dueling_output", "=", "before_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "after_dueling_layer", "=", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'trainable_out'", ")", ".", "output", ")", "\n", "after_dueling_output", "=", "after_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "true_dueling_output", "=", "before_dueling_output", "[", ":", ",", "0", ",", "None", "]", "+", "before_dueling_output", "[", ":", ",", "1", ":", "]", "-", "np", ".", "mean", "(", "before_dueling_output", "[", ":", ",", "1", ":", ",", "None", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "after_dueling_output", ",", "true_dueling_output", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_duel_prior.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_cnn_network": [[73, 107], ["network_architecture.NetworkCNN", "test_network_architecture.Tester.assertTrue", "network_architecture.NetworkCNN.model.predict", "test_network_architecture.Tester.assertEqual", "numpy.random.rand", "network_architecture.NetworkCNN.model.predict", "numpy.copy", "test_network_architecture.Tester.assertFalse", "network_architecture.NetworkCNN.model.predict", "test_network_architecture.Tester.assertTrue", "keras.utils.plot_model", "network_architecture.NetworkCNN", "network_architecture.NetworkCNN.model.predict", "test_network_architecture.Tester.assertEqual", "numpy.random.rand", "network_architecture.NetworkCNN.model.predict", "numpy.copy", "test_network_architecture.Tester.assertFalse", "network_architecture.NetworkCNN.model.predict", "test_network_architecture.Tester.assertTrue", "keras.utils.plot_model", "numpy.random.rand", "numpy.shape", "numpy.random.rand", "numpy.shape"], "methods", ["None"], ["", "def", "test_cnn_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "False", ",", "prior", "=", "False", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "44", ")", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "9", ")", ")", "\n", "input1", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "44", ")", "\n", "out1", "=", "net", ".", "model", ".", "predict", "(", "input1", ")", "\n", "input2", "=", "np", ".", "copy", "(", "input1", ")", "\n", "input2", "[", "0", ",", "0", ",", "4", ":", "12", "]", "=", "input1", "[", "0", ",", "0", ",", "12", ":", "20", "]", "\n", "input2", "[", "0", ",", "0", ",", "12", ":", "20", "]", "=", "input1", "[", "0", ",", "0", ",", "4", ":", "12", "]", "\n", "self", ".", "assertFalse", "(", "(", "input1", "==", "input2", ")", ".", "all", "(", ")", ")", "\n", "out2", "=", "net", ".", "model", ".", "predict", "(", "input2", ")", "\n", "self", ".", "assertTrue", "(", "(", "out1", "==", "out2", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n", "# window_length > 1", "\n", "net", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "window_length", "=", "5", ",", "duel", "=", "False", ",", "\n", "prior", "=", "False", ")", "\n", "net", ".", "model", ".", "predict", "(", "np", ".", "random", ".", "rand", "(", "32", ",", "5", ",", "44", ")", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "9", ")", ")", "\n", "\n", "input1", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "5", ",", "44", ")", "\n", "out1", "=", "net", ".", "model", ".", "predict", "(", "input1", ")", "\n", "input2", "=", "np", ".", "copy", "(", "input1", ")", "\n", "input2", "[", "0", ",", ":", ",", "4", ":", "12", "]", "=", "input1", "[", "0", ",", ":", ",", "12", ":", "20", "]", "\n", "input2", "[", "0", ",", ":", ",", "12", ":", "20", "]", "=", "input1", "[", "0", ",", ":", ",", "4", ":", "12", "]", "\n", "self", ".", "assertFalse", "(", "(", "input1", "==", "input2", ")", ".", "all", "(", ")", ")", "\n", "out2", "=", "net", ".", "model", ".", "predict", "(", "input2", ")", "\n", "self", ".", "assertTrue", "(", "(", "out1", "==", "out2", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn_window.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_cnn_dueling_network": [[108, 131], ["network_architecture.NetworkCNN", "test_network_architecture.Tester.assertTrue", "numpy.random.rand", "network_architecture.NetworkCNN.model.predict", "test_network_architecture.Tester.assertEqual", "numpy.random.rand", "network_architecture.NetworkCNN.model.predict", "numpy.copy", "test_network_architecture.Tester.assertFalse", "network_architecture.NetworkCNN.model.predict", "test_network_architecture.Tester.assertTrue", "keras.models.Model", "keras.models.Model.predict", "test_network_architecture.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.mean", "numpy.isclose().all", "numpy.isclose"], "methods", ["None"], ["", "def", "test_cnn_dueling_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "False", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "net_input", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "44", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "9", ")", ")", "\n", "input1", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "44", ")", "\n", "out1", "=", "net", ".", "model", ".", "predict", "(", "input1", ")", "\n", "input2", "=", "np", ".", "copy", "(", "input1", ")", "\n", "input2", "[", "0", ",", "0", ",", "4", ":", "12", "]", "=", "input1", "[", "0", ",", "0", ",", "12", ":", "20", "]", "\n", "input2", "[", "0", ",", "0", ",", "12", ":", "20", "]", "=", "input1", "[", "0", ",", "0", ",", "4", ":", "12", "]", "\n", "self", ".", "assertFalse", "(", "(", "input1", "==", "input2", ")", ".", "all", "(", ")", ")", "\n", "out2", "=", "net", ".", "model", ".", "predict", "(", "input2", ")", "\n", "self", ".", "assertTrue", "(", "(", "out1", "==", "out2", ")", ".", "all", "(", ")", ")", "\n", "\n", "before_dueling_layer", "=", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "layers", "[", "-", "2", "]", ".", "output", ")", "\n", "before_dueling_output", "=", "before_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "true_output", "=", "before_dueling_output", "[", ":", ",", "0", ",", "None", "]", "+", "before_dueling_output", "[", ":", ",", "1", ":", "]", "-", "np", ".", "mean", "(", "before_dueling_output", "[", ":", ",", "1", ":", ",", "None", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "out", ",", "true_output", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn_duel.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_cnn_dueling_prior": [[132, 165], ["network_architecture.NetworkCNN", "test_network_architecture.Tester.assertTrue", "numpy.random.rand", "network_architecture.NetworkCNN.model.predict", "test_network_architecture.Tester.assertEqual", "numpy.random.rand", "network_architecture.NetworkCNN.model.predict", "numpy.copy", "test_network_architecture.Tester.assertFalse", "network_architecture.NetworkCNN.model.predict", "test_network_architecture.Tester.assertTrue", "test_network_architecture.Tester.assertFalse", "network_architecture.NetworkCNN.model.get_config", "keras.models.Model", "keras.models.Model.predict", "keras.models.Model", "keras.models.Model.predict", "test_network_architecture.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "trainable.append", "all", "numpy.mean", "numpy.isclose().all", "network_architecture.NetworkCNN.model.get_layer", "network_architecture.NetworkCNN.model.get_layer", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "test_cnn_dueling_prior", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "net_input", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "44", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "9", ")", ")", "\n", "input1", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "44", ")", "\n", "out1", "=", "net", ".", "model", ".", "predict", "(", "input1", ")", "\n", "input2", "=", "np", ".", "copy", "(", "input1", ")", "\n", "input2", "[", "0", ",", "0", ",", "4", ":", "12", "]", "=", "input1", "[", "0", ",", "0", ",", "12", ":", "20", "]", "\n", "input2", "[", "0", ",", "0", ",", "12", ":", "20", "]", "=", "input1", "[", "0", ",", "0", ",", "4", ":", "12", "]", "\n", "self", ".", "assertFalse", "(", "(", "input1", "==", "input2", ")", ".", "all", "(", ")", ")", "\n", "out2", "=", "net", ".", "model", ".", "predict", "(", "input2", ")", "\n", "self", ".", "assertTrue", "(", "(", "out1", "==", "out2", ")", ".", "all", "(", ")", ")", "\n", "\n", "trainable", "=", "[", "]", "\n", "for", "layer", "in", "net", ".", "model", ".", "layers", ":", "\n", "            ", "trainable", ".", "append", "(", "layer", ".", "trainable", ")", "\n", "", "self", ".", "assertFalse", "(", "all", "(", "trainable", ")", ")", "# All layers should not be trainable", "\n", "net", ".", "model", ".", "get_config", "(", ")", "# This crashes for custom lambda layers", "\n", "\n", "before_dueling_layer", "=", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "\n", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'trainable_out_wo_dueling'", ")", ".", "output", ")", "\n", "before_dueling_output", "=", "before_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "after_dueling_layer", "=", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'trainable_out'", ")", ".", "output", ")", "\n", "after_dueling_output", "=", "after_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "true_dueling_output", "=", "before_dueling_output", "[", ":", ",", "0", ",", "None", "]", "+", "before_dueling_output", "[", ":", ",", "1", ":", "]", "-", "np", ".", "mean", "(", "before_dueling_output", "[", ":", ",", "1", ":", ",", "None", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "after_dueling_output", ",", "true_dueling_output", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn_duel_prior.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_trainable_weights_mlp": [[166, 193], ["network_architecture.NetworkMLP", "network_architecture.NetworkMLP.model.compile", "numpy.random.rand", "numpy.random.rand", "copy.deepcopy", "network_architecture.NetworkMLP.model.fit", "zip", "keras.backend.function", "keras.backend.function", "test_network_architecture.Tester.assertTrue", "keras.backend.function", "keras.backend.function", "test_network_architecture.Tester.assertTrue", "keras.backend.function.", "keras.backend.function.", "keras.backend.function.", "keras.backend.function.", "layer_init.get_weights", "layer.get_weights", "zip", "copy.deepcopy.get_layer", "copy.deepcopy.get_layer", "network_architecture.NetworkMLP.model.get_layer", "network_architecture.NetworkMLP.model.get_layer", "copy.deepcopy.get_layer", "copy.deepcopy.get_layer", "network_architecture.NetworkMLP.model.get_layer", "network_architecture.NetworkMLP.model.get_layer", "test_network_architecture.Tester.assertTrue", "tmp.all"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.fit"], ["", "def", "test_trainable_weights_mlp", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLP", "(", "5", ",", "3", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ")", "\n", "net", ".", "model", ".", "compile", "(", "loss", "=", "'mse'", ",", "optimizer", "=", "'adam'", ")", "\n", "x", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "1", ",", "5", ")", "\n", "y", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "3", ")", "\n", "initial_model", "=", "copy", ".", "deepcopy", "(", "net", ".", "model", ")", "\n", "net", ".", "model", ".", "fit", "(", "x", ",", "y", ",", "epochs", "=", "10", ",", "batch_size", "=", "100", ",", "verbose", "=", "0", ")", "\n", "for", "layer_init", ",", "layer", "in", "zip", "(", "initial_model", ".", "layers", ",", "net", ".", "model", ".", "layers", ")", ":", "\n", "            ", "if", "not", "layer", ".", "trainable", ":", "\n", "                ", "init_weights", "=", "layer_init", ".", "get_weights", "(", ")", "\n", "weights", "=", "layer", ".", "get_weights", "(", ")", "\n", "for", "row_init", ",", "row", "in", "zip", "(", "init_weights", ",", "weights", ")", ":", "\n", "                    ", "tmp", "=", "row_init", "==", "row", "\n", "self", ".", "assertTrue", "(", "tmp", ".", "all", "(", ")", ")", "\n", "", "", "", "get_prior_output_initial", "=", "K", ".", "function", "(", "initial_model", ".", "get_layer", "(", "'input'", ")", ".", "input", ",", "\n", "initial_model", ".", "get_layer", "(", "'prior_out'", ")", ".", "output", ")", "\n", "prior_out_initial", "=", "get_prior_output_initial", "(", "[", "x", "[", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "get_prior_output", "=", "K", ".", "function", "(", "net", ".", "model", ".", "get_layer", "(", "'input'", ")", ".", "input", ",", "net", ".", "model", ".", "get_layer", "(", "'prior_out'", ")", ".", "output", ")", "\n", "prior_out", "=", "get_prior_output", "(", "[", "x", "[", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "(", "prior_out_initial", "==", "prior_out", ")", ".", "all", "(", ")", ")", "\n", "get_trainable_output_initial", "=", "K", ".", "function", "(", "initial_model", ".", "get_layer", "(", "'input'", ")", ".", "input", ",", "\n", "initial_model", ".", "get_layer", "(", "'trainable_out'", ")", ".", "output", ")", "\n", "trainable_out_initial", "=", "get_trainable_output_initial", "(", "[", "x", "[", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "get_trainable_output", "=", "K", ".", "function", "(", "net", ".", "model", ".", "get_layer", "(", "'input'", ")", ".", "input", ",", "\n", "net", ".", "model", ".", "get_layer", "(", "'trainable_out'", ")", ".", "output", ")", "\n", "trainable_out", "=", "get_trainable_output", "(", "[", "x", "[", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "(", "trainable_out_initial", "!=", "trainable_out", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_trainable_weights_cnn": [[194, 223], ["network_architecture.NetworkCNN", "network_architecture.NetworkCNN.model.compile", "numpy.random.rand", "numpy.random.rand", "copy.deepcopy", "network_architecture.NetworkCNN.model.fit", "zip", "keras.backend.function", "keras.backend.function", "test_network_architecture.Tester.assertTrue", "keras.backend.function", "keras.backend.function", "test_network_architecture.Tester.assertTrue", "keras.backend.function.", "keras.backend.function.", "keras.backend.function.", "keras.backend.function.", "layer_init.get_weights", "layer.get_weights", "zip", "copy.deepcopy.get_layer", "copy.deepcopy.get_layer", "network_architecture.NetworkCNN.model.get_layer", "network_architecture.NetworkCNN.model.get_layer", "copy.deepcopy.get_layer", "copy.deepcopy.get_layer", "network_architecture.NetworkCNN.model.get_layer", "network_architecture.NetworkCNN.model.get_layer", "test_network_architecture.Tester.assertTrue", "tmp.all"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.fit"], ["", "def", "test_trainable_weights_cnn", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ")", "\n", "net", ".", "model", ".", "compile", "(", "loss", "=", "'mse'", ",", "optimizer", "=", "'adam'", ")", "\n", "x", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "1", ",", "44", ")", "\n", "y", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "9", ")", "\n", "initial_model", "=", "copy", ".", "deepcopy", "(", "net", ".", "model", ")", "\n", "net", ".", "model", ".", "fit", "(", "x", ",", "y", ",", "epochs", "=", "10", ",", "batch_size", "=", "100", ",", "verbose", "=", "0", ")", "\n", "for", "layer_init", ",", "layer", "in", "zip", "(", "initial_model", ".", "layers", ",", "net", ".", "model", ".", "layers", ")", ":", "\n", "            ", "if", "not", "layer", ".", "trainable", ":", "\n", "                ", "init_weights", "=", "layer_init", ".", "get_weights", "(", ")", "\n", "weights", "=", "layer", ".", "get_weights", "(", ")", "\n", "for", "row_init", ",", "row", "in", "zip", "(", "init_weights", ",", "weights", ")", ":", "\n", "                    ", "tmp", "=", "row_init", "==", "row", "\n", "self", ".", "assertTrue", "(", "tmp", ".", "all", "(", ")", ")", "\n", "", "", "", "get_prior_output_initial", "=", "K", ".", "function", "(", "initial_model", ".", "get_layer", "(", "'input'", ")", ".", "input", ",", "\n", "initial_model", ".", "get_layer", "(", "'prior_out'", ")", ".", "output", ")", "\n", "prior_out_initial", "=", "get_prior_output_initial", "(", "[", "x", "[", ":", "1", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "get_prior_output", "=", "K", ".", "function", "(", "net", ".", "model", ".", "get_layer", "(", "'input'", ")", ".", "input", ",", "net", ".", "model", ".", "get_layer", "(", "'prior_out'", ")", ".", "output", ")", "\n", "prior_out", "=", "get_prior_output", "(", "[", "x", "[", ":", "1", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "(", "prior_out_initial", "==", "prior_out", ")", ".", "all", "(", ")", ")", "\n", "get_trainable_output_initial", "=", "K", ".", "function", "(", "initial_model", ".", "get_layer", "(", "'input'", ")", ".", "input", ",", "\n", "initial_model", ".", "get_layer", "(", "'trainable_out'", ")", ".", "output", ")", "\n", "trainable_out_initial", "=", "get_trainable_output_initial", "(", "[", "x", "[", ":", "1", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "get_trainable_output", "=", "K", ".", "function", "(", "net", ".", "model", ".", "get_layer", "(", "'input'", ")", ".", "input", ",", "\n", "net", ".", "model", ".", "get_layer", "(", "'trainable_out'", ")", ".", "output", ")", "\n", "trainable_out", "=", "get_trainable_output", "(", "[", "x", "[", ":", "1", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "(", "trainable_out_initial", "!=", "trainable_out", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture.Tester.test_random_initialization": [[224, 247], ["network_architecture.NetworkCNN", "network_architecture.NetworkCNN", "zip", "test_network_architecture.Tester.assertFalse", "numpy.random.seed", "network_architecture.NetworkCNN", "numpy.random.seed", "network_architecture.NetworkCNN", "zip", "test_network_architecture.Tester.assertTrue", "network_architecture.NetworkCNN.model.get_weights", "network_architecture.NetworkCNN.model.get_weights", "network_architecture.NetworkCNN.model.get_weights", "network_architecture.NetworkCNN.model.get_weights"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed"], ["", "def", "test_random_initialization", "(", "self", ")", ":", "\n", "        ", "net1", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ")", "\n", "net2", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ")", "\n", "all_weights_equal", "=", "True", "\n", "for", "layer1", ",", "layer2", "in", "zip", "(", "net1", ".", "model", ".", "get_weights", "(", ")", ",", "net2", ".", "model", ".", "get_weights", "(", ")", ")", ":", "\n", "            ", "all_weights_equal", "=", "all_weights_equal", "and", "(", "layer1", "==", "layer2", ")", ".", "all", "(", ")", "\n", "", "self", ".", "assertFalse", "(", "all_weights_equal", ")", "\n", "np", ".", "random", ".", "seed", "(", "34", ")", "\n", "net1", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ")", "\n", "np", ".", "random", ".", "seed", "(", "34", ")", "\n", "net2", "=", "NetworkCNN", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ")", "\n", "all_weights_equal", "=", "True", "\n", "for", "layer1", ",", "layer2", "in", "zip", "(", "net1", ".", "model", ".", "get_weights", "(", ")", ",", "net2", ".", "model", ".", "get_weights", "(", ")", ")", ":", "\n", "            ", "all_weights_equal", "=", "all_weights_equal", "and", "(", "layer1", "==", "layer2", ")", ".", "all", "(", ")", "\n", "", "self", ".", "assertTrue", "(", "all_weights_equal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.__init__": [[10, 16], ["unittest.TestCase.__init__", "memory.BootstrappingMemory"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "limit", "=", "1000", "\n", "self", ".", "adding_prob", "=", "0.5", "\n", "self", ".", "nb_nets", "=", "10", "\n", "self", ".", "memory", "=", "BootstrappingMemory", "(", "self", ".", "nb_nets", ",", "self", ".", "limit", ",", "adding_prob", "=", "self", ".", "adding_prob", ",", "window_length", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.test_init": [[17, 21], ["test_replay_memory.Tester.memory.get_config", "test_replay_memory.Tester.assertEqual", "test_replay_memory.Tester.assertTrue"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "test_init", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "memory", ".", "get_config", "(", ")", "\n", "self", ".", "assertEqual", "(", "config", "[", "'limit'", "]", ",", "self", ".", "limit", ")", "\n", "self", ".", "assertTrue", "(", "self", ".", "memory", ".", "nb_entries", "==", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append": [[22, 27], ["range", "test_replay_memory.Tester.memory.append", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "def", "append", "(", "self", ",", "nb_samples", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "nb_samples", ")", ":", "\n", "            ", "observation", ",", "action", ",", "reward", ",", "terminal", "=", "np", ".", "random", ".", "rand", "(", ")", ",", "np", ".", "random", ".", "rand", "(", ")", ",", "np", ".", "random", ".", "rand", "(", ")", ",", "np", ".", "random", ".", "rand", "(", ")", "<", "0.1", "\n", "self", ".", "memory", ".", "append", "(", "observation", ",", "action", ",", "reward", ",", "terminal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.test_append": [[28, 36], ["memory.BootstrappingMemory", "int", "test_replay_memory.Tester.append", "test_replay_memory.Tester.assertEqual", "range", "test_replay_memory.Tester.assertLess", "numpy.abs", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "", "def", "test_append", "(", "self", ")", ":", "\n", "        ", "self", ".", "memory", "=", "BootstrappingMemory", "(", "self", ".", "nb_nets", ",", "self", ".", "limit", ",", "adding_prob", "=", "self", ".", "adding_prob", ",", "window_length", "=", "1", ")", "\n", "nb_samples", "=", "int", "(", "self", ".", "limit", "/", "2", ")", "\n", "self", ".", "append", "(", "nb_samples", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "memory", ".", "nb_entries", ",", "nb_samples", ")", "\n", "# This test should fail with a low probability", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_nets", ")", ":", "\n", "            ", "self", ".", "assertLess", "(", "np", ".", "abs", "(", "self", ".", "adding_prob", "-", "len", "(", "self", ".", "memory", ".", "index_refs", "[", "i", "]", ")", "/", "nb_samples", ")", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.test_append_full_memory": [[37, 45], ["memory.BootstrappingMemory", "int", "test_replay_memory.Tester.append", "test_replay_memory.Tester.assertEqual", "range", "test_replay_memory.Tester.assertAlmostEqual", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "", "def", "test_append_full_memory", "(", "self", ")", ":", "\n", "        ", "self", ".", "memory", "=", "BootstrappingMemory", "(", "self", ".", "nb_nets", ",", "self", ".", "limit", ",", "adding_prob", "=", "self", ".", "adding_prob", ",", "window_length", "=", "1", ")", "\n", "nb_samples", "=", "int", "(", "self", ".", "limit", "*", "9.5", ")", "\n", "self", ".", "append", "(", "nb_samples", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "memory", ".", "nb_entries", ",", "self", ".", "limit", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_nets", ")", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "self", ".", "limit", "*", "self", ".", "adding_prob", "/", "(", "self", ".", "limit", "/", "10", ")", ",", "\n", "len", "(", "self", ".", "memory", ".", "index_refs", "[", "i", "]", ")", "/", "(", "self", ".", "limit", "/", "10", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.test_get_recent_state": [[46, 50], ["test_replay_memory.Tester.memory.get_recent_state", "test_replay_memory.Tester.assertEqual"], "methods", ["None"], ["", "", "def", "test_get_recent_state", "(", "self", ")", ":", "\n", "        ", "state_in", "=", "5", "\n", "state_out", "=", "self", ".", "memory", ".", "get_recent_state", "(", "state_in", ")", "\n", "self", ".", "assertEqual", "(", "[", "state_in", "]", ",", "state_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.test_sample": [[51, 56], ["int", "test_replay_memory.Tester.append", "test_replay_memory.Tester.memory.sample", "test_replay_memory.Tester.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample"], ["", "def", "test_sample", "(", "self", ")", ":", "\n", "        ", "nb_samples", "=", "int", "(", "self", ".", "limit", "*", "1.5", ")", "\n", "self", ".", "append", "(", "nb_samples", ")", "\n", "sample", "=", "self", ".", "memory", ".", "sample", "(", "net", "=", "5", ",", "batch_size", "=", "32", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "sample", ")", ",", "32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.test_window_length": [[57, 65], ["memory.BootstrappingMemory", "int", "test_replay_memory.Tester.append", "test_replay_memory.Tester.memory.sample", "test_replay_memory.Tester.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.sample"], ["", "def", "test_window_length", "(", "self", ")", ":", "\n", "        ", "window_length", "=", "5", "\n", "self", ".", "memory", "=", "BootstrappingMemory", "(", "self", ".", "nb_nets", ",", "self", ".", "limit", ",", "adding_prob", "=", "self", ".", "adding_prob", ",", "\n", "window_length", "=", "window_length", ")", "\n", "nb_samples", "=", "int", "(", "self", ".", "limit", "*", "1.5", ")", "\n", "self", ".", "append", "(", "nb_samples", ")", "\n", "sample", "=", "self", ".", "memory", ".", "sample", "(", "net", "=", "5", ",", "batch_size", "=", "32", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "sample", ")", ",", "32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.__init__": [[12, 46], ["unittest.TestCase.__init__", "policy.DistributionalEpsGreedyPolicy", "policy.DistributionalEnsembleTestPolicy", "memory.BootstrappingMemory.BootstrappingMemory", "iqn_ensemble.IqnRpfAgentParallel"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "nb_nets", "=", "3", "\n", "greedy_policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0", ")", "\n", "test_policy", "=", "DistributionalEnsembleTestPolicy", "(", ")", "\n", "memory", "=", "BootstrappingMemory", "(", "nb_nets", "=", "self", ".", "nb_nets", ",", "limit", "=", "10000", ",", "adding_prob", "=", "0.5", ",", "window_length", "=", "1", ")", "\n", "self", ".", "agent", "=", "IqnRpfAgentParallel", "(", "nb_models", "=", "self", ".", "nb_nets", ",", "\n", "nb_actions", "=", "4", ",", "\n", "memory", "=", "memory", ",", "\n", "cnn_architecture", "=", "True", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "nb_ego_states", "=", "1", ",", "\n", "nb_states_per_vehicle", "=", "3", ",", "\n", "nb_vehicles", "=", "3", ",", "\n", "nb_conv_layers", "=", "2", ",", "\n", "nb_conv_filters", "=", "32", ",", "\n", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "\n", "nb_cos_embeddings", "=", "64", ",", "\n", "network_seed", "=", "13", ",", "\n", "policy", "=", "greedy_policy", ",", "test_policy", "=", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "enable_dueling_dqn", "=", "True", ",", "\n", "nb_samples_policy", "=", "32", ",", "\n", "nb_sampled_quantiles", "=", "32", ",", "\n", "cvar_eta", "=", "1", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "64", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "window_length", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "10", ",", "\n", "prior_scale_factor", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.test_sample_tau_values": [[47, 69], ["test_iqn_ensemble_parallel.Tester.agent.sample_tau_values", "test_iqn_ensemble_parallel.Tester.assertEqual", "test_iqn_ensemble_parallel.Tester.assertTrue", "test_iqn_ensemble_parallel.Tester.assertTrue", "test_iqn_ensemble_parallel.Tester.agent.compute_sampled_z_values", "test_iqn_ensemble_parallel.Tester.assertEqual", "test_iqn_ensemble_parallel.Tester.assertTrue", "test_iqn_ensemble_parallel.Tester.assertTrue", "test_iqn_ensemble_parallel.Tester.agent.sample_tau_values", "test_iqn_ensemble_parallel.Tester.assertEqual", "test_iqn_ensemble_parallel.Tester.assertEqual", "numpy.diff", "test_iqn_ensemble_parallel.Tester.assertTrue", "numpy.random.rand", "numpy.isclose().all", "worker.terminate", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values"], ["", "def", "test_sample_tau_values", "(", "self", ")", ":", "\n", "        ", "tau", "=", "self", ".", "agent", ".", "sample_tau_values", "(", "max_tau", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "size", ",", "32", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", "<", "1", ")", ".", "all", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", ">", "0", ")", ".", "all", ")", "\n", "\n", "# Risk sensitive policy", "\n", "state", "=", "[", "np", ".", "random", ".", "rand", "(", "10", ")", "]", "\n", "z_values", ",", "tau", "=", "self", ".", "agent", ".", "compute_sampled_z_values", "(", "state", ",", "max_tau", "=", "0.25", ",", "net", "=", "0", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "size", ",", "32", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", "<", "0.25", ")", ".", "all", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", ">", "0", ")", ".", "all", ")", "\n", "\n", "# Uniform sampling", "\n", "max_tau", "=", "0.5", "\n", "tau", "=", "self", ".", "agent", ".", "sample_tau_values", "(", "max_tau", "=", "max_tau", ",", "uniform", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "tau", "[", "0", ",", "0", ",", "0", "]", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "tau", "[", "0", ",", "0", ",", "-", "1", "]", ",", "max_tau", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "tau", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "\n", "[", "worker", ".", "terminate", "(", ")", "for", "worker", "in", "self", ".", "agent", ".", "workers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.test_compute_sampled_z_values": [[70, 79], ["test_iqn_ensemble_parallel.Tester.agent.compute_sampled_z_values", "test_iqn_ensemble_parallel.Tester.assertEqual", "test_iqn_ensemble_parallel.Tester.assertEqual", "numpy.diff", "test_iqn_ensemble_parallel.Tester.assertFalse", "numpy.random.rand", "numpy.isclose().all", "worker.terminate", "numpy.random.randint", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values"], ["", "def", "test_compute_sampled_z_values", "(", "self", ")", ":", "\n", "        ", "state", "=", "[", "np", ".", "random", ".", "rand", "(", "10", ")", "]", "\n", "z_values", ",", "tau", "=", "self", ".", "agent", ".", "compute_sampled_z_values", "(", "state", ",", "max_tau", "=", "1", ",", "net", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "nb_nets", ")", ")", "\n", "self", ".", "assertEqual", "(", "z_values", ".", "shape", ",", "(", "1", ",", "self", ".", "agent", ".", "nb_sampled_quantiles", ",", "self", ".", "agent", ".", "nb_actions", ")", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "shape", ",", "(", "1", ",", "1", ",", "32", ")", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "tau", ")", "\n", "self", ".", "assertFalse", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use random sampling", "\n", "\n", "[", "worker", ".", "terminate", "(", ")", "for", "worker", "in", "self", ".", "agent", ".", "workers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.test_compute_z_values_all_nets": [[80, 89], ["test_iqn_ensemble_parallel.Tester.agent.compute_z_values_all_nets", "test_iqn_ensemble_parallel.Tester.assertEqual", "test_iqn_ensemble_parallel.Tester.assertEqual", "numpy.diff", "test_iqn_ensemble_parallel.Tester.assertTrue", "numpy.random.rand", "numpy.isclose().all", "worker.terminate", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.compute_z_values_all_nets"], ["", "def", "test_compute_z_values_all_nets", "(", "self", ")", ":", "\n", "        ", "state", "=", "[", "np", ".", "random", ".", "rand", "(", "10", ")", "]", "\n", "z_values_all_nets", ",", "tau", "=", "self", ".", "agent", ".", "compute_z_values_all_nets", "(", "state", ",", "max_tau", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "z_values_all_nets", ".", "shape", ",", "(", "self", ".", "nb_nets", ",", "self", ".", "agent", ".", "nb_sampled_quantiles", ",", "self", ".", "agent", ".", "nb_actions", ")", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "shape", ",", "(", "1", ",", "1", ",", "32", ")", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "tau", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use uniform sampling", "\n", "\n", "[", "worker", ".", "terminate", "(", ")", "for", "worker", "in", "self", ".", "agent", ".", "workers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.test_forward": [[90, 107], ["numpy.random.rand", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.assertGreaterEqual", "test_iqn_ensemble_parallel.Tester.assertLess", "numpy.diff", "test_iqn_ensemble_parallel.Tester.assertFalse", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.assertGreaterEqual", "test_iqn_ensemble_parallel.Tester.assertLess", "numpy.diff", "test_iqn_ensemble_parallel.Tester.assertTrue", "numpy.isclose().all", "numpy.isclose().all", "worker.terminate", "numpy.isclose", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward"], ["", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "action", ",", "info", "=", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "assertGreaterEqual", "(", "action", ",", "0", ")", "\n", "self", ".", "assertLess", "(", "action", ",", "4", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "info", "[", "'quantiles'", "]", ")", "\n", "self", ".", "assertFalse", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use random sampling", "\n", "\n", "self", ".", "agent", ".", "training", "=", "False", "\n", "action", ",", "info", "=", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "assertGreaterEqual", "(", "action", ",", "0", ")", "\n", "self", ".", "assertLess", "(", "action", ",", "4", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "info", "[", "'quantiles'", "]", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use uniform sampling", "\n", "\n", "[", "worker", ".", "terminate", "(", ")", "for", "worker", "in", "self", ".", "agent", ".", "workers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.test_backward": [[108, 124], ["range", "numpy.random.rand", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "range", "numpy.random.rand", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "numpy.random.rand", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "worker.terminate"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_backward", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "training", "=", "True", "\n", "for", "_", "in", "range", "(", "0", ",", "1000", ")", ":", "# Fill up buffer", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "\n", "", "[", "worker", ".", "terminate", "(", ")", "for", "worker", "in", "self", ".", "agent", ".", "workers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.test_training": [[125, 156], ["numpy.random.rand", "numpy.random.rand", "range", "range", "range", "test_iqn_ensemble_parallel.Tester.assertTrue", "test_iqn_ensemble_parallel.Tester.assertTrue", "range", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "range", "range", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.assertTrue", "test_iqn_ensemble_parallel.Tester.assertTrue", "worker.terminate", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "numpy.round", "numpy.round", "numpy.mean", "numpy.mean", "numpy.round", "numpy.round", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_training", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "training", "=", "True", "\n", "obs1", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "obs2", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "for", "_", "in", "range", "(", "0", ",", "500", ")", ":", "# Fill up buffer", "\n", "            ", "self", ".", "agent", ".", "forward", "(", "obs1", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "for", "_", "in", "range", "(", "0", ",", "500", ")", ":", "# Fill up buffer", "\n", "            ", "self", ".", "agent", ".", "forward", "(", "obs2", ")", "\n", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "for", "_", "in", "range", "(", "30", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "action1", ",", "action_info1", "=", "self", ".", "agent", ".", "forward", "(", "obs1", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "action2", ",", "action_info2", "=", "self", ".", "agent", ".", "forward", "(", "obs2", ")", "\n", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "False", ")", "\n", "# Since actions are picked greedily, only one Q-value is expected to converge to the correct value", "\n", "", "", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info1", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "0", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info2", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "10", ")", ".", "any", "(", ")", ")", "\n", "\n", "# All nets should be trained", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_nets", ")", ":", "\n", "            ", "self", ".", "agent", ".", "active_model", "=", "i", "\n", "action1", ",", "action_info1", "=", "self", ".", "agent", ".", "forward", "(", "obs1", ")", "\n", "action2", ",", "action_info2", "=", "self", ".", "agent", ".", "forward", "(", "obs2", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info1", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "0", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info2", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "10", ")", ".", "any", "(", ")", ")", "\n", "\n", "", "[", "worker", ".", "terminate", "(", ")", "for", "worker", "in", "self", ".", "agent", ".", "workers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.test_no_double_dqn": [[157, 175], ["range", "numpy.random.rand", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "range", "numpy.random.rand", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "numpy.random.rand", "test_iqn_ensemble_parallel.Tester.agent.forward", "test_iqn_ensemble_parallel.Tester.agent.backward", "worker.terminate"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_no_double_dqn", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "enable_double_dqn", "=", "False", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "for", "_", "in", "range", "(", "0", ",", "1000", ")", ":", "# Fill up buffer", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "enable_double_dqn", "=", "True", "\n", "\n", "[", "worker", ".", "terminate", "(", ")", "for", "worker", "in", "self", ".", "agent", ".", "workers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble_parallel.Tester.test_get_config": [[176, 180], ["test_iqn_ensemble_parallel.Tester.agent.get_config", "worker.terminate"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "test_get_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "get_config", "(", ")", "\n", "\n", "[", "worker", ".", "terminate", "(", ")", "for", "worker", "in", "self", ".", "agent", ".", "workers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.__init__": [[16, 39], ["unittest.TestCase.__init__", "rl.policy.LinearAnnealedPolicy", "policy.DistributionalEpsGreedyPolicy", "rl.memory.SequentialMemory", "iqn.IQNAgent", "network_architecture_distributional.NetworkCNNDistributional", "policy.DistributionalEpsGreedyPolicy"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "model", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "1", ",", "nb_states_per_vehicle", "=", "3", ",", "nb_vehicles", "=", "3", ",", "nb_actions", "=", "4", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "True", ",", "prior", "=", "False", ",", "\n", "nb_quantiles", "=", "32", ",", "nb_cos_embeddings", "=", "64", ")", ".", "model", "\n", "self", ".", "policy", "=", "LinearAnnealedPolicy", "(", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "None", ")", ",", "attr", "=", "'eps'", ",", "value_max", "=", "1.", ",", "\n", "value_min", "=", "0.1", ",", "value_test", "=", ".0", ",", "\n", "nb_steps", "=", "10000", ")", "\n", "self", ".", "test_policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0", ")", "\n", "self", ".", "memory", "=", "SequentialMemory", "(", "limit", "=", "10000", ",", "window_length", "=", "1", ")", "\n", "self", ".", "agent", "=", "IQNAgent", "(", "model", "=", "self", ".", "model", ",", "policy", "=", "self", ".", "policy", ",", "test_policy", "=", "self", ".", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "nb_samples_policy", "=", "32", ",", "\n", "nb_sampled_quantiles", "=", "32", ",", "\n", "cvar_eta", "=", "1", ",", "\n", "nb_actions", "=", "4", ",", "memory", "=", "self", ".", "memory", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "64", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_sample_tau_values": [[40, 60], ["test_iqn.Tester.agent.sample_tau_values", "test_iqn.Tester.assertEqual", "test_iqn.Tester.assertTrue", "test_iqn.Tester.assertTrue", "test_iqn.Tester.agent.compute_sampled_z_values", "test_iqn.Tester.assertEqual", "test_iqn.Tester.assertTrue", "test_iqn.Tester.assertTrue", "test_iqn.Tester.agent.sample_tau_values", "test_iqn.Tester.assertEqual", "test_iqn.Tester.assertEqual", "numpy.diff", "test_iqn.Tester.assertTrue", "numpy.random.rand", "numpy.isclose().all", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values"], ["", "def", "test_sample_tau_values", "(", "self", ")", ":", "\n", "        ", "tau", "=", "self", ".", "agent", ".", "sample_tau_values", "(", "max_tau", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "size", ",", "32", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", "<", "1", ")", ".", "all", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", ">", "0", ")", ".", "all", ")", "\n", "\n", "# Risk sensitive policy", "\n", "state", "=", "[", "np", ".", "random", ".", "rand", "(", "10", ")", "]", "\n", "z_values", ",", "tau", "=", "self", ".", "agent", ".", "compute_sampled_z_values", "(", "state", ",", "max_tau", "=", "0.25", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "size", ",", "32", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", "<", "0.25", ")", ".", "all", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", ">", "0", ")", ".", "all", ")", "\n", "\n", "# Uniform sampling", "\n", "max_tau", "=", "0.5", "\n", "tau", "=", "self", ".", "agent", ".", "sample_tau_values", "(", "max_tau", "=", "max_tau", ",", "uniform", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "tau", "[", "0", ",", "0", ",", "0", "]", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "tau", "[", "0", ",", "0", ",", "-", "1", "]", ",", "max_tau", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "tau", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_compute_sampled_z_values": [[61, 69], ["test_iqn.Tester.agent.compute_sampled_z_values", "test_iqn.Tester.assertEqual", "test_iqn.Tester.assertEqual", "numpy.diff", "test_iqn.Tester.assertFalse", "numpy.random.rand", "numpy.isclose().all", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values"], ["", "def", "test_compute_sampled_z_values", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "training", "=", "True", "\n", "state", "=", "[", "np", ".", "random", ".", "rand", "(", "10", ")", "]", "\n", "z_values", ",", "tau", "=", "self", ".", "agent", ".", "compute_sampled_z_values", "(", "state", ",", "max_tau", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "z_values", ".", "shape", ",", "(", "1", ",", "self", ".", "agent", ".", "nb_sampled_quantiles", ",", "self", ".", "agent", ".", "nb_actions", ")", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "shape", ",", "(", "1", ",", "1", ",", "32", ")", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "tau", ")", "\n", "self", ".", "assertFalse", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use random sampling", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_forward": [[70, 85], ["numpy.random.rand", "test_iqn.Tester.agent.forward", "test_iqn.Tester.assertGreaterEqual", "test_iqn.Tester.assertLess", "numpy.diff", "test_iqn.Tester.assertFalse", "test_iqn.Tester.agent.forward", "test_iqn.Tester.assertGreaterEqual", "test_iqn.Tester.assertLess", "numpy.diff", "test_iqn.Tester.assertTrue", "numpy.isclose().all", "numpy.isclose().all", "numpy.isclose", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward"], ["", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "action", ",", "info", "=", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "assertGreaterEqual", "(", "action", ",", "0", ")", "\n", "self", ".", "assertLess", "(", "action", ",", "4", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "info", "[", "'quantiles'", "]", ")", "\n", "self", ".", "assertFalse", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use random sampling", "\n", "\n", "self", ".", "agent", ".", "training", "=", "False", "\n", "action", ",", "info", "=", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "assertGreaterEqual", "(", "action", ",", "0", ")", "\n", "self", ".", "assertLess", "(", "action", ",", "4", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "info", "[", "'quantiles'", "]", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use uniform sampling", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_compile": [[86, 88], ["test_iqn.Tester.agent.compile", "keras.optimizers.Adam"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "test_compile", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_backward": [[89, 106], ["test_iqn.Tester.agent.compile", "range", "numpy.random.rand", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward", "range", "keras.utils.plot_model", "keras.optimizers.Adam", "numpy.random.rand", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward", "numpy.random.rand", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_backward", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "for", "_", "in", "range", "(", "0", ",", "1000", ")", ":", "# Fill up buffer", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "\n", "", "plot_model", "(", "self", ".", "agent", ".", "trainable_model", ",", "to_file", "=", "'trainable_model.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_training": [[107, 128], ["test_iqn.Tester.agent.compile", "numpy.random.rand", "numpy.random.rand", "range", "range", "range", "test_iqn.Tester.assertTrue", "test_iqn.Tester.assertTrue", "keras.optimizers.Adam", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward", "range", "range", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward", "numpy.round", "numpy.round", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_training", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.001", ")", ")", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "obs1", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "obs2", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "for", "_", "in", "range", "(", "0", ",", "500", ")", ":", "# Fill up buffer", "\n", "            ", "self", ".", "agent", ".", "forward", "(", "obs1", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "for", "_", "in", "range", "(", "0", ",", "500", ")", ":", "# Fill up buffer", "\n", "            ", "self", ".", "agent", ".", "forward", "(", "obs2", ")", "\n", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "for", "_", "in", "range", "(", "30", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "action1", ",", "action_info1", "=", "self", ".", "agent", ".", "forward", "(", "obs1", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "action2", ",", "action_info2", "=", "self", ".", "agent", ".", "forward", "(", "obs2", ")", "\n", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "False", ")", "\n", "", "", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info1", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "0", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info2", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "10", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_trainable_model": [[129, 207], ["rl.policy.LinearAnnealedPolicy", "rl.policy.LinearAnnealedPolicy.DistributionalEpsGreedyPolicy", "rl.memory.SequentialMemory", "iqn.IQNAgent", "iqn.IQNAgent.compile", "keras.utils.plot_model", "numpy.random.rand", "numpy.random.randint", "numpy.random.rand", "numpy.random.rand", "iqn.IQNAgent.model.predict_on_batch", "numpy.zeros", "range", "numpy.zeros", "numpy.zeros", "iqn.IQNAgent.trainable_model.predict_on_batch", "test_iqn.Tester.assertTrue", "test_iqn.Tester.assertTrue", "iqn.IQNAgent.trainable_model.train_on_batch", "test_iqn.Tester.assertTrue", "numpy.mean", "numpy.mean", "test_iqn.Tester.assertTrue", "test_iqn.Tester.assertTrue", "network_architecture_distributional.NetworkMLPDistributional", "rl.policy.LinearAnnealedPolicy.DistributionalEpsGreedyPolicy", "keras.optimizers.Adam", "range", "numpy.isclose().all", "numpy.isclose", "numpy.max", "numpy.isclose", "numpy.isclose", "numpy.abs", "Exception", "range", "numpy.mean", "numpy.mean", "test_iqn.Tester.test_trainable_model.huber"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "test_trainable_model", "(", "self", ")", ":", "\n", "        ", "nb_inputs", "=", "10", "\n", "nb_actions", "=", "5", "\n", "nb_quantiles", "=", "32", "\n", "batch_size", "=", "64", "\n", "delta_clip", "=", "1", "\n", "model", "=", "NetworkMLPDistributional", "(", "nb_inputs", "=", "nb_inputs", ",", "nb_outputs", "=", "nb_actions", ",", "nb_hidden_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "nb_quantiles", "=", "nb_quantiles", ",", "\n", "nb_cos_embeddings", "=", "64", ",", "duel", "=", "True", ",", "\n", "prior", "=", "False", ",", "activation", "=", "'relu'", ",", "duel_type", "=", "'avg'", ",", "\n", "window_length", "=", "1", ")", ".", "model", "\n", "policy", "=", "LinearAnnealedPolicy", "(", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "None", ")", ",", "attr", "=", "'eps'", ",", "value_max", "=", "1.", ",", "\n", "value_min", "=", "0.1", ",", "value_test", "=", ".0", ",", "\n", "nb_steps", "=", "10000", ")", "\n", "test_policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0", ")", "\n", "memory", "=", "SequentialMemory", "(", "limit", "=", "10000", ",", "window_length", "=", "1", ")", "\n", "agent", "=", "IQNAgent", "(", "model", "=", "model", ",", "policy", "=", "policy", ",", "test_policy", "=", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "nb_samples_policy", "=", "nb_quantiles", ",", "\n", "nb_sampled_quantiles", "=", "nb_quantiles", ",", "\n", "cvar_eta", "=", "1", ",", "\n", "nb_actions", "=", "nb_actions", ",", "memory", "=", "memory", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "1", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "delta_clip", ")", "\n", "\n", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "plot_model", "(", "agent", ".", "trainable_model", ",", "to_file", "=", "'trainable_model_2.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n", "# Test input", "\n", "states", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "1", ",", "nb_inputs", ")", "\n", "actions", "=", "np", ".", "random", ".", "randint", "(", "nb_actions", ",", "size", "=", "batch_size", ")", "\n", "quantiles", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "1", ",", "nb_quantiles", ")", "\n", "targets", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "nb_quantiles", ")", "\n", "\n", "predictions", "=", "agent", ".", "model", ".", "predict_on_batch", "(", "[", "states", ",", "quantiles", "]", ")", "\n", "\n", "def", "huber", "(", "deltas", ",", "quantile", ")", ":", "\n", "            ", "if", "np", ".", "abs", "(", "deltas", ")", "<", "delta_clip", ":", "\n", "                ", "loss", "=", "0.5", "*", "deltas", "**", "2", "\n", "", "else", ":", "\n", "                ", "loss", "=", "delta_clip", "*", "(", "np", ".", "abs", "(", "deltas", ")", "-", "0.5", "*", "delta_clip", ")", "\n", "", "if", "deltas", ">", "0", ":", "\n", "                ", "loss", "*=", "quantile", "/", "delta_clip", "\n", "", "else", ":", "\n", "                ", "loss", "*=", "(", "1", "-", "quantile", ")", "/", "delta_clip", "\n", "", "if", "loss", "<", "0", ":", "\n", "                ", "raise", "Exception", "(", "\"Loss should always be positive\"", ")", "\n", "", "return", "loss", "\n", "\n", "", "true_loss", "=", "np", ".", "zeros", "(", "batch_size", ")", "\n", "for", "idx", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "nb_quantiles", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "nb_quantiles", ")", ":", "\n", "                    ", "true_loss", "[", "idx", "]", "+=", "huber", "(", "targets", "[", "idx", ",", "j", "]", "-", "predictions", "[", "idx", ",", "i", ",", "actions", "[", "idx", "]", "]", ",", "\n", "quantiles", "[", "idx", ",", "0", ",", "i", "]", ")", "\n", "", "", "true_loss", "[", "idx", "]", "*=", "1", "/", "nb_quantiles", "\n", "\n", "", "masks", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "nb_actions", ")", ")", "\n", "masks", "[", "range", "(", "batch_size", ")", ",", "actions", "]", "=", "1", "\n", "targets_expanded", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "nb_quantiles", ",", "nb_actions", ")", ")", "\n", "targets_expanded", "[", "range", "(", "batch_size", ")", ",", ":", ",", "actions", "]", "=", "targets", "[", "range", "(", "batch_size", ")", ",", ":", "]", "\n", "out", "=", "agent", ".", "trainable_model", ".", "predict_on_batch", "(", "[", "states", ",", "quantiles", ",", "targets_expanded", ",", "masks", "]", ")", "\n", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "true_loss", ",", "out", "[", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "predictions", "==", "out", "[", "1", "]", ")", ".", "all", "(", ")", ")", "\n", "\n", "metrics", "=", "agent", ".", "trainable_model", ".", "train_on_batch", "(", "[", "states", ",", "quantiles", ",", "targets_expanded", ",", "masks", "]", ",", "\n", "[", "targets", ",", "targets_expanded", "]", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "np", ".", "mean", "(", "true_loss", ")", ",", "metrics", "[", "0", "]", ")", ")", "\n", "\n", "average_q_value", "=", "np", ".", "mean", "(", "predictions", ")", "\n", "average_max_q_value", "=", "np", ".", "mean", "(", "np", ".", "max", "(", "np", ".", "mean", "(", "predictions", ",", "axis", "=", "1", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "average_q_value", ",", "metrics", "[", "3", "]", ")", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "average_max_q_value", ",", "metrics", "[", "4", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_no_double_dqn": [[208, 225], ["test_iqn.Tester.agent.compile", "range", "numpy.random.rand", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward", "range", "keras.optimizers.Adam", "numpy.random.rand", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward", "numpy.random.rand", "test_iqn.Tester.agent.forward", "test_iqn.Tester.agent.backward"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_no_double_dqn", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "self", ".", "agent", ".", "enable_double_dqn", "=", "False", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "for", "_", "in", "range", "(", "0", ",", "1000", ")", ":", "# Fill up buffer", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "enable_double_dqn", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn.Tester.test_get_config": [[226, 228], ["test_iqn.Tester.agent.get_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "test_get_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "get_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_distributional_ensemble_policy.Tester.test_standard": [[11, 27], ["policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy", "range", "numpy.random.rand", "numpy.random.randint", "range", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertTrue", "numpy.random.rand", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["    ", "def", "test_standard", "(", "self", ")", ":", "\n", "        ", "policy", "=", "DistributionalEnsembleTestPolicy", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "100", ")", ":", "\n", "            ", "z_values_all_nets", "=", "np", ".", "random", ".", "rand", "(", "10", ",", "32", ",", "4", ")", "\n", "z_values_all_nets", "[", ":", ",", ":", ",", "0", "]", "+=", "1", "# Action 0 should then be 'best'", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", "=", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "0", ")", "\n", "\n", "# Test for batch", "\n", "", "z_values_all_nets", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "10", ",", "32", ",", "4", ")", "\n", "best_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "4", ",", "32", ")", "\n", "for", "batch", "in", "range", "(", "0", ",", "32", ")", ":", "\n", "            ", "idx", "=", "best_idx", "[", "batch", "]", "\n", "z_values_all_nets", "[", "batch", ",", ":", ",", ":", ",", "idx", "]", "+=", "1", "\n", "", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", "=", "z_values_all_nets", ")", "\n", "self", ".", "assertTrue", "(", "(", "action", "==", "best_idx", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_distributional_ensemble_policy.Tester.test_safe_policy": [[28, 91], ["policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertFalse", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertFalse", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertTrue", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertFalse", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertFalse", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertTrue", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertFalse", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertTrue", "numpy.ones", "policy.DistributionalEnsembleTestPolicy.DistributionalEnsembleTestPolicy.select_action", "test_distributional_ensemble_policy.Tester.assertEqual", "test_distributional_ensemble_policy.Tester.assertTrue"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["", "def", "test_safe_policy", "(", "self", ")", ":", "\n", "        ", "policy", "=", "DistributionalEnsembleTestPolicy", "(", "aleatoric_threshold", "=", "0.1", ")", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", "...", ",", "2", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "2", ")", "\n", "self", ".", "assertFalse", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", "0", ":", "5", ",", ":", ",", "2", "]", "*=", "100", "\n", "z_values_all_nets", "[", "...", ",", "3", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "2", ")", "\n", "self", ".", "assertFalse", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", ":", ",", "0", ":", "10", ",", "2", "]", "*=", "100", "\n", "z_values_all_nets", "[", "...", ",", "3", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "4", ")", "\n", "self", ".", "assertTrue", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "policy", "=", "DistributionalEnsembleTestPolicy", "(", "epistemic_threshold", "=", "0.1", ")", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", "...", ",", "2", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "2", ")", "\n", "self", ".", "assertFalse", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", ":", ",", "0", ":", "10", ",", "2", "]", "*=", "100", "\n", "z_values_all_nets", "[", "...", ",", "3", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "2", ")", "\n", "self", ".", "assertFalse", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", "0", ":", "5", ",", ":", ",", ":", "2", "]", "*=", "100", "\n", "z_values_all_nets", "[", "...", ",", "3", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "4", ")", "\n", "self", ".", "assertTrue", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "policy", "=", "DistributionalEnsembleTestPolicy", "(", "aleatoric_threshold", "=", "0.1", ",", "epistemic_threshold", "=", "0.1", ")", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", "...", ",", "2", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "2", ")", "\n", "self", ".", "assertFalse", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", ":", ",", "0", ":", "10", ",", "2", "]", "*=", "100", "\n", "z_values_all_nets", "[", "...", ",", "3", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "4", ")", "\n", "self", ".", "assertTrue", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "z_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "32", ",", "4", "]", ")", "\n", "z_values_all_nets", "[", "0", ":", "5", ",", ":", ",", ":", "2", "]", "*=", "100", "\n", "z_values_all_nets", "[", "...", ",", "3", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "z_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "4", ")", "\n", "self", ".", "assertTrue", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.__init__": [[14, 16], ["unittest.TestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_mlp_distributional_network": [[17, 92], ["network_architecture_distributional.NetworkMLPDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.zeros", "keras.Model", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "keras.Model", "keras.Model", "keras.Model", "keras.Model.predict", "keras.Model.predict", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.random.rand", "numpy.random.rand", "rl.util.clone_model", "rl.util.clone_model.compile", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "rl.util.clone_model.predict", "test_network_architecture_distributional.Tester.assertTrue", "network_architecture_distributional.NetworkMLPDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.abs().all", "all", "numpy.isclose().all", "numpy.shape", "numpy.abs().all", "numpy.abs", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "numpy.isclose", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "numpy.isclose", "numpy.abs", "numpy.cos", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "test_mlp_distributional_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLPDistributional", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "False", ",", "prior", "=", "False", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "4", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "]", "=", "tau", "[", ":", ",", ":", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau -> equal Z_tau", "\n", "\n", "# Cos embedding", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "zeros", "(", "(", "1", ",", "1", ",", "8", ")", ")", "\n", "tau", "[", "0", ",", "0", ",", "0", "]", "=", "0", "\n", "tau", "[", "0", ",", "0", ",", "1", "]", "=", "1", "/", "64", "\n", "tau", "[", "0", ",", "0", ",", "2", "]", "=", "0.5", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "cos_embedding_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'cos_tau'", ")", ".", "output", ")", "\n", "cos_embedding_output", "=", "cos_embedding_layer", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "(", "cos_embedding_output", "[", "0", ",", "0", ",", ":", "]", "==", "1", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "all", "(", "[", "np", ".", "isclose", "(", "cos_embedding_output", "[", "0", ",", "1", ",", "i", "]", ",", "np", ".", "cos", "(", "np", ".", "pi", "*", "i", "*", "1", "/", "64", ")", ",", "atol", "=", "1e-7", ")", "\n", "for", "i", "in", "range", "(", "cos_embedding_output", ".", "shape", "[", "2", "]", ")", "]", ")", ")", "\n", "\n", "# Merge", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "tau_net_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'fc_tau'", ")", ".", "output", ")", "\n", "state_net_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'fc_state_extra_dim'", ")", ".", "output", ")", "\n", "merge_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'merge'", ")", ".", "output", ")", "\n", "tau_net_output", "=", "tau_net_layer", ".", "predict", "(", "net_input", ")", "\n", "state_net_output", "=", "state_net_layer", ".", "predict", "(", "net_input", ")", "\n", "merge_output", "=", "merge_layer", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "tau_net_output", "[", "None", ",", ":", ",", "0", ",", ":", "]", "*", "state_net_output", ",", "merge_output", "[", ":", ",", "0", ",", ":", "]", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_distributional.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n", "# Test clone model, mainly to see that no custom objects are missing", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "target_model", "=", "clone_model", "(", "net", ".", "model", ")", "\n", "target_model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "out_clone", "=", "target_model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "(", "out", "==", "out_clone", ")", ".", "all", "(", ")", ")", "\n", "\n", "# Window length > 1", "\n", "net", "=", "NetworkMLPDistributional", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "False", ",", "prior", "=", "False", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ",", "window_length", "=", "5", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "5", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "4", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "5", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "]", "=", "tau", "[", ":", ",", "0", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau should give equal values of Z_tau", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_window_5_distributional.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_mlp_dueling_network": [[93, 121], ["network_architecture_distributional.NetworkMLPDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "keras.Model", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.mean", "numpy.isclose().all", "numpy.isclose().all", "numpy.abs().all", "numpy.isclose", "numpy.isclose", "numpy.abs", "network_architecture_distributional.NetworkMLPDistributional.model.predict"], "methods", ["None"], ["", "def", "test_mlp_dueling_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLPDistributional", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "True", ",", "prior", "=", "False", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "4", ")", ")", "\n", "\n", "before_dueling_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "layers", "[", "-", "2", "]", ".", "output", ")", "\n", "before_dueling_output", "=", "before_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "true_output", "=", "before_dueling_output", "[", ":", ",", ":", ",", "0", ",", "None", "]", "+", "before_dueling_output", "[", ":", ",", ":", ",", "1", ":", "]", "-", "np", ".", "mean", "(", "before_dueling_output", "[", ":", ",", ":", ",", "1", ":", ",", "None", "]", ",", "axis", "=", "2", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "out", ",", "true_output", ")", ".", "all", "(", ")", ")", "\n", "\n", "single_input", "=", "[", "net_input", "[", "0", "]", "[", "None", ",", "0", "]", ",", "net_input", "[", "1", "]", "[", "None", ",", "0", "]", "]", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "out", "[", "0", "]", ",", "net", ".", "model", ".", "predict", "(", "single_input", ")", ")", ".", "all", "(", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "7", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "+", "1", "]", "=", "tau", "[", ":", ",", ":", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau -> equal Z_tau", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_duel_distributional.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_mlp_distributional_network_with_prior": [[122, 205], ["network_architecture_distributional.NetworkMLPDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.zeros", "keras.Model", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "keras.Model", "keras.Model", "keras.Model", "keras.Model.predict", "keras.Model.predict", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.random.rand", "numpy.random.rand", "rl.util.clone_model", "rl.util.clone_model.compile", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "rl.util.clone_model.predict", "test_network_architecture_distributional.Tester.assertTrue", "network_architecture_distributional.NetworkMLPDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.abs().all", "all", "numpy.isclose().all", "numpy.shape", "numpy.abs().all", "test_network_architecture_distributional.Tester.assertFalse", "test_network_architecture_distributional.Tester.assertFalse", "numpy.abs", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "numpy.isclose", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "numpy.isclose", "numpy.abs", "numpy.cos", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "test_mlp_distributional_network_with_prior", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLPDistributional", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "False", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ",", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "for", "layer", "in", "net", ".", "model", ".", "layers", ":", "\n", "            ", "if", "'prior'", "in", "layer", ".", "name", "and", "not", "not", "layer", ".", "weights", ":", "\n", "                ", "self", ".", "assertFalse", "(", "layer", ".", "trainable", ")", "\n", "\n", "", "", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "4", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "]", "=", "tau", "[", ":", ",", ":", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau -> equal Z_tau", "\n", "\n", "# Cos embedding", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "zeros", "(", "(", "1", ",", "1", ",", "8", ")", ")", "\n", "tau", "[", "0", ",", "0", ",", "0", "]", "=", "0", "\n", "tau", "[", "0", ",", "0", ",", "1", "]", "=", "1", "/", "64", "\n", "tau", "[", "0", ",", "0", ",", "2", "]", "=", "0.5", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "cos_embedding_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'cos_tau'", ")", ".", "output", ")", "\n", "cos_embedding_output", "=", "cos_embedding_layer", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "(", "cos_embedding_output", "[", "0", ",", "0", ",", ":", "]", "==", "1", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "all", "(", "[", "np", ".", "isclose", "(", "cos_embedding_output", "[", "0", ",", "1", ",", "i", "]", ",", "np", ".", "cos", "(", "np", ".", "pi", "*", "i", "*", "1", "/", "64", ")", ",", "atol", "=", "1e-7", ")", "\n", "for", "i", "in", "range", "(", "cos_embedding_output", ".", "shape", "[", "2", "]", ")", "]", ")", ")", "\n", "\n", "# Merge", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "tau_net_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'fc_tau_trainable'", ")", ".", "output", ")", "\n", "state_net_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'fc_state_extra_dim_trainable'", ")", ".", "output", ")", "\n", "merge_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'merge_trainable'", ")", ".", "output", ")", "\n", "tau_net_output", "=", "tau_net_layer", ".", "predict", "(", "net_input", ")", "\n", "state_net_output", "=", "state_net_layer", ".", "predict", "(", "net_input", ")", "\n", "merge_output", "=", "merge_layer", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "tau_net_output", "[", "None", ",", ":", ",", "0", ",", ":", "]", "*", "state_net_output", ",", "merge_output", "[", ":", ",", "0", ",", ":", "]", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_distributional_with_prior.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n", "# Test clone model, mainly to see that no custom objects are missing", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "target_model", "=", "clone_model", "(", "net", ".", "model", ")", "\n", "target_model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "out_clone", "=", "target_model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "(", "out", "==", "out_clone", ")", ".", "all", "(", ")", ")", "\n", "\n", "# Window length > 1", "\n", "net", "=", "NetworkMLPDistributional", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "False", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ",", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ",", "window_length", "=", "5", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "for", "layer", "in", "net", ".", "model", ".", "layers", ":", "\n", "            ", "if", "'prior'", "in", "layer", ".", "name", "and", "not", "not", "layer", ".", "weights", ":", "\n", "                ", "self", ".", "assertFalse", "(", "layer", ".", "trainable", ")", "\n", "\n", "", "", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "5", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "4", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "5", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "]", "=", "tau", "[", ":", ",", "0", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau should give equal values of Z_tau", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_window_5_distributional_with_prior.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_mlp_duel_distributional_with_prior_network": [[206, 243], ["network_architecture_distributional.NetworkMLPDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "network_architecture_distributional.NetworkMLPDistributional.model.get_config", "keras.Model", "keras.Model.predict", "keras.Model", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkMLPDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.mean", "numpy.isclose().all", "numpy.abs().all", "test_network_architecture_distributional.Tester.assertFalse", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "numpy.isclose", "numpy.abs", "network_architecture_distributional.NetworkMLPDistributional.model.predict"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "test_mlp_duel_distributional_with_prior_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLPDistributional", "(", "3", ",", "4", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ",", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "for", "layer", "in", "net", ".", "model", ".", "layers", ":", "\n", "            ", "if", "'prior'", "in", "layer", ".", "name", "and", "not", "not", "layer", ".", "weights", ":", "\n", "                ", "self", ".", "assertFalse", "(", "layer", ".", "trainable", ")", "\n", "\n", "", "", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "4", ")", ")", "\n", "\n", "net", ".", "model", ".", "get_config", "(", ")", "# This crashes for custom lambda layers", "\n", "\n", "before_dueling_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "\n", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'output_trainable_wo_dueling'", ")", ".", "output", ")", "\n", "before_dueling_output", "=", "before_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "after_dueling_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'output_trainable'", ")", ".", "output", ")", "\n", "after_dueling_output", "=", "after_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "true_dueling_output", "=", "before_dueling_output", "[", ":", ",", ":", ",", "0", ",", "None", "]", "+", "before_dueling_output", "[", ":", ",", ":", ",", "1", ":", "]", "-", "np", ".", "mean", "(", "before_dueling_output", "[", ":", ",", ":", ",", "1", ":", ",", "None", "]", ",", "axis", "=", "2", ")", "\n", "self", ".", "assertTrue", "(", "(", "after_dueling_output", "==", "true_dueling_output", ")", ".", "all", "(", ")", ")", "\n", "\n", "single_input", "=", "[", "net_input", "[", "0", "]", "[", "None", ",", "0", "]", ",", "net_input", "[", "1", "]", "[", "None", ",", "0", "]", "]", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "out", "[", "0", "]", ",", "net", ".", "model", ".", "predict", "(", "single_input", ")", ")", ".", "all", "(", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "3", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "7", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "+", "1", "]", "=", "tau", "[", ":", ",", ":", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau -> equal Z_tau", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'mlp_duel_distributional_with_prior.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_cnn_distributional_network": [[244, 344], ["network_architecture_distributional.NetworkCNNDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertFalse", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.zeros", "keras.Model", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "keras.Model", "keras.Model", "keras.Model", "keras.Model.predict", "keras.Model.predict", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.random.rand", "numpy.random.rand", "rl.util.clone_model", "rl.util.clone_model.compile", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "rl.util.clone_model.predict", "test_network_architecture_distributional.Tester.assertTrue", "network_architecture_distributional.NetworkCNNDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertFalse", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.copy", "numpy.copy", "numpy.abs().all", "all", "numpy.isclose().all", "numpy.shape", "numpy.copy", "numpy.copy", "numpy.abs().all", "numpy.abs", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "numpy.isclose", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "numpy.isclose", "numpy.abs", "numpy.cos", "range"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "test_cnn_distributional_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "7", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "False", ",", "prior", "=", "False", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "9", ")", ")", "\n", "\n", "state1", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "input1", "=", "[", "state1", ",", "tau", "]", "\n", "out1", "=", "net", ".", "model", ".", "predict", "(", "input1", ")", "\n", "input2", "=", "[", "np", ".", "copy", "(", "state1", ")", ",", "np", ".", "copy", "(", "tau", ")", "]", "\n", "input2", "[", "0", "]", "[", "0", ",", "0", ",", "7", ":", "15", "]", "=", "input1", "[", "0", "]", "[", "0", ",", "0", ",", "15", ":", "23", "]", "\n", "input2", "[", "0", "]", "[", "0", ",", "0", ",", "15", ":", "23", "]", "=", "input1", "[", "0", "]", "[", "0", ",", "0", ",", "7", ":", "15", "]", "\n", "self", ".", "assertFalse", "(", "(", "input1", "[", "0", "]", "==", "input2", "[", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "out2", "=", "net", ".", "model", ".", "predict", "(", "input2", ")", "\n", "self", ".", "assertTrue", "(", "(", "out1", "==", "out2", ")", ".", "all", "(", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "]", "=", "tau", "[", ":", ",", ":", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau -> equal Z_tau", "\n", "\n", "# Cos embedding", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "zeros", "(", "(", "1", ",", "1", ",", "8", ")", ")", "\n", "tau", "[", "0", ",", "0", ",", "0", "]", "=", "0", "\n", "tau", "[", "0", ",", "0", ",", "1", "]", "=", "1", "/", "64", "\n", "tau", "[", "0", ",", "0", ",", "2", "]", "=", "0.5", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "cos_embedding_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'cos_tau'", ")", ".", "output", ")", "\n", "cos_embedding_output", "=", "cos_embedding_layer", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "(", "cos_embedding_output", "[", "0", ",", "0", ",", ":", "]", "==", "1", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "all", "(", "[", "np", ".", "isclose", "(", "cos_embedding_output", "[", "0", ",", "1", ",", "i", "]", ",", "np", ".", "cos", "(", "np", ".", "pi", "*", "i", "*", "1", "/", "64", ")", ",", "atol", "=", "1e-7", ")", "\n", "for", "i", "in", "range", "(", "cos_embedding_output", ".", "shape", "[", "2", "]", ")", "]", ")", ")", "\n", "\n", "# Merge", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "tau_net_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'fc_tau'", ")", ".", "output", ")", "\n", "state_net_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'merged_extra_dim'", ")", ".", "output", ")", "\n", "merge_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'merge'", ")", ".", "output", ")", "\n", "tau_net_output", "=", "tau_net_layer", ".", "predict", "(", "net_input", ")", "\n", "state_net_output", "=", "state_net_layer", ".", "predict", "(", "net_input", ")", "\n", "merge_output", "=", "merge_layer", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "tau_net_output", "[", "None", ",", ":", ",", "0", ",", ":", "]", "*", "state_net_output", ",", "merge_output", "[", ":", ",", "0", ",", ":", "]", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn_distributional.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n", "# Test clone model, mainly to see that no custom objects are missing", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "target_model", "=", "clone_model", "(", "net", ".", "model", ")", "\n", "target_model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "out_clone", "=", "target_model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "(", "out", "==", "out_clone", ")", ".", "all", "(", ")", ")", "\n", "\n", "# Window length > 1", "\n", "net", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "7", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "False", ",", "prior", "=", "False", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ",", "window_length", "=", "5", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "5", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "9", ")", ")", "\n", "\n", "state1", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "5", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "input1", "=", "[", "state1", ",", "tau", "]", "\n", "out1", "=", "net", ".", "model", ".", "predict", "(", "input1", ")", "\n", "input2", "=", "[", "np", ".", "copy", "(", "state1", ")", ",", "np", ".", "copy", "(", "tau", ")", "]", "\n", "input2", "[", "0", "]", "[", "0", ",", ":", ",", "7", ":", "15", "]", "=", "input1", "[", "0", "]", "[", "0", ",", ":", ",", "15", ":", "23", "]", "\n", "input2", "[", "0", "]", "[", "0", ",", ":", ",", "15", ":", "23", "]", "=", "input1", "[", "0", "]", "[", "0", ",", ":", ",", "7", ":", "15", "]", "\n", "self", ".", "assertFalse", "(", "(", "input1", "[", "0", "]", "==", "input2", "[", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "out2", "=", "net", ".", "model", ".", "predict", "(", "input2", ")", "\n", "self", ".", "assertTrue", "(", "(", "out1", "==", "out2", ")", ".", "all", "(", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "5", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "]", "=", "tau", "[", ":", ",", "0", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau should give equal values of Z_tau", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn_window_5_distributional.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_cnn_dueling_distributional_network": [[345, 375], ["network_architecture_distributional.NetworkCNNDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "keras.Model", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.mean", "numpy.isclose().all", "numpy.isclose().all", "numpy.abs().all", "numpy.isclose", "numpy.isclose", "numpy.abs", "network_architecture_distributional.NetworkCNNDistributional.model.predict"], "methods", ["None"], ["", "def", "test_cnn_dueling_distributional_network", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "7", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "True", ",", "prior", "=", "False", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "9", ")", ")", "\n", "\n", "before_dueling_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "layers", "[", "-", "2", "]", ".", "output", ")", "\n", "before_dueling_output", "=", "before_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "true_output", "=", "before_dueling_output", "[", ":", ",", ":", ",", "0", ",", "None", "]", "+", "before_dueling_output", "[", ":", ",", ":", ",", "1", ":", "]", "-", "np", ".", "mean", "(", "before_dueling_output", "[", ":", ",", ":", ",", "1", ":", ",", "None", "]", ",", "axis", "=", "2", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "out", ",", "true_output", ")", ".", "all", "(", ")", ")", "\n", "\n", "single_input", "=", "[", "net_input", "[", "0", "]", "[", "None", ",", "0", "]", ",", "net_input", "[", "1", "]", "[", "None", ",", "0", "]", "]", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "out", "[", "0", "]", ",", "net", ".", "model", ".", "predict", "(", "single_input", ")", ")", ".", "all", "(", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "7", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "+", "1", "]", "=", "tau", "[", ":", ",", ":", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau -> equal Z_tau", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn_duel_distributional.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_cnn_dueling_distributional_with_prior": [[376, 496], ["network_architecture_distributional.NetworkCNNDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertFalse", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.zeros", "keras.Model", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "keras.Model", "keras.Model", "keras.Model", "keras.Model.predict", "keras.Model.predict", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.random.rand", "numpy.random.rand", "rl.util.clone_model", "rl.util.clone_model.compile", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "rl.util.clone_model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "network_architecture_distributional.NetworkCNNDistributional.model.get_config", "keras.Model", "keras.Model.predict", "keras.Model", "keras.Model.predict", "test_network_architecture_distributional.Tester.assertTrue", "test_network_architecture_distributional.Tester.assertTrue", "network_architecture_distributional.NetworkCNNDistributional", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertEqual", "numpy.random.rand", "numpy.random.rand", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertFalse", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "numpy.random.rand", "numpy.random.rand", "range", "network_architecture_distributional.NetworkCNNDistributional.model.predict", "test_network_architecture_distributional.Tester.assertTrue", "keras.utils.plot_model", "numpy.shape", "numpy.copy", "numpy.copy", "numpy.abs().all", "all", "numpy.isclose().all", "numpy.mean", "numpy.isclose().all", "numpy.isclose().all", "numpy.shape", "numpy.copy", "numpy.copy", "numpy.abs().all", "test_network_architecture_distributional.Tester.assertFalse", "numpy.abs", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "numpy.isclose", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "numpy.isclose", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "numpy.isclose", "numpy.isclose", "numpy.abs", "numpy.cos", "range", "network_architecture_distributional.NetworkCNNDistributional.model.predict"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "test_cnn_dueling_distributional_with_prior", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "7", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "9", ")", ")", "\n", "\n", "state1", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "input1", "=", "[", "state1", ",", "tau", "]", "\n", "out1", "=", "net", ".", "model", ".", "predict", "(", "input1", ")", "\n", "input2", "=", "[", "np", ".", "copy", "(", "state1", ")", ",", "np", ".", "copy", "(", "tau", ")", "]", "\n", "input2", "[", "0", "]", "[", "0", ",", "0", ",", "7", ":", "15", "]", "=", "input1", "[", "0", "]", "[", "0", ",", "0", ",", "15", ":", "23", "]", "\n", "input2", "[", "0", "]", "[", "0", ",", "0", ",", "15", ":", "23", "]", "=", "input1", "[", "0", "]", "[", "0", ",", "0", ",", "7", ":", "15", "]", "\n", "self", ".", "assertFalse", "(", "(", "input1", "[", "0", "]", "==", "input2", "[", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "out2", "=", "net", ".", "model", ".", "predict", "(", "input2", ")", "\n", "self", ".", "assertTrue", "(", "(", "out1", "==", "out2", ")", ".", "all", "(", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "]", "=", "tau", "[", ":", ",", ":", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau -> equal Z_tau", "\n", "\n", "# Cos embedding", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "zeros", "(", "(", "1", ",", "1", ",", "8", ")", ")", "\n", "tau", "[", "0", ",", "0", ",", "0", "]", "=", "0", "\n", "tau", "[", "0", ",", "0", ",", "1", "]", "=", "1", "/", "64", "\n", "tau", "[", "0", ",", "0", ",", "2", "]", "=", "0.5", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "cos_embedding_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'cos_tau'", ")", ".", "output", ")", "\n", "cos_embedding_output", "=", "cos_embedding_layer", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "(", "cos_embedding_output", "[", "0", ",", "0", ",", ":", "]", "==", "1", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "all", "(", "[", "np", ".", "isclose", "(", "cos_embedding_output", "[", "0", ",", "1", ",", "i", "]", ",", "np", ".", "cos", "(", "np", ".", "pi", "*", "i", "*", "1", "/", "64", ")", ",", "atol", "=", "1e-7", ")", "\n", "for", "i", "in", "range", "(", "cos_embedding_output", ".", "shape", "[", "2", "]", ")", "]", ")", ")", "\n", "\n", "# Merge", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "tau_net_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'fc_tau_trainable'", ")", ".", "output", ")", "\n", "state_net_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'merged_extra_dim_trainable'", ")", ".", "output", ")", "\n", "merge_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'merge_trainable'", ")", ".", "output", ")", "\n", "tau_net_output", "=", "tau_net_layer", ".", "predict", "(", "net_input", ")", "\n", "state_net_output", "=", "state_net_layer", ".", "predict", "(", "net_input", ")", "\n", "merge_output", "=", "merge_layer", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "tau_net_output", "[", "None", ",", ":", ",", "0", ",", ":", "]", "*", "state_net_output", ",", "merge_output", "[", ":", ",", "0", ",", ":", "]", ")", ".", "all", "(", ")", ")", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn_duel_distributional_with_prior.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n", "# Test clone model, mainly to see that no custom objects are missing", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "target_model", "=", "clone_model", "(", "net", ".", "model", ")", "\n", "target_model", ".", "compile", "(", "optimizer", "=", "'sgd'", ",", "loss", "=", "'mse'", ")", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "out_clone", "=", "target_model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "(", "out", "==", "out_clone", ")", ".", "all", "(", ")", ")", "\n", "\n", "# Prior nets not trainable", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "for", "layer", "in", "net", ".", "model", ".", "layers", ":", "\n", "            ", "if", "'prior'", "in", "layer", ".", "name", "and", "not", "not", "layer", ".", "weights", ":", "\n", "                ", "self", ".", "assertFalse", "(", "layer", ".", "trainable", ")", "\n", "\n", "", "", "net", ".", "model", ".", "get_config", "(", ")", "# This crashes for custom lambda layers", "\n", "\n", "before_dueling_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "\n", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'output_trainable_wo_dueling'", ")", ".", "output", ")", "\n", "before_dueling_output", "=", "before_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "after_dueling_layer", "=", "K", ".", "Model", "(", "inputs", "=", "net", ".", "model", ".", "inputs", ",", "outputs", "=", "net", ".", "model", ".", "get_layer", "(", "'output_trainable'", ")", ".", "output", ")", "\n", "after_dueling_output", "=", "after_dueling_layer", ".", "predict", "(", "net_input", ")", "\n", "true_dueling_output", "=", "before_dueling_output", "[", ":", ",", ":", ",", "0", ",", "None", "]", "+", "before_dueling_output", "[", ":", ",", ":", ",", "1", ":", "]", "-", "np", ".", "mean", "(", "before_dueling_output", "[", ":", ",", ":", ",", "1", ":", ",", "None", "]", ",", "axis", "=", "2", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "after_dueling_output", ",", "true_dueling_output", ")", ".", "all", "(", ")", ")", "\n", "\n", "single_input", "=", "[", "net_input", "[", "0", "]", "[", "None", ",", "0", "]", ",", "net_input", "[", "1", "]", "[", "None", ",", "0", "]", "]", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "out", "[", "0", "]", ",", "net", ".", "model", ".", "predict", "(", "single_input", ")", ")", ".", "all", "(", ")", ")", "\n", "\n", "# Window length > 1", "\n", "net", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "7", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ",", "window_length", "=", "5", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "model", ".", "trainable", ")", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "5", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertEqual", "(", "np", ".", "shape", "(", "out", ")", ",", "(", "32", ",", "8", ",", "9", ")", ")", "\n", "\n", "state1", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "5", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "1", ",", "8", ")", "\n", "input1", "=", "[", "state1", ",", "tau", "]", "\n", "out1", "=", "net", ".", "model", ".", "predict", "(", "input1", ")", "\n", "input2", "=", "[", "np", ".", "copy", "(", "state1", ")", ",", "np", ".", "copy", "(", "tau", ")", "]", "\n", "input2", "[", "0", "]", "[", "0", ",", ":", ",", "7", ":", "15", "]", "=", "input1", "[", "0", "]", "[", "0", ",", ":", ",", "15", ":", "23", "]", "\n", "input2", "[", "0", "]", "[", "0", ",", ":", ",", "15", ":", "23", "]", "=", "input1", "[", "0", "]", "[", "0", ",", ":", ",", "7", ":", "15", "]", "\n", "self", ".", "assertFalse", "(", "(", "input1", "[", "0", "]", "==", "input2", "[", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "out2", "=", "net", ".", "model", ".", "predict", "(", "input2", ")", "\n", "self", ".", "assertTrue", "(", "(", "out1", "==", "out2", ")", ".", "all", "(", ")", ")", "\n", "\n", "state", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "5", ",", "47", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "1", ",", "8", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "            ", "tau", "[", ":", ",", ":", ",", "i", "]", "=", "tau", "[", ":", ",", "0", ",", "0", "]", "\n", "", "net_input", "=", "[", "state", ",", "tau", "]", "\n", "out", "=", "net", ".", "model", ".", "predict", "(", "net_input", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "abs", "(", "(", "out", "[", "0", ",", "0", ",", ":", "]", "-", "out", "[", "0", ",", ":", ",", ":", "]", ")", "<", "1e-6", ")", ".", "all", "(", ")", ")", "# Equal values of tau should give equal values of Z_tau", "\n", "\n", "plot_model", "(", "net", ".", "model", ",", "to_file", "=", "'cnn_window_5_duel_distributional_with_prior.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_trainable_weights_mlp_prior": [[497, 528], ["network_architecture_distributional.NetworkMLPDistributional", "network_architecture_distributional.NetworkMLPDistributional.model.compile", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "copy.deepcopy", "network_architecture_distributional.NetworkMLPDistributional.model.fit", "zip", "keras.backend.function", "keras.backend.function", "test_network_architecture_distributional.Tester.assertTrue", "keras.backend.function", "keras.backend.function", "test_network_architecture_distributional.Tester.assertTrue", "keras.backend.function.", "keras.backend.function.", "keras.backend.function.", "keras.backend.function.", "layer_init.get_weights", "layer.get_weights", "zip", "copy.deepcopy.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "copy.deepcopy.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "test_network_architecture_distributional.Tester.assertTrue", "copy.deepcopy.get_layer", "copy.deepcopy.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "copy.deepcopy.get_layer", "copy.deepcopy.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "network_architecture_distributional.NetworkMLPDistributional.model.get_layer", "tmp.all"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.fit"], ["", "def", "test_trainable_weights_mlp_prior", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkMLPDistributional", "(", "5", ",", "3", ",", "nb_hidden_layers", "=", "2", ",", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "prior_scale_factor", "=", "1", ",", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "net", ".", "model", ".", "compile", "(", "loss", "=", "'mse'", ",", "optimizer", "=", "'adam'", ")", "\n", "x", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "1", ",", "5", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "1", ",", "8", ")", "\n", "y", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "8", ",", "3", ")", "\n", "net_input", "=", "[", "x", ",", "tau", "]", "\n", "initial_model", "=", "copy", ".", "deepcopy", "(", "net", ".", "model", ")", "\n", "net", ".", "model", ".", "fit", "(", "net_input", ",", "y", ",", "epochs", "=", "10", ",", "batch_size", "=", "100", ",", "verbose", "=", "0", ")", "\n", "for", "layer_init", ",", "layer", "in", "zip", "(", "initial_model", ".", "layers", ",", "net", ".", "model", ".", "layers", ")", ":", "\n", "            ", "if", "not", "layer", ".", "trainable", ":", "\n", "                ", "init_weights", "=", "layer_init", ".", "get_weights", "(", ")", "\n", "weights", "=", "layer", ".", "get_weights", "(", ")", "\n", "for", "row_init", ",", "row", "in", "zip", "(", "init_weights", ",", "weights", ")", ":", "\n", "                    ", "tmp", "=", "row_init", "==", "row", "\n", "self", ".", "assertTrue", "(", "tmp", ".", "all", "(", ")", ")", "\n", "", "", "", "get_prior_output_initial", "=", "K", ".", "backend", ".", "function", "(", "[", "initial_model", ".", "get_layer", "(", "'state_input'", ")", ".", "input", ",", "initial_model", ".", "get_layer", "(", "'tau_input'", ")", ".", "input", "]", ",", "\n", "initial_model", ".", "get_layer", "(", "'output_prior'", ")", ".", "output", ")", "\n", "prior_out_initial", "=", "get_prior_output_initial", "(", "[", "x", "[", "0", ",", ":", ",", ":", "]", ",", "tau", "[", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "get_prior_output", "=", "K", ".", "backend", ".", "function", "(", "[", "net", ".", "model", ".", "get_layer", "(", "'state_input'", ")", ".", "input", ",", "net", ".", "model", ".", "get_layer", "(", "'tau_input'", ")", ".", "input", "]", ",", "\n", "net", ".", "model", ".", "get_layer", "(", "'output_prior'", ")", ".", "output", ")", "\n", "prior_out", "=", "get_prior_output", "(", "[", "x", "[", "0", ",", ":", ",", ":", "]", ",", "tau", "[", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "(", "prior_out_initial", "==", "prior_out", ")", ".", "all", "(", ")", ")", "\n", "get_trainable_output_initial", "=", "K", ".", "backend", ".", "function", "(", "[", "initial_model", ".", "get_layer", "(", "'state_input'", ")", ".", "input", ",", "initial_model", ".", "get_layer", "(", "'tau_input'", ")", ".", "input", "]", ",", "\n", "initial_model", ".", "get_layer", "(", "'output_trainable'", ")", ".", "output", ")", "\n", "trainable_out_initial", "=", "get_trainable_output_initial", "(", "[", "x", "[", "0", ",", ":", ",", ":", "]", ",", "tau", "[", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "get_trainable_output", "=", "K", ".", "backend", ".", "function", "(", "[", "net", ".", "model", ".", "get_layer", "(", "'state_input'", ")", ".", "input", ",", "net", ".", "model", ".", "get_layer", "(", "'tau_input'", ")", ".", "input", "]", ",", "\n", "net", ".", "model", ".", "get_layer", "(", "'output_trainable'", ")", ".", "output", ")", "\n", "trainable_out", "=", "get_trainable_output", "(", "[", "x", "[", "0", ",", ":", ",", ":", "]", ",", "tau", "[", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "(", "trainable_out_initial", "!=", "trainable_out", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_trainable_weights_cnn_prior": [[529, 562], ["network_architecture_distributional.NetworkCNNDistributional", "network_architecture_distributional.NetworkCNNDistributional.model.compile", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "copy.deepcopy", "network_architecture_distributional.NetworkCNNDistributional.model.fit", "zip", "keras.backend.function", "keras.backend.function", "test_network_architecture_distributional.Tester.assertTrue", "keras.backend.function", "keras.backend.function", "test_network_architecture_distributional.Tester.assertTrue", "keras.backend.function.", "keras.backend.function.", "keras.backend.function.", "keras.backend.function.", "layer_init.get_weights", "layer.get_weights", "zip", "copy.deepcopy.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "copy.deepcopy.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "test_network_architecture_distributional.Tester.assertTrue", "copy.deepcopy.get_layer", "copy.deepcopy.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "copy.deepcopy.get_layer", "copy.deepcopy.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "network_architecture_distributional.NetworkCNNDistributional.model.get_layer", "tmp.all"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Agent.fit"], ["", "def", "test_trainable_weights_cnn_prior", "(", "self", ")", ":", "\n", "        ", "net", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "net", ".", "model", ".", "compile", "(", "loss", "=", "'mse'", ",", "optimizer", "=", "'adam'", ")", "\n", "x", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "1", ",", "44", ")", "\n", "tau", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "1", ",", "8", ")", "\n", "y", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "8", ",", "9", ")", "\n", "net_input", "=", "[", "x", ",", "tau", "]", "\n", "initial_model", "=", "copy", ".", "deepcopy", "(", "net", ".", "model", ")", "\n", "net", ".", "model", ".", "fit", "(", "net_input", ",", "y", ",", "epochs", "=", "10", ",", "batch_size", "=", "100", ",", "verbose", "=", "0", ")", "\n", "for", "layer_init", ",", "layer", "in", "zip", "(", "initial_model", ".", "layers", ",", "net", ".", "model", ".", "layers", ")", ":", "\n", "            ", "if", "not", "layer", ".", "trainable", ":", "\n", "                ", "init_weights", "=", "layer_init", ".", "get_weights", "(", ")", "\n", "weights", "=", "layer", ".", "get_weights", "(", ")", "\n", "for", "row_init", ",", "row", "in", "zip", "(", "init_weights", ",", "weights", ")", ":", "\n", "                    ", "tmp", "=", "row_init", "==", "row", "\n", "self", ".", "assertTrue", "(", "tmp", ".", "all", "(", ")", ")", "\n", "", "", "", "get_prior_output_initial", "=", "K", ".", "backend", ".", "function", "(", "[", "initial_model", ".", "get_layer", "(", "'state_input'", ")", ".", "input", ",", "initial_model", ".", "get_layer", "(", "'tau_input'", ")", ".", "input", "]", ",", "\n", "initial_model", ".", "get_layer", "(", "'output_prior'", ")", ".", "output", ")", "\n", "prior_out_initial", "=", "get_prior_output_initial", "(", "[", "x", "[", "None", ",", "0", ",", ":", ",", ":", "]", ",", "tau", "[", "None", ",", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "get_prior_output", "=", "K", ".", "backend", ".", "function", "(", "[", "net", ".", "model", ".", "get_layer", "(", "'state_input'", ")", ".", "input", ",", "net", ".", "model", ".", "get_layer", "(", "'tau_input'", ")", ".", "input", "]", ",", "\n", "net", ".", "model", ".", "get_layer", "(", "'output_prior'", ")", ".", "output", ")", "\n", "prior_out", "=", "get_prior_output", "(", "[", "x", "[", "None", ",", "0", ",", ":", ",", ":", "]", ",", "tau", "[", "None", ",", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "(", "prior_out_initial", "==", "prior_out", ")", ".", "all", "(", ")", ")", "\n", "get_trainable_output_initial", "=", "K", ".", "backend", ".", "function", "(", "[", "initial_model", ".", "get_layer", "(", "'state_input'", ")", ".", "input", ",", "initial_model", ".", "get_layer", "(", "'tau_input'", ")", ".", "input", "]", ",", "\n", "initial_model", ".", "get_layer", "(", "'output_trainable'", ")", ".", "output", ")", "\n", "trainable_out_initial", "=", "get_trainable_output_initial", "(", "[", "x", "[", "None", ",", "0", ",", ":", ",", ":", "]", ",", "tau", "[", "None", ",", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "get_trainable_output", "=", "K", ".", "backend", ".", "function", "(", "[", "net", ".", "model", ".", "get_layer", "(", "'state_input'", ")", ".", "input", ",", "net", ".", "model", ".", "get_layer", "(", "'tau_input'", ")", ".", "input", "]", ",", "\n", "net", ".", "model", ".", "get_layer", "(", "'output_trainable'", ")", ".", "output", ")", "\n", "trainable_out", "=", "get_trainable_output", "(", "[", "x", "[", "None", ",", "0", ",", ":", ",", ":", "]", ",", "tau", "[", "None", ",", "0", ",", ":", ",", ":", "]", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "(", "trainable_out_initial", "!=", "trainable_out", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_network_architecture_distributional.Tester.test_random_initialization": [[563, 590], ["network_architecture_distributional.NetworkCNNDistributional", "network_architecture_distributional.NetworkCNNDistributional", "zip", "test_network_architecture_distributional.Tester.assertFalse", "numpy.random.seed", "network_architecture_distributional.NetworkCNNDistributional", "numpy.random.seed", "network_architecture_distributional.NetworkCNNDistributional", "zip", "test_network_architecture_distributional.Tester.assertTrue", "network_architecture_distributional.NetworkCNNDistributional.model.get_weights", "network_architecture_distributional.NetworkCNNDistributional.model.get_weights", "network_architecture_distributional.NetworkCNNDistributional.model.get_weights", "network_architecture_distributional.NetworkCNNDistributional.model.get_weights"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed"], ["", "def", "test_random_initialization", "(", "self", ")", ":", "\n", "        ", "net1", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "net2", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "all_weights_equal", "=", "True", "\n", "for", "layer1", ",", "layer2", "in", "zip", "(", "net1", ".", "model", ".", "get_weights", "(", ")", ",", "net2", ".", "model", ".", "get_weights", "(", ")", ")", ":", "\n", "            ", "all_weights_equal", "=", "all_weights_equal", "and", "(", "layer1", "==", "layer2", ")", ".", "all", "(", ")", "\n", "", "self", ".", "assertFalse", "(", "all_weights_equal", ")", "\n", "np", ".", "random", ".", "seed", "(", "34", ")", "\n", "net1", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "np", ".", "random", ".", "seed", "(", "34", ")", "\n", "net2", "=", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "4", ",", "nb_states_per_vehicle", "=", "4", ",", "nb_vehicles", "=", "10", ",", "nb_actions", "=", "9", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "64", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "prior_scale_factor", "=", "1", ",", "\n", "nb_quantiles", "=", "8", ",", "nb_cos_embeddings", "=", "64", ")", "\n", "all_weights_equal", "=", "True", "\n", "for", "layer1", ",", "layer2", "in", "zip", "(", "net1", ".", "model", ".", "get_weights", "(", ")", ",", "net2", ".", "model", ".", "get_weights", "(", ")", ")", ":", "\n", "            ", "all_weights_equal", "=", "all_weights_equal", "and", "(", "layer1", "==", "layer2", ")", ".", "all", "(", ")", "\n", "", "self", ".", "assertTrue", "(", "all_weights_equal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_ensemble_policy.Tester.test_mean": [[11, 22], ["policy.EnsembleTestPolicy.EnsembleTestPolicy", "numpy.random.rand", "policy.EnsembleTestPolicy.EnsembleTestPolicy.select_action", "test_ensemble_policy.Tester.assertLess", "test_ensemble_policy.Tester.assertGreaterEqual", "numpy.zeros", "numpy.ones", "policy.EnsembleTestPolicy.EnsembleTestPolicy.select_action", "test_ensemble_policy.Tester.assertEqual"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["    ", "def", "test_mean", "(", "self", ")", ":", "\n", "        ", "policy", "=", "EnsembleTestPolicy", "(", ")", "\n", "q_values_all_nets", "=", "np", ".", "random", ".", "rand", "(", "10", ",", "8", ")", "# 10 nets and 8 actions in this example", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "q_values_all_nets", ")", "\n", "self", ".", "assertLess", "(", "action", ",", "8", ")", "\n", "self", ".", "assertGreaterEqual", "(", "action", ",", "0", ")", "\n", "\n", "q_values_all_nets", "=", "np", ".", "zeros", "(", "[", "10", ",", "8", "]", ")", "\n", "q_values_all_nets", "[", ":", ",", "3", "]", "=", "np", ".", "ones", "(", "[", "10", "]", ")", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "q_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_ensemble_policy.Tester.test_safe_policy": [[23, 46], ["policy.EnsembleTestPolicy.EnsembleTestPolicy", "numpy.ones", "policy.EnsembleTestPolicy.EnsembleTestPolicy.select_action", "test_ensemble_policy.Tester.assertEqual", "test_ensemble_policy.Tester.assertFalse", "numpy.ones", "policy.EnsembleTestPolicy.EnsembleTestPolicy.select_action", "test_ensemble_policy.Tester.assertEqual", "test_ensemble_policy.Tester.assertTrue", "numpy.ones", "policy.EnsembleTestPolicy.EnsembleTestPolicy.select_action", "test_ensemble_policy.Tester.assertEqual", "test_ensemble_policy.Tester.assertTrue"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.policy.DistributionalEnsembleTestPolicy.select_action"], ["", "def", "test_safe_policy", "(", "self", ")", ":", "\n", "        ", "safety_threshold", "=", "0.1", "\n", "nb_actions", "=", "8", "\n", "\n", "policy", "=", "EnsembleTestPolicy", "(", "safety_threshold", "=", "safety_threshold", ")", "\n", "q_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "nb_actions", "]", ")", "\n", "q_values_all_nets", "[", ":", ",", "4", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "q_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "4", ")", "\n", "self", ".", "assertFalse", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "q_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "nb_actions", "]", ")", "\n", "q_values_all_nets", "[", "0", ",", "0", ":", "2", "]", "*=", "100", "\n", "q_values_all_nets", "[", ":", ",", "6", "]", "*=", "1.001", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "q_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "nb_actions", ")", "\n", "self", ".", "assertTrue", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n", "q_values_all_nets", "=", "np", ".", "ones", "(", "[", "10", ",", "nb_actions", "]", ")", "\n", "q_values_all_nets", "[", "0", ",", ":", "]", "*=", "100", "\n", "action", ",", "policy_info", "=", "policy", ".", "select_action", "(", "q_values_all_nets", ")", "\n", "self", ".", "assertEqual", "(", "action", ",", "nb_actions", ")", "\n", "self", ".", "assertTrue", "(", "policy_info", "[", "'safe_action'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.__init__": [[15, 39], ["unittest.TestCase.__init__", "range", "policy.DistributionalEpsGreedyPolicy", "policy.DistributionalEnsembleTestPolicy", "memory.BootstrappingMemory.BootstrappingMemory", "iqn_ensemble.IqnRpfAgent", "models.append", "network_architecture_distributional.NetworkCNNDistributional"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "nb_nets", "=", "3", "\n", "models", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_nets", ")", ":", "\n", "            ", "models", ".", "append", "(", "NetworkCNNDistributional", "(", "nb_ego_states", "=", "1", ",", "nb_states_per_vehicle", "=", "3", ",", "nb_vehicles", "=", "3", ",", "nb_actions", "=", "4", ",", "\n", "nb_conv_layers", "=", "2", ",", "nb_conv_filters", "=", "32", ",", "nb_hidden_fc_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "duel", "=", "True", ",", "prior", "=", "True", ",", "\n", "nb_quantiles", "=", "32", ",", "nb_cos_embeddings", "=", "64", ",", "prior_scale_factor", "=", "1", ")", ".", "model", ")", "\n", "", "greedy_policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0", ")", "\n", "test_policy", "=", "DistributionalEnsembleTestPolicy", "(", ")", "\n", "memory", "=", "BootstrappingMemory", "(", "nb_nets", "=", "self", ".", "nb_nets", ",", "limit", "=", "10000", ",", "adding_prob", "=", "0.5", ",", "window_length", "=", "1", ")", "\n", "self", ".", "agent", "=", "IqnRpfAgent", "(", "models", "=", "models", ",", "policy", "=", "greedy_policy", ",", "test_policy", "=", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "nb_samples_policy", "=", "32", ",", "\n", "nb_sampled_quantiles", "=", "32", ",", "\n", "cvar_eta", "=", "1", ",", "\n", "nb_actions", "=", "4", ",", "memory", "=", "memory", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "64", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_sample_tau_values": [[40, 60], ["test_iqn_ensemble.Tester.agent.sample_tau_values", "test_iqn_ensemble.Tester.assertEqual", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.agent.compute_sampled_z_values", "test_iqn_ensemble.Tester.assertEqual", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.agent.sample_tau_values", "test_iqn_ensemble.Tester.assertEqual", "test_iqn_ensemble.Tester.assertEqual", "numpy.diff", "test_iqn_ensemble.Tester.assertTrue", "numpy.random.rand", "numpy.isclose().all", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.sample_tau_values"], ["", "def", "test_sample_tau_values", "(", "self", ")", ":", "\n", "        ", "tau", "=", "self", ".", "agent", ".", "sample_tau_values", "(", "max_tau", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "size", ",", "32", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", "<", "1", ")", ".", "all", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", ">", "0", ")", ".", "all", ")", "\n", "\n", "# Risk sensitive policy", "\n", "state", "=", "[", "np", ".", "random", ".", "rand", "(", "10", ")", "]", "\n", "z_values", ",", "tau", "=", "self", ".", "agent", ".", "compute_sampled_z_values", "(", "state", ",", "max_tau", "=", "0.25", ",", "net", "=", "0", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "size", ",", "32", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", "<", "0.25", ")", ".", "all", ")", "\n", "self", ".", "assertTrue", "(", "(", "tau", ">", "0", ")", ".", "all", ")", "\n", "\n", "# Uniform sampling", "\n", "max_tau", "=", "0.5", "\n", "tau", "=", "self", ".", "agent", ".", "sample_tau_values", "(", "max_tau", "=", "max_tau", ",", "uniform", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "tau", "[", "0", ",", "0", ",", "0", "]", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "tau", "[", "0", ",", "0", ",", "-", "1", "]", ",", "max_tau", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "tau", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_compute_sampled_z_values": [[61, 68], ["test_iqn_ensemble.Tester.agent.compute_sampled_z_values", "test_iqn_ensemble.Tester.assertEqual", "test_iqn_ensemble.Tester.assertEqual", "numpy.diff", "test_iqn_ensemble.Tester.assertFalse", "numpy.random.rand", "numpy.isclose().all", "numpy.random.randint", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn.IQNAgent.compute_sampled_z_values"], ["", "def", "test_compute_sampled_z_values", "(", "self", ")", ":", "\n", "        ", "state", "=", "[", "np", ".", "random", ".", "rand", "(", "10", ")", "]", "\n", "z_values", ",", "tau", "=", "self", ".", "agent", ".", "compute_sampled_z_values", "(", "state", ",", "max_tau", "=", "1", ",", "net", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "nb_nets", ")", ")", "\n", "self", ".", "assertEqual", "(", "z_values", ".", "shape", ",", "(", "1", ",", "self", ".", "agent", ".", "nb_sampled_quantiles", ",", "self", ".", "agent", ".", "nb_actions", ")", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "shape", ",", "(", "1", ",", "1", ",", "32", ")", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "tau", ")", "\n", "self", ".", "assertFalse", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use random sampling", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_compute_z_values_all_nets": [[69, 76], ["test_iqn_ensemble.Tester.agent.compute_z_values_all_nets", "test_iqn_ensemble.Tester.assertEqual", "test_iqn_ensemble.Tester.assertEqual", "numpy.diff", "test_iqn_ensemble.Tester.assertTrue", "numpy.random.rand", "numpy.isclose().all", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.iqn_ensemble.IqnRpfAgent.compute_z_values_all_nets"], ["", "def", "test_compute_z_values_all_nets", "(", "self", ")", ":", "\n", "        ", "state", "=", "[", "np", ".", "random", ".", "rand", "(", "10", ")", "]", "\n", "z_values_all_nets", ",", "tau", "=", "self", ".", "agent", ".", "compute_z_values_all_nets", "(", "state", ",", "max_tau", "=", "1", ")", "\n", "self", ".", "assertEqual", "(", "z_values_all_nets", ".", "shape", ",", "(", "self", ".", "nb_nets", ",", "self", ".", "agent", ".", "nb_sampled_quantiles", ",", "self", ".", "agent", ".", "nb_actions", ")", ")", "\n", "self", ".", "assertEqual", "(", "tau", ".", "shape", ",", "(", "1", ",", "1", ",", "32", ")", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "tau", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use uniform sampling", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_forward": [[77, 92], ["numpy.random.rand", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.assertGreaterEqual", "test_iqn_ensemble.Tester.assertLess", "numpy.diff", "test_iqn_ensemble.Tester.assertFalse", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.assertGreaterEqual", "test_iqn_ensemble.Tester.assertLess", "numpy.diff", "test_iqn_ensemble.Tester.assertTrue", "numpy.isclose().all", "numpy.isclose().all", "numpy.isclose", "numpy.isclose"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward"], ["", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "action", ",", "info", "=", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "assertGreaterEqual", "(", "action", ",", "0", ")", "\n", "self", ".", "assertLess", "(", "action", ",", "4", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "info", "[", "'quantiles'", "]", ")", "\n", "self", ".", "assertFalse", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use random sampling", "\n", "\n", "self", ".", "agent", ".", "training", "=", "False", "\n", "action", ",", "info", "=", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "assertGreaterEqual", "(", "action", ",", "0", ")", "\n", "self", ".", "assertLess", "(", "action", ",", "4", ")", "\n", "d_tau", "=", "np", ".", "diff", "(", "info", "[", "'quantiles'", "]", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "d_tau", ",", "d_tau", "[", "0", ",", "0", ",", "0", "]", ")", ".", "all", "(", ")", ")", "# Should use uniform sampling", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_compile": [[93, 95], ["test_iqn_ensemble.Tester.agent.compile", "keras.optimizers.Adam"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile"], ["", "def", "test_compile", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_backward": [[96, 113], ["test_iqn_ensemble.Tester.agent.compile", "range", "numpy.random.rand", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward", "range", "keras.utils.plot_model", "keras.optimizers.Adam", "numpy.random.rand", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward", "numpy.random.rand", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_backward", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "for", "_", "in", "range", "(", "0", ",", "1000", ")", ":", "# Fill up buffer", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "\n", "", "plot_model", "(", "self", ".", "agent", ".", "trainable_models", "[", "0", "]", ",", "to_file", "=", "'iqn_ensemble_trainable_model.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_training": [[114, 144], ["test_iqn_ensemble.Tester.agent.compile", "numpy.random.rand", "numpy.random.rand", "range", "range", "range", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.assertTrue", "range", "keras.optimizers.Adam", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward", "range", "range", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward", "numpy.round", "numpy.round", "numpy.mean", "numpy.mean", "numpy.round", "numpy.round", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_training", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.001", ")", ")", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "obs1", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "obs2", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "for", "_", "in", "range", "(", "0", ",", "500", ")", ":", "# Fill up buffer", "\n", "            ", "self", ".", "agent", ".", "forward", "(", "obs1", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "for", "_", "in", "range", "(", "0", ",", "500", ")", ":", "# Fill up buffer", "\n", "            ", "self", ".", "agent", ".", "forward", "(", "obs2", ")", "\n", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "for", "_", "in", "range", "(", "30", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "action1", ",", "action_info1", "=", "self", ".", "agent", ".", "forward", "(", "obs1", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "action2", ",", "action_info2", "=", "self", ".", "agent", ".", "forward", "(", "obs2", ")", "\n", "self", ".", "agent", ".", "backward", "(", "10", ",", "terminal", "=", "False", ")", "\n", "# Since actions are picked greedily, only one Q-value is expected to converge to the correct value", "\n", "", "", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info1", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "0", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info2", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "10", ")", ".", "any", "(", ")", ")", "\n", "\n", "# All nets should be trained", "\n", "for", "i", "in", "range", "(", "self", ".", "nb_nets", ")", ":", "\n", "            ", "self", ".", "agent", ".", "active_model", "=", "i", "\n", "action1", ",", "action_info1", "=", "self", ".", "agent", ".", "forward", "(", "obs1", ")", "\n", "action2", ",", "action_info2", "=", "self", ".", "agent", ".", "forward", "(", "obs2", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info1", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "0", ")", ".", "any", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "round", "(", "np", ".", "mean", "(", "action_info2", "[", "'z_values'", "]", ",", "axis", "=", "0", ")", ")", "==", "10", ")", ".", "any", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_trainable_model": [[145, 224], ["range", "policy.DistributionalEpsGreedyPolicy", "policy.DistributionalEnsembleTestPolicy", "memory.BootstrappingMemory.BootstrappingMemory", "iqn_ensemble.IqnRpfAgent", "iqn_ensemble.IqnRpfAgent.compile", "keras.utils.plot_model", "numpy.random.rand", "numpy.random.randint", "numpy.random.rand", "numpy.random.rand", "iqn_ensemble.IqnRpfAgent.models[].predict_on_batch", "numpy.zeros", "range", "numpy.zeros", "numpy.zeros", "iqn_ensemble.IqnRpfAgent.trainable_models[].predict_on_batch", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.assertTrue", "iqn_ensemble.IqnRpfAgent.trainable_models[].train_on_batch", "test_iqn_ensemble.Tester.assertTrue", "numpy.mean", "numpy.mean", "test_iqn_ensemble.Tester.assertTrue", "test_iqn_ensemble.Tester.assertTrue", "models.append", "keras.optimizers.Adam", "range", "numpy.isclose().all", "numpy.isclose", "numpy.max", "numpy.isclose", "numpy.isclose", "numpy.abs", "Exception", "range", "numpy.mean", "numpy.mean", "network_architecture_distributional.NetworkMLPDistributional", "test_iqn_ensemble.Tester.test_trainable_model.huber"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_replay_memory.Tester.append"], ["", "", "def", "test_trainable_model", "(", "self", ")", ":", "\n", "        ", "nb_inputs", "=", "10", "\n", "nb_actions", "=", "5", "\n", "nb_quantiles", "=", "32", "\n", "batch_size", "=", "64", "\n", "delta_clip", "=", "1", "\n", "nb_nets", "=", "3", "\n", "models", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "nb_nets", ")", ":", "\n", "            ", "models", ".", "append", "(", "NetworkMLPDistributional", "(", "nb_inputs", "=", "nb_inputs", ",", "nb_outputs", "=", "nb_actions", ",", "nb_hidden_layers", "=", "2", ",", "\n", "nb_hidden_neurons", "=", "100", ",", "nb_quantiles", "=", "nb_quantiles", ",", "\n", "nb_cos_embeddings", "=", "64", ",", "duel", "=", "True", ",", "\n", "prior", "=", "True", ",", "activation", "=", "'relu'", ",", "duel_type", "=", "'avg'", ",", "\n", "window_length", "=", "1", ",", "prior_scale_factor", "=", "1", ")", ".", "model", ")", "\n", "", "greedy_policy", "=", "DistributionalEpsGreedyPolicy", "(", "eps", "=", "0", ")", "\n", "test_policy", "=", "DistributionalEnsembleTestPolicy", "(", ")", "\n", "memory", "=", "BootstrappingMemory", "(", "nb_nets", "=", "self", ".", "nb_nets", ",", "limit", "=", "10000", ",", "adding_prob", "=", "0.5", ",", "window_length", "=", "1", ")", "\n", "agent", "=", "IqnRpfAgent", "(", "models", "=", "models", ",", "policy", "=", "greedy_policy", ",", "test_policy", "=", "test_policy", ",", "\n", "enable_double_dqn", "=", "True", ",", "\n", "nb_samples_policy", "=", "nb_quantiles", ",", "\n", "nb_sampled_quantiles", "=", "nb_quantiles", ",", "\n", "cvar_eta", "=", "1", ",", "\n", "nb_actions", "=", "nb_actions", ",", "memory", "=", "memory", ",", "\n", "gamma", "=", "0.99", ",", "batch_size", "=", "batch_size", ",", "\n", "nb_steps_warmup", "=", "1000", ",", "\n", "train_interval", "=", "1", ",", "\n", "memory_interval", "=", "1", ",", "\n", "target_model_update", "=", "1000", ",", "\n", "delta_clip", "=", "delta_clip", ")", "\n", "\n", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "plot_model", "(", "agent", ".", "trainable_models", "[", "0", "]", ",", "to_file", "=", "'iqn_ensemble_trainable_model_2.png'", ",", "show_shapes", "=", "True", ")", "\n", "\n", "# Test input", "\n", "states", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "1", ",", "nb_inputs", ")", "\n", "actions", "=", "np", ".", "random", ".", "randint", "(", "nb_actions", ",", "size", "=", "batch_size", ")", "\n", "quantiles", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "1", ",", "nb_quantiles", ")", "\n", "targets", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "nb_quantiles", ")", "\n", "\n", "predictions", "=", "agent", ".", "models", "[", "0", "]", ".", "predict_on_batch", "(", "[", "states", ",", "quantiles", "]", ")", "\n", "\n", "def", "huber", "(", "deltas", ",", "quantile", ")", ":", "\n", "            ", "if", "np", ".", "abs", "(", "deltas", ")", "<", "delta_clip", ":", "\n", "                ", "loss", "=", "0.5", "*", "deltas", "**", "2", "\n", "", "else", ":", "\n", "                ", "loss", "=", "delta_clip", "*", "(", "np", ".", "abs", "(", "deltas", ")", "-", "0.5", "*", "delta_clip", ")", "\n", "", "if", "deltas", ">", "0", ":", "\n", "                ", "loss", "*=", "quantile", "/", "delta_clip", "\n", "", "else", ":", "\n", "                ", "loss", "*=", "(", "1", "-", "quantile", ")", "/", "delta_clip", "\n", "", "if", "loss", "<", "0", ":", "\n", "                ", "raise", "Exception", "(", "\"Loss should always be positive\"", ")", "\n", "", "return", "loss", "\n", "\n", "", "true_loss", "=", "np", ".", "zeros", "(", "batch_size", ")", "\n", "for", "idx", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "nb_quantiles", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "nb_quantiles", ")", ":", "\n", "                    ", "true_loss", "[", "idx", "]", "+=", "huber", "(", "targets", "[", "idx", ",", "j", "]", "-", "predictions", "[", "idx", ",", "i", ",", "actions", "[", "idx", "]", "]", ",", "\n", "quantiles", "[", "idx", ",", "0", ",", "i", "]", ")", "\n", "", "", "true_loss", "[", "idx", "]", "*=", "1", "/", "nb_quantiles", "\n", "\n", "", "masks", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "nb_actions", ")", ")", "\n", "masks", "[", "range", "(", "batch_size", ")", ",", "actions", "]", "=", "1", "\n", "targets_expanded", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "nb_quantiles", ",", "nb_actions", ")", ")", "\n", "targets_expanded", "[", "range", "(", "batch_size", ")", ",", ":", ",", "actions", "]", "=", "targets", "[", "range", "(", "batch_size", ")", ",", ":", "]", "\n", "out", "=", "agent", ".", "trainable_models", "[", "0", "]", ".", "predict_on_batch", "(", "[", "states", ",", "quantiles", ",", "targets_expanded", ",", "masks", "]", ")", "\n", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "true_loss", ",", "out", "[", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "(", "predictions", "==", "out", "[", "1", "]", ")", ".", "all", "(", ")", ")", "\n", "\n", "metrics", "=", "agent", ".", "trainable_models", "[", "0", "]", ".", "train_on_batch", "(", "[", "states", ",", "quantiles", ",", "targets_expanded", ",", "masks", "]", ",", "\n", "[", "targets", ",", "targets_expanded", "]", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "np", ".", "mean", "(", "true_loss", ")", ",", "metrics", "[", "0", "]", ")", ")", "\n", "\n", "average_q_value", "=", "np", ".", "mean", "(", "predictions", ")", "\n", "average_max_q_value", "=", "np", ".", "mean", "(", "np", ".", "max", "(", "np", ".", "mean", "(", "predictions", ",", "axis", "=", "1", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "average_q_value", ",", "metrics", "[", "3", "]", ")", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "isclose", "(", "average_max_q_value", ",", "metrics", "[", "4", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_no_double_dqn": [[225, 242], ["test_iqn_ensemble.Tester.agent.compile", "range", "numpy.random.rand", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward", "range", "keras.optimizers.Adam", "numpy.random.rand", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward", "numpy.random.rand", "test_iqn_ensemble.Tester.agent.forward", "test_iqn_ensemble.Tester.agent.backward"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.Worker.compile", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.forward", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.dqn_ensemble.DQNAgentEnsembleParallel.backward"], ["", "def", "test_no_double_dqn", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "compile", "(", "Adam", "(", "lr", "=", "0.01", ")", ")", "\n", "self", ".", "agent", ".", "enable_double_dqn", "=", "False", "\n", "self", ".", "agent", ".", "training", "=", "True", "\n", "for", "_", "in", "range", "(", "0", ",", "1000", ")", ":", "# Fill up buffer", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "step", "=", "1001", "# Start training", "\n", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "observation", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "self", ".", "agent", ".", "forward", "(", "observation", ")", "\n", "self", ".", "agent", ".", "backward", "(", "0", ",", "terminal", "=", "False", ")", "\n", "", "self", ".", "agent", ".", "enable_double_dqn", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_iqn_ensemble.Tester.test_get_config": [[243, 245], ["test_iqn_ensemble.Tester.agent.get_config"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.memory.BootstrappingMemory.get_config"], ["", "def", "test_get_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "get_config", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__": [[12, 15], ["unittest.TestCase.__init__", "numpy.random.seed"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.__init__", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.seed"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Tester", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "np", ".", "random", ".", "seed", "(", "13", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_step": [[31, 40], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.env.step", "traci.close"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close"], ["", "def", "test_step", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "try", ":", "\n", "            ", "action", "=", "0", "\n", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_reset": [[41, 54], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "range", "test_intersection_env.Tester.env.reset", "range", "traci.close", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.env.step"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step"], ["", "", "def", "test_reset", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "try", ":", "\n", "            ", "action", "=", "0", "\n", "for", "_", "in", "range", "(", "9", ")", ":", "\n", "                ", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_gym_interface": [[55, 64], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "traci.close"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close"], ["", "", "def", "test_gym_interface", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "nb_actions", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "nb_observations", ",", "3", "+", "4", "*", "p", ".", "sim_params", "[", "'sensor_nb_vehicles'", "]", ")", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_sensor_model": [[65, 131], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "numpy.zeros", "numpy.array", "numpy.zeros", "numpy.array", "numpy.zeros", "numpy.array", "test_intersection_env.Tester.env.sensor_model", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertAlmostEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertAlmostEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "range", "test_intersection_env.Tester.env.sensor_model", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.sensor_model", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.sensor_model", "test_intersection_env.Tester.assertFalse", "traci.close", "numpy.array", "test_intersection_env.Tester.assertEqual", "sum", "numpy.array", "numpy.random.rand", "len", "sum", "zip", "numpy.random.rand", "numpy.random.rand", "zip", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.sensor_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.sensor_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.sensor_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.sensor_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close"], ["", "", "def", "test_sensor_model", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "env", ".", "sensor_range", "=", "200", "\n", "self", ".", "env", ".", "occlusion_dist", "=", "1e6", "\n", "self", ".", "env", ".", "sensor_noise", "=", "{", "'pos'", ":", "0", ",", "'speed'", ":", "0", ",", "'heading'", ":", "0", "}", "\n", "positions", "=", "np", ".", "zeros", "(", "[", "self", ".", "env", ".", "max_nb_vehicles", ",", "2", "]", ")", "\n", "rel_pos_intersect", "=", "np", ".", "array", "(", "[", "[", "1.6", ",", "0", "]", ",", "[", "-", "190", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", ",", "[", "190", ",", "self", ".", "env", ".", "lane_width", "/", "2", "]", ",", "\n", "[", "-", "205", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "]", ")", "\n", "positions", "[", "0", ":", "4", ",", ":", "]", "=", "rel_pos_intersect", "+", "np", ".", "array", "(", "self", ".", "env", ".", "intersection_pos", ")", "# Last vehicle outside sensor range", "\n", "speeds", "=", "np", ".", "zeros", "(", "[", "self", ".", "env", ".", "max_nb_vehicles", ",", "2", "]", ")", "\n", "speeds", "[", "0", ":", "4", ",", ":", "]", "=", "np", ".", "array", "(", "[", "[", "15.0", ",", "0", "]", ",", "[", "15", ",", "0.", "]", ",", "[", "0", ",", "0.", "]", ",", "[", "7.5", ",", "0", "]", "]", ")", "\n", "headings", "=", "np", ".", "zeros", "(", "self", ".", "env", ".", "max_nb_vehicles", ")", "\n", "headings", "[", "0", ":", "4", "]", "=", "np", ".", "array", "(", "[", "0", ",", "np", ".", "pi", "/", "2", ",", "3", "*", "np", ".", "pi", "/", "2", ",", "np", ".", "pi", "/", "2", "]", ")", "\n", "done", "=", "False", "\n", "state", "=", "[", "positions", ",", "speeds", ",", "headings", ",", "done", "]", "\n", "observation", "=", "self", ".", "env", ".", "sensor_model", "(", "state", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "0", "]", ",", "-", "2", "*", "p", ".", "sim_params", "[", "'ego_end_position'", "]", "/", "\n", "(", "p", ".", "sim_params", "[", "'ego_end_position'", "]", "-", "p", ".", "sim_params", "[", "'ego_start_position'", "]", ")", "+", "1", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "1", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "2", "]", ",", "-", "1", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "3", "]", ",", "-", "0.95", ")", "\n", "self", ".", "assertAlmostEqual", "(", "observation", "[", "4", "]", ",", "-", "1.6", "/", "200", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "5", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "6", "]", ",", "-", "0.5", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "7", "]", ",", "0.95", ")", "\n", "self", ".", "assertAlmostEqual", "(", "observation", "[", "8", "]", ",", "1.6", "/", "200", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "9", "]", ",", "-", "1", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "10", "]", ",", "0.5", ")", "\n", "for", "i", "in", "range", "(", "11", ",", "self", ".", "env", ".", "sensor_nb_vehicles", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "observation", "[", "i", "]", ",", "-", "1", ")", "\n", "\n", "", "rel_pos_intersect", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "30", "]", "\n", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect", ")", "]", "\n", "speeds", "[", "0", "]", "=", "[", "0", ",", "0", "]", "\n", "done", "=", "True", "\n", "state", "=", "[", "positions", ",", "speeds", ",", "headings", ",", "done", "]", "\n", "observation", "=", "self", ".", "env", ".", "sensor_model", "(", "state", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "0", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "1", "]", ",", "-", "1", ")", "\n", "self", ".", "assertEqual", "(", "observation", "[", "2", "]", ",", "1", ")", "\n", "\n", "self", ".", "env", ".", "max_nb_vehicles", "=", "self", ".", "env", ".", "sensor_nb_vehicles", "+", "5", "\n", "positions", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "env", ".", "sensor_nb_vehicles", "+", "5", ",", "2", ")", "*", "300", "+", "np", ".", "array", "(", "self", ".", "env", ".", "intersection_pos", ")", "\n", "positions", "[", "0", "]", "=", "self", ".", "env", ".", "intersection_pos", "\n", "speeds", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "env", ".", "sensor_nb_vehicles", "+", "5", ",", "2", ")", "*", "15", "\n", "headings", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "env", ".", "sensor_nb_vehicles", "+", "5", ")", "*", "2", "*", "np", ".", "pi", "\n", "state", "=", "[", "positions", ",", "speeds", ",", "headings", ",", "done", "]", "\n", "observation", "=", "self", ".", "env", ".", "sensor_model", "(", "state", ")", "\n", "self", ".", "assertTrue", "(", "(", "np", ".", "abs", "(", "observation", ")", "<=", "1", ")", ".", "all", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "observation", ")", ",", "3", "+", "self", ".", "env", ".", "sensor_nb_vehicles", "*", "4", ")", "\n", "\n", "# Noise", "\n", "self", ".", "env", ".", "sensor_noise", "=", "{", "'pos'", ":", "2", ",", "'speed'", ":", "2", ",", "'heading'", ":", "20", "/", "180", "*", "np", ".", "pi", "}", "\n", "rel_pos_intersect", "=", "[", "-", "50", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "positions", "[", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect", ")", "]", "\n", "# positions[1] = [950, 998.4]", "\n", "speeds", "[", "1", "]", "=", "[", "0", ",", "0", "]", "\n", "state", "=", "[", "positions", ",", "speeds", ",", "headings", ",", "done", "]", "\n", "observation", "=", "self", ".", "env", ".", "sensor_model", "(", "state", ")", "\n", "self", ".", "assertFalse", "(", "observation", "[", "5", "]", "==", "-", "1", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_occlusion_model": [[132, 161], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertFalse", "traci.close", "test_intersection_env.Tester.env.occlusion_model().all", "sum", "sum", "sum", "sum", "[].any", "[].any", "zip", "zip", "zip", "zip", "test_intersection_env.Tester.env.occlusion_model", "test_intersection_env.Tester.env.occlusion_model", "test_intersection_env.Tester.env.occlusion_model", "test_intersection_env.Tester.env.occlusion_model", "test_intersection_env.Tester.env.occlusion_model", "test_intersection_env.Tester.env.occlusion_model"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.occlusion_model"], ["", "", "def", "test_occlusion_model", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "try", ":", "\n", "            ", "self", ".", "env", ".", "occlusion_dist", "=", "1e6", "\n", "self", ".", "assertTrue", "(", "self", ".", "env", ".", "occlusion_model", "(", "-", "100", ")", ".", "all", "(", ")", ")", "\n", "\n", "self", ".", "env", ".", "occlusion_dist", "=", "2", "\n", "rel_pos_intersect", "=", "[", "0", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "1", ",", ":", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "1", "]", "=", "0", "\n", "rel_pos_intersect", "=", "[", "0", ",", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "2", ",", ":", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "2", "]", "=", "np", ".", "pi", "\n", "rel_pos_intersect", "=", "[", "-", "10.4", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "3", ",", ":", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "3", "]", "=", "0", "\n", "rel_pos_intersect", "=", "[", "-", "14.4", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "4", ",", ":", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "4", "]", "=", "0", "\n", "self", ".", "assertTrue", "(", "self", ".", "env", ".", "occlusion_model", "(", "-", "100", ")", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "self", ".", "env", ".", "occlusion_model", "(", "-", "100", ")", "[", "1", "]", ")", "\n", "self", ".", "assertFalse", "(", "self", ".", "env", ".", "occlusion_model", "(", "-", "100", ")", "[", "2", ":", "]", ".", "any", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "self", ".", "env", ".", "occlusion_model", "(", "-", "10", ")", "[", "2", "]", ")", "\n", "self", ".", "assertFalse", "(", "self", ".", "env", ".", "occlusion_model", "(", "-", "10", ")", "[", "3", ":", "]", ".", "any", "(", ")", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_reward_model": [[162, 178], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "traci.close", "test_intersection_env.Tester.env.reward_model", "test_intersection_env.Tester.env.reward_model", "test_intersection_env.Tester.env.reward_model", "test_intersection_env.Tester.env.reward_model"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reward_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reward_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reward_model", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reward_model"], ["", "", "def", "test_reward_model", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "reward_model", "(", "goal_reached", "=", "False", ",", "collision", "=", "False", ",", "\n", "near_collision", "=", "False", ")", "[", "0", "]", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "reward_model", "(", "goal_reached", "=", "True", ",", "collision", "=", "False", ",", "near_collision", "=", "False", ")", "[", "0", "]", ",", "\n", "p", ".", "sim_params", "[", "'goal_reward'", "]", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "reward_model", "(", "goal_reached", "=", "False", ",", "collision", "=", "True", ",", "near_collision", "=", "False", ")", "[", "0", "]", ",", "\n", "p", ".", "sim_params", "[", "'collision_penalty'", "]", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "reward_model", "(", "goal_reached", "=", "False", ",", "collision", "=", "False", ",", "near_collision", "=", "True", ")", "[", "0", "]", ",", "\n", "p", ".", "sim_params", "[", "'near_collision_penalty'", "]", ")", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_action_model": [[179, 209], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.assertLess", "range", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.assertGreater", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "traci.close", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.env.step"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step"], ["", "", "def", "test_action_model", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "try", ":", "\n", "            ", "ego_speed_0", "=", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "\n", "self", ".", "env", ".", "step", "(", "2", ")", "\n", "self", ".", "assertLess", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "ego_speed_0", ")", "\n", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                ", "self", ".", "env", ".", "step", "(", "2", ")", "\n", "", "ego_speed_0", "=", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "env", ".", "step", "(", "0", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "ego_speed_0", ")", "\n", "\n", "self", ".", "env", ".", "step", "(", "1", ")", "\n", "self", ".", "assertGreater", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "ego_speed_0", ")", "\n", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "env", ".", "step", "(", "1", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "self", ".", "env", ".", "max_ego_speed", ")", "\n", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "                ", "_", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "2", ")", "\n", "", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "0", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_safe_action": [[210, 240], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.assertGreater", "test_intersection_env.Tester.env.step", "test_intersection_env.Tester.assertEqual", "traci.close"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close"], ["", "", "def", "test_safe_action", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "try", ":", "\n", "# Stop at intersection", "\n", "            ", "ego_speed_0", "=", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "[", "1", "]", "=", "p", ".", "road_params", "[", "'intersection_position'", "]", "[", "1", "]", "-", "50", "\n", "self", ".", "env", ".", "step", "(", "3", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "ego_speed_0", "+", "p", ".", "sim_params", "[", "'idm_params'", "]", "[", "'a_min'", "]", ")", "\n", "\n", "# Use original action", "\n", "ego_speed_0", "=", "5", "\n", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "=", "ego_speed_0", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "[", "1", "]", "=", "p", ".", "road_params", "[", "'intersection_position'", "]", "[", "1", "]", "-", "p", ".", "road_params", "[", "'stop_line'", "]", "+", "1", "\n", "self", ".", "env", ".", "step", "(", "3", ",", "{", "'original_action'", ":", "0", "}", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "ego_speed_0", ")", "\n", "\n", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "=", "ego_speed_0", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "[", "1", "]", "=", "p", ".", "road_params", "[", "'intersection_position'", "]", "[", "1", "]", "-", "p", ".", "road_params", "[", "'stop_line'", "]", "+", "1", "\n", "self", ".", "env", ".", "step", "(", "3", ",", "{", "'original_action'", ":", "1", "}", ")", "\n", "self", ".", "assertGreater", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "ego_speed_0", ")", "\n", "\n", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "=", "ego_speed_0", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "[", "1", "]", "=", "p", ".", "road_params", "[", "'intersection_position'", "]", "[", "1", "]", "-", "p", ".", "road_params", "[", "'stop_line'", "]", "+", "1", "\n", "self", ".", "env", ".", "step", "(", "3", ",", "{", "'original_action'", ":", "2", "}", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", ",", "ego_speed_0", "+", "p", ".", "sim_params", "[", "'idm_params'", "]", "[", "'a_min'", "]", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_collision_detection": [[241, 626], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.assertTrue", "test_intersection_env.Tester.env.collision_detection", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertFalse", "test_intersection_env.Tester.assertEqual", "traci.close", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "zip", "zip", "zip", "zip", "str", "zip", "zip", "str", "zip", "str", "str", "zip", "zip", "zip", "zip", "zip", "str", "zip", "str", "zip", "zip", "str", "zip", "str", "zip", "zip", "zip", "zip", "zip", "str", "zip", "str", "zip", "zip", "str", "zip", "str", "zip", "zip", "zip", "zip", "str", "zip", "str", "zip", "zip", "str", "zip", "zip", "str", "zip", "zip", "zip", "str", "zip", "zip", "zip", "str", "zip", "zip", "zip", "zip", "zip", "zip", "str", "zip", "zip", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.collision_detection", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close"], ["", "", "def", "test_collision_detection", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "nb_cars", "=", "self", ".", "env", ".", "positions", ".", "shape", "[", "0", "]", "-", "1", "\n", "try", ":", "\n", "# Outside intersection", "\n", "            ", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "'Ego before_intersection'", ")", "\n", "rel_pos_intersect", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "50", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", ",", ":", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "\n", "# Collision", "\n", "# West bound", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "0", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "+", "0.1", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "-", "0.1", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertTrue", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "# North bound", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "ego_length", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "+", "0.1", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "/", "2", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "ego_length", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "-", "0.1", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "/", "2", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertTrue", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "# East bound", "\n", "rel_pos_intersect_2", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_width", "/", "2", "-", "self", ".", "env", ".", "car_length", "/", "2", "+", "0.1", ",", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "2", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_2", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "2", "]", "=", "0", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertTrue", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", "-", "1", ")", "in", "info", "[", "1", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "# Near collision, west", "\n", "# Within x margin, but ego vehicle too high", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "ego_length", "/", "2", "+", "self", ".", "env", ".", "car_width", "/", "2", "\n", "+", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "+", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "-", "0.1", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "# Within x margin, but ego vehicle too low", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "ego_length", "/", "2", "-", "self", ".", "env", ".", "car_width", "/", "2", "\n", "+", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "-", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "-", "0.1", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "# Within x margin right", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "0", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "# Within x margin left", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_width", "/", "2", "-", "self", ".", "env", ".", "car_length", "/", "2", "\n", "-", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "+", "0.1", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "# Within y margin top", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "ego_length", "/", "2", "+", "self", ".", "env", ".", "car_width", "/", "2", "\n", "+", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "-", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "-", "0.1", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "# Within y margin bottom", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "ego_length", "/", "2", "-", "self", ".", "env", ".", "car_width", "/", "2", "\n", "+", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "+", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "\n", "# Near collision, east", "\n", "# Within margin but ego vehicle too high", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "ego_length", "/", "2", "+", "self", ".", "env", ".", "car_width", "/", "2", "\n", "+", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "+", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_width", "/", "2", "-", "self", ".", "env", ".", "car_length", "/", "2", "\n", "-", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "+", "0.1", ",", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "0", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "# Within margin but ego vehicle too low", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "ego_length", "/", "2", "-", "self", ".", "env", ".", "car_width", "/", "2", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "-", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_width", "/", "2", "-", "self", ".", "env", ".", "car_length", "/", "2", "\n", "-", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "+", "0.1", ",", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "0", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "# Within margin left", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "0", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "# Within margin right", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "-", "0.1", ",", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "0", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "# Within y margin top", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "ego_length", "/", "2", "+", "self", ".", "env", ".", "car_width", "/", "2", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "-", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_width", "/", "2", "-", "self", ".", "env", ".", "car_length", "/", "2", "+", "0.1", ",", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "0", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "# Within y margin bottom", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "ego_length", "/", "2", "-", "self", ".", "env", ".", "car_width", "/", "2", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "+", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "\n", "# Turning vehicle", "\n", "# South", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "0", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "-", "3.84", ",", "-", "3.2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "5.6012", "\n", "self", ".", "env", ".", "positions", "[", "-", "2", "]", "=", "self", ".", "env", ".", "positions", "[", "-", "3", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "rel_pos_intersect_1", "=", "[", "-", "1.66", ",", "-", "8.79", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "4.7363", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "# North", "\n", "rel_pos_intersect_1", "=", "[", "3.84", ",", "3.2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "2.4596", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertTrue", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "3.2", "-", "self", ".", "env", ".", "ego_length", "/", "2", "-", "self", ".", "env", ".", "car_width", "/", "2", "-", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "0", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "ego_length", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "-", "0.1", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "/", "2", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "\n", "# Collision between time steps", "\n", "# East", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "-", "5", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "=", "[", "15", ",", "0", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "\n", "+", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "[", "0", "]", "-", "5", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "0", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertTrue", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "+", "1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "# West", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "-", "5", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "=", "[", "15", ",", "0", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_width", "/", "2", "-", "self", ".", "env", ".", "car_length", "/", "2", "\n", "-", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "[", "0", "]", "+", "5", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertTrue", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "+", "1", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "\n", "# Near collision between time steps", "\n", "# East", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "-", "0.6", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "=", "[", "15", ",", "0", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_width", "/", "2", "-", "self", ".", "env", ".", "car_length", "/", "2", "\n", "+", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "[", "0", "]", "-", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "-", "0.5", ",", "\n", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "0", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "+", "0.5", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "=", "0", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "-", "self", ".", "env", ".", "car_width", "/", "2", "-", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "+", "0.5", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "=", "[", "15", ",", "0", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "-", "self", ".", "env", ".", "ego_width", "/", "2", "-", "self", ".", "env", ".", "car_length", "/", "2", "\n", "+", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "[", "0", "]", "-", "3", ",", "-", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "0", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "-", "self", ".", "env", ".", "stop_line", "-", "self", ".", "env", ".", "ego_length", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "# West", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "-", "0.6", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "=", "[", "15", ",", "0", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "\n", "-", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "[", "0", "]", "+", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "+", "0.5", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "self", ".", "assertTrue", "(", "str", "(", "nb_cars", ")", "in", "info", "[", "1", "]", ")", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "+", "0.5", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "=", "1", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "-", "0.5", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "=", "[", "15", ",", "0", "]", "\n", "rel_pos_intersect_1", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_width", "/", "2", "+", "self", ".", "env", ".", "car_length", "/", "2", "\n", "-", "self", ".", "env", ".", "speeds", "[", "-", "1", "]", "[", "0", "]", "+", "self", ".", "env", ".", "near_collision_margin", "[", "0", "]", "+", "0.5", ",", "\n", "self", ".", "env", ".", "lane_width", "/", "2", "]", "\n", "self", ".", "env", ".", "positions", "[", "-", "1", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_1", ")", "]", "\n", "self", ".", "env", ".", "headings", "[", "-", "1", "]", "=", "np", ".", "pi", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertTrue", "(", "near_collision", ")", "\n", "self", ".", "assertTrue", "(", "'near_collision'", "==", "info", "[", "0", "]", ")", "\n", "rel_pos_intersect_0", "=", "[", "self", ".", "env", ".", "lane_width", "/", "2", ",", "self", ".", "env", ".", "lane_width", "/", "2", "+", "self", ".", "env", ".", "ego_length", "/", "2", "\n", "+", "self", ".", "env", ".", "car_width", "/", "2", "+", "self", ".", "env", ".", "speeds", "[", "0", "]", "[", "0", "]", "\n", "+", "self", ".", "env", ".", "near_collision_margin", "[", "1", "]", "+", "0.5", "]", "\n", "self", ".", "env", ".", "positions", "[", "0", "]", "=", "[", "sum", "(", "e", ")", "for", "e", "in", "zip", "(", "self", ".", "env", ".", "intersection_pos", ",", "rel_pos_intersect_0", ")", "]", "\n", "collision", ",", "near_collision", ",", "info", "=", "self", ".", "env", ".", "collision_detection", "(", ")", "\n", "self", ".", "assertFalse", "(", "collision", ")", "\n", "self", ".", "assertFalse", "(", "near_collision", ")", "\n", "self", ".", "assertEqual", "(", "info", ",", "''", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.tests.test_intersection_env.Tester.test_timeout": [[627, 641], ["intersection_env.IntersectionEnv", "test_intersection_env.Tester.env.reset", "test_intersection_env.Tester.assertEqual", "test_intersection_env.Tester.assertEqual", "traci.close", "test_intersection_env.Tester.env.step"], "methods", ["home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.reset", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.core.Env.close", "home.repos.pwc.inspect_result.carljohanhoel_EnsembleQuantileNetworks.src.intersection_env.IntersectionEnv.step"], ["", "", "def", "test_timeout", "(", "self", ")", ":", "\n", "        ", "gui_params", "=", "{", "'use_gui'", ":", "False", ",", "'print_gui_info'", ":", "False", ",", "'draw_sensor_range'", ":", "False", ",", "'zoom_level'", ":", "3000", "}", "\n", "self", ".", "env", "=", "IntersectionEnv", "(", "sim_params", "=", "p", ".", "sim_params", ",", "road_params", "=", "p", ".", "road_params", ",", "gui_params", "=", "gui_params", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "try", ":", "\n", "            ", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "                ", "_", ",", "_", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "2", ")", "# Action stop at intersection", "\n", "", "self", ".", "assertEqual", "(", "self", ".", "env", ".", "step_", ",", "p", ".", "sim_params", "[", "'max_steps'", "]", ")", "\n", "self", ".", "assertEqual", "(", "'Max steps'", ",", "info", "[", "'terminal_reason'", "]", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "traci", ".", "close", "(", ")", "\n", "\n"]]}