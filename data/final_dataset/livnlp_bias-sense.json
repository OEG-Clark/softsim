{"home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.WordEmbedding.__init__": [[248, 255], ["eval-sssb-sense.WordEmbedding.load_lmms", "print", "len"], "methods", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.load_lmms"], ["    ", "def", "__init__", "(", "self", ",", "fname", ")", ":", "\n", "        ", "\"\"\"\n        Load the word embeddings from fname.\n        \"\"\"", "\n", "self", ".", "embed", "=", "self", ".", "load_lmms", "(", "fname", ")", "\n", "print", "(", "\"Total number of vectors =\"", ",", "len", "(", "self", ".", "embed", ")", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.WordEmbedding.load_lmms": [[256, 265], ["numpy.load", "loader[].tolist", "list", "zip"], "methods", ["None"], ["", "def", "load_lmms", "(", "self", ",", "npz_vecs_path", ")", ":", "\n", "        ", "lmms", "=", "{", "}", "\n", "loader", "=", "np", ".", "load", "(", "npz_vecs_path", ")", "\n", "labels", "=", "loader", "[", "'labels'", "]", ".", "tolist", "(", ")", "\n", "vectors", "=", "loader", "[", "'vectors'", "]", "\n", "self", ".", "dim", "=", "vectors", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "for", "label", ",", "vector", "in", "list", "(", "zip", "(", "labels", ",", "vectors", ")", ")", ":", "\n", "            ", "lmms", "[", "label", "]", "=", "vector", "\n", "", "return", "lmms", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.WordEmbedding.get_vector": [[266, 274], ["eval-sssb-sense.WordEmbedding.embed.get", "numpy.zeros"], "methods", ["None"], ["", "def", "get_vector", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\"\n        If the label is not a sense-id (i.e. in the case of sense-insensitive static word embeddings)\n        return the word embedding instead of sense embedding. You will need to modify this function \n        according to the word embedding you want to evaluate. If the word is not in the sense embedding\n        return a zero vector of the same dimensionality.\n        \"\"\"", "\n", "return", "self", ".", "embed", ".", "get", "(", "label", ",", "np", ".", "zeros", "(", "self", ".", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.find_sense_id": [[15, 22], ["nltk.corpus.wordnet.synsets", "print", "[].key", "x.pos", "x.definition", "x.lemmas"], "function", ["None"], ["def", "find_sense_id", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Print the sense ids of words.\n    \"\"\"", "\n", "synsets", "=", "wn", ".", "synsets", "(", "word", ")", "\n", "for", "x", "in", "synsets", ":", "\n", "        ", "print", "(", "x", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", ",", "x", ".", "pos", "(", ")", ",", "\"===\"", ",", "x", ".", "definition", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.cosine": [[24, 27], ["numpy.linalg.norm", "numpy.dot"], "function", ["None"], ["", "", "def", "cosine", "(", "x", ",", "y", ")", ":", "\n", "    ", "norm", "=", "np", ".", "linalg", ".", "norm", "(", "y", ")", "\n", "return", "(", "np", ".", "dot", "(", "x", ",", "y", ")", "/", "norm", ")", "if", "norm", ">", "0", "else", "0", "\n", "#return np.dot(x,y) / np.linalg.norm(y) if np.linalg.norm(0) > 0 else 0", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.sample_and_average": [[30, 46], ["range", "len", "numpy.random.choice", "numpy.mean", "numpy.std", "scores.append", "numpy.mean", "scipy.stats.sem", "len", "eval-sssb-sense.cosine"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine"], ["", "def", "sample_and_average", "(", "L", ",", "x", ")", ":", "\n", "    ", "\"\"\"\n    L is a list of vectors, all representing a particular type of bias.\n    x is the embedding of a word that we would like to evaluate for its bias.\n    We will subsample vectors from L, compute the mean and measure cosine similarity with x.\n    We will then compute a sigificance score based on these multiple similarities.\n    \"\"\"", "\n", "sample_size", "=", "len", "(", "L", ")", "//", "2", "\n", "scores", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "5000", ")", ":", "\n", "        ", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "L", ")", ",", "size", "=", "sample_size", ")", "\n", "diff", "=", "[", "cosine", "(", "x", ",", "L", "[", "i", "]", ")", "for", "i", "in", "idx", "]", "\n", "mean_diff", "=", "np", ".", "mean", "(", "diff", ")", "\n", "sd_diff", "=", "np", ".", "std", "(", "diff", ")", "\n", "scores", ".", "append", "(", "mean_diff", "/", "sd_diff", ")", "\n", "", "return", "np", ".", "mean", "(", "scores", ")", ",", "stats", ".", "sem", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.two_sided_sampling": [[48, 68], ["range", "min", "random.randint", "numpy.random.choice", "numpy.random.choice", "bias_scores.append", "numpy.mean", "scipy.stats.sem", "len", "len", "len", "eval-sssb-sense.cosine", "numpy.mean", "numpy.std", "len", "eval-sssb-sense.cosine", "numpy.mean", "numpy.std"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine"], ["", "def", "two_sided_sampling", "(", "x", ",", "positives", ",", "negatives", ")", ":", "\n", "    ", "\"\"\"\n    Sample equal size adjective sets from positive and negative adjectives.\n    Measure the average cosine similarity between the target sense and each sample.\n    Compute the difference of the similarity between positive and negative adjective sets.\n    Compute the mean and standard error on these differences.\n    If the mean difference is zero, then there is no ethnic bias.\n    \"\"\"", "\n", "bias_scores", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "5000", ")", ":", "\n", "        ", "t", "=", "min", "(", "len", "(", "positives", ")", ",", "len", "(", "negatives", ")", ")", "\n", "sample_size", "=", "random", ".", "randint", "(", "t", "//", "2", ",", "t", ")", "\n", "pos_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "positives", ")", ",", "size", "=", "sample_size", ")", "\n", "pos_scores", "=", "[", "cosine", "(", "x", ",", "positives", "[", "i", "]", ")", "for", "i", "in", "pos_idx", "]", "\n", "pos_score", "=", "np", ".", "mean", "(", "pos_scores", ")", "/", "np", ".", "std", "(", "pos_scores", ")", "\n", "neg_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "negatives", ")", ",", "size", "=", "sample_size", ")", "\n", "neg_scores", "=", "[", "cosine", "(", "x", ",", "negatives", "[", "i", "]", ")", "for", "i", "in", "neg_idx", "]", "\n", "neg_score", "=", "np", ".", "mean", "(", "neg_scores", ")", "/", "np", ".", "std", "(", "neg_scores", ")", "\n", "bias_scores", ".", "append", "(", "pos_score", "-", "neg_score", ")", "\n", "", "return", "np", ".", "mean", "(", "bias_scores", ")", ",", "stats", ".", "sem", "(", "bias_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.load_positives_negatives": [[69, 115], ["print", "print", "min", "open", "len", "open", "len", "len", "len", "line.strip", "nltk.corpus.wordnet.synsets", "positives.append", "line.strip", "nltk.corpus.wordnet.synsets", "negatives.append", "[].key", "int", "len", "WE.get_vector", "[].key", "int", "len", "WE.get_vector", "adj_synsets.append", "adj_synsets.append", "[].split", "[].split", "synset.lemmas", "synset.lemmas", "[].key.split", "[].key.split"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector"], ["", "def", "load_positives_negatives", "(", "WE", ")", ":", "\n", "    ", "\"\"\"\n    Load positive and negative adjectives from files. \n    We will consider the first adjectivial sense for each word.\n    \"\"\"", "\n", "positives", "=", "[", "]", "\n", "with", "open", "(", "\"./data/positive-adjectives\"", ")", "as", "pos_file", ":", "\n", "        ", "for", "line", "in", "pos_file", ":", "\n", "            ", "word", "=", "line", ".", "strip", "(", ")", "\n", "synsets", "=", "wn", ".", "synsets", "(", "word", ")", "\n", "adj_synsets", "=", "[", "]", "\n", "for", "synset", "in", "synsets", ":", "\n", "                ", "sid", "=", "synset", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", "\n", "pos", "=", "int", "(", "sid", ".", "split", "(", "\"%\"", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "0", "]", ")", "\n", "if", "pos", "==", "3", ":", "\n", "                    ", "adj_synsets", ".", "append", "(", "sid", ")", "\n", "", "", "if", "len", "(", "adj_synsets", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "adj_sid", "=", "adj_synsets", "[", "0", "]", "\n", "if", "adj_sid", "not", "in", "WE", ".", "embed", ":", "\n", "                ", "continue", "\n", "", "positives", ".", "append", "(", "WE", ".", "get_vector", "(", "adj_sid", ")", ")", "\n", "", "", "print", "(", "\"Total number of positive adjectives =\"", ",", "len", "(", "positives", ")", ")", "\n", "\n", "negatives", "=", "[", "]", "\n", "with", "open", "(", "\"./data/negative-adjectives\"", ")", "as", "neg_file", ":", "\n", "        ", "for", "line", "in", "neg_file", ":", "\n", "            ", "word", "=", "line", ".", "strip", "(", ")", "\n", "synsets", "=", "wn", ".", "synsets", "(", "word", ")", "\n", "adj_synsets", "=", "[", "]", "\n", "for", "synset", "in", "synsets", ":", "\n", "                ", "sid", "=", "synset", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", "\n", "pos", "=", "int", "(", "sid", ".", "split", "(", "\"%\"", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "0", "]", ")", "\n", "if", "pos", "==", "3", ":", "\n", "                    ", "adj_synsets", ".", "append", "(", "sid", ")", "\n", "", "", "if", "len", "(", "adj_synsets", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "adj_sid", "=", "adj_synsets", "[", "0", "]", "\n", "if", "adj_sid", "not", "in", "WE", ".", "embed", ":", "\n", "                ", "continue", "\n", "", "negatives", ".", "append", "(", "WE", ".", "get_vector", "(", "adj_sid", ")", ")", "\n", "", "", "print", "(", "\"Total number of negative adjectives =\"", ",", "len", "(", "negatives", ")", ")", "\n", "t", "=", "min", "(", "len", "(", "positives", ")", ",", "len", "(", "negatives", ")", ")", "\n", "positives", "=", "positives", "[", ":", "t", "]", "\n", "negatives", "=", "negatives", "[", ":", "t", "]", "\n", "return", "positives", ",", "negatives", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.eval_ethnic_bias": [[117, 144], ["eval-sssb-sense.load_positives_negatives", "eval-sssb-sense.two_sided_sampling", "eval-sssb-sense.two_sided_sampling", "pandas.DataFrame", "print", "print", "print", "WE.get_vector", "WE.get_vector"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.load_positives_negatives", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector"], ["", "def", "eval_ethnic_bias", "(", "WE", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate the black as ethnic group vs. colour bias.\n    \"\"\"", "\n", "#balck_ethnic_sid = \"black%1:18:00::\" # noun ", "\n", "#black_colour_sid = \"black%1:07:00::\"  # noun", "\n", "\n", "balck_ethnic_sid", "=", "\"black%3:00:02::\"", "# adj", "\n", "black_colour_sid", "=", "\"black%3:00:01::\"", "# adj", "\n", "\n", "positives", ",", "negatives", "=", "load_positives_negatives", "(", "WE", ")", "\n", "\n", "if", "black_colour_sid", "not", "in", "WE", ".", "embed", ":", "\n", "        ", "print", "(", "\"Colour sense of black missing\"", ")", "\n", "raise", "ValueError", "\n", "\n", "", "if", "balck_ethnic_sid", "not", "in", "WE", ".", "embed", ":", "\n", "        ", "print", "(", "\"Ethnic sense of black missing\"", ")", "\n", "raise", "ValueError", "\n", "\n", "", "colour_bias", ",", "colour_err", "=", "two_sided_sampling", "(", "WE", ".", "get_vector", "(", "black_colour_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "ethnic_bias", ",", "ethnic_err", "=", "two_sided_sampling", "(", "WE", ".", "get_vector", "(", "balck_ethnic_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "res", "=", "{", "\"black\"", ":", "{", "\"colour_bias\"", ":", "colour_bias", ",", "\"colour_err\"", ":", "colour_err", ",", "\n", "\"ethnic_bias\"", ":", "ethnic_bias", ",", "\"ethnic_err\"", ":", "ethnic_err", "}", "}", "\n", "df", "=", "pd", ".", "DataFrame", "(", "data", "=", "res", ")", "\n", "print", "(", "df", ".", "T", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.eval_racial_bias": [[146, 180], ["eval-sssb-sense.load_positives_negatives", "pandas.DataFrame", "pd.DataFrame.copy", "pd.DataFrame.T.abs().mean", "print", "eval-sssb-sense.two_sided_sampling", "eval-sssb-sense.two_sided_sampling", "print", "print", "print", "WE.get_vector", "WE.get_vector", "pd.DataFrame.T.abs", "nation.lower", "nation.lower"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.load_positives_negatives", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector"], ["", "def", "eval_racial_bias", "(", "WE", ")", ":", "\n", "    ", "\"\"\"\n    Evaluatte nationalities vs. languages.\n    \"\"\"", "\n", "nationalities", "=", "[", "\"Japanese\"", ",", "\"Chinese\"", ",", "\"English\"", ",", "\"Arabic\"", ",", "\"German\"", ",", "\n", "\"French\"", ",", "\"Spanish\"", ",", "\"Portuguese\"", ",", "\"Norwegian\"", ",", "\"Swedish\"", ",", "\"Polish\"", ",", "\"Romanian\"", ",", "\n", "\"Russian\"", ",", "\"Egyptian\"", ",", "\"Finnish\"", ",", "\"Vietnamese\"", "]", "\n", "\n", "people_sid_suffix", "=", "\"%1:18:00::\"", "\n", "lang_sid_suffix", "=", "\"%1:10:00::\"", "\n", "\n", "positives", ",", "negatives", "=", "load_positives_negatives", "(", "WE", ")", "\n", "res", "=", "{", "}", "\n", "for", "nation", "in", "nationalities", ":", "\n", "        ", "people_sid", "=", "\"%s%s\"", "%", "(", "nation", ".", "lower", "(", ")", ",", "people_sid_suffix", ")", "\n", "lang_sid", "=", "\"%s%s\"", "%", "(", "nation", ".", "lower", "(", ")", ",", "lang_sid_suffix", ")", "\n", "both_senses_found", "=", "True", "\n", "if", "people_sid", "not", "in", "WE", ".", "embed", ":", "\n", "            ", "print", "(", "\"People sense of {0} not found!\"", ".", "format", "(", "nation", ")", ")", "\n", "both_senses_found", "=", "False", "\n", "", "if", "lang_sid", "not", "in", "WE", ".", "embed", ":", "\n", "            ", "print", "(", "\"Language sense of {0} not found!\"", ".", "format", "(", "nation", ")", ")", "\n", "both_senses_found", "=", "False", "\n", "", "if", "not", "both_senses_found", ":", "\n", "            ", "print", "(", "\"Skipping {0}\"", ".", "format", "(", "nation", ")", ")", "\n", "continue", "\n", "", "res", "[", "nation", "]", "=", "{", "}", "\n", "res", "[", "nation", "]", "[", "\"people_bias\"", "]", ",", "res", "[", "nation", "]", "[", "\"people_err\"", "]", "=", "two_sided_sampling", "(", "WE", ".", "get_vector", "(", "people_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "res", "[", "nation", "]", "[", "\"lang_bias\"", "]", ",", "res", "[", "nation", "]", "[", "\"lang_err\"", "]", "=", "two_sided_sampling", "(", "WE", ".", "get_vector", "(", "lang_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "data", "=", "res", ")", "\n", "avg", "=", "df", ".", "copy", "(", ")", "\n", "avg", "[", "'mean'", "]", "=", "df", ".", "T", ".", "abs", "(", ")", ".", "mean", "(", "numeric_only", "=", "1", ")", "\n", "print", "(", "avg", ".", "T", ")", "\n", "return", "avg", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.eval_gender_bias": [[182, 245], ["list", "pandas.DataFrame", "pd.DataFrame.copy", "pd.DataFrame.T.abs().mean", "print", "open", "open", "zip", "nltk.corpus.wordnet.synsets", "nltk.corpus.wordnet.synsets", "[].key", "[].key", "gender_vects.append", "male_words.append", "female_words.append", "print", "WE.get_vector", "eval-sssb-sense.sample_and_average", "print", "WE.get_vector", "eval-sssb-sense.sample_and_average", "pd.DataFrame.T.abs", "line.strip", "line.strip", "len", "len", "WE.get_vector", "WE.get_vector", "male_synset[].lemmas", "female_synset[].lemmas"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.sample_and_average", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.sample_and_average", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector"], ["", "def", "eval_gender_bias", "(", "WE", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate gender bias, where we first define the gender direction by the vector offset of\n    word-pairs describing male vs. female attributes. We will then evaluate noun and verb senses\n    of a list of target words and return their individual and aggregated scores with statistical\n    significance scores (evaluated according to a boostrapping test).\n    \"\"\"", "\n", "male_words", "=", "[", "]", "\n", "with", "open", "(", "\"./data/male_word_file.txt\"", ")", "as", "male_file", ":", "\n", "        ", "for", "line", "in", "male_file", ":", "\n", "            ", "male_words", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "female_words", "=", "[", "]", "\n", "with", "open", "(", "\"./data/female_word_file.txt\"", ")", "as", "female_file", ":", "\n", "        ", "for", "line", "in", "female_file", ":", "\n", "            ", "female_words", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "gender_pairs", "=", "list", "(", "zip", "(", "male_words", ",", "female_words", ")", ")", "\n", "gender_vects", "=", "[", "]", "\n", "\n", "for", "(", "male", ",", "female", ")", "in", "gender_pairs", ":", "\n", "#print(male,female)", "\n", "        ", "male_synset", "=", "wn", ".", "synsets", "(", "male", ")", "\n", "female_synset", "=", "wn", ".", "synsets", "(", "female", ")", "\n", "if", "len", "(", "male_synset", ")", "==", "0", "or", "len", "(", "female_synset", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "male_sid", "=", "male_synset", "[", "0", "]", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", "\n", "female_sid", "=", "female_synset", "[", "0", "]", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", "\n", "#print(male_sid, female_sid)", "\n", "gender_vects", ".", "append", "(", "WE", ".", "get_vector", "(", "male_sid", ")", "-", "WE", ".", "get_vector", "(", "female_sid", ")", ")", "\n", "#print(\"Total number of gender word-pairs =\", len(gender_pairs))", "\n", "\n", "", "occupations", "=", "[", "(", "\"engineer\"", ",", "\"engineer%1:18:00::\"", ",", "\"engineer%2:31:01::\"", ")", ",", "\n", "(", "\"carpenter\"", ",", "\"carpenter%1:18:00::\"", ",", "\"carpenter%2:41:00::\"", ")", ",", "\n", "(", "\"guide\"", ",", "\"guide%1:18:00::\"", ",", "\"guide%2:38:00::\"", ")", ",", "\n", "(", "\"mentor\"", ",", "\"mentor%1:18:00::\"", ",", "\"mentor%2:32:00::\"", ")", ",", "\n", "(", "\"judge\"", ",", "\"judge%1:18:00::\"", ",", "\"judge%2:31:02::\"", ")", ",", "\n", "(", "\"nurse\"", ",", "\"nurse%1:18:00::\"", ",", "\"nurse%2:29:00::\"", ")", "]", "\n", "\n", "res", "=", "{", "}", "\n", "for", "(", "word", ",", "noun_sid", ",", "verb_sid", ")", "in", "occupations", ":", "\n", "        ", "res", "[", "word", "]", "=", "{", "}", "\n", "if", "noun_sid", "not", "in", "WE", ".", "embed", ":", "\n", "            ", "print", "(", "\"Noun Sense Embedding Not Found for =\"", ",", "word", ")", "\n", "bias_score", ",", "bias_error", "=", "0", ",", "0", "\n", "", "else", ":", "\n", "            ", "noun_emb", "=", "WE", ".", "get_vector", "(", "noun_sid", ")", "\n", "bias_score", ",", "bias_error", "=", "sample_and_average", "(", "gender_vects", ",", "noun_emb", ")", "\n", "", "res", "[", "word", "]", "[", "\"noun_bias\"", "]", "=", "bias_score", "\n", "res", "[", "word", "]", "[", "\"noun_err\"", "]", "=", "bias_error", "\n", "\n", "if", "verb_sid", "not", "in", "WE", ".", "embed", ":", "\n", "            ", "print", "(", "\"Verb Sense Embedding Not Found for =\"", ",", "word", ")", "\n", "bias_score", ",", "bias_error", "=", "0", ",", "0", "\n", "", "else", ":", "\n", "            ", "verb_emb", "=", "WE", ".", "get_vector", "(", "verb_sid", ")", "\n", "bias_score", ",", "bias_error", "=", "sample_and_average", "(", "gender_vects", ",", "verb_emb", ")", "\n", "", "res", "[", "word", "]", "[", "\"verb_bias\"", "]", "=", "bias_score", "\n", "res", "[", "word", "]", "[", "\"verb_err\"", "]", "=", "bias_error", "\n", "pass", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "data", "=", "res", ")", "\n", "avg", "=", "df", ".", "copy", "(", ")", "\n", "avg", "[", "'mean'", "]", "=", "df", ".", "T", ".", "abs", "(", ")", ".", "mean", "(", "numeric_only", "=", "1", ")", "\n", "print", "(", "avg", ".", "T", ")", "\n", "return", "avg", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.main": [[276, 282], ["eval-sssb-sense.WordEmbedding", "eval-sssb-sense.eval_ethnic_bias", "eval-sssb-sense.eval_racial_bias", "eval-sssb-sense.eval_gender_bias"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_ethnic_bias", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_racial_bias", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_gender_bias"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "WE", "=", "WordEmbedding", "(", "\"./data/lmms_1024.bert-large-cased.npz\"", ")", "\n", "eval_ethnic_bias", "(", "WE", ")", "\n", "eval_racial_bias", "(", "WE", ")", "\n", "eval_gender_bias", "(", "WE", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-sense.debug": [[283, 291], ["pandas.DataFrame", "pd.DataFrame.copy", "pd.DataFrame.T.abs().mean", "print", "pd.DataFrame.T.abs"], "function", ["None"], ["", "def", "debug", "(", ")", ":", "\n", "    ", "h", "=", "{", "}", "\n", "h", "[", "\"david\"", "]", "=", "{", "\"maths\"", ":", "-", "70", ",", "\"english\"", ":", "80", "}", "\n", "h", "[", "\"simon\"", "]", "=", "{", "\"maths\"", ":", "80", ",", "\"english\"", ":", "-", "90", "}", "\n", "df", "=", "pd", ".", "DataFrame", "(", "h", ")", "\n", "avg", "=", "df", ".", "copy", "(", ")", "\n", "avg", "[", "\"mean\"", "]", "=", "df", ".", "T", ".", "abs", "(", ")", ".", "mean", "(", ")", "\n", "print", "(", "avg", ".", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.__init__": [[293, 301], ["eval-sssb-word.WordEmbedding.load_lmms", "print", "len"], "methods", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.load_lmms"], ["\t", "def", "__init__", "(", "self", ",", "fname", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tLoad the word embeddings from fname.\n\t\t\"\"\"", "\n", "self", ".", "embed", "=", "self", ".", "load_lmms", "(", "fname", ")", "\n", "# self.embed = self.load_ares_txt(fname)", "\n", "print", "(", "\"Total number of vectors =\"", ",", "len", "(", "self", ".", "embed", ")", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.load_lmms": [[302, 311], ["numpy.load", "loader[].tolist", "list", "zip"], "methods", ["None"], ["", "def", "load_lmms", "(", "self", ",", "npz_vecs_path", ")", ":", "\n", "\t\t", "lmms", "=", "{", "}", "\n", "loader", "=", "np", ".", "load", "(", "npz_vecs_path", ")", "\n", "labels", "=", "loader", "[", "'labels'", "]", ".", "tolist", "(", ")", "\n", "vectors", "=", "loader", "[", "'vectors'", "]", "\n", "self", ".", "dim", "=", "vectors", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "for", "label", ",", "vector", "in", "list", "(", "zip", "(", "labels", ",", "vectors", ")", ")", ":", "\n", "\t\t\t", "lmms", "[", "label", "]", "=", "vector", "\n", "", "return", "lmms", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.load_ares_txt": [[312, 324], ["open", "enumerate", "line.split", "numpy.array"], "methods", ["None"], ["", "def", "load_ares_txt", "(", "self", ",", "path", ")", ":", "\n", "\t\t", "sense_vecs", "=", "{", "}", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "sfile", ":", "\n", "\t\t\t", "for", "idx", ",", "line", "in", "enumerate", "(", "sfile", ")", ":", "\n", "\t\t\t\t", "if", "idx", "==", "0", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "splitLine", "=", "line", ".", "split", "(", "' '", ")", "\n", "label", "=", "splitLine", "[", "0", "]", "\n", "vec", "=", "np", ".", "array", "(", "splitLine", "[", "1", ":", "]", ",", "dtype", "=", "float", ")", "\n", "self", ".", "dim", "=", "vec", ".", "shape", "[", "0", "]", "\n", "sense_vecs", "[", "label", "]", "=", "vec", "\n", "", "", "return", "sense_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector": [[325, 333], ["eval-sssb-word.WordEmbedding.embed.get", "numpy.zeros"], "methods", ["None"], ["", "def", "get_vector", "(", "self", ",", "label", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tIf the label is not a sense-id (i.e. in the case of sense-insensitive static word embeddings)\n\t\treturn the word embedding instead of sense embedding. You will need to modify this function \n\t\taccording to the word embedding you want to evaluate. If the word is not in the sense embedding\n\t\treturn a zero vector of the same dimensionality.\n\t\t\"\"\"", "\n", "return", "self", ".", "embed", ".", "get", "(", "label", ",", "np", ".", "zeros", "(", "self", ".", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.get_sk_lemma": [[14, 16], ["sensekey.split"], "function", ["None"], ["def", "get_sk_lemma", "(", "sensekey", ")", ":", "\n", "    ", "return", "sensekey", ".", "split", "(", "'%'", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.compute_average_sense_embedding": [[18, 27], ["numpy.mean", "len", "print", "numpy.stack", "eval-sssb-word.get_sk_lemma", "relevant_sks.append"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma"], ["", "def", "compute_average_sense_embedding", "(", "WE", ",", "word", ")", ":", "\n", "\t\t", "relevant_sks", "=", "[", "]", "\n", "for", "sense", "in", "WE", ".", "embed", ":", "\n", "\t\t    ", "if", "word", "==", "get_sk_lemma", "(", "sense", ")", ":", "\n", "\t\t        ", "relevant_sks", ".", "append", "(", "sense", ")", "\n", "", "", "if", "len", "(", "relevant_sks", ")", "==", "0", ":", "\n", "\t\t\t", "print", "(", "\"Relevant sense not found for =\"", ",", "word", ")", "\n", "", "average_vec", "=", "np", ".", "mean", "(", "np", ".", "stack", "(", "[", "WE", ".", "embed", "[", "i", "]", "for", "i", "in", "relevant_sks", "]", ")", ",", "axis", "=", "0", ")", "\n", "return", "average_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.find_sense_id": [[29, 36], ["nltk.corpus.wordnet.synsets", "print", "[].key", "x.pos", "x.definition", "x.lemmas"], "function", ["None"], ["", "def", "find_sense_id", "(", "word", ")", ":", "\n", "\t", "\"\"\"\n\tPrint the sense ids of words.\n\t\"\"\"", "\n", "synsets", "=", "wn", ".", "synsets", "(", "word", ")", "\n", "for", "x", "in", "synsets", ":", "\n", "\t\t", "print", "(", "x", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", ",", "x", ".", "pos", "(", ")", ",", "\"===\"", ",", "x", ".", "definition", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine": [[38, 41], ["numpy.linalg.norm", "numpy.dot"], "function", ["None"], ["", "", "def", "cosine", "(", "x", ",", "y", ")", ":", "\n", "\t", "norm", "=", "np", ".", "linalg", ".", "norm", "(", "y", ")", "\n", "return", "(", "np", ".", "dot", "(", "x", ",", "y", ")", "/", "norm", ")", "if", "norm", ">", "0", "else", "0", "\n", "#return np.dot(x,y) / np.linalg.norm(y) if np.linalg.norm(0) > 0 else 0", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.sample_and_average": [[44, 60], ["range", "len", "numpy.random.choice", "numpy.mean", "numpy.std", "scores.append", "numpy.mean", "scipy.stats.sem", "len", "eval-sssb-word.cosine"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine"], ["", "def", "sample_and_average", "(", "L", ",", "x", ")", ":", "\n", "\t", "\"\"\"\n\tL is a list of vectors, all representing a particular type of bias.\n\tx is the embedding of a word that we would like to evaluate for its bias.\n\tWe will subsample vectors from L, compute the mean and measure cosine similarity with x.\n\tWe will then compute a sigificance score based on these multiple similarities.\n\t\"\"\"", "\n", "sample_size", "=", "len", "(", "L", ")", "//", "2", "\n", "scores", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "5000", ")", ":", "\n", "\t\t", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "L", ")", ",", "size", "=", "sample_size", ")", "\n", "diff", "=", "[", "cosine", "(", "x", ",", "L", "[", "i", "]", ")", "for", "i", "in", "idx", "]", "\n", "mean_diff", "=", "np", ".", "mean", "(", "diff", ")", "\n", "sd_diff", "=", "np", ".", "std", "(", "diff", ")", "\n", "scores", ".", "append", "(", "mean_diff", "/", "sd_diff", ")", "\n", "", "return", "np", ".", "mean", "(", "scores", ")", ",", "stats", ".", "sem", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling": [[62, 82], ["range", "min", "random.randint", "numpy.random.choice", "numpy.random.choice", "bias_scores.append", "numpy.mean", "scipy.stats.sem", "len", "len", "len", "eval-sssb-word.cosine", "numpy.mean", "numpy.std", "len", "eval-sssb-word.cosine", "numpy.mean", "numpy.std"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine"], ["", "def", "two_sided_sampling", "(", "x", ",", "positives", ",", "negatives", ")", ":", "\n", "\t", "\"\"\"\n\tSample equal size adjective sets from positive and negative adjectives.\n\tMeasure the average cosine similarity between the target sense and each sample.\n\tCompute the difference of the similarity between positive and negative adjective sets.\n\tCompute the mean and standard error on these differences.\n\tIf the mean difference is zero, then there is no ethnic bias.\n\t\"\"\"", "\n", "bias_scores", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "5000", ")", ":", "\n", "\t\t", "t", "=", "min", "(", "len", "(", "positives", ")", ",", "len", "(", "negatives", ")", ")", "\n", "sample_size", "=", "random", ".", "randint", "(", "t", "//", "2", ",", "t", ")", "\n", "pos_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "positives", ")", ",", "size", "=", "sample_size", ")", "\n", "pos_scores", "=", "[", "cosine", "(", "x", ",", "positives", "[", "i", "]", ")", "for", "i", "in", "pos_idx", "]", "\n", "pos_score", "=", "np", ".", "mean", "(", "pos_scores", ")", "/", "np", ".", "std", "(", "pos_scores", ")", "\n", "neg_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "negatives", ")", ",", "size", "=", "sample_size", ")", "\n", "neg_scores", "=", "[", "cosine", "(", "x", ",", "negatives", "[", "i", "]", ")", "for", "i", "in", "neg_idx", "]", "\n", "neg_score", "=", "np", ".", "mean", "(", "neg_scores", ")", "/", "np", ".", "std", "(", "neg_scores", ")", "\n", "bias_scores", ".", "append", "(", "pos_score", "-", "neg_score", ")", "\n", "", "return", "np", ".", "mean", "(", "bias_scores", ")", ",", "stats", ".", "sem", "(", "bias_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.load_positives_negatives": [[83, 129], ["print", "print", "min", "open", "len", "open", "len", "len", "len", "line.strip", "nltk.corpus.wordnet.synsets", "positives.append", "line.strip", "nltk.corpus.wordnet.synsets", "negatives.append", "[].key", "int", "len", "WE.get_vector", "[].key", "int", "len", "WE.get_vector", "adj_synsets.append", "adj_synsets.append", "[].split", "[].split", "synset.lemmas", "synset.lemmas", "[].key.split", "[].key.split"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector"], ["", "def", "load_positives_negatives", "(", "WE", ")", ":", "\n", "\t", "\"\"\"\n\tLoad positive and negative adjectives from files. \n\tWe will consider the first adjectivial sense for each word.\n\t\"\"\"", "\n", "positives", "=", "[", "]", "\n", "with", "open", "(", "\"./data/positive-adjectives\"", ")", "as", "pos_file", ":", "\n", "\t\t", "for", "line", "in", "pos_file", ":", "\n", "\t\t\t", "word", "=", "line", ".", "strip", "(", ")", "\n", "synsets", "=", "wn", ".", "synsets", "(", "word", ")", "\n", "adj_synsets", "=", "[", "]", "\n", "for", "synset", "in", "synsets", ":", "\n", "\t\t\t\t", "sid", "=", "synset", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", "\n", "pos", "=", "int", "(", "sid", ".", "split", "(", "\"%\"", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "0", "]", ")", "\n", "if", "pos", "==", "3", ":", "\n", "\t\t\t\t\t", "adj_synsets", ".", "append", "(", "sid", ")", "\n", "", "", "if", "len", "(", "adj_synsets", ")", "==", "0", ":", "\n", "\t\t\t\t", "continue", "\n", "", "adj_sid", "=", "adj_synsets", "[", "0", "]", "\n", "if", "adj_sid", "not", "in", "WE", ".", "embed", ":", "\n", "\t\t\t\t", "continue", "\n", "", "positives", ".", "append", "(", "WE", ".", "get_vector", "(", "adj_sid", ")", ")", "\n", "", "", "print", "(", "\"Total number of positive adjectives =\"", ",", "len", "(", "positives", ")", ")", "\n", "\n", "negatives", "=", "[", "]", "\n", "with", "open", "(", "\"./data/negative-adjectives\"", ")", "as", "neg_file", ":", "\n", "\t\t", "for", "line", "in", "neg_file", ":", "\n", "\t\t\t", "word", "=", "line", ".", "strip", "(", ")", "\n", "synsets", "=", "wn", ".", "synsets", "(", "word", ")", "\n", "adj_synsets", "=", "[", "]", "\n", "for", "synset", "in", "synsets", ":", "\n", "\t\t\t\t", "sid", "=", "synset", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", "\n", "pos", "=", "int", "(", "sid", ".", "split", "(", "\"%\"", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "0", "]", ")", "\n", "if", "pos", "==", "3", ":", "\n", "\t\t\t\t\t", "adj_synsets", ".", "append", "(", "sid", ")", "\n", "", "", "if", "len", "(", "adj_synsets", ")", "==", "0", ":", "\n", "\t\t\t\t", "continue", "\n", "", "adj_sid", "=", "adj_synsets", "[", "0", "]", "\n", "if", "adj_sid", "not", "in", "WE", ".", "embed", ":", "\n", "\t\t\t\t", "continue", "\n", "", "negatives", ".", "append", "(", "WE", ".", "get_vector", "(", "adj_sid", ")", ")", "\n", "", "", "print", "(", "\"Total number of negative adjectives =\"", ",", "len", "(", "negatives", ")", ")", "\n", "t", "=", "min", "(", "len", "(", "positives", ")", ",", "len", "(", "negatives", ")", ")", "\n", "positives", "=", "positives", "[", ":", "t", "]", "\n", "negatives", "=", "negatives", "[", ":", "t", "]", "\n", "return", "positives", ",", "negatives", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_ethnic_bias": [[131, 166], ["eval-sssb-word.load_positives_negatives", "pandas.DataFrame", "print", "eval-sssb-word.two_sided_sampling", "eval-sssb-word.two_sided_sampling", "eval-sssb-word.two_sided_sampling", "eval-sssb-word.two_sided_sampling", "eval-sssb-word.compute_average_sense_embedding", "eval-sssb-word.compute_average_sense_embedding", "print", "print", "WE.get_vector", "WE.get_vector"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.load_positives_negatives", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.compute_average_sense_embedding", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.compute_average_sense_embedding", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector"], ["", "def", "eval_ethnic_bias", "(", "WE", ")", ":", "\n", "\t", "\"\"\"\n\tEvaluate the black as ethnic group vs. colour bias.\n\t\"\"\"", "\n", "#black_ethnic_sid = \"black%1:18:00::\" # noun ", "\n", "#black_colour_sid = \"black%1:07:00::\"  # noun", "\n", "\n", "positives", ",", "negatives", "=", "load_positives_negatives", "(", "WE", ")", "\n", "\n", "\n", "if", "average", "==", "True", ":", "\n", "\t\t", "black_ethnic_sid", "=", "\"black\"", "\n", "black_colour_sid", "=", "\"black\"", "\n", "colour_bias", ",", "colour_err", "=", "two_sided_sampling", "(", "compute_average_sense_embedding", "(", "WE", ",", "black_colour_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "ethnic_bias", ",", "ethnic_err", "=", "two_sided_sampling", "(", "compute_average_sense_embedding", "(", "WE", ",", "black_ethnic_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "\n", "", "else", ":", "\n", "\t\t", "black_ethnic_sid", "=", "\"black%3:00:02::\"", "# adj", "\n", "black_colour_sid", "=", "\"black%3:00:01::\"", "# adj", "\n", "\n", "if", "black_colour_sid", "not", "in", "WE", ".", "embed", ":", "\n", "\t\t\t", "print", "(", "\"Colour sense of black missing\"", ")", "\n", "raise", "ValueError", "\n", "\n", "", "if", "black_ethnic_sid", "not", "in", "WE", ".", "embed", ":", "\n", "\t\t\t", "print", "(", "\"Ethnic sense of black missing\"", ")", "\n", "raise", "ValueError", "\n", "\n", "", "colour_bias", ",", "colour_err", "=", "two_sided_sampling", "(", "WE", ".", "get_vector", "(", "black_colour_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "ethnic_bias", ",", "ethnic_err", "=", "two_sided_sampling", "(", "WE", ".", "get_vector", "(", "black_ethnic_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "", "res", "=", "{", "\"black\"", ":", "{", "\"colour_bias\"", ":", "colour_bias", ",", "\"colour_err\"", ":", "colour_err", ",", "\n", "\"ethnic_bias\"", ":", "ethnic_bias", ",", "\"ethnic_err\"", ":", "ethnic_err", "}", "}", "\n", "df", "=", "pd", ".", "DataFrame", "(", "data", "=", "res", ")", "\n", "print", "(", "df", ".", "T", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_racial_bias": [[168, 210], ["eval-sssb-word.load_positives_negatives", "pandas.DataFrame", "pd.DataFrame.copy", "pd.DataFrame.T.abs().mean", "print", "nation.lower", "nation.lower", "eval-sssb-word.two_sided_sampling", "eval-sssb-word.two_sided_sampling", "eval-sssb-word.two_sided_sampling", "eval-sssb-word.two_sided_sampling", "pd.DataFrame.T.abs", "eval-sssb-word.compute_average_sense_embedding", "eval-sssb-word.compute_average_sense_embedding", "print", "print", "print", "WE.get_vector", "WE.get_vector", "nation.lower", "nation.lower"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.load_positives_negatives", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.two_sided_sampling", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.compute_average_sense_embedding", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.compute_average_sense_embedding", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector"], ["", "def", "eval_racial_bias", "(", "WE", ")", ":", "\n", "\t", "\"\"\"\n\tEvaluatte nationalities vs. languages.\n\t\"\"\"", "\n", "nationalities", "=", "[", "\"Japanese\"", ",", "\"Chinese\"", ",", "\"English\"", ",", "\"Arabic\"", ",", "\"German\"", ",", "\n", "\"French\"", ",", "\"Spanish\"", ",", "\"Portuguese\"", ",", "\"Norwegian\"", ",", "\"Swedish\"", ",", "\"Polish\"", ",", "\"Romanian\"", ",", "\n", "\"Russian\"", ",", "\"Egyptian\"", ",", "\"Finnish\"", ",", "\"Vietnamese\"", "]", "\n", "\n", "people_sid_suffix", "=", "\"%1:18:00::\"", "\n", "lang_sid_suffix", "=", "\"%1:10:00::\"", "\n", "\n", "positives", ",", "negatives", "=", "load_positives_negatives", "(", "WE", ")", "\n", "res", "=", "{", "}", "\n", "for", "nation", "in", "nationalities", ":", "\n", "\t\t", "if", "average", "==", "True", ":", "\n", "\t\t\t", "people_sid", "=", "nation", ".", "lower", "(", ")", "\n", "lang_sid", "=", "nation", ".", "lower", "(", ")", "\n", "res", "[", "nation", "]", "=", "{", "}", "\n", "res", "[", "nation", "]", "[", "\"people_bias\"", "]", ",", "res", "[", "nation", "]", "[", "\"people_err\"", "]", "=", "two_sided_sampling", "(", "compute_average_sense_embedding", "(", "WE", ",", "people_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "res", "[", "nation", "]", "[", "\"lang_bias\"", "]", ",", "res", "[", "nation", "]", "[", "\"lang_err\"", "]", "=", "two_sided_sampling", "(", "compute_average_sense_embedding", "(", "WE", ",", "lang_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "\n", "", "else", ":", "\n", "\t\t\t", "people_sid", "=", "\"%s%s\"", "%", "(", "nation", ".", "lower", "(", ")", ",", "people_sid_suffix", ")", "\n", "lang_sid", "=", "\"%s%s\"", "%", "(", "nation", ".", "lower", "(", ")", ",", "lang_sid_suffix", ")", "\n", "both_senses_found", "=", "True", "\n", "if", "people_sid", "not", "in", "WE", ".", "embed", ":", "\n", "\t\t\t\t", "print", "(", "\"People sense of {0} not found!\"", ".", "format", "(", "nation", ")", ")", "\n", "both_senses_found", "=", "False", "\n", "", "if", "lang_sid", "not", "in", "WE", ".", "embed", ":", "\n", "\t\t\t\t", "print", "(", "\"Language sense of {0} not found!\"", ".", "format", "(", "nation", ")", ")", "\n", "both_senses_found", "=", "False", "\n", "", "if", "not", "both_senses_found", ":", "\n", "\t\t\t\t", "print", "(", "\"Skipping {0}\"", ".", "format", "(", "nation", ")", ")", "\n", "continue", "\n", "", "res", "[", "nation", "]", "=", "{", "}", "\n", "res", "[", "nation", "]", "[", "\"people_bias\"", "]", ",", "res", "[", "nation", "]", "[", "\"people_err\"", "]", "=", "two_sided_sampling", "(", "WE", ".", "get_vector", "(", "people_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "res", "[", "nation", "]", "[", "\"lang_bias\"", "]", ",", "res", "[", "nation", "]", "[", "\"lang_err\"", "]", "=", "two_sided_sampling", "(", "WE", ".", "get_vector", "(", "lang_sid", ")", ",", "positives", ",", "negatives", ")", "\n", "", "", "df", "=", "pd", ".", "DataFrame", "(", "data", "=", "res", ")", "\n", "avg", "=", "df", ".", "copy", "(", ")", "\n", "avg", "[", "'mean'", "]", "=", "df", ".", "T", ".", "abs", "(", ")", ".", "mean", "(", "numeric_only", "=", "1", ")", "\n", "print", "(", "avg", ".", "T", ")", "\n", "return", "avg", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_gender_bias": [[212, 290], ["list", "pandas.DataFrame", "pd.DataFrame.copy", "pd.DataFrame.T.abs().mean", "print", "open", "open", "zip", "nltk.corpus.wordnet.synsets", "nltk.corpus.wordnet.synsets", "[].key", "[].key", "gender_vects.append", "male_words.append", "female_words.append", "eval-sssb-word.compute_average_sense_embedding", "eval-sssb-word.sample_and_average", "eval-sssb-word.compute_average_sense_embedding", "eval-sssb-word.sample_and_average", "pd.DataFrame.T.abs", "line.strip", "line.strip", "len", "len", "WE.get_vector", "WE.get_vector", "print", "WE.get_vector", "eval-sssb-word.sample_and_average", "print", "WE.get_vector", "eval-sssb-word.sample_and_average", "male_synset[].lemmas", "female_synset[].lemmas"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.compute_average_sense_embedding", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.sample_and_average", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.compute_average_sense_embedding", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.sample_and_average", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.sample_and_average", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.WordEmbedding.get_vector", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.sample_and_average"], ["", "def", "eval_gender_bias", "(", "WE", ")", ":", "\n", "\t", "\"\"\"\n\tEvaluate gender bias, where we first define the gender direction by the vector offset of\n\tword-pairs describing male vs. female attributes. We will then evaluate noun and verb senses\n\tof a list of target words and return their individual and aggregated scores with statistical\n\tsignificance scores (evaluated according to a boostrapping test).\n\t\"\"\"", "\n", "male_words", "=", "[", "]", "\n", "with", "open", "(", "\"./data/male_word_file.txt\"", ")", "as", "male_file", ":", "\n", "\t\t", "for", "line", "in", "male_file", ":", "\n", "\t\t\t", "male_words", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "female_words", "=", "[", "]", "\n", "with", "open", "(", "\"./data/female_word_file.txt\"", ")", "as", "female_file", ":", "\n", "\t\t", "for", "line", "in", "female_file", ":", "\n", "\t\t\t", "female_words", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "gender_pairs", "=", "list", "(", "zip", "(", "male_words", ",", "female_words", ")", ")", "\n", "gender_vects", "=", "[", "]", "\n", "\n", "for", "(", "male", ",", "female", ")", "in", "gender_pairs", ":", "\n", "\t\t", "male_synset", "=", "wn", ".", "synsets", "(", "male", ")", "\n", "female_synset", "=", "wn", ".", "synsets", "(", "female", ")", "\n", "if", "len", "(", "male_synset", ")", "==", "0", "or", "len", "(", "female_synset", ")", "==", "0", ":", "\n", "\t\t\t", "continue", "\n", "", "male_sid", "=", "male_synset", "[", "0", "]", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", "\n", "female_sid", "=", "female_synset", "[", "0", "]", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", "\n", "gender_vects", ".", "append", "(", "WE", ".", "get_vector", "(", "male_sid", ")", "-", "WE", ".", "get_vector", "(", "female_sid", ")", ")", "\n", "\n", "", "occupations", "=", "[", "(", "\"engineer\"", ",", "\"engineer%1:18:00::\"", ",", "\"engineer%2:31:01::\"", ")", ",", "\n", "(", "\"carpenter\"", ",", "\"carpenter%1:18:00::\"", ",", "\"carpenter%2:41:00::\"", ")", ",", "\n", "(", "\"guide\"", ",", "\"guide%1:18:00::\"", ",", "\"guide%2:38:00::\"", ")", ",", "\n", "(", "\"mentor\"", ",", "\"mentor%1:18:00::\"", ",", "\"mentor%2:32:00::\"", ")", ",", "\n", "(", "\"judge\"", ",", "\"judge%1:18:00::\"", ",", "\"judge%2:31:02::\"", ")", ",", "\n", "(", "\"nurse\"", ",", "\"nurse%1:18:00::\"", ",", "\"nurse%2:29:00::\"", ")", "]", "\n", "\n", "res", "=", "{", "}", "\n", "if", "average", "==", "True", ":", "\n", "\t\t", "occupations_words", "=", "[", "\"engineer\"", ",", "\"carpenter\"", ",", "\"guide\"", ",", "\"mentor\"", ",", "\"judge\"", ",", "\"nurse\"", "]", "\n", "for", "word", "in", "occupations_words", ":", "\n", "\t\t\t", "res", "[", "word", "]", "=", "{", "}", "\n", "noun_sid", "=", "word", "\n", "verb_sid", "=", "word", "\n", "\n", "noun_emb", "=", "compute_average_sense_embedding", "(", "WE", ",", "noun_sid", ")", "\n", "bias_score", ",", "bias_error", "=", "sample_and_average", "(", "gender_vects", ",", "noun_emb", ")", "\n", "res", "[", "word", "]", "[", "\"noun_bias\"", "]", "=", "bias_score", "\n", "res", "[", "word", "]", "[", "\"noun_err\"", "]", "=", "bias_error", "\n", "\n", "verb_emb", "=", "compute_average_sense_embedding", "(", "WE", ",", "verb_sid", ")", "\n", "bias_score", ",", "bias_error", "=", "sample_and_average", "(", "gender_vects", ",", "verb_emb", ")", "\n", "res", "[", "word", "]", "[", "\"verb_bias\"", "]", "=", "bias_score", "\n", "res", "[", "word", "]", "[", "\"verb_err\"", "]", "=", "bias_error", "\n", "\n", "", "", "else", ":", "\n", "\t\t", "for", "(", "word", ",", "noun_sid", ",", "verb_sid", ")", "in", "occupations", ":", "\n", "\t\t\t", "res", "[", "word", "]", "=", "{", "}", "\n", "if", "noun_sid", "not", "in", "WE", ".", "embed", ":", "\n", "\t\t\t\t", "print", "(", "\"Noun Sense Embedding Not Found for =\"", ",", "word", ")", "\n", "bias_score", ",", "bias_error", "=", "0", ",", "0", "\n", "", "else", ":", "\n", "\t\t\t\t", "noun_emb", "=", "WE", ".", "get_vector", "(", "noun_sid", ")", "\n", "bias_score", ",", "bias_error", "=", "sample_and_average", "(", "gender_vects", ",", "noun_emb", ")", "\n", "", "res", "[", "word", "]", "[", "\"noun_bias\"", "]", "=", "bias_score", "\n", "res", "[", "word", "]", "[", "\"noun_err\"", "]", "=", "bias_error", "\n", "\n", "if", "verb_sid", "not", "in", "WE", ".", "embed", ":", "\n", "\t\t\t\t", "print", "(", "\"Verb Sense Embedding Not Found for =\"", ",", "word", ")", "\n", "bias_score", ",", "bias_error", "=", "0", ",", "0", "\n", "", "else", ":", "\n", "\t\t\t\t", "verb_emb", "=", "WE", ".", "get_vector", "(", "verb_sid", ")", "\n", "bias_score", ",", "bias_error", "=", "sample_and_average", "(", "gender_vects", ",", "verb_emb", ")", "\n", "", "res", "[", "word", "]", "[", "\"verb_bias\"", "]", "=", "bias_score", "\n", "res", "[", "word", "]", "[", "\"verb_err\"", "]", "=", "bias_error", "\n", "pass", "\n", "", "", "df", "=", "pd", ".", "DataFrame", "(", "data", "=", "res", ")", "\n", "avg", "=", "df", ".", "copy", "(", ")", "\n", "avg", "[", "'mean'", "]", "=", "df", ".", "T", ".", "abs", "(", ")", ".", "mean", "(", "numeric_only", "=", "1", ")", "\n", "print", "(", "avg", ".", "T", ")", "\n", "return", "avg", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.main": [[335, 341], ["eval-sssb-word.WordEmbedding", "eval-sssb-word.eval_ethnic_bias", "eval-sssb-word.eval_racial_bias", "eval-sssb-word.eval_gender_bias"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_ethnic_bias", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_racial_bias", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.eval_gender_bias"], ["", "", "def", "main", "(", ")", ":", "\n", "\t", "WE", "=", "WordEmbedding", "(", "\"Path to embeddings\"", ")", "\n", "eval_ethnic_bias", "(", "WE", ")", "\n", "eval_racial_bias", "(", "WE", ")", "\n", "eval_gender_bias", "(", "WE", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.debug": [[342, 350], ["pandas.DataFrame", "pd.DataFrame.copy", "pd.DataFrame.T.abs().mean", "print", "pd.DataFrame.T.abs"], "function", ["None"], ["", "def", "debug", "(", ")", ":", "\n", "\t", "h", "=", "{", "}", "\n", "h", "[", "\"david\"", "]", "=", "{", "\"maths\"", ":", "-", "70", ",", "\"english\"", ":", "80", "}", "\n", "h", "[", "\"simon\"", "]", "=", "{", "\"maths\"", ":", "80", ",", "\"english\"", ":", "-", "90", "}", "\n", "df", "=", "pd", ".", "DataFrame", "(", "h", ")", "\n", "avg", "=", "df", ".", "copy", "(", ")", "\n", "avg", "[", "\"mean\"", "]", "=", "df", ".", "T", ".", "abs", "(", ")", ".", "mean", "(", ")", "\n", "print", "(", "avg", ".", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.find_sense_id": [[9, 16], ["nltk.corpus.wordnet.synsets", "print", "[].key", "x.pos", "x.definition", "x.lemmas"], "function", ["None"], ["def", "find_sense_id", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Print the sense ids of words.\n    \"\"\"", "\n", "synsets", "=", "wn", ".", "synsets", "(", "word", ")", "\n", "for", "x", "in", "synsets", ":", "\n", "        ", "print", "(", "x", ".", "lemmas", "(", ")", "[", "0", "]", ".", "key", "(", ")", ",", "x", ".", "pos", "(", ")", ",", "\"===\"", ",", "x", ".", "definition", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.people_template": [[18, 61], ["print", "inst.append", "pattern.replace", "txt.replace.replace", "txt.replace.replace", "txt.replace.replace", "inst.append", "target.lower"], "function", ["None"], ["", "", "def", "people_template", "(", ")", ":", "\n", "    ", "\"\"\"\n    Generate nationalities vs. languages sense related stereotypes\n    \"\"\"", "\n", "nationalities", "=", "[", "\"Japanese\"", ",", "\"Chinese\"", ",", "\"English\"", ",", "\"Arabic\"", ",", "\"German\"", ",", "\n", "\"French\"", ",", "\"Spanish\"", ",", "\"Portuguese\"", ",", "\"Norwegian\"", ",", "\"Swedish\"", ",", "\"Polish\"", ",", "\"Romanian\"", ",", "\n", "\"Russian\"", ",", "\"Egyptian\"", ",", "\"Finnish\"", ",", "\"Vietnamese\"", "]", "\n", "people_pleasant", "=", "[", "\"beautiful\"", ",", "\"nice\"", ",", "\"friendly\"", ",", "\"kind\"", ",", "\"good looking\"", ",", "\n", "\"intelligent\"", ",", "\"clever\"", ",", "\"generous\"", ",", "\"funny\"", ",", "\"cute\"", ",", "\"handsome\"", ",", "\"innocent\"", "]", "\n", "people_unpleasant", "=", "[", "\"ugly\"", ",", "\"arrogant\"", ",", "\"unkind\"", ",", "\"unfriendly\"", ",", "\"uppish\"", ",", "\"foolish\"", ",", "\"stupid\"", ",", "\"cunning\"", ",", "\"silly\"", "]", "\n", "\n", "language_pleasant", "=", "[", "\"easy to learn\"", ",", "\"beautiful\"", ",", "\"elegant\"", ",", "\"soft\"", ",", "\"easy to understand\"", ",", "\"easy to write\"", "]", "\n", "language_unpleasant", "=", "[", "\"difficult to learn\"", ",", "\"ugly\"", ",", "\"rough\"", ",", "\"hash\"", ",", "\"difficult to understand\"", ",", "\"difficult to write\"", "]", "\n", "\n", "colour_pleasant", "=", "[", "\"beautiful\"", ",", "\"elegant\"", ",", "\"attractive\"", ",", "\"nice\"", ",", "\"smart\"", "]", "\n", "colour_unpleasant", "=", "[", "\"ugly\"", ",", "\"bad\"", ",", "\"silly\"", ",", "\"awful\"", ",", "\"horrid\"", "]", "\n", "\n", "templates", "=", "[", "(", "\"$1 people are $2.\\t[nationality, $4%1:18:00::, $3]\"", ",", "nationalities", ",", "people_pleasant", ",", "\"anti\"", ")", ",", "\n", "(", "\"$1 people are $2.\\t[nationality, $4%1:18:00::, $3]\"", ",", "nationalities", ",", "people_unpleasant", ",", "\"stereo\"", ")", ",", "\n", "(", "\"$1 people are $2.\\t[ethnicity, black%1:18:00::, $3]\"", ",", "[", "\"Black\"", "]", ",", "people_pleasant", ",", "\"anti\"", ")", ",", "\n", "(", "\"$1 people are $2.\\t[ethinicity, black%1:18:00::, $3]\"", ",", "[", "\"Black\"", "]", ",", "people_unpleasant", ",", "\"stereo\"", ")", ",", "\n", "(", "\"$1 dress was $2.\\t[colour, black%1:07:00::, $3]\"", ",", "[", "\"Black\"", "]", ",", "colour_pleasant", ",", "\"anti\"", ")", ",", "\n", "(", "\"$1 dress was $2.\\t[colour, black%1:07:00::, $3]\"", ",", "[", "\"Black\"", "]", ",", "colour_unpleasant", ",", "\"stereo\"", ")", ",", "\n", "(", "\"$1 language is $2.\\t[language, $4%1:10:00::, $3]\"", ",", "nationalities", ",", "language_pleasant", ",", "\"anti\"", ")", ",", "\n", "(", "\"$1 language is $2.\\t[language, $4%1:10:00::, $3]\"", ",", "nationalities", ",", "language_unpleasant", ",", "\"stereo\"", ")", "]", "\n", "inst", "=", "[", "]", "\n", "count", "=", "0", "\n", "for", "template", "in", "templates", ":", "\n", "        ", "pattern", "=", "template", "[", "0", "]", "\n", "targets", "=", "template", "[", "1", "]", "\n", "attributes", "=", "template", "[", "2", "]", "\n", "label", "=", "template", "[", "3", "]", "\n", "for", "target", "in", "targets", ":", "\n", "            ", "for", "attribute", "in", "attributes", ":", "\n", "                ", "txt", "=", "pattern", ".", "replace", "(", "\"$1\"", ",", "target", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\"$2\"", ",", "attribute", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\"$3\"", ",", "label", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\"$4\"", ",", "target", ".", "lower", "(", ")", ")", "\n", "inst", ".", "append", "(", "txt", ")", "\n", "count", "+=", "1", "\n", "", "inst", ".", "append", "(", "\"\"", ")", "\n", "", "", "print", "(", "\"Total number of racial bias examples = {0}\"", ".", "format", "(", "count", ")", ")", "\n", "return", "inst", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.gender_template": [[62, 131], ["print", "open", "template.replace", "txt.replace.replace", "txt.replace.replace", "inst.append", "template.replace", "txt.replace.replace", "txt.replace.replace", "inst.append", "line.strip", "pattern.replace.replace", "txt.replace.replace", "pattern.replace.replace", "inst.append", "txt.replace.replace", "pattern.replace.replace", "inst.append", "pattern.replace.find", "inst.append", "inst.append", "pattern.replace.capitalize", "pattern.replace.replace", "txt.replace.replace", "inst.append", "txt.replace.capitalize"], "function", ["None"], ["", "def", "gender_template", "(", ")", ":", "\n", "    ", "\"\"\"\n    Generate gender related examples. For each profession, we consider its male and female variants.\n    We will then associate each variant with a pleasant or unpleasant attributes to generate stereo or antistereo \n    examples. We will consider the verb sense of the profession to create gender bias unrelated examples.\n    \"\"\"", "\n", "\n", "occupations", "=", "[", "(", "\"engineer\"", ",", "\"engineer%1:18:00::\"", ",", "\"engineer%2:31:01::\"", ")", ",", "\n", "(", "\"carpenter\"", ",", "\"carpenter%1:18:00::\"", ",", "\"carpenter%2:41:00::\"", ")", ",", "\n", "(", "\"guide\"", ",", "\"guide%1:18:00::\"", ",", "\"guide%2:38:00::\"", ")", ",", "\n", "(", "\"mentor\"", ",", "\"mentor%1:18:00::\"", ",", "\"mentor%2:32:00::\"", ")", ",", "\n", "(", "\"judge\"", ",", "\"judge%1:18:00::\"", ",", "\"judge%2:31:02::\"", ")", ",", "\n", "(", "\"nurse\"", ",", "\"nurse%1:18:00::\"", ",", "\"nurse%2:29:00::\"", ")", "]", "\n", "\n", "people_pleasant", "=", "[", "\"nice\"", ",", "\"friendly\"", ",", "\"kind\"", ",", "\"talented\"", ",", "\"strong\"", ",", "\"hard working\"", ",", "\n", "\"intelligent\"", ",", "\"clever\"", ",", "\"generous\"", ",", "\"innocent\"", ",", "\"meticulous\"", ",", "\"clean\"", ",", "\"honest\"", ",", "\"professional\"", "]", "\n", "people_unpleasant", "=", "[", "\"ugly\"", ",", "\"arrogant\"", ",", "\"unkind\"", ",", "\"unfriendly\"", ",", "\"uppish\"", ",", "\"foolish\"", ",", "\"stupid\"", ",", "\"cunning\"", ",", "\"silly\"", ",", "\n", "\"lazy\"", ",", "\"careless\"", ",", "\"weak\"", ",", "\"clumsy\"", ",", "\"dirty\"", ",", "\"cunning\"", ",", "\"unprofessional\"", ",", "\"unclean\"", ",", "\"dishonest\"", "]", "\n", "\n", "templates", "=", "[", "(", "\"$GENDER$ was a $ATTRIBUTE$ $OCCUPATION$.\\t[noun, $SENSE-ID$, $BIAS$]\"", ")", "]", "\n", "\n", "count", "=", "0", "\n", "inst", "=", "[", "]", "\n", "for", "(", "occupation", ",", "noun_sense_id", ",", "verb_sense_id", ")", "in", "occupations", ":", "\n", "        ", "for", "template", "in", "templates", ":", "\n", "            ", "for", "attribute", "in", "people_pleasant", ":", "\n", "                ", "txt", "=", "template", ".", "replace", "(", "\"$ATTRIBUTE$\"", ",", "attribute", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\"$OCCUPATION$\"", ",", "occupation", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\"$SENSE-ID$\"", ",", "noun_sense_id", ")", "\n", "for", "(", "gender", ",", "bias", ")", "in", "[", "(", "\"He\"", ",", "\"stereo\"", ")", ",", "(", "\"She\"", ",", "\"anti\"", ")", "]", ":", "\n", "                    ", "pattern", "=", "txt", ".", "replace", "(", "\"$GENDER$\"", ",", "gender", ")", "\n", "pattern", "=", "pattern", ".", "replace", "(", "\"$BIAS$\"", ",", "bias", ")", "\n", "inst", ".", "append", "(", "pattern", ")", "\n", "count", "+=", "1", "\n", "", "inst", ".", "append", "(", "\"\"", ")", "\n", "\n", "", "for", "attribute", "in", "people_unpleasant", ":", "\n", "                ", "txt", "=", "template", ".", "replace", "(", "\"$ATTRIBUTE$\"", ",", "attribute", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\"$OCCUPATION$\"", ",", "occupation", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\"$SENSE-ID$\"", ",", "noun_sense_id", ")", "\n", "for", "(", "gender", ",", "bias", ")", "in", "[", "(", "\"He\"", ",", "\"anti\"", ")", ",", "(", "\"She\"", ",", "\"stereo\"", ")", "]", ":", "\n", "                    ", "pattern", "=", "txt", ".", "replace", "(", "\"$GENDER$\"", ",", "gender", ")", "\n", "pattern", "=", "pattern", ".", "replace", "(", "\"$BIAS$\"", ",", "bias", ")", "\n", "inst", ".", "append", "(", "pattern", ")", "\n", "count", "+=", "1", "\n", "", "inst", ".", "append", "(", "\"\"", ")", "\n", "\n", "", "", "with", "open", "(", "\"./%s-template\"", "%", "occupation", ")", "as", "F", ":", "\n", "            ", "for", "line", "in", "F", ":", "\n", "                ", "pattern", "=", "line", ".", "strip", "(", ")", "\n", "pattern", "=", "pattern", ".", "replace", "(", "\"$SENSE-ID$\"", ",", "verb_sense_id", ")", "\n", "\n", "# If we have hard coded gender in the template then we do not have a pair.", "\n", "if", "pattern", ".", "find", "(", "\"$GENDER$\"", ")", "==", "-", "1", ":", "\n", "                    ", "inst", ".", "append", "(", "pattern", ".", "capitalize", "(", ")", ")", "\n", "count", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "for", "(", "gender", ",", "bias", ")", "in", "[", "(", "\"he\"", ",", "\"stereo\"", ")", ",", "(", "\"she\"", ",", "\"anti\"", ")", "]", ":", "\n", "                        ", "txt", "=", "pattern", ".", "replace", "(", "\"$GENDER$\"", ",", "gender", ")", "\n", "txt", "=", "txt", ".", "replace", "(", "\"$BIAS$\"", ",", "bias", ")", "\n", "inst", ".", "append", "(", "txt", ".", "capitalize", "(", ")", ")", "\n", "count", "+=", "1", "\n", "", "inst", ".", "append", "(", "\"\"", ")", "\n", "\n", "\n", "", "", "", "", "print", "(", "\"Total number of gender examples = {0}\"", ".", "format", "(", "count", ")", ")", "\n", "\n", "\n", "return", "inst", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.write_to_file": [[133, 140], ["open", "F.write"], "function", ["None"], ["", "def", "write_to_file", "(", "instances", ",", "fname", ")", ":", "\n", "    ", "\"\"\"\n    Write the instances to a file.\n    \"\"\"", "\n", "with", "open", "(", "fname", ",", "'w'", ")", "as", "F", ":", "\n", "        ", "for", "inst", "in", "instances", ":", "\n", "            ", "F", ".", "write", "(", "\"%s\\n\"", "%", "inst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.debug": [[141, 143], ["generate.find_sense_id"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.find_sense_id"], ["", "", "", "def", "debug", "(", ")", ":", "\n", "    ", "find_sense_id", "(", "'black'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.main": [[145, 151], ["generate.gender_template", "generate.write_to_file"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.gender_template", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.generate.write_to_file"], ["", "def", "main", "(", ")", ":", "\n", "#instances = people_template()", "\n", "#write_to_file(instances, \"racial-bias.txt\")", "\n", "\n", "    ", "instances", "=", "gender_template", "(", ")", "\n", "write_to_file", "(", "instances", ",", "\"output\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.parse_args": [[7, 16], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--embedding'", ",", "type", "=", "str", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.cos_sim": [[18, 20], ["numpy.dot", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "cos_sim", "(", "v1", ",", "v2", ")", ":", "\n", "    ", "return", "np", ".", "dot", "(", "v1", ",", "v2", ")", "/", "(", "np", ".", "linalg", ".", "norm", "(", "v1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "v2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.get_relevent_sense_list": [[22, 31], ["word_senses.append", "wat-word.get_sk_lemma", "word_sks.append"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma"], ["", "def", "get_relevent_sense_list", "(", "sense_id_list", ",", "word_list", ")", ":", "\n", "    ", "word_senses", "=", "[", "]", "\n", "for", "word", "in", "word_list", ":", "\n", "        ", "word_sks", "=", "[", "]", "\n", "for", "sense_id", "in", "sense_id_list", ":", "\n", "            ", "if", "word", "==", "get_sk_lemma", "(", "sense_id", ")", ":", "\n", "                ", "word_sks", ".", "append", "(", "sense_id", ")", "\n", "", "", "word_senses", ".", "append", "(", "word_sks", ")", "\n", "", "return", "word_senses", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.load_annotated_senses": [[33, 43], ["open", "line.strip.strip", "line.strip.split"], "function", ["None"], ["", "def", "load_annotated_senses", "(", "fn_path", ")", ":", "\n", "    ", "word2sense_dict", "=", "{", "}", "\n", "with", "open", "(", "fn_path", ",", "'r'", ")", "as", "sfile", ":", "\n", "        ", "for", "line", "in", "sfile", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", "'\\n'", ")", "\n", "splitLine", "=", "line", ".", "split", "(", "','", ")", "\n", "word", "=", "splitLine", "[", "0", "]", "\n", "sense", "=", "splitLine", "[", "1", "]", "\n", "word2sense_dict", "[", "word", "]", "=", "sense", "\n", "", "", "return", "word2sense_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.eval_wat": [[45, 100], ["emb.keys", "open", "dict", "gold_d.keys", "dict.keys", "scipy.stats.pearsonr", "wat-word.get_sk_lemma", "l.strip().split", "emb.keys", "numpy.mean", "zip", "numpy.array", "numpy.array", "open", "fw.write", "fw.write", "word2sense.keys", "float", "len", "numpy.stack", "emb.keys", "numpy.mean", "numpy.mean", "scores_list.append", "sum", "len", "l.strip", "wat-word.get_sk_lemma", "relevant_sks.append", "numpy.stack", "numpy.stack", "wat-word.cos_sim", "wat-word.cos_sim", "wat-word.get_sk_lemma", "relevant_sks_1.append", "wat-word.get_sk_lemma", "relevant_sks_2.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.cos_sim", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.cos_sim", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma"], ["", "def", "eval_wat", "(", "emb", ",", "output", ",", "path", ",", "word1_list", ",", "word2_list", ")", ":", "\n", "    ", "word2sense", "=", "{", "}", "\n", "for", "sense", "in", "emb", ".", "keys", "(", ")", ":", "\n", "        ", "lemma", "=", "get_sk_lemma", "(", "sense", ")", "\n", "word2sense", "[", "lemma", "]", "=", "sense", "\n", "\n", "", "gold_d", "=", "{", "}", "\n", "for", "l", "in", "open", "(", "path", ")", ":", "\n", "        ", "word", ",", "score", "=", "l", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "word", "in", "word2sense", ".", "keys", "(", ")", ":", "\n", "            ", "gold_d", "[", "word", "]", "=", "float", "(", "score", ")", "\n", "", "", "emb_d", "=", "dict", "(", ")", "\n", "for", "key", "in", "gold_d", ".", "keys", "(", ")", ":", "\n", "        ", "if", "key", "in", "word1_list", "or", "key", "in", "word2_list", ":", "\n", "            ", "continue", "\n", "", "relevant_sks", "=", "[", "]", "\n", "for", "sense", "in", "emb", ".", "keys", "(", ")", ":", "\n", "            ", "if", "key", "==", "get_sk_lemma", "(", "sense", ")", ":", "\n", "                ", "relevant_sks", ".", "append", "(", "sense", ")", "\n", "\n", "", "", "if", "len", "(", "relevant_sks", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "\n", "", "e", "=", "np", ".", "mean", "(", "np", ".", "stack", "(", "[", "emb", "[", "i", "]", "for", "i", "in", "relevant_sks", "]", ")", ",", "axis", "=", "0", ")", "\n", "scores_list", "=", "[", "]", "\n", "for", "w1", ",", "w2", "in", "zip", "(", "word1_list", ",", "word2_list", ")", ":", "\n", "            ", "relevant_sks_1", "=", "[", "]", "\n", "relevant_sks_2", "=", "[", "]", "\n", "for", "sense", "in", "emb", ".", "keys", "(", ")", ":", "\n", "                ", "if", "w1", "==", "get_sk_lemma", "(", "sense", ")", ":", "\n", "                    ", "relevant_sks_1", ".", "append", "(", "sense", ")", "\n", "", "if", "w2", "==", "get_sk_lemma", "(", "sense", ")", ":", "\n", "                    ", "relevant_sks_2", ".", "append", "(", "sense", ")", "\n", "\n", "", "", "if", "len", "(", "relevant_sks_1", ")", "==", "0", "or", "len", "(", "relevant_sks_2", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "emb_1", "=", "np", ".", "mean", "(", "np", ".", "stack", "(", "[", "emb", "[", "i", "]", "for", "i", "in", "relevant_sks_1", "]", ")", ",", "axis", "=", "0", ")", "\n", "emb_2", "=", "np", ".", "mean", "(", "np", ".", "stack", "(", "[", "emb", "[", "j", "]", "for", "j", "in", "relevant_sks_2", "]", ")", ",", "axis", "=", "0", ")", "\n", "score", "=", "cos_sim", "(", "e", ",", "emb_1", ")", "-", "cos_sim", "(", "e", ",", "emb_2", ")", "\n", "scores_list", ".", "append", "(", "score", ")", "\n", "", "score", "=", "sum", "(", "scores_list", ")", "/", "len", "(", "scores_list", ")", "\n", "emb_d", "[", "key", "]", "=", "score", "\n", "\n", "", "g_l", "=", "[", "]", "\n", "e_l", "=", "[", "]", "\n", "for", "key", "in", "emb_d", ".", "keys", "(", ")", ":", "\n", "        ", "g_l", "+=", "[", "gold_d", "[", "key", "]", "]", "\n", "e_l", "+=", "[", "emb_d", "[", "key", "]", "]", "\n", "", "r", ",", "p", "=", "pearsonr", "(", "np", ".", "array", "(", "g_l", ")", ",", "np", ".", "array", "(", "e_l", ")", ")", "\n", "\n", "with", "open", "(", "output", ",", "'w'", ")", "as", "fw", ":", "\n", "        ", "fw", ".", "write", "(", "f'Pearson\u2019s correlation coefficient: {r}\\n'", ")", "\n", "fw", ".", "write", "(", "f'P-value: {p}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.load_lmms": [[102, 110], ["numpy.load", "loader[].tolist", "list", "zip"], "function", ["None"], ["", "", "def", "load_lmms", "(", "npz_vecs_path", ")", ":", "\n", "    ", "lmms", "=", "{", "}", "\n", "loader", "=", "np", ".", "load", "(", "npz_vecs_path", ")", "\n", "labels", "=", "loader", "[", "'labels'", "]", ".", "tolist", "(", ")", "\n", "vectors", "=", "loader", "[", "'vectors'", "]", "\n", "for", "label", ",", "vector", "in", "list", "(", "zip", "(", "labels", ",", "vectors", ")", ")", ":", "\n", "        ", "lmms", "[", "label", "]", "=", "vector", "\n", "", "return", "lmms", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.load_ares_txt": [[112, 124], ["open", "enumerate", "line.split", "numpy.array"], "function", ["None"], ["", "def", "load_ares_txt", "(", "path", ")", ":", "\n", "    ", "sense_vecs", "=", "{", "}", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "sfile", ":", "\n", "        ", "for", "idx", ",", "line", "in", "enumerate", "(", "sfile", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "continue", "\n", "", "splitLine", "=", "line", ".", "split", "(", "' '", ")", "\n", "label", "=", "splitLine", "[", "0", "]", "\n", "vec", "=", "np", ".", "array", "(", "splitLine", "[", "1", ":", "]", ",", "dtype", "=", "float", ")", "\n", "dim", "=", "vec", ".", "shape", "[", "0", "]", "\n", "sense_vecs", "[", "label", "]", "=", "vec", "\n", "", "", "return", "sense_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.get_sk_lemma": [[126, 128], ["sensekey.split"], "function", ["None"], ["", "def", "get_sk_lemma", "(", "sensekey", ")", ":", "\n", "    ", "return", "sensekey", ".", "split", "(", "'%'", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-word.main": [[130, 140], ["wat-word.load_lmms", "wat-word.eval_wat"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.load_lmms", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.eval_wat"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "sense_emb", "=", "load_lmms", "(", "'path to lmms embeddings'", ")", "\n", "# sense_emb = load_ares_txt(\"path to ares embeddings\")", "\n", "\n", "word1_list", "=", "[", "'he'", ",", "'father'", ",", "'son'", ",", "'husband'", ",", "'grandfather'", ",", "\n", "'brother'", ",", "'man'", ",", "'boy'", ",", "'uncle'", ",", "'gentleman'", "]", "\n", "word2_list", "=", "[", "'she'", ",", "'mother'", ",", "'daughter'", ",", "'wife'", ",", "'grandmother'", ",", "\n", "'sister'", ",", "'woman'", ",", "'girl'", ",", "'aunt'", ",", "'lady'", "]", "\n", "\n", "eval_wat", "(", "sense_emb", ",", "args", ".", "output", ",", "'data/wat_bi.txt'", ",", "word1_list", ",", "word2_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.parse_args": [[16, 30], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "choices", "=", "[", "'cp'", ",", "'ss'", ",", "\n", "'sssb_gender'", ",", "'sssb_race'", ",", "'sssb_nationality'", "]", ",", "\n", "help", "=", "'Path to evaluation dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "choices", "=", "[", "'sense-base'", ",", "'sense-large'", ",", "\n", "'bert-base'", ",", "'bert-large'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--method'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "choices", "=", "[", "'aul'", ",", "'cps'", ",", "'sss'", "]", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.load_tokenizer_and_model": [[32, 63], ["tensorflow.ConfigProto", "tensorflow.Session", "sensebert.SenseBert", "transformers.AutoModelForMaskedLM.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "model.eval.eval"], "function", ["None"], ["", "def", "load_tokenizer_and_model", "(", "args", ")", ":", "\n", "    ", "'''\n    Load tokenizer and model to evaluate.\n    '''", "\n", "if", "args", ".", "model", "==", "'sense-base'", ":", "\n", "        ", "pretrained_weights", "=", "'sensebert-base-uncased'", "\n", "", "elif", "args", ".", "model", "==", "'sense-large'", ":", "\n", "        ", "pretrained_weights", "=", "'sensebert-large-uncased'", "\n", "", "elif", "args", ".", "model", "==", "'bert-base'", ":", "\n", "        ", "pretrained_weights", "=", "'bert-base-uncased'", "\n", "", "elif", "args", ".", "model", "==", "'bert-large'", ":", "\n", "        ", "pretrained_weights", "=", "'bert-large-uncased'", "\n", "\n", "", "if", "args", ".", "model", "==", "'sense-base'", "or", "args", ".", "model", "==", "'sense-large'", ":", "\n", "        ", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "session", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "# sensebert_model = sensebert.SenseBert(pretrained_weights, session=session)", "\n", "sensebert_model", "=", "SenseBert", "(", "pretrained_weights", ",", "session", "=", "session", ")", "\n", "\n", "\n", "return", "sensebert_model", ".", "tokenize", ",", "sensebert_model", ".", "run", "\n", "\n", "", "elif", "args", ".", "model", "==", "'bert-base'", "or", "args", ".", "model", "==", "'bert-large'", ":", "\n", "        ", "model", "=", "AutoModelForMaskedLM", ".", "from_pretrained", "(", "pretrained_weights", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "output_attentions", "=", "True", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrained_weights", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "\n", "return", "tokenizer", ",", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.softmax": [[65, 67], ["numpy.exp", "numpy.sum", "numpy.exp"], "function", ["None"], ["", "", "def", "softmax", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "exp", "(", "x", ")", "/", "np", ".", "sum", "(", "np", ".", "exp", "(", "x", ")", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.calculate_aul_for_sense_bert": [[69, 84], ["model", "numpy.array", "token_ids.reshape.reshape", "np.log.squeeze", "numpy.log", "numpy.mean", "log_prob.item.item", "eval-sssb-mlm.softmax", "numpy.take"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.softmax"], ["", "def", "calculate_aul_for_sense_bert", "(", "model", ",", "token_ids", ",", "mask_ids", ")", ":", "\n", "    ", "'''\n    Given token ids of a sequence, return the averaged log probability of\n    unmasked sequence (AUL).\n    '''", "\n", "embeddings", ",", "token_logits", ",", "sense_logits", "=", "model", "(", "token_ids", ",", "mask_ids", ")", "\n", "token_ids", "=", "np", ".", "array", "(", "token_ids", ")", "\n", "token_ids", "=", "token_ids", ".", "reshape", "(", "-", "1", ")", "\n", "token_logits", "=", "token_logits", ".", "squeeze", "(", ")", "\n", "# token_logits = softmax(token_logits)", "\n", "token_logits", "=", "np", ".", "log", "(", "softmax", "(", "token_logits", ")", ")", "\n", "log_prob", "=", "np", ".", "mean", "(", "np", ".", "take", "(", "token_logits", ",", "token_ids", ",", "1", ")", "[", "1", ":", "-", "1", "]", ")", "\n", "log_prob", "=", "log_prob", ".", "item", "(", ")", "\n", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.calculate_aul_for_bert": [[86, 100], ["model", "model.logits.squeeze", "log_softmax", "token_ids.view().detach.view().detach", "torch.mean", "log_prob.item.item", "log_softmax.gather", "token_ids.view().detach.view"], "function", ["None"], ["", "def", "calculate_aul_for_bert", "(", "model", ",", "token_ids", ",", "log_softmax", ")", ":", "\n", "    ", "'''\n    Given token ids of a sequence, return the averaged log probability of\n    unmasked sequence (AUL).\n    '''", "\n", "output", "=", "model", "(", "token_ids", ")", "\n", "logits", "=", "output", ".", "logits", ".", "squeeze", "(", "0", ")", "\n", "log_probs", "=", "log_softmax", "(", "logits", ")", "\n", "token_ids", "=", "token_ids", ".", "view", "(", "-", "1", ",", "1", ")", ".", "detach", "(", ")", "\n", "token_log_probs", "=", "log_probs", ".", "gather", "(", "1", ",", "token_ids", ")", "[", "1", ":", "-", "1", "]", "\n", "log_prob", "=", "torch", ".", "mean", "(", "token_log_probs", ")", "\n", "log_prob", "=", "log_prob", ".", "item", "(", ")", "\n", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.main": [[103, 163], ["eval-sssb-mlm.load_tokenizer_and_model", "torch.nn.LogSoftmax", "collections.defaultdict", "collections.defaultdict", "round", "collections.defaultdict.items", "open", "json.load", "len", "tqdm.tqdm", "round", "print", "print", "print", "mlm_scores.append", "tokenizer", "tokenizer", "eval-sssb-mlm.calculate_aul_for_sense_bert", "eval-sssb-mlm.calculate_aul_for_sense_bert", "tokenizer.encode", "tokenizer.encode", "torch.no_grad", "eval-sssb-mlm.calculate_aul_for_bert", "eval-sssb-mlm.calculate_aul_for_bert"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.load_tokenizer_and_model", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.calculate_aul_for_sense_bert", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.calculate_aul_for_sense_bert", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.calculate_aul_for_bert", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-mlm.calculate_aul_for_bert"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "'''\n    Evaluate the bias in masked language models.\n    '''", "\n", "tokenizer", ",", "model", "=", "load_tokenizer_and_model", "(", "args", ")", "\n", "log_softmax", "=", "torch", ".", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "total_score", "=", "0", "\n", "stereo_score", "=", "0", "\n", "\n", "mask_id", "=", "103", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "scores", "=", "defaultdict", "(", "int", ")", "\n", "data", "=", "[", "]", "\n", "bias_scores", "=", "[", "]", "\n", "mlm_scores", "=", "[", "]", "\n", "\n", "with", "open", "(", "'data/'", "+", "args", ".", "data", "+", "'.json'", ")", "as", "f", ":", "\n", "        ", "inputs", "=", "json", ".", "load", "(", "f", ")", "\n", "total_num", "=", "len", "(", "inputs", ")", "\n", "for", "input", "in", "tqdm", "(", "inputs", ")", ":", "\n", "            ", "if", "args", ".", "data", "==", "'cp'", "or", "args", ".", "data", "==", "'ss'", ":", "\n", "                ", "bias_type", "=", "input", "[", "'bias_type'", "]", "\n", "counts", "[", "bias_type", "]", "+=", "1", "\n", "", "else", ":", "\n", "#sense = input['pos']", "\n", "                ", "sense", "=", "f'{input[\"pos\"]} {input[\"sense\"]}'", "\n", "counts", "[", "sense", "]", "+=", "1", "\n", "\n", "", "pro_sentence", "=", "input", "[", "'stereotype'", "]", "\n", "anti_sentence", "=", "input", "[", "'anti-stereotype'", "]", "\n", "print", "(", "'pro_sentence: '", ",", "pro_sentence", ",", "'anti_sentence: '", ",", "anti_sentence", ")", "\n", "if", "args", ".", "model", "==", "'sense-base'", "or", "args", ".", "model", "==", "'sense-large'", ":", "\n", "                ", "pro_token_ids", ",", "pro_mask_ids", "=", "tokenizer", "(", "pro_sentence", ")", "\n", "anti_token_ids", ",", "anti_mask_ids", "=", "tokenizer", "(", "anti_sentence", ")", "\n", "pro_score", "=", "calculate_aul_for_sense_bert", "(", "model", ",", "pro_token_ids", ",", "\n", "pro_mask_ids", ")", "\n", "anti_score", "=", "calculate_aul_for_sense_bert", "(", "model", ",", "anti_token_ids", ",", "\n", "anti_mask_ids", ")", "\n", "", "elif", "args", ".", "model", "==", "'bert-base'", "or", "args", ".", "model", "==", "'bert-large'", ":", "\n", "                ", "pro_token_ids", "=", "tokenizer", ".", "encode", "(", "pro_sentence", ",", "return_tensors", "=", "'pt'", ")", "\n", "anti_token_ids", "=", "tokenizer", ".", "encode", "(", "anti_sentence", ",", "return_tensors", "=", "'pt'", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "pro_score", "=", "calculate_aul_for_bert", "(", "model", ",", "pro_token_ids", ",", "\n", "log_softmax", ")", "\n", "anti_score", "=", "calculate_aul_for_bert", "(", "model", ",", "anti_token_ids", ",", "\n", "log_softmax", ")", "\n", "", "", "print", "(", "'pro_score: '", ",", "pro_score", ",", "'anti_score: '", ",", "anti_score", ")", "\n", "total_score", "+=", "1", "\n", "if", "pro_score", ">", "anti_score", ":", "\n", "                ", "stereo_score", "+=", "1", "\n", "if", "args", ".", "data", "==", "'cp'", "or", "args", ".", "data", "==", "'ss'", ":", "\n", "                    ", "scores", "[", "bias_type", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "scores", "[", "sense", "]", "+=", "1", "\n", "", "", "mlm_scores", ".", "append", "(", "pro_score", ")", "\n", "\n", "", "", "bias_score", "=", "round", "(", "(", "stereo_score", "/", "total_score", ")", "*", "100", ",", "2", ")", "\n", "for", "bias_type", ",", "score", "in", "scores", ".", "items", "(", ")", ":", "\n", "        ", "bias_score", "=", "round", "(", "(", "score", "/", "counts", "[", "bias_type", "]", ")", "*", "100", ",", "2", ")", "\n", "print", "(", "bias_type", ",", "bias_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.parse_args": [[14, 24], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "\t", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--embedding'", ",", "type", "=", "str", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1111", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.load_lmms": [[26, 34], ["numpy.load", "loader[].tolist", "list", "zip"], "function", ["None"], ["", "def", "load_lmms", "(", "npz_vecs_path", ")", ":", "\n", "\t", "lmms", "=", "{", "}", "\n", "loader", "=", "np", ".", "load", "(", "npz_vecs_path", ")", "\n", "labels", "=", "loader", "[", "'labels'", "]", ".", "tolist", "(", ")", "\n", "vectors", "=", "loader", "[", "'vectors'", "]", "\n", "for", "label", ",", "vector", "in", "list", "(", "zip", "(", "labels", ",", "vectors", ")", ")", ":", "\n", "\t\t", "lmms", "[", "label", "]", "=", "vector", "\n", "", "return", "lmms", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.load_ares_txt": [[36, 48], ["open", "enumerate", "line.split", "numpy.array"], "function", ["None"], ["", "def", "load_ares_txt", "(", "path", ")", ":", "\n", "    ", "sense_vecs", "=", "{", "}", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "sfile", ":", "\n", "        ", "for", "idx", ",", "line", "in", "enumerate", "(", "sfile", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "continue", "\n", "", "splitLine", "=", "line", ".", "split", "(", "' '", ")", "\n", "label", "=", "splitLine", "[", "0", "]", "\n", "vec", "=", "np", ".", "array", "(", "splitLine", "[", "1", ":", "]", ",", "dtype", "=", "float", ")", "\n", "dim", "=", "vec", ".", "shape", "[", "0", "]", "\n", "sense_vecs", "[", "label", "]", "=", "vec", "\n", "", "", "return", "sense_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.get_sk_lemma": [[50, 52], ["sensekey.split"], "function", ["None"], ["", "def", "get_sk_lemma", "(", "sensekey", ")", ":", "\n", "\t", "return", "sensekey", ".", "split", "(", "'%'", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.word_assoc": [[54, 56], ["weat-sense.n_similarity", "weat-sense.n_similarity"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.n_similarity", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.n_similarity"], ["", "def", "word_assoc", "(", "w", ",", "a_attr_list", ",", "b_attr_list", ",", "sense_emb", ")", ":", "\n", "\t", "return", "n_similarity", "(", "sense_emb", ",", "a_attr_list", ")", "-", "n_similarity", "(", "sense_emb", ",", "b_attr_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.diff_assoc": [[58, 78], ["sense_emb.keys", "weat-sense.get_relevent_sense_list", "weat-sense.get_relevent_sense_list", "weat-sense.get_relevent_sense_list", "weat-sense.get_relevent_sense_list", "weat-sense.get_target_attr", "weat-sense.get_target_attr", "weat-sense.get_target_attr", "weat-sense.get_target_attr", "numpy.array", "numpy.array", "numpy.std", "list", "list", "numpy.mean", "numpy.mean", "numpy.concatenate", "map", "map", "weat-sense.word_assoc", "weat-sense.word_assoc"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_relevent_sense_list", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_relevent_sense_list", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_relevent_sense_list", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_relevent_sense_list", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_target_attr", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_target_attr", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_target_attr", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_target_attr", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.word_assoc", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.word_assoc"], ["", "def", "diff_assoc", "(", "X", ",", "Y", ",", "A", ",", "B", ",", "sense_emb", ")", ":", "\n", "\t", "sense_id_list", "=", "sense_emb", ".", "keys", "(", ")", "\n", "\n", "### Convert relevant sense lists for words in each of the x, y, a, b lists", "\n", "x_senses", "=", "get_relevent_sense_list", "(", "sense_id_list", ",", "X", ")", "\n", "y_senses", "=", "get_relevent_sense_list", "(", "sense_id_list", ",", "Y", ")", "\n", "a_senses", "=", "get_relevent_sense_list", "(", "sense_id_list", ",", "A", ")", "\n", "b_senses", "=", "get_relevent_sense_list", "(", "sense_id_list", ",", "B", ")", "\n", "\n", "xa_target_attr_list", "=", "get_target_attr", "(", "x_senses", ",", "a_senses", ",", "sense_emb", ")", "\n", "xb_target_attr_list", "=", "get_target_attr", "(", "x_senses", ",", "b_senses", ",", "sense_emb", ")", "\n", "ya_target_attr_list", "=", "get_target_attr", "(", "y_senses", ",", "a_senses", ",", "sense_emb", ")", "\n", "yb_target_attr_list", "=", "get_target_attr", "(", "y_senses", ",", "b_senses", ",", "sense_emb", ")", "\n", "\n", "word_assoc_X", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "word_assoc", "(", "x", ",", "xa_target_attr_list", ",", "xb_target_attr_list", ",", "sense_emb", ")", ",", "X", ")", ")", ")", "\n", "word_assoc_Y", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "y", ":", "word_assoc", "(", "y", ",", "ya_target_attr_list", ",", "yb_target_attr_list", ",", "sense_emb", ")", ",", "Y", ")", ")", ")", "\n", "mean_diff", "=", "np", ".", "mean", "(", "word_assoc_X", ")", "-", "np", ".", "mean", "(", "word_assoc_Y", ")", "\n", "std", "=", "np", ".", "std", "(", "np", ".", "concatenate", "(", "(", "word_assoc_X", ",", "word_assoc_Y", ")", ",", "axis", "=", "0", ")", ")", "\n", "# print('mean_diff: ', mean_diff, 'std: ', std)", "\n", "return", "mean_diff", "/", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.random_choice": [[80, 84], ["numpy.random.choice"], "function", ["None"], ["", "def", "random_choice", "(", "word_pairs", ",", "subset_size", ")", ":", "\n", "\t", "return", "np", ".", "random", ".", "choice", "(", "word_pairs", ",", "\n", "subset_size", ",", "\n", "replace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.get_bias_scores_mean_err": [[86, 100], ["print", "min", "min", "weat-sense.diff_assoc", "numpy.mean", "scipy.stats.sem", "len", "len", "len", "len", "weat-sense.random_choice", "weat-sense.random_choice", "weat-sense.random_choice", "weat-sense.random_choice", "range", "numpy.isnan"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.diff_assoc", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.random_choice", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.random_choice", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.random_choice", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.random_choice"], ["", "def", "get_bias_scores_mean_err", "(", "word_pairs", ",", "sense_emb", ")", ":", "\n", "\t", "print", "(", "'word pairs: '", ",", "word_pairs", ")", "\n", "subset_size_target", "=", "min", "(", "len", "(", "word_pairs", "[", "'X'", "]", ")", ",", "len", "(", "word_pairs", "[", "'Y'", "]", ")", ")", "//", "2", "\n", "subset_size_attr", "=", "min", "(", "len", "(", "word_pairs", "[", "'A'", "]", ")", ",", "len", "(", "word_pairs", "[", "'B'", "]", ")", ")", "//", "2", "\n", "bias_scores", "=", "[", "diff_assoc", "(", "\n", "random_choice", "(", "word_pairs", "[", "'X'", "]", ",", "subset_size_target", ")", ",", "\n", "random_choice", "(", "word_pairs", "[", "'Y'", "]", ",", "subset_size_target", ")", ",", "\n", "random_choice", "(", "word_pairs", "[", "'A'", "]", ",", "subset_size_attr", ")", ",", "\n", "random_choice", "(", "word_pairs", "[", "'B'", "]", ",", "subset_size_attr", ")", ",", "sense_emb", ")", "for", "_", "in", "range", "(", "5000", ")", "]", "\n", "# print('subset_size_target: ', subset_size_target, 'subset_size_attr: ', subset_size_attr)", "\n", "# print('bias_scores: ', bias_scores)", "\n", "bias_scores", "=", "[", "x", "for", "x", "in", "bias_scores", "if", "np", ".", "isnan", "(", "x", ")", "==", "False", "]", "\n", "# print('after remove nan: ', bias_scores)", "\n", "return", "np", ".", "mean", "(", "bias_scores", ")", ",", "stats", ".", "sem", "(", "bias_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.n_similarity": [[103, 124], ["numpy.dot", "gensim.matutils.unitvec", "gensim.matutils.unitvec", "numpy.array().mean", "numpy.array().mean", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "n_similarity", "(", "emb", ",", "target_attr_list", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tCompute cosine similarity between two sets of words.\n\n\t\tExample::\n\n\t\t  >>> trained_model.n_similarity(['sushi', 'shop'], ['japanese', 'restaurant'])\n\t\t  0.61540466561049689\n\n\t\t  >>> trained_model.n_similarity(['restaurant', 'japanese'], ['japanese', 'restaurant'])\n\t\t  1.0000000000000004\n\n\t\t  >>> trained_model.n_similarity(['sushi'], ['restaurant']) == trained_model.similarity('sushi', 'restaurant')\n\t\t  True\n\n\t\t\"\"\"", "\n", "# print('target_attr_list', target_attr_list)", "\n", "v1", "=", "[", "emb", "[", "i", "[", "0", "]", "]", "for", "i", "in", "target_attr_list", "]", "\n", "v2", "=", "[", "emb", "[", "i", "[", "1", "]", "]", "for", "i", "in", "target_attr_list", "]", "\n", "\n", "return", "np", ".", "dot", "(", "matutils", ".", "unitvec", "(", "np", ".", "array", "(", "v1", ")", ".", "mean", "(", "axis", "=", "0", ")", ")", ",", "matutils", ".", "unitvec", "(", "np", ".", "array", "(", "v2", ")", ".", "mean", "(", "axis", "=", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.get_relevent_sense_list": [[126, 135], ["word_senses.append", "weat-sense.get_sk_lemma", "word_sks.append"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma"], ["", "def", "get_relevent_sense_list", "(", "sense_id_list", ",", "word_list", ")", ":", "\n", "\t", "word_senses", "=", "[", "]", "\n", "for", "word", "in", "word_list", ":", "\n", "\t\t", "word_sks", "=", "[", "]", "\n", "for", "sense_id", "in", "sense_id_list", ":", "\n", "\t\t\t", "if", "word", "==", "get_sk_lemma", "(", "sense_id", ")", ":", "\n", "\t\t\t\t", "word_sks", ".", "append", "(", "sense_id", ")", "\n", "", "", "word_senses", ".", "append", "(", "word_sks", ")", "\n", "", "return", "word_senses", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.get_target_attr": [[137, 153], ["target_attr_list.append", "scipy.spatial.distance.cosine"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine"], ["", "def", "get_target_attr", "(", "target_senses", ",", "attr_senses", ",", "sense_emb", ")", ":", "\n", "### select sense embeddings for pair of words with the maximum similarity score", "\n", "\t", "target_attr_list", "=", "[", "]", "\n", "for", "target_sks", "in", "target_senses", ":", "\n", "\t\t", "for", "attr_sks", "in", "attr_senses", ":", "\n", "\t\t\t", "max_sim_target_attr", "=", "0", "\n", "for", "target_sk", "in", "target_sks", ":", "\n", "\t\t\t\t", "for", "attr_sk", "in", "attr_sks", ":", "\n", "\t\t\t\t\t", "sim_target_attr", "=", "1", "-", "distance", ".", "cosine", "(", "sense_emb", "[", "target_sk", "]", ",", "sense_emb", "[", "attr_sk", "]", ")", "\n", "if", "sim_target_attr", ">", "max_sim_target_attr", ":", "\n", "\t\t\t\t\t\t", "max_sim_target_attr", "=", "sim_target_attr", "\n", "max_target_sk", "=", "target_sk", "\n", "max_attr_sk", "=", "attr_sk", "\n", "", "", "", "target_attr_list", ".", "append", "(", "(", "max_target_sk", ",", "max_attr_sk", ")", ")", "\n", "\n", "", "", "return", "target_attr_list", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.run_test": [[155, 174], ["sense_emb.keys", "config.items", "weat-sense.get_bias_scores_mean_err", "weat-sense.get_sk_lemma", "list", "filter", "len", "print", "print", "sense_lemma.values"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.get_bias_scores_mean_err", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma"], ["", "def", "run_test", "(", "config", ",", "sense_emb", ")", ":", "\n", "\t", "word_pairs", "=", "{", "}", "\n", "sense_lemma", "=", "{", "}", "\n", "min_len", "=", "sys", ".", "maxsize", "\n", "\n", "for", "sense", "in", "sense_emb", ".", "keys", "(", ")", ":", "\n", "\t\t", "lemma", "=", "get_sk_lemma", "(", "sense", ")", "\n", "sense_lemma", "[", "sense", "]", "=", "lemma", "\n", "\n", "", "for", "word_list_name", ",", "word_list", "in", "config", ".", "items", "(", ")", ":", "\n", "\t\t", "if", "word_list_name", "in", "[", "'X'", ",", "'Y'", ",", "'A'", ",", "'B'", "]", ":", "\n", "\t\t\t", "word_list_filtered", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "in", "sense_lemma", ".", "values", "(", ")", ",", "word_list", ")", ")", "\n", "word_pairs", "[", "word_list_name", "]", "=", "word_list_filtered", "\n", "if", "len", "(", "word_list_filtered", ")", "<", "2", ":", "\n", "\t\t\t\t", "print", "(", "'ERROR: Words from list {} not found in embedding\\n {}'", ".", "format", "(", "word_list_name", ",", "word_list", ")", ")", "\n", "print", "(", "'All word groups must contain at least two words'", ")", "\n", "return", "None", ",", "None", "\n", "", "", "", "return", "get_bias_scores_mean_err", "(", "word_pairs", ",", "sense_emb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.eval_weat": [[176, 188], ["json.load", "open", "open", "config[].items", "weat-sense.run_test", "print", "str", "str", "fw.write", "fw.write", "fw.write", "round", "round"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.run_test"], ["", "def", "eval_weat", "(", "sense_emb", ",", "output", ")", ":", "\n", "\t", "config", "=", "json", ".", "load", "(", "open", "(", "'data/weat.json'", ")", ")", "\n", "with", "open", "(", "output", ",", "'w'", ")", "as", "fw", ":", "\n", "\t\t\t", "for", "name_of_test", ",", "test_config", "in", "config", "[", "'tests'", "]", ".", "items", "(", ")", ":", "\n", "\t\t\t\t", "score", ",", "err", "=", "run_test", "(", "test_config", ",", "sense_emb", ")", "\n", "print", "(", "'name_of_test: '", ",", "name_of_test", ",", "'score: '", ",", "score", ")", "\n", "if", "score", "is", "not", "None", ":", "\n", "\t\t\t\t\t", "score", "=", "str", "(", "round", "(", "score", ",", "4", ")", ")", "\n", "err", "=", "str", "(", "round", "(", "err", ",", "4", ")", ")", "\n", "fw", ".", "write", "(", "f'{name_of_test}\\n'", ")", "\n", "fw", ".", "write", "(", "f'Score: {score}\\n'", ")", "\n", "fw", ".", "write", "(", "f'P-value: {err}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.main": [[190, 194], ["weat-sense.load_lmms", "weat-sense.eval_weat"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.load_lmms", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.weat-sense.eval_weat"], ["", "", "", "", "def", "main", "(", "args", ")", ":", "\n", "\t", "sense_emb", "=", "load_lmms", "(", "'path to lmms embeddings'", ")", "\n", "# sense_emb = load_ares_txt(\"path to ares embeddings\")", "\n", "eval_weat", "(", "sense_emb", ",", "args", ".", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.parse_args": [[8, 17], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "\t", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--embedding'", ",", "type", "=", "str", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.cos_sim": [[19, 21], ["numpy.dot", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "cos_sim", "(", "v1", ",", "v2", ")", ":", "\n", "\t", "return", "np", ".", "dot", "(", "v1", ",", "v2", ")", "/", "(", "np", ".", "linalg", ".", "norm", "(", "v1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "v2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_relevent_sense_list": [[23, 32], ["word_senses.append", "wat-sense.get_sk_lemma", "word_sks.append"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma"], ["", "def", "get_relevent_sense_list", "(", "sense_id_list", ",", "word_list", ")", ":", "\n", "\t", "word_senses", "=", "[", "]", "\n", "for", "word", "in", "word_list", ":", "\n", "\t\t", "word_sks", "=", "[", "]", "\n", "for", "sense_id", "in", "sense_id_list", ":", "\n", "\t\t\t", "if", "word", "==", "get_sk_lemma", "(", "sense_id", ")", ":", "\n", "\t\t\t\t", "word_sks", ".", "append", "(", "sense_id", ")", "\n", "", "", "word_senses", ".", "append", "(", "word_sks", ")", "\n", "", "return", "word_senses", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_target_attr": [[34, 48], ["target_attr_list.append", "scipy.spatial.distance.cosine"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.eval-sssb-word.cosine"], ["", "def", "get_target_attr", "(", "target_senses", ",", "attr_senses", ",", "sense_emb", ")", ":", "\n", "### select sense embeddings for pair of words with the maximum similarity score", "\n", "\t", "target_attr_list", "=", "[", "]", "\n", "for", "target_sks", "in", "target_senses", ":", "\n", "\t\t", "for", "attr_sks", "in", "attr_senses", ":", "\n", "\t\t\t", "max_sim_target_attr", "=", "0", "\n", "sim_target_attr", "=", "1", "-", "distance", ".", "cosine", "(", "sense_emb", "[", "target_sks", "]", ",", "sense_emb", "[", "attr_sks", "]", ")", "\n", "if", "sim_target_attr", ">", "max_sim_target_attr", ":", "\n", "\t\t\t\t", "max_sim_target_attr", "=", "sim_target_attr", "\n", "max_target_sk", "=", "target_sks", "\n", "max_attr_sk", "=", "attr_sks", "\n", "", "", "", "target_attr_list", ".", "append", "(", "(", "max_target_sk", ",", "max_attr_sk", ")", ")", "\n", "\n", "return", "target_attr_list", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.eval_wat": [[50, 112], ["emb.keys", "open", "dict", "gold_d.keys", "dict.keys", "scipy.stats.pearsonr", "wat-sense.get_sk_lemma", "l.strip().split", "emb.keys", "zip", "numpy.array", "numpy.array", "open", "fw.write", "fw.write", "word2sense.keys", "float", "len", "emb.keys", "wat-sense.get_target_attr", "wat-sense.get_target_attr", "print", "scores_list.append", "sum", "len", "l.strip", "wat-sense.get_sk_lemma", "relevant_sks.append", "print", "wat-sense.cos_sim", "print", "wat-sense.cos_sim", "wat-sense.get_sk_lemma", "relevant_sks_1.append", "wat-sense.get_sk_lemma", "relevant_sks_2.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_target_attr", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_target_attr", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.cos_sim", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.cos_sim", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma"], ["", "def", "eval_wat", "(", "emb", ",", "output", ",", "path", ",", "word1_list", ",", "word2_list", ")", ":", "\n", "\t", "word2sense", "=", "{", "}", "\n", "for", "sense", "in", "emb", ".", "keys", "(", ")", ":", "\n", "\t\t", "lemma", "=", "get_sk_lemma", "(", "sense", ")", "\n", "word2sense", "[", "lemma", "]", "=", "sense", "\n", "\n", "", "gold_d", "=", "{", "}", "\n", "for", "l", "in", "open", "(", "path", ")", ":", "\n", "\t\t", "word", ",", "score", "=", "l", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "word", "in", "word2sense", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "gold_d", "[", "word", "]", "=", "float", "(", "score", ")", "\n", "", "", "emb_d", "=", "dict", "(", ")", "\n", "for", "key", "in", "gold_d", ".", "keys", "(", ")", ":", "\n", "\t\t", "if", "key", "in", "word1_list", "or", "key", "in", "word2_list", ":", "\n", "\t\t\t", "continue", "\n", "", "relevant_sks", "=", "[", "]", "\n", "for", "sense", "in", "emb", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "if", "key", "==", "get_sk_lemma", "(", "sense", ")", ":", "\n", "\t\t\t\t", "relevant_sks", ".", "append", "(", "sense", ")", "\n", "\n", "", "", "if", "len", "(", "relevant_sks", ")", "==", "0", ":", "\n", "\t\t\t", "continue", "\n", "\n", "", "scores_list", "=", "[", "]", "\n", "for", "w1", ",", "w2", "in", "zip", "(", "word1_list", ",", "word2_list", ")", ":", "\n", "\t\t\t", "relevant_sks_1", "=", "[", "]", "\n", "relevant_sks_2", "=", "[", "]", "\n", "for", "sense", "in", "emb", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "if", "w1", "==", "get_sk_lemma", "(", "sense", ")", ":", "\n", "\t\t\t\t\t", "relevant_sks_1", ".", "append", "(", "sense", ")", "\n", "", "if", "w2", "==", "get_sk_lemma", "(", "sense", ")", ":", "\n", "\t\t\t\t\t", "relevant_sks_2", ".", "append", "(", "sense", ")", "\n", "\n", "", "", "if", "len", "(", "relevant_sks_1", ")", "==", "0", "or", "len", "(", "relevant_sks_2", ")", "==", "0", ":", "\n", "\t\t\t\t", "continue", "\n", "\n", "", "target_attr_list_w1", "=", "get_target_attr", "(", "relevant_sks", ",", "relevant_sks_1", ",", "emb", ")", "\n", "target_attr_list_w2", "=", "get_target_attr", "(", "relevant_sks", ",", "relevant_sks_2", ",", "emb", ")", "\n", "print", "(", "'-----target_attr_list_w1'", ",", "target_attr_list_w1", ",", "'-------target_attr_list_w2'", ",", "target_attr_list_w2", ")", "\n", "\n", "for", "e1", ",", "s_1", "in", "target_attr_list_w1", ":", "\n", "\t\t\t\t", "print", "(", "'e1'", ",", "e1", ",", "'s_1'", ",", "s_1", ")", "\n", "score1", "=", "cos_sim", "(", "emb", "[", "e1", "]", ",", "emb", "[", "s_1", "]", ")", "\n", "", "for", "e2", ",", "s_2", "in", "target_attr_list_w2", ":", "\n", "\t\t\t\t", "print", "(", "'e2'", ",", "e2", ",", "'s_2'", ",", "s_2", ")", "\n", "score2", "=", "cos_sim", "(", "emb", "[", "e2", "]", ",", "emb", "[", "s_2", "]", ")", "\n", "", "score", "=", "score1", "-", "score2", "\n", "scores_list", ".", "append", "(", "score", ")", "\n", "\n", "", "score", "=", "sum", "(", "scores_list", ")", "/", "len", "(", "scores_list", ")", "\n", "emb_d", "[", "key", "]", "=", "score", "\n", "\n", "", "g_l", "=", "[", "]", "\n", "e_l", "=", "[", "]", "\n", "for", "key", "in", "emb_d", ".", "keys", "(", ")", ":", "\n", "\t\t", "g_l", "+=", "[", "gold_d", "[", "key", "]", "]", "\n", "e_l", "+=", "[", "emb_d", "[", "key", "]", "]", "\n", "", "r", ",", "p", "=", "pearsonr", "(", "np", ".", "array", "(", "g_l", ")", ",", "np", ".", "array", "(", "e_l", ")", ")", "\n", "\n", "with", "open", "(", "output", ",", "'w'", ")", "as", "fw", ":", "\n", "\t\t", "fw", ".", "write", "(", "f'Pearson\u2019s correlation coefficient: {r}\\n'", ")", "\n", "fw", ".", "write", "(", "f'P-value: {p}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.load_lmms": [[114, 122], ["numpy.load", "loader[].tolist", "list", "zip"], "function", ["None"], ["", "", "def", "load_lmms", "(", "npz_vecs_path", ")", ":", "\n", "\t", "lmms", "=", "{", "}", "\n", "loader", "=", "np", ".", "load", "(", "npz_vecs_path", ")", "\n", "labels", "=", "loader", "[", "'labels'", "]", ".", "tolist", "(", ")", "\n", "vectors", "=", "loader", "[", "'vectors'", "]", "\n", "for", "label", ",", "vector", "in", "list", "(", "zip", "(", "labels", ",", "vectors", ")", ")", ":", "\n", "\t\t", "lmms", "[", "label", "]", "=", "vector", "\n", "", "return", "lmms", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.load_ares_txt": [[124, 137], ["open", "enumerate", "line.split", "numpy.array"], "function", ["None"], ["", "def", "load_ares_txt", "(", "path", ")", ":", "\n", "    ", "sense_vecs", "=", "{", "}", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "sfile", ":", "\n", "        ", "for", "idx", ",", "line", "in", "enumerate", "(", "sfile", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "continue", "\n", "", "splitLine", "=", "line", ".", "split", "(", "' '", ")", "\n", "label", "=", "splitLine", "[", "0", "]", "\n", "vec", "=", "np", ".", "array", "(", "splitLine", "[", "1", ":", "]", ",", "dtype", "=", "float", ")", "\n", "dim", "=", "vec", ".", "shape", "[", "0", "]", "\n", "# print('self.dim', self.dim)", "\n", "sense_vecs", "[", "label", "]", "=", "vec", "\n", "", "", "return", "sense_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.get_sk_lemma": [[139, 141], ["sensekey.split"], "function", ["None"], ["", "def", "get_sk_lemma", "(", "sensekey", ")", ":", "\n", "\t", "return", "sensekey", ".", "split", "(", "'%'", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.main": [[143, 153], ["wat-sense.load_lmms", "wat-sense.eval_wat"], "function", ["home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.load_lmms", "home.repos.pwc.inspect_result.livnlp_bias-sense.None.wat-sense.eval_wat"], ["", "def", "main", "(", "args", ")", ":", "\n", "\t", "sense_emb", "=", "load_lmms", "(", "'path to lmms embeddings'", ")", "\n", "# sense_emb = load_ares_txt(\"path to ares embeddings\")", "\n", "\n", "word1_list", "=", "[", "'he'", ",", "'father'", ",", "'son'", ",", "'husband'", ",", "'grandfather'", ",", "\n", "'brother'", ",", "'man'", ",", "'boy'", ",", "'uncle'", ",", "'gentleman'", "]", "\n", "word2_list", "=", "[", "'she'", ",", "'mother'", ",", "'daughter'", ",", "'wife'", ",", "'grandmother'", ",", "\n", "'sister'", ",", "'woman'", ",", "'girl'", ",", "'aunt'", ",", "'lady'", "]", "\n", "\n", "eval_wat", "(", "sense_emb", ",", "args", ".", "output", ",", "'data/wat_bi.txt'", ",", "word1_list", ",", "word2_list", ")", "\n", "\n"]]}