{"home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.Net100.__init__": [[15, 20], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net100", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "784", ",", "100", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "100", ",", "100", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "100", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.Net100.forward": [[21, 26], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "main.Net100.fc3", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "main.Net100.fc1", "main.Net100.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.Net200.__init__": [[29, 34], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net200", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "784", ",", "200", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "200", ",", "200", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "200", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.Net200.forward": [[35, 40], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "main.Net200.fc3", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "main.Net200.fc1", "main.Net200.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.train_continuous_mnist": [[42, 107], ["utils.weight_lst", "utils.init_param", "range", "len", "range", "range", "print", "ava_test.append", "enumerate", "model.eval", "print", "model.eval", "print", "numpy.average", "model.train", "data.view.view", "range", "utils.update_m", "utils.update_a_b", "utils.zero_matrix", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "test_acc_lst.append", "numpy.asanyarray", "data.view.to", "target.to", "utils.gen_phi", "utils.randomize_weights", "model", "torch.CrossEntropyLoss", "utils.zero_grad", "loss.backward", "utils.weight_grad", "utils.aggregate_grads", "utils.aggregate_e_a", "utils.aggregate_e_b", "data.view.view", "range", "data.view.view", "range", "nn.CrossEntropyLoss.", "data.view.to", "target.to", "utils.gen_phi", "utils.randomize_weights", "model", "model.argmax", "output.argmax.eq().sum().item", "len", "data.view.to", "target.to", "utils.gen_phi", "utils.randomize_weights", "model", "model.argmax", "output.argmax.eq().sum().item", "len", "output.argmax.eq().sum", "output.argmax.eq().sum", "output.argmax.eq", "output.argmax.eq", "target.view_as", "target.view_as"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.weight_lst", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.init_param", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.update_m", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.update_a_b", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.zero_matrix", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.gen_phi", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.randomize_weights", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.zero_grad", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.weight_grad", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_grads", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_e_a", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_e_b", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.gen_phi", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.randomize_weights", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.gen_phi", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.randomize_weights"], ["", "", "def", "train_continuous_mnist", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "test_loader", ")", ":", "\n", "    ", "ava_test", "=", "[", "]", "\n", "weight_lst", "=", "utils", ".", "weight_lst", "(", "model", ")", "\n", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "avg_psi_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", "=", "utils", ".", "init_param", "(", "weight_lst", ",", "args", ".", "s_init", ",", "device", ",", "True", ",", "args", ".", "alpha", ")", "\n", "for", "task", "in", "range", "(", "len", "(", "test_loader", ")", ")", ":", "\n", "        ", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train_loader", "[", "0", "]", ")", ":", "\n", "                ", "model", ".", "train", "(", ")", "\n", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "data", "=", "data", ".", "view", "(", "-", "1", ",", "784", ")", "\n", "for", "mc_iter", "in", "range", "(", "args", ".", "train_mc_iters", ")", ":", "\n", "# Phi ~ MN(0,I,I)", "\n", "                    ", "phi_mat_lst", "=", "utils", ".", "gen_phi", "(", "w_mat_lst", ",", "device", ")", "\n", "# W = M +B*Phi*A^t", "\n", "utils", ".", "randomize_weights", "(", "weight_lst", ",", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "args", ".", "batch_size", "*", "criterion", "(", "output", ",", "target", ")", "\n", "utils", ".", "zero_grad", "(", "weight_lst", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_mat_lst", "=", "utils", ".", "weight_grad", "(", "weight_lst", ",", "device", ")", "\n", "utils", ".", "aggregate_grads", "(", "args", ",", "avg_psi_mat_lst", ",", "grad_mat_lst", ")", "\n", "utils", ".", "aggregate_e_a", "(", "args", ",", "e_a_mat_lst", ",", "grad_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "utils", ".", "aggregate_e_b", "(", "args", ",", "e_b_mat_lst", ",", "grad_mat_lst", ",", "a_mat_lst", ",", "phi_mat_lst", ")", "\n", "# M = M - B*B^t*avg_Phi*A*A^t", "\n", "", "utils", ".", "update_m", "(", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "avg_psi_mat_lst", ",", "args", ".", "eta", ")", "\n", "utils", ".", "update_a_b", "(", "a_mat_lst", ",", "b_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", ",", "device", ",", "args", ".", "use_gsvd", ")", "\n", "utils", ".", "zero_matrix", "(", "avg_psi_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "correct", "=", "0", "\n", "for", "data", ",", "target", "in", "test_loader", "[", "task", "]", ":", "\n", "                    ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "data", "=", "data", ".", "view", "(", "-", "1", ",", "784", ")", "\n", "for", "mc_iter", "in", "range", "(", "args", ".", "train_mc_iters", ")", ":", "\n", "                        ", "phi_mat_lst", "=", "utils", ".", "gen_phi", "(", "w_mat_lst", ",", "device", ")", "\n", "utils", ".", "randomize_weights", "(", "weight_lst", ",", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "test_acc", "=", "100.", "*", "correct", "/", "(", "len", "(", "test_loader", "[", "task", "]", ".", "dataset", ")", "*", "args", ".", "train_mc_iters", ")", "\n", "", "print", "(", "'\\nTask num {}, Epoch num {} Test Accuracy: {:.2f}%\\n'", ".", "format", "(", "\n", "task", ",", "epoch", ",", "test_acc", ")", ")", "\n", "", "test_acc_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "task", "+", "1", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "correct", "=", "0", "\n", "for", "data", ",", "target", "in", "test_loader", "[", "i", "]", ":", "\n", "                    ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "data", "=", "data", ".", "view", "(", "-", "1", ",", "784", ")", "\n", "for", "mc_iter", "in", "range", "(", "args", ".", "train_mc_iters", ")", ":", "\n", "                        ", "phi_mat_lst", "=", "utils", ".", "gen_phi", "(", "w_mat_lst", ",", "device", ")", "\n", "utils", ".", "randomize_weights", "(", "weight_lst", ",", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "test_acc", "=", "100.", "*", "correct", "/", "(", "len", "(", "test_loader", "[", "i", "]", ".", "dataset", ")", "*", "args", ".", "train_mc_iters", ")", "\n", "test_acc_lst", ".", "append", "(", "test_acc", ")", "\n", "", "print", "(", "'\\nTraning task Num: {} Test Accuracy of task {}: {:.2f}%\\n'", ".", "format", "(", "\n", "task", ",", "i", ",", "test_acc", ")", ")", "\n", "", "print", "(", "test_acc_lst", ")", "\n", "ava_test", ".", "append", "(", "np", ".", "average", "(", "np", ".", "asanyarray", "(", "test_acc_lst", ")", ")", ")", "\n", "", "return", "ava_test", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.train_multiple_tasks": [[109, 189], ["utils.weight_lst", "utils.init_param", "range", "len", "range", "range", "print", "ava_test.append", "enumerate", "model.eval", "print", "model.eval", "print", "numpy.average", "model.train", "data.view.view", "range", "utils.update_m", "utils.update_a_b", "utils.zero_matrix", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "test_acc_lst.append", "numpy.asanyarray", "data.view.to", "target.to", "utils.gen_phi", "utils.randomize_weights", "model", "torch.CrossEntropyLoss", "utils.zero_grad", "loss.backward", "utils.weight_grad", "utils.aggregate_grads", "utils.aggregate_e_a", "utils.aggregate_e_b", "data.view.view", "range", "data.view.view", "range", "data.view.view", "range", "nn.CrossEntropyLoss.", "data.view.to", "target.to", "utils.gen_phi", "utils.randomize_weights", "model", "model.argmax", "output.argmax.eq().sum().item", "len", "data.view.to", "target.to", "utils.gen_phi", "utils.randomize_weights", "model", "model.argmax", "output.argmax.eq().sum().item", "len", "data.view.to", "target.to", "utils.gen_phi", "utils.randomize_weights", "model", "model.argmax", "output.argmax.eq().sum().item", "len", "output.argmax.eq().sum", "output.argmax.eq().sum", "output.argmax.eq().sum", "output.argmax.eq", "output.argmax.eq", "output.argmax.eq", "target.view_as", "target.view_as", "target.view_as"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.weight_lst", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.init_param", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.update_m", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.update_a_b", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.zero_matrix", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.gen_phi", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.randomize_weights", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.zero_grad", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.weight_grad", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_grads", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_e_a", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_e_b", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.gen_phi", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.randomize_weights", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.gen_phi", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.randomize_weights", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.gen_phi", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.randomize_weights"], ["", "def", "train_multiple_tasks", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "test_loader", ",", "perm_lst", ",", "save_path", ")", ":", "\n", "    ", "ava_test", "=", "[", "]", "\n", "weight_lst", "=", "utils", ".", "weight_lst", "(", "model", ")", "\n", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "avg_psi_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", "=", "utils", ".", "init_param", "(", "weight_lst", ",", "args", ".", "s_init", ",", "device", ",", "True", ",", "args", ".", "alpha", ")", "\n", "for", "task", "in", "range", "(", "len", "(", "perm_lst", ")", ")", ":", "\n", "        ", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "                ", "model", ".", "train", "(", ")", "\n", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "data", "=", "data", ".", "view", "(", "-", "1", ",", "784", ")", "\n", "data", "=", "data", "[", ":", ",", "perm_lst", "[", "task", "]", "]", "\n", "for", "mc_iter", "in", "range", "(", "args", ".", "train_mc_iters", ")", ":", "\n", "# Phi ~ MN(0,I,I)", "\n", "                    ", "phi_mat_lst", "=", "utils", ".", "gen_phi", "(", "w_mat_lst", ",", "device", ")", "\n", "# W = M +B*Phi*A^t", "\n", "utils", ".", "randomize_weights", "(", "weight_lst", ",", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "args", ".", "batch_size", "*", "criterion", "(", "output", ",", "target", ")", "\n", "utils", ".", "zero_grad", "(", "weight_lst", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_mat_lst", "=", "utils", ".", "weight_grad", "(", "weight_lst", ",", "device", ")", "\n", "utils", ".", "aggregate_grads", "(", "args", ",", "avg_psi_mat_lst", ",", "grad_mat_lst", ")", "\n", "utils", ".", "aggregate_e_a", "(", "args", ",", "e_a_mat_lst", ",", "grad_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "utils", ".", "aggregate_e_b", "(", "args", ",", "e_b_mat_lst", ",", "grad_mat_lst", ",", "a_mat_lst", ",", "phi_mat_lst", ")", "\n", "# M = M - B*B^t*avg_Phi*A*A^t", "\n", "", "utils", ".", "update_m", "(", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "avg_psi_mat_lst", ",", "args", ".", "eta", ")", "# , task == 0)", "\n", "utils", ".", "update_a_b", "(", "a_mat_lst", ",", "b_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", ",", "device", ",", "args", ".", "use_gsvd", ")", "\n", "utils", ".", "zero_matrix", "(", "avg_psi_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "correct", "=", "0", "\n", "for", "data", ",", "target", "in", "train_loader", ":", "\n", "                    ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "data", "=", "data", ".", "view", "(", "-", "1", ",", "784", ")", "\n", "data", "=", "data", "[", ":", ",", "perm_lst", "[", "task", "]", "]", "\n", "for", "mc_iter", "in", "range", "(", "args", ".", "train_mc_iters", ")", ":", "\n", "                        ", "phi_mat_lst", "=", "utils", ".", "gen_phi", "(", "w_mat_lst", ",", "device", ")", "\n", "utils", ".", "randomize_weights", "(", "weight_lst", ",", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "train_acc", "=", "100.", "*", "correct", "/", "(", "len", "(", "train_loader", ".", "dataset", ")", "*", "args", ".", "train_mc_iters", ")", "\n", "correct", "=", "0", "\n", "for", "data", ",", "target", "in", "test_loader", ":", "\n", "                    ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "data", "=", "data", ".", "view", "(", "-", "1", ",", "784", ")", "\n", "data", "=", "data", "[", ":", ",", "perm_lst", "[", "task", "]", "]", "\n", "for", "mc_iter", "in", "range", "(", "args", ".", "train_mc_iters", ")", ":", "\n", "                        ", "phi_mat_lst", "=", "utils", ".", "gen_phi", "(", "w_mat_lst", ",", "device", ")", "\n", "utils", ".", "randomize_weights", "(", "weight_lst", ",", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "test_acc", "=", "100.", "*", "correct", "/", "(", "len", "(", "test_loader", ".", "dataset", ")", "*", "args", ".", "train_mc_iters", ")", "\n", "", "print", "(", "'\\nTask num {}, Epoch num {}, Train Accuracy: {:.2f}% Test Accuracy: {:.2f}%\\n'", ".", "format", "(", "\n", "task", ",", "epoch", ",", "train_acc", ",", "test_acc", ")", ")", "\n", "", "test_acc_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "task", "+", "1", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "correct", "=", "0", "\n", "for", "data", ",", "target", "in", "test_loader", ":", "\n", "                    ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "data", "=", "data", ".", "view", "(", "-", "1", ",", "784", ")", "\n", "data", "=", "data", "[", ":", ",", "perm_lst", "[", "i", "]", "]", "\n", "for", "mc_iter", "in", "range", "(", "args", ".", "train_mc_iters", ")", ":", "\n", "                        ", "phi_mat_lst", "=", "utils", ".", "gen_phi", "(", "w_mat_lst", ",", "device", ")", "\n", "utils", ".", "randomize_weights", "(", "weight_lst", ",", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "test_acc", "=", "100.", "*", "correct", "/", "(", "len", "(", "test_loader", ".", "dataset", ")", "*", "args", ".", "train_mc_iters", ")", "\n", "test_acc_lst", ".", "append", "(", "test_acc", ")", "\n", "", "print", "(", "'\\nTraning task Num: {} Test Accuracy of task {}: {:.2f}%\\n'", ".", "format", "(", "\n", "task", ",", "i", ",", "test_acc", ")", ")", "\n", "", "print", "(", "test_acc_lst", ")", "\n", "ava_test", ".", "append", "(", "np", ".", "average", "(", "np", ".", "asanyarray", "(", "test_acc_lst", ")", ")", ")", "\n", "", "return", "ava_test", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.main": [[191, 266], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "utils.set_seed", "os.path.join", "torch.device", "torch.device", "torch.device", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.exists", "os.makedirs", "Net100().to", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "utils.create_random_perm", "main.train_multiple_tasks", "print", "torch.save", "torch.save", "torch.save", "str", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "Net200().to", "utils.create_random_perm", "datasets.ds_padded_cont_permuted_mnist", "main.train_continuous_mnist", "print", "Net200().to.state_dict", "main.Net100", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "main.Net200", "int", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.set_seed", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.create_random_perm", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.train_multiple_tasks", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.create_random_perm", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_padded_cont_permuted_mnist", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.main.train_continuous_mnist"], ["", "def", "main", "(", ")", ":", "\n", "# Training settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch implementation of FOO-VB algorithm'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'input batch size for training (default: 128)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'input batch size for testing (default: 1000)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of epochs per task (default: 20)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-cuda'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'disables CUDA training'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "metavar", "=", "'S'", ",", "\n", "help", "=", "'random seed (default: 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_model'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'For Saving the current Model'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_mc_iters'", ",", "default", "=", "2500", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of MonteCarlo samples during training(default 10)'", ")", "\n", "parser", ".", "add_argument", "(", "'--s_init'", ",", "default", "=", "0.27", ",", "type", "=", "float", ",", "\n", "help", "=", "'STD init value (default 0.27)'", ")", "\n", "parser", ".", "add_argument", "(", "'--eta'", ",", "default", "=", "1", ",", "type", "=", "float", ",", "\n", "help", "=", "'STD init value (default 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "default", "=", "0.5", ",", "type", "=", "float", ",", "\n", "help", "=", "'STD init value (default 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--tasks'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of tasks (default 10)'", ")", "\n", "parser", ".", "add_argument", "(", "'--results_dir'", ",", "type", "=", "str", ",", "default", "=", "\"TMP\"", ",", "\n", "help", "=", "'Results dir name'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_gsvd'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use gsvd'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "\"permuted_mnist\"", ",", "type", "=", "str", ",", "choices", "=", "[", "'permuted_mnist'", ",", "'continuous_permuted_mnist'", "]", ",", "\n", "help", "=", "'The name of the dataset to train. [Default: permuted_mnist]'", ")", "\n", "parser", ".", "add_argument", "(", "'--iterations_per_virtual_epc'", ",", "default", "=", "468", ",", "type", "=", "int", ",", "\n", "help", "=", "'When using continuous dataset, number of iterations per epoch (in continuous mode, '", "\n", "'epoch is not defined)'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "use_cuda", "=", "not", "args", ".", "no_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "utils", ".", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "\"./logs\"", ",", "str", "(", "args", ".", "results_dir", ")", "+", "\"/\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "if", "args", ".", "dataset", "==", "'permuted_mnist'", ":", "\n", "        ", "model", "=", "Net100", "(", ")", ".", "to", "(", "device", ")", "\n", "kwargs", "=", "{", "'num_workers'", ":", "1", ",", "'pin_memory'", ":", "True", "}", "if", "use_cuda", "else", "{", "}", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "'../data'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "'../data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "perm_lst", "=", "utils", ".", "create_random_perm", "(", "args", ".", "tasks", ")", "\n", "ava_test", "=", "train_multiple_tasks", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "test_loader", ",", "perm_lst", ",", "save_path", ")", "\n", "print", "(", "ava_test", ")", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "dataset", "==", "'continuous_permuted_mnist'", ":", "\n", "            ", "model", "=", "Net200", "(", ")", ".", "to", "(", "device", ")", "\n", "perm_lst", "=", "utils", ".", "create_random_perm", "(", "10", ")", "\n", "perm_lst", "=", "perm_lst", "[", "1", ":", "11", "]", "\n", "kwargs", "=", "{", "'num_workers'", ":", "1", ",", "'pin_memory'", ":", "True", "}", "if", "use_cuda", "else", "{", "}", "\n", "train_loaders", ",", "test_loaders", "=", "ds", ".", "ds_padded_cont_permuted_mnist", "(", "num_epochs", "=", "int", "(", "args", ".", "epochs", "*", "args", ".", "tasks", ")", ",", "iterations_per_virtual_epc", "=", "args", ".", "iterations_per_virtual_epc", ",", "\n", "contpermuted_beta", "=", "4", ",", "permutations", "=", "perm_lst", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "**", "kwargs", ")", "\n", "ava_test", "=", "train_continuous_mnist", "(", "args", ",", "model", ",", "device", ",", "train_loaders", ",", "test_loaders", ")", "\n", "print", "(", "ava_test", ")", "\n", "", "", "if", "args", ".", "save_model", ":", "\n", "        ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save_path", "+", "\"/fcn.pt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.create_random_perm": [[7, 20], ["range", "numpy.arange", "numpy.random.seed", "perm_lst.append", "numpy.random.permutation"], "function", ["None"], ["def", "create_random_perm", "(", "n_permutations", ")", ":", "\n", "    ", "\"\"\"\n        This function returns a list of array permutation (size of 28*28 = 784) to create permuted MNIST data.\n        Note the first permutation is the identity permutation.\n        :param n_permutations: number of permutations.\n        :return perm_lst: a list of permutations.\n    \"\"\"", "\n", "perm_lst", "=", "[", "np", ".", "arange", "(", "784", ")", "]", "\n", "for", "seed", "in", "range", "(", "1", ",", "n_permutations", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "perm_lst", ".", "append", "(", "np", ".", "random", ".", "permutation", "(", "784", ")", ")", "\n", "\n", "", "return", "perm_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.solve_matrix_equation": [[22, 57], ["v_mat.double.double", "e_mat.double.double", "torch.mm", "torch.add", "torch.svd", "torch.mm", "torch.mm", "torch.svd", "torch.mm", "torch.add", "torch.add.float", "torch.mm", "torch.min().item", "torch.mm", "torch.transpose", "torch.mm", "torch.transpose", "torch.mm", "torch.transpose", "torch.mm", "torch.add", "torch.norm", "print", "torch.transpose", "torch.diagflat", "torch.diagflat", "torch.add", "torch.norm.item", "torch.min", "torch.sqrt", "torch.reciprocal", "torch.mm", "torch.mm", "torch.sqrt", "torch.transpose", "torch.transpose"], "function", ["None"], ["", "def", "solve_matrix_equation", "(", "v_mat", ",", "e_mat", ",", "print_norm_flag", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n        This function returns a solution for the following non-linear matrix equation XX^{\\top}+VEX^{\\top}-V = 0.\n        All the calculations are done in double precision.\n        :param v_mat: N*N PD matrix.\n        :param e_mat: N*N matrix.\n        :param print_norm_flag: Boolean parameter. Print the norm of the matrix equation.\n        :return: x_mat: N*N matrix a solution to the non-linear matrix equation.\n    \"\"\"", "\n", "# B = V + (1/4)V*E*(E^T)*V", "\n", "v_mat", "=", "v_mat", ".", "double", "(", ")", "\n", "e_mat", "=", "e_mat", ".", "double", "(", ")", "\n", "ve_product", "=", "torch", ".", "mm", "(", "v_mat", ",", "e_mat", ")", "\n", "b_mat", "=", "torch", ".", "add", "(", "v_mat", ",", "0.25", ",", "torch", ".", "mm", "(", "ve_product", ",", "torch", ".", "transpose", "(", "ve_product", ",", "0", ",", "1", ")", ")", ")", "\n", "left_mat", ",", "diag_mat", ",", "right_mat", "=", "torch", ".", "svd", "(", "b_mat", ")", "\n", "\n", "assert", "(", "torch", ".", "min", "(", "diag_mat", ")", ".", "item", "(", ")", ">", "0", ")", ",", "\"v_mat is singular!\"", "\n", "\n", "# L = B^{1/2}", "\n", "l_mat", "=", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "left_mat", ",", "torch", ".", "diagflat", "(", "torch", ".", "sqrt", "(", "diag_mat", ")", ")", ")", ",", "\n", "torch", ".", "transpose", "(", "right_mat", ",", "0", ",", "1", ")", ")", "\n", "inv_l_mat", "=", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "right_mat", ",", "torch", ".", "diagflat", "(", "torch", ".", "reciprocal", "(", "torch", ".", "sqrt", "(", "diag_mat", ")", ")", ")", ")", ",", "\n", "torch", ".", "transpose", "(", "left_mat", ",", "0", ",", "1", ")", ")", "\n", "# L^-1*V*E=S*Lambda*W^t (SVD)", "\n", "s_mat", ",", "lambda_mat", ",", "w_mat", "=", "torch", ".", "svd", "(", "torch", ".", "mm", "(", "inv_l_mat", ",", "ve_product", ")", ")", "\n", "# Q = S*W^t", "\n", "q_mat", "=", "torch", ".", "mm", "(", "s_mat", ",", "torch", ".", "transpose", "(", "w_mat", ",", "0", ",", "1", ")", ")", "\n", "# X = L*Q-(1/2)V*E", "\n", "x_mat", "=", "torch", ".", "add", "(", "torch", ".", "mm", "(", "l_mat", ",", "q_mat", ")", ",", "-", "1", "/", "2", ",", "ve_product", ")", "\n", "if", "print_norm_flag", ":", "\n", "        ", "mat", "=", "torch", ".", "add", "(", "torch", ".", "add", "(", "torch", ".", "mm", "(", "x_mat", ",", "torch", ".", "transpose", "(", "x_mat", ",", "0", ",", "1", ")", ")", ",", "\n", "torch", ".", "mm", "(", "ve_product", ",", "torch", ".", "transpose", "(", "x_mat", ",", "0", ",", "1", ")", ")", ")", ",", "-", "1", ",", "v_mat", ")", "\n", "mat_norm", "=", "torch", ".", "norm", "(", "mat", ")", "\n", "print", "(", "'The Frobenius norm of the matrix is'", ",", "mat_norm", ".", "item", "(", ")", ")", "\n", "", "return", "x_mat", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device": [[59, 67], ["enumerate", "tensor_lst[].to"], "function", ["None"], ["", "def", "lst_to_device", "(", "device", ",", "tensor_lst", ")", ":", "\n", "    ", "\"\"\"\n        :param device: device index to select.\n        :param tensor_lst: list of tensors\n        :return:\n    \"\"\"", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "tensor_lst", ")", ":", "\n", "        ", "tensor_lst", "[", "idx", "]", "=", "tensor_lst", "[", "idx", "]", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.weight_lst": [[69, 75], ["utils..parameters"], "function", ["None"], ["", "", "def", "weight_lst", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n        :param self.\n        :return: A list of iterators of the network parameters.\n    \"\"\"", "\n", "return", "[", "w", "for", "w", "in", "self", ".", "parameters", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.weight_grad": [[77, 93], ["range", "utils.lst_to_device", "len", "grad_mat_lst.append", "torch.cat", "torch.unsqueeze"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device"], ["", "def", "weight_grad", "(", "tensor_lst", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n        This function return a list of matrices containing the gradient of the network parameters for each layer.\n        :param tensor_lst: A list of iterators of the network parameters.\n        :param device: device index to select.\n        :return: grad_mat_lst: A list of matrices containing the gradients of the network parameters.\n    \"\"\"", "\n", "grad_mat_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tensor_lst", ")", ")", ":", "\n", "        ", "if", "i", "%", "2", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "grad_mat_lst", ".", "append", "(", "torch", ".", "cat", "(", "(", "tensor_lst", "[", "i", "]", ".", "grad", ".", "data", ",", "\n", "torch", ".", "unsqueeze", "(", "tensor_lst", "[", "i", "+", "1", "]", ".", "grad", ".", "data", ",", "1", ")", ")", ",", "1", ")", ")", "\n", "", "", "lst_to_device", "(", "device", ",", "grad_mat_lst", ")", "\n", "return", "grad_mat_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.init_param": [[95, 144], ["range", "utils.lst_to_device", "utils.lst_to_device", "utils.lst_to_device", "utils.lst_to_device", "utils.lst_to_device", "utils.lst_to_device", "utils.lst_to_device", "len", "w_mat_lst.append", "avg_psi_mat_lst.append", "e_a_mat_lst.append", "e_b_mat_lst.append", "torch.zeros", "torch.zeros", "m_mat_lst.append", "a_mat_lst.append", "b_mat_lst.append", "m_mat_lst.append", "a_mat_lst.append", "b_mat_lst.append", "torch.zeros", "torch.zeros", "torch.diagflat", "torch.diagflat", "torch.cat", "torch.diagflat", "torch.diagflat", "tensor_lst[].size", "tensor_lst[].size", "math.sqrt", "torch.randn_like", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size", "torch.cat", "math.sqrt", "torch.ones", "math.sqrt", "torch.ones", "torch.ones", "torch.ones", "tensor_lst[].size", "tensor_lst[].size", "math.sqrt", "math.sqrt", "math.sqrt", "torch.randn_like", "math.sqrt", "torch.randn_like", "torch.unsqueeze", "tensor_lst[].size", "torch.unsqueeze", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size", "tensor_lst[].size"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device"], ["", "def", "init_param", "(", "tensor_lst", ",", "s_init", ",", "device", ",", "use_custom_init", "=", "False", ",", "alpha", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n        :param tensor_lst: A list of iterators of the network parameters.\n        :param s_init: Init value of the diagonal of a and b.\n        :param device: device index to select.\n        :return: w_mat_lst: A list of matrices in size of P*N.\n        :return: m_mat_lst: A list of matrices in size of P*N.\n        :return: a_mat_lst: A list of matrices in size of N*N.\n        :return: b_mat_lst: A list of matrices in size of P*P.\n        :return: avg_psi_mat_lst: A list of matrices in size of P*N.\n        :return: e_a_mat_lst: A list of matrices in size of N*N.\n        :return: e_b_mat_lst: A list of matrices in size of P*P.\n    \"\"\"", "\n", "w_mat_lst", "=", "[", "]", "\n", "m_mat_lst", "=", "[", "]", "\n", "a_mat_lst", "=", "[", "]", "\n", "b_mat_lst", "=", "[", "]", "\n", "avg_psi_mat_lst", "=", "[", "]", "\n", "e_a_mat_lst", "=", "[", "]", "\n", "e_b_mat_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tensor_lst", ")", ")", ":", "\n", "        ", "if", "i", "%", "2", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "w_mat_lst", ".", "append", "(", "torch", ".", "zeros", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", ",", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "1", ")", ")", "\n", "avg_psi_mat_lst", ".", "append", "(", "torch", ".", "zeros", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", ",", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "1", ")", ")", "\n", "if", "use_custom_init", ":", "\n", "                ", "m_mat_lst", ".", "append", "(", "math", ".", "sqrt", "(", "(", "2.0", "*", "alpha", "/", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "2.0", ")", ")", ")", "*", "torch", ".", "randn_like", "(", "\n", "torch", ".", "cat", "(", "(", "tensor_lst", "[", "i", "]", ".", "data", ",", "torch", ".", "unsqueeze", "(", "tensor_lst", "[", "i", "+", "1", "]", ",", "1", ")", ")", ",", "1", ")", ",", "device", "=", "device", ")", ")", "\n", "a_mat_lst", ".", "append", "(", "torch", ".", "diagflat", "(", "math", ".", "sqrt", "(", "math", ".", "sqrt", "(", "(", "2.0", "*", "(", "1.0", "-", "alpha", ")", "/", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "2.0", ")", ")", ")", ")", "*", "torch", ".", "ones", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "1", ")", ")", ")", "\n", "b_mat_lst", ".", "append", "(", "torch", ".", "diagflat", "(", "math", ".", "sqrt", "(", "math", ".", "sqrt", "(", "(", "2.0", "*", "(", "1.0", "-", "alpha", ")", "/", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "2.0", ")", ")", ")", ")", "*", "torch", ".", "ones", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "# m_mat_lst.append(torch.cat((tensor_lst[i].data, torch.unsqueeze(tensor_lst[i + 1].data, 1)), 1))", "\n", "                ", "m_mat_lst", ".", "append", "(", "torch", ".", "cat", "(", "(", "math", ".", "sqrt", "(", "2.0", "/", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", "+", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", ")", ")", "*", "\n", "torch", ".", "randn_like", "(", "tensor_lst", "[", "i", "]", ".", "data", ",", "device", "=", "device", ")", ",", "\n", "math", ".", "sqrt", "(", "2.0", "/", "(", "1.0", "+", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", ")", ")", "*", "\n", "torch", ".", "randn_like", "(", "torch", ".", "unsqueeze", "(", "tensor_lst", "[", "i", "+", "1", "]", ".", "data", ",", "1", ")", ")", ")", ",", "1", ")", ")", "\n", "a_mat_lst", ".", "append", "(", "torch", ".", "diagflat", "(", "s_init", "*", "torch", ".", "ones", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "1", ")", ")", ")", "\n", "b_mat_lst", ".", "append", "(", "torch", ".", "diagflat", "(", "s_init", "*", "torch", ".", "ones", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", ")", ")", ")", "\n", "", "e_a_mat_lst", ".", "append", "(", "torch", ".", "zeros", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "1", ",", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "1", "]", "+", "1", ")", ")", "\n", "e_b_mat_lst", ".", "append", "(", "torch", ".", "zeros", "(", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", ",", "tensor_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", ")", ")", "\n", "", "", "lst_to_device", "(", "device", ",", "w_mat_lst", ")", "\n", "lst_to_device", "(", "device", ",", "avg_psi_mat_lst", ")", "\n", "lst_to_device", "(", "device", ",", "m_mat_lst", ")", "\n", "lst_to_device", "(", "device", ",", "a_mat_lst", ")", "\n", "lst_to_device", "(", "device", ",", "b_mat_lst", ")", "\n", "lst_to_device", "(", "device", ",", "e_a_mat_lst", ")", "\n", "lst_to_device", "(", "device", ",", "e_b_mat_lst", ")", "\n", "return", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "avg_psi_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.update_weight": [[146, 159], ["range", "len", "tensor_lst[].data.copy_", "tensor_lst[].data.copy_", "int", "int"], "function", ["None"], ["", "def", "update_weight", "(", "tensor_lst", ",", "w_mat_lst", ")", ":", "\n", "    ", "\"\"\"\n        This function update the parameters of the network.\n        :param tensor_lst: A list of iterators of the network parameters.\n        :param w_mat_lst: A list of matrices in size of P*N.\n        :return:\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "tensor_lst", ")", ")", ":", "\n", "        ", "if", "i", "%", "2", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "tensor_lst", "[", "i", "]", ".", "data", ".", "copy_", "(", "w_mat_lst", "[", "int", "(", "i", "/", "2", ")", "]", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "tensor_lst", "[", "i", "+", "1", "]", ".", "data", ".", "copy_", "(", "w_mat_lst", "[", "int", "(", "i", "/", "2", ")", "]", "[", ":", ",", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.gen_phi": [[161, 172], ["utils.lst_to_device", "phi_mat_lst.append", "torch.randn_like"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.lst_to_device"], ["", "", "", "def", "gen_phi", "(", "w_mat_lst", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n        :param w_mat_lst: A list of matrices in size of P*N.\n        :param device: device index to select.\n        :return phi_mat_lst: A list of normal random matrices in size of P*N.\n    \"\"\"", "\n", "phi_mat_lst", "=", "[", "]", "\n", "for", "i", "in", "w_mat_lst", ":", "\n", "        ", "phi_mat_lst", ".", "append", "(", "torch", ".", "randn_like", "(", "i", ",", "device", "=", "device", ")", ")", "\n", "", "lst_to_device", "(", "device", ",", "phi_mat_lst", ")", "\n", "return", "phi_mat_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.randomize_weights": [[174, 191], ["range", "utils.update_weight", "len", "w_mat_lst[].copy_", "torch.add", "torch.mm", "torch.mm", "torch.transpose"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.update_weight"], ["", "def", "randomize_weights", "(", "tensor_lst", ",", "w_mat_lst", ",", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", ":", "\n", "    ", "\"\"\"\n        This function generate a sample of normal random weights with mean M and covariance matrix of (A*A^t)\\otimes(B*B^t)\n        (\\otimes = kronecker product). In matrix form the update rule is W = M + B*Phi*A^t.\n        :param tensor_lst: A list of iterators of the network parameters.\n        :param w_mat_lst: m_mat_lst: A list of matrices in size of P*N.\n        :param m_mat_lst: m_mat_lst: A list of matrices in size of P*N.\n        :param a_mat_lst: A list of matrices in size of N*N.\n        :param b_mat_lst: A list of matrices in size of P*P.\n        :param phi_mat_lst: A list of normal random matrices in size of P*N.\n        :return:\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "w_mat_lst", ")", ")", ":", "\n", "# W = M + B*Phi*A^t", "\n", "        ", "w_mat_lst", "[", "i", "]", ".", "copy_", "(", "torch", ".", "add", "(", "m_mat_lst", "[", "i", "]", ",", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "b_mat_lst", "[", "i", "]", ",", "phi_mat_lst", "[", "i", "]", ")", ",", "\n", "torch", ".", "transpose", "(", "a_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", ")", ")", ")", "\n", "", "update_weight", "(", "tensor_lst", ",", "w_mat_lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.zero_grad": [[193, 202], ["i.grad.detach_", "i.grad.zero_"], "function", ["None"], ["", "def", "zero_grad", "(", "tensor_lst", ")", ":", "\n", "    ", "\"\"\"\n        :param tensor_lst: A list of iterators of the network parameters.\n        :return:\n    \"\"\"", "\n", "for", "i", "in", "tensor_lst", ":", "\n", "        ", "if", "i", ".", "grad", "is", "not", "None", ":", "\n", "            ", "i", ".", "grad", ".", "detach_", "(", ")", "\n", "i", ".", "grad", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.zero_matrix": [[204, 217], ["range", "range", "range", "len", "avg_psi_mat_lst[].copy_", "len", "e_a_mat_lst[].copy_", "len", "e_b_mat_lst[].copy_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["None"], ["", "", "", "def", "zero_matrix", "(", "avg_psi_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", ")", ":", "\n", "    ", "\"\"\"\n        :param avg_psi_mat_lst: A list of matrices in size of P*N.\n        :param e_a_mat_lst: A list of matrices in size of N*N.\n        :param e_b_mat_lst: A list of matrices in size of P*P.\n        :return:\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "avg_psi_mat_lst", ")", ")", ":", "\n", "        ", "avg_psi_mat_lst", "[", "i", "]", ".", "copy_", "(", "torch", ".", "zeros_like", "(", "avg_psi_mat_lst", "[", "i", "]", ")", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "e_a_mat_lst", ")", ")", ":", "\n", "        ", "e_a_mat_lst", "[", "i", "]", ".", "copy_", "(", "torch", ".", "zeros_like", "(", "e_a_mat_lst", "[", "i", "]", ")", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "e_b_mat_lst", ")", ")", ":", "\n", "        ", "e_b_mat_lst", "[", "i", "]", ".", "copy_", "(", "torch", ".", "zeros_like", "(", "e_b_mat_lst", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_grads": [[219, 229], ["range", "len", "avg_psi_mat_lst[].add_"], "function", ["None"], ["", "", "def", "aggregate_grads", "(", "args", ",", "avg_psi_mat_lst", ",", "grad_mat_list", ")", ":", "\n", "    ", "\"\"\"\n        This function estimate the expectation of the gradient using Monte Carlo average.\n        :param args: Training settings.\n        :param avg_psi_mat_lst: A list of matrices in size of P*N.\n        :param grad_mat_list: A list of matrices in size of P*N.\n        :return:\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "grad_mat_list", ")", ")", ":", "\n", "        ", "avg_psi_mat_lst", "[", "i", "]", ".", "add_", "(", "(", "1", "/", "args", ".", "train_mc_iters", ")", "*", "grad_mat_list", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_e_a": [[231, 244], ["range", "len", "e_a_mat_lst[].add_", "torch.mm", "torch.mm", "torch.transpose", "b_mat_lst[].size"], "function", ["None"], ["", "", "def", "aggregate_e_a", "(", "args", ",", "e_a_mat_lst", ",", "grad_mat_lst", ",", "b_mat_lst", ",", "phi_mat_lst", ")", ":", "\n", "    ", "\"\"\"\n        This function estimate the expectation of the e_a ((1/P)E(Psi^t*B*Phi)) using Monte Carlo average.\n        :param args: Training settings.\n        :param e_a_mat_lst: A list of matrices in size of N*N.\n        :param grad_mat_lst: A list of matrices in size of P*N.\n        :param b_mat_lst: A list of matrices in size of P*P.\n        :param phi_mat_lst: A list of normal random matrices in size of P*N.\n        :return:\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "grad_mat_lst", ")", ")", ":", "\n", "        ", "e_a_mat_lst", "[", "i", "]", ".", "add_", "(", "(", "1", "/", "(", "args", ".", "train_mc_iters", "*", "b_mat_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", ")", ")", "*", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "\n", "torch", ".", "transpose", "(", "grad_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", ",", "b_mat_lst", "[", "i", "]", ")", ",", "phi_mat_lst", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.aggregate_e_b": [[246, 259], ["range", "len", "e_b_mat_lst[].add_", "torch.mm", "torch.mm", "torch.transpose", "a_mat_lst[].size"], "function", ["None"], ["", "", "def", "aggregate_e_b", "(", "args", ",", "e_b_mat_lst", ",", "grad_mat_lst", ",", "a_mat_lst", ",", "phi_mat_lst", ")", ":", "\n", "    ", "\"\"\"\n        This function estimate the expectation of the e_b ((1/N)E(Phi^t*A*Psi)) using Monte Carlo average.\n        :param args: Training settings.\n        :param e_b_mat_lst: A list of matrices in size of P*P.\n        :param grad_mat_lst: A list of matrices in size of P*N.\n        :param a_mat_lst: A list of matrices in size of N*N.\n        :param phi_mat_lst: A list of normal random matrices in size of P*N\n        :return:\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "grad_mat_lst", ")", ")", ":", "\n", "        ", "e_b_mat_lst", "[", "i", "]", ".", "add_", "(", "(", "1", "/", "(", "args", ".", "train_mc_iters", "*", "a_mat_lst", "[", "i", "]", ".", "size", "(", ")", "[", "0", "]", ")", ")", "*", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "\n", "grad_mat_lst", "[", "i", "]", ",", "a_mat_lst", "[", "i", "]", ")", ",", "torch", ".", "transpose", "(", "phi_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.update_m": [[261, 287], ["range", "range", "len", "m_mat_lst[].copy_", "len", "m_mat_lst[].copy_", "torch.add", "torch.add", "torch.mm", "torch.mm", "torch.mm", "torch.diagflat", "torch.mm", "torch.mm", "torch.diagflat", "torch.diagonal", "torch.mm", "torch.transpose", "torch.diagonal", "torch.mm", "torch.transpose", "torch.mm", "torch.transpose", "torch.transpose"], "function", ["None"], ["", "", "def", "update_m", "(", "m_mat_lst", ",", "a_mat_lst", ",", "b_mat_lst", ",", "avg_psi_mat_lst", ",", "eta", "=", "1", ",", "diagonal", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n        This function updates the mean according to M = M - B*B^t*E[Psi]*A*A^t.\n        :param m_mat_lst: m_mat_lst: A list of matrices in size of P*N.\n        :param a_mat_lst: A list of matrices in size of N*N.\n        :param b_mat_lst: A list of matrices in size of P*P.\n        :param avg_psi_mat_lst: A list of matrices in size of P*N.\n        :param eta: .\n        :param diagonal: .\n        :return:\n    \"\"\"", "\n", "if", "diagonal", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "m_mat_lst", ")", ")", ":", "\n", "# M = M - diag(B*B^t)*E[Psi]*diag(A*A^t)", "\n", "            ", "m_mat_lst", "[", "i", "]", ".", "copy_", "(", "torch", ".", "add", "(", "m_mat_lst", "[", "i", "]", ",", "-", "eta", ",", "\n", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "torch", ".", "diagflat", "(", "torch", ".", "diagonal", "(", "torch", ".", "mm", "(", "b_mat_lst", "[", "i", "]", ",", "torch", ".", "transpose", "(", "b_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", ")", ")", ")", ",", "\n", "avg_psi_mat_lst", "[", "i", "]", ")", ",", "torch", ".", "diagflat", "(", "torch", ".", "diagonal", "(", "torch", ".", "mm", "(", "a_mat_lst", "[", "i", "]", ",", "\n", "torch", ".", "transpose", "(", "a_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", "\n", ")", ")", ")", ")", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "m_mat_lst", ")", ")", ":", "\n", "# M = M - B*B^t*E[Psi]*A*A^t", "\n", "            ", "m_mat_lst", "[", "i", "]", ".", "copy_", "(", "torch", ".", "add", "(", "m_mat_lst", "[", "i", "]", ",", "-", "eta", ",", "\n", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "b_mat_lst", "[", "i", "]", ",", "torch", ".", "transpose", "(", "b_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", ")", ",", "\n", "avg_psi_mat_lst", "[", "i", "]", ")", ",", "torch", ".", "mm", "(", "a_mat_lst", "[", "i", "]", ",", "\n", "torch", ".", "transpose", "(", "a_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", "\n", ")", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.update_a_b": [[290, 305], ["range", "len", "utils.solve_matrix_equation", "utils.solve_matrix_equation", "a_mat_lst[].copy_", "b_mat_lst[].copy_", "torch.mm", "torch.mm", "torch.transpose", "torch.transpose"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.solve_matrix_equation", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.solve_matrix_equation"], ["", "", "", "def", "update_a_b", "(", "a_mat_lst", ",", "b_mat_lst", ",", "e_a_mat_lst", ",", "e_b_mat_lst", ",", "device", ",", "use_gsvd", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n        This function updates the matrices A & B using a solution to the non-linear matrix equation\n        XX^{\\top}+VEX^{\\top}-V = 0.\n        :param a_mat_lst:\n        :param b_mat_lst:\n        :param e_a_mat_lst:\n        :param e_b_mat_lst:\n        :return:\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "a_mat_lst", ")", ")", ":", "\n", "        ", "a_temp", "=", "solve_matrix_equation", "(", "torch", ".", "mm", "(", "a_mat_lst", "[", "i", "]", ",", "torch", ".", "transpose", "(", "a_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", ")", ",", "e_a_mat_lst", "[", "i", "]", ")", "\n", "b_temp", "=", "solve_matrix_equation", "(", "torch", ".", "mm", "(", "b_mat_lst", "[", "i", "]", ",", "torch", ".", "transpose", "(", "b_mat_lst", "[", "i", "]", ",", "0", ",", "1", ")", ")", ",", "e_b_mat_lst", "[", "i", "]", ")", "\n", "a_mat_lst", "[", "i", "]", ".", "copy_", "(", "a_temp", ")", "\n", "b_mat_lst", "[", "i", "]", ".", "copy_", "(", "b_temp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.utils.set_seed": [[307, 315], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "", "def", "set_seed", "(", "seed", ",", "fully_deterministic", "=", "True", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "if", "fully_deterministic", ":", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.Permutation.__init__": [[59, 64], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "permute_idx", ",", "target_offset", ")", ":", "\n", "        ", "super", "(", "Permutation", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "permute_idx", "=", "permute_idx", "\n", "self", ".", "target_offset", "=", "target_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.Permutation.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.Permutation.__getitem__": [[68, 74], ["[].view.size", "[].view", "[].view.view"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "self", ".", "dataset", "[", "index", "]", "\n", "target", "=", "target", "+", "self", ".", "target_offset", "\n", "shape", "=", "img", ".", "size", "(", ")", "\n", "img", "=", "img", ".", "view", "(", "-", "1", ")", "[", "self", ".", "permute_idx", "]", ".", "view", "(", "shape", ")", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.DatasetsLoaders.__init__": [[77, 393], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.Compose", "torchvision.Compose", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "datasets._reduce_class", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "datasets._reduce_class", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "kwargs.get", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "kwargs.get", "datasets._reduce_class", "kwargs.get", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "kwargs.get", "datasets._reduce_class", "kwargs.get", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.Compose", "torchvision.Compose", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.Compose", "torchvision.Compose", "torchvision.datasets.SVHN", "torchvision.datasets.SVHN", "torchvision.datasets.SVHN", "torchvision.datasets.SVHN", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.SVHN", "torchvision.datasets.SVHN", "torchvision.datasets.SVHN", "torchvision.datasets.SVHN", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.Compose", "torchvision.Compose", "datasets.NOTMNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "datasets.NOTMNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.Compose", "torchvision.Compose", "len", "len", "kwargs.get", "range", "kwargs.get", "kwargs.get", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "range", "datasets.ContinuousMultinomialSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "datasets.Permutation", "kwargs.get", "range", "datasets.Permutation", "kwargs.get", "range", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "kwargs.get", "tasks_datasets.append", "tasks_samples_indices.append", "len", "datasets.Permutation", "test_loaders.append", "datasets._create_task_probs", "torch.zeros_like.add_", "torch.zeros_like.add_", "probs.div_", "tasks_probs_over_iterations_lst.append", "torchvision.RandomCrop", "torchvision.RandomCrop", "torchvision.RandomHorizontalFlip", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "kwargs.get", "kwargs.get", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "kwargs.get", "kwargs.get", "len", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "kwargs.get", "kwargs.get", "len", "torchvision.Pad", "torchvision.Pad", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.Pad", "torchvision.Pad", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "range", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "datasets.Permutation", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "kwargs.get", "torchvision.Pad", "torchvision.Pad", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.ToTensor", "torchvision.ToTensor", "len", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "range", "len"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._reduce_class", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._reduce_class", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._reduce_class", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._reduce_class", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._create_task_probs"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", "=", "4", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "dataset_name", "=", "dataset", "\n", "self", ".", "valid_loader", "=", "None", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "if", "self", ".", "num_workers", "is", "None", ":", "\n", "            ", "self", ".", "num_workers", "=", "4", "\n", "\n", "", "self", ".", "random_erasing", "=", "kwargs", ".", "get", "(", "\"random_erasing\"", ",", "False", ")", "\n", "self", ".", "reduce_classes", "=", "kwargs", ".", "get", "(", "\"reduce_classes\"", ",", "None", ")", "\n", "self", ".", "permute", "=", "kwargs", ".", "get", "(", "\"permute\"", ",", "False", ")", "\n", "self", ".", "target_offset", "=", "kwargs", ".", "get", "(", "\"target_offset\"", ",", "0", ")", "\n", "\n", "pin_memory", "=", "pin_memory", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "False", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "cifar10_mean", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", "\n", "cifar10_std", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", "\n", "cifar100_mean", "=", "(", "0.5070", ",", "0.4865", ",", "0.4409", ")", "\n", "cifar100_std", "=", "(", "0.2673", ",", "0.2564", ",", "0.2761", ")", "\n", "mnist_mean", "=", "[", "33.318421449829934", "]", "\n", "mnist_std", "=", "[", "78.56749083061408", "]", "\n", "fashionmnist_mean", "=", "[", "73.14654541015625", "]", "\n", "fashionmnist_std", "=", "[", "89.8732681274414", "]", "\n", "\n", "if", "dataset", "==", "\"CIFAR10\"", ":", "\n", "# CIFAR10:", "\n", "#   type               : uint8", "\n", "#   shape              : train_set.train_data.shape (50000, 32, 32, 3)", "\n", "#   test data shape    : (10000, 32, 32, 3)", "\n", "#   number of channels : 3", "\n", "#   Mean per channel   : train_set.train_data[:,:,:,0].mean() 125.306918046875", "\n", "#                        train_set.train_data[:,:,:,1].mean() 122.95039414062499", "\n", "#                        train_set.train_data[:,:,:,2].mean() 113.86538318359375", "\n", "#   Std per channel   :  train_set.train_data[:, :, :, 0].std() 62.993219278136884", "\n", "#                        train_set.train_data[:, :, :, 1].std() 62.088707640014213", "\n", "#                        train_set.train_data[:, :, :, 2].std() 66.704899640630913", "\n", "            ", "self", ".", "mean", "=", "cifar10_mean", "\n", "self", ".", "std", "=", "cifar10_std", "\n", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", ",", "\n", "]", ")", "\n", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "train_set", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform_train", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "\n", "self", ".", "test_set", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform_test", ")", "\n", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "test_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "", "if", "dataset", "==", "\"CIFAR100\"", ":", "\n", "# CIFAR100:", "\n", "#   type               : uint8", "\n", "#   shape              : train_set.train_data.shape (50000, 32, 32, 3)", "\n", "#   test data shape    : (10000, 32, 32, 3)", "\n", "#   number of channels : 3", "\n", "#   Mean per channel   : train_set.train_data[:,:,:,0].mean() 129.304165605/255=0.5070", "\n", "#                        train_set.train_data[:,:,:,1].mean() 124.069962695/255=0.4865", "\n", "#                        train_set.train_data[:,:,:,2].mean() 112.434050059/255=0.4409", "\n", "#   Std per channel   :  train_set.train_data[:, :, :, 0].std() 68.1702428992/255=0.2673", "\n", "#                        train_set.train_data[:, :, :, 1].std() 65.3918080439/255=0.2564", "\n", "#                        train_set.train_data[:, :, :, 2].std() 70.418370188/255=0.2761", "\n", "\n", "            ", "self", ".", "mean", "=", "cifar100_mean", "\n", "self", ".", "std", "=", "cifar100_std", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "]", ")", "\n", "\n", "self", ".", "train_set", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "_reduce_class", "(", "self", ".", "train_set", ",", "self", ".", "reduce_classes", ",", "train", "=", "True", ",", "\n", "preserve_label_space", "=", "kwargs", ".", "get", "(", "\"preserve_label_space\"", ")", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "\n", "self", ".", "test_set", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "_reduce_class", "(", "self", ".", "test_set", ",", "self", ".", "reduce_classes", ",", "train", "=", "False", ",", "\n", "preserve_label_space", "=", "kwargs", ".", "get", "(", "\"preserve_label_space\"", ")", ")", "\n", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "test_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "", "if", "dataset", "==", "\"MNIST\"", ":", "\n", "# MNIST:", "\n", "#   type               : torch.ByteTensor", "\n", "#   shape              : train_set.train_data.shape torch.Size([60000, 28, 28])", "\n", "#   test data shape    : [10000, 28, 28]", "\n", "#   number of channels : 1", "\n", "#   Mean per channel   : 33.318421449829934", "\n", "#   Std per channel    : 78.56749083061408", "\n", "\n", "# Transforms", "\n", "            ", "self", ".", "mean", "=", "mnist_mean", "\n", "self", ".", "std", "=", "mnist_std", "\n", "if", "kwargs", ".", "get", "(", "\"pad_to_32\"", ",", "False", ")", ":", "\n", "                ", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Pad", "(", "2", ",", "fill", "=", "0", ",", "padding_mode", "=", "'constant'", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.1000", ",", ")", ",", "std", "=", "(", "0.2752", ",", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", "]", ")", "\n", "\n", "# Create train set", "\n", "", "self", ".", "train_set", "=", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "if", "kwargs", ".", "get", "(", "\"permutation\"", ",", "False", ")", ":", "\n", "# Permute if permutation is provided", "\n", "                ", "self", ".", "train_set", "=", "Permutation", "(", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", ",", "\n", "kwargs", ".", "get", "(", "\"permutation\"", ",", "False", ")", ",", "self", ".", "target_offset", ")", "\n", "# Reduce classes if necessary", "\n", "", "_reduce_class", "(", "self", ".", "train_set", ",", "self", ".", "reduce_classes", ",", "train", "=", "True", ",", "\n", "preserve_label_space", "=", "kwargs", ".", "get", "(", "\"preserve_label_space\"", ")", ")", "\n", "# Remap labels", "\n", "if", "kwargs", ".", "get", "(", "\"labels_remapping\"", ",", "False", ")", ":", "\n", "                ", "labels_remapping", "=", "kwargs", ".", "get", "(", "\"labels_remapping\"", ",", "False", ")", "\n", "for", "lbl_idx", "in", "range", "(", "len", "(", "self", ".", "train_set", ".", "train_labels", ")", ")", ":", "\n", "                    ", "self", ".", "train_set", ".", "train_labels", "[", "lbl_idx", "]", "=", "labels_remapping", "[", "self", ".", "train_set", ".", "train_labels", "[", "lbl_idx", "]", "]", "\n", "\n", "", "", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "\n", "# Create test set", "\n", "self", ".", "test_set", "=", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "if", "kwargs", ".", "get", "(", "\"permutation\"", ",", "False", ")", ":", "\n", "# Permute if permutation is provided", "\n", "                ", "self", ".", "test_set", "=", "Permutation", "(", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", ",", "\n", "kwargs", ".", "get", "(", "\"permutation\"", ",", "False", ")", ",", "self", ".", "target_offset", ")", "\n", "# Reduce classes if necessary", "\n", "", "_reduce_class", "(", "self", ".", "test_set", ",", "self", ".", "reduce_classes", ",", "train", "=", "False", ",", "\n", "preserve_label_space", "=", "kwargs", ".", "get", "(", "\"preserve_label_space\"", ")", ")", "\n", "# Remap labels", "\n", "if", "kwargs", ".", "get", "(", "\"labels_remapping\"", ",", "False", ")", ":", "\n", "                ", "labels_remapping", "=", "kwargs", ".", "get", "(", "\"labels_remapping\"", ",", "False", ")", "\n", "for", "lbl_idx", "in", "range", "(", "len", "(", "self", ".", "test_set", ".", "test_labels", ")", ")", ":", "\n", "                    ", "self", ".", "test_set", ".", "test_labels", "[", "lbl_idx", "]", "=", "labels_remapping", "[", "self", ".", "test_set", ".", "test_labels", "[", "lbl_idx", "]", "]", "\n", "\n", "", "", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "test_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "", "if", "dataset", "==", "\"FashionMNIST\"", ":", "\n", "# MNIST:", "\n", "#   type               : torch.ByteTensor", "\n", "#   shape              : train_set.train_data.shape torch.Size([60000, 28, 28])", "\n", "#   test data shape    : [10000, 28, 28]", "\n", "#   number of channels : 1", "\n", "#   Mean per channel   : fm.train_data.type(torch.FloatTensor).mean() is 72.94035223214286", "\n", "#   Std per channel    : fm.train_data.type(torch.FloatTensor).std() is 90.0211833054075", "\n", "            ", "self", ".", "mean", "=", "fashionmnist_mean", "\n", "self", ".", "std", "=", "fashionmnist_std", "\n", "# transform = transforms.Compose(", "\n", "#     [transforms.ToTensor(),", "\n", "#      transforms.Normalize(self.mean, self.std)])", "\n", "# transform = transforms.Compose(", "\n", "#     [transforms.ToTensor()])", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Pad", "(", "2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "72.94035223214286", "/", "255", ",", ")", ",", "(", "90.0211833054075", "/", "255", ",", ")", ")", "]", ")", "\n", "\n", "\n", "\n", "self", ".", "train_set", "=", "torchvision", ".", "datasets", ".", "FashionMNIST", "(", "root", "=", "'./data/fmnist'", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "\n", "self", ".", "test_set", "=", "torchvision", ".", "datasets", ".", "FashionMNIST", "(", "root", "=", "'./data/fmnist'", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "test_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "", "if", "dataset", "==", "\"SVHN\"", ":", "\n", "# SVHN:", "\n", "#   type               : numpy.ndarray", "\n", "#   shape              : self.train_set.data.shape is (73257, 3, 32, 32)", "\n", "#   test data shape    : self.test_set.data.shape is (26032, 3, 32, 32)", "\n", "#   number of channels : 3", "\n", "#   Mean per channel   : sv.data.mean(axis=0).mean(axis=1).mean(axis=1) is array([111.60893668, 113.16127466, 120.56512767])", "\n", "#   Std per channel    : np.transpose(sv.data, (1, 0, 2, 3)).reshape(3,-1).std(axis=1) is array([50.49768174, 51.2589843 , 50.24421614])", "\n", "            ", "self", ".", "mean", "=", "mnist_mean", "\n", "self", ".", "std", "=", "mnist_std", "\n", "# transform = transforms.Compose(", "\n", "#     [transforms.ToTensor(),", "\n", "#      transforms.Normalize(self.mean, self.std)])", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "111.60893668", "/", "255", ",", "113.16127466", "/", "255", ",", "120.56512767", "/", "255", ")", ",", "(", "50.49768174", "/", "255", ",", "51.2589843", "/", "255", ",", "50.24421614", "/", "255", ")", ")", "]", ")", "\n", "\n", "\n", "\n", "self", ".", "train_set", "=", "torchvision", ".", "datasets", ".", "SVHN", "(", "root", "=", "'./data'", ",", "split", "=", "\"train\"", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "\n", "self", ".", "test_set", "=", "torchvision", ".", "datasets", ".", "SVHN", "(", "root", "=", "'./data'", ",", "split", "=", "\"test\"", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "test_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "", "if", "dataset", "==", "\"NOTMNIST\"", ":", "\n", "# MNIST:", "\n", "#   type               : torch.ByteTensor", "\n", "#   shape              : train_set.train_data.shape torch.Size([60000, 28, 28])", "\n", "#   test data shape    : [10000, 28, 28]", "\n", "#   number of channels : 1", "\n", "#   Mean per channel   : nm.train_data.type(torch.FloatTensor).mean() is 106.51712372448979", "\n", "#   Std per channel    : nm.train_data.type(torch.FloatTensor).std() is 115.76734631096612", "\n", "            ", "self", ".", "mean", "=", "mnist_mean", "\n", "self", ".", "std", "=", "mnist_std", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Pad", "(", "2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "106.51712372448979", "/", "255", ",", ")", ",", "(", "115.76734631096612", "/", "255", ",", ")", ")", "]", ")", "\n", "\n", "self", ".", "train_set", "=", "NOTMNIST", "(", "root", "=", "'./data/notmnist'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "\n", "self", ".", "test_set", "=", "NOTMNIST", "(", "root", "=", "'./data/notmnist'", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "test_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "", "if", "dataset", "==", "\"CONTPERMUTEDPADDEDMNIST\"", ":", "\n", "            ", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "]", ")", "\n", "'''\n            transform = transforms.Compose(\n                [transforms.Pad(2, fill=0, padding_mode='constant'),\n                 transforms.ToTensor(),\n                 transforms.Normalize(mean=(0.1000,), std=(0.2752,))])\n            '''", "\n", "\n", "# Original MNIST", "\n", "tasks_datasets", "=", "[", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "]", "\n", "tasks_samples_indices", "=", "[", "torch", ".", "tensor", "(", "range", "(", "len", "(", "tasks_datasets", "[", "0", "]", ")", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "]", "\n", "total_len", "=", "len", "(", "tasks_datasets", "[", "0", "]", ")", "\n", "test_loaders", "=", "[", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "pin_memory", "=", "pin_memory", ")", "]", "\n", "self", ".", "num_of_permutations", "=", "len", "(", "kwargs", ".", "get", "(", "\"all_permutation\"", ")", ")", "\n", "all_permutation", "=", "kwargs", ".", "get", "(", "\"all_permutation\"", ",", "None", ")", "\n", "for", "p_idx", "in", "range", "(", "self", ".", "num_of_permutations", ")", ":", "\n", "# Create permuation", "\n", "                ", "permutation", "=", "all_permutation", "[", "p_idx", "]", "\n", "\n", "# Add train set:", "\n", "tasks_datasets", ".", "append", "(", "Permutation", "(", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", ",", "\n", "permutation", ",", "target_offset", "=", "0", ")", ")", "\n", "\n", "tasks_samples_indices", ".", "append", "(", "torch", ".", "tensor", "(", "range", "(", "total_len", ",", "\n", "total_len", "+", "len", "(", "tasks_datasets", "[", "-", "1", "]", ")", "\n", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ")", "\n", "total_len", "+=", "len", "(", "tasks_datasets", "[", "-", "1", "]", ")", "\n", "# Add test set:", "\n", "test_set", "=", "Permutation", "(", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", ",", "\n", "permutation", ",", "self", ".", "target_offset", ")", "\n", "test_loaders", ".", "append", "(", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_set", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "pin_memory", "=", "pin_memory", ")", ")", "\n", "", "self", ".", "test_loader", "=", "test_loaders", "\n", "# Concat datasets", "\n", "total_iters", "=", "kwargs", ".", "get", "(", "\"total_iters\"", ",", "None", ")", "\n", "\n", "assert", "total_iters", "is", "not", "None", "\n", "beta", "=", "kwargs", ".", "get", "(", "\"contpermuted_beta\"", ",", "3", ")", "\n", "all_datasets", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "tasks_datasets", ")", "\n", "\n", "# Create probabilities of tasks over iterations", "\n", "self", ".", "tasks_probs_over_iterations", "=", "[", "_create_task_probs", "(", "total_iters", ",", "self", ".", "num_of_permutations", "+", "1", ",", "task_id", ",", "\n", "beta", "=", "beta", ")", "for", "task_id", "in", "\n", "range", "(", "self", ".", "num_of_permutations", "+", "1", ")", "]", "\n", "normalize_probs", "=", "torch", ".", "zeros_like", "(", "self", ".", "tasks_probs_over_iterations", "[", "0", "]", ")", "\n", "for", "probs", "in", "self", ".", "tasks_probs_over_iterations", ":", "\n", "                ", "normalize_probs", ".", "add_", "(", "probs", ")", "\n", "", "for", "probs", "in", "self", ".", "tasks_probs_over_iterations", ":", "\n", "                ", "probs", ".", "div_", "(", "normalize_probs", ")", "\n", "", "self", ".", "tasks_probs_over_iterations", "=", "torch", ".", "cat", "(", "self", ".", "tasks_probs_over_iterations", ")", ".", "view", "(", "-", "1", ",", "self", ".", "tasks_probs_over_iterations", "[", "0", "]", ".", "shape", "[", "0", "]", ")", "\n", "tasks_probs_over_iterations_lst", "=", "[", "]", "\n", "for", "col", "in", "range", "(", "self", ".", "tasks_probs_over_iterations", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "tasks_probs_over_iterations_lst", ".", "append", "(", "self", ".", "tasks_probs_over_iterations", "[", ":", ",", "col", "]", ")", "\n", "", "self", ".", "tasks_probs_over_iterations", "=", "tasks_probs_over_iterations_lst", "\n", "\n", "train_sampler", "=", "ContinuousMultinomialSampler", "(", "data_source", "=", "all_datasets", ",", "samples_in_batch", "=", "self", ".", "batch_size", ",", "\n", "tasks_samples_indices", "=", "tasks_samples_indices", ",", "\n", "tasks_probs_over_iterations", "=", "\n", "self", ".", "tasks_probs_over_iterations", ",", "\n", "num_of_batches", "=", "kwargs", ".", "get", "(", "\"iterations_per_virtual_epc\"", ",", "1", ")", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "all_datasets", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "sampler", "=", "train_sampler", ",", "pin_memory", "=", "pin_memory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ContinuousMultinomialSampler.__init__": [[407, 435], ["len", "all", "str", "ValueError", "len", "range", "isinstance", "isinstance", "str", "len", "type", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ",", "samples_in_batch", "=", "128", ",", "num_of_batches", "=", "69", ",", "tasks_samples_indices", "=", "None", ",", "\n", "tasks_probs_over_iterations", "=", "None", ")", ":", "\n", "        ", "self", ".", "data_source", "=", "data_source", "\n", "assert", "tasks_samples_indices", "is", "not", "None", ",", "\"Must provide tasks_samples_indices - a list of tensors,\"", "\"each item in the list corrosponds to a task, each item of the \"", "\"tensor corrosponds to index of sample of this task\"", "\n", "self", ".", "tasks_samples_indices", "=", "tasks_samples_indices", "\n", "self", ".", "num_of_tasks", "=", "len", "(", "self", ".", "tasks_samples_indices", ")", "\n", "assert", "tasks_probs_over_iterations", "is", "not", "None", ",", "\"Must provide tasks_probs_over_iterations - a list of \"", "\"probs per iteration\"", "\n", "assert", "all", "(", "[", "isinstance", "(", "probs", ",", "torch", ".", "Tensor", ")", "and", "len", "(", "probs", ")", "==", "self", ".", "num_of_tasks", "for", "\n", "probs", "in", "tasks_probs_over_iterations", "]", ")", ",", "\"All probs must be tensors of len\"", "+", "str", "(", "self", ".", "num_of_tasks", ")", "+", "\", first tensor type is \"", "+", "str", "(", "type", "(", "tasks_probs_over_iterations", "[", "0", "]", ")", ")", "+", "\", and \"", "\" len is \"", "+", "str", "(", "len", "(", "tasks_probs_over_iterations", "[", "0", "]", ")", ")", "\n", "self", ".", "tasks_probs_over_iterations", "=", "tasks_probs_over_iterations", "\n", "self", ".", "current_iteration", "=", "0", "\n", "\n", "self", ".", "samples_in_batch", "=", "samples_in_batch", "\n", "self", ".", "num_of_batches", "=", "num_of_batches", "\n", "\n", "# Create the samples_distribution_over_time", "\n", "self", ".", "samples_distribution_over_time", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_of_tasks", ")", "]", "\n", "self", ".", "iter_indices_per_iteration", "=", "[", "]", "\n", "\n", "if", "not", "isinstance", "(", "self", ".", "samples_in_batch", ",", "int", ")", "or", "self", ".", "samples_in_batch", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_samples should be a positive integeral \"", "\n", "\"value, but got num_samples={}\"", ".", "format", "(", "self", ".", "samples_in_batch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ContinuousMultinomialSampler.generate_iters_indices": [[436, 455], ["len", "range", "torch.distributions.categorical.Categorical().sample", "torch.distributions.categorical.Categorical().sample", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "datasets.ContinuousMultinomialSampler.iter_indices_per_iteration.append", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.cat.tolist", "torch.cat.tolist", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical", "datasets.ContinuousMultinomialSampler.samples_distribution_over_time[].append", "numpy.random.permutation", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "datasets.ContinuousMultinomialSampler.samples_distribution_over_time[].append", "len"], "methods", ["None"], ["", "", "def", "generate_iters_indices", "(", "self", ",", "num_of_iters", ")", ":", "\n", "        ", "from_iter", "=", "len", "(", "self", ".", "iter_indices_per_iteration", ")", "\n", "for", "iter_num", "in", "range", "(", "from_iter", ",", "from_iter", "+", "num_of_iters", ")", ":", "\n", "\n", "# Get random number of samples per task (according to iteration distribution)", "\n", "            ", "tsks", "=", "Categorical", "(", "probs", "=", "self", ".", "tasks_probs_over_iterations", "[", "iter_num", "]", ")", ".", "sample", "(", "torch", ".", "Size", "(", "[", "self", ".", "samples_in_batch", "]", ")", ")", "\n", "# Generate samples indices for iter_num", "\n", "iter_indices", "=", "torch", ".", "zeros", "(", "0", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "for", "task_idx", "in", "range", "(", "self", ".", "num_of_tasks", ")", ":", "\n", "                ", "if", "self", ".", "tasks_probs_over_iterations", "[", "iter_num", "]", "[", "task_idx", "]", ">", "0", ":", "\n", "                    ", "num_samples_from_task", "=", "(", "tsks", "==", "task_idx", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "samples_distribution_over_time", "[", "task_idx", "]", ".", "append", "(", "num_samples_from_task", ")", "\n", "# Randomize indices for each task (to allow creation of random task batch)", "\n", "tasks_inner_permute", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "tasks_samples_indices", "[", "task_idx", "]", ")", ")", "\n", "rand_indices_of_task", "=", "tasks_inner_permute", "[", ":", "num_samples_from_task", "]", "\n", "iter_indices", "=", "torch", ".", "cat", "(", "[", "iter_indices", ",", "self", ".", "tasks_samples_indices", "[", "task_idx", "]", "[", "rand_indices_of_task", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "samples_distribution_over_time", "[", "task_idx", "]", ".", "append", "(", "0", ")", "\n", "", "", "self", ".", "iter_indices_per_iteration", ".", "append", "(", "iter_indices", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ContinuousMultinomialSampler.__iter__": [[456, 460], ["datasets.ContinuousMultinomialSampler.generate_iters_indices", "iter"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ContinuousMultinomialSampler.generate_iters_indices"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "generate_iters_indices", "(", "self", ".", "num_of_batches", ")", "\n", "self", ".", "current_iteration", "+=", "self", ".", "num_of_batches", "\n", "return", "iter", "(", "[", "item", "for", "sublist", "in", "self", ".", "iter_indices_per_iteration", "[", "self", ".", "current_iteration", "-", "self", ".", "num_of_batches", ":", "self", ".", "current_iteration", "]", "for", "item", "in", "sublist", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ContinuousMultinomialSampler.__len__": [[461, 463], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples_in_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__init__": [[525, 544], ["os.path.expanduser", "datasets.NOTMNIST.download", "datasets.NOTMNIST._check_exists", "RuntimeError", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.download", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST._check_exists"], ["def", "__init__", "(", "self", ",", "root", ",", "train", "=", "True", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "download", "=", "False", ")", ":", "\n", "        ", "self", ".", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "self", ".", "train_data", ",", "self", ".", "train_labels", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "processed_folder", ",", "self", ".", "training_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "test_data", ",", "self", ".", "test_labels", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "processed_folder", ",", "self", ".", "test_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__getitem__": [[545, 568], ["PIL.Image.fromarray", "datasets.NOTMNIST.numpy", "datasets.NOTMNIST.transform", "datasets.NOTMNIST.target_transform"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "if", "self", ".", "train", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "train_data", "[", "index", "]", ",", "self", ".", "train_labels", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "test_data", "[", "index", "]", ",", "self", ".", "test_labels", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "", "img", "=", "Image", ".", "fromarray", "(", "img", ".", "numpy", "(", ")", ",", "mode", "=", "'L'", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__len__": [[569, 574], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "return", "len", "(", "self", ".", "train_data", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "test_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST._check_exists": [[575, 578], ["os.path.exists", "os.path.exists", "os.path.join", "os.path.join"], "methods", ["None"], ["", "", "def", "_check_exists", "(", "self", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "processed_folder", ",", "self", ".", "training_file", ")", ")", "and", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "processed_folder", ",", "self", ".", "test_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.download": [[579, 626], ["datasets.NOTMNIST._check_exists", "print", "print", "os.makedirs", "os.makedirs", "print", "urllib.request.urlopen", "os.path.join", "os.unlink", "datasets.NOTMNIST.read_image_file", "datasets.NOTMNIST.read_label_file", "datasets.NOTMNIST.read_image_file", "datasets.NOTMNIST.read_label_file", "open", "torch.save", "torch.save", "torch.save", "torch.save", "open", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "os.path.join", "url.rpartition", "open", "f.write", "open", "gzip.GzipFile", "out_f.write", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "urllib.request.urlopen.read", "os.path.join.replace", "zip_f.read"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST._check_exists", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.read_image_file", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.read_label_file", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.read_image_file", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.read_label_file"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "\"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"", "\n", "from", "six", ".", "moves", "import", "urllib", "\n", "import", "gzip", "\n", "\n", "if", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "# download files", "\n", "", "try", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "raw_folder", ")", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "processed_folder", ")", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "            ", "if", "e", ".", "errno", "==", "errno", ".", "EEXIST", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "for", "url", "in", "self", ".", "urls", ":", "\n", "            ", "print", "(", "'Downloading '", "+", "url", ")", "\n", "data", "=", "urllib", ".", "request", ".", "urlopen", "(", "url", ")", "\n", "filename", "=", "url", ".", "rpartition", "(", "'/'", ")", "[", "2", "]", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "raw_folder", ",", "filename", ")", "\n", "with", "open", "(", "file_path", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "data", ".", "read", "(", ")", ")", "\n", "", "with", "open", "(", "file_path", ".", "replace", "(", "'.gz'", ",", "''", ")", ",", "'wb'", ")", "as", "out_f", ",", "gzip", ".", "GzipFile", "(", "file_path", ")", "as", "zip_f", ":", "\n", "                ", "out_f", ".", "write", "(", "zip_f", ".", "read", "(", ")", ")", "\n", "", "os", ".", "unlink", "(", "file_path", ")", "\n", "\n", "# process and save as torch files", "\n", "", "print", "(", "'Processing...'", ")", "\n", "\n", "training_set", "=", "(", "\n", "self", ".", "read_image_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "raw_folder", ",", "'train-images-idx3-ubyte'", ")", ")", ",", "\n", "self", ".", "read_label_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "raw_folder", ",", "'train-labels-idx1-ubyte'", ")", ")", "\n", ")", "\n", "test_set", "=", "(", "\n", "self", ".", "read_image_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "raw_folder", ",", "'t10k-images-idx3-ubyte'", ")", ")", ",", "\n", "self", ".", "read_label_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "raw_folder", ",", "'t10k-labels-idx1-ubyte'", ")", ")", "\n", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "processed_folder", ",", "self", ".", "training_file", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "training_set", ",", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "processed_folder", ",", "self", ".", "test_file", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "test_set", ",", "f", ")", "\n", "\n", "", "print", "(", "'Done!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__repr__": [[627, 638], ["datasets.NOTMNIST.__len__", "datasets.NOTMNIST.transform.__repr__().replace", "datasets.NOTMNIST.target_transform.__repr__().replace", "datasets.NOTMNIST.transform.__repr__", "datasets.NOTMNIST.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__len__", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__repr__", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "tmp", "=", "'train'", "if", "self", ".", "train", "is", "True", "else", "'test'", "\n", "fmt_str", "+=", "'    Split: {}\\n'", ".", "format", "(", "tmp", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.get_int": [[639, 642], ["int", "codecs.encode"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_int", "(", "b", ")", ":", "\n", "        ", "return", "int", "(", "codecs", ".", "encode", "(", "b", ",", "'hex'", ")", ",", "16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.read_label_file": [[643, 650], ["open", "f.read", "datasets.NOTMNIST.get_int", "numpy.frombuffer", "torch.from_numpy().view().long", "torch.from_numpy().view().long", "torch.from_numpy().view().long", "torch.from_numpy().view().long", "datasets.NOTMNIST.get_int", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.get_int", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.get_int"], ["", "def", "read_label_file", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "f", ".", "read", "(", ")", "\n", "assert", "self", ".", "get_int", "(", "data", "[", ":", "4", "]", ")", "==", "2049", "\n", "length", "=", "self", ".", "get_int", "(", "data", "[", "4", ":", "8", "]", ")", "\n", "parsed", "=", "np", ".", "frombuffer", "(", "data", ",", "dtype", "=", "np", ".", "uint8", ",", "offset", "=", "8", ")", "\n", "return", "torch", ".", "from_numpy", "(", "parsed", ")", ".", "view", "(", "length", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.read_image_file": [[651, 661], ["open", "f.read", "datasets.NOTMNIST.get_int", "datasets.NOTMNIST.get_int", "datasets.NOTMNIST.get_int", "numpy.frombuffer", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "datasets.NOTMNIST.get_int", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.get_int", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.get_int", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.get_int", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.get_int"], ["", "", "def", "read_image_file", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "f", ".", "read", "(", ")", "\n", "assert", "self", ".", "get_int", "(", "data", "[", ":", "4", "]", ")", "==", "2051", "\n", "length", "=", "self", ".", "get_int", "(", "data", "[", "4", ":", "8", "]", ")", "\n", "num_rows", "=", "self", ".", "get_int", "(", "data", "[", "8", ":", "12", "]", ")", "\n", "num_cols", "=", "self", ".", "get_int", "(", "data", "[", "12", ":", "16", "]", ")", "\n", "images", "=", "[", "]", "\n", "parsed", "=", "np", ".", "frombuffer", "(", "data", ",", "dtype", "=", "np", ".", "uint8", ",", "offset", "=", "16", ")", "\n", "return", "torch", ".", "from_numpy", "(", "parsed", ")", ".", "view", "(", "length", ",", "num_rows", ",", "num_cols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._reduce_class": [[13, 53], ["zip", "new_class_idx.__len__", "type", "numpy.array", "type", "label.item", "torch.stack.append", "type", "torch.stack", "torch.stack"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.NOTMNIST.__len__"], ["def", "_reduce_class", "(", "set", ",", "classes", ",", "train", ",", "preserve_label_space", "=", "True", ")", ":", "\n", "    ", "if", "classes", "is", "None", ":", "\n", "        ", "return", "\n", "\n", "", "new_class_idx", "=", "{", "}", "\n", "for", "c", "in", "classes", ":", "\n", "        ", "new_class_idx", "[", "c", "]", "=", "new_class_idx", ".", "__len__", "(", ")", "\n", "\n", "", "new_data", "=", "[", "]", "\n", "new_labels", "=", "[", "]", "\n", "if", "train", ":", "\n", "        ", "all_data", "=", "set", ".", "train_data", "\n", "labels", "=", "set", ".", "train_labels", "\n", "", "else", ":", "\n", "        ", "all_data", "=", "set", ".", "test_data", "\n", "labels", "=", "set", ".", "test_labels", "\n", "\n", "", "for", "data", ",", "label", "in", "zip", "(", "all_data", ",", "labels", ")", ":", "\n", "        ", "if", "type", "(", "label", ")", "==", "int", ":", "\n", "            ", "label_val", "=", "label", "\n", "", "else", ":", "\n", "            ", "label_val", "=", "label", ".", "item", "(", ")", "\n", "", "if", "label_val", "in", "classes", ":", "\n", "            ", "new_data", ".", "append", "(", "data", ")", "\n", "if", "preserve_label_space", ":", "\n", "                ", "new_labels", "+=", "[", "label_val", "]", "\n", "", "else", ":", "\n", "                ", "new_labels", "+=", "[", "new_class_idx", "[", "label_val", "]", "]", "\n", "", "", "", "if", "type", "(", "new_data", "[", "0", "]", ")", "==", "np", ".", "ndarray", ":", "\n", "        ", "new_data", "=", "np", ".", "array", "(", "new_data", ")", "\n", "", "elif", "type", "(", "new_data", "[", "0", "]", ")", "==", "torch", ".", "Tensor", ":", "\n", "        ", "new_data", "=", "torch", ".", "stack", "(", "new_data", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "\"Reduce class not supported\"", "\n", "", "if", "train", ":", "\n", "        ", "set", ".", "train_data", "=", "new_data", "\n", "set", ".", "train_labels", "=", "new_labels", "\n", "", "else", ":", "\n", "        ", "set", ".", "test_data", "=", "new_data", "\n", "set", ".", "test_labels", "=", "new_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._get_linear_line": [[465, 469], ["torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "range"], "function", ["None"], ["", "", "def", "_get_linear_line", "(", "start", ",", "end", ",", "direction", "=", "\"up\"", ")", ":", "\n", "    ", "if", "direction", "==", "\"up\"", ":", "\n", "        ", "return", "torch", ".", "FloatTensor", "(", "[", "(", "i", "-", "start", ")", "/", "(", "end", "-", "start", ")", "for", "i", "in", "range", "(", "start", ",", "end", ")", "]", ")", "\n", "", "return", "torch", ".", "FloatTensor", "(", "[", "1", "-", "(", "(", "i", "-", "start", ")", "/", "(", "end", "-", "start", ")", ")", "for", "i", "in", "range", "(", "start", ",", "end", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._create_task_probs": [[471, 494], ["torch.zeros", "torch.zeros", "probs[].add_", "int", "int", "max", "int", "int", "min", "probs[].add_", "datasets._get_linear_line", "probs[].add_", "datasets._get_linear_line", "int", "int"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._get_linear_line", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets._get_linear_line"], ["", "def", "_create_task_probs", "(", "iters", ",", "tasks", ",", "task_id", ",", "beta", "=", "3", ")", ":", "\n", "    ", "if", "beta", "<=", "1", ":", "\n", "        ", "peak_start", "=", "int", "(", "(", "task_id", "/", "tasks", ")", "*", "iters", ")", "\n", "peak_end", "=", "int", "(", "(", "(", "task_id", "+", "1", ")", "/", "tasks", ")", "*", "iters", ")", "\n", "start", "=", "peak_start", "\n", "end", "=", "peak_end", "\n", "", "else", ":", "\n", "        ", "start", "=", "max", "(", "int", "(", "(", "(", "beta", "*", "task_id", "-", "1", ")", "*", "iters", ")", "/", "(", "beta", "*", "tasks", ")", ")", ",", "0", ")", "\n", "peak_start", "=", "int", "(", "(", "(", "beta", "*", "task_id", "+", "1", ")", "*", "iters", ")", "/", "(", "beta", "*", "tasks", ")", ")", "\n", "peak_end", "=", "int", "(", "(", "(", "beta", "*", "task_id", "+", "(", "beta", "-", "1", ")", ")", "*", "iters", ")", "/", "(", "beta", "*", "tasks", ")", ")", "\n", "end", "=", "min", "(", "int", "(", "(", "(", "beta", "*", "task_id", "+", "(", "beta", "+", "1", ")", ")", "*", "iters", ")", "/", "(", "beta", "*", "tasks", ")", ")", ",", "iters", ")", "\n", "\n", "", "probs", "=", "torch", ".", "zeros", "(", "iters", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "task_id", "==", "0", ":", "\n", "        ", "probs", "[", "start", ":", "peak_start", "]", ".", "add_", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "probs", "[", "start", ":", "peak_start", "]", "=", "_get_linear_line", "(", "start", ",", "peak_start", ",", "direction", "=", "\"up\"", ")", "\n", "", "probs", "[", "peak_start", ":", "peak_end", "]", ".", "add_", "(", "1", ")", "\n", "if", "task_id", "==", "tasks", "-", "1", ":", "\n", "        ", "probs", "[", "peak_end", ":", "end", "]", ".", "add_", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "probs", "[", "peak_end", ":", "end", "]", "=", "_get_linear_line", "(", "peak_end", ",", "end", ",", "direction", "=", "\"down\"", ")", "\n", "", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_mnist": [[668, 684], ["datasets.DatasetsLoaders", "kwargs.get", "kwargs.get", "kwargs.get"], "function", ["None"], ["", "", "", "def", "ds_mnist", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    MNIST dataset.\n    :param batch_size: batch size\n           num_workers: num of workers\n           pad_to_32: If true, will pad digits to size 32x32 and normalize to zero mean and unit variance.\n    :return: Tuple with two lists.\n             First list of the tuple is a list of 1 train loaders.\n             Second list of the tuple is a list of 1 test loaders.\n    \"\"\"", "\n", "dataset", "=", "[", "DatasetsLoaders", "(", "\"MNIST\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "\n", "pad_to_32", "=", "kwargs", ".", "get", "(", "\"pad_to_32\"", ",", "False", ")", ")", "]", "\n", "test_loaders", "=", "[", "ds", ".", "test_loader", "for", "ds", "in", "dataset", "]", "\n", "train_loaders", "=", "[", "ds", ".", "train_loader", "for", "ds", "in", "dataset", "]", "\n", "return", "train_loaders", ",", "test_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_split_mnist": [[686, 712], ["datasets.DatasetsLoaders", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "function", ["None"], ["", "def", "ds_split_mnist", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Split MNIST dataset. Consists of 5 tasks: digits 0 & 1, 2 & 3, 4 & 5, 6 & 7, and 8 & 9.\n    :param batch_size: batch size\n           num_workers: num of workers\n           pad_to_32: If true, will pad digits to size 32x32 and normalize to zero mean and unit variance.\n           separate_labels_space: If true, each task will have its own label space (e.g. 01, 23 etc.).\n                                  If false, all tasks will have label space of 0,1 only.\n    :return: Tuple with two lists.\n             First list of the tuple is a list of 5 train loaders, each loader is a task.\n             Second list of the tuple is a list of 5 test loaders, each loader is a task.\n    \"\"\"", "\n", "classes_lst", "=", "[", "\n", "[", "0", ",", "1", "]", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", "[", "4", ",", "5", "]", ",", "\n", "[", "6", ",", "7", "]", ",", "\n", "[", "8", ",", "9", "]", "\n", "]", "\n", "dataset", "=", "[", "DatasetsLoaders", "(", "\"MNIST\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "\n", "reduce_classes", "=", "cl", ",", "pad_to_32", "=", "kwargs", ".", "get", "(", "\"pad_to_32\"", ",", "False", ")", ",", "\n", "preserve_label_space", "=", "kwargs", ".", "get", "(", "\"separate_labels_space\"", ")", ")", "for", "cl", "in", "classes_lst", "]", "\n", "test_loaders", "=", "[", "ds", ".", "test_loader", "for", "ds", "in", "dataset", "]", "\n", "train_loaders", "=", "[", "ds", ".", "train_loader", "for", "ds", "in", "dataset", "]", "\n", "return", "train_loaders", ",", "test_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_padded_split_mnist": [[714, 719], ["datasets.ds_split_mnist"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_split_mnist"], ["", "def", "ds_padded_split_mnist", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Split MNIST dataset, padded to 32x32 pixels.\n    \"\"\"", "\n", "return", "ds_split_mnist", "(", "pad_to_32", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_split_mnist_offline": [[721, 729], ["kwargs.get", "datasets.ds_mnist", "datasets.ds_mnist", "range"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_mnist", "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_mnist"], ["", "def", "ds_split_mnist_offline", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Split MNIST dataset. Offline means that all tasks are mixed together.\n    \"\"\"", "\n", "if", "kwargs", ".", "get", "(", "\"separate_labels_space\"", ")", ":", "\n", "        ", "return", "ds_mnist", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "return", "ds_mnist", "(", "labels_remapping", "=", "{", "l", ":", "l", "%", "2", "for", "l", "in", "range", "(", "10", ")", "}", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_padded_split_mnist_offline": [[731, 736], ["datasets.ds_split_mnist_offline"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_split_mnist_offline"], ["", "", "def", "ds_padded_split_mnist_offline", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Split MNIST dataset. Padded to 32x32. Offline means that all tasks are mixed together.\n    \"\"\"", "\n", "return", "ds_split_mnist_offline", "(", "pad_to_32", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_permuted_mnist": [[738, 782], ["kwargs.get", "range", "kwargs.get", "datasets.DatasetsLoaders", "len", "kwargs.get", "dataset.append", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "datasets.DatasetsLoaders", "train_sets.append", "test_sets.append", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "function", ["None"], ["", "def", "ds_permuted_mnist", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Permuted MNIST dataset.\n    First task is the MNIST datasets (with 10 possible labels).\n    Other tasks are permutations (pixel-wise) of the MNIST datasets (with 10 possible labels).\n    :param batch_size: batch size\n           num_workers: num of workers\n           pad_to_32: If true, will pad digits to size 32x32 and normalize to zero mean and unit variance.\n           permutations: A list of permutations. Each permutation should be a list containing new pixel position.\n           separate_labels_space: True for seperated labels space - task i labels will be (10*i) to (10*i + 9).\n                                  False for unified labels space - all tasks will have labels of 0 to 9.\n    :return: Tuple with two lists.\n             First list of the tuple is a list of train loaders, each loader is a task.\n             Second list of the tuple is a list of test loaders, each loader is a task.\n    \"\"\"", "\n", "# First task", "\n", "dataset", "=", "[", "DatasetsLoaders", "(", "\"MNIST\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "pad_to_32", "=", "kwargs", ".", "get", "(", "\"pad_to_32\"", ",", "False", ")", ")", "]", "\n", "target_offset", "=", "0", "\n", "permutations", "=", "kwargs", ".", "get", "(", "\"permutations\"", ",", "[", "]", ")", "\n", "for", "pidx", "in", "range", "(", "len", "(", "permutations", ")", ")", ":", "\n", "        ", "if", "kwargs", ".", "get", "(", "\"separate_labels_space\"", ")", ":", "\n", "            ", "target_offset", "=", "(", "pidx", "+", "1", ")", "*", "10", "\n", "", "dataset", ".", "append", "(", "DatasetsLoaders", "(", "\"MNIST\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "\n", "permutation", "=", "permutations", "[", "pidx", "]", ",", "target_offset", "=", "target_offset", ",", "\n", "pad_to_32", "=", "kwargs", ".", "get", "(", "\"pad_to_32\"", ",", "False", ")", ")", ")", "\n", "# For offline permuted we take the datasets and mix them.", "\n", "", "if", "kwargs", ".", "get", "(", "\"offline\"", ",", "False", ")", ":", "\n", "        ", "train_sets", "=", "[", "]", "\n", "test_sets", "=", "[", "]", "\n", "for", "ds", "in", "dataset", ":", "\n", "            ", "train_sets", ".", "append", "(", "ds", ".", "train_set", ")", "\n", "test_sets", ".", "append", "(", "ds", ".", "test_set", ")", "\n", "", "train_set", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "train_sets", ")", "\n", "test_set", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "test_sets", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_set", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "pin_memory", "=", "True", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_set", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "pin_memory", "=", "True", ")", "\n", "return", "[", "train_loader", "]", ",", "[", "test_loader", "]", "\n", "", "test_loaders", "=", "[", "ds", ".", "test_loader", "for", "ds", "in", "dataset", "]", "\n", "train_loaders", "=", "[", "ds", ".", "train_loader", "for", "ds", "in", "dataset", "]", "\n", "return", "train_loaders", ",", "test_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_padded_permuted_mnist": [[784, 789], ["datasets.ds_permuted_mnist"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_permuted_mnist"], ["", "def", "ds_padded_permuted_mnist", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Permuted MNIST dataset, padded to 32x32.\n    \"\"\"", "\n", "return", "ds_permuted_mnist", "(", "pad_to_32", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_permuted_mnist_offline": [[791, 796], ["datasets.ds_permuted_mnist"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_permuted_mnist"], ["", "def", "ds_permuted_mnist_offline", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Permuted MNIST dataset. Offline means that all tasks are mixed together.\n    \"\"\"", "\n", "return", "ds_permuted_mnist", "(", "offline", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_padded_permuted_mnist_offline": [[798, 803], ["datasets.ds_permuted_mnist"], "function", ["home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_permuted_mnist"], ["", "def", "ds_padded_permuted_mnist_offline", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Permuted MNIST dataset, padded to 32x32. Offline means that all tasks are mixed together.\n    \"\"\"", "\n", "return", "ds_permuted_mnist", "(", "pad_to_32", "=", "True", ",", "offline", "=", "True", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_padded_cont_permuted_mnist": [[805, 830], ["datasets.DatasetsLoaders", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "function", ["None"], ["", "def", "ds_padded_cont_permuted_mnist", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Continuous Permuted MNIST dataset, padded to 32x32.\n    :param num_epochs: Number of epochs for the training (since it builds distribution over iterations,\n                            it needs this information in advance)\n    :param iterations_per_virtual_epc: In continuous task-agnostic learning, the notion of epoch does not exists,\n                                        since we cannot define 'passing over the whole dataset'. Therefore,\n                                        we define \"iterations_per_virtual_epc\" -\n                                        how many iterations consist a single epoch.\n    :param contpermuted_beta: The proportion in which the tasks overlap. 4 means that 1/4 of a task duration will\n                                consist of data from previous/next task. Larger values means less overlapping.\n    :param permutations: The permutations which will be used (first task is always the original MNIST).\n    :param batch_size: Batch size.\n    :param num_workers: Num workers.\n    \"\"\"", "\n", "dataset", "=", "[", "DatasetsLoaders", "(", "\"CONTPERMUTEDPADDEDMNIST\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "\n", "total_iters", "=", "(", "kwargs", ".", "get", "(", "\"num_epochs\"", ")", "*", "kwargs", ".", "get", "(", "\"iterations_per_virtual_epc\"", ")", ")", ",", "\n", "contpermuted_beta", "=", "kwargs", ".", "get", "(", "\"contpermuted_beta\"", ")", ",", "\n", "iterations_per_virtual_epc", "=", "kwargs", ".", "get", "(", "\"iterations_per_virtual_epc\"", ")", ",", "\n", "all_permutation", "=", "kwargs", ".", "get", "(", "\"permutations\"", ",", "[", "]", ")", ")", "]", "\n", "test_loaders", "=", "[", "tloader", "for", "ds", "in", "dataset", "for", "tloader", "in", "ds", ".", "test_loader", "]", "\n", "train_loaders", "=", "[", "ds", ".", "train_loader", "for", "ds", "in", "dataset", "]", "\n", "\n", "return", "train_loaders", ",", "test_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_visionmix": [[832, 849], ["datasets.DatasetsLoaders", "datasets.DatasetsLoaders", "datasets.DatasetsLoaders", "datasets.DatasetsLoaders", "datasets.DatasetsLoaders", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "function", ["None"], ["", "def", "ds_visionmix", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Vision mix dataset. Consists of: MNIST, notMNIST, FashionMNIST, SVHN and CIFAR10.\n    \"\"\"", "\n", "dataset", "=", "[", "DatasetsLoaders", "(", "\"MNIST\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "pad_to_32", "=", "True", ")", ",", "\n", "DatasetsLoaders", "(", "\"NOTMNIST\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ")", ",", "\n", "DatasetsLoaders", "(", "\"FashionMNIST\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ")", ",", "\n", "DatasetsLoaders", "(", "\"SVHN\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ")", ",", "\n", "DatasetsLoaders", "(", "\"CIFAR10\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ")", "]", "\n", "test_loaders", "=", "[", "ds", ".", "test_loader", "for", "ds", "in", "dataset", "]", "\n", "train_loaders", "=", "[", "ds", ".", "train_loader", "for", "ds", "in", "dataset", "]", "\n", "return", "train_loaders", ",", "test_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_cifar10and100": [[851, 867], ["datasets.DatasetsLoaders", "range", "datasets.DatasetsLoaders", "range", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "function", ["None"], ["", "def", "ds_cifar10and100", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    CIFAR10 and CIFAR100 dataset. Consists of 6 tasks:\n        1) CIFAR10\n        2-6) Subsets of 10 classes from CIFAR100.\n    \"\"\"", "\n", "classes_lst", "=", "[", "[", "j", "for", "j", "in", "range", "(", "i", "*", "10", ",", "(", "i", "+", "1", ")", "*", "10", ")", "]", "for", "i", "in", "range", "(", "0", ",", "5", ")", "]", "\n", "dataset", "=", "[", "DatasetsLoaders", "(", "\"CIFAR100\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "\n", "reduce_classes", "=", "cl", ",", "preserve_label_space", "=", "False", ")", "for", "cl", "in", "classes_lst", "]", "\n", "dataset", "=", "[", "DatasetsLoaders", "(", "\"CIFAR10\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ",", "preserve_label_space", "=", "False", ")", "]", "+", "dataset", "\n", "\n", "test_loaders", "=", "[", "ds", ".", "test_loader", "for", "ds", "in", "dataset", "]", "\n", "train_loaders", "=", "[", "ds", ".", "train_loader", "for", "ds", "in", "dataset", "]", "\n", "return", "train_loaders", ",", "test_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.chenzeno_FOO-VB.None.datasets.ds_cifar10": [[869, 879], ["datasets.DatasetsLoaders", "kwargs.get", "kwargs.get"], "function", ["None"], ["", "def", "ds_cifar10", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    CIFAR10 dataset. No tasks.\n    \"\"\"", "\n", "dataset", "=", "[", "DatasetsLoaders", "(", "\"CIFAR10\"", ",", "batch_size", "=", "kwargs", ".", "get", "(", "\"batch_size\"", ",", "128", ")", ",", "\n", "num_workers", "=", "kwargs", ".", "get", "(", "\"num_workers\"", ",", "1", ")", ")", "]", "\n", "\n", "test_loaders", "=", "[", "ds", ".", "test_loader", "for", "ds", "in", "dataset", "]", "\n", "train_loaders", "=", "[", "ds", ".", "train_loader", "for", "ds", "in", "dataset", "]", "\n", "return", "train_loaders", ",", "test_loaders", "", "", ""]]}