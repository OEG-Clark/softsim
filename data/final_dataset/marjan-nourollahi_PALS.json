{"home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.My_Active_Learning.load_data": [[17, 32], ["dataset.load_data", "print", "numpy.random.RandomState", "numpy.arange", "print", "print", "print", "np.random.RandomState.shuffle", "collections.Counter", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data"], ["def", "load_data", "(", ")", ":", "\n", "    ", "sensor_data", "=", "dataset", ".", "load_data", "(", ")", "\n", "X1", ",", "y1", "=", "sensor_data", ".", "data", "[", ":", "6000", "]", ",", "sensor_data", ".", "target", "[", ":", "6000", "]", "\n", "print", "(", "Counter", "(", "y1", ")", ")", "\n", "\n", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "X1", ")", ")", "\n", "print", "(", "len", "(", "sensor_data", ".", "data", "[", ":", "]", ")", ")", "\n", "print", "(", "'*'", "*", "20", ")", "\n", "print", "(", "len", "(", "indices", ")", ")", "\n", "rng", ".", "shuffle", "(", "indices", ")", "\n", "\n", "X", ",", "y", "=", "X1", "[", "indices", "]", ",", "y1", "[", "indices", "]", "\n", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.My_Active_Learning.PAL": [[35, 217], ["len", "print", "print", "print", "range", "len", "numpy.arange", "imblearn.over_sampling.ADASYN", "numpy.setdiff1d", "imblearn.over_sampling.ADASYN.fit_sample", "numpy.copy", "label_propagation.LabelSpreading.fit", "numpy.arange", "label_propagation.LabelSpreading.predict", "sklearn.metrics.confusion_matrix", "print", "print", "print", "print", "print", "print", "f_result.append", "acc_result.append", "recall_result.append", "method", "numpy.array", "numpy.delete", "len", "open", "numpy.savetxt", "open", "numpy.savetxt", "open", "numpy.savetxt", "len", "print", "numpy.arange", "sklearn.semi_supervised.label_propagation.LabelSpreading", "sklearn.semi_supervised.label_propagation.LabelSpreading", "numpy.concatenate", "numpy.concatenate", "len", "sklearn.metrics.classification_report", "sklearn.metrics.accuracy_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "sklearn.metrics.recall_score", "numpy.where", "numpy.concatenate", "len"], "function", ["None"], ["", "def", "PAL", "(", "X", ",", "y", ",", "method", ",", "file_name", "=", "'PAL'", ",", "use_default_lp_setting", "=", "True", ",", "d", "=", "None", ")", ":", "\n", "\n", "    ", "n_total_samples", "=", "len", "(", "y", ")", "#+ len(y_test)", "\n", "print", "(", "'#'", "*", "70", ")", "\n", "print", "(", "len", "(", "y", ")", ")", "\n", "print", "(", "'#'", "*", "70", ")", "\n", "n_labeled_points", "=", "200", "\n", "max_iterations", "=", "50", "\n", "f_result", "=", "[", "]", "\n", "acc_result", "=", "[", "]", "\n", "recall_result", "=", "[", "]", "\n", "\n", "# all_y = np.concatenate((y, y_test), axis=0)", "\n", "# all_X = np.concatenate((X, X_test), axis=0)", "\n", "#", "\n", "# print(Counter(y_test))", "\n", "\n", "unlabeled_indices", "=", "np", ".", "arange", "(", "n_total_samples", ")", "[", "n_labeled_points", ":", "]", "\n", "\n", "for", "i", "in", "range", "(", "max_iterations", ")", ":", "\n", "        ", "if", "len", "(", "unlabeled_indices", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"No unlabeled items left to label.\"", ")", "\n", "break", "\n", "\n", "", "sm", "=", "ADASYN", "(", "random_state", "=", "42", ")", "\n", "mask", "=", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "len", "(", "X", ")", ")", ",", "unlabeled_indices", ")", "\n", "X_res", ",", "y_res", "=", "sm", ".", "fit_sample", "(", "X", "[", "mask", "]", ",", "y", "[", "mask", "]", ")", "\n", "y_unlabeled", "=", "np", ".", "copy", "(", "y", "[", "unlabeled_indices", "]", ")", "\n", "y_unlabeled", "[", ":", "]", "=", "-", "1", "\n", "X_unlabeled", "=", "X", "[", "unlabeled_indices", "]", "\n", "# y_train = np.copy(y[unlabeled_indices])#all_y)", "\n", "# y_train[:] = -1", "\n", "# y_train_2 = np.copy(y_test)", "\n", "# y_train_2[:] = -1", "\n", "# y_unlabeled = np.concatenate((y_train, y_train_2), axis=0)", "\n", "\n", "# h = np.setdiff1d(np.arange(n_total_samples), unlabeled_indices, assume_unique=True)", "\n", "\n", "if", "use_default_lp_setting", ":", "\n", "            ", "lp_model", "=", "label_propagation", ".", "LabelSpreading", "(", "kernel", "=", "'knn'", ",", "n_neighbors", "=", "10", ")", "\n", "", "else", ":", "\n", "            ", "lp_model", "=", "label_propagation", ".", "LabelSpreading", "(", "**", "d", ")", "\n", "\n", "\n", "", "y_f", ",", "X_f", "=", "np", ".", "concatenate", "(", "(", "y_res", ",", "y_unlabeled", ")", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "(", "X_res", ",", "X_unlabeled", ")", ",", "axis", "=", "0", ")", "\n", "\n", "\n", "lp_model", ".", "fit", "(", "X_f", ",", "y_f", ")", "\n", "########$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$", "\n", "# model = QuadraticDiscriminantAnalysis()", "\n", "# model.fit(X[mask], y[mask])", "\n", "# QD_predicted = model.predict(X[unlabeled_indices])", "\n", "\n", "########$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$4444", "\n", "\n", "ind", "=", "np", ".", "arange", "(", "len", "(", "X_f", ")", ")", "\n", "# predicted_labels = lp_model.transduction_[ind[ind >= len(X_res)]]", "\n", "lp_predicted", "=", "lp_model", ".", "predict", "(", "X", "[", "unlabeled_indices", "]", ")", "\n", "\n", "true_labels", "=", "y", "[", "unlabeled_indices", "]", "#[unlabeled_indices > 4000]", "\n", "\n", "predicted_labels", "=", "lp_predicted", "\n", "\n", "cm", "=", "confusion_matrix", "(", "true_labels", ",", "predicted_labels", ",", "\n", "labels", "=", "lp_model", ".", "classes_", ")", "\n", "\n", "print", "(", "\"Iteration %i %s\"", "%", "(", "i", ",", "70", "*", "\"_\"", ")", ")", "\n", "print", "(", "\"Label Spreading model: %d labeled & %d unlabeled (%d total)\"", "\n", "%", "(", "n_labeled_points", ",", "n_total_samples", "-", "n_labeled_points", ",", "\n", "n_total_samples", ")", ")", "\n", "\n", "print", "(", "classification_report", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "print", "(", "accuracy_score", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "print", "(", "\"Confusion matrix\"", ")", "\n", "print", "(", "cm", ")", "\n", "####################################  End Prints   ##############################################", "\n", "\n", "f_result", ".", "append", "(", "f1_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'binary'", ")", ")", "\n", "acc_result", ".", "append", "(", "accuracy_score", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "recall_result", ".", "append", "(", "recall_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'macro'", ")", ")", "\n", "\n", "uncertainty_index", "=", "method", "(", "lp_model", ",", "X", ",", "unlabeled_indices", ")", "\n", "\n", "# keep track of indices that we get labels for", "\n", "delete_indices", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "eating_counter", "=", "0", "\n", "non_eating_counter", "=", "0", "\n", "\n", "for", "index", "in", "uncertainty_index", ":", "\n", "\n", "            ", "delete_index", ",", "=", "np", ".", "where", "(", "unlabeled_indices", "==", "index", ")", "\n", "delete_indices", "=", "np", ".", "concatenate", "(", "(", "delete_indices", ",", "delete_index", ")", ")", "\n", "", "unlabeled_indices", "=", "np", ".", "delete", "(", "unlabeled_indices", ",", "delete_indices", ")", "\n", "n_labeled_points", "+=", "len", "(", "delete_indices", ")", "\n", "\n", "###################################AUC-ROC##############################################", "\n", "# Compute ROC curve and ROC area for each class", "\n", "# p = lp_model.predict_proba(X[unlabeled_indices])", "\n", "# from collections import Counter", "\n", "# print(max(p[:, 1]))", "\n", "# print(min(p[:, 1]))", "\n", "# prob= [round(x, 4) for x in p[:,1]]", "\n", "# print(max(prob))", "\n", "# print(min(prob))", "\n", "# not_nan_index = []", "\n", "#", "\n", "# for i, item in enumerate(prob):", "\n", "#     if np.isfinite(item):", "\n", "#         not_nan_index.append(i)", "\n", "#", "\n", "# true_label = y[unlabeled_indices]  # [unlabeled_indices > 4000]", "\n", "# true_label = true_label[not_nan_index]", "\n", "# prob = p[:,1][not_nan_index]", "\n", "#", "\n", "#", "\n", "# fpr, tpr, xxx = roc_curve(true_label, prob)", "\n", "# fpr = fpr[1:]", "\n", "# tpr = tpr[1:]", "\n", "# xxx = xxx[1:]", "\n", "#", "\n", "# roc_auc = auc(fpr, tpr)", "\n", "\n", "# Compute micro-average ROC curve and ROC area", "\n", "\n", "##############################################################################", "\n", "# # Plot of a ROC curve for a specific class", "\n", "# fig =plt.figure()", "\n", "# lw = 2", "\n", "# plt.plot(fpr, tpr, color='darkorange',", "\n", "#          lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)", "\n", "# plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')", "\n", "# plt.plot([0, 1], [0.5, 0.5], markeredgecolor='b', linestyle='dashed', color='b')", "\n", "# plt.plot([0, 1], [0.52, 0.52], color='navy', lw=lw, linestyle='--')", "\n", "# plt.plot([0.5, 0.5], [0, 1], color='navy', lw=lw, linestyle='--')", "\n", "\n", "# plt.xlim([0.0, 1.0])", "\n", "# plt.ylim([0.0, 1.05])", "\n", "# plt.xlabel('False Positive Rate')", "\n", "# plt.ylabel('True Positive Rate')", "\n", "# plt.title('ROC')", "\n", "# plt.legend(loc=\"lower right\")", "\n", "# ax2 = plt.gca().twinx()", "\n", "# ax2.plot(fpr, xxx, markeredgecolor='r', linestyle='dashed', color='r')", "\n", "# ax2.set_ylabel('Threshold', color='r')", "\n", "# # ax2.set_ylim([xxx[-1], xxx[0]])", "\n", "# ax2.set_ylim([0.0, 1.05])", "\n", "# ax2.set_xlim([fpr[0], fpr[-1]])", "\n", "#", "\n", "# plt.show()", "\n", "#", "\n", "\n", "#############################################################################################", "\n", "# p = lp_model.predict_proba(X[unlabeled_indices])", "\n", "# true_label = y[unlabeled_indices]  # [unlabeled_indices > 4000]", "\n", "# predicted_labels=lp_model.predict(X[unlabeled_indices])", "\n", "# print('+'*70)", "\n", "# print(classification_report(true_label, predicted_labels))", "\n", "# predicted_labels2 = [1 if x>0.57 else 0 for x in p[:, 1]]", "\n", "# cm = confusion_matrix(true_label, predicted_labels,", "\n", "#                       labels=lp_model.classes_)", "\n", "# print(cm)", "\n", "#", "\n", "# print('+' * 70)", "\n", "# print(classification_report(true_label, predicted_labels2))", "\n", "# cm = confusion_matrix(true_label, predicted_labels2,", "\n", "#                       labels=lp_model.classes_)", "\n", "# print(cm)", "\n", "# print('+' * 70)", "\n", "# print(sum([1 if x>1.00  else 0 for x in xxx]))", "\n", "# ts_method(lp_model)", "\n", "####################################   Prints   #################################################", "\n", "\n", "\n", "", "with", "open", "(", "\"f1_score_\"", "+", "file_name", "+", "\".csv\"", ",", "'wb'", ")", "as", "f_file", ":", "\n", "        ", "np", ".", "savetxt", "(", "f_file", ",", "f_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "\n", "", "with", "open", "(", "\"accuracy_score_\"", "+", "file_name", "+", "\".csv\"", ",", "'wb'", ")", "as", "acc_file", ":", "\n", "        ", "np", ".", "savetxt", "(", "acc_file", ",", "acc_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "\n", "\n", "", "with", "open", "(", "\"recall_score_\"", "+", "file_name", "+", "\".csv\"", ",", "'wb'", ")", "as", "recall_file", ":", "\n", "        ", "np", ".", "savetxt", "(", "recall_file", ",", "recall_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.My_Active_Learning.entropy_method": [[223, 233], ["mdl.predict_proba", "numpy.argsort", "scipy.stats.distributions.entropy", "numpy.in1d"], "function", ["None"], ["", "", "def", "entropy_method", "(", "mdl", ",", "X", ",", "unlabeled_indices", ")", ":", "# compute the entropies of transduced label distributions", "\n", "# uncertainty_index = np.argsort(stats.distributions.entropy(", "\n", "#     mld.label_distributions_.T))[::-1]", "\n", "\n", "    ", "p", "=", "mdl", ".", "predict_proba", "(", "X", ")", "\n", "uncertainty_index", "=", "np", ".", "argsort", "(", "stats", ".", "distributions", ".", "entropy", "(", "p", ".", "T", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "uncertainty_index", "=", "uncertainty_index", "[", "\n", "np", ".", "in1d", "(", "uncertainty_index", ",", "unlabeled_indices", ")", "]", "[", ":", "40", "]", "\n", "return", "uncertainty_index", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.My_Active_Learning.ts_method": [[234, 246], ["dataset.load_data", "model.predict", "sklearn.metrics.confusion_matrix", "print", "print", "print", "sklearn.metrics.classification_report"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data"], ["", "def", "ts_method", "(", "model", ")", ":", "\n", "    ", "sensor_data", "=", "dataset", ".", "load_data", "(", ")", "\n", "X", ",", "y", "=", "sensor_data", ".", "data", "[", "4000", ":", "]", ",", "sensor_data", ".", "target", "[", "4000", ":", "]", "\n", "\n", "predicted_labels", "=", "model", ".", "predict", "(", "X", ")", "\n", "# predicted_labels = [1 if x > 0.5 else 0 for x in p[:, 1]]", "\n", "cm", "=", "confusion_matrix", "(", "y", ",", "predicted_labels", ",", "\n", "labels", "=", "model", ".", "classes_", ")", "\n", "\n", "print", "(", "'&'", "*", "70", ")", "\n", "print", "(", "cm", ")", "\n", "print", "(", "classification_report", "(", "y", ",", "predicted_labels", ")", ")", "\n", "# print('&' * 70)", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.My_Active_Learning.random_method": [[265, 270], ["numpy.random.RandomState", "numpy.copy", "np.random.RandomState.shuffle"], "function", ["None"], ["", "def", "random_method", "(", "mld", ",", "X", ",", "unlabeled_indices", ")", ":", "\n", "    ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "\n", "indices", "=", "np", ".", "copy", "(", "unlabeled_indices", ")", "\n", "rng", ".", "shuffle", "(", "indices", ")", "\n", "return", "indices", "[", ":", "40", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.My_Active_Learning.least_confident_method": [[272, 277], ["numpy.argsort", "numpy.max", "numpy.in1d"], "function", ["None"], ["", "def", "least_confident_method", "(", "mld", ",", "unlabeled_indices", ")", ":", "\n", "    ", "uncertainty_index", "=", "np", ".", "argsort", "(", "np", ".", "max", "(", "mld", ".", "label_distributions_", ",", "axis", "=", "1", ")", ")", "\n", "uncertainty_index", "=", "uncertainty_index", "[", "\n", "np", ".", "in1d", "(", "uncertainty_index", ",", "unlabeled_indices", ")", "]", "\n", "return", "uncertainty_index", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_features": [[10, 39], ["range", "mean", "var", "stats.skew", "stats.kurtosis", "sqrt", "median", "frame.max", "frame.min", "numpy.ptp", "numpy.hstack", "numpy.hstack", "numpy.hstack", "numpy.hstack", "numpy.hstack", "numpy.hstack", "numpy.hstack", "numpy.hstack", "mean", "numpy.vstack"], "function", ["None"], ["def", "calc_features", "(", "data", ",", "step_size", "=", "75", ",", "frame_size", "=", "150", ")", ":", "\n", "    ", "row", ",", "columns", "=", "data", ".", "shape", "\n", "\n", "for", "counter", "in", "range", "(", "0", ",", "row", ",", "step_size", ")", ":", "\n", "        ", "frame", "=", "data", "[", "counter", ":", "counter", "+", "frame_size", ",", ":", "columns", "]", "\n", "\n", "m", "=", "mean", "(", "frame", ",", "axis", "=", "0", ")", "\n", "v", "=", "var", "(", "frame", ",", "axis", "=", "0", ")", "\n", "skew", "=", "stats", ".", "skew", "(", "frame", ",", "axis", "=", "0", ")", "\n", "kurtosis", "=", "stats", ".", "kurtosis", "(", "frame", ",", "axis", "=", "0", ")", "\n", "rms", "=", "sqrt", "(", "mean", "(", "frame", "**", "2", ",", "axis", "=", "0", ")", ")", "\n", "med", "=", "median", "(", "frame", ",", "axis", "=", "0", ")", "\n", "maxvalue", "=", "frame", ".", "max", "(", "axis", "=", "0", ")", "\n", "minvalue", "=", "frame", ".", "min", "(", "axis", "=", "0", ")", "\n", "p2p", "=", "np", ".", "ptp", "(", "frame", ",", "axis", "=", "0", ")", "\n", "\n", "\n", "temp", "=", "np", ".", "hstack", "(", "(", "m", ",", "v", ")", ")", "\n", "temp", "=", "np", ".", "hstack", "(", "(", "temp", ",", "skew", ")", ")", "\n", "temp", "=", "np", ".", "hstack", "(", "(", "temp", ",", "kurtosis", ")", ")", "\n", "temp", "=", "np", ".", "hstack", "(", "(", "temp", ",", "rms", ")", ")", "\n", "temp", "=", "np", ".", "hstack", "(", "(", "temp", ",", "med", ")", ")", "\n", "temp", "=", "np", ".", "hstack", "(", "(", "temp", ",", "maxvalue", ")", ")", "\n", "temp", "=", "np", ".", "hstack", "(", "(", "temp", ",", "minvalue", ")", ")", "\n", "temp", "=", "np", ".", "hstack", "(", "(", "temp", ",", "p2p", ")", ")", "\n", "\n", "result", "=", "temp", "if", "counter", "==", "0", "else", "np", ".", "vstack", "(", "(", "result", ",", "temp", ")", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_y": [[41, 51], ["numpy.array", "range", "numpy.append", "sum"], "function", ["None"], ["", "def", "calc_y", "(", "data", ",", "step_size", "=", "75", ")", ":", "\n", "\n", "    ", "y", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "row_num", ",", "column_num", "=", "data", ".", "shape", "\n", "\n", "for", "counter", "in", "range", "(", "0", ",", "row_num", ",", "step_size", ")", ":", "\n", "        ", "l", "=", "1", "if", "sum", "(", "data", "[", "counter", ":", "counter", "+", "step_size", ",", "column_num", "]", ")", ">=", "step_size", "/", "2", "else", "0", "\n", "y", "=", "np", ".", "append", "(", "y", ",", "l", ")", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.make_data": [[53, 96], ["os.path.dirname", "range", "range", "sklearn.preprocessing.scale", "dataset.calc_y", "sklearn.preprocessing.scale", "dataset.calc_y", "numpy.savetxt", "numpy.savetxt", "numpy.savetxt", "numpy.savetxt", "utils.Bunch", "int", "numpy.genfromtxt", "numpy.genfromtxt", "dataset.calc_features", "dataset.calc_features", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.vstack", "os.path.join", "numpy.vstack", "str", "str"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_y", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_y", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_features", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_features"], ["", "def", "make_data", "(", ")", ":", "\n", "\n", "    ", "NUMBER_OF_TRAIN_FILES", "=", "1", "\n", "NUMBER_OF_TEST_FILES", "=", "1", "\n", "WINDOW_SIZE", "=", "6", "\n", "SAMPLING_RATE", "=", "25", "\n", "\n", "frame_size", "=", "WINDOW_SIZE", "*", "SAMPLING_RATE", "\n", "step_size", "=", "int", "(", "WINDOW_SIZE", "/", "2", ")", "*", "SAMPLING_RATE", "\n", "\n", "first_iteration", "=", "True", "\n", "module_path", "=", "dirname", "(", "__file__", ")", "\n", "\n", "for", "file_id", "in", "range", "(", "1", ",", "NUMBER_OF_TRAIN_FILES", "+", "1", ")", ":", "\n", "\n", "        ", "raw_data", "=", "np", ".", "genfromtxt", "(", "join", "(", "module_path", ",", "'train/DATA_'", ",", "str", "(", "file_id", ")", ",", "'.csv'", ")", ",", "\n", "delimiter", "=", "','", ")", "\n", "\n", "train_data", "=", "raw_data", "if", "first_iteration", "else", "np", ".", "vstack", "(", "(", "train_data", ",", "raw_data", ")", ")", "\n", "first_iteration", "=", "False", "\n", "\n", "", "first_iteration", "=", "True", "\n", "for", "file_id", "in", "range", "(", "1", ",", "NUMBER_OF_TEST_FILES", "+", "1", ")", ":", "\n", "\n", "        ", "raw_data", "=", "np", ".", "genfromtxt", "(", "join", "(", "module_path", ",", "'test/DATA_'", ",", "str", "(", "file_id", ")", ",", "'.csv'", ")", ",", "\n", "delimiter", "=", "','", ")", "\n", "\n", "test_data", "=", "raw_data", "if", "first_iteration", "else", "np", ".", "vstack", "(", "(", "test_data", ",", "raw_data", ")", ")", "\n", "first_iteration", "=", "False", "\n", "\n", "", "X", "=", "preprocessing", ".", "scale", "(", "calc_features", "(", "train_data", ",", "step_size", ",", "frame_size", ")", ")", "\n", "Y", "=", "calc_y", "(", "train_data", ",", "step_size", ")", "\n", "\n", "X_test", "=", "preprocessing", ".", "scale", "(", "calc_features", "(", "test_data", ",", "step_size", ",", "frame_size", ")", ")", "\n", "Y_test", "=", "calc_y", "(", "test_data", ",", "step_size", ")", "\n", "\n", "np", ".", "savetxt", "(", "join", "(", "module_path", ",", "\"data/X_file.csv\"", ")", ",", "X", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "np", ".", "savetxt", "(", "join", "(", "module_path", ",", "\"data/Y_file.csv\"", ")", ",", "Y", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.1f'", ")", "\n", "\n", "np", ".", "savetxt", "(", "join", "(", "module_path", ",", "\"data/X_test_file.csv\"", ")", ",", "X_test", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "np", ".", "savetxt", "(", "join", "(", "module_path", ",", "\"data/Y_test_file.csv\"", ")", ",", "Y_test", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.1f'", ")", "\n", "\n", "return", "utils", ".", "Bunch", "(", "data", "=", "X", ",", "target", "=", "Y", ",", "test_data", "=", "X_test", ",", "test_target", "=", "Y_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data": [[98, 110], ["os.path.dirname", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.genfromtxt", "utils.Bunch", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "load_data", "(", ")", ":", "\n", "    ", "module_path", "=", "dirname", "(", "__file__", ")", "\n", "\n", "X", "=", "np", ".", "genfromtxt", "(", "join", "(", "module_path", ",", "'data/X_file.csv'", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "\n", "Y", "=", "np", ".", "genfromtxt", "(", "join", "(", "module_path", ",", "'data/Y_file.csv'", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "\n", "test_data", "=", "np", ".", "genfromtxt", "(", "join", "(", "module_path", ",", "'data/X_test_file.csv'", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "\n", "test_target", "=", "np", ".", "genfromtxt", "(", "join", "(", "module_path", ",", "'data/Y_test_file.csv'", ")", ",", "delimiter", "=", "\",\"", ")", "\n", "\n", "return", "utils", ".", "Bunch", "(", "data", "=", "X", ",", "target", "=", "Y", ",", "test_data", "=", "test_data", ",", "test_target", "=", "test_target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.first_experiment": [[25, 33], ["My_Active_Learning.load_data", "My_Active_Learning.PAL", "My_Active_Learning.PAL", "experiments.pal_depict_measurments"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.My_Active_Learning.PAL", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.My_Active_Learning.PAL", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.pal_depict_measurments"], ["def", "first_experiment", "(", ")", ":", "\n", "    ", "X", ",", "y", "=", "pal", ".", "load_data", "(", ")", "\n", "# pal.PAL(pal.least_confident_method, 'PAL_Least_Confident')", "\n", "pal", ".", "PAL", "(", "X", ",", "y", ",", "pal", ".", "entropy_method", ",", "'PAL_Entropy'", ")", "\n", "pal", ".", "PAL", "(", "X", ",", "y", ",", "pal", ".", "random_method", ",", "'PAL_Random'", ")", "\n", "file_names", "=", "[", "'PAL_Entropy'", ",", "'PAL_Random'", "]", "\n", "names", "=", "[", "'Entropy'", ",", "'Random'", "]", "\n", "pal_depict_measurments", "(", "file_names", ",", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.second_experiment": [[40, 51], ["experiments.pal_depict_measurments"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.pal_depict_measurments"], ["", "def", "second_experiment", "(", ")", ":", "\n", "# X, y = pal.load_data()", "\n", "# pal.PAL(X,y ,pal.entropy_method, 'PAL_RBF',False,  {'gamma': .25, 'max_iter': 5})", "\n", "# # pal.PAL(pal.entropy_method, 'PAL_RBF_10', False, {'gamma': 10, 'max_iter': 15})", "\n", "# pal.PAL(X,y, pal.entropy_method, 'PAL_KNN',False, {'kernel':'knn','n_neighbors':30})", "\n", "# pal.PAL(pal.entropy_method, 'PAL_KNN_30', False, {'n_neighbors': 30})", "\n", "# file_names = ['PAL_200_1', 'PAL_4','PAL_6', 'PAL_8']", "\n", "\n", "    ", "file_names", "=", "[", "'PAL_RBF'", ",", "'PAL_KNN'", "]", "\n", "names", "=", "[", "'RBF'", ",", "'KNN'", "]", "\n", "pal_depict_measurments", "(", "file_names", ",", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.third_experiment": [[62, 92], ["My_Active_Learning.load_data", "print", "print", "Active_Learning_SVM.explore", "len"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.Active_Learning_SVM.explore"], ["", "def", "third_experiment", "(", ")", ":", "\n", "#", "\n", "    ", "X", ",", "y", "=", "pal", ".", "load_data", "(", ")", "\n", "print", "(", "'^'", "*", "40", ")", "\n", "print", "(", "len", "(", "X", ")", ")", "\n", "\n", "#", "\n", "# p1 = Process(target=pal.PAL, args=(X, y,  pal.entropy_method,'PAL_200',))", "\n", "# p2 = Process(target=other_approaches.explore, args=(X, y,  'svm_200',SVC, {'gamma':2, 'C': 1, 'probability':True},))", "\n", "# p3 = Process(target=other_approaches.explore, args=(X, y,  'LR_200', linear_model.LogisticRegression,))", "\n", "# p4 = Process(target=other_approaches.explore, args=(X, y, 'RFC_200',RandomForestClassifier, {'n_estimators':185} ,))", "\n", "# p7 = Process(target=other_approaches.explore,", "\n", "#              args=(X, y, 'RFC_200_X_1', RandomForestClassifier,))", "\n", "#", "\n", "# p5 = Process(target=other_approaches.explore, args=(X, y, 'QDA_200',QuadraticDiscriminantAnalysis,))", "\n", "# p6 = Process(target=other_approaches.explore, args=(X, y,  'ABC_200',AdaBoostClassifier,))", "\n", "#", "\n", "# processes = [p1,p2, p3, p4, p5, p6, p7]", "\n", "# for p in processes:", "\n", "#     p.start()", "\n", "# for p in processes:", "\n", "#     p.join()", "\n", "\n", "# p1.start()", "\n", "# p1.join()", "\n", "\n", "# pal.PAL(X, y, pal.entropy_method,'PAL_20')", "\n", "# other_approaches.explore(X, y, 'svm_20',SVC, {'gamma':2, 'C': 1, 'probability':True} )", "\n", "# other_approaches.explore(X, y, 'LR_20', linear_model.LogisticRegression)", "\n", "other_approaches", ".", "explore", "(", "X", ",", "y", ",", "'RFC_20'", ",", "RandomForestClassifier", ",", "{", "'n_estimators'", ":", "185", "}", ")", "\n", "# other_approaches.explore(X, y, 'QDA_20',QuadraticDiscriminantAnalysis)", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.spal_first_experiment": [[110, 131], ["experiments.depict_f_measure"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.depict_f_measure"], ["def", "spal_first_experiment", "(", ")", ":", "\n", "    ", "fold_count", "=", "10", "\n", "# file_names = [\"experimental_upper_bound\",'adaptive_lambda', 'static_lambda' ]", "\n", "file_names", "=", "[", "'adaptive_lambda'", ",", "'simple'", ",", "'adaptive_lambda_no_model'", "]", "#, 'adaptive_lambda','simple_model']#[\"experimental_upper_bound_15\", 'adaptive_lambda_15', 'static_lambda_15']", "\n", "model_names", "=", "[", "'(1)'", ",", "'(2)'", ",", "'(3)'", "]", "#,'PAL as base model', 'Simple Model'] #['Experimental Upper Bound', 'Adaptive Lambda', 'Static Lambda']", "\n", "participants", "=", "[", "2", ",", "4", ",", "5", ",", "7", "]", "\n", "\n", "# for p in participants:", "\n", "#     spal.customize(spal.make_model2(), spal.update_threshold_adaptive_lambda, file_names[0], fold_count, str(p))", "\n", "# spal.customize(spal.make_model3(), spal.update_threshold_adaptive_lambda, file_names[1], fold_count, str(p))", "\n", "# spal.customize(spal.make_model(), spal.update_threshold_adaptive_lambda, file_names[2], fold_count, str(p))", "\n", "\n", "\n", "# spal.customize(spal.make_model(), spal.update_threshold_static_lambda,file_names[2] ,fold_count, str(p))", "\n", "# spal.customize_with_perfect_lambda(spal.make_model(), file_names[0], fold_count ,str(p))", "\n", "\n", "\n", "# ************************chart**********************************", "\n", "\n", "\n", "depict_f_measure", "(", "file_names", ",", "model_names", ",", "max_iter", "=", "fold_count", ",", "xlabel", "=", "'Number of time intervals'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.spal_second_experiment": [[138, 154], ["list", "numpy.arange", "experiments.depict_f_measure", "map", "range"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.depict_f_measure"], ["def", "spal_second_experiment", "(", ")", ":", "\n", "    ", "fold_count", "=", "1", "\n", "file_names", "=", "[", "\"SPAL_5\"", ",", "'SPAL_10'", ",", "'SPAL_15'", ",", "'SPAL_20'", ",", "'SPAL_25'", ",", "'SPAL_30'", ",", "\"SPAL_35\"", ",", "'SPAL_40'", ",", "'SPAL_45'", ",", "'SPAL_50'", ",", "'SPAL_55'", ",", "'SPAL_60'", "]", "\n", "model_names", "=", "list", "(", "map", "(", "str", ",", "range", "(", "5", ",", "61", ",", "5", ")", ")", ")", "\n", "delta", "=", "np", ".", "arange", "(", "5", ",", "61", ",", "5", ")", "\n", "participants", "=", "[", "2", ",", "4", ",", "5", ",", "7", "]", "\n", "\n", "# model = spal.make_model2()", "\n", "# for p in participants:", "\n", "#     for name, aq in zip(file_names, delta):", "\n", "#         spal.customize( model, spal.update_threshold_adaptive_lambda,name , fold_count, str(p),aq )", "\n", "# #", "\n", "# # ************************chart**********************************", "\n", "#", "\n", "\n", "depict_f_measure", "(", "file_names", ",", "model_names", ",", "max_iter", "=", "12", ",", "xlabel", "=", "'Budget/Hour'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.depict_f_measure_bar_chart": [[159, 214], ["zip", "zip", "zip", "numpy.arange", "matplotlib.pyplot.subplots", "ax.bar", "ax.bar", "ax.set_xlabel", "ax.set_ylabel", "ax.set_xticks", "ax.set_xticklabels", "ax.legend", "fig.tight_layout", "matplotlib.pyplot.show", "numpy.divide", "y_axis_f.append", "numpy.divide", "y_axis_r.append", "numpy.divide", "y_axis_a.append", "numpy.arange", "numpy.genfromtxt", "numpy.array", "numpy.genfromtxt", "numpy.array", "numpy.genfromtxt", "numpy.array", "str", "str", "str"], "function", ["None"], ["def", "depict_f_measure_bar_chart", "(", "file_names", ",", "model_names", ",", "bins", "=", "6", ",", "xlabel", "=", "'Budget'", ")", ":", "\n", "    ", "y_axis_f", "=", "[", "]", "\n", "bar_width", "=", "0.25", "\n", "for", "model", ",", "name", "in", "zip", "(", "file_names", ",", "model_names", ")", ":", "\n", "        ", "y", "=", "0.0", "\n", "for", "i", "in", "[", "2", ",", "4", ",", "5", ",", "7", "]", ":", "\n", "            ", "y", "+=", "np", ".", "genfromtxt", "(", "(", "'f1_macro_score_'", "+", "model", "+", "'_'", "+", "str", "(", "i", ")", "+", "\".csv\"", ")", ",", "delimiter", "=", "','", ")", "\n", "\n", "", "y", "=", "np", ".", "divide", "(", "y", ",", "np", ".", "array", "(", "[", "4.0", "]", ",", "dtype", "=", "float", ")", ")", "\n", "y_axis_f", ".", "append", "(", "y", ")", "\n", "\n", "", "y_axis_r", "=", "[", "]", "\n", "for", "model", ",", "name", "in", "zip", "(", "file_names", ",", "model_names", ")", ":", "\n", "        ", "y", "=", "0.0", "\n", "for", "i", "in", "[", "2", ",", "4", ",", "5", ",", "7", "]", ":", "\n", "            ", "y", "+=", "np", ".", "genfromtxt", "(", "(", "'recall_macro_score_'", "+", "model", "+", "'_'", "+", "str", "(", "i", ")", "+", "\".csv\"", ")", ",", "delimiter", "=", "','", ")", "\n", "\n", "", "y", "=", "np", ".", "divide", "(", "y", ",", "np", ".", "array", "(", "[", "4.0", "]", ",", "dtype", "=", "float", ")", ")", "\n", "y_axis_r", ".", "append", "(", "y", ")", "\n", "\n", "\n", "", "y_axis_a", "=", "[", "]", "\n", "for", "model", ",", "name", "in", "zip", "(", "file_names", ",", "model_names", ")", ":", "\n", "        ", "y", "=", "0.0", "\n", "for", "i", "in", "[", "2", ",", "4", ",", "5", ",", "7", "]", ":", "\n", "            ", "y", "+=", "np", ".", "genfromtxt", "(", "(", "'accuracy_score_'", "+", "model", "+", "'_'", "+", "str", "(", "i", ")", "+", "\".csv\"", ")", ",", "delimiter", "=", "','", ")", "\n", "\n", "", "y", "=", "np", ".", "divide", "(", "y", ",", "np", ".", "array", "(", "[", "4.0", "]", ",", "dtype", "=", "float", ")", ")", "\n", "y_axis_a", ".", "append", "(", "y", ")", "\n", "\n", "", "index", "=", "np", ".", "arange", "(", "6", ")", "\n", "opacity", "=", "0.8", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "rects1", "=", "ax", ".", "bar", "(", "index", ",", "y_axis_f", ",", "bar_width", ",", "\n", "alpha", "=", "opacity", ",", "color", "=", "'b'", ",", "\n", "label", "=", "'f-score'", ")", "\n", "\n", "rects2", "=", "ax", ".", "bar", "(", "index", "+", "1.1", "*", "bar_width", ",", "y_axis_r", ",", "bar_width", ",", "\n", "alpha", "=", "opacity", ",", "color", "=", "'r'", ",", "\n", "label", "=", "'recall'", ")", "\n", "\n", "# rects3 = ax.bar(index +2.2* bar_width, y_axis_a, bar_width,", "\n", "#                 alpha=opacity, color='g',", "\n", "#                 label='accuracy')", "\n", "\n", "ax", ".", "set_xlabel", "(", "'Query Budget/ Hour'", ",", "fontsize", "=", "'x-large'", ")", "\n", "ax", ".", "set_ylabel", "(", "'Scores'", ",", "fontsize", "=", "'x-large'", ")", "\n", "ax", ".", "set_xticks", "(", "index", "+", "bar_width", ")", "\n", "ax", ".", "set_xticklabels", "(", "np", ".", "arange", "(", "10", ",", "161", ",", "30", ")", ")", "\n", "ax", ".", "legend", "(", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.depict_f_measure": [[216, 242], ["zip", "numpy.arange", "matplotlib.pyplot.ylim", "matplotlib.pyplot.plot", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.show", "numpy.zeros", "print", "numpy.divide", "ys.append", "print", "numpy.sum", "numpy.array", "numpy.genfromtxt", "str"], "function", ["None"], ["", "def", "depict_f_measure", "(", "file_names", ",", "model_names", ",", "max_iter", "=", "50", ",", "xlabel", "=", "'Number of Iterations'", ")", ":", "\n", "    ", "ys", "=", "[", "]", "\n", "for", "model", ",", "name", "in", "zip", "(", "file_names", ",", "model_names", ")", ":", "\n", "        ", "y", "=", "np", ".", "zeros", "(", "(", "4", ",", ")", ")", "\n", "print", "(", "name", ")", "\n", "for", "i", "in", "[", "2", ",", "4", ",", "5", ",", "7", "]", ":", "\n", "            ", "print", "(", "i", ")", "\n", "y", "=", "np", ".", "sum", "(", "[", "y", ",", "np", ".", "genfromtxt", "(", "(", "'f1_macro_score_'", "+", "model", "+", "'_'", "+", "str", "(", "i", ")", "+", "\".csv\"", ")", ",", "delimiter", "=", "','", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "y", "=", "np", ".", "divide", "(", "y", ",", "np", ".", "array", "(", "[", "4.0", "]", ",", "dtype", "=", "float", ")", ")", "\n", "ys", ".", "append", "(", "y", ")", "\n", "", "x", "=", "np", ".", "arange", "(", "5", ",", "max_iter", "*", "5", "+", "1", ",", "5", ")", "\n", "plt", ".", "ylim", "(", "[", "0.4", ",", "0.7", "]", ")", "\n", "plt", ".", "plot", "(", "x", ",", "ys", ")", "\n", "\n", "# for i in [2,4,5,7]:", "\n", "#     for model, name in zip(file_names, model_names):", "\n", "#         y = np.genfromtxt(('f1_score_'+model + '_'+ str(i) +\".csv\"), delimiter=',')", "\n", "#", "\n", "#         x = np.arange(1, max_iter+1)", "\n", "#         plt.plot(x, y, label=name+'_'+ str(i))", "\n", "plt", ".", "ylabel", "(", "'F Score'", ",", "fontsize", "=", "'x-large'", ")", "\n", "plt", ".", "legend", "(", "fontsize", "=", "'x-large'", ")", "\n", "plt", ".", "xlabel", "(", "xlabel", ",", "fontsize", "=", "'x-large'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.pal_depict_measurments": [[244, 255], ["zip", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.xticks", "matplotlib.pyplot.show", "numpy.genfromtxt", "numpy.arange", "matplotlib.pyplot.plot", "numpy.arange", "type_of_result.split"], "function", ["None"], ["", "def", "pal_depict_measurments", "(", "file_names", ",", "model_names", ",", "max_iter", "=", "50", ",", "xlabel", "=", "'Number of Iterations'", ",", "type_of_result", "=", "'f1_score'", ")", ":", "\n", "    ", "for", "model", ",", "name", "in", "zip", "(", "file_names", ",", "model_names", ")", ":", "\n", "            ", "y", "=", "np", ".", "genfromtxt", "(", "(", "type_of_result", "+", "'_'", "+", "model", "+", "\".csv\"", ")", ",", "delimiter", "=", "','", ")", "\n", "x", "=", "np", ".", "arange", "(", "0", ",", "max_iter", ")", "\n", "plt", ".", "plot", "(", "x", ",", "y", ",", "label", "=", "name", ")", "\n", "", "plt", ".", "ylabel", "(", "(", "' '", ".", "join", "(", "type_of_result", ".", "split", "(", "'_'", ")", ")", ".", "title", "(", ")", ")", ",", "fontsize", "=", "'x-large'", ")", "\n", "plt", ".", "legend", "(", "fontsize", "=", "'x-large'", ")", "\n", "plt", ".", "xlabel", "(", "xlabel", ",", "fontsize", "=", "'x-large'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "0", ",", "max_iter", "+", "1", ",", "5", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.experiments.test_size": [[256, 270], ["numpy.genfromtxt", "calc_features", "print", "join", "Counter", "str"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_features"], ["", "def", "test_size", "(", ")", ":", "\n", "    ", "from", "os", ".", "path", "import", "join", "\n", "from", "dataset", "import", "calc_features", "\n", "from", "sklearn", "import", "preprocessing", "\n", "from", "collections", "import", "Counter", "\n", "participants", "=", "[", "2", ",", "4", ",", "5", ",", "7", "]", "\n", "for", "p", "in", "participants", ":", "\n", "        ", "user_data", "=", "np", ".", "genfromtxt", "(", "join", "(", "'C:/Users/Marjan/Desktop/Thesis/participants_wild'", ",", "str", "(", "p", ")", ",", "'wrist_ss.csv'", ")", ",", "delimiter", "=", "','", ")", "\n", "user_data", "=", "user_data", "[", ":", ",", "1", ":", "]", "\n", "data", "=", "calc_features", "(", "user_data", ")", "\n", "# X = preprocessing.scale(data[:, :(user_data.shape[1] - 1) * 9])", "\n", "\n", "y", "=", "data", "[", ":", ",", "-", "1", "]", "\n", "print", "(", "Counter", "(", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.Query_by_commitee.vote_entropy": [[27, 40], ["scipy.stats.entropy", "numpy.array", "collections.Counter", "scipy.stats.entropy", "numpy.append", "collections.Counter.values"], "function", ["None"], ["def", "vote_entropy", "(", "C", ",", "y", ")", ":", "\n", "    ", "result", "=", "stats", ".", "entropy", "(", "y", ")", "\n", "result", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "x", "in", "y", ".", "T", ":", "\n", "        ", "d", "=", "Counter", "(", "x", ")", "\n", "disagreement", "=", "stats", ".", "entropy", "(", "[", "*", "d", ".", "values", "(", ")", "]", ")", "\n", "\n", "# disagreement = -np.sum([i/C* np.log2(i/C) for i in d.values()])", "\n", "\n", "result", "=", "np", ".", "append", "(", "result", ",", "disagreement", ")", "\n", "\n", "# print(Counter(result))", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.Query_by_commitee.query_by_committee": [[42, 116], ["dataset.load_data", "numpy.random.RandomState", "numpy.arange", "np.random.RandomState.shuffle", "len", "range", "matplotlib.pyplot.plot", "matplotlib.pyplot.show", "len", "numpy.arange", "sklearn.svm.SVC", "sklearn.gaussian_process.GaussianProcessClassifier", "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis", "print", "numpy.array", "enumerate", "Query_by_commitee.vote_entropy", "numpy.array", "plt_x.append", "plt_acc.append", "plt_y.append", "numpy.array", "numpy.delete", "len", "model.fit", "print", "print", "len", "collections.Counter", "numpy.append", "sklearn.metrics.accuracy_score", "max", "numpy.where", "numpy.concatenate", "sklearn.gaussian_process.kernels.RBF", "model.predict", "numpy.vstack", "sklearn.metrics.accuracy_score", "max", "numpy.argsort", "collections.Counter().values", "model.predict", "collections.Counter.items", "model.predict", "str", "collections.Counter"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.Query_by_commitee.vote_entropy"], ["", "def", "query_by_committee", "(", ")", ":", "\n", "    ", "n_labeled_points", "=", "300", "\n", "\n", "sensor_data", "=", "dataset", ".", "load_data", "(", ")", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "sensor_data", ".", "data", ")", ")", "\n", "rng", ".", "shuffle", "(", "indices", ")", "\n", "X", "=", "sensor_data", ".", "data", "[", "indices", "[", ":", "4000", "]", "]", "\n", "y", "=", "sensor_data", ".", "target", "[", "indices", "[", ":", "4000", "]", "]", "\n", "n_total_samples", "=", "len", "(", "y", ")", "\n", "unlabeled_indices", "=", "np", ".", "arange", "(", "n_total_samples", ")", "[", "n_labeled_points", ":", "]", "\n", "\n", "committee", "=", "[", "\n", "# KNeighborsClassifier(3),", "\n", "#      SVC(kernel=\"linear\", C=0.025),", "\n", "SVC", "(", "gamma", "=", "2", ",", "C", "=", "1", ")", ",", "\n", "GaussianProcessClassifier", "(", "1.0", "*", "RBF", "(", "1.0", ")", ")", ",", "\n", "# DecisionTreeClassifier(max_depth=5),", "\n", "# RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),", "\n", "# AdaBoostClassifier(),", "\n", "# GaussianNB(),", "\n", "QuadraticDiscriminantAnalysis", "(", ")", ",", "\n", "# linear_model.LogisticRegression()", "\n", "]", "\n", "plt_x", "=", "[", "]", "\n", "plt_y", "=", "[", "]", "\n", "plt_acc", "=", "[", "]", "\n", "for", "iteration", "in", "range", "(", "max_iterations", ")", ":", "\n", "        ", "print", "(", "iteration", ")", "\n", "y_train", "=", "y", "[", ":", "n_labeled_points", "]", "\n", "X_train", "=", "X", "[", ":", "n_labeled_points", "]", "\n", "X_test", "=", "X", "[", "n_labeled_points", ":", "]", "\n", "y_test", "=", "y", "[", "n_labeled_points", ":", "]", "\n", "\n", "predicted", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "i", ",", "model", "in", "enumerate", "(", "committee", ")", ":", "\n", "            ", "model", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "predicted", "=", "model", ".", "predict", "(", "X_test", ")", "\n", "", "else", ":", "\n", "                ", "predicted", "=", "np", ".", "vstack", "(", "(", "predicted", ",", "model", ".", "predict", "(", "X_test", ")", ")", ")", "\n", "", "print", "(", "\"_____________\"", "+", "str", "(", "i", ")", "+", "\"_____________\"", ")", "\n", "print", "(", "accuracy_score", "(", "y_test", ",", "model", ".", "predict", "(", "X_test", ")", ")", ")", "\n", "", "voted", "=", "vote_entropy", "(", "len", "(", "committee", ")", ",", "predicted", ")", "\n", "y_predicted", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "for", "item", "in", "predicted", ".", "T", ":", "\n", "\n", "\n", "            ", "d", "=", "Counter", "(", "item", ")", "\n", "y_x", "=", "max", "(", "d", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "[", "0", "]", "\n", "y_predicted", "=", "np", ".", "append", "(", "y_predicted", ",", "y_x", ")", "\n", "\n", "# print(classification_report(y_test, y_predicted))", "\n", "# print(accuracy_score(y_test, y_predicted))", "\n", "\n", "", "uncertain_points", "=", "(", "np", ".", "argsort", "(", "voted", ")", "[", ":", ":", "-", "1", "]", ")", "[", ":", "20", "]", "\n", "# _________________________________________________________", "\n", "plt_x", ".", "append", "(", "iteration", ")", "\n", "plt_acc", ".", "append", "(", "accuracy_score", "(", "y_test", ",", "y_predicted", ")", ")", "\n", "plt_y", ".", "append", "(", "max", "(", "Counter", "(", "voted", ")", ".", "values", "(", ")", ")", ")", "\n", "\n", "\n", "#__________________________________________________________", "\n", "\n", "delete_indices", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "index", "in", "uncertain_points", ":", "\n", "            ", "delete_index", ",", "=", "np", ".", "where", "(", "unlabeled_indices", "==", "index", ")", "\n", "delete_indices", "=", "np", ".", "concatenate", "(", "(", "delete_indices", ",", "delete_index", ")", ")", "\n", "", "unlabeled_indices", "=", "np", ".", "delete", "(", "unlabeled_indices", ",", "delete_indices", ")", "\n", "n_labeled_points", "+=", "len", "(", "uncertain_points", ")", "\n", "\n", "", "plt", ".", "plot", "(", "plt_x", ",", "plt_y", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.make_model3": [[18, 26], ["sklearn.semi_supervised.label_propagation.LabelSpreading", "dataset.load_data", "label_propagation.LabelSpreading.fit", "numpy.savetxt", "numpy.savetxt"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data"], ["def", "make_model3", "(", ")", ":", "\n", "    ", "model", "=", "label_propagation", ".", "LabelSpreading", "(", "kernel", "=", "'knn'", ",", "n_neighbors", "=", "15", ")", "\n", "sensor_data", "=", "dataset", ".", "load_data", "(", ")", "\n", "X", ",", "y", "=", "sensor_data", ".", "data", "[", ":", "200", "]", ",", "sensor_data", ".", "target", "[", ":", "200", "]", "\n", "model", ".", "fit", "(", "X", ",", "y", ")", "\n", "np", ".", "savetxt", "(", "\"X.csv\"", ",", "X", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "np", ".", "savetxt", "(", "\"y_train.csv\"", ",", "y", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.1f'", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.make_model": [[27, 35], ["sklearn.ensemble.RandomForestClassifier", "dataset.load_data", "sklearn.ensemble.RandomForestClassifier.fit", "numpy.savetxt", "numpy.savetxt"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data"], ["", "def", "make_model", "(", ")", ":", "\n", "    ", "model", "=", "RandomForestClassifier", "(", "n_estimators", "=", "185", ")", "#label_propagation.LabelSpreading(gamma=0.25, max_iter=5)", "\n", "sensor_data", "=", "dataset", ".", "load_data", "(", ")", "\n", "X", ",", "y", "=", "sensor_data", ".", "data", "[", ":", "200", "]", ",", "sensor_data", ".", "target", "[", ":", "200", "]", "\n", "model", ".", "fit", "(", "X", ",", "y", ")", "\n", "np", ".", "savetxt", "(", "\"X.csv\"", ",", "X", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "np", ".", "savetxt", "(", "\"y_train.csv\"", ",", "y", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.1f'", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.make_model2": [[36, 85], ["dataset.load_data", "numpy.random.RandomState", "numpy.arange", "np.random.RandomState.shuffle", "print", "imblearn.over_sampling.SMOTE", "imblearn.over_sampling.SMOTE.fit_sample", "len", "print", "sklearn.semi_supervised.label_propagation.LabelSpreading", "range", "numpy.savetxt", "numpy.savetxt", "len", "len", "len", "numpy.arange", "numpy.copy", "label_propagation.LabelSpreading.fit", "label_propagation.LabelSpreading.predict_proba", "label_propagation.LabelSpreading.predict", "scipy.stats.distributions.entropy", "numpy.array", "numpy.delete", "len", "len", "print", "numpy.argsort", "numpy.where", "numpy.concatenate", "numpy.in1d"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data"], ["", "def", "make_model2", "(", ")", ":", "\n", "    ", "sensor_data", "=", "dataset", ".", "load_data", "(", ")", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "sensor_data", ".", "data", ")", ")", "\n", "rng", ".", "shuffle", "(", "indices", ")", "\n", "print", "(", "len", "(", "sensor_data", ".", "data", ")", ")", "\n", "sm", "=", "SMOTE", "(", "random_state", "=", "42", ")", "\n", "X", ",", "y", "=", "sm", ".", "fit_sample", "(", "sensor_data", ".", "data", "[", "indices", "[", ":", "2000", "]", "]", ",", "sensor_data", ".", "target", "[", "indices", "[", ":", "2000", "]", "]", ")", "\n", "\n", "n_total_samples", "=", "len", "(", "y", ")", "\n", "print", "(", "len", "(", "y", ")", ")", "\n", "n_labeled_points", "=", "200", "\n", "max_iterations", "=", "50", "\n", "unlabeled_indices", "=", "np", ".", "arange", "(", "n_total_samples", ")", "[", "n_labeled_points", ":", "]", "\n", "lp_model", "=", "label_propagation", ".", "LabelSpreading", "(", "kernel", "=", "'knn'", ",", "n_neighbors", "=", "15", ")", "\n", "\n", "for", "i", "in", "range", "(", "max_iterations", ")", ":", "\n", "        ", "if", "len", "(", "unlabeled_indices", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"No unlabeled items left to label.\"", ")", "\n", "break", "\n", "", "y_train", "=", "np", ".", "copy", "(", "y", ")", "\n", "y_train", "[", "unlabeled_indices", "]", "=", "-", "1", "\n", "lp_model", ".", "fit", "(", "X", ",", "y_train", ")", "\n", "p", "=", "lp_model", ".", "predict_proba", "(", "X", "[", "unlabeled_indices", "]", ")", "\n", "# predicted_labels = [1 if x > 0.57 else 0 for x in p[:, 1]]", "\n", "predicted_labels", "=", "lp_model", ".", "predict", "(", "X", "[", "unlabeled_indices", "]", ")", "\n", "\n", "true_labels", "=", "y", "[", "unlabeled_indices", "]", "\n", "# print(\"#\"*20 + \"Iteration :: \" + str(i) + \"#\"*20)", "\n", "# print(classification_report(true_labels, predicted_labels))", "\n", "\n", "pred_entropies", "=", "stats", ".", "distributions", ".", "entropy", "(", "\n", "lp_model", ".", "label_distributions_", ".", "T", ")", "\n", "uncertainty_index", "=", "np", ".", "argsort", "(", "pred_entropies", ")", "[", ":", ":", "-", "1", "]", "\n", "uncertainty_index", "=", "uncertainty_index", "[", "\n", "np", ".", "in1d", "(", "uncertainty_index", ",", "unlabeled_indices", ")", "]", "[", ":", "40", "]", "\n", "delete_indices", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "index", "in", "uncertainty_index", ":", "\n", "            ", "delete_index", ",", "=", "np", ".", "where", "(", "unlabeled_indices", "==", "index", ")", "\n", "delete_indices", "=", "np", ".", "concatenate", "(", "(", "delete_indices", ",", "delete_index", ")", ")", "\n", "", "unlabeled_indices", "=", "np", ".", "delete", "(", "unlabeled_indices", ",", "delete_indices", ")", "\n", "n_labeled_points", "+=", "len", "(", "uncertainty_index", ")", "\n", "\n", "\n", "\n", "\n", "", "np", ".", "savetxt", "(", "\"X.csv\"", ",", "X", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "np", ".", "savetxt", "(", "\"y_train.csv\"", ",", "y_train", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.1f'", ")", "\n", "return", "lp_model", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.update_data": [[87, 95], ["x.reshape.reshape", "mdl.predict_proba", "scipy.stats.distributions.entropy", "numpy.append"], "function", ["None"], ["", "def", "update_data", "(", "mdl", ",", "x", ",", "aq", ",", "entropy", ",", "threshold", ")", ":", "\n", "    ", "x", "=", "x", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "p", "=", "mdl", ".", "predict_proba", "(", "x", ")", "\n", "e", "=", "stats", ".", "distributions", ".", "entropy", "(", "p", ".", "T", ")", "\n", "entropy", "=", "np", ".", "append", "(", "entropy", ",", "e", ")", "\n", "if", "e", ">", "threshold", "and", "aq", ">", "0", ":", "\n", "        ", "aq", "-=", "1", "\n", "", "return", "aq", ",", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.customize_model": [[100, 118], ["print", "print", "imblearn.over_sampling.SMOTE", "numpy.genfromtxt", "numpy.genfromtxt", "numpy.append", "numpy.append", "mdl.fit", "len"], "function", ["None"], ["", "def", "customize_model", "(", "mdl", ",", "W_X", ",", "W_Y", ")", ":", "\n", "    ", "print", "(", "\"@\"", "*", "100", ")", "\n", "print", "(", "len", "(", "W_Y", ")", ")", "\n", "sm", "=", "SMOTE", "(", "random_state", "=", "42", ")", "\n", "# mdl = label_propagation.LabelSpreading(gamma=0.25, max_iter=5)", "\n", "\n", "X", "=", "np", ".", "genfromtxt", "(", "'X.csv'", ",", "delimiter", "=", "','", ")", "\n", "y_train", "=", "np", ".", "genfromtxt", "(", "'y_train.csv'", ",", "delimiter", "=", "','", ")", "\n", "# y_train = y_train.reshape(-1,1)", "\n", "# W_Y = W_Y.reshape(-1, 1)", "\n", "# h = np.arange(len(W_Y))[[i!= -1 for i in W_Y ]]", "\n", "# W_Y = W_Y[h]", "\n", "# W_X = W_X[h]", "\n", "y_train", "=", "np", ".", "append", "(", "y_train", ",", "W_Y", ",", "axis", "=", "0", ")", "\n", "X", "=", "np", ".", "append", "(", "X", ",", "W_X", ",", "axis", "=", "0", ")", "\n", "mdl", ".", "fit", "(", "X", ",", "y_train", ")", "\n", "\n", "return", "mdl", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.update_threshold_adaptive_lambda": [[122, 126], ["sorted", "int"], "function", ["None"], ["", "def", "update_threshold_adaptive_lambda", "(", "entropy", ",", "k", ",", "N", ",", "fold_count", ",", "AR", ")", ":", "\n", "\n", "    ", "threshold", "=", "sorted", "(", "entropy", ")", "[", ":", ":", "-", "1", "]", "[", "int", "(", "AR", "*", "k", "*", "fold_count", "/", "N", ")", "]", "\n", "return", "threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.update_threshold_static_lambda": [[128, 131], ["None"], "function", ["None"], ["", "def", "update_threshold_static_lambda", "(", ")", ":", "\n", "    ", "threshold", "=", "0.65", "\n", "return", "threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.customize": [[133, 219], ["numpy.array", "numpy.genfromtxt", "dataset.calc_features", "sklearn.preprocessing.scale", "print", "print", "numpy.tile", "print", "print", "numpy.tile", "print", "numpy.copy", "print", "len", "numpy.arange", "enumerate", "numpy.savetxt", "customize_model.predict", "print", "os.path.join", "stream_PAL.update_data", "sorted", "open", "numpy.savetxt", "open", "numpy.savetxt", "open", "numpy.savetxt", "open", "numpy.savetxt", "open", "numpy.savetxt", "sklearn.metrics.classification_report", "stream_PAL.customize_model", "customize_model.predict", "print", "print", "print", "print", "print", "f_macro_result.append", "acc_result.append", "rec_macro_result.append", "f_result.append", "rec_result.append", "numpy.delete", "method", "method", "collections.Counter", "sklearn.metrics.classification_report", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.recall_score", "numpy.where", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_features", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.update_data", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.customize_model"], ["", "def", "customize", "(", "mdl", ",", "method", ",", "name", ",", "fold_count", ",", "participant_id", ",", "AR", "=", "60", ")", ":", "\n", "    ", "f_result", "=", "[", "]", "\n", "acc_result", "=", "[", "]", "\n", "rec_result", "=", "[", "]", "\n", "f_macro_result", "=", "[", "]", "\n", "rec_macro_result", "=", "[", "]", "\n", "threshold", "=", "0.691", "\n", "entropy", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "total_query", "=", "0", "\n", "aq", "=", "AR", "\n", "user_data", "=", "np", ".", "genfromtxt", "(", "join", "(", "'C:/Users/Marjan/Desktop/Thesis/participants_wild'", ",", "participant_id", ",", "'wrist_ss.csv'", ")", ",", "delimiter", "=", "','", ")", "\n", "user_data", "=", "user_data", "[", ":", ",", "1", ":", "]", "\n", "data", "=", "calc_features", "(", "user_data", ")", "\n", "X", "=", "preprocessing", ".", "scale", "(", "data", "[", ":", ",", ":", "(", "user_data", ".", "shape", "[", "1", "]", "-", "1", ")", "*", "9", "]", ")", "\n", "print", "(", "\"*\"", "*", "20", ")", "\n", "print", "(", "X", ".", "shape", ")", "\n", "X", "=", "np", ".", "tile", "(", "X", ",", "(", "2", ",", "1", ")", ")", "\n", "#X = np.tile(X, 10) #repeat 10 times", "\n", "print", "(", "X", ".", "shape", ")", "\n", "print", "(", "\"*\"", "*", "20", ")", "\n", "y", "=", "data", "[", ":", ",", "-", "1", "]", "\n", "y", "=", "np", ".", "tile", "(", "y", ",", "2", ")", "\n", "print", "(", "y", ".", "shape", ")", "\n", "W_Y", "=", "np", ".", "copy", "(", "y", ")", "\n", "print", "(", "W_Y", ".", "shape", ")", "\n", "\n", "N", "=", "len", "(", "X", ")", "\n", "unlabeled_indices", "=", "np", ".", "arange", "(", "N", ")", "\n", "W_Y", "[", "unlabeled_indices", "]", "=", "-", "1", "\n", "# size = int(N//fold_count)", "\n", "size", "=", "3600", "/", "3", "# number of instances per hour", "\n", "for", "k", ",", "row", "in", "enumerate", "(", "X", ")", ":", "\n", "        ", "if", "k", "%", "size", "==", "size", "-", "1", ":", "\n", "            ", "total_query", "+=", "(", "AR", "-", "aq", ")", "\n", "aq", "=", "AR", "\n", "\n", "mdl", "=", "customize_model", "(", "mdl", ",", "X", "[", ":", "k", "+", "1", "]", ",", "W_Y", "[", ":", "k", "+", "1", "]", ")", "\n", "predicted_labels", "=", "mdl", ".", "predict", "(", "X", "[", "unlabeled_indices", "]", ")", "\n", "# p = mdl.predict_proba(X[unlabeled_indices])", "\n", "# predicted_labels = [1 if x > 0.50 else 0 for x in p[:, 1]]", "\n", "\n", "true_labels", "=", "y", "[", "unlabeled_indices", "]", "\n", "from", "collections", "import", "Counter", "\n", "print", "(", "Counter", "(", "true_labels", ")", ")", "\n", "print", "(", "\"size is :: \"", "+", "str", "(", "size", ")", ")", "\n", "print", "(", "\"k is :: \"", "+", "str", "(", "k", ")", ")", "\n", "print", "(", "\"Iteration :: \"", "+", "str", "(", "(", "k", "+", "1", ")", "/", "size", ")", "+", "\" Queried :: \"", "+", "str", "(", "total_query", ")", ")", "\n", "print", "(", "classification_report", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "f_macro_result", ".", "append", "(", "f1_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'macro'", ")", ")", "\n", "acc_result", ".", "append", "(", "accuracy_score", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "rec_macro_result", ".", "append", "(", "recall_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'macro'", ")", ")", "\n", "f_result", ".", "append", "(", "f1_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'binary'", ")", ")", "\n", "rec_result", ".", "append", "(", "recall_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'binary'", ")", ")", "\n", "\n", "", "a", ",", "entropy", "=", "update_data", "(", "mdl", ",", "row", ",", "aq", ",", "entropy", ",", "threshold", ")", "\n", "if", "a", "<", "aq", ":", "\n", "            ", "aq", "=", "a", "\n", "unlabeled_indices", "=", "np", ".", "delete", "(", "unlabeled_indices", ",", "np", ".", "where", "(", "unlabeled_indices", "==", "k", ")", ")", "\n", "W_Y", "[", "k", "]", "=", "y", "[", "k", "]", "\n", "", "if", "method", ".", "__name__", "==", "'update_threshold_adaptive_lambda'", ":", "\n", "            ", "threshold", "=", "method", "(", "entropy", ",", "k", ",", "N", ",", "fold_count", ",", "AR", ")", "\n", "", "else", ":", "\n", "            ", "threshold", "=", "method", "(", ")", "\n", "# print(\"%.5f\" % threshold)", "\n", "", "", "np", ".", "savetxt", "(", "\"en.csv\"", ",", "sorted", "(", "entropy", ")", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "with", "open", "(", "\"f1_macro_score_\"", "+", "name", "+", "'_'", "+", "participant_id", "+", "\".csv\"", ",", "'wb'", ")", "as", "afile", ":", "\n", "        ", "np", ".", "savetxt", "(", "afile", ",", "f_macro_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "", "with", "open", "(", "\"accuracy_score_\"", "+", "name", "+", "'_'", "+", "participant_id", "+", "\".csv\"", ",", "'wb'", ")", "as", "afile", ":", "\n", "        ", "np", ".", "savetxt", "(", "afile", ",", "acc_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "\n", "", "with", "open", "(", "\"recall_macro_score_\"", "+", "name", "+", "'_'", "+", "participant_id", "+", "\".csv\"", ",", "'wb'", ")", "as", "afile", ":", "\n", "        ", "np", ".", "savetxt", "(", "afile", ",", "rec_macro_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "\n", "", "with", "open", "(", "\"f1_score_\"", "+", "name", "+", "'_'", "+", "participant_id", "+", "\".csv\"", ",", "'wb'", ")", "as", "afile", ":", "\n", "        ", "np", ".", "savetxt", "(", "afile", ",", "f_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "\n", "", "with", "open", "(", "\"recall_score_\"", "+", "name", "+", "'_'", "+", "participant_id", "+", "\".csv\"", ",", "'wb'", ")", "as", "afile", ":", "\n", "        ", "np", ".", "savetxt", "(", "afile", ",", "rec_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "\n", "\n", "", "predicted_labels", "=", "mdl", ".", "predict", "(", "X", "[", "unlabeled_indices", "]", ")", "\n", "# predicted_labels = [1 if x > 0.5 else 0 for x in p[:, 1]]", "\n", "\n", "true_labels", "=", "y", "[", "unlabeled_indices", "]", "\n", "print", "(", "classification_report", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.depict_uncertainty": [[223, 238], ["dataset.load_data", "print", "model.predict_proba", "print", "range", "matplotlib.scatter", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.show", "len", "numpy.sort", "print", "numpy.zeros_like", "scipy.stats.distributions.entropy"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.load_data"], ["", "def", "depict_uncertainty", "(", "model", ")", ":", "\n", "    ", "sensor_data", "=", "dataset", ".", "load_data", "(", ")", "\n", "y_validate", "=", "sensor_data", ".", "test_target", "\n", "X_validate", "=", "sensor_data", ".", "test_data", "\n", "print", "(", "len", "(", "X_validate", ")", ")", "\n", "p", "=", "model", ".", "predict_proba", "(", "X_validate", ")", "\n", "e", "=", "np", ".", "sort", "(", "stats", ".", "distributions", ".", "entropy", "(", "p", ".", "T", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "print", "(", "e", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "print", "(", "e", "[", "(", "i", "+", "1", ")", "*", "100", "]", ")", "\n", "\n", "", "plt", ".", "scatter", "(", "e", "[", ":", "100", "]", ",", "np", ".", "zeros_like", "(", "e", "[", ":", "100", "]", ")", ")", "\n", "plt", ".", "ylabel", "(", "\"Uncertainty\"", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "2", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.customize_with_perfect_lambda": [[240, 305], ["numpy.genfromtxt", "dataset.calc_features", "sklearn.preprocessing.scale", "numpy.random.RandomState", "numpy.arange", "np.random.RandomState.shuffle", "numpy.copy", "len", "numpy.arange", "int", "range", "os.path.join", "len", "numpy.array", "customize_model.predict_proba", "numpy.array", "numpy.delete", "numpy.copy", "stream_PAL.customize_model", "customize_model.predict", "print", "print", "f_result.append", "acc_result.append", "open", "numpy.savetxt", "numpy.sort", "numpy.argsort", "sklearn.metrics.classification_report", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "scipy.stats.distributions.entropy", "numpy.in1d", "numpy.where", "str", "numpy.concatenate", "int"], "function", ["home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.dataset.calc_features", "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.stream_PAL.customize_model"], ["", "def", "customize_with_perfect_lambda", "(", "mdl", ",", "name", ",", "fold_count", ",", "participant_id", ",", "AR", "=", "15", ")", ":", "\n", "    ", "f_result", "=", "[", "]", "\n", "acc_result", "=", "[", "]", "\n", "\n", "user_data", "=", "np", ".", "genfromtxt", "(", "join", "(", "'C:/Users/Marjan/Desktop/Thesis/participants_wild'", ",", "participant_id", ",", "'wrist_ss.csv'", ")", ",", "delimiter", "=", "','", ")", "\n", "user_data", "=", "user_data", "[", ":", ",", "1", ":", "]", "\n", "data", "=", "calc_features", "(", "user_data", ")", "\n", "\n", "X_n", "=", "preprocessing", ".", "scale", "(", "data", "[", ":", ",", ":", "(", "user_data", ".", "shape", "[", "1", "]", "-", "1", ")", "*", "9", "]", ")", "\n", "y_n", "=", "data", "[", ":", ",", "-", "1", "]", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "X_n", ")", ")", "\n", "rng", ".", "shuffle", "(", "indices", ")", "\n", "X", ",", "y", "=", "X_n", "[", "indices", "[", ":", "]", "]", ",", "y_n", "[", "indices", "[", ":", "]", "]", "\n", "W_Y", "=", "np", ".", "copy", "(", "y", ")", "\n", "N", "=", "len", "(", "X", ")", "\n", "unlabeled_indices", "=", "np", ".", "arange", "(", "N", ")", "\n", "W_Y", "[", "unlabeled_indices", "]", "=", "-", "1", "\n", "size", "=", "int", "(", "N", "//", "fold_count", ")", "\n", "for", "i", "in", "range", "(", "fold_count", ")", ":", "\n", "        ", "current_X", "=", "np", ".", "array", "(", "X", "[", "i", "*", "size", ":", "(", "i", "+", "1", ")", "*", "size", "]", ")", "\n", "# current_Y = W_Y[i*size: (i+1)*size]", "\n", "p", "=", "mdl", ".", "predict_proba", "(", "current_X", ")", "\n", "e", "=", "np", ".", "sort", "(", "stats", ".", "distributions", ".", "entropy", "(", "p", ".", "T", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "# select up to 5 digit examples that the classifier is most uncertain about", "\n", "uncertainty_index", "=", "np", ".", "argsort", "(", "e", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "uncertainty_index", "=", "uncertainty_index", "[", "\n", "np", ".", "in1d", "(", "uncertainty_index", ",", "unlabeled_indices", ")", "]", "\n", "\n", "# keep track of indices that we get labels for", "\n", "delete_indices", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "eating_counter", "=", "0", "\n", "non_eating_counter", "=", "0", "\n", "for", "index", "in", "uncertainty_index", ":", "\n", "            ", "if", "eating_counter", "+", "non_eating_counter", "<", "AR", ":", "\n", "                ", "delete_index", ",", "=", "np", ".", "where", "(", "unlabeled_indices", "==", "index", ")", "\n", "\n", "is_changed", "=", "False", "\n", "if", "y", "[", "delete_index", "]", "==", "0", "and", "non_eating_counter", "<", "int", "(", "0.5", "*", "AR", ")", ":", "\n", "                    ", "non_eating_counter", "+=", "1", "\n", "is_changed", "=", "True", "\n", "", "elif", "y", "[", "delete_index", "]", "==", "1", ":", "\n", "                    ", "eating_counter", "+=", "1", "\n", "is_changed", "=", "True", "\n", "", "if", "is_changed", ":", "\n", "                    ", "delete_indices", "=", "np", ".", "concatenate", "(", "(", "delete_indices", ",", "delete_index", ")", ")", "\n", "\n", "\n", "", "", "", "unlabeled_indices", "=", "np", ".", "delete", "(", "unlabeled_indices", ",", "delete_indices", ")", "\n", "\n", "W_Y", "=", "np", ".", "copy", "(", "y", ")", "\n", "W_Y", "[", "unlabeled_indices", "]", "=", "-", "1", "\n", "mdl", "=", "customize_model", "(", "mdl", ",", "X", "[", ":", "(", "i", "+", "1", ")", "*", "size", "]", ",", "W_Y", "[", ":", "(", "i", "+", "1", ")", "*", "size", "]", ")", "\n", "# p = mdl.predict_proba(X[unlabeled_indices])", "\n", "# predicted_labels = [1 if x > 0.50 else 0 for x in p[:, 1]]", "\n", "predicted_labels", "=", "mdl", ".", "predict", "(", "X", "[", "unlabeled_indices", "]", ")", "\n", "true_labels", "=", "y", "[", "unlabeled_indices", "]", "\n", "print", "(", "\"Iteration :: \"", "+", "str", "(", "(", "i", "+", "1", ")", ")", ")", "\n", "print", "(", "classification_report", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "f_result", ".", "append", "(", "f1_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'binary'", ")", ")", "\n", "acc_result", ".", "append", "(", "accuracy_score", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "", "with", "open", "(", "\"f1_score_\"", "+", "name", "+", "'_'", "+", "participant_id", "+", "\".csv\"", ",", "'wb'", ")", "as", "afile", ":", "\n", "        ", "np", ".", "savetxt", "(", "afile", ",", "f_result", ",", "delimiter", "=", "\",\"", ",", "fmt", "=", "'%10.5f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.marjan-nourollahi_PALS.None.Active_Learning_SVM.explore": [[37, 128], ["len", "range", "numpy.arange", "numpy.setdiff1d", "mdl.fit", "mdl.predict", "sklearn.metrics.confusion_matrix", "mdl.predict_proba", "stats.distributions.entropy", "numpy.array", "enumerate", "numpy.delete", "len", "len", "print", "numpy.arange", "mdl", "mdl", "print", "print", "print", "print", "f_result.append", "acc_result.append", "recall_result.append", "print", "print", "numpy.argsort", "numpy.where", "numpy.concatenate", "sklearn.metrics.classification_report", "sklearn.metrics.accuracy_score", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "sklearn.metrics.recall_score", "numpy.in1d"], "function", ["None"], ["def", "explore", "(", "X", ",", "y", ",", "file_name", ",", "mdl", ",", "d", "=", "None", ")", ":", "\n", "    ", "n_total_samples", "=", "len", "(", "y", ")", "\n", "n_labeled_points", "=", "300", "\n", "max_iterations", "=", "1", "\n", "\n", "unlabeled_indices", "=", "np", ".", "arange", "(", "n_total_samples", ")", "[", "n_labeled_points", ":", "]", "\n", "f_result", "=", "[", "]", "\n", "acc_result", "=", "[", "]", "\n", "recall_result", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "max_iterations", ")", ":", "\n", "        ", "if", "len", "(", "unlabeled_indices", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"No unlabeled items left to label.\"", ")", "\n", "break", "\n", "", "h", "=", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "n_total_samples", ")", ",", "unlabeled_indices", ",", "assume_unique", "=", "True", ")", "\n", "y_train", "=", "y", "[", "h", "]", "\n", "X_train", "=", "X", "[", "h", "]", "\n", "\n", "\n", "# model = SVC(gamma=2, C=1)", "\n", "# model = linear_model.LogisticRegression()", "\n", "# model = QuadraticDiscriminantAnalysis()#KNeighborsClassifier(3)", "\n", "# model  = AdaBoostClassifier()", "\n", "# model = RandomForestClassifier( n_estimators=185)", "\n", "if", "d", "!=", "None", ":", "\n", "            ", "model", "=", "mdl", "(", "**", "d", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "mdl", "(", ")", "\n", "", "model", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "\n", "# predicted_labels = lp_model.transduction_[unlabeled_indices]", "\n", "\n", "#      SVC(kernel=\"linear\", C=0.025),", "\n", "#     SVC(gamma=2, C=1),", "\n", "# GaussianProcessClassifier(1.0 * RBF(1.0)),", "\n", "# # DecisionTreeClassifier(max_depth=5),", "\n", "# # RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),", "\n", "# # AdaBoostClassifier(),", "\n", "# # GaussianNB(),", "\n", "# QuadraticDiscriminantAnalysis(),", "\n", "predicted_labels", "=", "model", ".", "predict", "(", "X", "[", "unlabeled_indices", "]", ")", "\n", "true_labels", "=", "y", "[", "unlabeled_indices", "]", "\n", "\n", "cm", "=", "confusion_matrix", "(", "true_labels", ",", "predicted_labels", ",", "\n", "labels", "=", "model", ".", "classes_", ")", "\n", "\n", "if", "i", "%", "1", "==", "0", ":", "\n", "            ", "print", "(", "\"Iteration %i %s\"", "%", "(", "i", ",", "70", "*", "\"_\"", ")", ")", "\n", "\n", "print", "(", "classification_report", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "print", "(", "accuracy_score", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "print", "(", "f1_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'binary'", ")", ")", "\n", "f_result", ".", "append", "(", "f1_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'binary'", ")", ")", "\n", "acc_result", ".", "append", "(", "accuracy_score", "(", "true_labels", ",", "predicted_labels", ")", ")", "\n", "recall_result", ".", "append", "(", "recall_score", "(", "true_labels", ",", "predicted_labels", ",", "average", "=", "'macro'", ")", ")", "\n", "\n", "\n", "print", "(", "\"Confusion matrix\"", ")", "\n", "print", "(", "cm", ")", "\n", "", "from", "scipy", "import", "stats", "\n", "# compute the entropies of transduced label distributions", "\n", "\n", "# model.predict(X)", "\n", "p", "=", "model", ".", "predict_proba", "(", "X", ")", "\n", "e", "=", "stats", ".", "distributions", ".", "entropy", "(", "p", ".", "T", ")", "\n", "# pred_entropies = stats.distributions.entropy(", "\n", "#     model.p)", "\n", "# uncertainty_index = np.argsort(pred_entropies)[::-1]", "\n", "\n", "# pred_decision_function = np.abs([x for x in model.decision_function(X)])", "\n", "\n", "\n", "# select up to 5 digit examples that the classifier is most uncertain about", "\n", "# uncertainty_index = np.argsort(model.decision_function(X))[::-1]", "\n", "uncertainty_index", "=", "np", ".", "argsort", "(", "e", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "# print(unlabeled_indices.shape)", "\n", "# print(uncertainty_index[:10])", "\n", "#", "\n", "uncertainty_index", "=", "uncertainty_index", "[", "\n", "np", ".", "in1d", "(", "uncertainty_index", ",", "unlabeled_indices", ")", "]", "[", ":", "40", "]", "\n", "\n", "\n", "# keep track of indices that we get labels for", "\n", "delete_indices", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "index", ",", "image_index", "in", "enumerate", "(", "uncertainty_index", ")", ":", "\n", "# labeling 5 points, remote from labeled set", "\n", "            ", "delete_index", ",", "=", "np", ".", "where", "(", "unlabeled_indices", "==", "image_index", ")", "\n", "delete_indices", "=", "np", ".", "concatenate", "(", "(", "delete_indices", ",", "delete_index", ")", ")", "\n", "", "unlabeled_indices", "=", "np", ".", "delete", "(", "unlabeled_indices", ",", "delete_indices", ")", "\n", "n_labeled_points", "+=", "len", "(", "uncertainty_index", ")", "\n", "\n"]]}