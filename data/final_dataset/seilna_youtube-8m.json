{"home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.FrameLevelLogisticModel.create_model": [[65, 97], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_input.get_shape().as_list", "tensorflow.tile", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "model_input.get_shape"], "methods", ["None"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a logistic classifier over the average of the\n    frame-level features.\n\n    This class is intended to be an example for implementors of frame level\n    models. If you want to train a model over averaged features it is more\n    efficient to average them beforehand rather than on the fly.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                   input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n           frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "\n", "denominators", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "num_frames", ",", "[", "1", ",", "feature_size", "]", ")", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "avg_pooled", "=", "tf", ".", "reduce_sum", "(", "model_input", ",", "\n", "axis", "=", "[", "1", "]", ")", "/", "denominators", "\n", "\n", "output", "=", "slim", ".", "fully_connected", "(", "\n", "avg_pooled", ",", "vocab_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "1e-8", ")", ")", "\n", "return", "{", "\"predictions\"", ":", "output", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.DbofModel.create_model": [[121, 209], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.reshape", "tensorflow.reshape", "model_utils.FramePooling", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_utils.SampleRandomFrames", "model_utils.SampleRandomSequence", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.random_normal", "tensorflow.random_normal", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.model_utils.FramePooling", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.model_utils.SampleRandomSequence"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_frames", ",", "\n", "iterations", "=", "None", ",", "\n", "add_batch_norm", "=", "None", ",", "\n", "sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "dbof_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "dbof_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "dbof_hidden_size", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "random_frames", ":", "\n", "      ", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "      ", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"input_hist\"", ",", "reshaped_input", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "      ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "feature_size", ",", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_output\"", ",", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "max_frames", ",", "cluster_size", "]", ")", "\n", "activation", "=", "utils", ".", "FramePooling", "(", "activation", ",", "FLAGS", ".", "dbof_pooling_method", ")", "\n", "\n", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\"hidden1_weights\"", ",", "\n", "[", "cluster_size", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_weights\"", ",", "hidden1_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "activation", ",", "hidden1_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\"hidden1_biases\"", ",", "\n", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_output\"", ",", "activation", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.LayerNormLstmAveConcatModel.create_model": [[212, 239], ["tensorflow.contrib.rnn.LayerNormBasicLSTMCell", "tensorflow.contrib.rnn.LayerNormBasicLSTMCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.concat", "tensorflow.concat", "getattr", "getattr.create_model", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "getattr."], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "stacked_lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LayerNormBasicLSTMCell", "(", "\n", "num_units", "=", "lstm_size", ",", "\n", "dropout_keep_prob", "=", "FLAGS", ".", "dropout", ")", "\n", "\n", "loss", "=", "0.0", "\n", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "stacked_lstm", ",", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "state", "=", "tf", ".", "concat", "(", "[", "state", "[", "0", "]", ",", "state", "[", "1", "]", "]", ",", "1", ")", "\n", "\n", "average_state", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "tf", ".", "reduce_sum", "(", "model_input", ",", "axis", "=", "1", ")", ",", "dim", "=", "1", ")", "\n", "state", "=", "tf", ".", "concat", "(", "[", "state", ",", "average_state", "]", ",", "1", ")", "\n", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.LstmModel.create_model": [[243, 281], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "getattr", "getattr.create_model", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a stack of LSTMs to represent the video.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                   input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n           frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "stacked_lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "\n", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "lstm_size", ",", "forget_bias", "=", "1.0", ",", "state_is_tuple", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ",", "state_is_tuple", "=", "False", ")", "\n", "\n", "loss", "=", "0.0", "\n", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "stacked_lstm", ",", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.ContextMemoryModel.create_model": [[284, 314], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.concat", "tensorflow.concat", "getattr", "getattr.create_model", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "1", "\n", "\n", "stacked_lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "\n", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "lstm_size", ",", "forget_bias", "=", "1.0", ",", "state_is_tuple", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ",", "state_is_tuple", "=", "False", ")", "\n", "\n", "loss", "=", "0.0", "\n", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "stacked_lstm", ",", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "context_memory", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "tf", ".", "reduce_sum", "(", "outputs", ",", "axis", "=", "1", ")", ",", "dim", "=", "1", ")", "\n", "average_state", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "tf", ".", "reduce_sum", "(", "model_input", ",", "axis", "=", "1", ")", ",", "dim", "=", "1", ")", "\n", "#state = tf.concat([state[0], state[1]], 1)", "\n", "\n", "final_state", "=", "tf", ".", "concat", "(", "[", "context_memory", ",", "state", ",", "average_state", "]", ",", "1", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "final_state", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.Many2ManyLstmModel.create_model": [[318, 338], ["tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "lstm_size", ")", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "cell", ",", "\n", "inputs", "=", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "parallel_iterations", "=", "128", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "# output = (batch, num_frames, lstm_size)", "\n", "\n", "class_per_output", "=", "slim", ".", "fully_connected", "(", "\n", "outputs", ",", "\n", "4716", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "1e-8", ")", ")", "# (batch, num_frames, 4716)", "\n", "\n", "final_probabilities", "=", "tf", ".", "reduce_mean", "(", "class_per_output", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.PositionEncodingModel.create_model": [[341, 376], ["tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "getattr", "getattr.create_model", "range", "tensorflow.random_normal", "tensorflow.random_normal", "getattr.", "range"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a stack of LSTMs to represent the video.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                   input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n           frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "\n", "J", "=", "300", "\n", "d", "=", "FLAGS", ".", "feature_dim", "\n", "\n", "# PE matrix", "\n", "l", "=", "[", "[", "(", "1", "-", "j", "/", "J", ")", "-", "(", "k", "/", "d", ")", "*", "(", "1", "-", "2", "*", "j", "/", "J", ")", "for", "k", "in", "range", "(", "d", ")", "]", "for", "j", "in", "range", "(", "J", ")", "]", "\n", "\n", "# Adding Gaussian Noise", "\n", "state", "=", "model_input", "+", "FLAGS", ".", "gaussian_noise", "*", "tf", ".", "random_normal", "(", "shape", "=", "[", "J", ",", "d", "]", ")", "\n", "state", "=", "tf", ".", "reduce_sum", "(", "state", "*", "l", ",", "axis", "=", "1", ")", "\n", "state", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "state", ",", "dim", "=", "1", ",", "epsilon", "=", "1e-6", ")", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.BiLstmModel.create_model": [[379, 429], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat", "tensorflow.concat", "getattr", "getattr.create_model", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range", "range"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a stack of LSTMs to represent the video.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                   input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n           frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "stacked_lstm_fw", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "\n", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "lstm_size", ",", "forget_bias", "=", "1.0", ",", "state_is_tuple", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ",", "state_is_tuple", "=", "False", ")", "\n", "\n", "stacked_lstm_bw", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "\n", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "lstm_size", ",", "forget_bias", "=", "1.0", ",", "state_is_tuple", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ",", "state_is_tuple", "=", "False", ")", "\n", "\n", "\n", "loss", "=", "0.0", "\n", "\n", "output", ",", "state", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "cell_fw", "=", "stacked_lstm_fw", ",", "\n", "cell_bw", "=", "stacked_lstm_bw", ",", "\n", "inputs", "=", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "state", "=", "tf", ".", "concat", "(", "[", "state", "[", "0", "]", ",", "state", "[", "1", "]", "]", ",", "1", ")", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "", "", "class", "ordinalTopK", "(", "models", ".", "BaseModel", ")", ":", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.ordinalTopK.create_model": [[430, 464], ["tensorflow.nn.moments", "tensorflow.nn.moments", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.nn.top_k", "tensorflow.nn.top_k", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.concat", "tensorflow.concat", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape.set_shape", "getattr", "getattr.create_model", "getattr."], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a ordinal TopK to represent the video.\n    Args:\n    model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                  input features.\n    vocab_size: The number of classes in the dataset.\n    num_frames: A vector of length 'batch' which indicates the number of\n      frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "\n", "num_features", "=", "FLAGS", ".", "feature_dim", "\n", "k", "=", "FLAGS", ".", "topk", "\n", "mean", ",", "var", "=", "tf", ".", "nn", ".", "moments", "(", "x", "=", "model_input", ",", "axes", "=", "[", "1", "]", ",", "keep_dims", "=", "True", ")", "# [batch_size, 1, num_featuers]", "\n", "model_input_trans", "=", "tf", ".", "transpose", "(", "a", "=", "model_input", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "# [batch_size, num_features, max_frames]", "\n", "topk", ",", "indices", "=", "tf", ".", "nn", ".", "top_k", "(", "input", "=", "model_input_trans", ",", "k", "=", "k", ",", "sorted", "=", "True", ")", "# topk: [batch_size, num_features, k]", "\n", "topk_trans", "=", "tf", ".", "transpose", "(", "a", "=", "topk", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "# [batch_size, k, num_features]", "\n", "topk_trans", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "topk_trans", ",", "dim", "=", "2", ")", "\n", "\n", "concat", "=", "tf", ".", "concat", "(", "[", "mean", ",", "var", ",", "topk_trans", "]", ",", "1", ")", "# [batch_size, k+2, num_features]", "\n", "concat_flat", "=", "tf", ".", "reshape", "(", "concat", ",", "shape", "=", "[", "-", "1", ",", "(", "k", "+", "2", ")", "*", "num_features", "]", ")", "# [batch_size, (k+2) * num_featuers]", "\n", "#concat_flat = tf.nn.l2_normalize(concat_flat, dim=1)", "\n", "concat_flat", ".", "set_shape", "(", "[", "None", ",", "(", "k", "+", "2", ")", "*", "num_features", "]", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "concat_flat", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.CNN.create_model": [[466, 502], ["tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.contrib.layers.conv2d", "tensorflow.contrib.layers.conv2d", "tensorflow.contrib.layers.max_pool2d", "tensorflow.contrib.layers.max_pool2d", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "getattr", "getattr.create_model", "getattr."], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "max_frames", "=", "300", "\n", "model_input", "=", "tf", ".", "expand_dims", "(", "model_input", ",", "-", "1", ")", "# [batch_size, max_frames, num_features, 1]", "\n", "num_channels", "=", "FLAGS", ".", "num_channels", "\n", "\n", "kernel_height", "=", "FLAGS", ".", "kernel_height", "\n", "kernel_width", "=", "FLAGS", ".", "kernel_width", "\n", "\n", "# [batch_size, max_frames - k, 1, num_channels]", "\n", "cnn_activation", "=", "tf", ".", "contrib", ".", "layers", ".", "conv2d", "(", "\n", "inputs", "=", "model_input", ",", "\n", "num_outputs", "=", "num_channels", ",", "\n", "kernel_size", "=", "[", "kernel_height", ",", "kernel_width", "]", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "\"VALID\"", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "\n", "#cnn_activation = tf.nn.l2_normalize(cnn_activation, dim=3)", "\n", "\n", "# [batch_size, 1, 1, num_channels]", "\n", "max_pool_over_time", "=", "tf", ".", "contrib", ".", "layers", ".", "max_pool2d", "(", "\n", "inputs", "=", "cnn_activation", ",", "\n", "kernel_size", "=", "[", "max_frames", "-", "kernel_height", "+", "1", ",", "1", "]", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "\"VALID\"", ")", "\n", "\n", "state", "=", "tf", ".", "reshape", "(", "max_pool_over_time", ",", "shape", "=", "[", "-", "1", ",", "num_channels", "]", ")", "\n", "state", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "state", ",", "dim", "=", "1", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.Lstm_average_concat.create_model": [[504, 543], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "tensorflow.concat", "tensorflow.concat", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.cast", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range", "tensorflow.range", "tensorflow.range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "if", "FLAGS", ".", "position_encoding", "==", "True", ":", "\n", "      ", "J", "=", "300", "\n", "d", "=", "1152", "\n", "l", "=", "[", "[", "(", "1", "-", "j", "/", "J", ")", "-", "(", "k", "/", "d", ")", "*", "(", "1", "-", "2", "*", "j", "/", "J", ")", "for", "k", "in", "range", "(", "d", ")", "]", "for", "j", "in", "range", "(", "J", ")", "]", "\n", "model_input", "=", "model_input", "*", "l", "\n", "\n", "", "if", "FLAGS", ".", "interpolate", "==", "True", ":", "\n", "      ", "interpolate", "=", "tf", ".", "cast", "(", "tf", ".", "range", "(", "300", ")", ",", "tf", ".", "float32", ")", "/", "300.0", "\n", "interpolate", "=", "tf", ".", "expand_dims", "(", "interpolate", ",", "0", ")", "\n", "interpolate", "=", "tf", ".", "expand_dims", "(", "interpolate", ",", "2", ")", "# (1, 300, 1)", "\n", "model_input", "=", "model_input", "*", "interpolate", "\n", "", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "stacked_lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "\n", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "lstm_size", ",", "forget_bias", "=", "1.0", ",", "state_is_tuple", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ",", "state_is_tuple", "=", "False", ")", "\n", "\n", "loss", "=", "0.0", "\n", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "stacked_lstm", ",", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "#state = tf.nn.l2_normalize(state, dim=1)", "\n", "average_state", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "tf", ".", "reduce_sum", "(", "model_input", ",", "axis", "=", "1", ")", ",", "dim", "=", "1", ")", "\n", "state", "=", "tf", ".", "concat", "(", "[", "state", ",", "average_state", "]", ",", "1", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.SoftClusteringModel.create_model": [[545, 577], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.contrib.layers.layer_norm", "tensorflow.contrib.layers.layer_norm", "getattr", "getattr.create_model", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "getattr."], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "input_features", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "FLAGS", ".", "feature_dim", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "1e-8", ")", "\n", ")", "\n", "\n", "att_matrix", "=", "tf", ".", "matmul", "(", "input_features", ",", "tf", ".", "transpose", "(", "input_features", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# [batch_size, max_frames, max_frames]", "\n", "\n", "att_matrix", "=", "tf", ".", "expand_dims", "(", "att_matrix", ",", "-", "1", ")", "\n", "att", "=", "tf", ".", "reduce_sum", "(", "att_matrix", ",", "axis", "=", "2", ")", "# [batch_size, max_frames]", "\n", "att", "=", "tf", ".", "nn", ".", "softmax", "(", "FLAGS", ".", "alpha", "*", "att", ")", "\n", "\n", "state", "=", "tf", ".", "reduce_sum", "(", "model_input", "*", "att", ",", "axis", "=", "1", ")", "# [batch_size, num_features]", "\n", "state", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "\n", "inputs", "=", "state", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "trainable", "=", "True", ")", "\n", "\n", "\n", "#state = tf.nn.l2_normalize(state, dim=1)", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.frame_level_models.RnnFvModel.create_model": [[580, 622], ["tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.concat", "tensorflow.concat", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.fully_connected", "tensorflow.fully_connected", "model_input.get_shape().as_list", "model_input.get_shape().as_list", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "model_input.get_shape", "model_input.get_shape"], "methods", ["None"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a LSTM to predict the next element of the sequence.\n    using derived gradient from the RNN as a vector representation,\n    instead of using a hidden or an output layer of the RNN\n    model_input: A 'batch_size' x 'sequence_length' x 'feature_size' matrix \n    \"\"\"", "\n", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "sequence_length", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "# start_token is important!", "\n", "start_token", "=", "tf", ".", "zeros_like", "(", "tf", ".", "expand_dims", "(", "model_input", "[", ":", ",", "0", ",", ":", "]", ",", "axis", "=", "1", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_sequence", "=", "tf", ".", "concat", "(", "[", "start_token", ",", "model_input", "[", ":", ",", ":", "-", "1", ",", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "output_sequence", "=", "model_input", "[", ":", ",", ":", ",", ":", "]", "\n", "\n", "# fc-relu", "\n", "# input_sequence = tf.reshape(input_sequence, [-1, feature_size])", "\n", "# fc1 = tf.contrib.layers.fully_connected(input_sequence, lstm_size, activation_fn=tf.nn.relu)", "\n", "# input_sequence = tf.reshape(fc1, [-1, sequence_length, lstm_size])", "\n", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "lstm_size", ")", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "cell", ",", "\n", "inputs", "=", "input_sequence", ",", "\n", "sequence_length", "=", "None", ",", "\n", "parallel_iterations", "=", "128", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "# output = (batch, num_frames, lstm_size)", "\n", "\n", "# fc-linear", "\n", "outputs", "=", "tf", ".", "reshape", "(", "outputs", ",", "[", "-", "1", ",", "lstm_size", "]", ")", "\n", "fc2", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "outputs", ",", "feature_size", ",", "activation_fn", "=", "None", ")", "\n", "outputs", "=", "tf", ".", "reshape", "(", "fc2", ",", "[", "-", "1", ",", "sequence_length", ",", "feature_size", "]", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "l2_loss", "(", "outputs", "-", "output_sequence", ")", "\n", "\n", "dummy_pooled", "=", "tf", ".", "reduce_sum", "(", "model_input", ",", "axis", "=", "[", "1", "]", ")", "\n", "dummy_output", "=", "slim", ".", "fully_connected", "(", "\n", "dummy_pooled", ",", "vocab_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "1e-8", ")", ")", "\n", "\n", "return", "{", "\"predictions\"", ":", "dummy_output", ",", "\"loss\"", ":", "loss", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.__init__": [[64, 82], ["ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "top_n", "=", "None", ")", ":", "\n", "    ", "\"\"\"Construct an AveragePrecisionCalculator to calculate average precision.\n\n    This class is used to calculate the average precision for a single label.\n\n    Args:\n      top_n: A positive Integer specifying the average precision at n, or\n        None to use all provided data points.\n\n    Raises:\n      ValueError: An error occurred when the top_n is not a positive integer.\n    \"\"\"", "\n", "if", "not", "(", "(", "isinstance", "(", "top_n", ",", "int", ")", "and", "top_n", ">=", "0", ")", "or", "top_n", "is", "None", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"top_n must be a positive integer or None.\"", ")", "\n", "\n", "", "self", ".", "_top_n", "=", "top_n", "# average precision at n", "\n", "self", ".", "_total_positives", "=", "0", "# total number of positives have seen", "\n", "self", ".", "_heap", "=", "[", "]", "# max heap of (prediction, actual)", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.heap_size": [[83, 87], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "heap_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the heap size maintained in the class.\"\"\"", "\n", "return", "len", "(", "self", ".", "_heap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.num_accumulated_positives": [[88, 92], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_accumulated_positives", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the number of positive samples that have been accumulated.\"\"\"", "\n", "return", "self", ".", "_total_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.accumulate": [[93, 133], ["range", "len", "len", "ValueError", "numpy.size", "numpy.size", "ValueError", "numpy.where", "heapq.heappush", "isinstance", "len", "heapq.heappop", "heapq.heappush"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    After the function call, we may call peek_ap_at_n to actually calculate\n    the average precision.\n    Note predictions and actuals must have the same shape.\n\n    Args:\n      predictions: a list storing the prediction scores.\n      actuals: a list storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives = If the 'predictions' and 'actuals' inputs aren't complete,\n      then it's possible some true positives were missed in them. In that case,\n      you can provide 'num_positives' in order to accurately track recall.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "not", "num_positives", "is", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "num_positives", ",", "numbers", ".", "Number", ")", "or", "num_positives", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"'num_positives' was provided but it wan't a nonzero number.\"", ")", "\n", "\n", "", "", "if", "not", "num_positives", "is", "None", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "num_positives", "\n", "", "else", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "topk", "=", "self", ".", "_top_n", "\n", "heap", "=", "self", ".", "_heap", "\n", "\n", "for", "i", "in", "range", "(", "numpy", ".", "size", "(", "predictions", ")", ")", ":", "\n", "      ", "if", "topk", "is", "None", "or", "len", "(", "heap", ")", "<", "topk", ":", "\n", "        ", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "predictions", "[", "i", "]", ">", "heap", "[", "0", "]", "[", "0", "]", ":", "# heap[0] is the smallest", "\n", "          ", "heapq", ".", "heappop", "(", "heap", ")", "\n", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.clear": [[134, 138], ["None"], "methods", ["None"], ["", "", "", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the accumulated predictions.\"\"\"", "\n", "self", ".", "_heap", "=", "[", "]", "\n", "self", ".", "_total_positives", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n": [[139, 156], ["numpy.array", "average_precision_calculator.AveragePrecisionCalculator.ap_at_n", "list", "zip"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "def", "peek_ap_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated average precision at n.\n\n    Returns:\n      The non-interpolated average precision at n (default 0).\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n    \"\"\"", "\n", "if", "self", ".", "heap_size", "<=", "0", ":", "\n", "      ", "return", "0", "\n", "", "predlists", "=", "numpy", ".", "array", "(", "list", "(", "zip", "(", "*", "self", ".", "_heap", ")", ")", ")", "\n", "\n", "ap", "=", "self", ".", "ap_at_n", "(", "predlists", "[", "0", "]", ",", "\n", "predlists", "[", "1", "]", ",", "\n", "n", "=", "self", ".", "_top_n", ",", "\n", "total_num_positives", "=", "self", ".", "_total_positives", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.ap": [[157, 178], ["average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "@", "staticmethod", "\n", "def", "ap", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "return", "AveragePrecisionCalculator", ".", "ap_at_n", "(", "predictions", ",", "\n", "actuals", ",", "\n", "n", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.ap_at_n": [[179, 246], ["numpy.array", "numpy.array", "average_precision_calculator.AveragePrecisionCalculator._shuffle", "sorted", "len", "range", "len", "len", "ValueError", "range", "numpy.size", "min", "min", "ValueError", "len", "numpy.where", "isinstance"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator._shuffle"], ["", "@", "staticmethod", "\n", "def", "ap_at_n", "(", "predictions", ",", "actuals", ",", "n", "=", "20", ",", "total_num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      n: the top n items to be considered in ap@n.\n      total_num_positives : (optionally) you can specify the number of total\n        positive\n      in the list. If specified, it will be used in calculation.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when\n      1) the format of the input is not the numpy 1-D array;\n      2) the shape of predictions and actuals does not match;\n      3) the input n is not a positive integer.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "n", ",", "int", ")", "or", "n", "<=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"n must be 'None' or a positive integer.\"", "\n", "\" It was '%s'.\"", "%", "n", ")", "\n", "\n", "", "", "ap", "=", "0.0", "\n", "\n", "predictions", "=", "numpy", ".", "array", "(", "predictions", ")", "\n", "actuals", "=", "numpy", ".", "array", "(", "actuals", ")", "\n", "\n", "# add a shuffler to avoid overestimating the ap", "\n", "predictions", ",", "actuals", "=", "AveragePrecisionCalculator", ".", "_shuffle", "(", "predictions", ",", "\n", "actuals", ")", "\n", "sortidx", "=", "sorted", "(", "\n", "range", "(", "len", "(", "predictions", ")", ")", ",", "\n", "key", "=", "lambda", "k", ":", "predictions", "[", "k", "]", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "if", "total_num_positives", "is", "None", ":", "\n", "      ", "numpos", "=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "else", ":", "\n", "      ", "numpos", "=", "total_num_positives", "\n", "\n", "", "if", "numpos", "==", "0", ":", "\n", "      ", "return", "0", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "numpos", "=", "min", "(", "numpos", ",", "n", ")", "\n", "", "delta_recall", "=", "1.0", "/", "numpos", "\n", "poscount", "=", "0.0", "\n", "\n", "# calculate the ap", "\n", "r", "=", "len", "(", "sortidx", ")", "\n", "if", "n", "is", "not", "None", ":", "\n", "      ", "r", "=", "min", "(", "r", ",", "n", ")", "\n", "", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "      ", "if", "actuals", "[", "sortidx", "[", "i", "]", "]", ">", "0", ":", "\n", "        ", "poscount", "+=", "1", "\n", "ap", "+=", "poscount", "/", "(", "i", "+", "1", ")", "*", "delta_recall", "\n", "", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator._shuffle": [[247, 254], ["random.seed", "random.sample", "range", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_shuffle", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "random", ".", "seed", "(", "0", ")", "\n", "suffidx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "predictions", ")", ")", ",", "len", "(", "predictions", ")", ")", "\n", "predictions", "=", "predictions", "[", "suffidx", "]", "\n", "actuals", "=", "actuals", "[", "suffidx", "]", "\n", "return", "predictions", ",", "actuals", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator._zero_one_normalize": [[255, 275], ["numpy.max", "numpy.min", "numpy.max", "numpy.min"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_zero_one_normalize", "(", "predictions", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"Normalize the predictions to the range between 0.0 and 1.0.\n\n    For some predictions like SVM predictions, we need to normalize them before\n    calculate the interpolated average precision. The normalization will not\n    change the rank in the original list and thus won't change the average\n    precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      epsilon: a small constant to avoid denominator being zero.\n\n    Returns:\n      The normalized prediction.\n    \"\"\"", "\n", "denominator", "=", "numpy", ".", "max", "(", "predictions", ")", "-", "numpy", ".", "min", "(", "predictions", ")", "\n", "ret", "=", "(", "predictions", "-", "numpy", ".", "min", "(", "predictions", ")", ")", "/", "numpy", ".", "max", "(", "denominator", ",", "\n", "epsilon", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model": [[20, 22], ["NotImplementedError"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "unused_model_input", ",", "**", "unused_params", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.BaseReader.prepare_reader": [[72, 75], ["NotImplementedError"], "methods", ["None"], ["def", "prepare_reader", "(", "self", ",", "unused_filename_queue", ")", ":", "\n", "    ", "\"\"\"Create a thread for generating prediction and label tensors.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MAggregatedFeatureReader.__init__": [[85, 104], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", "=", "4716", ",", "\n", "feature_sizes", "=", "[", "1024", "]", ",", "\n", "feature_names", "=", "[", "\"mean_inc3\"", "]", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MAggregatedFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MAggregatedFeatureReader.prepare_reader": [[105, 119], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read_up_to", "tensorflow.add_to_collection", "readers.YT8MAggregatedFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "filename_queue", ",", "batch_size", "=", "1024", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for pre-aggregated YouTube 8M Examples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n\n    Returns:\n      A tuple of video indexes, features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_examples", "=", "reader", ".", "read_up_to", "(", "filename_queue", ",", "batch_size", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"serialized_examples\"", ",", "serialized_examples", ")", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MAggregatedFeatureReader.prepare_serialized_examples": [[120, 160], ["len", "range", "tensorflow.parse_example", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.sparse_to_indicator", "tensorflow.sparse_to_indicator.set_shape", "tensorflow.add_to_collection", "len", "len", "len", "len", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenFeature", "tensorflow.concat", "tensorflow.ones", "cbp.compact_bilinear_pooling.compact_bilinear_pooling_layer", "tensorflow.nn.l2_normalize.set_shape", "tensorflow.nn.l2_normalize", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.random_normal", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling.compact_bilinear_pooling_layer"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_examples", ")", ":", "\n", "# set the mapping from the fields to data types in the proto", "\n", "    ", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"self.feature_names is empty!\"", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "feature_map", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_map", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "self", ".", "feature_sizes", "[", "feature_index", "]", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "", "features", "=", "tf", ".", "parse_example", "(", "serialized_examples", ",", "features", "=", "feature_map", ")", "\n", "tf", ".", "add_to_collection", "(", "\"features\"", ",", "features", ")", "\n", "tf", ".", "add_to_collection", "(", "\"mean_rgb\"", ",", "features", "[", "\"mean_rgb\"", "]", ")", "\n", "tf", ".", "add_to_collection", "(", "\"mean_audio\"", ",", "features", "[", "\"mean_audio\"", "]", ")", "\n", "\n", "labels", "=", "tf", ".", "sparse_to_indicator", "(", "features", "[", "\"labels\"", "]", ",", "self", ".", "num_classes", ")", "\n", "labels", ".", "set_shape", "(", "[", "None", ",", "self", ".", "num_classes", "]", ")", "\n", "\n", "if", "FLAGS", ".", "cbp", "==", "False", ":", "\n", "      ", "concatenated_features", "=", "tf", ".", "concat", "(", "[", "\n", "features", "[", "feature_name", "]", "for", "feature_name", "in", "self", ".", "feature_names", "]", ",", "1", ")", "\n", "", "elif", "FLAGS", ".", "cbp", "==", "True", ":", "\n", "      ", "cbp_size", "=", "FLAGS", ".", "cbp_size", "\n", "concatenated_features", "=", "cbp_layer", "(", "\n", "tf", ".", "reshape", "(", "features", "[", "\"mean_rgb\"", "]", ",", "shape", "=", "[", "-", "1", ",", "1", ",", "1", ",", "1024", "]", ")", ",", "\n", "tf", ".", "reshape", "(", "features", "[", "\"mean_audio\"", "]", ",", "shape", "=", "[", "-", "1", ",", "1", ",", "1", ",", "128", "]", ")", ",", "\n", "output_dim", "=", "cbp_size", ")", "\n", "concatenated_features", ".", "set_shape", "(", "[", "None", ",", "cbp_size", "]", ")", "\n", "\n", "# 10% of Gaussian random noise added.", "\n", "concatenated_features", "=", "concatenated_features", "+", "FLAGS", ".", "random_noise", "*", "tf", ".", "random_normal", "(", "shape", "=", "tf", ".", "shape", "(", "concatenated_features", ")", ")", "\n", "concatenated_features", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "concatenated_features", ",", "dim", "=", "1", ")", "\n", "\n", "", "tf", ".", "add_to_collection", "(", "\"concat_features\"", ",", "concatenated_features", ")", "\n", "\n", "return", "features", "[", "\"video_id\"", "]", ",", "concatenated_features", ",", "labels", ",", "tf", ".", "ones", "(", "[", "tf", ".", "shape", "(", "serialized_examples", ")", "[", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.__init__": [[170, 192], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", "=", "4716", ",", "\n", "feature_sizes", "=", "[", "1024", "]", ",", "\n", "feature_names", "=", "[", "\"inc3\"", "]", ",", "\n", "max_frames", "=", "300", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MFrameFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n      max_frames: the maximum number of frames to process.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.get_video_matrix": [[193, 222], ["tensorflow.reshape", "tensorflow.minimum", "utils.Dequantize", "readers.resize_axis", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.Dequantize", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.resize_axis"], ["", "def", "get_video_matrix", "(", "self", ",", "\n", "features", ",", "\n", "feature_size", ",", "\n", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", ":", "\n", "    ", "\"\"\"Decodes features from an input string and quantizes it.\n\n    Args:\n      features: raw feature values\n      feature_size: length of each frame feature vector\n      max_frames: number of frames (rows) in the output feature_matrix\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      feature_matrix: matrix of all frame-features\n      num_frames: number of frames in the sequence\n    \"\"\"", "\n", "decoded_features", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "decode_raw", "(", "features", ",", "tf", ".", "uint8", ")", ",", "tf", ".", "float32", ")", ",", "\n", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "\n", "num_frames", "=", "tf", ".", "minimum", "(", "tf", ".", "shape", "(", "decoded_features", ")", "[", "0", "]", ",", "max_frames", ")", "\n", "feature_matrix", "=", "utils", ".", "Dequantize", "(", "decoded_features", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "feature_matrix", "=", "resize_axis", "(", "feature_matrix", ",", "0", ",", "max_frames", ")", "\n", "return", "feature_matrix", ",", "num_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.prepare_reader": [[223, 242], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read", "readers.YT8MFrameFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "\n", "filename_queue", ",", "\n", "max_quantized_value", "=", "2", ",", "\n", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for YouTube8M SequenceExamples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      A tuple of video indexes, video features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_example", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_example", ",", "\n", "max_quantized_value", ",", "min_quantized_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.prepare_serialized_examples": [[243, 313], ["tensorflow.parse_single_sequence_example", "tensorflow.cast", "len", "range", "tensorflow.add_to_collection", "tensorflow.minimum", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sparse_to_dense", "len", "len", "len", "len", "readers.YT8MFrameFeatureReader.get_video_matrix", "tensorflow.concat", "tensorflow.assert_equal", "cbp.compact_bilinear_pooling.compact_bilinear_pooling_layer", "cbp.compact_bilinear_pooling.compact_bilinear_pooling_layer.set_shape", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenSequenceFeature", "tensorflow.reshape", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.get_video_matrix", "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling.compact_bilinear_pooling_layer"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_example", ",", "\n", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "\n", "    ", "contexts", ",", "features", "=", "tf", ".", "parse_single_sequence_example", "(", "\n", "serialized_example", ",", "\n", "context_features", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", ",", "\n", "sequence_features", "=", "{", "\n", "feature_name", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "for", "feature_name", "in", "self", ".", "feature_names", "\n", "}", ")", "\n", "\n", "# read ground truth labels", "\n", "labels", "=", "(", "tf", ".", "cast", "(", "\n", "tf", ".", "sparse_to_dense", "(", "contexts", "[", "\"labels\"", "]", ".", "values", ",", "(", "self", ".", "num_classes", ",", ")", ",", "1", ",", "\n", "validate_indices", "=", "False", ")", ",", "\n", "tf", ".", "bool", ")", ")", "\n", "\n", "# loads (potentially) different types of features and concatenates them", "\n", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"No feature selected: feature_names is empty!\"", "\n", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "num_frames", "=", "-", "1", "# the number of frames in the video", "\n", "feature_matrices", "=", "[", "None", "]", "*", "num_features", "# an array of different features", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_matrix", ",", "num_frames_in_this_feature", "=", "self", ".", "get_video_matrix", "(", "\n", "features", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", ",", "\n", "self", ".", "feature_sizes", "[", "feature_index", "]", ",", "\n", "self", ".", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "if", "num_frames", "==", "-", "1", ":", "\n", "        ", "num_frames", "=", "num_frames_in_this_feature", "\n", "", "else", ":", "\n", "        ", "tf", ".", "assert_equal", "(", "num_frames", ",", "num_frames_in_this_feature", ")", "\n", "\n", "", "feature_matrices", "[", "feature_index", "]", "=", "feature_matrix", "\n", "\n", "# cap the number of frames at self.max_frames", "\n", "#num_frames = tf.minimum(num_frames, self.max_frames)", "\n", "\n", "# concatenate different features", "\n", "", "tf", ".", "add_to_collection", "(", "\"feature_matrix\"", ",", "feature_matrices", ")", "\n", "\n", "cbp_size", "=", "FLAGS", ".", "cbp_size", "\n", "if", "FLAGS", ".", "cbp", "==", "False", ":", "\n", "      ", "video_matrix", "=", "tf", ".", "concat", "(", "feature_matrices", ",", "1", ")", "\n", "", "elif", "FLAGS", ".", "cbp", "==", "True", ":", "\n", "      ", "video_matrix", "=", "cbp_layer", "(", "\n", "tf", ".", "reshape", "(", "feature_matrices", "[", "0", "]", ",", "shape", "=", "[", "1", ",", "1", ",", "300", ",", "1024", "]", ")", ",", "\n", "tf", ".", "reshape", "(", "feature_matrices", "[", "1", "]", ",", "shape", "=", "[", "1", ",", "1", ",", "300", ",", "128", "]", ")", ",", "\n", "output_dim", "=", "FLAGS", ".", "cbp_size", ")", "\n", "video_matrix", ".", "set_shape", "(", "[", "300", ",", "cbp_size", "]", ")", "\n", "\n", "", "num_frames", "=", "tf", ".", "minimum", "(", "num_frames", ",", "self", ".", "max_frames", ")", "\n", "\n", "\n", "# convert to batch format.", "\n", "# TODO: Do proper batch reads to remove the IO bottleneck.", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"video_id\"", "]", ",", "0", ")", "\n", "batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "video_matrix", ",", "0", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "batch_frames", "=", "tf", ".", "expand_dims", "(", "num_frames", ",", "0", ")", "\n", "\n", "return", "batch_video_ids", ",", "batch_video_matrix", ",", "batch_labels", ",", "batch_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.resize_axis": [[32, 68], ["tensorflow.convert_to_tensor", "tensorflow.unstack", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.stack", "tensorflow.concat", "tf.convert_to_tensor.get_shape().as_list", "tf.concat.set_shape", "tensorflow.shape", "tensorflow.slice", "tensorflow.fill", "tf.convert_to_tensor.get_shape", "tensorflow.zeros_like", "tensorflow.stack", "tensorflow.cast"], "function", ["None"], ["def", "resize_axis", "(", "tensor", ",", "axis", ",", "new_size", ",", "fill_value", "=", "0", ")", ":", "\n", "  ", "\"\"\"Truncates or pads a tensor to new_size on on a given axis.\n\n  Truncate or extend tensor such that tensor.shape[axis] == new_size. If the\n  size increases, the padding will be performed at the end, using fill_value.\n\n  Args:\n    tensor: The tensor to be resized.\n    axis: An integer representing the dimension to be sliced.\n    new_size: An integer or 0d tensor representing the new value for\n      tensor.shape[axis].\n    fill_value: Value to use to fill any new entries in the tensor. Will be\n      cast to the type of tensor.\n\n  Returns:\n    The resized tensor.\n  \"\"\"", "\n", "tensor", "=", "tf", ".", "convert_to_tensor", "(", "tensor", ")", "\n", "shape", "=", "tf", ".", "unstack", "(", "tf", ".", "shape", "(", "tensor", ")", ")", "\n", "\n", "pad_shape", "=", "shape", "[", ":", "]", "\n", "pad_shape", "[", "axis", "]", "=", "tf", ".", "maximum", "(", "0", ",", "new_size", "-", "shape", "[", "axis", "]", ")", "\n", "\n", "shape", "[", "axis", "]", "=", "tf", ".", "minimum", "(", "shape", "[", "axis", "]", ",", "new_size", ")", "\n", "shape", "=", "tf", ".", "stack", "(", "shape", ")", "\n", "\n", "resized", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "slice", "(", "tensor", ",", "tf", ".", "zeros_like", "(", "shape", ")", ",", "shape", ")", ",", "\n", "tf", ".", "fill", "(", "tf", ".", "stack", "(", "pad_shape", ")", ",", "tf", ".", "cast", "(", "fill_value", ",", "tensor", ".", "dtype", ")", ")", "\n", "]", ",", "axis", ")", "\n", "\n", "# Update shape.", "\n", "new_shape", "=", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "# A copy is being made.", "\n", "new_shape", "[", "axis", "]", "=", "new_size", "\n", "resized", ".", "set_shape", "(", "new_shape", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.input_fn": [[60, 98], ["tensorflow.python.framework.constant_op.constant", "tensorflow.python.ops.array_ops.gather", "tensorflow.python.ops.random_ops.random_uniform", "tensorflow.python.ops.data_flow_ops.FIFOQueue", "tensorflow.python.ops.control_flow_ops.cond", "tensorflow.python.training.input.limit_epochs", "tensorflow.python.training.input.limit_epochs", "tensorflow.python.framework.constant_op.constant", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.data_flow_ops.FIFOQueue.dequeue_many", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.control_flow_ops.no_op", "tensorflow.python.ops.data_flow_ops.FIFOQueue.size", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.array_ops.identity", "tensorflow.python.ops.data_flow_ops.FIFOQueue.enqueue_many", "tensorflow.python.ops.data_flow_ops.FIFOQueue.enqueue_many", "tensorflow.python.ops.math_ops.range"], "methods", ["None"], ["  ", "def", "input_fn", "(", "self", ",", "batch_size", "=", "None", ",", "points", "=", "None", ",", "randomize", "=", "None", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns an input_fn that randomly selects batches from given points.\"\"\"", "\n", "batch_size", "=", "batch_size", "or", "self", ".", "batch_size", "\n", "points", "=", "points", "if", "points", "is", "not", "None", "else", "self", ".", "points", "\n", "num_points", "=", "points", ".", "shape", "[", "0", "]", "\n", "if", "randomize", "is", "None", ":", "\n", "      ", "randomize", "=", "(", "self", ".", "use_mini_batch", "and", "\n", "self", ".", "mini_batch_steps_per_iteration", "<=", "1", ")", "\n", "", "def", "_fn", "(", ")", ":", "\n", "      ", "x", "=", "constant_op", ".", "constant", "(", "points", ")", "\n", "if", "batch_size", "==", "num_points", ":", "\n", "        ", "return", "input_lib", ".", "limit_epochs", "(", "x", ",", "num_epochs", "=", "num_epochs", ")", ",", "None", "\n", "", "if", "randomize", ":", "\n", "        ", "indices", "=", "random_ops", ".", "random_uniform", "(", "\n", "constant_op", ".", "constant", "(", "[", "batch_size", "]", ")", ",", "\n", "minval", "=", "0", ",", "maxval", "=", "num_points", "-", "1", ",", "\n", "dtype", "=", "dtypes", ".", "int32", ",", "\n", "seed", "=", "10", ")", "\n", "", "else", ":", "\n", "# We need to cycle through the indices sequentially. We create a queue", "\n", "# to maintain the list of indices.", "\n", "        ", "q", "=", "data_flow_ops", ".", "FIFOQueue", "(", "self", ".", "num_points", ",", "dtypes", ".", "int32", ",", "(", ")", ")", "\n", "# Conditionally initialize the Queue.", "\n", "def", "_init_q", "(", ")", ":", "\n", "          ", "with", "ops", ".", "control_dependencies", "(", "[", "q", ".", "enqueue_many", "(", "\n", "math_ops", ".", "range", "(", "self", ".", "num_points", ")", ")", "]", ")", ":", "\n", "            ", "return", "control_flow_ops", ".", "no_op", "(", ")", "\n", "", "", "init_q", "=", "control_flow_ops", ".", "cond", "(", "q", ".", "size", "(", ")", "<=", "0", ",", "\n", "_init_q", ",", "\n", "control_flow_ops", ".", "no_op", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "init_q", "]", ")", ":", "\n", "          ", "offsets", "=", "q", ".", "dequeue_many", "(", "self", ".", "batch_size", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "q", ".", "enqueue_many", "(", "offsets", ")", "]", ")", ":", "\n", "            ", "indices", "=", "array_ops", ".", "identity", "(", "offsets", ")", "\n", "", "", "", "batch", "=", "array_ops", ".", "gather", "(", "x", ",", "indices", ")", "\n", "return", "(", "input_lib", ".", "limit_epochs", "(", "batch", ",", "num_epochs", "=", "num_epochs", ")", ",", "None", ")", "\n", "", "return", "_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.config": [[99, 102], ["tensorflow.contrib.learn.python.learn.estimators.run_config.RunConfig"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "config", "(", "tf_random_seed", ")", ":", "\n", "    ", "return", "run_config", ".", "RunConfig", "(", "tf_random_seed", "=", "tf_random_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.batch_size": [[103, 106], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "batch_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "num_points", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.use_mini_batch": [[107, 110], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "use_mini_batch", "(", "self", ")", ":", "\n", "    ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.mini_batch_steps_per_iteration": [[111, 114], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mini_batch_steps_per_iteration", "(", "self", ")", ":", "\n", "    ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTest.setUp": [[118, 124], ["numpy.random.seed", "numpy.zeros"], "methods", ["None"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "3", ")", "\n", "self", ".", "num_centers", "=", "5", "\n", "self", ".", "num_dims", "=", "2", "\n", "self", ".", "num_points", "=", "1000", "\n", "self", ".", "points", "=", "np", ".", "zeros", "(", "[", "10000", ",", "1024", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTest._kmeans": [[125, 134], ["tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering"], "methods", ["None"], ["", "def", "_kmeans", "(", "self", ",", "relative_tolerance", "=", "None", ")", ":", "\n", "    ", "return", "kmeans_lib", ".", "KMeansClustering", "(", "\n", "self", ".", "num_centers", ",", "\n", "initial_clusters", "=", "kmeans_lib", ".", "KMeansClustering", ".", "KMEANS_PLUS_PLUS_INIT", ",", "\n", "distance_metric", "=", "kmeans_lib", ".", "KMeansClustering", ".", "SQUARED_EUCLIDEAN_DISTANCE", ",", "\n", "use_mini_batch", "=", "self", ".", "use_mini_batch", ",", "\n", "mini_batch_steps_per_iteration", "=", "self", ".", "mini_batch_steps_per_iteration", ",", "\n", "random_seed", "=", "24", ",", "\n", "relative_tolerance", "=", "relative_tolerance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTest.test_clusters": [[135, 140], ["kemans_tf.KMeansTest._kmeans", "kemans_tf.KMeansTest.fit", "kemans_tf.KMeansTest.clusters", "kemans_tf.KMeansTest.assertAllEqual", "list", "kemans_tf.KMeansTest.input_fn"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTest._kmeans", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.input_fn"], ["", "def", "test_clusters", "(", "self", ")", ":", "\n", "    ", "kmeans", "=", "self", ".", "_kmeans", "(", ")", "\n", "kmeans", ".", "fit", "(", "input_fn", "=", "self", ".", "input_fn", "(", ")", ",", "steps", "=", "1", ")", "\n", "clusters", "=", "kmeans", ".", "clusters", "(", ")", "\n", "self", ".", "assertAllEqual", "(", "list", "(", "clusters", ".", "shape", ")", ",", "[", "self", ".", "num_centers", ",", "self", ".", "num_dims", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTest.test_fit": [[141, 151], ["kemans_tf.KMeansTest._kmeans", "kemans_tf.KMeansTest.fit", "kemans_tf.KMeansTest.score", "kemans_tf.KMeansTest.fit", "kemans_tf.KMeansTest.score", "kemans_tf.KMeansTest.assertTrue", "kemans_tf.KMeansTest.input_fn", "kemans_tf.KMeansTest.input_fn", "kemans_tf.KMeansTest.input_fn", "kemans_tf.KMeansTest.input_fn"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTest._kmeans", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.input_fn", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.input_fn", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.input_fn", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.input_fn"], ["", "def", "test_fit", "(", "self", ")", ":", "\n", "    ", "kmeans", "=", "self", ".", "_kmeans", "(", ")", "\n", "kmeans", ".", "fit", "(", "input_fn", "=", "self", ".", "input_fn", "(", ")", ",", "steps", "=", "1", ")", "\n", "score1", "=", "kmeans", ".", "score", "(", "\n", "input_fn", "=", "self", ".", "input_fn", "(", "batch_size", "=", "self", ".", "num_points", ")", ",", "steps", "=", "1", ")", "\n", "steps", "=", "10", "*", "self", ".", "num_points", "//", "self", ".", "batch_size", "\n", "kmeans", ".", "fit", "(", "input_fn", "=", "self", ".", "input_fn", "(", ")", ",", "steps", "=", "steps", ")", "\n", "score2", "=", "kmeans", ".", "score", "(", "\n", "input_fn", "=", "self", ".", "input_fn", "(", "batch_size", "=", "self", ".", "num_points", ")", ",", "steps", "=", "1", ")", "\n", "self", ".", "assertTrue", "(", "score1", ">", "score2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTest.test_monitor": [[152, 172], ["tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering", "tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering.fit", "tensorflow.contrib.learn.python.learn.estimators.kmeans.KMeansClustering.score", "tensorflow.contrib.learn.python.learn.RunConfig", "kemans_tf.KMeansTest.input_fn", "kemans_tf.KMeansTest.input_fn"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.input_fn", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.KMeansTestBase.input_fn"], ["", "def", "test_monitor", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "use_mini_batch", ":", "\n", "# We don't test for use_mini_batch case since the loss value can be noisy.", "\n", "      ", "return", "\n", "", "kmeans", "=", "kmeans_lib", ".", "KMeansClustering", "(", "\n", "self", ".", "num_centers", ",", "\n", "initial_clusters", "=", "kmeans_lib", ".", "KMeansClustering", ".", "KMEANS_PLUS_PLUS_INIT", ",", "\n", "distance_metric", "=", "kmeans_lib", ".", "KMeansClustering", ".", "SQUARED_EUCLIDEAN_DISTANCE", ",", "\n", "use_mini_batch", "=", "self", ".", "use_mini_batch", ",", "\n", "mini_batch_steps_per_iteration", "=", "self", ".", "mini_batch_steps_per_iteration", ",", "\n", "config", "=", "learn", ".", "RunConfig", "(", "tf_random_seed", "=", "14", ")", ",", "\n", "random_seed", "=", "12", ",", "\n", "relative_tolerance", "=", "1e-4", ")", "\n", "\n", "kmeans", ".", "fit", "(", "\n", "input_fn", "=", "self", ".", "input_fn", "(", ")", ",", "\n", "# Force it to train until the relative tolerance monitor stops it.", "\n", "steps", "=", "None", ")", "\n", "score", "=", "kmeans", ".", "score", "(", "\n", "input_fn", "=", "self", ".", "input_fn", "(", "batch_size", "=", "self", ".", "num_points", ")", ",", "steps", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.normalize": [[36, 38], ["numpy.sqrt", "numpy.sum"], "function", ["None"], ["def", "normalize", "(", "x", ")", ":", "\n", "  ", "return", "x", "/", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "x", "*", "x", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.cosine_similarity": [[40, 42], ["numpy.dot", "kemans_tf.normalize", "numpy.transpose", "kemans_tf.normalize"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.normalize", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.normalize"], ["", "def", "cosine_similarity", "(", "x", ",", "y", ")", ":", "\n", "  ", "return", "np", ".", "dot", "(", "normalize", "(", "x", ")", ",", "np", ".", "transpose", "(", "normalize", "(", "y", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.make_random_centers": [[44, 47], ["numpy.round", "numpy.random.rand().astype", "numpy.random.rand"], "function", ["None"], ["", "def", "make_random_centers", "(", "num_centers", ",", "num_dims", ",", "center_norm", "=", "500", ")", ":", "\n", "  ", "return", "np", ".", "round", "(", "\n", "np", ".", "random", ".", "rand", "(", "num_centers", ",", "num_dims", ")", ".", "astype", "(", "np", ".", "float32", ")", "*", "center_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.kemans_tf.make_random_points": [[49, 56], ["numpy.random.choice", "numpy.round", "numpy.add.reduce", "numpy.random.randn().astype", "numpy.random.randn"], "function", ["None"], ["", "def", "make_random_points", "(", "centers", ",", "num_points", ",", "max_offset", "=", "20", ")", ":", "\n", "  ", "num_centers", ",", "num_dims", "=", "centers", ".", "shape", "\n", "assignments", "=", "np", ".", "random", ".", "choice", "(", "num_centers", ",", "num_points", ")", "\n", "offsets", "=", "np", ".", "round", "(", "\n", "np", ".", "random", ".", "randn", "(", "num_points", ",", "num_dims", ")", ".", "astype", "(", "np", ".", "float32", ")", "*", "max_offset", ")", "\n", "return", "(", "centers", "[", "assignments", "]", "+", "offsets", ",", "assignments", ",", "\n", "np", ".", "add", ".", "reduce", "(", "offsets", "*", "offsets", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.export_model.ModelExporter.__init__": [[31, 48], ["tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "export_model.ModelExporter.build_inputs_and_outputs", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.Graph", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.export_model.ModelExporter.build_inputs_and_outputs"], ["  ", "def", "__init__", "(", "self", ",", "frame_features", ",", "model", ",", "reader", ")", ":", "\n", "    ", "self", ".", "frame_features", "=", "frame_features", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "      ", "\"\"\"\n      label_corelation_data = load(\"./data/corelated_matrix.hkl\")\n      label_corelation_matrix = tf.nn.softmax(tf.cast(tf.constant(label_corelation_data), tf.float32))\n      tf.add_to_collection(\"label_corelation_matrix\", label_corelation_matrix)\n      \"\"\"", "\n", "\n", "\n", "\n", "self", ".", "inputs", ",", "self", ".", "outputs", "=", "self", ".", "build_inputs_and_outputs", "(", ")", "\n", "self", ".", "graph", "=", "graph", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ",", "sharded", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.export_model.ModelExporter.export_model": [[49, 71], ["export_model.ModelExporter.graph.as_default", "tensorflow.Session", "tensorflow.Session", "session.run", "export_model.ModelExporter.saver.restore", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder.add_meta_graph_and_variables", "tensorflow.python.saved_model.builder.SavedModelBuilder.save", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run"], ["", "", "def", "export_model", "(", "self", ",", "model_dir", ",", "global_step_val", ",", "last_checkpoint", ")", ":", "\n", "    ", "\"\"\"Exports the model so that it can used for batch predictions.\"\"\"", "\n", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "      ", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "saver", ".", "restore", "(", "session", ",", "last_checkpoint", ")", "\n", "\n", "signature", "=", "signature_def_utils", ".", "build_signature_def", "(", "\n", "inputs", "=", "self", ".", "inputs", ",", "\n", "outputs", "=", "self", ".", "outputs", ",", "\n", "method_name", "=", "signature_constants", ".", "PREDICT_METHOD_NAME", ")", "\n", "\n", "signature_map", "=", "{", "signature_constants", ".", "DEFAULT_SERVING_SIGNATURE_DEF_KEY", ":", "\n", "signature", "}", "\n", "\n", "model_builder", "=", "saved_model_builder", ".", "SavedModelBuilder", "(", "model_dir", ")", "\n", "model_builder", ".", "add_meta_graph_and_variables", "(", "session", ",", "\n", "tags", "=", "[", "tag_constants", ".", "SERVING", "]", ",", "\n", "signature_def_map", "=", "signature_map", ",", "\n", "clear_devices", "=", "True", ")", "\n", "model_builder", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.export_model.ModelExporter.build_inputs_and_outputs": [[72, 96], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.map_fn", "tensorflow.map_fn", "tensorflow.placeholder", "tensorflow.placeholder", "export_model.ModelExporter.build_prediction_graph", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "export_model.ModelExporter.build_prediction_graph"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.export_model.ModelExporter.build_prediction_graph", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.export_model.ModelExporter.build_prediction_graph"], ["", "", "", "def", "build_inputs_and_outputs", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "frame_features", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "fn", "=", "lambda", "x", ":", "self", ".", "build_prediction_graph", "(", "x", ")", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "tf", ".", "map_fn", "(", "fn", ",", "serialized_examples", ",", "\n", "dtype", "=", "(", "tf", ".", "string", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "self", ".", "build_prediction_graph", "(", "serialized_examples", ")", ")", "\n", "\n", "", "inputs", "=", "{", "\"example_bytes\"", ":", "\n", "saved_model_utils", ".", "build_tensor_info", "(", "serialized_examples", ")", "}", "\n", "\n", "outputs", "=", "{", "\n", "\"video_id\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "video_id_output", ")", ",", "\n", "\"class_indexes\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "top_indices_output", ")", ",", "\n", "\"predictions\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "top_predictions_output", ")", "}", "\n", "\n", "return", "inputs", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.export_model.ModelExporter.build_prediction_graph": [[97, 120], ["export_model.ModelExporter.reader.prepare_serialized_examples", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "len", "tensorflow.variable_scope", "tensorflow.variable_scope", "export_model.ModelExporter.model.create_model", "tensorflow.get_model_variables", "tensorflow.get_model_variables", "tensorflow.nn.top_k", "tensorflow.nn.top_k", "model_input_raw.get_shape", "tensorflow.summary.histogram", "tensorflow.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.prepare_serialized_examples", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model"], ["", "def", "build_prediction_graph", "(", "self", ",", "serialized_examples", ")", ":", "\n", "    ", "video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "self", ".", "reader", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "      ", "result", "=", "self", ".", "model", ".", "create_model", "(", "\n", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "self", ".", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "False", ")", "\n", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "\n", "top_predictions", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "predictions", ",", "\n", "_TOP_PREDICTIONS_IN_OUTPUT", ")", "\n", "", "return", "video_id", ",", "top_indices", ",", "top_predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.mean_average_precision_calculator.MeanAveragePrecisionCalculator.__init__": [[48, 70], ["range", "ValueError", "mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators.append", "isinstance", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ")", ":", "\n", "    ", "\"\"\"Construct a calculator to calculate the (macro) average precision.\n\n    Args:\n      num_class: A positive Integer specifying the number of classes.\n      top_n_array: A list of positive integers specifying the top n for each\n      class. The top n in each class will be used to calculate its average\n      precision at n.\n      The size of the array must be num_class.\n\n    Raises:\n      ValueError: An error occurred when num_class is not a positive integer;\n      or the top_n_array is not a list of positive integers.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "num_class", ",", "int", ")", "or", "num_class", "<=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"num_class must be a positive integer.\"", ")", "\n", "\n", "", "self", ".", "_ap_calculators", "=", "[", "]", "# member of AveragePrecisionCalculator", "\n", "self", ".", "_num_class", "=", "num_class", "# total number of classes", "\n", "for", "i", "in", "range", "(", "num_class", ")", ":", "\n", "      ", "self", ".", "_ap_calculators", ".", "append", "(", "\n", "average_precision_calculator", ".", "AveragePrecisionCalculator", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.mean_average_precision_calculator.MeanAveragePrecisionCalculator.accumulate": [[71, 94], ["range", "len", "calculators[].accumulate"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.accumulate"], ["", "", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    Args:\n      predictions: A list of lists storing the prediction scores. The outer\n      dimension corresponds to classes.\n      actuals: A list of lists storing the ground truth labels. The dimensions\n      should correspond to the predictions input. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives: If provided, it is a list of numbers representing the\n      number of true positives for each class. If not provided, the number of\n      true positives will be inferred from the 'actuals' array.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n      does not match.\n    \"\"\"", "\n", "if", "not", "num_positives", ":", "\n", "      ", "num_positives", "=", "[", "None", "for", "i", "in", "predictions", ".", "shape", "[", "1", "]", "]", "\n", "\n", "", "calculators", "=", "self", ".", "_ap_calculators", "\n", "for", "i", "in", "range", "(", "len", "(", "predictions", ")", ")", ":", "\n", "      ", "calculators", "[", "i", "]", ".", "accumulate", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ",", "num_positives", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.mean_average_precision_calculator.MeanAveragePrecisionCalculator.clear": [[95, 98], ["calculator.clear"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.clear"], ["", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "for", "calculator", "in", "self", ".", "_ap_calculators", ":", "\n", "      ", "calculator", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.mean_average_precision_calculator.MeanAveragePrecisionCalculator.is_empty": [[99, 102], ["range"], "methods", ["None"], ["", "", "def", "is_empty", "(", "self", ")", ":", "\n", "    ", "return", "(", "[", "calculator", ".", "heap_size", "for", "calculator", "in", "self", ".", "_ap_calculators", "]", "==", "\n", "[", "0", "for", "_", "in", "range", "(", "self", ".", "_num_class", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n": [[103, 113], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators[].peek_ap_at_n", "range"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "peek_map_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated mean average precision at n.\n\n    Returns:\n      An array of non-interpolated average precision at n (default 0) for each\n      class.\n    \"\"\"", "\n", "aps", "=", "[", "self", ".", "_ap_calculators", "[", "i", "]", ".", "peek_ap_at_n", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_class", ")", "]", "\n", "return", "aps", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.model_utils.SampleRandomSequence": [[23, 49], ["tensorflow.tile", "tensorflow.maximum", "tensorflow.cast", "tensorflow.minimum", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.random_uniform", "tensorflow.cast", "tensorflow.range"], "function", ["None"], ["def", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random sequence of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index_offset", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "num_samples", ")", ",", "0", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "max_start_frame_index", "=", "tf", ".", "maximum", "(", "num_frames", "-", "num_samples", ",", "0", ")", "\n", "start_frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "1", "]", ")", ",", "\n", "tf", ".", "cast", "(", "max_start_frame_index", "+", "1", ",", "tf", ".", "float32", ")", ")", ",", "tf", ".", "int32", ")", "\n", "frame_index", "=", "tf", ".", "minimum", "(", "start_frame_index", "+", "frame_index_offset", ",", "\n", "tf", ".", "cast", "(", "num_frames", "-", "1", ",", "tf", ".", "int32", ")", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.model_utils.SampleRandomFrames": [[51, 71], ["tensorflow.cast", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.multiply", "tensorflow.expand_dims", "tensorflow.random_uniform", "tensorflow.tile", "tensorflow.range", "tensorflow.cast"], "function", ["None"], ["", "def", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random set of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "num_samples", "]", ")", ",", "\n", "tf", ".", "tile", "(", "tf", ".", "cast", "(", "num_frames", ",", "tf", ".", "float32", ")", ",", "[", "1", ",", "num_samples", "]", ")", ")", ",", "tf", ".", "int32", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.model_utils.FramePooling": [[72, 96], ["tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reshape", "ValueError", "frames.shape_as_list"], "function", ["None"], ["", "def", "FramePooling", "(", "frames", ",", "method", ",", "**", "unused_params", ")", ":", "\n", "  ", "\"\"\"Pools over the frames of a video.\n\n  Args:\n    frames: A tensor with shape [batch_size, num_frames, feature_size].\n    method: \"average\", \"max\", \"attention\", or \"none\".\n  Returns:\n    A tensor with shape [batch_size, feature_size] for average, max, or\n    attention pooling. A tensor with shape [batch_size*num_frames, feature_size]\n    for none pooling.\n\n  Raises:\n    ValueError: if method is other than \"average\", \"max\", \"attention\", or\n    \"none\".\n  \"\"\"", "\n", "if", "method", "==", "\"average\"", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"max\"", ":", "\n", "    ", "return", "tf", ".", "reduce_max", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"none\"", ":", "\n", "    ", "feature_size", "=", "frames", ".", "shape_as_list", "(", ")", "[", "2", "]", "\n", "return", "tf", ".", "reshape", "(", "frames", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unrecognized pooling method: %s\"", "%", "method", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._int64_feature": [[41, 44], ["tensorflow.train.Feature", "tensorflow.train.Int64List"], "function", ["None"], ["def", "_int64_feature", "(", "value", ")", ":", "\n", "    ", "\"\"\"Wrapper for inserting an int64 Feature into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._float_feature": [[45, 48], ["tensorflow.train.Feature", "tensorflow.train.FloatList"], "function", ["None"], ["", "def", "_float_feature", "(", "value", ")", ":", "\n", "    ", "\"\"\"Wrapper for inserting an int64 Feature into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._bytes_feature": [[49, 52], ["tensorflow.train.Feature", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "_bytes_feature", "(", "value", ")", ":", "\n", "    ", "\"\"\"Wrapper for inserting a byte Feature into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._int64_feature_list": [[54, 57], ["tensorflow.train.FeatureList", "build_VLAD_data._int64_feature"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._int64_feature"], ["", "def", "_int64_feature_list", "(", "values", ")", ":", "\n", "    ", "\"\"\"Wrapper for inserting an int64 FeatureList into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "FeatureList", "(", "feature", "=", "[", "_int64_feature", "(", "v", ")", "for", "v", "in", "values", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._bytes_feature_list": [[59, 62], ["tensorflow.train.FeatureList", "build_VLAD_data._bytes_feature"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._bytes_feature"], ["", "def", "_bytes_feature_list", "(", "values", ")", ":", "\n", "    ", "\"\"\"Wrapper for inserting an byte FeatureList into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "FeatureList", "(", "feature", "=", "[", "_bytes_feature", "(", "v", ")", "for", "v", "in", "values", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._float_feature_list": [[64, 67], ["tensorflow.train.FeatureList", "build_VLAD_data._float_feature"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._float_feature"], ["", "def", "_float_feature_list", "(", "values", ")", ":", "\n", "    ", "\"\"\"Wrapper for inserting an byte FeatureList into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "FeatureList", "(", "feature", "=", "[", "_float_feature", "(", "v", ")", "for", "v", "in", "values", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._to_sequence_example": [[69, 87], ["pudb.set_trace", "pudb.set_trace", "tensorflow.train.Features", "tensorflow.train.Example", "build_VLAD_data._bytes_feature", "build_VLAD_data._int64_feature_list", "build_VLAD_data._float_feature"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._bytes_feature", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._int64_feature_list", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._float_feature"], ["", "def", "_to_sequence_example", "(", "cont", ",", "vlad", ")", ":", "\n", "    ", "\"\"\"Builds a SequenceExample proto for an video-caption pair etc..\n\n    Args:\n        video: An VideoMetadata object.\n\n    Returns:\n        A SequenceExample proto.\n    \"\"\"", "\n", "pudb", ".", "set_trace", "(", ")", "\n", "context", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "\"video_id\"", ":", "_bytes_feature", "(", "cont", "[", "'video_id'", "]", ")", ",", "\n", "\"labels\"", ":", "_int64_feature_list", "(", "cont", "[", "'labels'", "]", ".", "values", ")", ",", "\n", "\"VLAD\"", ":", "_float_feature", "(", "vlad", ")", "\n", "}", ")", "\n", "sequence_example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "context", ")", "\n", "\n", "return", "sequence_example", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._process_videos": [[89, 149], ["range", "len", "tensorflow.train.string_input_producer", "tensorflow.TFRecordReader", "tf.TFRecordReader.read", "tensorflow.parse_single_sequence_example", "os.path.join", "tensorflow.python_io.TFRecordWriter", "print", "sys.stdout.flush", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenSequenceFeature", "tensorflow.FixedLenSequenceFeature", "tensorflow.Session", "sess.run", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "tensorflow.contrib.learn.KMeansClustering", "tf.python_io.TFRecordWriter.close", "print", "sys.stdout.flush", "vid.split", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tf.train.Coordinator.should_stop", "sess.run", "sess.run", "tensorflow.reshape", "sess.run", "VLAD_tf", "build_VLAD_data._to_sequence_example", "tensorflow.cast", "utils.Dequantize", "tf.python_io.TFRecordWriter.write", "datetime.datetime.now", "tensorflow.decode_raw", "_to_sequence_example.SerializeToString", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._to_sequence_example", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.Dequantize"], ["", "def", "_process_videos", "(", "thread_index", ",", "ranges", ",", "name", ",", "videos", ",", "num_shards", ")", ":", "\n", "    ", "\"\"\"Processes and saves a subset of video metadata as TFRecord files in one thread.\n\n    Each thread produces N shards where N = num_shards / num_threads.\n    For instance, if num_shards = 128, and num_threads = 2, then the first\n    thread would produce shards [0, 64).\n\n    Args:\n        thread_index: Integer thread identifier within [0, len(ranges)].\n        ranges: A list of pairs of integers specifying the ranges of the datset to\n            process in parallel.\n        name: Unique identifier specifying the dataset.\n        videos: List of VideoMetadata.\n        num_shards: Integer number of shards for the output files.\n    \"\"\"", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "videos", ")", ")", ":", "\n", "        ", "vid", "=", "videos", "[", "i", "]", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "[", "vid", "]", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ")", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_examples", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "context_features", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", "\n", "\n", "sequence_features", "=", "{", "\"rgb\"", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "\"audio\"", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "}", "\n", "\n", "contexts", ",", "features", "=", "tf", ".", "parse_single_sequence_example", "(", "\n", "serialized_examples", ",", "context_features", "=", "context_features", ",", "sequence_features", "=", "sequence_features", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "vid", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "output_file", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "vis_dic", "=", "tf", ".", "contrib", ".", "learn", ".", "KMeansClustering", "(", "\n", "num_clusters", "=", "256", ",", "\n", "relative_tolerance", "=", "0.0001", ",", "\n", "model_dir", "=", "'/data1/yj/kmeans/'", ")", "\n", "counter", "=", "0", "\n", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "                ", "feat", "=", "sess", ".", "run", "(", "features", ")", "\n", "cont", "=", "sess", ".", "run", "(", "contexts", ")", "\n", "decoded_rgb", "=", "tf", ".", "reshape", "(", "tf", ".", "cast", "(", "tf", ".", "decode_raw", "(", "features", "[", "'rgb'", "]", ",", "tf", ".", "uint8", ")", ",", "tf", ".", "float32", ")", ",", "shape", "=", "[", "-", "1", ",", "1024", "]", ")", "\n", "temp", "=", "sess", ".", "run", "(", "decoded_rgb", ")", "\n", "vlad", "=", "VLAD_tf", "(", "utils", ".", "Dequantize", "(", "temp", ")", ",", "vis_dic", ")", "\n", "sequence_example", "=", "_to_sequence_example", "(", "cont", ",", "vlad", ")", "\n", "if", "sequence_example", "is", "not", "None", ":", "\n", "                    ", "counter", "+=", "1", "\n", "writer", ".", "write", "(", "sequence_example", ".", "SerializeToString", "(", ")", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"%s [thread %d]: Wrote %d %s working data to %s.\"", "%", "\n", "(", "datetime", ".", "now", "(", ")", ",", "thread_index", ",", "counter", ",", "FLAGS", ".", "type", ",", "output_file", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "shard_counter", "=", "0", "\n", "", "print", "(", "\"%s [thread %d]: Wrote %d %s working data to %d shards.\"", "%", "\n", "(", "datetime", ".", "now", "(", ")", ",", "thread_index", ",", "counter", ",", "FLAGS", ".", "type", ",", "num_shards_per_batch", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data._process_dataset": [[151, 181], ["min", "numpy.linspace().astype", "xrange", "tensorflow.train.Coordinator", "print", "xrange", "tf.train.Coordinator.join", "print", "ranges.append", "len", "threading.Thread", "threading.Thread.start", "threads.append", "numpy.linspace", "len", "len", "datetime.datetime.now", "len"], "function", ["None"], ["", "", "def", "_process_dataset", "(", "name", ",", "videos", ",", "num_shards", ")", ":", "\n", "    ", "\"\"\"Processes a complete data set and saves it as a TFRecord.\n\n    Args:\n        name: Unique identifier specifying the dataset.\n        videos: List of VideoMetadata.\n        num_shards: Integer number of shards for the output files.\n    \"\"\"", "\n", "#random.seed(12345)", "\n", "#random.shuffle(videos)", "\n", "\n", "num_threads", "=", "min", "(", "num_shards", ",", "FLAGS", ".", "num_threads", ")", "\n", "spacing", "=", "np", ".", "linspace", "(", "0", ",", "len", "(", "videos", ")", ",", "num_threads", "+", "1", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "ranges", "=", "[", "]", "\n", "threads", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "spacing", ")", "-", "1", ")", ":", "\n", "        ", "ranges", ".", "append", "(", "[", "spacing", "[", "i", "]", ",", "spacing", "[", "i", "+", "1", "]", "]", ")", "\n", "\n", "", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "\n", "print", "(", "\"Launching %d threads for spacings: %s\"", "%", "(", "num_threads", ",", "ranges", ")", ")", "\n", "for", "thread_index", "in", "xrange", "(", "len", "(", "ranges", ")", ")", ":", "\n", "        ", "args", "=", "(", "thread_index", ",", "ranges", ",", "name", ",", "videos", ",", "num_shards", ")", "\n", "t", "=", "threading", ".", "Thread", "(", "target", "=", "_process_videos", ",", "args", "=", "args", ")", "\n", "t", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "t", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "print", "(", "\"%s: Finished processing all %d video metadata in the data set '%s'.\"", "%", "\n", "(", "datetime", ".", "now", "(", ")", ",", "len", "(", "videos", ")", ",", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.build_VLAD_data.main": [[183, 199], ["build_VLAD_data.main._is_valid_num_shards"], "function", ["None"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "    ", "def", "_is_valid_num_shards", "(", "num_shards", ")", ":", "\n", "        ", "return", "num_shards", "<", "FLAGS", ".", "num_threads", "or", "not", "num_shards", "%", "FLAGS", ".", "num_threads", "\n", "\n", "", "assert", "_is_valid_num_shards", "(", "FLAGS", ".", "train_shards", ")", "\n", "assert", "_is_valid_num_shards", "(", "FLAGS", ".", "val_shards", ")", "\n", "assert", "_is_valid_num_shards", "(", "FLAGS", ".", "test_shards", ")", "\n", "\n", "FLAGS", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "FLAGS", ".", "type", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "FLAGS", ".", "output_dir", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "FLAGS", ".", "output_dir", ")", "\n", "\n", "", "files", "=", "glob", ".", "glob", "(", "'/data1/common_datasets/yt8m-data/frame-level/train*.tfrecord'", ")", "\n", "\n", "_process_dataset", "(", "\"train\"", ",", "files", ",", "FLAGS", ".", "train_shards", ")", "\n", "#_process_dataset(\"train_neg\", train_neg, FLAGS.train_shards)", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.find_class_by_name": [[70, 74], ["next", "getattr"], "function", ["None"], ["", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.get_input_evaluation_tensors": [[76, 113], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_evaluation_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1024", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the evaluation data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for evaluation.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"eval_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find the evaluation files.\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of evaluation files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "shuffle", "=", "False", ",", "num_epochs", "=", "1", ")", "\n", "eval_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "return", "tf", ".", "train", ".", "batch_join", "(", "\n", "eval_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "3", "*", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.build_graph": [[115, 168], ["tensorflow.Variable", "eval.get_input_evaluation_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "len", "tensorflow.variable_scope", "model.create_model", "tensorflow.summary.histogram", "tensorflow.cast", "tensorflow.summary.merge_all", "model_input_raw.get_shape", "model.create_model.keys", "label_loss_fn.calculate_loss"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.get_input_evaluation_tensors", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.CenterLoss.calculate_loss"], ["", "", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "eval_data_pattern", ",", "\n", "label_loss_fn", ",", "\n", "batch_size", "=", "1024", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph for evaluation.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    eval_data_pattern: glob path to the evaluation data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    num_readers: How many threads to use for I/O operations.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "video_id_batch", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "get_input_evaluation_tensors", "(", "# pylint: disable=g-line-too-long", "\n", "reader", ",", "\n", "eval_data_pattern", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_readers", "=", "num_readers", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model_input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "# Normalize input features.", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "    ", "result", "=", "model", ".", "create_model", "(", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "False", ")", "\n", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model_activations\"", ",", "predictions", ")", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "      ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "      ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "labels_batch", ")", "\n", "\n", "", "", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "predictions", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"video_id_batch\"", ",", "video_id_batch", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"summary_op\"", ",", "tf", ".", "summary", ".", "merge_all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.evaluation_loop": [[170, 275], ["tensorflow.Session", "sess.run", "tensorflow.train.Coordinator", "tf.train.Coordinator.request_stop", "tf.train.Coordinator.join", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "saver.restore", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.logging.info", "evl_metrics.clear", "[].split", "tensorflow.local_variables_initializer", "threads.extend", "tf.train.Coordinator.should_stop", "time.time", "sess.run", "evl_metrics.accumulate", "utils.AddGlobalStepSummary", "tensorflow.logging.info", "tensorflow.logging.info", "evl_metrics.get", "summary_writer.add_summary", "utils.AddEpochSummary", "tensorflow.logging.info", "evl_metrics.clear", "tensorflow.logging.info", "tf.train.Coordinator.request_stop", "qr.create_threads", "time.time", "str", "tf.train.latest_checkpoint.split"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.AddGlobalStepSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.AddEpochSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.clear"], ["", "def", "evaluation_loop", "(", "video_id_batch", ",", "prediction_batch", ",", "label_batch", ",", "loss", ",", "\n", "summary_op", ",", "saver", ",", "summary_writer", ",", "evl_metrics", ",", "\n", "last_global_step_val", ")", ":", "\n", "  ", "\"\"\"Run the evaluation loop once.\n\n  Args:\n    video_id_batch: a tensor of video ids mini-batch.\n    prediction_batch: a tensor of predictions mini-batch.\n    label_batch: a tensor of label_batch mini-batch.\n    loss: a tensor of loss for the examples in the mini-batch.\n    summary_op: a tensor which runs the tensorboard summary operations.\n    saver: a tensorflow saver to restore the model.\n    summary_writer: a tensorflow summary_writer\n    evl_metrics: an EvaluationMetrics object.\n    last_global_step_val: the global step used in the previous evaluation.\n\n  Returns:\n    The global_step used in the latest model.\n  \"\"\"", "\n", "\n", "global_step_val", "=", "-", "1", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "if", "FLAGS", ".", "checkpoint_file", "==", "None", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "FLAGS", ".", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "checkpoint_file", "\n", "\n", "", "if", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"Loading checkpoint for eval: \"", "+", "latest_checkpoint", ")", "\n", "# Restores from checkpoint", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "# Assuming model_checkpoint_path looks something like:", "\n", "# /my-favorite-path/yt8m_train/model.ckpt-0, extract global_step from it.", "\n", "global_step_val", "=", "latest_checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "\"No checkpoint file found.\"", ")", "\n", "return", "global_step_val", "\n", "\n", "", "if", "global_step_val", "==", "last_global_step_val", ":", "\n", "      ", "logging", ".", "info", "(", "\"skip this checkpoint global_step_val=%s \"", "\n", "\"(same as the previous one).\"", ",", "global_step_val", ")", "\n", "return", "global_step_val", "\n", "\n", "", "sess", ".", "run", "(", "[", "tf", ".", "local_variables_initializer", "(", ")", "]", ")", "\n", "\n", "# Start the queue runners.", "\n", "fetches", "=", "[", "video_id_batch", ",", "prediction_batch", ",", "label_batch", ",", "loss", ",", "summary_op", "]", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "try", ":", "\n", "      ", "threads", "=", "[", "]", "\n", "for", "qr", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "QUEUE_RUNNERS", ")", ":", "\n", "        ", "threads", ".", "extend", "(", "qr", ".", "create_threads", "(", "\n", "sess", ",", "coord", "=", "coord", ",", "daemon", "=", "True", ",", "\n", "start", "=", "True", ")", ")", "\n", "", "logging", ".", "info", "(", "\"enter eval_once loop global_step_val = %s. \"", ",", "\n", "global_step_val", ")", "\n", "\n", "evl_metrics", ".", "clear", "(", ")", "\n", "\n", "examples_processed", "=", "0", "\n", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "        ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "predictions_val", ",", "labels_val", ",", "loss_val", ",", "summary_val", "=", "sess", ".", "run", "(", "\n", "fetches", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "example_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "examples_processed", "+=", "labels_val", ".", "shape", "[", "0", "]", "\n", "\n", "iteration_info_dict", "=", "evl_metrics", ".", "accumulate", "(", "predictions_val", ",", "\n", "labels_val", ",", "loss_val", ")", "\n", "iteration_info_dict", "[", "\"examples_per_second\"", "]", "=", "example_per_second", "\n", "current_average_loss", "=", "evl_metrics", ".", "sum_loss", "/", "examples_processed", "\n", "\n", "iterinfo", "=", "utils", ".", "AddGlobalStepSummary", "(", "\n", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "iteration_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", "\n", "logging", ".", "info", "(", "\"examples_processed: %d | %s | average loss: %.4f\"", ",", "examples_processed", ",", "\n", "iterinfo", ",", "current_average_loss", ")", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", "as", "e", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"Done with batched inference. Now calculating global performance \"", "\n", "\"metrics.\"", ")", "\n", "# calculate the metrics for the entire epoch", "\n", "epoch_info_dict", "=", "evl_metrics", ".", "get", "(", ")", "\n", "epoch_info_dict", "[", "\"epoch_id\"", "]", "=", "global_step_val", "\n", "\n", "summary_writer", ".", "add_summary", "(", "summary_val", ",", "global_step_val", ")", "\n", "epochinfo", "=", "utils", ".", "AddEpochSummary", "(", "\n", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", "\n", "logging", ".", "info", "(", "epochinfo", ")", "\n", "evl_metrics", ".", "clear", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "# pylint: disable=broad-except", "\n", "      ", "logging", ".", "info", "(", "\"Unexpected exception: \"", "+", "str", "(", "e", ")", ")", "\n", "coord", ".", "request_stop", "(", "e", ")", "\n", "\n", "", "coord", ".", "request_stop", "(", ")", "\n", "coord", ".", "join", "(", "threads", ",", "stop_grace_period_secs", "=", "10", ")", "\n", "\n", "return", "global_step_val", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.evaluate": [[277, 327], ["tensorflow.set_random_seed", "tensorflow.Graph().as_default", "utils.GetListOfFeatureNamesAndSizes", "eval.build_graph", "tensorflow.logging.info", "tensorflow.train.Saver", "tensorflow.summary.FileWriter", "eval_util.EvaluationMetrics", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "eval.find_class_by_name", "eval.find_class_by_name", "IOError", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.global_variables", "eval.evaluation_loop", "tensorflow.Graph", "tensorflow.get_default_graph"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.build_graph", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.find_class_by_name", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.find_class_by_name", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.evaluation_loop"], ["", "", "def", "evaluate", "(", ")", ":", "\n", "  ", "tf", ".", "set_random_seed", "(", "0", ")", "# for reproducibility", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "    ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "\n", "if", "FLAGS", ".", "eval_data_pattern", "is", "\"\"", ":", "\n", "      ", "raise", "IOError", "(", "\"'eval_data_pattern' was not specified. \"", "+", "\n", "\"Nothing to evaluate.\"", ")", "\n", "\n", "", "build_graph", "(", "\n", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "eval_data_pattern", "=", "FLAGS", ".", "eval_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ")", "\n", "logging", ".", "info", "(", "\"built evaluation graph\"", ")", "\n", "video_id_batch", "=", "tf", ".", "get_collection", "(", "\"video_id_batch\"", ")", "[", "0", "]", "\n", "prediction_batch", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "label_batch", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "summary_op", "=", "tf", ".", "get_collection", "(", "\"summary_op\"", ")", "[", "0", "]", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "FLAGS", ".", "train_dir", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "evl_metrics", "=", "eval_util", ".", "EvaluationMetrics", "(", "reader", ".", "num_classes", ",", "FLAGS", ".", "top_k", ")", "\n", "\n", "last_global_step_val", "=", "-", "1", "\n", "while", "True", ":", "\n", "      ", "last_global_step_val", "=", "evaluation_loop", "(", "video_id_batch", ",", "prediction_batch", ",", "\n", "label_batch", ",", "loss", ",", "summary_op", ",", "\n", "saver", ",", "summary_writer", ",", "evl_metrics", ",", "\n", "last_global_step_val", ")", "\n", "if", "FLAGS", ".", "run_once", ":", "\n", "        ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.main": [[329, 333], ["tensorflow.logging.set_verbosity", "print", "eval.evaluate"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval.evaluate"], ["", "", "", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "print", "(", "\"tensorflow version: %s\"", "%", "tf", ".", "__version__", ")", "\n", "evaluate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.inference.format_lines": [[69, 78], ["len", "range", "sorted", "numpy.argpartition", "video_ids[].decode"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "predictions", ",", "top_k", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "video_index", "]", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "pair", "\n", "for", "pair", "in", "line", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.inference.get_input_data_tensors": [[80, 114], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.inference.inference": [[115, 179], ["tensorflow.Session", "tensorflow.gfile.Open", "inference.get_input_data_tensors", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "out_file.write", "tf.train.Coordinator.join", "sess.close", "tensorflow.train.latest_checkpoint", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "inference.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.get_input_data_tensors", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run"], ["", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\"w+\"", ")", "as", "out_file", ":", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "\n", "if", "FLAGS", ".", "checkpoint_file", "==", "None", ":", "\n", "\t    ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "", "else", ":", "latest_checkpoint", "=", "FLAGS", ".", "checkpoint_file", "\n", "if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "True", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "\n", "try", ":", "\n", "      ", "f", "=", "h5py", ".", "File", "(", "FLAGS", ".", "raw_prediction", ",", "\"w\"", ")", "\n", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "]", ")", "\n", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", "}", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "try", ":", "\n", "              ", "f", ".", "create_dataset", "(", "video_id_batch_val", "[", "i", "]", ",", "data", "=", "predictions_val", "[", "i", "]", ")", "\n", "", "except", ":", "continue", "\n", "\n", "", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "for", "line", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "line", ")", "\n", "", "out_file", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.inference.main": [[181, 205], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "inference.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.inference.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.__init__": [[345, 369], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.get_data": [[374, 384], ["pudb.set_trace", "train.get_input_data_tensors"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.get_input_data_tensors"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "      ", "import", "pudb", "\n", "pudb", ".", "set_trace", "(", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "self", ".", "reader", ",", "\n", "FLAGS", ".", "train_data_pattern", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "num_epochs", "=", "1", ")", ")", "\n", "", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.run": [[384, 484], ["train.Trainer.start_server_if_distributed", "train.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "train.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "train.task_as_string", "tensorflow.train.Supervisor.managed_session", "train.task_as_string", "train.Trainer.recover_model", "tensorflow.device", "tensorflow.device", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.contrib.framework.get_model_variables", "tensorflow.contrib.framework.get_model_variables", "tensorflow.model_analyzer.analyze_vars", "tensorflow.model_analyzer.analyze_vars", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.Graph", "tensorflow.Graph", "train.Trainer.build_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "train.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "train.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.recover_model", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.build_model", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.calculate_gap", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "      ", "if", "meta_filename", ":", "\n", "        ", "saver", "=", "self", ".", "recover_model", "(", "meta_filename", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "        ", "if", "not", "meta_filename", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "15", "*", "60", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "\n", "# Check the variables and their shapes", "\n", "        ", "model_vars", "=", "tf", ".", "contrib", ".", "framework", ".", "get_model_variables", "(", ")", "\n", "slim", ".", "model_analyzer", ".", "analyze_vars", "(", "model_vars", ",", "print_info", "=", "True", ")", "\n", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "10", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.export_model": [[485, 501], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "train.Trainer.model_exporter.export_model", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.export_model", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.start_server_if_distributed": [[502, 518], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "train.task_as_string", "train.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.start_server", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.remove_training_directory": [[519, 531], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "train.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.get_meta_filename": [[532, 551], ["tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "train.task_as_string", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "not", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No checkpoint file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.recover_model": [[552, 556], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.Trainer.build_model": [[557, 579], ["train.find_class_by_name", "train.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "train.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.find_class_by_name", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.build_graph", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "# Each default, CrossEntropy Loss/ AdamOptimizer", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ",", "keep_checkpoint_every_n_hours", "=", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.__init__": [[600, 611], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run": [[612, 619], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "start_server.join", "train.task_as_string", "train.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.start_server", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.validate_class_name": [[107, 134], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.get_input_data_tensors": [[135, 178], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.find_class_by_name": [[180, 184], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.build_graph": [[185, 340], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "train.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "model.create_model.keys", "label_loss_fn.calculate_loss", "label_loss_fn.calculate_loss", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.get_input_data_tensors", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.combine_gradients", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.models.BaseModel.create_model", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.CenterLoss.calculate_loss", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.CenterLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ")", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "elif", "\"features\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ",", "feature", "=", "result", "[", "\"features\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.get_reader": [[581, 594], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.start_server": [[621, 643], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "train.task_as_string", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string": [[644, 646], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.main": [[647, 686], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "train.task_as_string", "train.get_reader", "export_model.ModelExporter", "train.Trainer.run", "train.find_class_by_name", "train.ParameterServer.run", "ValueError", "train.Trainer", "train.ParameterServer", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.get_reader", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.find_class_by_name", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.__init__": [[140, 158], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ",", "top_k", ")", ":", "\n", "    ", "\"\"\"Construct an EvaluationMetrics object to store the evaluation metrics.\n\n    Args:\n      num_class: A positive integer specifying the number of classes.\n      top_k: A positive integer specifying how many predictions are considered per video.\n\n    Raises:\n      ValueError: An error occurred when MeanAveragePrecisionCalculator cannot\n        not be constructed.\n    \"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", "=", "map_calculator", ".", "MeanAveragePrecisionCalculator", "(", "num_class", ")", "\n", "self", ".", "global_ap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "num_examples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.accumulate": [[159, 192], ["eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "numpy.mean", "eval_util.top_k_by_class", "eval_util.EvaluationMetrics.map_calculator.accumulate", "eval_util.EvaluationMetrics.global_ap_calculator.accumulate", "eval_util.flatten", "eval_util.flatten", "sum"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.flatten", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.flatten"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "labels", ",", "loss", ")", ":", "\n", "    ", "\"\"\"Accumulate the metrics calculated locally for this mini-batch.\n\n    Args:\n      predictions: A numpy matrix containing the outputs of the model.\n        Dimensions are 'batch' x 'num_classes'.\n      labels: A numpy matrix containing the ground truth labels.\n        Dimensions are 'batch' x 'num_classes'.\n      loss: A numpy array containing the loss for each sample.\n\n    Returns:\n      dictionary: A dictionary storing the metrics for the mini-batch.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n        does not match.\n    \"\"\"", "\n", "batch_size", "=", "labels", ".", "shape", "[", "0", "]", "\n", "mean_hit_at_one", "=", "calculate_hit_at_one", "(", "predictions", ",", "labels", ")", "\n", "mean_perr", "=", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "labels", ")", "\n", "mean_loss", "=", "numpy", ".", "mean", "(", "loss", ")", "\n", "\n", "# Take the top 20 predictions.", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "predictions", ",", "labels", ",", "self", ".", "top_k", ")", "\n", "self", ".", "map_calculator", ".", "accumulate", "(", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", ")", "\n", "self", ".", "global_ap_calculator", ".", "accumulate", "(", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "\n", "self", ".", "num_examples", "+=", "batch_size", "\n", "self", ".", "sum_hit_at_one", "+=", "mean_hit_at_one", "*", "batch_size", "\n", "self", ".", "sum_perr", "+=", "mean_perr", "*", "batch_size", "\n", "self", ".", "sum_loss", "+=", "mean_loss", "*", "batch_size", "\n", "\n", "return", "{", "\"hit_at_one\"", ":", "mean_hit_at_one", ",", "\"perr\"", ":", "mean_perr", ",", "\"loss\"", ":", "mean_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.get": [[193, 216], ["eval_util.EvaluationMetrics.map_calculator.peek_map_at_n", "eval_util.EvaluationMetrics.global_ap_calculator.peek_ap_at_n", "ValueError"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "get", "(", "self", ")", ":", "\n", "    ", "\"\"\"Calculate the evaluation metrics for the whole epoch.\n\n    Raises:\n      ValueError: If no examples were accumulated.\n\n    Returns:\n      dictionary: a dictionary storing the evaluation metrics for the epoch. The\n        dictionary has the fields: avg_hit_at_one, avg_perr, avg_loss, and\n        aps (default nan).\n    \"\"\"", "\n", "if", "self", ".", "num_examples", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"total_sample must be positive.\"", ")", "\n", "", "avg_hit_at_one", "=", "self", ".", "sum_hit_at_one", "/", "self", ".", "num_examples", "\n", "avg_perr", "=", "self", ".", "sum_perr", "/", "self", ".", "num_examples", "\n", "avg_loss", "=", "self", ".", "sum_loss", "/", "self", ".", "num_examples", "\n", "\n", "aps", "=", "self", ".", "map_calculator", ".", "peek_map_at_n", "(", ")", "\n", "gap", "=", "self", ".", "global_ap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n", "epoch_info_dict", "=", "{", "}", "\n", "return", "{", "\"avg_hit_at_one\"", ":", "avg_hit_at_one", ",", "\"avg_perr\"", ":", "avg_perr", ",", "\n", "\"avg_loss\"", ":", "avg_loss", ",", "\"aps\"", ":", "aps", ",", "\"gap\"", ":", "gap", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.clear": [[217, 225], ["eval_util.EvaluationMetrics.map_calculator.clear", "eval_util.EvaluationMetrics.global_ap_calculator.clear"], "methods", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the evaluation metrics and reset the EvaluationMetrics object.\"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", ".", "clear", "(", ")", "\n", "self", ".", "global_ap_calculator", ".", "clear", "(", ")", "\n", "self", ".", "num_examples", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.flatten": [[24, 27], ["None"], "function", ["None"], ["def", "flatten", "(", "l", ")", ":", "\n", "  ", "\"\"\" Merges a list of lists into a single list. \"\"\"", "\n", "return", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.calculate_hit_at_one": [[28, 43], ["numpy.argmax", "numpy.average", "numpy.arange"], "function", ["None"], ["", "def", "calculate_hit_at_one", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the hit at one.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n\n  Returns:\n    float: The average hit at one across the entire batch.\n  \"\"\"", "\n", "top_prediction", "=", "numpy", ".", "argmax", "(", "predictions", ",", "1", ")", "\n", "hits", "=", "actuals", "[", "numpy", ".", "arange", "(", "actuals", ".", "shape", "[", "0", "]", ")", ",", "top_prediction", "]", "\n", "return", "numpy", ".", "average", "(", "hits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.calculate_precision_at_equal_recall_rate": [[45, 71], ["numpy.arange", "int", "numpy.sum", "numpy.argpartition"], "function", ["None"], ["", "def", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the PERR.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n\n  Returns:\n    float: The average precision at equal recall rate across the entire batch.\n  \"\"\"", "\n", "aggregated_precision", "=", "0.0", "\n", "num_videos", "=", "actuals", ".", "shape", "[", "0", "]", "\n", "for", "row", "in", "numpy", ".", "arange", "(", "num_videos", ")", ":", "\n", "    ", "num_labels", "=", "int", "(", "numpy", ".", "sum", "(", "actuals", "[", "row", "]", ")", ")", "\n", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "row", "]", ",", "\n", "-", "num_labels", ")", "[", "-", "num_labels", ":", "]", "\n", "item_precision", "=", "0.0", "\n", "for", "label_index", "in", "top_indices", ":", "\n", "      ", "if", "predictions", "[", "row", "]", "[", "label_index", "]", ">", "0", ":", "\n", "        ", "item_precision", "+=", "actuals", "[", "row", "]", "[", "label_index", "]", "\n", "", "", "item_precision", "/=", "top_indices", ".", "size", "\n", "aggregated_precision", "+=", "item_precision", "\n", "", "aggregated_precision", "/=", "num_videos", "\n", "return", "aggregated_precision", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.calculate_gap": [[72, 91], ["average_precision_calculator.AveragePrecisionCalculator", "eval_util.top_k_by_class", "ap_calculator.AveragePrecisionCalculator.accumulate", "ap_calculator.AveragePrecisionCalculator.peek_ap_at_n", "eval_util.flatten", "eval_util.flatten", "sum"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.flatten", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.flatten"], ["", "def", "calculate_gap", "(", "predictions", ",", "actuals", ",", "top_k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the global average precision.\n\n  Only the top_k predictions are taken for each of the videos.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n    top_k: How many predictions to use per video.\n\n  Returns:\n    float: The global average precision.\n  \"\"\"", "\n", "gap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "predictions", ",", "actuals", ",", "top_k", ")", "\n", "gap_calculator", ".", "accumulate", "(", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "return", "gap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.top_k_by_class": [[93, 128], ["min", "range", "ValueError", "prediction_triplets.extend", "out_predictions[].append", "out_labels[].append", "numpy.sum", "eval_util.top_k_triplets", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.top_k_triplets"], ["", "def", "top_k_by_class", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Extracts the top k predictions for each video, sorted by class.\n\n  Args:\n    predictions: A numpy matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    k: the top k non-zero entries to preserve in each prediction.\n\n  Returns:\n    A tuple (predictions,labels, true_positives). 'predictions' and 'labels'\n    are lists of lists of floats. 'true_positives' is a list of scalars. The\n    length of the lists are equal to the number of classes. The entries in the\n    predictions variable are probability predictions, and\n    the corresponding entries in the labels variable are the ground truth for\n    those predictions. The entries in 'true_positives' are the number of true\n    positives for each class in the ground truth.\n\n  Raises:\n    ValueError: An error occurred when the k is not a positive integer.\n  \"\"\"", "\n", "if", "k", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"k must be a positive integer.\"", ")", "\n", "", "k", "=", "min", "(", "k", ",", "predictions", ".", "shape", "[", "1", "]", ")", "\n", "num_classes", "=", "predictions", ".", "shape", "[", "1", "]", "\n", "prediction_triplets", "=", "[", "]", "\n", "for", "video_index", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "prediction_triplets", ".", "extend", "(", "top_k_triplets", "(", "predictions", "[", "video_index", "]", ",", "labels", "[", "video_index", "]", ",", "k", ")", ")", "\n", "", "out_predictions", "=", "[", "[", "]", "for", "v", "in", "range", "(", "num_classes", ")", "]", "\n", "out_labels", "=", "[", "[", "]", "for", "v", "in", "range", "(", "num_classes", ")", "]", "\n", "for", "triplet", "in", "prediction_triplets", ":", "\n", "    ", "out_predictions", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "1", "]", ")", "\n", "out_labels", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "2", "]", ")", "\n", "", "out_true_positives", "=", "[", "numpy", ".", "sum", "(", "labels", "[", ":", ",", "i", "]", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "\n", "return", "out_predictions", ",", "out_labels", ",", "out_true_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.top_k_triplets": [[129, 136], ["len", "min", "numpy.argpartition"], "function", ["None"], ["", "def", "top_k_triplets", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Get the top_k for a 1-d numpy array. Returns a sparse list of tuples in\n  (prediction, class) format\"\"\"", "\n", "m", "=", "len", "(", "predictions", ")", "\n", "k", "=", "min", "(", "k", ",", "m", ")", "\n", "indices", "=", "numpy", ".", "argpartition", "(", "predictions", ",", "-", "k", ")", "[", "-", "k", ":", "]", "\n", "return", "[", "(", "index", ",", "predictions", "[", "index", "]", ",", "labels", "[", "index", "]", ")", "for", "index", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.convert_prediction_from_json_to_csv.get_csv_header": [[46, 48], ["None"], "function", ["None"], ["", "def", "get_csv_header", "(", ")", ":", "\n", "  ", "return", "\"VideoId,LabelConfidencePairs\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.convert_prediction_from_json_to_csv.to_csv_row": [[49, 69], ["isinstance", "len", "len", "ValueError", "video_id.decode", "len", "len", "builtins.range", "len"], "function", ["None"], ["", "def", "to_csv_row", "(", "json_data", ")", ":", "\n", "\n", "  ", "video_id", "=", "json_data", "[", "\"video_id\"", "]", "\n", "\n", "class_indexes", "=", "json_data", "[", "\"class_indexes\"", "]", "\n", "predictions", "=", "json_data", "[", "\"predictions\"", "]", "\n", "\n", "if", "isinstance", "(", "video_id", ",", "list", ")", ":", "\n", "    ", "video_id", "=", "video_id", "[", "0", "]", "\n", "class_indexes", "=", "class_indexes", "[", "0", "]", "\n", "predictions", "=", "predictions", "[", "0", "]", "\n", "\n", "", "if", "len", "(", "class_indexes", ")", "!=", "len", "(", "predictions", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The number of indexes (%s) and predictions (%s) must be equal.\"", "\n", "%", "(", "len", "(", "class_indexes", ")", ",", "len", "(", "predictions", ")", ")", ")", "\n", "\n", "", "return", "(", "video_id", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "\n", "(", "class_indexes", "[", "i", "]", ",", "predictions", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "class_indexes", ")", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.convert_prediction_from_json_to_csv.main": [[70, 101], ["tensorflow.logging.set_verbosity", "tensorflow.logging.info", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "ValueError", "ValueError", "tensorflow.gfile.Open", "output_file.write", "output_file.flush", "convert_prediction_from_json_to_csv.get_csv_header", "tensorflow.logging.info", "tensorflow.gfile.Open", "json.loads", "output_file.write", "convert_prediction_from_json_to_csv.to_csv_row"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.convert_prediction_from_json_to_csv.get_csv_header", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.convert_prediction_from_json_to_csv.to_csv_row"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "if", "not", "FLAGS", ".", "json_prediction_files_pattern", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The flag --json_prediction_files_pattern must be specified.\"", ")", "\n", "\n", "", "if", "not", "FLAGS", ".", "csv_output_file", ":", "\n", "    ", "raise", "ValueError", "(", "\"The flag --csv_output_file must be specified.\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Looking for prediction files with pattern: %s\"", ",", "\n", "FLAGS", ".", "json_prediction_files_pattern", ")", "\n", "\n", "file_paths", "=", "gfile", ".", "Glob", "(", "FLAGS", ".", "json_prediction_files_pattern", ")", "\n", "logging", ".", "info", "(", "\"Found files: %s\"", ",", "file_paths", ")", "\n", "\n", "logging", ".", "info", "(", "\"Writing submission file to: %s\"", ",", "FLAGS", ".", "csv_output_file", ")", "\n", "with", "gfile", ".", "Open", "(", "FLAGS", ".", "csv_output_file", ",", "\"w+\"", ")", "as", "output_file", ":", "\n", "    ", "output_file", ".", "write", "(", "get_csv_header", "(", ")", ")", "\n", "\n", "for", "file_path", "in", "file_paths", ":", "\n", "      ", "logging", ".", "info", "(", "\"processing file: %s\"", ",", "file_path", ")", "\n", "\n", "with", "gfile", ".", "Open", "(", "file_path", ")", "as", "input_file", ":", "\n", "\n", "        ", "for", "line", "in", "input_file", ":", "\n", "          ", "json_data", "=", "json", ".", "loads", "(", "line", ")", "\n", "output_file", ".", "write", "(", "to_csv_row", "(", "json_data", ")", ")", "\n", "\n", "", "", "", "output_file", ".", "flush", "(", ")", "\n", "", "logging", ".", "info", "(", "\"done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.Dequantize": [[23, 39], ["None"], "function", ["None"], ["def", "Dequantize", "(", "feat_vector", ",", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "  ", "\"\"\"Dequantize the feature from the byte format to the float format.\n\n  Args:\n    feat_vector: the input 1-d vector.\n    max_quantized_value: the maximum of the quantized value.\n    min_quantized_value: the minimum of the quantized value.\n\n  Returns:\n    A float vector which has the same shape as feat_vector.\n  \"\"\"", "\n", "assert", "max_quantized_value", ">", "min_quantized_value", "\n", "quantized_range", "=", "max_quantized_value", "-", "min_quantized_value", "\n", "scalar", "=", "quantized_range", "/", "255.0", "\n", "bias", "=", "(", "quantized_range", "/", "512.0", ")", "+", "min_quantized_value", "\n", "return", "feat_vector", "*", "scalar", "+", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary": [[41, 48], ["tensorflow.Summary", "tf.Summary.value.add", "str", "float"], "function", ["None"], ["", "def", "MakeSummary", "(", "name", ",", "value", ")", ":", "\n", "  ", "\"\"\"Creates a tf.Summary proto with the given name and value.\"\"\"", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "val", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "val", ".", "tag", "=", "str", "(", "name", ")", "\n", "val", ".", "simple_value", "=", "float", "(", "value", ")", "\n", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.AddGlobalStepSummary": [[50, 92], ["global_step_info_dict.get", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "summary_writer.add_summary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary"], ["", "def", "AddGlobalStepSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "global_step_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the global_step summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    global_step_info_dict: a dictionary of the evaluation metrics calculated for\n      a mini-batch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "this_hit_at_one", "=", "global_step_info_dict", "[", "\"hit_at_one\"", "]", "\n", "this_perr", "=", "global_step_info_dict", "[", "\"perr\"", "]", "\n", "this_loss", "=", "global_step_info_dict", "[", "\"loss\"", "]", "\n", "examples_per_second", "=", "global_step_info_dict", ".", "get", "(", "\"examples_per_second\"", ",", "-", "1", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Hit@1\"", ",", "this_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Perr\"", ",", "this_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Loss\"", ",", "this_loss", ")", ",", "\n", "global_step_val", ")", "\n", "\n", "if", "examples_per_second", "!=", "-", "1", ":", "\n", "    ", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Example_Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "info", "=", "(", "\"global_step {0} | Batch Hit@1: {1:.3f} | Batch PERR: {2:.3f} | Batch Loss: {3:.3f} \"", "\n", "\"| Examples_per_sec: {4:.3f}\"", ")", ".", "format", "(", "\n", "global_step_val", ",", "this_hit_at_one", ",", "this_perr", ",", "this_loss", ",", "\n", "examples_per_second", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.AddEpochSummary": [[94, 139], ["numpy.mean", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.MakeSummary"], ["", "def", "AddEpochSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the epoch summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    epoch_info_dict: a dictionary of the evaluation metrics calculated for the\n      whole epoch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "epoch_id", "=", "epoch_info_dict", "[", "\"epoch_id\"", "]", "\n", "avg_hit_at_one", "=", "epoch_info_dict", "[", "\"avg_hit_at_one\"", "]", "\n", "avg_perr", "=", "epoch_info_dict", "[", "\"avg_perr\"", "]", "\n", "avg_loss", "=", "epoch_info_dict", "[", "\"avg_loss\"", "]", "\n", "aps", "=", "epoch_info_dict", "[", "\"aps\"", "]", "\n", "gap", "=", "epoch_info_dict", "[", "\"gap\"", "]", "\n", "mean_ap", "=", "numpy", ".", "mean", "(", "aps", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Hit@1\"", ",", "avg_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Perr\"", ",", "avg_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Loss\"", ",", "avg_loss", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_MAP\"", ",", "mean_ap", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_GAP\"", ",", "gap", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "info", "=", "(", "\"epoch/eval number {0} | Avg_Hit@1: {1:.3f} | Avg_PERR: {2:.3f} \"", "\n", "\"| MAP: {3:.3f} | GAP: {4:.3f} | Avg_Loss: {5:3f}\"", ")", ".", "format", "(", "\n", "epoch_id", ",", "avg_hit_at_one", ",", "avg_perr", ",", "mean_ap", ",", "gap", ",", "avg_loss", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.GetListOfFeatureNamesAndSizes": [[140, 162], ["feature_names.strip", "int", "len", "len", "tensorflow.logging.error", "feature_names.split", "feature_sizes.split", "str", "len", "str", "len"], "function", ["None"], ["", "def", "GetListOfFeatureNamesAndSizes", "(", "feature_names", ",", "feature_sizes", ")", ":", "\n", "  ", "\"\"\"Extract the list of feature names and the dimensionality of each feature\n     from string of comma separated values.\n\n  Args:\n    feature_names: string containing comma separated list of feature names\n    feature_sizes: string containing comma separated list of feature sizes\n\n  Returns:\n    List of the feature names and list of the dimensionality of each feature.\n    Elements in the first/second list are strings/integers.\n  \"\"\"", "\n", "list_of_feature_names", "=", "[", "\n", "feature_names", ".", "strip", "(", ")", "for", "feature_names", "in", "feature_names", ".", "split", "(", "','", ")", "]", "\n", "list_of_feature_sizes", "=", "[", "\n", "int", "(", "feature_sizes", ")", "for", "feature_sizes", "in", "feature_sizes", ".", "split", "(", "','", ")", "]", "\n", "if", "len", "(", "list_of_feature_names", ")", "!=", "len", "(", "list_of_feature_sizes", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"length of the feature names (=\"", "+", "\n", "str", "(", "len", "(", "list_of_feature_names", ")", ")", "+", "\") != length of feature \"", "\n", "\"sizes (=\"", "+", "str", "(", "len", "(", "list_of_feature_sizes", ")", ")", "+", "\")\"", ")", "\n", "\n", "", "return", "list_of_feature_names", ",", "list_of_feature_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.clip_gradient_norms": [[163, 183], ["clipped_grads_and_vars.append", "isinstance", "tensorflow.clip_by_norm", "tensorflow.IndexedSlices", "tensorflow.clip_by_norm"], "function", ["None"], ["", "def", "clip_gradient_norms", "(", "gradients_to_variables", ",", "max_norm", ")", ":", "\n", "  ", "\"\"\"Clips the gradients by the given value.\n\n  Args:\n    gradients_to_variables: A list of gradient to variable pairs (tuples).\n    max_norm: the maximum norm value.\n\n  Returns:\n    A list of clipped gradient to variable pairs.\n  \"\"\"", "\n", "clipped_grads_and_vars", "=", "[", "]", "\n", "for", "grad", ",", "var", "in", "gradients_to_variables", ":", "\n", "    ", "if", "grad", "is", "not", "None", ":", "\n", "      ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "        ", "tmp", "=", "tf", ".", "clip_by_norm", "(", "grad", ".", "values", ",", "max_norm", ")", "\n", "grad", "=", "tf", ".", "IndexedSlices", "(", "tmp", ",", "grad", ".", "indices", ",", "grad", ".", "dense_shape", ")", "\n", "", "else", ":", "\n", "        ", "grad", "=", "tf", ".", "clip_by_norm", "(", "grad", ",", "max_norm", ")", "\n", "", "", "clipped_grads_and_vars", ".", "append", "(", "(", "grad", ",", "var", ")", ")", "\n", "", "return", "clipped_grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.utils.combine_gradients": [[184, 206], ["xrange", "len", "tensorflow.stack", "tensorflow.reduce_sum", "final_grads.append", "xrange", "len"], "function", ["None"], ["", "def", "combine_gradients", "(", "tower_grads", ")", ":", "\n", "  ", "\"\"\"Calculate the combined gradient for each shared variable across all towers.\n\n  Note that this function provides a synchronization point across all towers.\n\n  Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n      is over individual gradients. The inner list is over the gradient\n      calculation for each tower.\n  Returns:\n     List of pairs of (gradient, variable) where the gradient has been summed\n     across all towers.\n  \"\"\"", "\n", "filtered_grads", "=", "[", "[", "x", "for", "x", "in", "grad_list", "if", "x", "[", "0", "]", "is", "not", "None", "]", "for", "grad_list", "in", "tower_grads", "]", "\n", "final_grads", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "filtered_grads", "[", "0", "]", ")", ")", ":", "\n", "    ", "grads", "=", "[", "filtered_grads", "[", "t", "]", "[", "i", "]", "for", "t", "in", "xrange", "(", "len", "(", "filtered_grads", ")", ")", "]", "\n", "grad", "=", "tf", ".", "stack", "(", "[", "x", "[", "0", "]", "for", "x", "in", "grads", "]", ",", "0", ")", "\n", "grad", "=", "tf", ".", "reduce_sum", "(", "grad", ",", "0", ")", "\n", "final_grads", ".", "append", "(", "(", "grad", ",", "filtered_grads", "[", "0", "]", "[", "i", "]", "[", "1", "]", ",", ")", ")", "\n", "\n", "", "return", "final_grads", "\n", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.BaseLoss.calculate_loss": [[30, 45], ["NotImplementedError"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "unused_predictions", ",", "unused_labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Calculates the average loss of the examples in a mini-batch.\n\n     Args:\n      unused_predictions: a 2-d tensor storing the prediction scores, in which\n        each row represents a sample in the mini-batch and each column\n        represents a class.\n      unused_labels: a 2-d tensor storing the labels, which has the same shape\n        as the unused_predictions. The labels must be in the range of 0 and 1.\n      unused_params: loss specific parameters.\n\n    Returns:\n      A scalar loss tensor.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.CrossEntropyLoss.calculate_loss": [[51, 59], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.negative", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_xent\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-6", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "cross_entropy_loss", "=", "float_labels", "*", "tf", ".", "log", "(", "predictions", "+", "epsilon", ")", "+", "(", "\n", "1", "-", "float_labels", ")", "*", "tf", ".", "log", "(", "1", "-", "predictions", "+", "epsilon", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "negative", "(", "cross_entropy_loss", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.L2_CrossEntropyLoss.calculate_loss": [[64, 73], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.negative", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_xent\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-6", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "cross_entropy_loss", "=", "float_labels", "*", "tf", ".", "log", "(", "predictions", "+", "epsilon", ")", "+", "(", "\n", "1", "-", "float_labels", ")", "*", "tf", ".", "log", "(", "1", "-", "predictions", "+", "epsilon", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "negative", "(", "cross_entropy_loss", ")", "\n", "cross_entropy_loss", "=", "cross_entropy_loss", "*", "cross_entropy_loss", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.Huber_CrossEntropyLoss.calculate_loss": [[78, 90], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.negative", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log", "tensorflow.sqrt"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_xent\"", ")", ":", "\n", "      ", "delta", "=", "FLAGS", ".", "delta", "\n", "epsilon", "=", "10e-6", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "cross_entropy_loss", "=", "float_labels", "*", "tf", ".", "log", "(", "predictions", "+", "epsilon", ")", "+", "(", "\n", "1", "-", "float_labels", ")", "*", "tf", ".", "log", "(", "1", "-", "predictions", "+", "epsilon", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "negative", "(", "cross_entropy_loss", ")", "\n", "\n", "# Huber Loss Approximation", "\n", "cross_entropy_loss", "=", "delta", "*", "delta", "*", "(", "tf", ".", "sqrt", "(", "1", "+", "(", "cross_entropy_loss", "/", "delta", ")", "*", "(", "cross_entropy_loss", "/", "delta", ")", ")", "-", "1", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.HingeLoss.calculate_loss": [[99, 108], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.zeros", "tensorflow.ones", "tensorflow.subtract", "tensorflow.maximum", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape", "tensorflow.scalar_mul", "tensorflow.reduce_sum", "tensorflow.scalar_mul"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "b", "=", "1.0", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_hinge\"", ")", ":", "\n", "      ", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "all_zeros", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "sign_labels", "=", "tf", ".", "subtract", "(", "tf", ".", "scalar_mul", "(", "2", ",", "float_labels", ")", ",", "all_ones", ")", "\n", "hinge_loss", "=", "tf", ".", "maximum", "(", "\n", "all_zeros", ",", "tf", ".", "scalar_mul", "(", "b", ",", "all_ones", ")", "-", "sign_labels", "*", "predictions", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "hinge_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.L2_HingeLoss.calculate_loss": [[117, 127], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.zeros", "tensorflow.ones", "tensorflow.subtract", "tensorflow.maximum", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape", "tensorflow.scalar_mul", "tensorflow.reduce_sum", "tensorflow.scalar_mul"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "b", "=", "1.0", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_hinge\"", ")", ":", "\n", "      ", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "all_zeros", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "sign_labels", "=", "tf", ".", "subtract", "(", "tf", ".", "scalar_mul", "(", "2", ",", "float_labels", ")", ",", "all_ones", ")", "\n", "hinge_loss", "=", "tf", ".", "maximum", "(", "\n", "all_zeros", ",", "tf", ".", "scalar_mul", "(", "b", ",", "all_ones", ")", "-", "sign_labels", "*", "predictions", ")", "\n", "hinge_loss", "=", "hinge_loss", "*", "hinge_loss", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "hinge_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.Huber_HingeLoss.calculate_loss": [[137, 151], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.zeros", "tensorflow.ones", "tensorflow.subtract", "tensorflow.maximum", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape", "tensorflow.scalar_mul", "tensorflow.reduce_sum", "tensorflow.scalar_mul", "tensorflow.sqrt"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "b", "=", "1.0", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_hinge\"", ")", ":", "\n", "      ", "delta", "=", "FLAGS", ".", "delta", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "all_zeros", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "sign_labels", "=", "tf", ".", "subtract", "(", "tf", ".", "scalar_mul", "(", "2", ",", "float_labels", ")", ",", "all_ones", ")", "\n", "hinge_loss", "=", "tf", ".", "maximum", "(", "\n", "all_zeros", ",", "tf", ".", "scalar_mul", "(", "b", ",", "all_ones", ")", "-", "sign_labels", "*", "predictions", ")", "\n", "\n", "# Huber Loss Approximation", "\n", "hinge_loss_entropy_loss", "=", "delta", "*", "delta", "*", "(", "tf", ".", "sqrt", "(", "1", "+", "(", "hinge_loss", "/", "delta", ")", "*", "(", "hinge_loss", "/", "delta", ")", ")", "-", "1", ")", "\n", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "hinge_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.SoftmaxLoss.calculate_loss": [[167, 180], ["tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.maximum", "tensorflow.div", "tensorflow.nn.softmax", "tensorflow.negative", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_softmax\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-8", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "# l1 normalization (labels are no less than 0)", "\n", "label_rowsum", "=", "tf", ".", "maximum", "(", "\n", "tf", ".", "reduce_sum", "(", "float_labels", ",", "1", ",", "keep_dims", "=", "True", ")", ",", "\n", "epsilon", ")", "\n", "norm_float_labels", "=", "tf", ".", "div", "(", "float_labels", ",", "label_rowsum", ")", "\n", "softmax_outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "predictions", ")", "\n", "softmax_loss", "=", "tf", ".", "negative", "(", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "norm_float_labels", ",", "tf", ".", "log", "(", "softmax_outputs", ")", ")", ",", "1", ")", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "softmax_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.src.losses.CenterLoss.calculate_loss": [[186, 218], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.negative", "tensorflow.reduce_mean", "tensorflow.get_variable", "tensorflow.where", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.gather", "tensorflow.gather", "tensorflow.scatter_sub", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.equal", "tensorflow.slice", "tensorflow.slice", "tensorflow.squared_difference", "tensorflow.log", "tensorflow.log", "tensorflow.constant_initializer"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_center\"", ")", ":", "\n", "\n", "      ", "epsilon", "=", "FLAGS", ".", "epsilon", "\n", "alfa", "=", "FLAGS", ".", "alfa", "\n", "beta", "=", "FLAGS", ".", "beta", "\n", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "cross_entropy_loss", "=", "float_labels", "*", "tf", ".", "log", "(", "predictions", "+", "epsilon", ")", "+", "(", "\n", "1", "-", "float_labels", ")", "*", "tf", ".", "log", "(", "1", "-", "predictions", "+", "epsilon", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "negative", "(", "cross_entropy_loss", ")", "\n", "xent_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ",", "1", ")", ")", "\n", "\n", "features", "=", "unused_params", "[", "'feature'", "]", "\n", "centers", "=", "tf", ".", "get_variable", "(", "'centers'", ",", "[", "labels", ".", "shape", "[", "1", "]", ",", "features", ".", "shape", "[", "1", "]", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ",", "trainable", "=", "False", ")", "\n", "\n", "multi_label", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "float_labels", ",", "1", ")", ")", "\n", "\n", "feature_index", "=", "tf", ".", "squeeze", "(", "tf", ".", "slice", "(", "multi_label", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "1", "]", ")", ")", "\n", "label_index", "=", "tf", ".", "squeeze", "(", "tf", ".", "slice", "(", "multi_label", ",", "[", "0", ",", "1", "]", ",", "[", "-", "1", ",", "1", "]", ")", ")", "\n", "\n", "features_batch", "=", "tf", ".", "gather", "(", "features", ",", "feature_index", ")", "\n", "centers_batch", "=", "tf", ".", "gather", "(", "centers", ",", "label_index", ")", "\n", "diff", "=", "(", "1", "-", "alfa", ")", "*", "(", "centers_batch", "-", "features_batch", ")", "\n", "centers", "=", "tf", ".", "scatter_sub", "(", "centers", ",", "label_index", ",", "diff", ")", "\n", "#center_loss = tf.nn.l2_loss(features_batch - centers_batch)", "\n", "center_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "features_batch", ",", "centers_batch", ")", ")", "\n", "\n", "loss", "=", "xent_loss", "+", "beta", "*", "center_loss", "\n", "\n", "return", "loss", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling._fft": [[8, 13], ["sequential_fft.sequential_batch_fft", "tensorflow.fft"], "function", ["None"], ["def", "_fft", "(", "bottom", ",", "sequential", ",", "compute_size", ")", ":", "\n", "    ", "if", "sequential", ":", "\n", "        ", "return", "sequential_batch_fft", "(", "bottom", ",", "compute_size", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "fft", "(", "bottom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling._ifft": [[14, 19], ["sequential_fft.sequential_batch_ifft", "tensorflow.ifft"], "function", ["None"], ["", "", "def", "_ifft", "(", "bottom", ",", "sequential", ",", "compute_size", ")", ":", "\n", "    ", "if", "sequential", ":", "\n", "        ", "return", "sequential_batch_ifft", "(", "bottom", ",", "compute_size", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "ifft", "(", "bottom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling._generate_sketch_matrix": [[20, 46], ["rand_h.astype.astype", "rand_s.astype.astype", "len", "numpy.concatenate", "tensorflow.sparse_reorder", "numpy.all", "numpy.all", "tensorflow.SparseTensor", "len", "len", "numpy.arange"], "function", ["None"], ["", "", "def", "_generate_sketch_matrix", "(", "rand_h", ",", "rand_s", ",", "output_dim", ")", ":", "\n", "    ", "\"\"\"\n    Return a sparse matrix used for tensor sketch operation in compact bilinear\n    pooling\n\n    Args:\n        rand_h: an 1D numpy array containing indices in interval `[0, output_dim)`.\n        rand_s: an 1D numpy array of 1 and -1, having the same shape as `rand_h`.\n        output_dim: the output dimensions of compact bilinear pooling.\n\n    Returns:\n        a sparse matrix of shape [input_dim, output_dim] for tensor sketch.\n    \"\"\"", "\n", "\n", "# Generate a sparse matrix for tensor count sketch", "\n", "rand_h", "=", "rand_h", ".", "astype", "(", "np", ".", "int64", ")", "\n", "rand_s", "=", "rand_s", ".", "astype", "(", "np", ".", "float32", ")", "\n", "assert", "(", "rand_h", ".", "ndim", "==", "1", "and", "rand_s", ".", "ndim", "==", "1", "and", "len", "(", "rand_h", ")", "==", "len", "(", "rand_s", ")", ")", "\n", "assert", "(", "np", ".", "all", "(", "rand_h", ">=", "0", ")", "and", "np", ".", "all", "(", "rand_h", "<", "output_dim", ")", ")", "\n", "\n", "input_dim", "=", "len", "(", "rand_h", ")", "\n", "indices", "=", "np", ".", "concatenate", "(", "(", "np", ".", "arange", "(", "input_dim", ")", "[", "...", ",", "np", ".", "newaxis", "]", ",", "\n", "rand_h", "[", "...", ",", "np", ".", "newaxis", "]", ")", ",", "axis", "=", "1", ")", "\n", "sparse_sketch_matrix", "=", "tf", ".", "sparse_reorder", "(", "\n", "tf", ".", "SparseTensor", "(", "indices", ",", "rand_s", ",", "[", "input_dim", ",", "output_dim", "]", ")", ")", "\n", "return", "sparse_sketch_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling.compact_bilinear_pooling_layer": [[47, 156], ["compact_bilinear_pooling._generate_sketch_matrix", "compact_bilinear_pooling._generate_sketch_matrix", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "compact_bilinear_pooling._fft", "compact_bilinear_pooling._fft", "tensorflow.multiply", "tensorflow.real", "tensorflow.add", "tensorflow.reshape", "bottom1.get_shape().as_list", "bottom2.get_shape().as_list", "numpy.random.seed", "numpy.random.randint", "numpy.random.seed", "numpy.random.seed", "numpy.random.randint", "numpy.random.seed", "tensorflow.sparse_tensor_dense_matmul", "tensorflow.sparse_tensor_dense_matmul", "tensorflow.complex", "tensorflow.complex", "compact_bilinear_pooling._ifft", "tensorflow.multiply", "tensorflow.reduce_sum", "tensorflow.shape", "bottom1.get_shape", "bottom2.get_shape", "numpy.random.randint", "numpy.random.randint", "tensorflow.zeros_like", "tensorflow.zeros_like"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling._generate_sketch_matrix", "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling._generate_sketch_matrix", "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling._fft", "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling._fft", "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling._ifft"], ["", "def", "compact_bilinear_pooling_layer", "(", "bottom1", ",", "bottom2", ",", "output_dim", ",", "sum_pool", "=", "True", ",", "\n", "rand_h_1", "=", "None", ",", "rand_s_1", "=", "None", ",", "rand_h_2", "=", "None", ",", "rand_s_2", "=", "None", ",", "\n", "seed_h_1", "=", "1", ",", "seed_s_1", "=", "3", ",", "seed_h_2", "=", "5", ",", "seed_s_2", "=", "7", ",", "sequential", "=", "True", ",", "\n", "compute_size", "=", "128", ")", ":", "\n", "    ", "\"\"\"\n    Compute compact bilinear pooling over two bottom inputs. Reference:\n\n    Yang Gao, et al. \"Compact Bilinear Pooling.\" in Proceedings of IEEE\n    Conference on Computer Vision and Pattern Recognition (2016).\n    Akira Fukui, et al. \"Multimodal Compact Bilinear Pooling for Visual Question\n    Answering and Visual Grounding.\" arXiv preprint arXiv:1606.01847 (2016).\n\n    Args:\n        bottom1: 1st input, 4D Tensor of shape [batch_size, height, width, input_dim1].\n        bottom2: 2nd input, 4D Tensor of shape [batch_size, height, width, input_dim2].\n\n        output_dim: output dimension for compact bilinear pooling.\n\n        sum_pool: (Optional) If True, sum the output along height and width\n                  dimensions and return output shape [batch_size, output_dim].\n                  Otherwise return [batch_size, height, width, output_dim].\n                  Default: True.\n\n        rand_h_1: (Optional) an 1D numpy array containing indices in interval\n                  `[0, output_dim)`. Automatically generated from `seed_h_1`\n                  if is None.\n        rand_s_1: (Optional) an 1D numpy array of 1 and -1, having the same shape\n                  as `rand_h_1`. Automatically generated from `seed_s_1` if is\n                  None.\n        rand_h_2: (Optional) an 1D numpy array containing indices in interval\n                  `[0, output_dim)`. Automatically generated from `seed_h_2`\n                  if is None.\n        rand_s_2: (Optional) an 1D numpy array of 1 and -1, having the same shape\n                  as `rand_h_2`. Automatically generated from `seed_s_2` if is\n                  None.\n\n        sequential: (Optional) if True, use the sequential FFT and IFFT\n                    instead of tf.batch_fft or tf.batch_ifft to avoid\n                    out-of-memory (OOM) error.\n                    Note: sequential FFT and IFFT are only available on GPU\n                    Default: True.\n        compute_size: (Optional) The maximum size of sub-batch to be forwarded\n                      through FFT or IFFT in one time. Large compute_size may\n                      be faster but can cause OOM and FFT failure. This\n                      parameter is only effective when sequential == True.\n                      Default: 128.\n\n    Returns:\n        Compact bilinear pooled results of shape [batch_size, output_dim] or\n        [batch_size, height, width, output_dim], depending on `sum_pool`.\n    \"\"\"", "\n", "\n", "# Static shapes are needed to construction count sketch matrix", "\n", "input_dim1", "=", "bottom1", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "input_dim2", "=", "bottom2", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "# Step 0: Generate vectors and sketch matrix for tensor count sketch", "\n", "# This is only done once during graph construction, and fixed during each", "\n", "# operation", "\n", "if", "rand_h_1", "is", "None", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed_h_1", ")", "\n", "rand_h_1", "=", "np", ".", "random", ".", "randint", "(", "output_dim", ",", "size", "=", "input_dim1", ")", "\n", "", "if", "rand_s_1", "is", "None", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed_s_1", ")", "\n", "rand_s_1", "=", "2", "*", "np", ".", "random", ".", "randint", "(", "2", ",", "size", "=", "input_dim1", ")", "-", "1", "\n", "", "sparse_sketch_matrix1", "=", "_generate_sketch_matrix", "(", "rand_h_1", ",", "rand_s_1", ",", "output_dim", ")", "\n", "if", "rand_h_2", "is", "None", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed_h_2", ")", "\n", "rand_h_2", "=", "np", ".", "random", ".", "randint", "(", "output_dim", ",", "size", "=", "input_dim2", ")", "\n", "", "if", "rand_s_2", "is", "None", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed_s_2", ")", "\n", "rand_s_2", "=", "2", "*", "np", ".", "random", ".", "randint", "(", "2", ",", "size", "=", "input_dim2", ")", "-", "1", "\n", "", "sparse_sketch_matrix2", "=", "_generate_sketch_matrix", "(", "rand_h_2", ",", "rand_s_2", ",", "output_dim", ")", "\n", "\n", "# Step 1: Flatten the input tensors and count sketch", "\n", "bottom1_flat", "=", "tf", ".", "reshape", "(", "bottom1", ",", "[", "-", "1", ",", "input_dim1", "]", ")", "\n", "bottom2_flat", "=", "tf", ".", "reshape", "(", "bottom2", ",", "[", "-", "1", ",", "input_dim2", "]", ")", "\n", "# Essentially:", "\n", "#   sketch1 = bottom1 * sparse_sketch_matrix", "\n", "#   sketch2 = bottom2 * sparse_sketch_matrix", "\n", "# But tensorflow only supports left multiplying a sparse matrix, so:", "\n", "#   sketch1 = (sparse_sketch_matrix.T * bottom1.T).T", "\n", "#   sketch2 = (sparse_sketch_matrix.T * bottom2.T).T", "\n", "sketch1", "=", "tf", ".", "transpose", "(", "tf", ".", "sparse_tensor_dense_matmul", "(", "sparse_sketch_matrix1", ",", "\n", "bottom1_flat", ",", "adjoint_a", "=", "True", ",", "adjoint_b", "=", "True", ")", ")", "\n", "sketch2", "=", "tf", ".", "transpose", "(", "tf", ".", "sparse_tensor_dense_matmul", "(", "sparse_sketch_matrix2", ",", "\n", "bottom2_flat", ",", "adjoint_a", "=", "True", ",", "adjoint_b", "=", "True", ")", ")", "\n", "\n", "# Step 2: FFT", "\n", "fft1", "=", "_fft", "(", "tf", ".", "complex", "(", "real", "=", "sketch1", ",", "imag", "=", "tf", ".", "zeros_like", "(", "sketch1", ")", ")", ",", "\n", "sequential", ",", "compute_size", ")", "\n", "fft2", "=", "_fft", "(", "tf", ".", "complex", "(", "real", "=", "sketch2", ",", "imag", "=", "tf", ".", "zeros_like", "(", "sketch2", ")", ")", ",", "\n", "sequential", ",", "compute_size", ")", "\n", "\n", "# Step 3: Elementwise product", "\n", "fft_product", "=", "tf", ".", "multiply", "(", "fft1", ",", "fft2", ")", "\n", "\n", "# Step 4: Inverse FFT and reshape back", "\n", "# Compute output shape dynamically: [batch_size, height, width, output_dim]", "\n", "cbp_flat", "=", "tf", ".", "real", "(", "_ifft", "(", "fft_product", ",", "sequential", ",", "compute_size", ")", ")", "\n", "output_shape", "=", "tf", ".", "add", "(", "tf", ".", "multiply", "(", "tf", ".", "shape", "(", "bottom1", ")", ",", "[", "1", ",", "1", ",", "1", ",", "0", "]", ")", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "output_dim", "]", ")", "\n", "cbp", "=", "tf", ".", "reshape", "(", "cbp_flat", ",", "output_shape", ")", "\n", "\n", "# Step 5: Sum pool over spatial dimensions, if specified", "\n", "if", "sum_pool", ":", "\n", "        ", "cbp", "=", "tf", ".", "reduce_sum", "(", "cbp", ",", "reduction_indices", "=", "[", "1", ",", "2", "]", ")", "\n", "\n", "", "return", "cbp", "\n", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.bp": [[7, 23], ["numpy.all", "bottom1.reshape", "bottom2.reshape", "numpy.empty", "range", "np.sum.reshape", "len", "numpy.outer().reshape", "numpy.sum", "numpy.outer"], "function", ["None"], ["def", "bp", "(", "bottom1", ",", "bottom2", ",", "sum_pool", "=", "True", ")", ":", "\n", "    ", "assert", "(", "np", ".", "all", "(", "bottom1", ".", "shape", "[", ":", "3", "]", "==", "bottom2", ".", "shape", "[", ":", "3", "]", ")", ")", "\n", "batch_size", ",", "height", ",", "width", "=", "bottom1", ".", "shape", "[", ":", "3", "]", "\n", "output_dim", "=", "bottom1", ".", "shape", "[", "-", "1", "]", "*", "bottom2", ".", "shape", "[", "-", "1", "]", "\n", "\n", "bottom1_flat", "=", "bottom1", ".", "reshape", "(", "(", "-", "1", ",", "bottom1", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "bottom2_flat", "=", "bottom2", ".", "reshape", "(", "(", "-", "1", ",", "bottom2", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "\n", "output", "=", "np", ".", "empty", "(", "(", "batch_size", "*", "height", "*", "width", ",", "output_dim", ")", ",", "np", ".", "float32", ")", "\n", "for", "n", "in", "range", "(", "len", "(", "output", ")", ")", ":", "\n", "        ", "output", "[", "n", ",", "...", "]", "=", "np", ".", "outer", "(", "bottom1_flat", "[", "n", "]", ",", "bottom2_flat", "[", "n", "]", ")", ".", "reshape", "(", "-", "1", ")", "\n", "", "output", "=", "output", ".", "reshape", "(", "(", "batch_size", ",", "height", ",", "width", ",", "output_dim", ")", ")", "\n", "\n", "if", "sum_pool", ":", "\n", "        ", "output", "=", "np", ".", "sum", "(", "output", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.cbp": [[34, 38], ["tensorflow.get_default_session", "tf.get_default_session.run"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run"], ["def", "cbp", "(", "bottom1_value", ",", "bottom2_value", ")", ":", "\n", "    ", "sess", "=", "tf", ".", "get_default_session", "(", ")", "\n", "return", "sess", ".", "run", "(", "top", ",", "feed_dict", "=", "{", "bottom1", ":", "bottom1_value", ",", "\n", "bottom2", ":", "bottom2_value", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.cbp_with_grad": [[39, 43], ["tensorflow.get_default_session", "tf.get_default_session.run"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run"], ["", "def", "cbp_with_grad", "(", "bottom1_value", ",", "bottom2_value", ")", ":", "\n", "    ", "sess", "=", "tf", ".", "get_default_session", "(", ")", "\n", "return", "sess", ".", "run", "(", "[", "top", "]", "+", "grad", ",", "feed_dict", "=", "{", "bottom1", ":", "bottom1_value", ",", "\n", "bottom2", ":", "bottom2_value", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.test_kernel_approximation": [[44, 71], ["print", "numpy.random.rand().astype", "numpy.random.rand().astype", "numpy.random.rand().astype", "numpy.random.rand().astype", "compact_bilinear_pooling_test.cbp", "compact_bilinear_pooling_test.cbp", "compact_bilinear_pooling_test.bp", "compact_bilinear_pooling_test.bp", "numpy.sum", "numpy.sum", "print", "print", "numpy.all", "print", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.cbp", "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.cbp", "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.bp", "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.bp"], ["", "def", "test_kernel_approximation", "(", "batch_size", ",", "height", ",", "width", ")", ":", "\n", "    ", "print", "(", "\"Testing kernel approximation...\"", ")", "\n", "\n", "# Input values", "\n", "x", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "height", ",", "width", ",", "input_dim1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "y", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "height", ",", "width", ",", "input_dim2", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "z", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "height", ",", "width", ",", "input_dim1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "w", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "height", ",", "width", ",", "input_dim2", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "# Compact Bilinear Pooling results", "\n", "cbp_xy", "=", "cbp", "(", "x", ",", "y", ")", "\n", "cbp_zw", "=", "cbp", "(", "z", ",", "w", ")", "\n", "\n", "# (Original) Bilinear Pooling results", "\n", "bp_xy", "=", "bp", "(", "x", ",", "y", ")", "\n", "bp_zw", "=", "bp", "(", "z", ",", "w", ")", "\n", "\n", "# Check the kernel results of Compact Bilinear Pooling", "\n", "# against Bilinear Pooling", "\n", "cbp_kernel", "=", "np", ".", "sum", "(", "cbp_xy", "*", "cbp_zw", ",", "axis", "=", "1", ")", "\n", "bp_kernel", "=", "np", ".", "sum", "(", "bp_xy", "*", "bp_zw", ",", "axis", "=", "1", ")", "\n", "ratio", "=", "cbp_kernel", "/", "bp_kernel", "\n", "print", "(", "\"ratio between Compact Bilinear Pooling (CBP) and Bilinear Pooling (BP):\"", ")", "\n", "print", "(", "ratio", ")", "\n", "assert", "(", "np", ".", "all", "(", "np", ".", "abs", "(", "ratio", "-", "1", ")", "<", "2e-2", ")", ")", "\n", "print", "(", "\"Passed.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.test_large_input": [[72, 84], ["print", "numpy.random.rand().astype", "numpy.random.rand().astype", "compact_bilinear_pooling_test.cbp_with_grad", "print", "numpy.random.rand", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.cbp_with_grad"], ["", "def", "test_large_input", "(", "batch_size", ",", "height", ",", "width", ")", ":", "\n", "    ", "print", "(", "\"Testing large input...\"", ")", "\n", "\n", "# Input values", "\n", "x", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "height", ",", "width", ",", "input_dim1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "y", "=", "np", ".", "random", ".", "rand", "(", "batch_size", ",", "height", ",", "width", ",", "input_dim2", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "# Compact Bilinear Pooling results", "\n", "_", "=", "cbp_with_grad", "(", "x", ",", "y", ")", "\n", "\n", "# Test passes iff no exception occurs.", "\n", "print", "(", "\"Passed.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.main": [[85, 90], ["tensorflow.InteractiveSession", "compact_bilinear_pooling_test.test_kernel_approximation", "compact_bilinear_pooling_test.test_large_input", "tf.InteractiveSession.close"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.cbp.compact_bilinear_pooling_test.test_kernel_approximation", "home.repos.pwc.inspect_result.seilna_youtube-8m.sequential_fft.sequential_batch_fft_test.test_large_input"], ["", "def", "main", "(", ")", ":", "\n", "    ", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "test_kernel_approximation", "(", "batch_size", "=", "2", ",", "height", "=", "3", ",", "width", "=", "4", ")", "\n", "test_large_input", "(", "batch_size", "=", "64", ",", "height", "=", "14", ",", "width", "=", "14", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.sequential_fft.sequential_batch_fft_ops._SequentialBatchFFTGrad": [[24, 34], ["tensorflow.python.framework.ops.RegisterGradient", "tensorflow.cast", "tensorflow.cast", "sequential_batch_ifft", "tensorflow.complex", "sequential_batch_ifft", "tensorflow.complex", "tensorflow.shape", "op.get_attr", "tensorflow.shape", "op.get_attr", "tensorflow.zeros"], "function", ["None"], ["@", "ops", ".", "RegisterGradient", "(", "\"SequentialBatchFFT\"", ")", "\n", "def", "_SequentialBatchFFTGrad", "(", "op", ",", "grad", ")", ":", "\n", "    ", "if", "(", "grad", ".", "dtype", "==", "tf", ".", "complex64", ")", ":", "\n", "        ", "size", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "grad", ")", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "return", "(", "sequential_batch_ifft", "(", "grad", ",", "op", ".", "get_attr", "(", "\"compute_size\"", ")", ")", "\n", "*", "tf", ".", "complex", "(", "size", ",", "0.", ")", ")", "\n", "", "else", ":", "\n", "        ", "size", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "grad", ")", "[", "1", "]", ",", "tf", ".", "float64", ")", "\n", "return", "(", "sequential_batch_ifft", "(", "grad", ",", "op", ".", "get_attr", "(", "\"compute_size\"", ")", ")", "\n", "*", "tf", ".", "complex", "(", "size", ",", "tf", ".", "zeros", "(", "[", "]", ",", "tf", ".", "float64", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.sequential_fft.sequential_batch_fft_ops._SequentialBatchIFFTGrad": [[35, 45], ["tensorflow.python.framework.ops.RegisterGradient", "tensorflow.cast", "sequential_batch_fft", "tensorflow.complex", "tensorflow.cast", "sequential_batch_fft", "tensorflow.complex", "op.get_attr", "op.get_attr", "tensorflow.zeros", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "", "@", "ops", ".", "RegisterGradient", "(", "\"SequentialBatchIFFT\"", ")", "\n", "def", "_SequentialBatchIFFTGrad", "(", "op", ",", "grad", ")", ":", "\n", "    ", "if", "(", "grad", ".", "dtype", "==", "tf", ".", "complex64", ")", ":", "\n", "        ", "rsize", "=", "1.", "/", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "grad", ")", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "return", "(", "sequential_batch_fft", "(", "grad", ",", "op", ".", "get_attr", "(", "\"compute_size\"", ")", ")", "\n", "*", "tf", ".", "complex", "(", "rsize", ",", "0.", ")", ")", "\n", "", "else", ":", "\n", "        ", "rsize", "=", "1.", "/", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "grad", ")", "[", "1", "]", ",", "tf", ".", "float64", ")", "\n", "return", "(", "sequential_batch_fft", "(", "grad", ",", "op", ".", "get_attr", "(", "\"compute_size\"", ")", ")", "\n", "*", "tf", ".", "complex", "(", "rsize", ",", "tf", ".", "zeros", "(", "[", "]", ",", "tf", ".", "float64", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.seilna_youtube-8m.sequential_fft.sequential_batch_fft_test.test_shape": [[28, 44], ["print", "tensorflow.placeholder", "sequential_batch_fft_ops.sequential_batch_fft", "sequential_batch_fft_ops.sequential_batch_ifft", "print", "tensorflow.gradients", "tensorflow.gradients", "sequential_batch_fft_ops.sequential_batch_fft.get_shape", "tf.placeholder.get_shape", "sequential_batch_fft_ops.sequential_batch_ifft.get_shape", "tf.placeholder.get_shape", "g_fft.get_shape", "tf.placeholder.get_shape", "g_ifft.get_shape", "tf.placeholder.get_shape"], "function", ["None"], ["def", "test_shape", "(", ")", ":", "\n", "    ", "print", "(", "\"Testing shape...\"", ")", "\n", "\n", "# Test Shape inference. Output shape should be", "\n", "# the same as input shape", "\n", "input_pl", "=", "tf", ".", "placeholder", "(", "tf", ".", "complex64", ",", "[", "1000", ",", "16000", "]", ")", "\n", "output_fft", "=", "sequential_batch_fft", "(", "input_pl", ")", "\n", "output_ifft", "=", "sequential_batch_ifft", "(", "input_pl", ")", "\n", "g_fft", "=", "tf", ".", "gradients", "(", "output_fft", ",", "input_pl", ")", "[", "0", "]", "\n", "g_ifft", "=", "tf", ".", "gradients", "(", "output_ifft", ",", "input_pl", ")", "[", "0", "]", "\n", "assert", "(", "output_fft", ".", "get_shape", "(", ")", "==", "input_pl", ".", "get_shape", "(", ")", ")", "\n", "assert", "(", "output_ifft", ".", "get_shape", "(", ")", "==", "input_pl", ".", "get_shape", "(", ")", ")", "\n", "assert", "(", "g_fft", ".", "get_shape", "(", ")", "==", "input_pl", ".", "get_shape", "(", ")", ")", "\n", "assert", "(", "g_ifft", ".", "get_shape", "(", ")", "==", "input_pl", ".", "get_shape", "(", ")", ")", "\n", "\n", "print", "(", "\"Passed.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.sequential_fft.sequential_batch_fft_test.test_forward": [[45, 77], ["print", "tensorflow.Session", "range", "tf.Session.close", "print", "range", "tf.Session.run", "tf.Session.run", "tf.Session.run", "numpy.sum", "numpy.sum", "numpy.abs", "numpy.abs", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "x_val.astype", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run"], ["", "def", "test_forward", "(", ")", ":", "\n", "# Test forward and compare with tf.batch_fft and tf.batch_ifft", "\n", "    ", "print", "(", "\"Testing forward...\"", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "for", "dim", "in", "range", "(", "1000", ",", "5000", ",", "1000", ")", ":", "\n", "        ", "for", "batch_size", "in", "range", "(", "1", ",", "10", ")", ":", "\n", "            ", "x_val", "=", "(", "np", ".", "random", ".", "randn", "(", "batch_size", ",", "dim", ")", "+", "\n", "np", ".", "random", ".", "randn", "(", "batch_size", ",", "dim", ")", "*", "1j", ")", ".", "astype", "(", "np", ".", "complex64", ")", "\n", "\n", "# Forward complex64", "\n", "x_fft_val", ",", "x_ifft_tf_val", "=", "sess", ".", "run", "(", "[", "x_fft", ",", "x_ifft", "]", ",", "{", "x", ":", "x_val", "}", ")", "\n", "# Forward complex128", "\n", "x_fft_128_val", ",", "x_ifft_128_val", "=", "sess", ".", "run", "(", "[", "x_fft_128", ",", "x_ifft_128", "]", ",", "\n", "{", "x_128", ":", "x_val", ".", "astype", "(", "np", ".", "complex128", ")", "}", ")", "\n", "# Forward with reference tf.batch_fft and tf.batch_ifft", "\n", "x_fft_tf_val", ",", "x_ifft_val", "=", "sess", ".", "run", "(", "[", "x_fft_tf", ",", "x_ifft_tf", "]", ",", "{", "x", ":", "x_val", "}", ")", "\n", "\n", "ref_sum_fft", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "x_fft_tf_val", ")", ")", "\n", "ref_sum_ifft", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "x_ifft_tf_val", ")", ")", "\n", "relative_diff_fft", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "x_fft_val", "-", "x_fft_tf_val", ")", ")", "/", "ref_sum_fft", "\n", "relative_diff_ifft", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "x_ifft_val", "-", "x_ifft_tf_val", ")", ")", "/", "ref_sum_ifft", "\n", "relative_diff_fft128", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "x_fft_128_val", "-", "x_fft_tf_val", ")", ")", "/", "ref_sum_fft", "\n", "relative_diff_ifft128", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "x_ifft_128_val", "-", "x_ifft_tf_val", ")", ")", "/", "ref_sum_ifft", "\n", "\n", "assert", "(", "relative_diff_fft", "<", "1e-5", ")", "\n", "assert", "(", "relative_diff_fft128", "<", "1e-5", ")", "\n", "assert", "(", "relative_diff_ifft", "<", "1e-5", ")", "\n", "assert", "(", "relative_diff_ifft128", "<", "1e-5", ")", "\n", "\n", "", "", "sess", ".", "close", "(", ")", "\n", "print", "(", "\"Passed.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.sequential_fft.sequential_batch_fft_test.test_gradient": [[78, 110], ["print", "tensorflow.Session", "range", "tf.Session.close", "print", "range", "tf.Session.run", "tf.Session.run", "tf.Session.run", "numpy.sum", "numpy.sum", "numpy.abs", "numpy.abs", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "x_val.astype", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run", "home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run"], ["", "def", "test_gradient", "(", ")", ":", "\n", "# Test Backward and compare with tf.batch_fft and tf.batch_ifft", "\n", "    ", "print", "(", "\"Testing gradient...\"", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "for", "dim", "in", "range", "(", "1000", ",", "5000", ",", "1000", ")", ":", "\n", "        ", "for", "batch_size", "in", "range", "(", "1", ",", "10", ")", ":", "\n", "            ", "x_val", "=", "(", "np", ".", "random", ".", "randn", "(", "batch_size", ",", "dim", ")", "+", "\n", "np", ".", "random", ".", "randn", "(", "batch_size", ",", "dim", ")", "*", "1j", ")", ".", "astype", "(", "np", ".", "complex64", ")", "\n", "\n", "# Backward complex64", "\n", "gx_fft_val", ",", "gx_ifft_tf_val", "=", "sess", ".", "run", "(", "[", "gx_fft", ",", "gx_ifft", "]", ",", "{", "x", ":", "x_val", "}", ")", "\n", "# Backward complex128", "\n", "gx_fft_128_val", ",", "gx_ifft_128_val", "=", "sess", ".", "run", "(", "[", "gx_fft_128", ",", "gx_ifft_128", "]", ",", "\n", "{", "x_128", ":", "x_val", ".", "astype", "(", "np", ".", "complex128", ")", "}", ")", "\n", "# Backward with reference tf.batch_fft and tf.batch_ifft", "\n", "gx_fft_tf_val", ",", "gx_ifft_val", "=", "sess", ".", "run", "(", "[", "gx_fft_tf", ",", "gx_ifft_tf", "]", ",", "{", "x", ":", "x_val", "}", ")", "\n", "\n", "ref_sum_fft", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "gx_fft_tf_val", ")", ")", "\n", "ref_sum_ifft", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "gx_ifft_tf_val", ")", ")", "\n", "relative_diff_fft", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "gx_fft_val", "-", "gx_fft_tf_val", ")", ")", "/", "ref_sum_fft", "\n", "relative_diff_ifft", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "gx_ifft_val", "-", "gx_ifft_tf_val", ")", ")", "/", "ref_sum_ifft", "\n", "relative_diff_fft128", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "gx_fft_128_val", "-", "gx_fft_tf_val", ")", ")", "/", "ref_sum_fft", "\n", "relative_diff_ifft128", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "gx_ifft_128_val", "-", "gx_ifft_tf_val", ")", ")", "/", "ref_sum_ifft", "\n", "\n", "assert", "(", "relative_diff_fft", "<", "1e-5", ")", "\n", "assert", "(", "relative_diff_fft128", "<", "1e-5", ")", "\n", "assert", "(", "relative_diff_ifft", "<", "1e-5", ")", "\n", "assert", "(", "relative_diff_ifft128", "<", "1e-5", ")", "\n", "\n", "", "", "sess", ".", "close", "(", ")", "\n", "print", "(", "\"Passed.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.seilna_youtube-8m.sequential_fft.sequential_batch_fft_test.test_large_input": [[111, 127], ["print", "tensorflow.Session", "print", "tf.Session.run", "tf.Session.close", "print", "tensorflow.group", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.seilna_youtube-8m.src.train.ParameterServer.run"], ["", "def", "test_large_input", "(", ")", ":", "\n", "# Very large input size, where tf.batch_fft and tf.batch_ifft", "\n", "# will run OOM", "\n", "    ", "print", "(", "\"Testing large input...\"", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "batch_size", ",", "dim", "=", "64", "*", "16", "*", "16", ",", "16000", "\n", "print", "(", "\"Forwarding and Backwarding with input shape\"", ",", "\n", "[", "batch_size", ",", "dim", "]", ",", "\"This may take a while...\"", ")", "\n", "x_val", "=", "(", "np", ".", "random", ".", "randn", "(", "batch_size", ",", "dim", ")", "+", "\n", "np", ".", "random", ".", "randn", "(", "batch_size", ",", "dim", ")", "*", "1j", ")", ".", "astype", "(", "np", ".", "complex64", ")", "\n", "sess", ".", "run", "(", "tf", ".", "group", "(", "x_fft", ",", "x_ifft", ",", "gx_fft", ",", "gx_ifft", ")", ",", "{", "x", ":", "x_val", "}", ")", "\n", "\n", "sess", ".", "close", "(", ")", "\n", "# Test passes iff no exception occurs.", "\n", "print", "(", "\"Passed.\"", ")", "\n", "\n"]]}