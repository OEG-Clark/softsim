{"home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.select_field": [[67, 69], ["None"], "function", ["None"], ["def", "select_field", "(", "features", ",", "field", ")", ":", "\n", "    ", "return", "[", "[", "choice", "[", "field", "]", "for", "choice", "in", "feature", ".", "choices_features", "]", "for", "feature", "in", "features", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.simple_accuracy": [[71, 73], ["None"], "function", ["None"], ["", "def", "simple_accuracy", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "return", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.set_seed": [[75, 81], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.train": [[83, 303], ["torch.utils.data.DataLoader", "exec", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_multiple_choice.set_seed", "str().split", "os.path.join", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "int", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "numpy.argmax", "run_multiple_choice.simple_accuracy", "run_multiple_choice.evaluate", "logger.info", "SummaryWriter.add_scalar", "evaluate.items", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_vocabulary", "tokenizer.save_pretrained", "torch.save", "logger.info", "int", "tqdm.tqdm", "enumerate", "run_multiple_choice.train.evaluate_model"], "function", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.set_seed", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.simple_accuracy", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "str_list", "=", "str", "(", "args", ".", "output_dir", ")", ".", "split", "(", "'/'", ")", "\n", "tb_log_dir", "=", "os", ".", "path", ".", "join", "(", "'summaries'", ",", "str_list", "[", "-", "1", "]", ")", "\n", "tb_writer", "=", "SummaryWriter", "(", "tb_log_dir", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "exec", "(", "'args.adam_betas = '", "+", "args", ".", "adam_betas", ")", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "betas", "=", "args", ".", "adam_betas", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "assert", "not", "(", "(", "args", ".", "warmup_steps", ">", "0", ")", "and", "(", "args", ".", "warmup_proportion", ">", "0", ")", ")", ",", "\"--only can set one of --warmup_steps and --warm_ratio \"", "\n", "if", "args", ".", "warmup_proportion", ">", "0", ":", "\n", "        ", "args", ".", "warmup_steps", "=", "int", "(", "t_total", "*", "args", ".", "warmup_proportion", ")", "\n", "", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "def", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ")", ":", "\n", "        ", "train_preds", "=", "np", ".", "argmax", "(", "train_preds", ",", "axis", "=", "1", ")", "\n", "train_acc", "=", "simple_accuracy", "(", "train_preds", ",", "train_label_ids", ")", "\n", "train_preds", "=", "None", "\n", "train_label_ids", "=", "None", "\n", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\n", "\"train acc: %s, dev acc: %s, loss: %s, global steps: %s\"", ",", "\n", "str", "(", "train_acc", ")", ",", "\n", "str", "(", "results", "[", "\"eval_acc\"", "]", ")", ",", "\n", "str", "(", "results", "[", "\"eval_loss\"", "]", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"training/acc\"", ",", "train_acc", ",", "global_step", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "if", "results", "[", "\"eval_acc\"", "]", ">", "best_dev_acc", ":", "\n", "            ", "best_dev_acc", "=", "results", "[", "\"eval_acc\"", "]", "\n", "best_steps", "=", "global_step", "\n", "logger", ".", "info", "(", "\"achieve BEST dev acc: %s at global step: %s\"", ",", "\n", "str", "(", "best_dev_acc", ")", ",", "\n", "str", "(", "best_steps", ")", "\n", ")", "\n", "# if args.do_test:", "\n", "#     results_test = evaluate(args, model, tokenizer, test=True)", "\n", "#     for key, value in results_test.items():", "\n", "#         tb_writer.add_scalar(\"test_{}\".format(key), value, global_step)", "\n", "#     logger.info(", "\n", "#         \"test acc: %s, loss: %s, global steps: %s\",", "\n", "#         str(results_test[\"eval_acc\"]),", "\n", "#         str(results_test[\"eval_loss\"]),", "\n", "#         str(global_step),", "\n", "#     )", "\n", "# save best dev acc model", "\n", "# output_dir = os.path.join(args.output_dir, \"checkpoint-best\")", "\n", "output_dir", "=", "args", ".", "output_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_vocabulary", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "txt_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'best_dev_results.txt'", ")", "\n", "with", "open", "(", "txt_dir", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "rs", "=", "'global_steps: {}; dev_acc: {}'", ".", "format", "(", "global_step", ",", "best_dev_acc", ")", "\n", "f", ".", "write", "(", "rs", ")", "\n", "tb_writer", ".", "add_text", "(", "'best_results'", ",", "rs", ",", "global_step", ")", "\n", "\n", "", "", "return", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "\n", "", "def", "save_model", "(", "args", ",", "model", ",", "tokenizer", ")", ":", "\n", "        ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_vocabulary", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "best_dev_acc", "=", "0.0", "\n", "best_steps", "=", "0", "\n", "train_preds", "=", "None", "\n", "train_label_ids", "=", "None", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "logits", "=", "outputs", "[", "1", "]", "\n", "################# work only gpu = 1 ######################", "\n", "if", "train_preds", "is", "None", ":", "\n", "                ", "train_preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "train_label_ids", "=", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "train_preds", "=", "np", ".", "append", "(", "train_preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "train_label_ids", "=", "np", ".", "append", "(", "train_label_ids", ",", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "###########################################################", "\n", "\n", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "if", "not", "args", ".", "no_clip_grad_norm", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "if", "not", "args", ".", "no_clip_grad_norm", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "=", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ")", "\n", "", "tb_writer", ".", "add_scalar", "(", "\"training/lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"training/loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\n", "\"Average loss: %s, average acc: %s at global step: %s\"", ",", "\n", "str", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "train_acc", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                    ", "save_model", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "=", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ")", "\n", "save_model", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", ",", "best_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.evaluate": [[305, 389], ["zip", "run_multiple_choice.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "numpy.argmax", "run_multiple_choice.simple_accuracy", "results.update", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "open", "logger.info", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "sorted", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "str().lower", "result.keys", "logger.info", "writer.write", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "str", "str", "logits.detach().cpu", "inputs[].detach().cpu", "str", "str", "logits.detach", "inputs[].detach", "str", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.load_and_cache_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.simple_accuracy"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ",", "test", "=", "False", ")", ":", "\n", "    ", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "eval_task", ",", "tokenizer", ",", "evaluate", "=", "not", "test", ",", "test", "=", "test", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "acc", "=", "simple_accuracy", "(", "preds", ",", "out_label_ids", ")", "\n", "\n", "result", "=", "{", "\"eval_acc\"", ":", "acc", ",", "\"eval_loss\"", ":", "eval_loss", "}", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "\"is_test_\"", "+", "str", "(", "test", ")", ".", "lower", "(", ")", "+", "\"_eval_results.txt\"", ")", "\n", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "str", "(", "prefix", ")", "+", "\" is test:\"", "+", "str", "(", "test", ")", ")", ")", "\n", "# writer.write(\"model           =%s\\n\" % str(args.model_name_or_path))", "\n", "# writer.write(", "\n", "#     \"total batch size=%d\\n\"", "\n", "#     % (", "\n", "#         args.per_gpu_train_batch_size", "\n", "#         * args.gradient_accumulation_steps", "\n", "#         * (torch.distributed.get_world_size() if args.local_rank != -1 else 1)", "\n", "#     )", "\n", "# )", "\n", "# writer.write(\"train num epochs=%d\\n\" % args.num_train_epochs)", "\n", "# writer.write(\"fp16            =%s\\n\" % args.fp16)", "\n", "# writer.write(\"max seq length  =%d\\n\" % args.max_seq_length)", "\n", "if", "not", "test", ":", "\n", "                ", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "", "", "", "", "if", "test", ":", "\n", "        ", "return", "results", ",", "preds", "\n", "", "else", ":", "\n", "        ", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.load_and_cache_examples": [[391, 449], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "logger.info", "utils_multiple_choice.convert_examples_to_features", "torch.distributed.barrier", "run_multiple_choice.select_field", "run_multiple_choice.select_field", "run_multiple_choice.select_field", "list().pop", "str", "str", "processor.get_dev_examples", "str", "logger.info", "torch.save", "processor.get_test_examples", "processor.get_train_examples", "len", "bool", "list", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_labels", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.convert_examples_to_features", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.select_field", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.select_field", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.select_field", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_dev_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_test_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_train_examples"], ["", "", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "test", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "# Load data features from cache or dataset file", "\n", "if", "evaluate", ":", "\n", "        ", "cached_mode", "=", "\"dev\"", "\n", "", "elif", "test", ":", "\n", "        ", "cached_mode", "=", "\"test\"", "\n", "", "else", ":", "\n", "        ", "cached_mode", "=", "\"train\"", "\n", "", "assert", "not", "(", "evaluate", "and", "test", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "cached_mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "evaluate", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "test", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "", "logger", ".", "info", "(", "\"Training number: %s\"", ",", "str", "(", "len", "(", "examples", ")", ")", ")", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "label_list", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"input_ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"input_mask\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"segment_ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.main": [[451, 769], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_multiple_choice.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "run_multiple_choice.load_and_cache_examples", "run_multiple_choice.train", "logger.info", "logger.info", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_multiple_choice.evaluate", "dict", "results.update", "numpy.save", "bool", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_multiple_choice.evaluate", "dict", "results.update", "os.path.join", "logger.info", "os.path.join", "MODEL_CLASSES.keys", "utils_multiple_choice.processors.keys", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "dict.items", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.set_seed", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_labels", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.load_and_cache_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.train", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.evaluate", "home.repos.pwc.inspect_result.yuweihao_reclor.None.run_multiple_choice.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "ALL_MODELS", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run test on the test set\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_betas'", ",", "default", "=", "'(0.9, 0.999)'", ",", "type", "=", "str", ",", "help", "=", "'betas for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_clip_grad_norm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"whether not to clip grad norm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_proportion\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Linear warmup over warmup ratios.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "best_steps", "=", "0", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "global_step", ",", "tr_loss", ",", "best_steps", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "\"\"\"\n    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n        # Create output directory if needed\n        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n            os.makedirs(args.output_dir)\n\n        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n        # They can then be reloaded using `from_pretrained()`\n        # model_to_save = (\n        #     model.module if hasattr(model, \"module\") else model\n        # )  # Take care of distributed/parallel training\n        # model_to_save.save_pretrained(args.output_dir)\n        # tokenizer.save_pretrained(args.output_dir)\n\n        # Good practice: save your training arguments together with the trained model\n        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n\n        # Load a trained model and vocabulary that you have fine-tuned\n        model = model_class.from_pretrained(args.output_dir)\n        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n        model.to(args.device)\n    \"\"\"", "\n", "\n", "# Evaluation", "\n", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "not", "args", ".", "do_train", ":", "\n", "            ", "args", ".", "output_dir", "=", "args", ".", "model_name_or_path", "\n", "", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "# if args.do_test and args.local_rank in [-1, 0]:", "\n", "#     if not args.do_train:", "\n", "#         args.output_dir = args.model_name_or_path", "\n", "#     checkpoints = [args.output_dir]", "\n", "#     # if args.eval_all_checkpoints: # can not use this to do test!!", "\n", "#     #     checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + '/**/' + WEIGHTS_NAME, recursive=True)))", "\n", "#     #     logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging", "\n", "#     logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)", "\n", "#     for checkpoint in checkpoints:", "\n", "#         global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"", "\n", "#         prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"", "\n", "\n", "#         model = model_class.from_pretrained(checkpoint)", "\n", "#         model.to(args.device)", "\n", "#         result = evaluate(args, model, tokenizer, prefix=prefix, test=True)", "\n", "#         result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())", "\n", "#         results.update(result)", "\n", "# if best_steps:", "\n", "#     logger.info(\"best steps of eval acc is the following checkpoints: %s\", best_steps)", "\n", "# return results", "\n", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "not", "args", ".", "do_train", ":", "\n", "            ", "checkpoint_dir", "=", "args", ".", "model_name_or_path", "\n", "", "if", "args", ".", "evaluate_during_training", ":", "\n", "            ", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ")", "\n", "", "if", "best_steps", ":", "\n", "            ", "logger", ".", "info", "(", "\"best steps of eval acc is the following checkpoints: %s\"", ",", "best_steps", ")", "\n", "\n", "# global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"", "\n", "# prefix = checkpoint_dir.split(\"/\")[-1] if checkpoint_dir.find(\"checkpoint\") != -1 else \"\"", "\n", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "# result, preds = evaluate(args, model, tokenizer, prefix=prefix, test=True)", "\n", "result", ",", "preds", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "test", "=", "True", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"test_preds.npy\"", "if", "args", ".", "output_dir", "is", "not", "None", "else", "\"test_preds.npy\"", ")", ",", "preds", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.InputExample.__init__": [[37, 53], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "example_id", ",", "question", ",", "contexts", ",", "endings", ",", "label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            example_id: Unique id for the example.\n            contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n            question: string. The untokenized text of the second sequence (question).\n            endings: list of str. multiple choice's options. Its length must be equal to contexts' length.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "question", "=", "question", "\n", "self", ".", "contexts", "=", "contexts", "\n", "self", ".", "endings", "=", "endings", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.InputFeatures.__init__": [[56, 63], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "example_id", ",", "choices_features", ",", "label", ")", ":", "\n", "        ", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "choices_features", "=", "[", "\n", "{", "\"input_ids\"", ":", "input_ids", ",", "\"input_mask\"", ":", "input_mask", ",", "\"segment_ids\"", ":", "segment_ids", "}", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", "in", "choices_features", "\n", "]", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.DataProcessor.get_train_examples": [[68, 71], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.DataProcessor.get_dev_examples": [[72, 75], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.DataProcessor.get_test_examples": [[76, 79], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.DataProcessor.get_labels": [[80, 83], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor.get_train_examples": [[88, 96], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor.get_dev_examples": [[97, 105], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor.get_test_examples": [[106, 114], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor.get_labels": [[115, 118], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\"3\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor._read_txt": [[119, 128], ["glob.glob", "tqdm.tqdm", "open", "json.load", "lines.append"], "methods", ["None"], ["", "def", "_read_txt", "(", "self", ",", "input_dir", ")", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "files", "=", "glob", ".", "glob", "(", "input_dir", "+", "\"/*txt\"", ")", "\n", "for", "file", "in", "tqdm", ".", "tqdm", "(", "files", ",", "desc", "=", "\"read files\"", ")", ":", "\n", "            ", "with", "open", "(", "file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fin", ":", "\n", "                ", "data_raw", "=", "json", ".", "load", "(", "fin", ")", "\n", "data_raw", "[", "\"race_id\"", "]", "=", "file", "\n", "lines", ".", "append", "(", "data_raw", ")", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.RaceProcessor._create_examples": [[129, 150], ["enumerate", "range", "len", "str", "examples.append", "utils_multiple_choice.InputExample", "ord", "ord"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "_", ",", "data_raw", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "race_id", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "data_raw", "[", "\"race_id\"", "]", ")", "\n", "article", "=", "data_raw", "[", "\"article\"", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "data_raw", "[", "\"answers\"", "]", ")", ")", ":", "\n", "                ", "truth", "=", "str", "(", "ord", "(", "data_raw", "[", "\"answers\"", "]", "[", "i", "]", ")", "-", "ord", "(", "\"A\"", ")", ")", "\n", "question", "=", "data_raw", "[", "\"questions\"", "]", "[", "i", "]", "\n", "options", "=", "data_raw", "[", "\"options\"", "]", "[", "i", "]", "\n", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "race_id", ",", "\n", "question", "=", "question", ",", "\n", "contexts", "=", "[", "article", ",", "article", ",", "article", ",", "article", "]", ",", "# this is not efficient but convenient", "\n", "endings", "=", "[", "options", "[", "0", "]", ",", "options", "[", "1", "]", ",", "options", "[", "2", "]", ",", "options", "[", "3", "]", "]", ",", "\n", "label", "=", "truth", ",", "\n", ")", "\n", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor.get_train_examples": [[155, 159], ["logger.info", "utils_multiple_choice.SwagProcessor._create_examples", "utils_multiple_choice.SwagProcessor._read_csv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor._read_csv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.csv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor.get_dev_examples": [[160, 164], ["logger.info", "utils_multiple_choice.SwagProcessor._create_examples", "utils_multiple_choice.SwagProcessor._read_csv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor._read_csv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val.csv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor.get_test_examples": [[165, 173], ["logger.info", "ValueError", "utils_multiple_choice.SwagProcessor._create_examples", "utils_multiple_choice.SwagProcessor._read_csv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor._read_csv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "raise", "ValueError", "(", "\n", "\"For swag testing, the input file does not contain a label column. It can not be tested in current code\"", "\n", "\"setting!\"", "\n", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.csv\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor.get_labels": [[174, 177], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\"3\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor._read_csv": [[178, 181], ["open", "list", "csv.reader"], "methods", ["None"], ["", "def", "_read_csv", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "return", "list", "(", "csv", ".", "reader", "(", "f", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.SwagProcessor._create_examples": [[182, 201], ["ValueError", "utils_multiple_choice.InputExample"], "methods", ["None"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ":", "List", "[", "List", "[", "str", "]", "]", ",", "type", ":", "str", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "if", "type", "==", "\"train\"", "and", "lines", "[", "0", "]", "[", "-", "1", "]", "!=", "\"label\"", ":", "\n", "            ", "raise", "ValueError", "(", "\"For training, the input file must contain a label column.\"", ")", "\n", "\n", "", "examples", "=", "[", "\n", "InputExample", "(", "\n", "example_id", "=", "line", "[", "2", "]", ",", "\n", "question", "=", "line", "[", "5", "]", ",", "# in the swag dataset, the", "\n", "# common beginning of each", "\n", "# choice is stored in \"sent2\".", "\n", "contexts", "=", "[", "line", "[", "4", "]", ",", "line", "[", "4", "]", ",", "line", "[", "4", "]", ",", "line", "[", "4", "]", "]", ",", "\n", "endings", "=", "[", "line", "[", "7", "]", ",", "line", "[", "8", "]", ",", "line", "[", "9", "]", ",", "line", "[", "10", "]", "]", ",", "\n", "label", "=", "line", "[", "11", "]", ",", "\n", ")", "\n", "for", "line", "in", "lines", "[", "1", ":", "]", "# we skip the line with the column names", "\n", "]", "\n", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ArcProcessor.get_train_examples": [[206, 210], ["logger.info", "utils_multiple_choice.ArcProcessor._create_examples", "utils_multiple_choice.ArcProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._read_json"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.jsonl\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ArcProcessor.get_dev_examples": [[211, 215], ["logger.info", "utils_multiple_choice.ArcProcessor._create_examples", "utils_multiple_choice.ArcProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._read_json"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.jsonl\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ArcProcessor.get_test_examples": [[216, 219], ["logger.info", "utils_multiple_choice.ArcProcessor._create_examples", "utils_multiple_choice.ArcProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._read_json"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.jsonl\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ArcProcessor.get_labels": [[220, 223], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\"3\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ArcProcessor._read_json": [[224, 228], ["open", "fin.readlines"], "methods", ["None"], ["", "def", "_read_json", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fin", ":", "\n", "            ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ArcProcessor._create_examples": [[229, 292], ["tqdm.tqdm", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "json.loads", "str", "str", "str", "str", "str", "str", "line.strip", "len", "utils_multiple_choice.ArcProcessor._create_examples.normalize"], "methods", ["None"], ["", "", "def", "_create_examples", "(", "self", ",", "lines", ",", "type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "\n", "# There are two types of labels. They should be normalized", "\n", "def", "normalize", "(", "truth", ")", ":", "\n", "            ", "if", "truth", "in", "\"ABCD\"", ":", "\n", "                ", "return", "ord", "(", "truth", ")", "-", "ord", "(", "\"A\"", ")", "\n", "", "elif", "truth", "in", "\"1234\"", ":", "\n", "                ", "return", "int", "(", "truth", ")", "-", "1", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"truth ERROR! %s\"", ",", "str", "(", "truth", ")", ")", "\n", "return", "None", "\n", "\n", "", "", "examples", "=", "[", "]", "\n", "three_choice", "=", "0", "\n", "four_choice", "=", "0", "\n", "five_choice", "=", "0", "\n", "other_choices", "=", "0", "\n", "# we deleted example which has more than or less than four choices", "\n", "for", "line", "in", "tqdm", ".", "tqdm", "(", "lines", ",", "desc", "=", "\"read arc data\"", ")", ":", "\n", "            ", "data_raw", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", "\"\\n\"", ")", ")", "\n", "if", "len", "(", "data_raw", "[", "\"question\"", "]", "[", "\"choices\"", "]", ")", "==", "3", ":", "\n", "                ", "three_choice", "+=", "1", "\n", "continue", "\n", "", "elif", "len", "(", "data_raw", "[", "\"question\"", "]", "[", "\"choices\"", "]", ")", "==", "5", ":", "\n", "                ", "five_choice", "+=", "1", "\n", "continue", "\n", "", "elif", "len", "(", "data_raw", "[", "\"question\"", "]", "[", "\"choices\"", "]", ")", "!=", "4", ":", "\n", "                ", "other_choices", "+=", "1", "\n", "continue", "\n", "", "four_choice", "+=", "1", "\n", "truth", "=", "str", "(", "normalize", "(", "data_raw", "[", "\"answerKey\"", "]", ")", ")", "\n", "assert", "truth", "!=", "\"None\"", "\n", "question_choices", "=", "data_raw", "[", "\"question\"", "]", "\n", "question", "=", "question_choices", "[", "\"stem\"", "]", "\n", "id", "=", "data_raw", "[", "\"id\"", "]", "\n", "options", "=", "question_choices", "[", "\"choices\"", "]", "\n", "if", "len", "(", "options", ")", "==", "4", ":", "\n", "                ", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "id", ",", "\n", "question", "=", "question", ",", "\n", "contexts", "=", "[", "\n", "options", "[", "0", "]", "[", "\"para\"", "]", ".", "replace", "(", "\"_\"", ",", "\"\"", ")", ",", "\n", "options", "[", "1", "]", "[", "\"para\"", "]", ".", "replace", "(", "\"_\"", ",", "\"\"", ")", ",", "\n", "options", "[", "2", "]", "[", "\"para\"", "]", ".", "replace", "(", "\"_\"", ",", "\"\"", ")", ",", "\n", "options", "[", "3", "]", "[", "\"para\"", "]", ".", "replace", "(", "\"_\"", ",", "\"\"", ")", ",", "\n", "]", ",", "\n", "endings", "=", "[", "options", "[", "0", "]", "[", "\"text\"", "]", ",", "options", "[", "1", "]", "[", "\"text\"", "]", ",", "options", "[", "2", "]", "[", "\"text\"", "]", ",", "options", "[", "3", "]", "[", "\"text\"", "]", "]", ",", "\n", "label", "=", "truth", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "type", "==", "\"train\"", ":", "\n", "            ", "assert", "len", "(", "examples", ")", ">", "1", "\n", "assert", "examples", "[", "0", "]", ".", "label", "is", "not", "None", "\n", "", "logger", ".", "info", "(", "\"len examples: %s}\"", ",", "str", "(", "len", "(", "examples", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Three choices: %s\"", ",", "str", "(", "three_choice", ")", ")", "\n", "logger", ".", "info", "(", "\"Five choices: %s\"", ",", "str", "(", "five_choice", ")", ")", "\n", "logger", ".", "info", "(", "\"Other choices: %s\"", ",", "str", "(", "other_choices", ")", ")", "\n", "logger", ".", "info", "(", "\"four choices: %s\"", ",", "str", "(", "four_choice", ")", ")", "\n", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_train_examples": [[297, 301], ["logger.info", "utils_multiple_choice.ReclorProcessor._create_examples", "utils_multiple_choice.ReclorProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._read_json"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.json\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_dev_examples": [[302, 306], ["logger.info", "utils_multiple_choice.ReclorProcessor._create_examples", "utils_multiple_choice.ReclorProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._read_json"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val.json\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_test_examples": [[307, 310], ["logger.info", "utils_multiple_choice.ReclorProcessor._create_examples", "utils_multiple_choice.ReclorProcessor._read_json", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._read_json"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.json\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor.get_labels": [[311, 314], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "0", ",", "1", ",", "2", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._read_json": [[315, 319], ["open", "json.load"], "methods", ["None"], ["", "def", "_read_json", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.ReclorProcessor._create_examples": [[320, 339], ["examples.append", "utils_multiple_choice.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "d", "in", "lines", ":", "\n", "            ", "context", "=", "d", "[", "'context'", "]", "\n", "question", "=", "d", "[", "'question'", "]", "\n", "answers", "=", "d", "[", "'answers'", "]", "\n", "label", "=", "0", "if", "type", "==", "\"test\"", "else", "d", "[", "'label'", "]", "# for test set, there is no label. Just use 0 for convenience.", "\n", "id_string", "=", "d", "[", "'id_string'", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "id_string", ",", "\n", "question", "=", "question", ",", "\n", "contexts", "=", "[", "context", ",", "context", ",", "context", ",", "context", "]", ",", "# this is not efficient but convenient", "\n", "endings", "=", "[", "answers", "[", "0", "]", ",", "answers", "[", "1", "]", ",", "answers", "[", "2", "]", ",", "answers", "[", "3", "]", "]", ",", "\n", "label", "=", "label", "\n", ")", "\n", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.yuweihao_reclor.None.utils_multiple_choice.convert_examples_to_features": [[341, 415], ["tqdm.tqdm", "enumerate", "enumerate", "features.append", "enumerate", "logger.info", "zip", "tokenizer.encode_plus", "choices_features.append", "logger.info", "logger.info", "enumerate", "utils_multiple_choice.InputFeatures", "example.question.find", "example.question.replace", "logger.info", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "map", "map", "map"], "function", ["None"], ["", "", "def", "convert_examples_to_features", "(", "\n", "examples", ":", "List", "[", "InputExample", "]", ",", "\n", "label_list", ":", "List", "[", "str", "]", ",", "\n", "max_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", "->", "List", "[", "InputFeatures", "]", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of `InputFeatures`\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "examples", ")", ",", "desc", "=", "\"convert examples to features\"", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "", "choices_features", "=", "[", "]", "\n", "for", "ending_idx", ",", "(", "context", ",", "ending", ")", "in", "enumerate", "(", "zip", "(", "example", ".", "contexts", ",", "example", ".", "endings", ")", ")", ":", "\n", "            ", "text_a", "=", "context", "\n", "if", "example", ".", "question", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "# this is for cloze question", "\n", "                ", "text_b", "=", "example", ".", "question", ".", "replace", "(", "\"_\"", ",", "ending", ")", "\n", "", "else", ":", "\n", "                ", "text_b", "=", "example", ".", "question", "+", "\" \"", "+", "ending", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "text_a", ",", "text_b", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", ")", "\n", "if", "\"num_truncated_tokens\"", "in", "inputs", "and", "inputs", "[", "\"num_truncated_tokens\"", "]", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Attention! you are cropping tokens (swag task is ok). \"", "\n", "\"If you are training ARC and RACE and you are poping question + options,\"", "\n", "\"you need to try to use a bigger max seq length!\"", "\n", ")", "\n", "\n", "", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", "\n", "choices_features", ".", "append", "(", "(", "input_ids", ",", "attention_mask", ",", "token_type_ids", ")", ")", "\n", "\n", "", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "if", "ex_index", "<", "2", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"race_id: {}\"", ".", "format", "(", "example", ".", "example_id", ")", ")", "\n", "for", "choice_idx", ",", "(", "input_ids", ",", "attention_mask", ",", "token_type_ids", ")", "in", "enumerate", "(", "choices_features", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"choice: {}\"", ".", "format", "(", "choice_idx", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "input_ids", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "attention_mask", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "token_type_ids", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"label: {}\"", ".", "format", "(", "label", ")", ")", "\n", "\n", "", "", "features", ".", "append", "(", "InputFeatures", "(", "example_id", "=", "example", ".", "example_id", ",", "choices_features", "=", "choices_features", ",", "label", "=", "label", ",", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]]}