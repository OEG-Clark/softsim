{"home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.opts.model_opts": [[1, 64], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "# Model options", "\n", "# Embedding Options", "\n", "parser", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "\n", "help", "=", "'Word embedding for both.'", ")", "\n", "parser", ".", "add_argument", "(", "'-ent_vec_size'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'POS embedding size.'", ")", "\n", "\n", "# RNN Options", "\n", "parser", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'brnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "'Type of decoder layer to use.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "parser", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "parser", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "250", ",", "\n", "help", "=", "'Size of LSTM hidden states'", ")", "\n", "parser", ".", "add_argument", "(", "'-score_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Size of hidden layer in scorer'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", "]", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-brnn_merge'", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", "]", ",", "\n", "help", "=", "\"Merge action for the bidir hidden states\"", ")", "\n", "\n", "# Table encoding options", "\n", "parser", ".", "add_argument", "(", "'-split_type'", ",", "default", "=", "'incell'", ",", "\n", "choices", "=", "[", "'incell'", ",", "'outcell'", "]", ",", "\n", "help", "=", "\"whether encode column split token |\"", ")", "\n", "parser", ".", "add_argument", "(", "'-merge_type'", ",", "default", "=", "'cat'", ",", "\n", "choices", "=", "[", "'sub'", ",", "'cat'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"compute span vector for table column: mlp>cat>sub\"", ")", "\n", "\n", "# Decoder options", "\n", "parser", ".", "add_argument", "(", "'-layout_encode'", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'none'", ",", "'rnn'", "]", ",", "\n", "help", "=", "\"Layout encoding method.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-cond_op_vec_size'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "\n", "help", "=", "'Layout embedding size.'", ")", "\n", "\n", "# Attention options", "\n", "parser", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                        dotprot or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-attn_hidden'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "\"if attn_hidden > 0, then attention score = f(Ue) B f(Ud)\"", ")", "\n", "parser", ".", "add_argument", "(", "'-co_attention'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if attn_hidden > 0, then attention score = f(Ue) B f(Ud)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.opts.preprocess_opts": [[66, 89], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "# Dictionary Options", "\n", "    ", "parser", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "# Truncation options", "\n", "parser", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "parser", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-tgt_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "\n", "# Data processing options", "\n", "parser", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "parser", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-span_exact_match'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Must have exact match for cond span in WHERE clause'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.opts.train_opts": [[91, 168], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "# Model loading/saving options", "\n", "    ", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "''", ",", "\n", "help", "=", "\"\"\"Path prefix to the \"train.pt\" and\n                        \"valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-save_dir'", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Model save dir\"", ")", "\n", "parser", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                        path to the pretrained model's state_dict.\"\"\"", ")", "\n", "# GPU", "\n", "parser", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "0", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Use CUDA on the listed devices.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "123", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                        reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "parser", ".", "add_argument", "(", "'-start_epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'The epoch from which to start'", ")", "\n", "parser", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.08", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                        with support (-param_init, param_init).\n                        Use 0 to not use initialization\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-fix_word_vecs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-update_word_vecs_after'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'When fix_word_vecs=True, only update word vectors after update_word_vecs_after epochs.'", ")", "\n", "parser", ".", "add_argument", "(", "'-agg_sample_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'Randomly skip agg loss, because this loss term tends to be overfitting.'", ")", "\n", "\n", "# Optimization options", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "'Maximum batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "40", ",", "\n", "help", "=", "'Number of training epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'-optim'", ",", "default", "=", "'rmsprop'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "\n", "'adadelta'", ",", "'adam'", ",", "'rmsprop'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                        renormalize it to have the norm equal to\n                        max_grad_norm\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"Dropout rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-lock_dropout'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use the same dropout mask for RNNs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-weight_dropout'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\">0: Weight dropout probability; applied in LSTM stacks.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-smooth_eps'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Label smoothing\"", ")", "\n", "# learning rate", "\n", "parser", ".", "add_argument", "(", "'-learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.002", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.95", ",", "\n", "help", "=", "\"Optimization hyperparameter\"", ")", "\n", "parser", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.98", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by this much if (i) perplexity does not decrease on the validation set or (ii) epoch has gone past start_decay_at\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-start_decay_at'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"\"\"Start decaying every epoch after and including this epoch\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-start_checkpoint_at'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"\"\"Start checkpointing every epoch after and including this epoch\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.opts.translate_opts": [[170, 185], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-model_path'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file'", ")", "\n", "parser", ".", "add_argument", "(", "'-data_path'", ",", "default", "=", "''", ",", "\n", "help", "=", "'Path to data'", ")", "\n", "parser", ".", "add_argument", "(", "'-split'", ",", "default", "=", "\"dev\"", ",", "\n", "help", "=", "\"Path to the evaluation annotated data\"", ")", "\n", "parser", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will be the decoded sequence\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "parser", ".", "add_argument", "(", "'-gold_layout'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Given the golden layout sequences for evaluation.\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate": [[16, 32], ["stanza.nlp.corenlp.CoreNLPClient.annotate", "stanza.nlp.corenlp.CoreNLPClient", "words.append", "gloss.append", "after.append", "w.lower"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower"], ["def", "annotate", "(", "sentence", ",", "lower", "=", "True", ")", ":", "\n", "    ", "global", "client", "\n", "if", "client", "is", "None", ":", "\n", "        ", "client", "=", "CoreNLPClient", "(", "default_annotators", "=", "'ssplit,tokenize'", ".", "split", "(", "','", ")", ")", "\n", "", "words", ",", "gloss", ",", "after", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "s", "in", "client", ".", "annotate", "(", "sentence", ")", ":", "\n", "        ", "for", "t", "in", "s", ":", "\n", "            ", "words", ".", "append", "(", "t", ".", "word", ")", "\n", "gloss", ".", "append", "(", "t", ".", "originalText", ")", "\n", "after", ".", "append", "(", "t", ".", "after", ")", "\n", "", "", "if", "lower", ":", "\n", "        ", "words", "=", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "words", "]", "\n", "", "return", "{", "\n", "'gloss'", ":", "gloss", ",", "\n", "'words'", ":", "words", ",", "\n", "'after'", ":", "after", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate_example": [[35, 67], ["annotate.annotate", "copy.deepcopy", "annotate.annotate", "annotate.annotate", "annotate.annotate", "annotate.annotate", "annotate.annotate", "str", "lib.common.detokenize"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.annotate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.common.detokenize"], ["", "def", "annotate_example", "(", "example", ",", "table", ")", ":", "\n", "    ", "ann", "=", "{", "'table_id'", ":", "example", "[", "'table_id'", "]", "}", "\n", "ann", "[", "'question'", "]", "=", "annotate", "(", "example", "[", "'question'", "]", ")", "\n", "ann", "[", "'table'", "]", "=", "{", "\n", "'header'", ":", "[", "annotate", "(", "h", ")", "for", "h", "in", "table", "[", "'header'", "]", "]", ",", "\n", "}", "\n", "ann", "[", "'query'", "]", "=", "sql", "=", "copy", ".", "deepcopy", "(", "example", "[", "'sql'", "]", ")", "\n", "for", "c", "in", "ann", "[", "'query'", "]", "[", "'conds'", "]", ":", "\n", "        ", "c", "[", "-", "1", "]", "=", "annotate", "(", "str", "(", "c", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "q1", "=", "'SYMSELECT SYMAGG {} SYMCOL {}'", ".", "format", "(", "\n", "agg_ops", "[", "sql", "[", "'agg'", "]", "]", ",", "table", "[", "'header'", "]", "[", "sql", "[", "'sel'", "]", "]", ")", "\n", "q2", "=", "[", "'SYMCOL {} SYMOP {} SYMCOND {}'", ".", "format", "(", "\n", "table", "[", "'header'", "]", "[", "col", "]", ",", "cond_ops", "[", "op", "]", ",", "detokenize", "(", "cond", ")", ")", "for", "col", ",", "op", ",", "cond", "in", "sql", "[", "'conds'", "]", "]", "\n", "if", "q2", ":", "\n", "        ", "q2", "=", "'SYMWHERE '", "+", "' SYMAND '", ".", "join", "(", "q2", ")", "+", "' SYMEND'", "\n", "", "else", ":", "\n", "        ", "q2", "=", "'SYMEND'", "\n", "", "inp", "=", "'SYMSYMS {syms} SYMAGGOPS {aggops} SYMCONDOPS {condops} SYMTABLE {table} SYMQUESTION {question} SYMEND'", ".", "format", "(", "\n", "syms", "=", "' '", ".", "join", "(", "[", "'SYM'", "+", "s", "for", "s", "in", "Query", ".", "syms", "]", ")", ",", "\n", "table", "=", "' '", ".", "join", "(", "[", "'SYMCOL '", "+", "s", "for", "s", "in", "table", "[", "'header'", "]", "]", ")", ",", "\n", "question", "=", "example", "[", "'question'", "]", ",", "\n", "aggops", "=", "' '", ".", "join", "(", "[", "s", "for", "s", "in", "agg_ops", "]", ")", ",", "\n", "condops", "=", "' '", ".", "join", "(", "[", "s", "for", "s", "in", "cond_ops", "]", ")", ",", "\n", ")", "\n", "ann", "[", "'seq_input'", "]", "=", "annotate", "(", "inp", ")", "\n", "out", "=", "'{q1} {q2}'", ".", "format", "(", "q1", "=", "q1", ",", "q2", "=", "q2", ")", "if", "q2", "else", "q1", "\n", "ann", "[", "'seq_output'", "]", "=", "annotate", "(", "out", ")", "\n", "ann", "[", "'where_output'", "]", "=", "annotate", "(", "q2", ")", "\n", "assert", "'symend'", "in", "ann", "[", "'seq_output'", "]", "[", "'words'", "]", "\n", "assert", "'symend'", "in", "ann", "[", "'where_output'", "]", "[", "'words'", "]", "\n", "return", "ann", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.annotate.is_valid_example": [[69, 89], ["set", "set", "all", "lib.common.detokenize().lower", "len", "len", "set", "print", "lib.common.detokenize", "print"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.common.detokenize"], ["", "def", "is_valid_example", "(", "e", ")", ":", "\n", "    ", "if", "not", "all", "(", "[", "h", "[", "'words'", "]", "for", "h", "in", "e", "[", "'table'", "]", "[", "'header'", "]", "]", ")", ":", "\n", "        ", "return", "False", "\n", "", "headers", "=", "[", "detokenize", "(", "h", ")", ".", "lower", "(", ")", "for", "h", "in", "e", "[", "'table'", "]", "[", "'header'", "]", "]", "\n", "if", "len", "(", "headers", ")", "!=", "len", "(", "set", "(", "headers", ")", ")", ":", "\n", "        ", "return", "False", "\n", "", "input_vocab", "=", "set", "(", "e", "[", "'seq_input'", "]", "[", "'words'", "]", ")", "\n", "for", "w", "in", "e", "[", "'seq_output'", "]", "[", "'words'", "]", ":", "\n", "        ", "if", "w", "not", "in", "input_vocab", ":", "\n", "            ", "print", "(", "'query word \"{}\" is not in input vocabulary.\\n{}'", ".", "format", "(", "\n", "w", ",", "e", "[", "'seq_input'", "]", "[", "'words'", "]", ")", ")", "\n", "return", "False", "\n", "", "", "input_vocab", "=", "set", "(", "e", "[", "'question'", "]", "[", "'words'", "]", ")", "\n", "for", "col", ",", "op", ",", "cond", "in", "e", "[", "'query'", "]", "[", "'conds'", "]", ":", "\n", "        ", "for", "w", "in", "cond", "[", "'words'", "]", ":", "\n", "            ", "if", "w", "not", "in", "input_vocab", ":", "\n", "                ", "print", "(", "'cond word \"{}\" is not in input vocabulary.\\n{}'", ".", "format", "(", "\n", "w", ",", "e", "[", "'question'", "]", "[", "'words'", "]", ")", ")", "\n", "return", "False", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.evaluate.main": [[36, 82], ["argparse.ArgumentParser", "opts.model_opts", "opts.train_opts", "lib.dbengine.DBEngine", "table.IO.read_anno_json", "table.IO.read_anno_json", "glob.glob", "argparse.ArgumentParser.parse_known_args", "codecs.open", "print", "print", "table.Translator", "table.Translator", "table.IO.TableDataset", "table.IO.TableDataset", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "r_list.sort", "zip", "print", "table.Translator.translate", "len", "len", "len", "len", "pred.eval", "sum", "print", "codecs.open", "f_out.write", "json.loads", "os.path.join", "len", "len"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.model_opts", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.train_opts", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.translate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ParseResult.ParseResult.eval"], ["def", "main", "(", ")", ":", "\n", "    ", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "opts", ".", "train_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "\n", "engine", "=", "DBEngine", "(", "opt", ".", "db_file", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "opt", ".", "source_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "        ", "sql_list", "=", "[", "json", ".", "loads", "(", "line", ")", "[", "'sql'", "]", "for", "line", "in", "corpus_file", "]", "\n", "\n", "", "js_list", "=", "table", ".", "IO", ".", "read_anno_json", "(", "opt", ".", "anno", ")", "\n", "\n", "prev_best", "=", "(", "None", ",", "None", ")", "\n", "for", "fn_model", "in", "glob", ".", "glob", "(", "opt", ".", "model_path", ")", ":", "\n", "        ", "print", "(", "fn_model", ")", "\n", "print", "(", "opt", ".", "anno", ")", "\n", "opt", ".", "model", "=", "fn_model", "\n", "\n", "translator", "=", "table", ".", "Translator", "(", "opt", ",", "dummy_opt", ".", "__dict__", ")", "\n", "data", "=", "table", ".", "IO", ".", "TableDataset", "(", "js_list", ",", "translator", ".", "fields", ",", "None", ",", "False", ")", "\n", "test_data", "=", "table", ".", "IO", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "device", "=", "opt", ".", "gpu", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "train", "=", "False", ",", "sort", "=", "True", ",", "sort_within_batch", "=", "False", ")", "\n", "\n", "# inference", "\n", "r_list", "=", "[", "]", "\n", "for", "batch", "in", "test_data", ":", "\n", "            ", "r_list", "+=", "translator", ".", "translate", "(", "batch", ")", "\n", "", "r_list", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "idx", ")", "\n", "assert", "len", "(", "r_list", ")", "==", "len", "(", "js_list", ")", ",", "'len(r_list) != len(js_list): {} != {}'", ".", "format", "(", "\n", "len", "(", "r_list", ")", ",", "len", "(", "js_list", ")", ")", "\n", "\n", "# evaluation", "\n", "for", "pred", ",", "gold", ",", "sql_gold", "in", "zip", "(", "r_list", ",", "js_list", ",", "sql_list", ")", ":", "\n", "            ", "pred", ".", "eval", "(", "gold", ",", "sql_gold", ",", "engine", ")", "\n", "", "print", "(", "'Results:'", ")", "\n", "for", "metric_name", "in", "(", "'all'", ",", "'exe'", ")", ":", "\n", "            ", "c_correct", "=", "sum", "(", "(", "x", ".", "correct", "[", "metric_name", "]", "for", "x", "in", "r_list", ")", ")", "\n", "print", "(", "'{}: {} / {} = {:.2%}'", ".", "format", "(", "metric_name", ",", "c_correct", ",", "\n", "len", "(", "r_list", ")", ",", "c_correct", "/", "len", "(", "r_list", ")", ")", ")", "\n", "if", "metric_name", "==", "'all'", "and", "(", "prev_best", "[", "0", "]", "is", "None", "or", "c_correct", ">", "prev_best", "[", "1", "]", ")", ":", "\n", "                ", "prev_best", "=", "(", "fn_model", ",", "c_correct", ")", "\n", "\n", "", "", "", "if", "(", "opt", ".", "split", "==", "'dev'", ")", "and", "(", "prev_best", "[", "0", "]", "is", "not", "None", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "'dev_best.txt'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f_out", ":", "\n", "            ", "f_out", ".", "write", "(", "'{}\\n'", ".", "format", "(", "prev_best", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.train.get_save_index": [[21, 29], ["path.Path().exists", "path.Path", "os.path.join"], "function", ["None"], ["def", "get_save_index", "(", "save_dir", ")", ":", "\n", "    ", "save_index", "=", "0", "\n", "while", "True", ":", "\n", "        ", "if", "Path", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'run.%d'", "%", "(", "save_index", ",", ")", ")", ")", ".", "exists", "(", ")", ":", "\n", "            ", "save_index", "+=", "1", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "save_index", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.train.report_func": [[61, 82], ["table.Statistics.output", "table.Statistics", "table.Statistics", "table.Statistics", "table.Statistics"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.output"], ["def", "report_func", "(", "epoch", ",", "batch", ",", "num_batches", ",", "\n", "start_time", ",", "lr", ",", "report_stats", ")", ":", "\n", "    ", "\"\"\"\n    This is the user-defined batch-level traing progress\n    report function.\n\n    Args:\n        epoch(int): current epoch count.\n        batch(int): current batch count.\n        num_batches(int): total number of batches.\n        start_time(float): last report time.\n        lr(float): current learning rate.\n        report_stats(Statistics): old Statistics instance.\n    Returns:\n        report_stats(Statistics): updated Statistics instance.\n    \"\"\"", "\n", "if", "batch", "%", "opt", ".", "report_every", "==", "-", "1", "%", "opt", ".", "report_every", ":", "\n", "        ", "report_stats", ".", "output", "(", "epoch", ",", "batch", "+", "1", ",", "num_batches", ",", "start_time", ")", "\n", "report_stats", "=", "table", ".", "Statistics", "(", "0", ",", "{", "}", ")", "\n", "\n", "", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.train.train_model": [[84, 123], ["table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.Loss.TableLossCompute().cuda", "table.Loss.TableLossCompute().cuda", "table.Loss.TableLossCompute().cuda", "table.Loss.TableLossCompute().cuda", "table.Loss.TableLossCompute().cuda", "table.Loss.TableLossCompute().cuda", "table.Loss.TableLossCompute().cuda", "table.Loss.TableLossCompute().cuda", "table.Trainer", "table.Trainer", "table.Trainer", "table.Trainer", "range", "print", "table.Trainer.train", "print", "table.Trainer.validate", "print", "table.Trainer.epoch_step", "table.Loss.TableLossCompute", "table.Loss.TableLossCompute", "table.Loss.TableLossCompute", "table.Loss.TableLossCompute", "table.Loss.TableLossCompute", "table.Loss.TableLossCompute", "table.Loss.TableLossCompute", "table.Loss.TableLossCompute", "table.Trainer.drop_checkpoint", "model.q_encoder.embeddings.set_update", "model.q_encoder.embeddings.set_update", "trainer.train.accuracy", "trainer.validate.accuracy"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.train", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.validate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.epoch_step", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.drop_checkpoint", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.set_update", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.set_update", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy"], ["", "def", "train_model", "(", "model", ",", "train_data", ",", "valid_data", ",", "fields", ",", "optim", ")", ":", "\n", "    ", "train_iter", "=", "table", ".", "IO", ".", "OrderedIterator", "(", "\n", "dataset", "=", "train_data", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "device", "=", "opt", ".", "gpuid", "[", "0", "]", ",", "repeat", "=", "False", ")", "\n", "valid_iter", "=", "table", ".", "IO", ".", "OrderedIterator", "(", "\n", "dataset", "=", "valid_data", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "device", "=", "opt", ".", "gpuid", "[", "0", "]", ",", "train", "=", "False", ",", "sort", "=", "True", ",", "sort_within_batch", "=", "False", ")", "\n", "\n", "train_loss", "=", "table", ".", "Loss", ".", "TableLossCompute", "(", "opt", ".", "agg_sample_rate", ",", "smooth_eps", "=", "model", ".", "opt", ".", "smooth_eps", ")", ".", "cuda", "(", ")", "\n", "valid_loss", "=", "table", ".", "Loss", ".", "TableLossCompute", "(", "opt", ".", "agg_sample_rate", ",", "smooth_eps", "=", "model", ".", "opt", ".", "smooth_eps", ")", ".", "cuda", "(", ")", "\n", "\n", "trainer", "=", "table", ".", "Trainer", "(", "model", ",", "train_iter", ",", "valid_iter", ",", "\n", "train_loss", ",", "valid_loss", ",", "optim", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "opt", ".", "start_epoch", ",", "opt", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "print", "(", "''", ")", "\n", "\n", "if", "opt", ".", "fix_word_vecs", ":", "\n", "            ", "if", "(", "epoch", ">=", "opt", ".", "update_word_vecs_after", ")", ":", "\n", "                ", "model", ".", "q_encoder", ".", "embeddings", ".", "set_update", "(", "True", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "q_encoder", ".", "embeddings", ".", "set_update", "(", "False", ")", "\n", "\n", "# 1. Train for one epoch on the training set.", "\n", "", "", "train_stats", "=", "trainer", ".", "train", "(", "epoch", ",", "report_func", ")", "\n", "print", "(", "'Train accuracy: %s'", "%", "train_stats", ".", "accuracy", "(", "True", ")", ")", "\n", "\n", "# 2. Validate on the validation set.", "\n", "valid_stats", "=", "trainer", ".", "validate", "(", ")", "\n", "print", "(", "'Validation accuracy: %s'", "%", "valid_stats", ".", "accuracy", "(", "True", ")", ")", "\n", "\n", "# 3. Log to remote server.", "\n", "# train_stats.log(\"train\", logger, optim.lr, epoch)", "\n", "# valid_stats.log(\"valid\", logger, optim.lr, epoch)", "\n", "\n", "# 4. Update the learning rate", "\n", "trainer", ".", "epoch_step", "(", "None", ",", "epoch", ")", "\n", "\n", "# 5. Drop a checkpoint if needed.", "\n", "if", "epoch", ">=", "opt", ".", "start_checkpoint_at", ":", "\n", "            ", "trainer", ".", "drop_checkpoint", "(", "opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.train.load_fields": [[125, 138], ["table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "dict", "torch.load", "torch.load", "print", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "os.path.join", "table.IO.TableDataset.load_fields.items"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields"], ["", "", "", "def", "load_fields", "(", "train", ",", "valid", ",", "checkpoint", ")", ":", "\n", "    ", "fields", "=", "table", ".", "IO", ".", "TableDataset", ".", "load_fields", "(", "\n", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'vocab.pt'", ")", ")", ")", "\n", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "train", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "train", ".", "fields", "=", "fields", "\n", "valid", ".", "fields", "=", "fields", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading vocab from checkpoint at %s.'", "%", "opt", ".", "train_from", ")", "\n", "fields", "=", "table", ".", "IO", ".", "TableDataset", ".", "load_fields", "(", "checkpoint", "[", "'vocab'", "]", ")", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.train.build_model": [[140, 147], ["print", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "print"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model"], ["", "def", "build_model", "(", "model_opt", ",", "fields", ",", "checkpoint", ")", ":", "\n", "    ", "print", "(", "'Building model...'", ")", "\n", "model", "=", "table", ".", "ModelConstructor", ".", "make_base_model", "(", "\n", "model_opt", ",", "fields", ",", "checkpoint", ")", "\n", "print", "(", "model", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.train.build_optim": [[149, 167], ["table.Optim.set_parameters", "print", "table.Optim.optimizer.load_state_dict", "table.Optim", "table.Optim", "table.Optim", "table.Optim", "model.parameters", "checkpoint[].optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.set_parameters"], ["", "def", "build_optim", "(", "model", ",", "checkpoint", ")", ":", "\n", "    ", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading optimizer from checkpoint.'", ")", "\n", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "'optim'", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "", "else", ":", "\n", "# what members of opt does Optim need?", "\n", "        ", "optim", "=", "table", ".", "Optim", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "alpha", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", ",", "\n", "opt", "=", "opt", "\n", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.train.main": [[169, 200], ["print", "torch.load", "torch.load", "torch.load", "torch.load", "print", "print", "train.load_fields", "train.build_model", "train.build_optim", "train.train_model", "os.path.join", "os.path.join", "print", "torch.load", "torch.load", "len"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.build_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.build_optim", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.train_model"], ["", "def", "main", "(", ")", ":", "\n", "# Load train and validate data.", "\n", "    ", "print", "(", "\"Loading train and validate data from '%s'\"", "%", "opt", ".", "data", ")", "\n", "train", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'train.pt'", ")", ")", "\n", "valid", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'valid.pt'", ")", ")", "\n", "print", "(", "' * number of training sentences: %d'", "%", "len", "(", "train", ")", ")", "\n", "print", "(", "' * maximum batch size: %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "\n", "opt", ".", "train_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "# I don't like reassigning attributes of opt: it's not clear", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "", "fields", "=", "load_fields", "(", "train", ",", "valid", ",", "checkpoint", ")", "\n", "\n", "# Build model.", "\n", "model", "=", "build_model", "(", "model_opt", ",", "fields", ",", "checkpoint", ")", "\n", "\n", "# Build optimizer.", "\n", "optim", "=", "build_optim", "(", "model", ",", "checkpoint", ")", "\n", "\n", "# Do training.", "\n", "train_model", "(", "model", ",", "train", ",", "valid", ",", "fields", ",", "optim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.wikisql.preprocess.main": [[44, 67], ["print", "table.IO.TableDataset.get_fields", "table.IO.TableDataset.get_fields", "print", "table.IO.TableDataset", "table.IO.TableDataset", "print", "table.IO.TableDataset", "table.IO.TableDataset", "print", "table.IO.TableDataset", "table.IO.TableDataset", "print", "table.IO.TableDataset.build_vocab", "table.IO.TableDataset.build_vocab", "print", "torch.save", "torch.save", "torch.save", "table.IO.TableDataset.save_vocab", "table.IO.TableDataset.save_vocab", "open", "open", "open", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.get_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.get_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.build_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.build_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "'Preparing training ...'", ")", "\n", "fields", "=", "table", ".", "IO", ".", "TableDataset", ".", "get_fields", "(", ")", "\n", "print", "(", "\"Building Training...\"", ")", "\n", "train", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "train_anno", ",", "fields", ",", "opt", ",", "True", ")", "\n", "\n", "print", "(", "\"Building Valid...\"", ")", "\n", "valid", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "valid_anno", ",", "fields", ",", "opt", ",", "True", ")", "\n", "\n", "print", "(", "\"Building Test...\"", ")", "\n", "test", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "test_anno", ",", "fields", ",", "opt", ",", "False", ")", "\n", "\n", "print", "(", "\"Building Vocab...\"", ")", "\n", "table", ".", "IO", ".", "TableDataset", ".", "build_vocab", "(", "train", ",", "valid", ",", "test", ",", "opt", ")", "\n", "\n", "print", "(", "\"Saving train/valid/fields\"", ")", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "torch", ".", "save", "(", "table", ".", "IO", ".", "TableDataset", ".", "save_vocab", "(", "fields", ")", ",", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'vocab.pt'", ")", ",", "'wb'", ")", ")", "\n", "train", ".", "fields", "=", "[", "]", "\n", "valid", ".", "fields", "=", "[", "]", "\n", "torch", ".", "save", "(", "train", ",", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'train.pt'", ")", ",", "'wb'", ")", ")", "\n", "torch", ".", "save", "(", "valid", ",", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'valid.pt'", ")", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.__init__": [[17, 21], ["tuple", "list"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sel_index", ",", "agg_index", ",", "conditions", "=", "tuple", "(", ")", ")", ":", "\n", "        ", "self", ".", "sel_index", "=", "sel_index", "\n", "self", ".", "agg_index", "=", "agg_index", "\n", "self", ".", "conditions", "=", "list", "(", "conditions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.__eq__": [[22, 28], ["isinstance", "isinstance", "cond.lower", "isinstance", "cond.lower"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "other", ",", "self", ".", "__class__", ")", ":", "\n", "            ", "indices", "=", "self", ".", "sel_index", "==", "other", ".", "sel_index", "and", "self", ".", "agg_index", "==", "other", ".", "agg_index", "\n", "conds", "=", "[", "(", "col", ",", "op", ",", "cond", ".", "lower", "(", ")", "if", "isinstance", "(", "cond", ",", "str", ")", "else", "cond", ")", "for", "col", ",", "op", ",", "cond", "in", "self", ".", "conditions", "]", "==", "[", "(", "col", ",", "op", ",", "cond", ".", "lower", "(", ")", "if", "isinstance", "(", "cond", ",", "str", ")", "else", "cond", ")", "for", "col", ",", "op", ",", "cond", "in", "other", ".", "conditions", "]", "\n", "return", "indices", "and", "conds", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.__ne__": [[29, 33], ["isinstance", "query.Query.__eq__"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__eq__"], ["", "def", "__ne__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "other", ",", "self", ".", "__class__", ")", ":", "\n", "            ", "return", "not", "self", ".", "__eq__", "(", "other", ")", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.__hash__": [[34, 36], ["hash", "tuple", "sorted", "query.Query.__dict__.items"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "tuple", "(", "sorted", "(", "self", ".", "__dict__", ".", "items", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.__repr__": [[37, 45], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "rep", "=", "'SELECT {agg} {sel} FROM table'", ".", "format", "(", "\n", "agg", "=", "agg_ops", "[", "self", ".", "agg_index", "]", ",", "\n", "sel", "=", "'col{}'", ".", "format", "(", "self", ".", "sel_index", ")", ",", "\n", ")", "\n", "if", "self", ".", "conditions", ":", "\n", "            ", "rep", "+=", "' WHERE '", "+", "' AND '", ".", "join", "(", "[", "'{} {} {}'", ".", "format", "(", "'col{}'", ".", "format", "(", "i", ")", ",", "cond_ops", "[", "o", "]", ",", "v", ")", "for", "i", ",", "o", ",", "v", "in", "self", ".", "conditions", "]", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.to_dict": [[46, 48], ["None"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "'sel'", ":", "self", ".", "sel_index", ",", "'agg'", ":", "self", ".", "agg_index", ",", "'conds'", ":", "self", ".", "conditions", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower": [[49, 54], ["query.Query.__class__", "conds.append", "cond.lower"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower"], ["", "def", "lower", "(", "self", ")", ":", "\n", "        ", "conds", "=", "[", "]", "\n", "for", "col", ",", "op", ",", "cond", "in", "self", ".", "conditions", ":", "\n", "            ", "conds", ".", "append", "(", "[", "col", ",", "op", ",", "cond", ".", "lower", "(", ")", "]", ")", "\n", "", "return", "self", ".", "__class__", "(", "self", ".", "sel_index", ",", "self", ".", "agg_index", ",", "conds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.from_dict": [[55, 58], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "d", ")", ":", "\n", "        ", "return", "cls", "(", "sel_index", "=", "d", "[", "'sel'", "]", ",", "agg_index", "=", "d", "[", "'agg'", "]", ",", "conditions", "=", "d", "[", "'conds'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.from_tokenized_dict": [[59, 65], ["cls", "conds.append", "lib.common.detokenize"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.common.detokenize"], ["", "@", "classmethod", "\n", "def", "from_tokenized_dict", "(", "cls", ",", "d", ")", ":", "\n", "        ", "conds", "=", "[", "]", "\n", "for", "col", ",", "op", ",", "val", "in", "d", "[", "'conds'", "]", ":", "\n", "            ", "conds", ".", "append", "(", "[", "col", ",", "op", ",", "detokenize", "(", "val", ")", "]", ")", "\n", "", "return", "cls", "(", "d", "[", "'sel'", "]", ",", "d", "[", "'agg'", "]", ",", "conds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.from_generated_dict": [[66, 73], ["cls", "len", "conds.append", "lib.common.detokenize"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.common.detokenize"], ["", "@", "classmethod", "\n", "def", "from_generated_dict", "(", "cls", ",", "d", ")", ":", "\n", "        ", "conds", "=", "[", "]", "\n", "for", "col", ",", "op", ",", "val", "in", "d", "[", "'conds'", "]", ":", "\n", "            ", "end", "=", "len", "(", "val", "[", "'words'", "]", ")", "\n", "conds", ".", "append", "(", "[", "col", ",", "op", ",", "detokenize", "(", "val", ")", "]", ")", "\n", "", "return", "cls", "(", "d", "[", "'sel'", "]", ",", "d", "[", "'agg'", "]", ",", "conds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.from_sequence": [[74, 164], ["copy.deepcopy", "query.Query.from_sequence.flatten"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_sequence", "(", "cls", ",", "sequence", ",", "table", ",", "lowercase", "=", "True", ")", ":", "\n", "        ", "sequence", "=", "deepcopy", "(", "sequence", ")", "\n", "if", "'symend'", "in", "sequence", "[", "'words'", "]", ":", "\n", "            ", "end", "=", "sequence", "[", "'words'", "]", ".", "index", "(", "'symend'", ")", "\n", "for", "k", ",", "v", "in", "sequence", ".", "items", "(", ")", ":", "\n", "                ", "sequence", "[", "k", "]", "=", "v", "[", ":", "end", "]", "\n", "", "", "terms", "=", "[", "{", "'gloss'", ":", "g", ",", "'word'", ":", "w", ",", "'after'", ":", "a", "}", "for", "g", ",", "w", ",", "a", "in", "zip", "(", "sequence", "[", "'gloss'", "]", ",", "sequence", "[", "'words'", "]", ",", "sequence", "[", "'after'", "]", ")", "]", "\n", "headers", "=", "[", "detokenize", "(", "h", ")", "for", "h", "in", "table", "[", "'header'", "]", "]", "\n", "\n", "# lowercase everything and truncate sequence", "\n", "if", "lowercase", ":", "\n", "            ", "headers", "=", "[", "h", ".", "lower", "(", ")", "for", "h", "in", "headers", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "terms", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "t", ".", "items", "(", ")", ":", "\n", "                    ", "t", "[", "k", "]", "=", "v", ".", "lower", "(", ")", "\n", "", "", "", "headers_no_whitespcae", "=", "[", "re", ".", "sub", "(", "re_whitespace", ",", "''", ",", "h", ")", "for", "h", "in", "headers", "]", "\n", "\n", "# get select", "\n", "if", "'symselect'", "!=", "terms", ".", "pop", "(", "0", ")", "[", "'word'", "]", ":", "\n", "            ", "raise", "Exception", "(", "'Missing symselect operator'", ")", "\n", "\n", "# get aggregation", "\n", "", "if", "'symagg'", "!=", "terms", ".", "pop", "(", "0", ")", "[", "'word'", "]", ":", "\n", "            ", "raise", "Exception", "(", "'Missing symagg operator'", ")", "\n", "", "agg_op", "=", "terms", ".", "pop", "(", "0", ")", "[", "'word'", "]", "\n", "\n", "if", "agg_op", "==", "'symcol'", ":", "\n", "            ", "agg_op", "=", "''", "\n", "", "else", ":", "\n", "            ", "if", "'symcol'", "!=", "terms", ".", "pop", "(", "0", ")", "[", "'word'", "]", ":", "\n", "                ", "raise", "Exception", "(", "'Missing aggregation column'", ")", "\n", "", "", "try", ":", "\n", "            ", "agg_op", "=", "agg_ops", ".", "index", "(", "agg_op", ".", "upper", "(", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "'Invalid agg op {}'", ".", "format", "(", "agg_op", ")", ")", "\n", "\n", "", "def", "find_column", "(", "name", ")", ":", "\n", "            ", "return", "headers_no_whitespcae", ".", "index", "(", "re", ".", "sub", "(", "re_whitespace", ",", "''", ",", "name", ")", ")", "\n", "\n", "", "def", "flatten", "(", "tokens", ")", ":", "\n", "            ", "ret", "=", "{", "'words'", ":", "[", "]", ",", "'after'", ":", "[", "]", ",", "'gloss'", ":", "[", "]", "}", "\n", "for", "t", "in", "tokens", ":", "\n", "                ", "ret", "[", "'words'", "]", ".", "append", "(", "t", "[", "'word'", "]", ")", "\n", "ret", "[", "'after'", "]", ".", "append", "(", "t", "[", "'after'", "]", ")", "\n", "ret", "[", "'gloss'", "]", ".", "append", "(", "t", "[", "'gloss'", "]", ")", "\n", "", "return", "ret", "\n", "", "where_index", "=", "[", "i", "for", "i", ",", "t", "in", "enumerate", "(", "terms", ")", "if", "t", "[", "'word'", "]", "==", "'symwhere'", "]", "\n", "where_index", "=", "where_index", "[", "0", "]", "if", "where_index", "else", "len", "(", "terms", ")", "\n", "flat", "=", "flatten", "(", "terms", "[", ":", "where_index", "]", ")", "\n", "try", ":", "\n", "            ", "agg_col", "=", "find_column", "(", "detokenize", "(", "flat", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "'Cannot find aggregation column {}'", ".", "format", "(", "flat", "[", "'words'", "]", ")", ")", "\n", "", "where_terms", "=", "terms", "[", "where_index", "+", "1", ":", "]", "\n", "\n", "# get conditions", "\n", "conditions", "=", "[", "]", "\n", "while", "where_terms", ":", "\n", "            ", "t", "=", "where_terms", ".", "pop", "(", "0", ")", "\n", "flat", "=", "flatten", "(", "where_terms", ")", "\n", "if", "t", "[", "'word'", "]", "!=", "'symcol'", ":", "\n", "                ", "raise", "Exception", "(", "'Missing conditional column {}'", ".", "format", "(", "flat", "[", "'words'", "]", ")", ")", "\n", "", "try", ":", "\n", "                ", "op_index", "=", "flat", "[", "'words'", "]", ".", "index", "(", "'symop'", ")", "\n", "col_tokens", "=", "flatten", "(", "where_terms", "[", ":", "op_index", "]", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "'Missing conditional operator {}'", ".", "format", "(", "flat", "[", "'words'", "]", ")", ")", "\n", "", "cond_op", "=", "where_terms", "[", "op_index", "+", "1", "]", "[", "'word'", "]", "\n", "try", ":", "\n", "                ", "cond_op", "=", "cond_ops", ".", "index", "(", "cond_op", ".", "upper", "(", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "'Invalid cond op {}'", ".", "format", "(", "cond_op", ")", ")", "\n", "", "try", ":", "\n", "                ", "cond_col", "=", "find_column", "(", "detokenize", "(", "col_tokens", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "'Cannot find conditional column {}'", ".", "format", "(", "col_tokens", "[", "'words'", "]", ")", ")", "\n", "", "try", ":", "\n", "                ", "val_index", "=", "flat", "[", "'words'", "]", ".", "index", "(", "'symcond'", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "'Cannot find conditional value {}'", ".", "format", "(", "flat", "[", "'words'", "]", ")", ")", "\n", "\n", "", "where_terms", "=", "where_terms", "[", "val_index", "+", "1", ":", "]", "\n", "flat", "=", "flatten", "(", "where_terms", ")", "\n", "val_end_index", "=", "flat", "[", "'words'", "]", ".", "index", "(", "'symand'", ")", "if", "'symand'", "in", "flat", "[", "'words'", "]", "else", "len", "(", "where_terms", ")", "\n", "cond_val", "=", "detokenize", "(", "flatten", "(", "where_terms", "[", ":", "val_end_index", "]", ")", ")", "\n", "conditions", ".", "append", "(", "[", "cond_col", ",", "cond_op", ",", "cond_val", "]", ")", "\n", "where_terms", "=", "where_terms", "[", "val_end_index", "+", "1", ":", "]", "\n", "", "q", "=", "cls", "(", "agg_col", ",", "agg_op", ",", "conditions", ")", "\n", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.from_partial_sequence": [[165, 231], ["copy.deepcopy", "cls", "sequence[].index", "copy.deepcopy.items", "lib.common.detokenize", "enumerate", "re.sub", "headers_no_whitespcae.index", "len", "where_terms.pop", "query.Query.from_sequence.flatten"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.common.detokenize"], ["", "@", "classmethod", "\n", "def", "from_partial_sequence", "(", "cls", ",", "agg_col", ",", "agg_op", ",", "sequence", ",", "table", ",", "lowercase", "=", "True", ")", ":", "\n", "        ", "sequence", "=", "deepcopy", "(", "sequence", ")", "\n", "if", "'symend'", "in", "sequence", "[", "'words'", "]", ":", "\n", "            ", "end", "=", "sequence", "[", "'words'", "]", ".", "index", "(", "'symend'", ")", "\n", "for", "k", ",", "v", "in", "sequence", ".", "items", "(", ")", ":", "\n", "                ", "sequence", "[", "k", "]", "=", "v", "[", ":", "end", "]", "\n", "", "", "terms", "=", "[", "{", "'gloss'", ":", "g", ",", "'word'", ":", "w", ",", "'after'", ":", "a", "}", "for", "g", ",", "w", ",", "a", "in", "zip", "(", "sequence", "[", "'gloss'", "]", ",", "sequence", "[", "'words'", "]", ",", "sequence", "[", "'after'", "]", ")", "]", "\n", "headers", "=", "[", "detokenize", "(", "h", ")", "for", "h", "in", "table", "[", "'header'", "]", "]", "\n", "\n", "# lowercase everything and truncate sequence", "\n", "if", "lowercase", ":", "\n", "            ", "headers", "=", "[", "h", ".", "lower", "(", ")", "for", "h", "in", "headers", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "terms", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "t", ".", "items", "(", ")", ":", "\n", "                    ", "t", "[", "k", "]", "=", "v", ".", "lower", "(", ")", "\n", "", "", "", "headers_no_whitespcae", "=", "[", "re", ".", "sub", "(", "re_whitespace", ",", "''", ",", "h", ")", "for", "h", "in", "headers", "]", "\n", "\n", "def", "find_column", "(", "name", ")", ":", "\n", "            ", "return", "headers_no_whitespcae", ".", "index", "(", "re", ".", "sub", "(", "re_whitespace", ",", "''", ",", "name", ")", ")", "\n", "\n", "", "def", "flatten", "(", "tokens", ")", ":", "\n", "            ", "ret", "=", "{", "'words'", ":", "[", "]", ",", "'after'", ":", "[", "]", ",", "'gloss'", ":", "[", "]", "}", "\n", "for", "t", "in", "tokens", ":", "\n", "                ", "ret", "[", "'words'", "]", ".", "append", "(", "t", "[", "'word'", "]", ")", "\n", "ret", "[", "'after'", "]", ".", "append", "(", "t", "[", "'after'", "]", ")", "\n", "ret", "[", "'gloss'", "]", ".", "append", "(", "t", "[", "'gloss'", "]", ")", "\n", "", "return", "ret", "\n", "", "where_index", "=", "[", "i", "for", "i", ",", "t", "in", "enumerate", "(", "terms", ")", "if", "t", "[", "'word'", "]", "==", "'symwhere'", "]", "\n", "where_index", "=", "where_index", "[", "0", "]", "if", "where_index", "else", "len", "(", "terms", ")", "\n", "where_terms", "=", "terms", "[", "where_index", "+", "1", ":", "]", "\n", "\n", "# get conditions", "\n", "conditions", "=", "[", "]", "\n", "while", "where_terms", ":", "\n", "            ", "t", "=", "where_terms", ".", "pop", "(", "0", ")", "\n", "flat", "=", "flatten", "(", "where_terms", ")", "\n", "if", "t", "[", "'word'", "]", "!=", "'symcol'", ":", "\n", "                ", "raise", "Exception", "(", "'Missing conditional column {}'", ".", "format", "(", "flat", "[", "'words'", "]", ")", ")", "\n", "", "try", ":", "\n", "                ", "op_index", "=", "flat", "[", "'words'", "]", ".", "index", "(", "'symop'", ")", "\n", "col_tokens", "=", "flatten", "(", "where_terms", "[", ":", "op_index", "]", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "'Missing conditional operator {}'", ".", "format", "(", "flat", "[", "'words'", "]", ")", ")", "\n", "", "cond_op", "=", "where_terms", "[", "op_index", "+", "1", "]", "[", "'word'", "]", "\n", "try", ":", "\n", "                ", "cond_op", "=", "cond_ops", ".", "index", "(", "cond_op", ".", "upper", "(", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "'Invalid cond op {}'", ".", "format", "(", "cond_op", ")", ")", "\n", "", "try", ":", "\n", "                ", "cond_col", "=", "find_column", "(", "detokenize", "(", "col_tokens", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "'Cannot find conditional column {}'", ".", "format", "(", "col_tokens", "[", "'words'", "]", ")", ")", "\n", "", "try", ":", "\n", "                ", "val_index", "=", "flat", "[", "'words'", "]", ".", "index", "(", "'symcond'", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "'Cannot find conditional value {}'", ".", "format", "(", "flat", "[", "'words'", "]", ")", ")", "\n", "\n", "", "where_terms", "=", "where_terms", "[", "val_index", "+", "1", ":", "]", "\n", "flat", "=", "flatten", "(", "where_terms", ")", "\n", "val_end_index", "=", "flat", "[", "'words'", "]", ".", "index", "(", "'symand'", ")", "if", "'symand'", "in", "flat", "[", "'words'", "]", "else", "len", "(", "where_terms", ")", "\n", "cond_val", "=", "detokenize", "(", "flatten", "(", "where_terms", "[", ":", "val_end_index", "]", ")", ")", "\n", "conditions", ".", "append", "(", "[", "cond_col", ",", "cond_op", ",", "cond_val", "]", ")", "\n", "where_terms", "=", "where_terms", "[", "val_end_index", "+", "1", ":", "]", "\n", "", "q", "=", "cls", "(", "agg_col", ",", "agg_op", ",", "conditions", ")", "\n", "return", "q", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.__init__": [[11, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "table_id", ",", "header", ",", "types", ",", "rows", ",", "caption", "=", "None", ")", ":", "\n", "        ", "self", ".", "table_id", "=", "table_id", "\n", "self", ".", "header", "=", "header", "\n", "self", ".", "types", "=", "types", "\n", "self", ".", "rows", "=", "rows", "\n", "self", ".", "caption", "=", "caption", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.__repr__": [[18, 23], ["tabulate.tabulate.tabulate"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'Table: {id}\\nCaption: {caption}\\n{tabulate}'", ".", "format", "(", "\n", "id", "=", "self", ".", "table_id", ",", "\n", "caption", "=", "self", ".", "caption", ",", "\n", "tabulate", "=", "tabulate", "(", "self", ".", "rows", ",", "headers", "=", "self", ".", "header", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.get_schema": [[25, 32], ["db.query().all", "db.query", "cls.get_id"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.get_id"], ["", "@", "classmethod", "\n", "def", "get_schema", "(", "cls", ",", "db", ",", "table_id", ")", ":", "\n", "        ", "table_infos", "=", "db", ".", "query", "(", "'SELECT sql from sqlite_master WHERE tbl_name = :name'", ",", "name", "=", "cls", ".", "get_id", "(", "table_id", ")", ")", ".", "all", "(", ")", "\n", "if", "table_infos", ":", "\n", "            ", "return", "table_infos", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.get_id": [[33, 36], ["table_id.replace"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "get_id", "(", "cls", ",", "table_id", ")", ":", "\n", "        ", "return", "'table_{}'", ".", "format", "(", "table_id", ".", "replace", "(", "'-'", ",", "'_'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.from_db": [[37, 51], ["cls.get_schema", "schema_str.split", "cls", "cls.schema_re.findall", "tup.split", "header.append", "types.append", "getattr", "db.query", "cls.get_id"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.get_schema", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.get_id"], ["", "@", "classmethod", "\n", "def", "from_db", "(", "cls", ",", "db", ",", "table_id", ")", ":", "\n", "        ", "table_info", "=", "cls", ".", "get_schema", "(", "db", ",", "table_id", ")", "\n", "if", "table_info", ":", "\n", "            ", "schema_str", "=", "cls", ".", "schema_re", ".", "findall", "(", "table_info", ")", "[", "0", "]", "=", "[", "0", "]", ".", "sql", "\n", "header", ",", "types", "=", "[", "]", ",", "[", "]", "\n", "for", "tup", "in", "schema_str", ".", "split", "(", "', '", ")", ":", "\n", "                ", "c", ",", "t", "=", "tup", ".", "split", "(", ")", "\n", "header", ".", "append", "(", "c", ")", "\n", "types", ".", "append", "(", "t", ")", "\n", "", "rows", "=", "[", "[", "getattr", "(", "r", ",", "h", ")", "for", "h", "in", "header", "]", "for", "r", "in", "db", ".", "query", "(", "'SELECT * from {}'", ".", "format", "(", "cls", ".", "get_id", "(", "table_id", ")", ")", ")", "]", "\n", "return", "cls", "(", "table_id", ",", "header", ",", "types", ",", "rows", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.name": [[52, 55], ["table.Table.get_id"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.get_id"], ["", "", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_id", "(", "self", ".", "table_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.create_table": [[56, 71], ["table.Table.get_schema", "db.query", "db.query", "db.query", "enumerate", "enumerate", "enumerate", "isinstance", "v.lower", "value_dict.items"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.get_schema", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower"], ["", "def", "create_table", "(", "self", ",", "db", ",", "replace_existing", "=", "False", ",", "lower", "=", "True", ")", ":", "\n", "        ", "exists", "=", "self", ".", "get_schema", "(", "db", ",", "self", ".", "table_id", ")", "\n", "if", "exists", ":", "\n", "            ", "if", "replace_existing", ":", "\n", "                ", "db", ".", "query", "(", "'DROP TABLE {}'", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "", "else", ":", "\n", "                ", "return", "\n", "", "", "type_str", "=", "', '", ".", "join", "(", "[", "'col{} {}'", ".", "format", "(", "i", ",", "t", ")", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "types", ")", "]", ")", "\n", "db", ".", "query", "(", "'CREATE TABLE {name} ({types})'", ".", "format", "(", "name", "=", "self", ".", "name", ",", "types", "=", "type_str", ")", ")", "\n", "for", "row", "in", "self", ".", "rows", ":", "\n", "            ", "value_str", "=", "', '", ".", "join", "(", "[", "':val{}'", ".", "format", "(", "j", ")", "for", "j", ",", "c", "in", "enumerate", "(", "row", ")", "]", ")", "\n", "value_dict", "=", "{", "'val{}'", ".", "format", "(", "j", ")", ":", "c", "for", "j", ",", "c", "in", "enumerate", "(", "row", ")", "}", "\n", "if", "lower", ":", "\n", "                ", "value_dict", "=", "{", "k", ":", "v", ".", "lower", "(", ")", "if", "isinstance", "(", "v", ",", "str", ")", "else", "v", "for", "k", ",", "v", "in", "value_dict", ".", "items", "(", ")", "}", "\n", "", "db", ".", "query", "(", "'INSERT INTO {name} VALUES ({values})'", ".", "format", "(", "name", "=", "self", ".", "name", ",", "values", "=", "value_str", ")", ",", "**", "value_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.execute_query": [[72, 91], ["isinstance", "v.lower", "where_map.items", "db.query", "getattr", "db.query", "range", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower"], ["", "", "def", "execute_query", "(", "self", ",", "db", ",", "query", ",", "lower", "=", "True", ")", ":", "\n", "        ", "sel_str", "=", "'col{}'", ".", "format", "(", "query", ".", "sel_index", ")", "if", "query", ".", "sel_index", ">=", "0", "else", "'*'", "\n", "agg_str", "=", "sel_str", "\n", "agg_op", "=", "agg_ops", "[", "query", ".", "agg_index", "]", "\n", "if", "agg_op", ":", "\n", "            ", "agg_str", "=", "'{}({})'", ".", "format", "(", "agg_op", ",", "sel_str", ")", "\n", "", "where_str", "=", "' AND '", ".", "join", "(", "[", "'col{} {} :col{}'", ".", "format", "(", "i", ",", "cond_ops", "[", "o", "]", ",", "i", ")", "for", "i", ",", "o", ",", "v", "in", "query", ".", "conditions", "]", ")", "\n", "where_map", "=", "{", "'col{}'", ".", "format", "(", "i", ")", ":", "v", "for", "i", ",", "o", ",", "v", "in", "query", ".", "conditions", "}", "\n", "if", "lower", ":", "\n", "            ", "where_map", "=", "{", "k", ":", "v", ".", "lower", "(", ")", "if", "isinstance", "(", "v", ",", "str", ")", "else", "v", "for", "k", ",", "v", "in", "where_map", ".", "items", "(", ")", "}", "\n", "", "if", "where_map", ":", "\n", "            ", "where_str", "=", "'WHERE '", "+", "where_str", "\n", "\n", "", "if", "query", ".", "sel_index", ">=", "0", ":", "\n", "            ", "query_str", "=", "'SELECT {agg_str} AS result FROM {name} {where_str}'", ".", "format", "(", "agg_str", "=", "agg_str", ",", "name", "=", "self", ".", "name", ",", "where_str", "=", "where_str", ")", "\n", "return", "[", "r", ".", "result", "for", "r", "in", "db", ".", "query", "(", "query_str", ",", "**", "where_map", ")", "]", "\n", "", "else", ":", "\n", "            ", "query_str", "=", "'SELECT {agg_str} FROM {name} {where_str}'", ".", "format", "(", "agg_str", "=", "agg_str", ",", "name", "=", "self", ".", "name", ",", "where_str", "=", "where_str", ")", "\n", "return", "[", "[", "getattr", "(", "r", ",", "'col{}'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "header", ")", ")", "]", "for", "r", "in", "db", ".", "query", "(", "query_str", ",", "**", "where_map", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.query_str": [[92, 99], ["None"], "methods", ["None"], ["", "", "def", "query_str", "(", "self", ",", "query", ")", ":", "\n", "        ", "agg_str", "=", "self", ".", "header", "[", "query", ".", "sel_index", "]", "\n", "agg_op", "=", "agg_ops", "[", "query", ".", "agg_index", "]", "\n", "if", "agg_op", ":", "\n", "            ", "agg_str", "=", "'{}({})'", ".", "format", "(", "agg_op", ",", "agg_str", ")", "\n", "", "where_str", "=", "' AND '", ".", "join", "(", "[", "'{} {} {}'", ".", "format", "(", "self", ".", "header", "[", "i", "]", ",", "cond_ops", "[", "o", "]", ",", "v", ")", "for", "i", ",", "o", ",", "v", "in", "query", ".", "conditions", "]", ")", "\n", "return", "'SELECT {} FROM {} WHERE {}'", ".", "format", "(", "agg_str", ",", "self", ".", "name", ",", "where_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.generate_query": [[100, 133], ["min", "random.choice", "lib.query.Query", "table.Table.execute_query", "list", "list.remove", "range", "table.Table.execute_query", "len", "list", "lib.query.agg_ops.index", "range", "random.choice", "random.choice", "lib.query.Query.conditions.append", "table.Table.execute_query", "lib.query.agg_ops.index", "random.choice", "range", "len", "lib.query.cond_ops.index", "random.choice", "list.remove", "lib.query.Query.conditions.pop", "list", "len", "list", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.dbengine.DBEngine.execute_query", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.dbengine.DBEngine.execute_query", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.dbengine.DBEngine.execute_query"], ["", "def", "generate_query", "(", "self", ",", "db", ",", "max_cond", "=", "4", ")", ":", "\n", "        ", "max_cond", "=", "min", "(", "len", "(", "self", ".", "header", ")", ",", "max_cond", ")", "\n", "# sample a select column", "\n", "sel_index", "=", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "self", ".", "header", ")", ")", ")", ")", "\n", "# sample where conditions", "\n", "query", "=", "Query", "(", "-", "1", ",", "agg_ops", ".", "index", "(", "''", ")", ")", "\n", "results", "=", "self", ".", "execute_query", "(", "db", ",", "query", ")", "\n", "condition_options", "=", "list", "(", "range", "(", "len", "(", "self", ".", "header", ")", ")", ")", "\n", "condition_options", ".", "remove", "(", "sel_index", ")", "\n", "for", "i", "in", "range", "(", "max_cond", ")", ":", "\n", "            ", "if", "not", "results", ":", "\n", "                ", "break", "\n", "", "cond_index", "=", "random", ".", "choice", "(", "condition_options", ")", "\n", "if", "self", ".", "types", "[", "cond_index", "]", "==", "'text'", ":", "\n", "                ", "cond_op", "=", "cond_ops", ".", "index", "(", "'='", ")", "\n", "", "else", ":", "\n", "                ", "cond_op", "=", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "cond_ops", ")", ")", ")", ")", "\n", "", "cond_val", "=", "random", ".", "choice", "(", "[", "r", "[", "cond_index", "]", "for", "r", "in", "results", "]", ")", "\n", "query", ".", "conditions", ".", "append", "(", "(", "cond_index", ",", "cond_op", ",", "cond_val", ")", ")", "\n", "new_results", "=", "self", ".", "execute_query", "(", "db", ",", "query", ")", "\n", "if", "[", "r", "[", "sel_index", "]", "for", "r", "in", "new_results", "]", "!=", "[", "r", "[", "sel_index", "]", "for", "r", "in", "results", "]", ":", "\n", "                ", "condition_options", ".", "remove", "(", "cond_index", ")", "\n", "results", "=", "new_results", "\n", "", "else", ":", "\n", "                ", "query", ".", "conditions", ".", "pop", "(", ")", "\n", "# sample an aggregation operation", "\n", "", "", "if", "self", ".", "types", "[", "sel_index", "]", "==", "'text'", ":", "\n", "            ", "query", ".", "agg_index", "=", "agg_ops", ".", "index", "(", "''", ")", "\n", "", "else", ":", "\n", "            ", "query", ".", "agg_index", "=", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "agg_ops", ")", ")", ")", ")", "\n", "", "query", ".", "sel_index", "=", "sel_index", "\n", "results", "=", "self", ".", "execute_query", "(", "db", ",", "query", ")", "\n", "return", "query", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.generate_queries": [[134, 145], ["range", "table.Table.generate_query", "qs.append"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.table.Table.generate_query"], ["", "def", "generate_queries", "(", "self", ",", "db", ",", "n", "=", "1", ",", "max_tries", "=", "5", ",", "lower", "=", "True", ")", ":", "\n", "        ", "qs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "n_tries", "=", "0", "\n", "r", "=", "None", "\n", "while", "r", "is", "None", "and", "n_tries", "<", "max_tries", ":", "\n", "                ", "q", ",", "r", "=", "self", ".", "generate_query", "(", "db", ",", "max_cond", "=", "4", ")", "\n", "n_tries", "+=", "1", "\n", "", "if", "r", ":", "\n", "                ", "qs", ".", "append", "(", "(", "q", ",", "r", ")", ")", "\n", "", "", "return", "qs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.dbengine.DBEngine.__init__": [[13, 15], ["records.Database"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fdb", ")", ":", "\n", "        ", "self", ".", "db", "=", "records", ".", "Database", "(", "'sqlite:///{}'", ".", "format", "(", "fdb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.dbengine.DBEngine.execute_query": [[16, 18], ["dbengine.DBEngine.execute"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.dbengine.DBEngine.execute"], ["", "def", "execute_query", "(", "self", ",", "table_id", ",", "query", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "execute", "(", "table_id", ",", "query", ".", "sel_index", ",", "query", ".", "agg_index", ",", "query", ".", "conditions", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.dbengine.DBEngine.execute": [[19, 50], ["schema_str.split", "dbengine.DBEngine.db.query", "table_id.startswith", "schema_re.findall", "tup.split", "where_clause.append", "table_id.replace", "dbengine.DBEngine.db.query().all", "isinstance", "float.lower", "isinstance", "float", "dbengine.DBEngine.db.query", "babel.numbers.parse_decimal", "float", "num_re.findall"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower"], ["", "def", "execute", "(", "self", ",", "table_id", ",", "select_index", ",", "aggregation_index", ",", "conditions", ",", "lower", "=", "True", ")", ":", "\n", "        ", "if", "not", "table_id", ".", "startswith", "(", "'table'", ")", ":", "\n", "            ", "table_id", "=", "'table_{}'", ".", "format", "(", "table_id", ".", "replace", "(", "'-'", ",", "'_'", ")", ")", "\n", "", "table_info", "=", "self", ".", "db", ".", "query", "(", "'SELECT sql from sqlite_master WHERE tbl_name = :name'", ",", "name", "=", "table_id", ")", ".", "all", "(", ")", "[", "0", "]", ".", "sql", "\n", "schema_str", "=", "schema_re", ".", "findall", "(", "table_info", ")", "[", "0", "]", "\n", "schema", "=", "{", "}", "\n", "for", "tup", "in", "schema_str", ".", "split", "(", "', '", ")", ":", "\n", "            ", "c", ",", "t", "=", "tup", ".", "split", "(", ")", "\n", "schema", "[", "c", "]", "=", "t", "\n", "", "select", "=", "'col{}'", ".", "format", "(", "select_index", ")", "\n", "agg", "=", "agg_ops", "[", "aggregation_index", "]", "\n", "if", "agg", ":", "\n", "            ", "select", "=", "'{}({})'", ".", "format", "(", "agg", ",", "select", ")", "\n", "", "where_clause", "=", "[", "]", "\n", "where_map", "=", "{", "}", "\n", "for", "col_index", ",", "op", ",", "val", "in", "conditions", ":", "\n", "            ", "if", "lower", "and", "isinstance", "(", "val", ",", "str", ")", ":", "\n", "                ", "val", "=", "val", ".", "lower", "(", ")", "\n", "", "if", "schema", "[", "'col{}'", ".", "format", "(", "col_index", ")", "]", "==", "'real'", "and", "not", "isinstance", "(", "val", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "val", "=", "float", "(", "parse_decimal", "(", "val", ")", ")", "\n", "", "except", "NumberFormatError", "as", "e", ":", "\n", "                    ", "val", "=", "float", "(", "num_re", ".", "findall", "(", "val", ")", "[", "0", "]", ")", "\n", "", "", "where_clause", ".", "append", "(", "'col{} {} :col{}'", ".", "format", "(", "col_index", ",", "cond_ops", "[", "op", "]", ",", "col_index", ")", ")", "\n", "where_map", "[", "'col{}'", ".", "format", "(", "col_index", ")", "]", "=", "val", "\n", "", "where_str", "=", "''", "\n", "if", "where_clause", ":", "\n", "            ", "where_str", "=", "'WHERE '", "+", "' AND '", ".", "join", "(", "where_clause", ")", "\n", "", "query", "=", "'SELECT {} AS result FROM {} {}'", ".", "format", "(", "select", ",", "table_id", ",", "where_str", ")", "\n", "out", "=", "self", ".", "db", ".", "query", "(", "query", ",", "**", "where_map", ")", "\n", "return", "[", "o", ".", "result", "for", "o", "in", "out", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.common.count_lines": [[1, 4], ["open", "sum"], "function", ["None"], ["def", "count_lines", "(", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ")", "as", "f", ":", "\n", "        ", "return", "sum", "(", "1", "for", "line", "in", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.common.detokenize": [[6, 11], ["zip", "ret.strip"], "function", ["None"], ["", "", "def", "detokenize", "(", "tokens", ")", ":", "\n", "    ", "ret", "=", "''", "\n", "for", "g", ",", "a", "in", "zip", "(", "tokens", "[", "'gloss'", "]", ",", "tokens", "[", "'after'", "]", ")", ":", "\n", "        ", "ret", "+=", "g", "+", "a", "\n", "", "return", "ret", ".", "strip", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_word_embeddings": [[16, 45], ["len", "torch.Embedding", "len", "word_dict.load_vectors", "nn.Embedding.weight.data.copy_", "len", "nn.Embedding.weight.data[].zero_", "torch.Embedding", "table.modules.Embeddings.PartUpdateEmbedding", "torchtext.vocab.GloVe", "str"], "function", ["None"], ["\n", "\n", "def", "make_word_embeddings", "(", "opt", ",", "word_dict", ",", "fields", ")", ":", "\n", "    ", "word_padding_idx", "=", "word_dict", ".", "stoi", "[", "table", ".", "IO", ".", "PAD_WORD", "]", "\n", "num_word", "=", "len", "(", "word_dict", ")", "\n", "emb_word", "=", "nn", ".", "Embedding", "(", "num_word", ",", "opt", ".", "word_vec_size", ",", "\n", "padding_idx", "=", "word_padding_idx", ")", "\n", "\n", "if", "len", "(", "opt", ".", "pre_word_vecs", ")", ">", "0", ":", "\n", "        ", "vectors", "=", "torchtext", ".", "vocab", ".", "GloVe", "(", "\n", "name", "=", "\"840B\"", ",", "cache", "=", "opt", ".", "pre_word_vecs", ",", "dim", "=", "str", "(", "opt", ".", "word_vec_size", ")", ")", "\n", "fields", "[", "\"src\"", "]", ".", "vocab", ".", "load_vectors", "(", "vectors", ")", "\n", "emb_word", ".", "weight", ".", "data", ".", "copy_", "(", "fields", "[", "\"src\"", "]", ".", "vocab", ".", "vectors", ")", "\n", "\n", "", "if", "opt", ".", "fix_word_vecs", ":", "\n", "# <unk> is 0", "\n", "        ", "num_special", "=", "len", "(", "table", ".", "IO", ".", "special_token_list", ")", "\n", "# zero vectors in the fixed embedding (emb_word)", "\n", "emb_word", ".", "weight", ".", "data", "[", ":", "num_special", "]", ".", "zero_", "(", ")", "\n", "emb_special", "=", "nn", ".", "Embedding", "(", "\n", "num_special", ",", "opt", ".", "word_vec_size", ",", "padding_idx", "=", "word_padding_idx", ")", "\n", "emb", "=", "PartUpdateEmbedding", "(", "num_special", ",", "emb_special", ",", "emb_word", ")", "\n", "return", "emb", "\n", "", "else", ":", "\n", "        ", "return", "emb_word", "\n", "\n", "\n", "", "", "def", "make_embeddings", "(", "word_dict", ",", "vec_size", ")", ":", "\n", "    ", "word_padding_idx", "=", "word_dict", ".", "stoi", "[", "table", ".", "IO", ".", "PAD_WORD", "]", "\n", "num_word", "=", "len", "(", "word_dict", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_embeddings": [[47, 53], ["len", "torch.Embedding"], "function", ["None"], ["num_word", ",", "vec_size", ",", "padding_idx", "=", "word_padding_idx", ")", "\n", "return", "w_embeddings", "\n", "\n", "\n", "", "def", "make_encoder", "(", "opt", ",", "embeddings", ",", "ent_embedding", "=", "None", ")", ":", "\n", "# \"rnn\" or \"brnn\"", "\n", "    ", "return", "RNNEncoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_layers", ",", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ",", "opt", ".", "lock_dropout", ",", "opt", ".", "weight_dropout", ",", "embeddings", ",", "ent_embedding", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_encoder": [[55, 57], ["table.Models.RNNEncoder"], "function", ["None"], ["\n", "", "def", "make_table_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "# \"rnn\" or \"brnn\"", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_table_encoder": [[56, 59], ["table.Models.TableRNNEncoder", "ModelConstructor.make_encoder"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_encoder"], ["", "def", "make_table_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "# \"rnn\" or \"brnn\"", "\n", "    ", "return", "TableRNNEncoder", "(", "make_encoder", "(", "opt", ",", "embeddings", ")", ",", "opt", ".", "split_type", ",", "opt", ".", "merge_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_cond_decoder": [[61, 64], ["table.Models.CondDecoder"], "function", ["None"], ["", "def", "make_cond_decoder", "(", "opt", ")", ":", "\n", "    ", "input_size", "=", "opt", ".", "rnn_size", "\n", "return", "CondDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "dec_layers", ",", "input_size", ",", "opt", ".", "rnn_size", ",", "opt", ".", "global_attention", ",", "opt", ".", "attn_hidden", ",", "opt", ".", "dropout", ",", "opt", ".", "lock_dropout", ",", "opt", ".", "weight_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_co_attention": [[66, 70], ["table.Models.CoAttention"], "function", ["None"], ["", "def", "make_co_attention", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "co_attention", ":", "\n", "        ", "return", "CoAttention", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_layers", ",", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ",", "opt", ".", "weight_dropout", ",", "opt", ".", "global_attention", ",", "opt", ".", "attn_hidden", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model": [[94, 174], ["ModelConstructor.make_word_embeddings", "ModelConstructor.make_encoder", "ModelConstructor.make_embeddings", "ModelConstructor.make_decoder", "ModelConstructor.make_q_co_attention", "ModelConstructor.make_lay_co_attention", "ModelConstructor.make_embeddings", "ModelConstructor.make_decoder", "table.Models.ParserModel", "table.Models.ParserModel.cuda", "ModelConstructor.make_embeddings", "ModelConstructor.make_encoder", "ModelConstructor.make_word_embeddings", "ModelConstructor.make_encoder", "torch.Sequential", "ModelConstructor.make_embeddings", "ModelConstructor.make_layout_encoder", "print", "table.Models.ParserModel.load_state_dict", "torch.Dropout", "torch.Linear", "len", "len"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_word_embeddings", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_encoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_decoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_q_co_attention", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_lay_co_attention", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_decoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_encoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_word_embeddings", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_encoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_layout_encoder"], ["", "q_encoder", "=", "make_encoder", "(", "model_opt", ",", "w_embeddings", ",", "ent_embedding", ")", "\n", "# Make table encoder.", "\n", "tbl_encoder", "=", "make_table_encoder", "(", "model_opt", ",", "w_embeddings", ")", "\n", "\n", "co_attention", "=", "make_co_attention", "(", "model_opt", ")", "\n", "\n", "agg_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "model_opt", ".", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "len", "(", "agg_ops", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", ")", ")", "\n", "sel_match", "=", "MatchScorer", "(", "2", "*", "model_opt", ".", "rnn_size", ",", "\n", "model_opt", ".", "score_size", ",", "model_opt", ".", "dropout", ")", "\n", "lay_classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "model_opt", ".", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "len", "(", "fields", "[", "'lay'", "]", ".", "vocab", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", ")", ")", "\n", "\n", "# embedding", "\n", "# layout encoding", "\n", "if", "model_opt", ".", "layout_encode", "==", "'rnn'", ":", "\n", "        ", "cond_embedding", "=", "make_embeddings", "(", "\n", "fields", "[", "\"cond_op\"", "]", ".", "vocab", ",", "model_opt", ".", "cond_op_vec_size", ")", "\n", "lay_encoder", "=", "make_encoder", "(", "model_opt", ",", "cond_embedding", ")", "\n", "", "else", ":", "\n", "        ", "cond_embedding", "=", "make_embeddings", "(", "\n", "fields", "[", "\"cond_op\"", "]", ".", "vocab", ",", "model_opt", ".", "rnn_size", ")", "\n", "lay_encoder", "=", "None", "\n", "\n", "# Make cond models.", "\n", "", "cond_decoder", "=", "make_cond_decoder", "(", "model_opt", ")", "\n", "cond_col_match", "=", "CondMatchScorer", "(", "\n", "MatchScorer", "(", "2", "*", "model_opt", ".", "rnn_size", ",", "model_opt", ".", "score_size", ",", "model_opt", ".", "dropout", ")", ")", "\n", "cond_span_l_match", "=", "CondMatchScorer", "(", "\n", "MatchScorer", "(", "2", "*", "model_opt", ".", "rnn_size", ",", "model_opt", ".", "score_size", ",", "model_opt", ".", "dropout", ")", ")", "\n", "cond_span_r_match", "=", "CondMatchScorer", "(", "\n", "MatchScorer", "(", "3", "*", "model_opt", ".", "rnn_size", ",", "model_opt", ".", "score_size", ",", "model_opt", ".", "dropout", ")", ")", "\n", "\n", "# Make ParserModel", "\n", "pad_word_index", "=", "fields", "[", "\"src\"", "]", ".", "vocab", ".", "stoi", "[", "table", ".", "IO", ".", "PAD_WORD", "]", "\n", "model", "=", "ParserModel", "(", "q_encoder", ",", "tbl_encoder", ",", "co_attention", ",", "agg_classifier", ",", "sel_match", ",", "lay_classifier", ",", "cond_embedding", ",", "\n", "lay_encoder", ",", "cond_decoder", ",", "cond_col_match", ",", "cond_span_l_match", ",", "cond_span_r_match", ",", "model_opt", ",", "pad_word_index", ")", "\n", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Loading model'", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "\n", "", "model", ".", "cuda", "(", ")", "\n", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.__init__": [[21, 25], ["time.time"], "methods", ["None"], ["self", ".", "eval_result", "=", "eval_result", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "def", "update", "(", "self", ",", "stat", ")", ":", "\n", "        ", "self", ".", "loss", "+=", "stat", ".", "loss", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.update": [[26, 35], ["stat.eval_result.items"], "methods", ["None"], ["for", "k", ",", "v", "in", "stat", ".", "eval_result", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "self", ".", "eval_result", ":", "\n", "                ", "v0", "=", "self", ".", "eval_result", "[", "k", "]", "[", "0", "]", "+", "v", "[", "0", "]", "\n", "v1", "=", "self", ".", "eval_result", "[", "k", "]", "[", "1", "]", "+", "v", "[", "1", "]", "\n", "self", ".", "eval_result", "[", "k", "]", "=", "(", "v0", ",", "v1", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "eval_result", "[", "k", "]", "=", "(", "v", "[", "0", "]", ",", "v", "[", "1", "]", ")", "\n", "\n", "", "", "", "def", "accuracy", "(", "self", ",", "return_str", "=", "False", ")", ":", "\n", "        ", "d", "=", "sorted", "(", "[", "(", "k", ",", "v", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy": [[36, 43], ["sorted", "dict", "Trainer.Statistics.eval_result.items"], "methods", ["None"], ["for", "k", ",", "v", "in", "self", ".", "eval_result", ".", "items", "(", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "if", "return_str", ":", "\n", "            ", "return", "'; '", ".", "join", "(", "(", "(", "'{}: {:.2%}'", ".", "format", "(", "k", ",", "v", "[", "0", "]", "/", "v", "[", "1", "]", ",", ")", ")", "for", "k", ",", "v", "in", "d", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "dict", "(", "[", "(", "k", ",", "100.0", "*", "v", "[", "0", "]", "/", "v", "[", "1", "]", ")", "for", "k", ",", "v", "in", "d", "]", ")", "\n", "\n", "", "", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "return", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.elapsed_time": [[44, 46], ["time.time"], "methods", ["None"], ["\n", "", "def", "output", "(", "self", ",", "epoch", ",", "batch", ",", "n_batches", ",", "start", ")", ":", "\n", "        ", "print", "(", "(", "\"Epoch %2d, %5d/%5d; %s; %.0f s elapsed\"", ")", "%", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.output": [[47, 51], ["print", "sys.stdout.flush", "Trainer.Statistics.accuracy", "time.time"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy"], ["(", "epoch", ",", "batch", ",", "n_batches", ",", "self", ".", "accuracy", "(", "True", ")", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "def", "log", "(", "self", ",", "split", ",", "logger", ",", "lr", ",", "step", ")", ":", "\n", "        ", "pass", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.log": [[52, 54], ["None"], "methods", ["None"], ["\n", "\n", "", "", "def", "count_accuracy", "(", "scores", ",", "target", ",", "mask", "=", "None", ",", "row", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.__init__": [[108, 135], ["Trainer.Trainer.model.train", "copy.deepcopy", "list", "model.parameters"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.train"], ["\n", "# 2. Compute loss.", "\n", "pred", "=", "{", "'agg'", ":", "agg_out", ",", "'sel'", ":", "sel_out", ",", "'lay'", ":", "lay_out", ",", "'cond_col'", ":", "cond_col_out", ",", "\n", "'cond_span_l'", ":", "cond_span_l_out", ",", "'cond_span_r'", ":", "cond_span_r_out", "}", "\n", "gold", "=", "{", "'agg'", ":", "batch", ".", "agg", ",", "'sel'", ":", "batch", ".", "sel", ",", "'lay'", ":", "batch", ".", "lay", ",", "'cond_col'", ":", "batch", ".", "cond_col_loss", ",", "\n", "'cond_span_l'", ":", "batch", ".", "cond_span_l_loss", ",", "'cond_span_r'", ":", "batch", ".", "cond_span_r_loss", "}", "\n", "loss", "=", "criterion", ".", "compute_loss", "(", "pred", ",", "gold", ")", "\n", "\n", "# 3. Get the batch statistics.", "\n", "r_dict", "=", "{", "}", "\n", "for", "metric_name", "in", "(", "'agg'", ",", "'sel'", ",", "'lay'", ")", ":", "\n", "            ", "r_dict", "[", "metric_name", "]", "=", "count_accuracy", "(", "\n", "pred", "[", "metric_name", "]", ".", "data", ",", "gold", "[", "metric_name", "]", ".", "data", ")", "\n", "", "for", "metric_name", "in", "(", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ":", "\n", "            ", "r_dict", "[", "metric_name", "+", "'-token'", "]", "=", "count_accuracy", "(", "\n", "pred", "[", "metric_name", "]", ".", "data", ",", "gold", "[", "metric_name", "]", ".", "data", ",", "mask", "=", "gold", "[", "metric_name", "]", ".", "data", ".", "eq", "(", "-", "1", ")", ",", "row", "=", "False", ")", "\n", "r_dict", "[", "metric_name", "]", "=", "count_accuracy", "(", "\n", "pred", "[", "metric_name", "]", ".", "data", ",", "gold", "[", "metric_name", "]", ".", "data", ",", "mask", "=", "gold", "[", "metric_name", "]", ".", "data", ".", "eq", "(", "-", "1", ")", ",", "row", "=", "True", ")", "\n", "", "st", "=", "dict", "(", "[", "(", "k", ",", "(", "v", "[", "0", "]", ".", "sum", "(", ")", ",", "v", "[", "1", "]", ")", ")", "for", "k", ",", "v", "in", "r_dict", ".", "items", "(", ")", "]", ")", "\n", "st", "[", "'where'", "]", "=", "aggregate_accuracy", "(", "\n", "r_dict", ",", "(", "'lay'", ",", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ")", "\n", "st", "[", "'all'", "]", "=", "aggregate_accuracy", "(", "\n", "r_dict", ",", "(", "'agg'", ",", "'sel'", ",", "'lay'", ",", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ")", "\n", "batch_stats", "=", "Statistics", "(", "loss", ".", "data", "[", "0", "]", ",", "st", ")", "\n", "\n", "return", "loss", ",", "batch_stats", "\n", "\n", "", "def", "train", "(", "self", ",", "epoch", ",", "report_func", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.forward": [[136, 208], ["Trainer.Trainer.model", "criterion.compute_loss", "dict", "Trainer.aggregate_accuracy", "Trainer.Statistics", "lay.size", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "lay.data.clone().cpu", "range", "torch.autograd.Variable", "torch.autograd.Variable", "range", "Trainer.count_accuracy", "Trainer.count_accuracy", "Trainer.count_token_prune_accuracy", "Trainer.count_token_prune_accuracy", "range", "token_loss[].cuda", "len", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "lay.data.clone", "w.startswith", "m_list.append", "m_list.append", "g.eq", "g.eq", "r_dict.items", "len", "v[].sum", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Loss.LossCompute.compute_loss", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.aggregate_accuracy", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.count_accuracy", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.count_accuracy", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.count_token_prune_accuracy", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.count_token_prune_accuracy"], ["        ", "\"\"\" Called for each epoch to train. \"\"\"", "\n", "total_stats", "=", "Statistics", "(", "0", ",", "{", "}", ")", "\n", "report_stats", "=", "Statistics", "(", "0", ",", "{", "}", ")", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "self", ".", "train_iter", ")", ":", "\n", "            ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "loss", ",", "batch_stats", "=", "self", ".", "forward", "(", "batch", ",", "self", ".", "train_loss", ")", "\n", "\n", "# Update the parameters and statistics.", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optim", ".", "step", "(", ")", "\n", "total_stats", ".", "update", "(", "batch_stats", ")", "\n", "report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "if", "report_func", "is", "not", "None", ":", "\n", "                ", "report_stats", "=", "report_func", "(", "\n", "epoch", ",", "i", ",", "len", "(", "self", ".", "train_iter", ")", ",", "\n", "total_stats", ".", "start_time", ",", "self", ".", "optim", ".", "lr", ",", "report_stats", ")", "\n", "\n", "", "", "return", "total_stats", "\n", "\n", "", "def", "validate", "(", "self", ")", ":", "\n", "        ", "\"\"\" Called for each epoch to validate. \"\"\"", "\n", "# Set model in validating mode.", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "stats", "=", "Statistics", "(", "0", ",", "{", "}", ")", "\n", "for", "batch", "in", "self", ".", "valid_iter", ":", "\n", "            ", "loss", ",", "batch_stats", "=", "self", ".", "forward", "(", "batch", ",", "self", ".", "valid_loss", ")", "\n", "\n", "# Update statistics.", "\n", "stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# Set model back to training mode.", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "stats", "\n", "\n", "", "def", "epoch_step", "(", "self", ",", "eval_metric", ",", "epoch", ")", ":", "\n", "        ", "\"\"\" Called for each epoch to update learning rate. \"\"\"", "\n", "return", "self", ".", "optim", ".", "updateLearningRate", "(", "eval_metric", ",", "epoch", ")", "\n", "\n", "", "def", "drop_checkpoint", "(", "self", ",", "opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", ":", "\n", "        ", "\"\"\" Called conditionally each epoch to save a snapshot. \"\"\"", "\n", "\n", "model_state_dict", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'vocab'", ":", "table", ".", "IO", ".", "TableDataset", ".", "save_vocab", "(", "fields", ")", ",", "\n", "'opt'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'optim'", ":", "self", ".", "optim", "\n", "}", "\n", "eval_result", "=", "valid_stats", ".", "accuracy", "(", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "os", ".", "path", ".", "join", "(", "\n", "opt", ".", "save_path", ",", "'m_%d.pt'", "%", "(", "epoch", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.train": [[209, 240], ["Trainer.Statistics", "Trainer.Statistics", "enumerate", "Trainer.Trainer.model.zero_grad", "Trainer.Trainer.forward", "loss.backward", "Trainer.Trainer.optim.step", "Trainer.Statistics.update", "report_func.update", "report_func", "min", "zip", "len", "Trainer.Trainer.model.parameters", "avg_p.mul_().add_", "avg_p.mul_"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.forward", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.step", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.update", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.update", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.report_func"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.validate": [[241, 258], ["Trainer.Trainer.model.eval", "Trainer.Statistics", "Trainer.Trainer.model.train", "Trainer.Trainer.forward", "Trainer.Statistics.update"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ParseResult.ParseResult.eval", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.train", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.forward", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.update"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.epoch_step": [[259, 262], ["Trainer.Trainer.optim.updateLearningRate"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.updateLearningRate"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.drop_checkpoint": [[263, 280], ["Trainer.Trainer.model.state_dict", "valid_stats.accuracy", "torch.save", "torch.save", "torch.save", "torch.save", "table.IO.TableDataset.save_vocab", "table.IO.TableDataset.save_vocab", "table.IO.TableDataset.save_vocab", "table.IO.TableDataset.save_vocab", "os.path.join", "Trainer.Trainer.items"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.count_accuracy": [[56, 70], ["table.Utils.argmax", "table.Utils.argmax.eq", "pred.eq().masked_select.numel", "table.Utils.argmax.eq().masked_fill_().prod", "pred.eq().masked_select.numel", "mask.ne", "table.Utils.argmax.eq().masked_select", "mask.ne.sum", "table.Utils.argmax.eq().masked_fill_", "table.Utils.argmax.eq", "table.Utils.argmax.eq"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax"], ["if", "mask", "is", "None", ":", "\n", "        ", "m_correct", "=", "pred", ".", "eq", "(", "target", ")", "\n", "num_all", "=", "m_correct", ".", "numel", "(", ")", "\n", "", "elif", "row", ":", "\n", "        ", "m_correct", "=", "pred", ".", "eq", "(", "target", ")", ".", "masked_fill_", "(", "\n", "mask", ",", "1", ")", ".", "prod", "(", "0", ",", "keepdim", "=", "False", ")", "\n", "num_all", "=", "m_correct", ".", "numel", "(", ")", "\n", "", "else", ":", "\n", "        ", "non_mask", "=", "mask", ".", "ne", "(", "1", ")", "\n", "m_correct", "=", "pred", ".", "eq", "(", "target", ")", ".", "masked_select", "(", "non_mask", ")", "\n", "num_all", "=", "non_mask", ".", "sum", "(", ")", "\n", "", "return", "(", "m_correct", ",", "num_all", ")", "\n", "\n", "\n", "", "def", "aggregate_accuracy", "(", "r_dict", ",", "metric_name_list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.aggregate_accuracy": [[88, 94], ["torch.stack().prod", "torch.stack().prod", "m_list.append", "torch.stack().prod.sum", "torch.stack().prod.numel", "torch.stack", "torch.stack"], "function", ["None"], ["\n", "# Basic attributes.", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "train_iter", "=", "train_iter", "\n", "self", ".", "valid_iter", "=", "valid_iter", "\n", "self", ".", "train_loss", "=", "train_loss", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq": [[9, 17], ["next", "all", "str"], "function", ["None"], ["def", "aeq", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Assert all arguments have the same value\n    \"\"\"", "\n", "arguments", "=", "(", "arg", "for", "arg", "in", "args", ")", "\n", "first", "=", "next", "(", "arguments", ")", "\n", "assert", "all", "(", "arg", "==", "first", "for", "arg", "in", "arguments", ")", ",", "\"Not all arguments have the same value: \"", "+", "str", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.set_seed": [[19, 25], ["torch.manual_seed", "torch.cuda.manual_seed", "random.seed", "numpy.random.seed"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"Sets random seed everywhere.\"\"\"", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.sort_for_pack": [[27, 34], ["zip", "list", "list", "list", "map", "sorted", "sorted", "list", "list", "enumerate", "enumerate"], "function", ["None"], ["", "def", "sort_for_pack", "(", "input_len", ")", ":", "\n", "    ", "idx_sorted", ",", "input_len_sorted", "=", "zip", "(", "\n", "*", "sorted", "(", "list", "(", "enumerate", "(", "input_len", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "idx_sorted", ",", "input_len_sorted", "=", "list", "(", "idx_sorted", ")", ",", "list", "(", "input_len_sorted", ")", "\n", "idx_map_back", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "0", "]", ",", "sorted", "(", "\n", "list", "(", "enumerate", "(", "idx_sorted", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ")", ")", "\n", "return", "idx_sorted", ",", "input_len_sorted", ",", "idx_map_back", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax": [[36, 38], ["scores.max", "scores.dim"], "function", ["None"], ["", "def", "argmax", "(", "scores", ")", ":", "\n", "    ", "return", "scores", ".", "max", "(", "scores", ".", "dim", "(", ")", "-", "1", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.add_pad": [[40, 49], ["max", "r_list.append", "torch.LongTensor().cuda", "len", "torch.LongTensor", "len"], "function", ["None"], ["", "def", "add_pad", "(", "b_list", ",", "pad_index", ",", "return_tensor", "=", "True", ")", ":", "\n", "    ", "max_len", "=", "max", "(", "(", "len", "(", "b", ")", "for", "b", "in", "b_list", ")", ")", "\n", "r_list", "=", "[", "]", "\n", "for", "b", "in", "b_list", ":", "\n", "        ", "r_list", ".", "append", "(", "b", "+", "[", "pad_index", "]", "*", "(", "max_len", "-", "len", "(", "b", ")", ")", ")", "\n", "", "if", "return_tensor", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "r_list", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "r_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.RNNEncoder.__init__": [[28, 49], ["torch.Module.__init__", "Models._build_rnn", "table.modules.LockedDropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models._build_rnn"], ["hidden_size", ",", "dropout", ",", "lock_dropout", ",", "weight_dropout", ",", "embeddings", ",", "ent_embedding", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "ent_embedding", "=", "ent_embedding", "\n", "self", ".", "no_pack_padded_seq", "=", "False", "\n", "if", "lock_dropout", ":", "\n", "            ", "self", ".", "word_dropout", "=", "table", ".", "modules", ".", "LockedDropout", "(", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Use pytorch version when available.", "\n", "", "input_size", "=", "embeddings", ".", "embedding_dim", "\n", "if", "ent_embedding", "is", "not", "None", ":", "\n", "            ", "input_size", "+=", "ent_embedding", ".", "embedding_dim", "\n", "", "self", ".", "rnn", "=", "_build_rnn", "(", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", "//", "num_directions", ",", "num_layers", ",", "dropout", ",", "weight_dropout", ",", "bidirectional", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ",", "ent", "=", "None", ")", ":", "\n", "        ", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.RNNEncoder.forward": [[50, 77], ["Models.RNNEncoder.rnn", "table.modules.embed_regularize.embedded_dropout", "Models.RNNEncoder.embeddings", "Models.RNNEncoder.ent_embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.RNNEncoder.word_dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "isinstance", "lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.view().tolist.view().tolist.view"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.embed_regularize.embedded_dropout"], ["if", "self", ".", "ent_embedding", "is", "not", "None", ":", "\n", "            ", "emb_ent", "=", "self", ".", "ent_embedding", "(", "ent", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "(", "emb", ",", "emb_ent", ")", ",", "2", ")", "\n", "", "if", "self", ".", "word_dropout", "is", "not", "None", ":", "\n", "            ", "emb", "=", "self", ".", "word_dropout", "(", "emb", ")", "\n", "# s_len, batch, emb_dim = emb.size()", "\n", "\n", "", "packed_emb", "=", "emb", "\n", "need_pack", "=", "(", "lengths", "is", "not", "None", ")", "and", "(", "not", "self", ".", "no_pack_padded_seq", ")", "\n", "if", "need_pack", ":", "\n", "# Lengths data is wrapped inside a Variable.", "\n", "            ", "if", "not", "isinstance", "(", "lengths", ",", "list", ")", ":", "\n", "                ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "", "packed_emb", "=", "pack", "(", "emb", ",", "lengths", ")", "\n", "\n", "", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "packed_emb", ",", "hidden", ")", "\n", "\n", "if", "need_pack", ":", "\n", "            ", "outputs", "=", "unpack", "(", "outputs", ")", "[", "0", "]", "\n", "\n", "", "return", "hidden_t", ",", "outputs", "\n", "\n", "\n", "", "", "def", "encode_unsorted_batch", "(", "encoder", ",", "tbl", ",", "tbl_len", ")", ":", "\n", "# sort for pack()", "\n", "    ", "idx_sorted", ",", "tbl_len_sorted", ",", "idx_map_back", "=", "sort_for_pack", "(", "tbl_len", ")", "\n", "tbl_sorted", "=", "tbl", ".", "index_select", "(", "1", ",", "Variable", "(", "\n", "torch", ".", "LongTensor", "(", "idx_sorted", ")", ".", "cuda", "(", ")", ",", "requires_grad", "=", "False", ")", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.TableRNNEncoder.__init__": [[88, 98], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "split_type", "=", "'incell'", ",", "merge_type", "=", "'cat'", ")", ":", "\n", "        ", "super", "(", "TableRNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "split_type", "=", "split_type", "\n", "self", ".", "merge_type", "=", "merge_type", "\n", "self", ".", "hidden_size", "=", "encoder", ".", "hidden_size", "\n", "self", ".", "encoder", "=", "encoder", "\n", "if", "self", ".", "merge_type", "==", "'mlp'", ":", "\n", "            ", "self", ".", "merge", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "self", ".", "hidden_size", ",", "self", ".", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.TableRNNEncoder.forward": [[99, 131], ["Models.encode_unsorted_batch", "torch.LongTensor().unsqueeze_().cuda().expand_as", "torch.LongTensor().unsqueeze_().cuda().expand_as", "torch.LongTensor().unsqueeze_().cuda().expand_as", "torch.LongTensor().unsqueeze_().cuda().expand_as", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "tbl_split.data.size", "Models.TableRNNEncoder.merge", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "tbl_split.data.size", "encode_unsorted_batch.size", "encode_unsorted_batch.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "tbl_split.data.size", "range", "tbl_split.data.size"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.encode_unsorted_batch"], ["", "", "def", "forward", "(", "self", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ")", ":", "\n", "        ", "\"\"\"\n        Encode table headers.\n            :param tbl: header token list\n            :param tbl_len: length of token list (num_table_header, batch)\n            :param tbl_split: table header boundary list\n        \"\"\"", "\n", "tbl_context", "=", "encode_unsorted_batch", "(", "self", ".", "encoder", ",", "tbl", ",", "tbl_len", ")", "\n", "# --> (num_table_header, batch, hidden_size * num_directions)", "\n", "if", "self", ".", "split_type", "==", "'outcell'", ":", "\n", "            ", "batch_index", "=", "torch", ".", "LongTensor", "(", "range", "(", "tbl_split", ".", "data", ".", "size", "(", "1", ")", ")", ")", ".", "unsqueeze_", "(", "\n", "0", ")", ".", "cuda", "(", ")", ".", "expand_as", "(", "tbl_split", ".", "data", ")", "\n", "enc_split", "=", "tbl_context", "[", "tbl_split", ".", "data", ",", "batch_index", ",", ":", "]", "\n", "enc_left", ",", "enc_right", "=", "enc_split", "[", ":", "-", "1", "]", ",", "enc_split", "[", "1", ":", "]", "\n", "", "elif", "self", ".", "split_type", "==", "'incell'", ":", "\n", "            ", "batch_index", "=", "torch", ".", "LongTensor", "(", "range", "(", "tbl_split", ".", "data", ".", "size", "(", "1", ")", ")", ")", ".", "unsqueeze_", "(", "\n", "0", ")", ".", "cuda", "(", ")", ".", "expand", "(", "tbl_split", ".", "data", ".", "size", "(", "0", ")", "-", "1", ",", "tbl_split", ".", "data", ".", "size", "(", "1", ")", ")", "\n", "split_left", "=", "(", "tbl_split", ".", "data", "[", ":", "-", "1", "]", "+", "\n", "1", ")", ".", "clamp", "(", "0", ",", "tbl_context", ".", "size", "(", "0", ")", "-", "1", ")", "\n", "enc_left", "=", "tbl_context", "[", "split_left", ",", "batch_index", ",", ":", "]", "\n", "split_right", "=", "(", "tbl_split", ".", "data", "[", "1", ":", "]", "-", "\n", "1", ")", ".", "clamp", "(", "0", ",", "tbl_context", ".", "size", "(", "0", ")", "-", "1", ")", "\n", "enc_right", "=", "tbl_context", "[", "split_right", ",", "batch_index", ",", ":", "]", "\n", "\n", "", "if", "self", ".", "merge_type", "==", "'sub'", ":", "\n", "            ", "return", "(", "enc_right", "-", "enc_left", ")", "\n", "", "elif", "self", ".", "merge_type", "==", "'cat'", ":", "\n", "# take half vector for each direction", "\n", "            ", "half_hidden_size", "=", "self", ".", "hidden_size", "//", "2", "\n", "return", "torch", ".", "cat", "(", "[", "enc_right", "[", ":", ",", ":", ",", ":", "half_hidden_size", "]", ",", "enc_left", "[", ":", ",", ":", ",", "half_hidden_size", ":", "]", "]", ",", "2", ")", "\n", "", "elif", "self", ".", "merge_type", "==", "'mlp'", ":", "\n", "            ", "return", "self", ".", "merge", "(", "torch", ".", "cat", "(", "[", "enc_right", ",", "enc_left", "]", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.MatchScorer.__init__": [[134, 142], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.LogSoftmax", "torch.LogSoftmax", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "score_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "MatchScorer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "score_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "input_size", ",", "score_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "score_size", ",", "1", ")", ")", "\n", "self", ".", "log_sm", "=", "nn", ".", "LogSoftmax", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.MatchScorer.forward": [[143, 160], ["q_enc.unsqueeze().expand", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "Models.MatchScorer.score_layer().squeeze", "Models.MatchScorer.masked_fill", "Models.MatchScorer.log_sm", "tbl_enc.size", "tbl_enc.size", "q_enc.size", "q_enc.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.MatchScorer.score_layer", "float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q_enc", ",", "tbl_enc", ",", "tbl_mask", ")", ":", "\n", "        ", "\"\"\"\n        Match and return table column score.\n            :param q_enc: question encoding vectors (batch, rnn_size)\n            :param tbl_enc: header encoding vectors (num_table_header, batch, rnn_size)\n            :param tbl_num: length of token list\n        \"\"\"", "\n", "q_enc_expand", "=", "q_enc", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "\n", "tbl_enc", ".", "size", "(", "0", ")", ",", "tbl_enc", ".", "size", "(", "1", ")", ",", "q_enc", ".", "size", "(", "1", ")", ")", "\n", "# (batch, num_table_header, input_size)", "\n", "feat", "=", "torch", ".", "cat", "(", "(", "q_enc_expand", ",", "tbl_enc", ")", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# (batch, num_table_header)", "\n", "score", "=", "self", ".", "score_layer", "(", "feat", ")", ".", "squeeze", "(", "2", ")", "\n", "# mask scores", "\n", "score_mask", "=", "score", ".", "masked_fill", "(", "tbl_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# normalize", "\n", "return", "self", ".", "log_sm", "(", "score_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CondMatchScorer.__init__": [[163, 166], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["    ", "def", "__init__", "(", "self", ",", "sel_match", ")", ":", "\n", "        ", "super", "(", "CondMatchScorer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sel_match", "=", "sel_match", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CondMatchScorer.forward": [[167, 185], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "r_list.append", "Models.CondMatchScorer.sel_match"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "cond_context_filter", ",", "tbl_enc", ",", "tbl_mask", ",", "emb_span_l", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Match and return table column score for cond decoder.\n            :param cond_context: cond decoder's context vectors (num_cond*3, batch, rnn_size)\n            :param tbl_enc: header encoding vectors (num_table_header, batch, rnn_size)\n            :param tbl_num: length of token list\n        \"\"\"", "\n", "# -> (num_cond, batch, rnn_size)", "\n", "if", "emb_span_l", "is", "not", "None", ":", "\n", "# -> (num_cond, batch, 2*rnn_size)", "\n", "            ", "cond_context_filter", "=", "torch", ".", "cat", "(", "\n", "(", "cond_context_filter", ",", "emb_span_l", ")", ",", "2", ")", "\n", "", "r_list", "=", "[", "]", "\n", "for", "cond_context_one", "in", "cond_context_filter", ":", "\n", "# -> (batch, num_table_header)", "\n", "            ", "r_list", ".", "append", "(", "self", ".", "sel_match", "(", "cond_context_one", ",", "tbl_enc", ",", "tbl_mask", ")", ")", "\n", "# (num_cond, batch, num_table_header)", "\n", "", "return", "torch", ".", "stack", "(", "r_list", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CondDecoder.__init__": [[188, 209], ["torch.Module.__init__", "Models._build_rnn", "table.modules.GlobalAttention", "table.modules.LockedDropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models._build_rnn"], ["    ", "def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "input_size", ",", "hidden_size", ",", "attn_type", ",", "attn_hidden", ",", "dropout", ",", "lock_dropout", ",", "weight_dropout", ")", ":", "\n", "        ", "super", "(", "CondDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'rnn'", "\n", "self", ".", "bidirectional_encoder", "=", "bidirectional_encoder", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "if", "lock_dropout", ":", "\n", "            ", "self", ".", "word_dropout", "=", "table", ".", "modules", ".", "LockedDropout", "(", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Build the RNN.", "\n", "", "self", ".", "rnn", "=", "_build_rnn", "(", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", ",", "num_layers", ",", "dropout", ",", "weight_dropout", ")", "\n", "\n", "# Set up the standard attention.", "\n", "self", ".", "attn", "=", "table", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "True", ",", "attn_type", "=", "attn_type", ",", "attn_hidden", "=", "attn_hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CondDecoder.forward": [[210, 244], ["isinstance", "Models.CondDecoder._run_forward_pass", "state.update_state", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoderParentFeedInput._run_forward_pass", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.RNNDecoderState.update_state"], ["", "def", "forward", "(", "self", ",", "emb", ",", "context", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Forward through the decoder.\n        Args:\n            input (LongTensor): a sequence of input tokens tensors\n                                of size (len x batch x nfeats).\n            context (FloatTensor): output(tensor sequence) from the encoder\n                        RNN of size (src_len x batch x hidden_size).\n            state (FloatTensor): hidden state from the encoder RNN for\n                                 initializing the decoder.\n        Returns:\n            outputs (FloatTensor): a Tensor sequence of output from the decoder\n                                   of shape (len x batch x hidden_size).\n            state (FloatTensor): final hidden state from the decoder.\n            attns (dict of (str, FloatTensor)): a dictionary of different\n                                type of attention Tensor from the decoder\n                                of shape (src_len x batch).\n        \"\"\"", "\n", "# Args Check", "\n", "assert", "isinstance", "(", "state", ",", "RNNDecoderState", ")", "\n", "# END Args Check", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "hidden", ",", "outputs", ",", "attns", "=", "self", ".", "_run_forward_pass", "(", "emb", ",", "context", ",", "state", ")", "\n", "\n", "# Update the state with the result.", "\n", "state", ".", "update_state", "(", "hidden", ")", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "for", "k", "in", "attns", ":", "\n", "            ", "attns", "[", "k", "]", "=", "torch", ".", "stack", "(", "attns", "[", "k", "]", ")", "\n", "\n", "", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CondDecoder._fix_enc_hidden": [[245, 253], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["None"], ["", "def", "_fix_enc_hidden", "(", "self", ",", "h", ")", ":", "\n", "        ", "\"\"\"\n        The encoder hidden is  (layers*directions) x batch x dim.\n        We need to convert it to layers x batch x (directions*dim).\n        \"\"\"", "\n", "if", "self", ".", "bidirectional_encoder", ":", "\n", "            ", "h", "=", "torch", ".", "cat", "(", "[", "h", "[", "0", ":", "h", ".", "size", "(", "0", ")", ":", "2", "]", ",", "h", "[", "1", ":", "h", ".", "size", "(", "0", ")", ":", "2", "]", "]", ",", "2", ")", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CondDecoder.init_decoder_state": [[254, 256], ["Models.RNNDecoderState", "tuple", "Models.CondDecoder._fix_enc_hidden", "range", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder._fix_enc_hidden"], ["", "def", "init_decoder_state", "(", "self", ",", "context", ",", "enc_hidden", ")", ":", "\n", "        ", "return", "RNNDecoderState", "(", "context", ",", "self", ".", "hidden_size", ",", "tuple", "(", "[", "self", ".", "_fix_enc_hidden", "(", "enc_hidden", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "enc_hidden", ")", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CondDecoder._run_forward_pass": [[257, 298], ["Models.CondDecoder.rnn", "Models.CondDecoder.attn", "Models.CondDecoder.word_dropout", "rnn_output.transpose().contiguous", "context.transpose", "rnn_output.transpose"], "methods", ["None"], ["", "def", "_run_forward_pass", "(", "self", ",", "emb", ",", "context", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for running the specific RNN forward pass.\n        Must be overriden by all subclasses.\n        Args:\n            input (LongTensor): a sequence of input tokens tensors\n                                of size (len x batch x nfeats).\n            context (FloatTensor): output(tensor sequence) from the encoder\n                        RNN of size (src_len x batch x hidden_size).\n            state (FloatTensor): hidden state from the encoder RNN for\n                                 initializing the decoder.\n        Returns:\n            hidden (Variable): final hidden state from the decoder.\n            outputs ([FloatTensor]): an array of output of every time\n                                     step from the decoder.\n            attns (dict of (str, [FloatTensor]): a dictionary of different\n                            type of attention Tensor array of every time\n                            step from the decoder.\n        \"\"\"", "\n", "\n", "# Initialize local and return variables.", "\n", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "\n", "if", "self", ".", "word_dropout", "is", "not", "None", ":", "\n", "            ", "emb", "=", "self", ".", "word_dropout", "(", "emb", ")", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", ")", "\n", "\n", "# Calculate the attention.", "\n", "attn_outputs", ",", "attn_scores", "=", "self", ".", "attn", "(", "\n", "rnn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "# (output_len, batch, d)", "\n", "context", ".", "transpose", "(", "0", ",", "1", ")", "# (contxt_len, batch, d)", "\n", ")", "\n", "attns", "[", "\"std\"", "]", "=", "attn_scores", "\n", "\n", "outputs", "=", "attn_outputs", "# (input_len, batch, d)", "\n", "\n", "# Return result.", "\n", "return", "hidden", ",", "outputs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.DecoderState.detach": [[310, 318], ["h.detach_"], "methods", ["None"], ["\n", "for", "h", "in", "self", ".", "_all", ":", "\n", "            ", "if", "h", "is", "not", "None", ":", "\n", "                ", "h", ".", "detach_", "(", ")", "\n", "\n", "", "", "", "def", "beam_update", "(", "self", ",", "idx", ",", "positions", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Update when beam advances. \"\"\"", "\n", "for", "e", "in", "self", ".", "_all", ":", "\n", "            ", "a", ",", "br", ",", "d", "=", "e", ".", "size", "(", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.DecoderState.beam_update": [[319, 326], ["e.size", "sentStates.data.copy_", "e.view", "sentStates.data.index_select"], "methods", ["None"], ["sentStates", "=", "e", ".", "view", "(", "a", ",", "beam_size", ",", "br", "//", "beam_size", ",", "d", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "sentStates", ".", "data", ".", "copy_", "(", "\n", "sentStates", ".", "data", ".", "index_select", "(", "1", ",", "positions", ")", ")", "\n", "\n", "\n", "", "", "", "class", "RNNDecoderState", "(", "DecoderState", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "context", ",", "hidden_size", ",", "rnnstate", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.RNNDecoderState.__init__": [[329, 342], ["isinstance"], "methods", ["None"], ["\n", "if", "not", "isinstance", "(", "rnnstate", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "hidden", "=", "(", "rnnstate", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hidden", "=", "rnnstate", "\n", "\n", "", "", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.RNNDecoderState._all": [[343, 346], ["None"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "rnnstate", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "rnnstate", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "hidden", "=", "(", "rnnstate", ",", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.RNNDecoderState.update_state": [[347, 352], ["isinstance"], "methods", ["None"], ["            ", "self", ".", "hidden", "=", "rnnstate", "\n", "\n", "", "", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "v_list", "=", "[", "Variable", "(", "e", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", ",", "volatile", "=", "True", ")", "\n", "for", "e", "in", "self", ".", "_all", "]", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.RNNDecoderState.repeat_beam_size_times": [[353, 358], ["tuple", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "e.data.repeat"], "methods", ["None"], ["self", ".", "hidden", "=", "tuple", "(", "v_list", ")", "\n", "\n", "\n", "", "", "class", "CoAttention", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "hidden_size", ",", "dropout", ",", "weight_dropout", ",", "attn_type", ",", "attn_hidden", ")", ":", "\n", "        ", "super", "(", "CoAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CoAttention.__init__": [[361, 380], ["torch.Module.__init__", "Models._build_rnn", "table.modules.GlobalAttention", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models._build_rnn"], ["self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "no_pack_padded_seq", "=", "False", "\n", "\n", "self", ".", "rnn", "=", "_build_rnn", "(", "rnn_type", ",", "2", "*", "hidden_size", ",", "hidden_size", "//", "\n", "num_directions", ",", "num_layers", ",", "dropout", ",", "weight_dropout", ",", "bidirectional", ")", "\n", "self", ".", "attn", "=", "table", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "False", ",", "attn_type", "=", "attn_type", ",", "attn_hidden", "=", "attn_hidden", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "q_all", ",", "lengths", ",", "tbl_enc", ",", "tbl_mask", ")", ":", "\n", "        ", "self", ".", "attn", ".", "applyMask", "(", "tbl_mask", ".", "data", ".", "unsqueeze", "(", "0", ")", ")", "\n", "# attention", "\n", "emb", ",", "_", "=", "self", ".", "attn", "(", "\n", "q_all", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "# (output_len, batch, d)", "\n", "tbl_enc", ".", "transpose", "(", "0", ",", "1", ")", "# (contxt_len, batch, d)", "\n", ")", "\n", "\n", "# feed to rnn", "\n", "if", "not", "isinstance", "(", "lengths", ",", "list", ")", ":", "\n", "            ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "", "packed_emb", "=", "pack", "(", "emb", ",", "lengths", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CoAttention.forward": [[369, 387], ["Models.CoAttention.attn.applyMask", "Models.CoAttention.attn", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Models.CoAttention.rnn", "tbl_mask.data.unsqueeze", "q_all.transpose().contiguous", "tbl_enc.transpose", "isinstance", "lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "q_all.transpose", "lengths.view().tolist.view().tolist.view"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMask"], ["", "def", "forward", "(", "self", ",", "q_all", ",", "lengths", ",", "tbl_enc", ",", "tbl_mask", ")", ":", "\n", "        ", "self", ".", "attn", ".", "applyMask", "(", "tbl_mask", ".", "data", ".", "unsqueeze", "(", "0", ")", ")", "\n", "# attention", "\n", "emb", ",", "_", "=", "self", ".", "attn", "(", "\n", "q_all", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "# (output_len, batch, d)", "\n", "tbl_enc", ".", "transpose", "(", "0", ",", "1", ")", "# (contxt_len, batch, d)", "\n", ")", "\n", "\n", "# feed to rnn", "\n", "if", "not", "isinstance", "(", "lengths", ",", "list", ")", ":", "\n", "            ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "", "packed_emb", "=", "pack", "(", "emb", ",", "lengths", ")", "\n", "\n", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "packed_emb", ",", "None", ")", "\n", "\n", "outputs", "=", "unpack", "(", "outputs", ")", "[", "0", "]", "\n", "\n", "return", "hidden_t", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.__init__": [[438, 455], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["# emb_op", "\n", "if", "self", ".", "opt", ".", "layout_encode", "==", "'rnn'", ":", "\n", "            ", "emb_op", "=", "encode_unsorted_batch", "(", "\n", "self", ".", "lay_encoder", ",", "cond_op", ",", "cond_op_len", ".", "clamp", "(", "min", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "emb_op", "=", "self", ".", "cond_embedding", "(", "cond_op", ")", "\n", "# emb_col", "\n", "", "batch_index", "=", "torch", ".", "LongTensor", "(", "range", "(", "batch_size", ")", ")", ".", "unsqueeze_", "(", "\n", "0", ")", ".", "cuda", "(", ")", ".", "expand", "(", "cond_col", ".", "size", "(", "0", ")", ",", "cond_col", ".", "size", "(", "1", ")", ")", "\n", "emb_col", "=", "tbl_enc", "[", "cond_col", ".", "data", ",", "batch_index", ",", ":", "]", "\n", "# emb_span_l/r: (num_cond, batch, hidden_size)", "\n", "emb_span_l", "=", "q_all", "[", "cond_span_l", ".", "data", ",", "batch_index", ",", ":", "]", "\n", "emb_span_r", "=", "q_all", "[", "cond_span_r", ".", "data", ",", "batch_index", ",", ":", "]", "\n", "emb_span", "=", "self", ".", "span_merge", "(", "torch", ".", "cat", "(", "[", "emb_span_l", ",", "emb_span_r", "]", ",", "2", ")", ")", "\n", "# stack embeddings", "\n", "# (seq_len*3, batch, hidden_size)", "\n", "emb", "=", "torch", ".", "stack", "(", "[", "emb_op", ",", "emb_col", ",", "emb_span", "]", ",", "\n", "1", ")", ".", "view", "(", "-", "1", ",", "batch_size", ",", "emb_op", ".", "size", "(", "2", ")", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.enc": [[410, 422], ["Models.ParserModel.q_encoder", "Models.ParserModel.tbl_encoder", "q_ht.size", "Models.ParserModel.co_attention", "q_ht[].transpose().contiguous().view", "q_ht[].transpose().contiguous", "q_ht[].transpose"], "methods", ["None"], ["", "def", "enc", "(", "self", ",", "q", ",", "q_len", ",", "ent", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ",", "tbl_mask", ")", ":", "\n", "        ", "q_enc", ",", "q_all", "=", "self", ".", "q_encoder", "(", "q", ",", "lengths", "=", "q_len", ",", "ent", "=", "ent", ")", "\n", "tbl_enc", "=", "self", ".", "tbl_encoder", "(", "tbl", ",", "tbl_len", ",", "tbl_split", ")", "\n", "if", "self", ".", "co_attention", "is", "not", "None", ":", "\n", "            ", "q_enc", ",", "q_all", "=", "self", ".", "co_attention", "(", "q_all", ",", "q_len", ",", "tbl_enc", ",", "tbl_mask", ")", "\n", "# (num_layers * num_directions, batch, hidden_size)", "\n", "", "q_ht", ",", "q_ct", "=", "q_enc", "\n", "batch_size", "=", "q_ht", ".", "size", "(", "1", ")", "\n", "q_ht", "=", "q_ht", "[", "-", "1", "]", "if", "not", "self", ".", "opt", ".", "brnn", "else", "q_ht", "[", "-", "2", ":", "]", ".", "transpose", "(", "\n", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "return", "q_enc", ",", "q_all", ",", "tbl_enc", ",", "q_ht", ",", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.select3": [[423, 426], ["cond_context.size"], "methods", ["None"], ["", "def", "select3", "(", "self", ",", "cond_context", ",", "start_index", ")", ":", "\n", "        ", "return", "cond_context", "[", "start_index", ":", "cond_context", ".", "size", "(", "\n", "0", ")", ":", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.forward": [[487, 562], ["q.size", "Models.ParserModel.q_encoder", "Models.ParserModel.run_decoder", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "Models.ParserModel.tgt_embeddings", "tgt_mask.unsqueeze().expand_as", "Models.ParserModel.run_decoder", "Models.ParserModel.q_tgt_encoder", "Models.ParserModel.q_token_encoder", "q_token_ht.size", "Models.ParserModel.token_pruner().t", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "lay_attn_scores.mean", "Models.ParserModel.lay_encoder", "Models.encode_unsorted_batch", "Models.ParserModel.lay_co_attention", "lay_index.size", "lay_index.size", "Models.ParserModel.mul", "lay_select.mul", "Models.ParserModel.q_co_attention", "q_token_ht[].transpose().contiguous().view", "q.data.ne().t", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "tgt_mask.unsqueeze", "Models.ParserModel.token_pruner", "q_token_ht[].transpose().contiguous", "q.data.ne", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "q_token_ht[].transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "lay_len.unsqueeze().float", "lay_len.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.run_decoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.run_decoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.encode_unsorted_batch"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models._build_rnn": [[14, 23], ["getattr", "table.modules.WeightDrop", "str", "range"], "function", ["None"], ["rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "dropout", "=", "dr", ",", "bidirectional", "=", "bidirectional", ")", "\n", "if", "weight_dropout", ">", "0", ":", "\n", "        ", "param_list", "=", "[", "'weight_hh_l0'", "]", "\n", "if", "bidirectional", ":", "\n", "            ", "param_list", "+=", "[", "it", "+", "'_reverse'", "for", "it", "in", "param_list", "]", "\n", "", "rnn", "=", "table", ".", "modules", ".", "WeightDrop", "(", "rnn", ",", "param_list", ",", "dropout", "=", "weight_dropout", ")", "\n", "", "return", "rnn", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.encode_unsorted_batch": [[79, 91], ["table.Utils.sort_for_pack", "tbl.index_select", "encoder", "torch.autograd.Variable", "tbl_context.index_select.index_select", "torch.autograd.Variable", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.sort_for_pack"], ["__", ",", "tbl_context", "=", "encoder", "(", "tbl_sorted", ",", "tbl_len_sorted", ")", "\n", "# recover the sort for pack()", "\n", "v_idx_map_back", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "\n", "idx_map_back", ")", ".", "cuda", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "tbl_context", "=", "tbl_context", ".", "index_select", "(", "1", ",", "v_idx_map_back", ")", "\n", "return", "tbl_context", "\n", "\n", "\n", "", "class", "TableRNNEncoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "encoder", ",", "split_type", "=", "'incell'", ",", "merge_type", "=", "'cat'", ")", ":", "\n", "        ", "super", "(", "TableRNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "split_type", "=", "split_type", "\n", "self", ".", "merge_type", "=", "merge_type", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.__init__": [[108, 132], ["torch.load", "torch.load", "torch.load", "torch.load", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "Translator.Translator.model.eval", "zip", "Translator.Translator.model.parameters", "p.data.copy_"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ParseResult.ParseResult.eval"], ["q_mask", "=", "v_eval", "(", "\n", "q", ".", "data", ".", "eq", "(", "self", ".", "model", ".", "pad_word_index", ")", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "cond_span_l", "=", "argmax", "(", "self", ".", "model", ".", "cond_span_l_match", "(", "\n", "cond_context", ",", "q_all", ",", "q_mask", ")", ".", "data", ")", "\n", "cond_span_l_list", ".", "append", "(", "cpu_vector", "(", "cond_span_l", ")", ")", "\n", "# emb_span_l: (1, batch, hidden_size)", "\n", "emb_span_l", "=", "q_all", "[", "cond_span_l", ",", "batch_index", ",", ":", "]", "\n", "cond_span_r", "=", "argmax", "(", "self", ".", "model", ".", "cond_span_r_match", "(", "\n", "cond_context", ",", "q_all", ",", "q_mask", ",", "emb_span_l", ")", ".", "data", ")", "\n", "cond_span_r_list", ".", "append", "(", "cpu_vector", "(", "cond_span_r", ")", ")", "\n", "# emb_span_r: (1, batch, hidden_size)", "\n", "emb_span_r", "=", "q_all", "[", "cond_span_r", ",", "batch_index", ",", ":", "]", "\n", "emb_span", "=", "self", ".", "model", ".", "span_merge", "(", "\n", "torch", ".", "cat", "(", "[", "emb_span_l", ",", "emb_span_r", "]", ",", "2", ")", ")", "\n", "cond_context", ",", "cond_state", ",", "_", "=", "self", ".", "model", ".", "cond_decoder", "(", "\n", "emb_span", ",", "q_all", ",", "cond_state", ")", "\n", "\n", "# (3) recover output", "\n", "", "indices", "=", "cpu_vector", "(", "batch", ".", "indices", ".", "data", ")", "\n", "r_list", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "idx", "=", "indices", "[", "b", "]", "\n", "agg", "=", "agg_pred", "[", "b", "]", "\n", "sel", "=", "sel_pred", "[", "b", "]", "\n", "cond", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.translate": [[263, 372], ["q.size", "Translator.Translator.model.q_encoder", "Translator.Translator.run_lay_decoder", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "range", "Translator.v_eval", "Translator.expand_layout_with_skip", "Translator.Translator.run_tgt_decoder", "range", "Translator.cpu_vector", "Translator.Translator.model.q_tgt_encoder", "Translator.Translator.model.q_token_encoder", "q_token_ht.size", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.data.lt().view", "range", "range", "Translator.recover_layout_token", "lay_list.append", "range", "v_eval.cuda", "Translator.Translator.model.lay_encoder", "torch.LongTensor.cuda().clamp", "torch.LongTensor.cuda().clamp", "table.Models.encode_unsorted_batch", "table.Models.encode_unsorted_batch", "table.Models.encode_unsorted_batch", "table.Models.encode_unsorted_batch", "table.Models.encode_unsorted_batch", "Translator.Translator.model.lay_co_attention", "Translator.Translator.model.q_co_attention", "Translator.recover_target_token", "tgt_list.append", "table.ParseResult.ParseResult", "table.ParseResult.ParseResult", "table.ParseResult.ParseResult", "table.ParseResult.ParseResult", "table.ParseResult.ParseResult", "q_token_ht[].transpose().contiguous().view", "Translator.Translator.model.token_pruner", "len", "len", "range", "layout_token_prune_list.append", "v_eval.size", "bpe.recover_bpe", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "Translator.Translator.size", "zip", "torch.sigmoid.data.lt", "w.startswith", "F.sigmoid.data.lt().view.size", "range", "range", "torch.LongTensor.max", "torch.LongTensor.max", "torch.LongTensor.cuda", "torch.LongTensor.cuda", "q_token_ht[].transpose().contiguous", "len", "masked_v_list.append", "range", "range", "v_eval.size", "Translator.Translator.size", "q_token_ht[].transpose", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.run_lay_decoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.v_eval", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.expand_layout_with_skip", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.run_tgt_decoder", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.cpu_vector", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.recover_layout_token", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.encode_unsorted_batch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.encode_unsorted_batch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.encode_unsorted_batch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.encode_unsorted_batch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.encode_unsorted_batch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.recover_target_token", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.recover_bpe"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.v_eval": [[18, 20], ["torch.autograd.Variable"], "function", ["None"], ["\n", "\n", "", "class", "Translator", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.cpu_vector": [[22, 24], ["v.clone().view().cpu", "v.clone().view", "v.clone"], "function", ["None"], ["# Add in default model arguments, possibly added since training.", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ParseResult.ParseResult.__init__": [[8, 15], ["collections.defaultdict", "set"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "idx", ",", "agg", ",", "sel", ",", "cond", ")", ":", "\n", "        ", "self", ".", "idx", "=", "idx", "\n", "self", ".", "agg", "=", "agg", "\n", "self", ".", "sel", "=", "sel", "\n", "self", ".", "cond", "=", "cond", "\n", "self", ".", "correct", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "\n", "", "def", "eval", "(", "self", ",", "gold", ",", "sql_gold", ",", "engine", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ParseResult.ParseResult.eval": [[16, 40], ["tree.is_tree_eq", "tree.is_tree_eq", "ParseResult.ParseResult.incorrect_prune.add"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.is_tree_eq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.is_tree_eq"], ["        ", "if", "self", ".", "agg", "==", "gold", "[", "'query'", "]", "[", "'agg'", "]", ":", "\n", "            ", "self", ".", "correct", "[", "'agg'", "]", "=", "1", "\n", "\n", "", "if", "self", ".", "sel", "==", "gold", "[", "'query'", "]", "[", "'sel'", "]", ":", "\n", "            ", "self", ".", "correct", "[", "'sel'", "]", "=", "1", "\n", "\n", "", "op_list_pred", "=", "[", "op", "for", "col", ",", "op", ",", "span", "in", "self", ".", "cond", "]", "\n", "op_list_gold", "=", "[", "op", "for", "col", ",", "op", ",", "span", "in", "gold", "[", "'query'", "]", "[", "'conds'", "]", "]", "\n", "\n", "col_list_pred", "=", "[", "col", "for", "col", ",", "op", ",", "span", "in", "self", ".", "cond", "]", "\n", "col_list_gold", "=", "[", "col", "for", "col", ",", "op", ",", "span", "in", "gold", "[", "'query'", "]", "[", "'conds'", "]", "]", "\n", "\n", "q", "=", "gold", "[", "'question'", "]", "[", "'words'", "]", "\n", "span_list_pred", "=", "[", "' '", ".", "join", "(", "q", "[", "span", "[", "0", "]", ":", "span", "[", "1", "]", "+", "1", "]", ")", "\n", "for", "col", ",", "op", ",", "span", "in", "self", ".", "cond", "]", "\n", "span_list_gold", "=", "[", "' '", ".", "join", "(", "span", "[", "'words'", "]", ")", "\n", "for", "col", ",", "op", ",", "span", "in", "gold", "[", "'query'", "]", "[", "'conds'", "]", "]", "\n", "\n", "where_pred", "=", "list", "(", "zip", "(", "col_list_pred", ",", "op_list_pred", ",", "span_list_pred", ")", ")", "\n", "where_gold", "=", "list", "(", "zip", "(", "col_list_gold", ",", "op_list_gold", ",", "span_list_gold", ")", ")", "\n", "where_pred", ".", "sort", "(", ")", "\n", "where_gold", ".", "sort", "(", ")", "\n", "if", "where_pred", "==", "where_gold", "and", "(", "len", "(", "col_list_pred", ")", "==", "len", "(", "col_list_gold", ")", ")", "and", "(", "len", "(", "op_list_pred", ")", "==", "len", "(", "op_list_gold", ")", ")", "and", "(", "len", "(", "span_list_pred", ")", "==", "len", "(", "span_list_gold", ")", ")", ":", "\n", "            ", "self", ".", "correct", "[", "'where'", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ParseResult.ParseResult.recover_cond_to_gloss": [[66, 75], ["range", "r_list.append", "tk_list.append", "tk_list.append"], "methods", ["None"], ["", "", "def", "recover_cond_to_gloss", "(", "self", ",", "gold", ")", ":", "\n", "        ", "r_list", "=", "[", "]", "\n", "for", "col", ",", "op", ",", "span", "in", "self", ".", "cond", ":", "\n", "            ", "tk_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "span", "[", "0", "]", ",", "span", "[", "1", "]", "+", "1", ")", ":", "\n", "                ", "tk_list", ".", "append", "(", "gold", "[", "'question'", "]", "[", "'gloss'", "]", "[", "i", "]", ")", "\n", "tk_list", ".", "append", "(", "gold", "[", "'question'", "]", "[", "'after'", "]", "[", "i", "]", ")", "\n", "", "r_list", ".", "append", "(", "[", "col", ",", "op", ",", "''", ".", "join", "(", "tk_list", ")", ".", "strip", "(", ")", "]", ")", "\n", "", "return", "r_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.set_parameters": [[7, 19], ["torch.SGD", "torch.RMSprop", "torch.Adam", "RuntimeError"], "methods", ["None"], ["    ", "def", "set_parameters", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "[", "p", "for", "p", "in", "params", "if", "p", ".", "requires_grad", "]", "\n", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'rmsprop'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "RMSprop", "(", "\n", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ",", "alpha", "=", "self", ".", "alpha", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-9", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.__init__": [[20, 35], ["None"], "methods", ["None"], ["", "", "def", "__init__", "(", "self", ",", "method", ",", "lr", ",", "alpha", ",", "max_grad_norm", ",", "\n", "lr_decay", "=", "1", ",", "start_decay_at", "=", "None", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.98", ",", "\n", "opt", "=", "None", ")", ":", "\n", "        ", "self", ".", "last_metric", "=", "None", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_at", "=", "start_decay_at", "\n", "self", ".", "start_decay", "=", "False", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "betas", "=", "[", "beta1", ",", "beta2", "]", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim._setRate": [[36, 39], ["None"], "methods", ["None"], ["", "def", "_setRate", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "lr", "=", "lr", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.step": [[40, 47], ["Optim.Optim.optimizer.step", "torch.nn.utils.clip_grad_norm"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Compute gradients norm.\"", "\n", "self", ".", "_step", "+=", "1", "\n", "\n", "# Decay method used in tensor2tensor.", "\n", "if", "self", ".", "opt", ".", "__dict__", ".", "get", "(", "\"decay_method\"", ",", "\"\"", ")", "==", "\"noam\"", ":", "\n", "            ", "self", ".", "_setRate", "(", "\n", "self", ".", "opt", ".", "learning_rate", "*", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.updateLearningRate": [[48, 65], ["print"], "methods", ["None"], ["(", "self", ".", "opt", ".", "rnn_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "self", ".", "_step", "**", "(", "-", "0.5", ")", ",", "\n", "self", ".", "_step", "*", "self", ".", "opt", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "max_grad_norm", ":", "\n", "            ", "clip_grad_norm", "(", "self", ".", "params", ",", "self", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "def", "updateLearningRate", "(", "self", ",", "metric", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Decay learning rate if val perf does not improve\n        or we hit the start_decay_at limit.\n        \"\"\"", "\n", "\n", "if", "(", "self", ".", "start_decay_at", "is", "not", "None", ")", "and", "(", "epoch", ">=", "self", ".", "start_decay_at", ")", ":", "\n", "            ", "self", ".", "start_decay", "=", "True", "\n", "", "if", "(", "self", ".", "last_metric", "is", "not", "None", ")", "and", "(", "metric", "is", "not", "None", ")", "and", "(", "metric", ">", "self", ".", "last_metric", ")", ":", "\n", "            ", "self", ".", "start_decay", "=", "True", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Loss.TableLossCompute.__init__": [[18, 32], ["torch.Module.__init__", "torch.NLLLoss", "torch.NLLLoss", "table.modules.cross_entropy_smooth.CrossEntropyLossSmooth"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["    ", "def", "__init__", "(", "self", ",", "agg_sample_rate", ",", "smooth_eps", "=", "0", ")", ":", "\n", "        ", "super", "(", "TableLossCompute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "{", "}", "\n", "nll", "=", "nn", ".", "NLLLoss", "(", "size_average", "=", "False", ",", "ignore_index", "=", "-", "1", ")", "\n", "if", "smooth_eps", ">", "0", ":", "\n", "            ", "for", "loss_name", "in", "(", "'sel'", ",", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ":", "\n", "                ", "self", ".", "criterion", "[", "loss_name", "]", "=", "nll", "\n", "", "for", "loss_name", "in", "(", "'agg'", ",", "'lay'", ")", ":", "\n", "                ", "self", ".", "criterion", "[", "loss_name", "]", "=", "CrossEntropyLossSmooth", "(", "\n", "size_average", "=", "False", ",", "ignore_index", "=", "-", "1", ",", "smooth_eps", "=", "smooth_eps", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "loss_name", "in", "(", "'agg'", ",", "'sel'", ",", "'lay'", ",", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ":", "\n", "                ", "self", ".", "criterion", "[", "loss_name", "]", "=", "nll", "\n", "", "", "self", ".", "agg_sample_rate", "=", "agg_sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Loss.TableLossCompute.compute_loss": [[33, 45], ["sum", "zip", "loss_list.append", "loss_list.append", "random.random"], "methods", ["None"], ["", "def", "compute_loss", "(", "self", ",", "pred", ",", "gold", ")", ":", "\n", "# sum up the loss functions", "\n", "        ", "loss_list", "=", "[", "]", "\n", "for", "loss_name", "in", "(", "'agg'", ",", "'sel'", ",", "'lay'", ")", ":", "\n", "            ", "loss", "=", "self", ".", "criterion", "[", "loss_name", "]", "(", "pred", "[", "loss_name", "]", ",", "gold", "[", "loss_name", "]", ")", "\n", "if", "(", "loss_name", "!=", "'agg'", ")", "or", "(", "rnd", ".", "random", "(", ")", "<", "self", ".", "agg_sample_rate", ")", ":", "\n", "                ", "loss_list", ".", "append", "(", "loss", ")", "\n", "", "", "for", "loss_name", "in", "(", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ":", "\n", "            ", "for", "p", ",", "g", "in", "zip", "(", "pred", "[", "loss_name", "]", ",", "gold", "[", "loss_name", "]", ")", ":", "\n", "                ", "loss", "=", "self", ".", "criterion", "[", "loss_name", "]", "(", "p", ",", "g", ")", "\n", "loss_list", ".", "append", "(", "loss", ")", "\n", "", "", "return", "sum", "(", "loss_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.OrderedIterator.create_batches": [[126, 137], ["torchtext.data.pool", "torchtext.data.pool", "torchtext.data.pool", "torchtext.data.pool", "torchtext.data.batch", "torchtext.data.batch", "torchtext.data.batch", "torchtext.data.batch", "IO.OrderedIterator.data", "IO.OrderedIterator.data", "IO.OrderedIterator.batches.append", "sorted"], "methods", ["None"], ["opt", ",", "js_list", ",", "'tbl_split'", ",", "filter_ex", ")", "\n", "tbl_split_examples", "=", "self", ".", "_construct_examples", "(", "\n", "tbl_split_data", ",", "'tbl_split'", ")", "\n", "\n", "tbl_mask_data", "=", "self", ".", "_read_annotated_file", "(", "\n", "opt", ",", "js_list", ",", "'tbl_mask'", ",", "filter_ex", ")", "\n", "tbl_mask_examples", "=", "self", ".", "_construct_examples", "(", "\n", "tbl_mask_data", ",", "'tbl_mask'", ")", "\n", "\n", "lay_data", "=", "self", ".", "_read_annotated_file", "(", "opt", ",", "js_list", ",", "'lay'", ",", "filter_ex", ")", "\n", "lay_examples", "=", "self", ".", "_construct_examples", "(", "lay_data", ",", "'lay'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.sort_key": [[174, 178], ["len"], "methods", ["None"], ["len_lay_list", "=", "[", "]", "\n", "len_tgt_list", "=", "[", "]", "\n", "for", "ex", "in", "examples", ":", "\n", "            ", "has_agg", "=", "0", "if", "int", "(", "ex", "[", "'agg'", "]", ")", "==", "0", "else", "1", "\n", "if", "len", "(", "ex", "[", "'cond_op'", "]", ")", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.__init__": [[179, 267], ["isinstance", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "IO.TableDataset._read_annotated_file", "IO.TableDataset._construct_examples", "len", "list", "len", "ex.keys", "super().__init__", "IO.read_anno_json", "IO.data_aug_by_permute_order", "IO.join_dicts", "filter", "enumerate", "IO.TableDataset.__init__.construct_final"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.data_aug_by_permute_order", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.join_dicts"], ["                ", "len_lay_list", ".", "append", "(", "0", ")", "\n", "len_tgt_list", ".", "append", "(", "1", "+", "has_agg", "+", "1", ")", "\n", "", "else", ":", "\n", "                ", "len_lay", "=", "len", "(", "ex", "[", "'cond_op'", "]", ")", "*", "2", "\n", "len_lay_list", ".", "append", "(", "len_lay", ")", "\n", "len_tgt_list", ".", "append", "(", "\n", "1", "+", "has_agg", "+", "1", "+", "len_lay", "+", "len", "(", "ex", "[", "'cond_op'", "]", ")", "*", "2", ")", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "", "ex", "=", "examples", "[", "0", "]", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "\n", "for", "k", "in", "(", "list", "(", "keys", ")", "+", "[", "\"indices\"", "]", ")", "]", "\n", "\n", "def", "construct_final", "(", "examples", ")", ":", "\n", "            ", "for", "i", ",", "ex", "in", "enumerate", "(", "examples", ")", ":", "\n", "                ", "yield", "torchtext", ".", "data", ".", "Example", ".", "fromlist", "(", "\n", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "+", "[", "i", "]", ",", "\n", "fields", ")", "\n", "\n", "", "", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "return", "True", "\n", "\n", "", "super", "(", "TableDataset", ",", "self", ")", ".", "__init__", "(", "\n", "construct_final", "(", "examples", ")", ",", "fields", ",", "filter_pred", ")", "\n", "\n", "", "def", "_read_annotated_file", "(", "self", ",", "opt", ",", "js_list", ",", "field", ",", "filter_ex", ")", ":", "\n", "        ", "\"\"\"\n        path: location of a src or tgt file\n        truncate: maximum sequence length (0 for unlimited)\n        \"\"\"", "\n", "if", "field", "in", "(", "'sel'", ",", "'agg'", ")", ":", "\n", "            ", "lines", "=", "(", "line", "[", "'query'", "]", "[", "field", "]", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'ent'", ",", ")", ":", "\n", "            ", "lines", "=", "(", "line", "[", "'question'", "]", "[", "'ent'", "]", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'tbl'", ",", ")", ":", "\n", "            ", "def", "_tbl", "(", "line", ")", ":", "\n", "                ", "tk_list", "=", "[", "SPLIT_WORD", "]", "\n", "tk_split", "=", "'\\t'", "+", "SPLIT_WORD", "+", "'\\t'", "\n", "tk_list", ".", "extend", "(", "tk_split", ".", "join", "(", "\n", "[", "'\\t'", ".", "join", "(", "col", "[", "'words'", "]", ")", "for", "col", "in", "line", "[", "'table'", "]", "[", "'header'", "]", "]", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", ")", "\n", "tk_list", ".", "append", "(", "SPLIT_WORD", ")", "\n", "return", "tk_list", "\n", "", "lines", "=", "(", "_tbl", "(", "line", ")", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'tbl_split'", ",", ")", ":", "\n", "            ", "def", "_cum_length_for_split", "(", "line", ")", ":", "\n", "                ", "len_list", "=", "[", "len", "(", "col", "[", "'words'", "]", ")", "\n", "for", "col", "in", "line", "[", "'table'", "]", "[", "'header'", "]", "]", "\n", "r", "=", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "len_list", ")", ")", ":", "\n", "                    ", "r", ".", "append", "(", "r", "[", "-", "1", "]", "+", "len_list", "[", "i", "]", "+", "1", ")", "\n", "", "return", "r", "\n", "", "lines", "=", "(", "_cum_length_for_split", "(", "line", ")", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'tbl_mask'", ",", ")", ":", "\n", "            ", "lines", "=", "(", "[", "0", "for", "col", "in", "line", "[", "'table'", "]", "[", "'header'", "]", "]", "\n", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'lay'", ",", ")", ":", "\n", "            ", "def", "_lay", "(", "where_list", ")", ":", "\n", "                ", "return", "' '", ".", "join", "(", "[", "str", "(", "op", ")", "for", "col", ",", "op", ",", "cond", "in", "where_list", "]", ")", "\n", "", "lines", "=", "(", "_lay", "(", "line", "[", "'query'", "]", "[", "'conds'", "]", ")", "\n", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'cond_op'", ",", ")", ":", "\n", "            ", "lines", "=", "(", "[", "str", "(", "op", ")", "for", "col", ",", "op", ",", "cond", "in", "line", "[", "'query'", "]", "[", "'conds'", "]", "]", "\n", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'cond_col'", ",", ")", ":", "\n", "            ", "lines", "=", "(", "[", "col", "for", "col", ",", "op", ",", "cond", "in", "line", "[", "'query'", "]", "[", "'conds'", "]", "]", "\n", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'cond_span'", ",", ")", ":", "\n", "            ", "def", "_find_span", "(", "q_list", ",", "where_list", ")", ":", "\n", "                ", "r_list", "=", "[", "]", "\n", "for", "col", ",", "op", ",", "cond", "in", "where_list", ":", "\n", "                    ", "tk_list", "=", "cond", "[", "'words'", "]", "\n", "# find exact match first", "\n", "if", "len", "(", "tk_list", ")", "<=", "len", "(", "q_list", ")", ":", "\n", "                        ", "match_list", "=", "[", "]", "\n", "for", "st", "in", "range", "(", "0", ",", "len", "(", "q_list", ")", "-", "len", "(", "tk_list", ")", "+", "1", ")", ":", "\n", "                            ", "if", "q_list", "[", "st", ":", "st", "+", "len", "(", "tk_list", ")", "]", "==", "tk_list", ":", "\n", "                                ", "match_list", ".", "append", "(", "(", "st", ",", "st", "+", "len", "(", "tk_list", ")", "-", "1", ")", ")", "\n", "", "", "if", "len", "(", "match_list", ")", ">", "0", ":", "\n", "                            ", "r_list", ".", "append", "(", "rnd", ".", "choice", "(", "match_list", ")", ")", "\n", "continue", "\n", "", "elif", "(", "opt", "is", "not", "None", ")", "and", "opt", ".", "span_exact_match", ":", "\n", "                            ", "return", "None", "\n", "", "else", ":", "\n", "# do not have exact match, then fuzzy match (w/o considering order)", "\n", "                            ", "for", "len_span", "in", "range", "(", "len", "(", "tk_list", ")", ",", "len", "(", "tk_list", ")", "+", "2", ")", ":", "\n", "                                ", "for", "st", "in", "range", "(", "0", ",", "len", "(", "q_list", ")", "-", "len_span", "+", "1", ")", ":", "\n", "                                    ", "if", "set", "(", "tk_list", ")", "<=", "set", "(", "q_list", "[", "st", ":", "st", "+", "len_span", "]", ")", ":", "\n", "                                        ", "match_list", ".", "append", "(", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._read_annotated_file": [[268, 310], ["tree.STree", "IO.TableDataset.bpe_processor.process", "tree.STree.to_list", "IO.TableDataset._read_annotated_file._lay_bpe"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpeProcessor.process", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.to_list"], ["(", "st", ",", "st", "+", "len_span", "-", "1", ")", ")", "\n", "", "", "if", "len", "(", "match_list", ")", ">", "0", ":", "\n", "# match spans that are as short as possible", "\n", "                                    ", "break", "\n", "", "", "if", "len", "(", "match_list", ")", ">", "0", ":", "\n", "                                ", "r_list", ".", "append", "(", "rnd", ".", "choice", "(", "match_list", ")", ")", "\n", "", "else", ":", "\n", "                                ", "return", "None", "\n", "", "", "", "else", ":", "\n", "                        ", "return", "None", "\n", "", "", "return", "r_list", "\n", "\n", "", "def", "_span", "(", "q_list", ",", "where_list", ",", "filter_ex", ")", ":", "\n", "                ", "r_list", "=", "_find_span", "(", "q_list", ",", "where_list", ")", "\n", "if", "(", "not", "filter_ex", ")", "and", "(", "r_list", "is", "None", ")", ":", "\n", "                    ", "r_list", "=", "[", "]", "\n", "for", "col", ",", "op", ",", "cond", "in", "where_list", ":", "\n", "                        ", "r_list", ".", "append", "(", "(", "0", ",", "0", ")", ")", "\n", "", "", "return", "r_list", "\n", "", "lines", "=", "(", "_span", "(", "line", "[", "'question'", "]", "[", "'words'", "]", ",", "line", "[", "'query'", "]", "\n", "[", "'conds'", "]", ",", "filter_ex", ")", "for", "line", "in", "js_list", ")", "\n", "", "elif", "field", "in", "(", "'cond_mask'", ",", ")", ":", "\n", "            ", "lines", "=", "(", "[", "0", "for", "col", ",", "op", ",", "cond", "in", "line", "[", "'query'", "]", "[", "'conds'", "]", "]", "\n", "for", "line", "in", "js_list", ")", "\n", "", "else", ":", "\n", "            ", "lines", "=", "(", "line", "[", "field", "]", "[", "'words'", "]", "for", "line", "in", "js_list", ")", "\n", "", "for", "line", "in", "lines", ":", "\n", "            ", "yield", "line", "\n", "\n", "", "", "def", "_construct_examples", "(", "self", ",", "lines", ",", "side", ")", ":", "\n", "        ", "for", "words", "in", "lines", ":", "\n", "            ", "example_dict", "=", "{", "side", ":", "words", "}", "\n", "yield", "example_dict", "\n", "\n", "", "", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "\n", "\n", "", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "d", ")", "\n", "\n", "", "def", "__reduce_ex__", "(", "self", ",", "proto", ")", ":", "\n", "        ", "\"This is a hack. Something is broken with torch pickle.\"", "\n", "return", "super", "(", "TableDataset", ",", "self", ")", ".", "__reduce_ex__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset._construct_examples": [[311, 315], ["None"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "def", "load_fields", "(", "vocab", ")", ":", "\n", "        ", "vocab", "=", "dict", "(", "vocab", ")", "\n", "fields", "=", "TableDataset", ".", "get_fields", "(", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.__getstate__": [[316, 318], ["None"], "methods", ["None"], ["for", "k", ",", "v", "in", "vocab", ".", "items", "(", ")", ":", "\n", "# Hack. Can't pickle defaultdict :(", "\n", "            ", "v", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "v", ".", "stoi", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.__setstate__": [[319, 321], ["IO.TableDataset.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.update"], ["fields", "[", "k", "]", ".", "vocab", "=", "v", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.__reduce_ex__": [[322, 325], ["super().__reduce_ex__"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.__reduce_ex__"], ["", "@", "staticmethod", "\n", "def", "save_vocab", "(", "fields", ")", ":", "\n", "        ", "vocab", "=", "[", "]", "\n", "for", "k", ",", "f", "in", "fields", ".", "items", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.load_fields": [[326, 335], ["dict", "IO.TableDataset.get_fields", "dict.items", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.get_fields"], ["            ", "if", "'vocab'", "in", "f", ".", "__dict__", ":", "\n", "                ", "f", ".", "vocab", ".", "stoi", "=", "dict", "(", "f", ".", "vocab", ".", "stoi", ")", "\n", "vocab", ".", "append", "(", "(", "k", ",", "f", ".", "vocab", ")", ")", "\n", "", "", "return", "vocab", "\n", "\n", "", "@", "staticmethod", "\n", "def", "get_fields", "(", ")", ":", "\n", "        ", "fields", "=", "{", "}", "\n", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "include_lengths", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab": [[336, 344], ["fields.items", "dict", "vocab.append"], "methods", ["None"], ["fields", "[", "\"ent\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "include_lengths", "=", "False", ")", "\n", "fields", "[", "\"agg\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "sequential", "=", "False", ",", "use_vocab", "=", "False", ",", "batch_first", "=", "True", ")", "\n", "fields", "[", "\"sel\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "sequential", "=", "False", ",", "use_vocab", "=", "False", ",", "batch_first", "=", "True", ")", "\n", "fields", "[", "\"tbl\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "include_lengths", "=", "True", ")", "\n", "fields", "[", "\"tbl_split\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.get_fields": [[345, 373], ["torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field"], "methods", ["None"], ["use_vocab", "=", "False", ",", "pad_token", "=", "0", ")", "\n", "fields", "[", "\"tbl_mask\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "ByteTensor", ",", "batch_first", "=", "True", ",", "pad_token", "=", "1", ")", "\n", "fields", "[", "\"lay\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "sequential", "=", "False", ",", "batch_first", "=", "True", ")", "\n", "fields", "[", "\"cond_op\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "include_lengths", "=", "True", ",", "pad_token", "=", "PAD_WORD", ")", "\n", "fields", "[", "\"cond_col\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "include_lengths", "=", "False", ",", "pad_token", "=", "0", ")", "\n", "fields", "[", "\"cond_span_l\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "include_lengths", "=", "False", ",", "pad_token", "=", "0", ")", "\n", "fields", "[", "\"cond_span_r\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "include_lengths", "=", "False", ",", "pad_token", "=", "0", ")", "\n", "fields", "[", "\"cond_col_loss\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "include_lengths", "=", "False", ",", "pad_token", "=", "-", "1", ")", "\n", "fields", "[", "\"cond_span_l_loss\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "include_lengths", "=", "False", ",", "pad_token", "=", "-", "1", ")", "\n", "fields", "[", "\"cond_span_r_loss\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "include_lengths", "=", "False", ",", "pad_token", "=", "-", "1", ")", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "sequential", "=", "False", ")", "\n", "return", "fields", "\n", "\n", "", "@", "staticmethod", "\n", "def", "build_vocab", "(", "train", ",", "dev", ",", "test", ",", "opt", ")", ":", "\n", "        ", "fields", "=", "train", ".", "fields", "\n", "\n", "merge_list", "=", "[", "]", "\n", "merge_name_list", "=", "(", "'src'", ",", "'tbl'", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.build_vocab": [[374, 391], ["IO.merge_vocabs", "fields[].build_vocab", "IO.merge_vocabs"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.merge_vocabs", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.build_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.merge_vocabs"], ["for", "split", "in", "(", "dev", ",", "test", ",", "train", ",", ")", ":", "\n", "            ", "for", "merge_name_it", "in", "merge_name_list", ":", "\n", "                ", "fields", "[", "merge_name_it", "]", ".", "build_vocab", "(", "\n", "split", ",", "max_size", "=", "opt", ".", "src_vocab_size", ",", "min_freq", "=", "0", ")", "\n", "merge_list", ".", "append", "(", "fields", "[", "merge_name_it", "]", ".", "vocab", ")", "\n", "# build vocabulary only based on the training set", "\n", "", "", "fields", "[", "\"ent\"", "]", ".", "build_vocab", "(", "\n", "train", ",", "max_size", "=", "opt", ".", "src_vocab_size", ",", "min_freq", "=", "0", ")", "\n", "fields", "[", "\"lay\"", "]", ".", "build_vocab", "(", "\n", "train", ",", "max_size", "=", "opt", ".", "src_vocab_size", ",", "min_freq", "=", "0", ")", "\n", "fields", "[", "\"cond_op\"", "]", ".", "build_vocab", "(", "\n", "train", ",", "max_size", "=", "opt", ".", "src_vocab_size", ",", "min_freq", "=", "0", ")", "\n", "\n", "# need to know all the words to filter the pretrained word embeddings", "\n", "merged_vocab", "=", "merge_vocabs", "(", "merge_list", ",", "vocab_size", "=", "opt", ".", "src_vocab_size", ")", "\n", "for", "merge_name_it", "in", "merge_name_list", ":", "\n", "            ", "fields", "[", "merge_name_it", "]", ".", "vocab", "=", "merged_vocab", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.__getstate__": [[85, 87], ["dict", "dict"], "function", ["None"], ["js", "[", "'query'", "]", "[", "'conds'", "]", "=", "[", "x", "[", "1", "]", "for", "x", "in", "cond_list", "]", "\n", "", "", "return", "js_list", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.__setstate__": [[89, 92], ["IO..__dict__.update", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.update"], ["", "class", "TableDataset", "(", "torchtext", ".", "data", ".", "Dataset", ")", ":", "\n", "    ", "\"\"\"Defines a dataset for machine translation.\"\"\"", "\n", "\n", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.merge_vocabs": [[98, 115], ["collections.Counter", "torchtext.vocab.Vocab", "torchtext.vocab.Vocab", "list"], "function", ["None"], ["        ", "\"\"\"\n        Create a TranslationDataset given paths and fields.\n\n        anno: location of annotated data / js_list\n        filter_ex: False - keep all the examples for evaluation (should not have filtered examples); True - filter examples with unmatched spans;\n        \"\"\"", "\n", "if", "isinstance", "(", "anno", ",", "string_types", ")", ":", "\n", "            ", "js_list", "=", "read_anno_json", "(", "anno", ")", "\n", "", "else", ":", "\n", "            ", "js_list", "=", "anno", "\n", "\n", "", "src_data", "=", "self", ".", "_read_annotated_file", "(", "\n", "opt", ",", "js_list", ",", "'question'", ",", "filter_ex", ")", "\n", "src_examples", "=", "self", ".", "_construct_examples", "(", "src_data", ",", "'src'", ")", "\n", "\n", "ent_data", "=", "self", ".", "_read_annotated_file", "(", "opt", ",", "js_list", ",", "'ent'", ",", "filter_ex", ")", "\n", "ent_examples", "=", "self", ".", "_construct_examples", "(", "ent_data", ",", "'ent'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.join_dicts": [[117, 123], ["dict", "itertools.chain", "d.items"], "function", ["None"], ["agg_examples", "=", "self", ".", "_construct_examples", "(", "agg_data", ",", "'agg'", ")", "\n", "\n", "sel_data", "=", "self", ".", "_read_annotated_file", "(", "opt", ",", "js_list", ",", "'sel'", ",", "filter_ex", ")", "\n", "sel_examples", "=", "self", ".", "_construct_examples", "(", "sel_data", ",", "'sel'", ")", "\n", "\n", "tbl_data", "=", "self", ".", "_read_annotated_file", "(", "opt", ",", "js_list", ",", "'tbl'", ",", "filter_ex", ")", "\n", "tbl_examples", "=", "self", ".", "_construct_examples", "(", "tbl_data", ",", "'tbl'", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json": [[148, 154], ["codecs.open", "json.loads", "IO._preprocess_json"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO._preprocess_json"], ["def", "_map_to_sublist_index", "(", "d_list", ",", "idx", ")", ":", "\n", "            ", "return", "[", "(", "[", "it", "[", "idx", "]", "for", "it", "in", "d", "]", "if", "(", "d", "is", "not", "None", ")", "else", "None", ")", "for", "d", "in", "d_list", "]", "\n", "", "span_data", "=", "list", "(", "self", ".", "_read_annotated_file", "(", "\n", "opt", ",", "js_list", ",", "'cond_span'", ",", "filter_ex", ")", ")", "\n", "span_l_examples", "=", "self", ".", "_construct_examples", "(", "\n", "_map_to_sublist_index", "(", "span_data", ",", "0", ")", ",", "'cond_span_l'", ")", "\n", "span_r_examples", "=", "self", ".", "_construct_examples", "(", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.Beam.__init__": [[13, 46], ["Beam.Beam.tt.FloatTensor().zero_", "Beam.Beam.tt.LongTensor().fill_", "Beam.Beam.tt.FloatTensor", "Beam.Beam.tt.LongTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "n_best", "=", "1", ",", "cuda", "=", "False", ",", "vocab", "=", "None", ",", "\n", "global_scorer", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "self", ".", "allScores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prevKs", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "nextYs", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", "\n", ".", "fill_", "(", "vocab", ".", "stoi", "[", "table", ".", "IO", ".", "PAD_WORD", "]", ")", "]", "\n", "self", ".", "nextYs", "[", "0", "]", "[", "0", "]", "=", "vocab", ".", "stoi", "[", "table", ".", "IO", ".", "BOS_WORD", "]", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "# Has EOS topped the beam yet.", "\n", "self", ".", "_eos", "=", "self", ".", "vocab", ".", "stoi", "[", "table", ".", "IO", ".", "EOS_WORD", "]", "\n", "self", ".", "eosTop", "=", "False", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n", "# Time and k pair for finished.", "\n", "self", ".", "finished", "=", "[", "]", "\n", "self", ".", "n_best", "=", "n_best", "\n", "\n", "# Information for global scoring.", "\n", "self", ".", "globalScorer", "=", "global_scorer", "\n", "self", ".", "globalState", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.Beam.getCurrentState": [[47, 50], ["None"], "methods", ["None"], ["", "def", "getCurrentState", "(", "self", ")", ":", "\n", "        ", "\"Get the outputs for the current timestep.\"", "\n", "return", "self", ".", "nextYs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.Beam.getCurrentOrigin": [[51, 54], ["None"], "methods", ["None"], ["", "def", "getCurrentOrigin", "(", "self", ")", ":", "\n", "        ", "\"Get the backpointers for the current timestep.\"", "\n", "return", "self", ".", "prevKs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.Beam.advance": [[55, 107], ["wordLk.size", "beamLk.view", "beamLk.view.topk", "Beam.Beam.allScores.append", "Beam.Beam.prevKs.append", "Beam.Beam.nextYs.append", "Beam.Beam.attn.append", "range", "len", "range", "attnOut.index_select", "Beam.Beam.globalScorer.updateGlobalState", "Beam.Beam.nextYs[].size", "Beam.Beam.scores.unsqueeze().expand_as", "Beam.Beam.nextYs[].size", "Beam.Beam.finished.append", "Beam.Beam.globalScorer.score", "Beam.Beam.scores.unsqueeze", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.topk", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.GNMTGlobalScorer.updateGlobalState", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.score"], ["", "def", "advance", "(", "self", ",", "wordLk", ",", "attnOut", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `wordLk` and attention\n        `attnOut`: Compute and update the beam search.\n\n        Parameters:\n\n        * `wordLk`- probs of advancing from the last step (K x words)\n        * `attnOut`- attention at the last step\n\n        Returns: True if beam search is complete.\n        \"\"\"", "\n", "numWords", "=", "wordLk", ".", "size", "(", "1", ")", "\n", "\n", "# Sum the previous scores.", "\n", "if", "len", "(", "self", ".", "prevKs", ")", ">", "0", ":", "\n", "            ", "beamLk", "=", "wordLk", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "wordLk", ")", "\n", "\n", "# Don't let EOS have children.", "\n", "for", "i", "in", "range", "(", "self", ".", "nextYs", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "if", "self", ".", "nextYs", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                    ", "beamLk", "[", "i", "]", "=", "-", "1e20", "\n", "", "", "", "else", ":", "\n", "            ", "beamLk", "=", "wordLk", "[", "0", "]", "\n", "", "flatBeamLk", "=", "beamLk", ".", "view", "(", "-", "1", ")", "\n", "bestScores", ",", "bestScoresId", "=", "flatBeamLk", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "True", ",", "True", ")", "\n", "\n", "self", ".", "allScores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "bestScores", "\n", "\n", "# bestScoresId is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prevK", "=", "bestScoresId", "/", "numWords", "\n", "self", ".", "prevKs", ".", "append", "(", "prevK", ")", "\n", "self", ".", "nextYs", ".", "append", "(", "(", "bestScoresId", "-", "prevK", "*", "numWords", ")", ")", "\n", "self", ".", "attn", ".", "append", "(", "attnOut", ".", "index_select", "(", "0", ",", "prevK", ")", ")", "\n", "\n", "if", "self", ".", "globalScorer", "is", "not", "None", ":", "\n", "            ", "self", ".", "globalScorer", ".", "updateGlobalState", "(", "self", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nextYs", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "self", ".", "nextYs", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                ", "s", "=", "self", ".", "scores", "[", "i", "]", "\n", "if", "self", ".", "globalScorer", "is", "not", "None", ":", "\n", "                    ", "globalScores", "=", "self", ".", "globalScorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "globalScores", "[", "i", "]", "\n", "", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "nextYs", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS and no global score.", "\n", "", "", "if", "self", ".", "nextYs", "[", "-", "1", "]", "[", "0", "]", "==", "self", ".", "vocab", ".", "stoi", "[", "table", ".", "IO", ".", "EOS_WORD", "]", ":", "\n", "# self.allScores.append(self.scores)", "\n", "            ", "self", ".", "eosTop", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.Beam.done": [[108, 110], ["len"], "methods", ["None"], ["", "", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eosTop", "and", "len", "(", "self", ".", "finished", ")", ">=", "self", ".", "n_best", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.Beam.sortFinished": [[111, 126], ["Beam.Beam.finished.sort", "len", "Beam.Beam.finished.append", "Beam.Beam.globalScorer.score", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.score"], ["", "def", "sortFinished", "(", "self", ",", "minimum", "=", "None", ")", ":", "\n", "        ", "if", "minimum", "is", "not", "None", ":", "\n", "            ", "i", "=", "0", "\n", "# Add from beam until we have minimum outputs.", "\n", "while", "len", "(", "self", ".", "finished", ")", "<", "minimum", ":", "\n", "                ", "s", "=", "self", ".", "scores", "[", "i", "]", "\n", "if", "self", ".", "globalScorer", "is", "not", "None", ":", "\n", "                    ", "globalScores", "=", "self", ".", "globalScorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "globalScores", "[", "i", "]", "\n", "", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "nextYs", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "", "", "self", ".", "finished", ".", "sort", "(", "key", "=", "lambda", "a", ":", "-", "a", "[", "0", "]", ")", "\n", "scores", "=", "[", "sc", "for", "sc", ",", "_", ",", "_", "in", "self", ".", "finished", "]", "\n", "ks", "=", "[", "(", "t", ",", "k", ")", "for", "_", ",", "t", ",", "k", "in", "self", ".", "finished", "]", "\n", "return", "scores", ",", "ks", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.Beam.getHyp": [[127, 137], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["", "def", "getHyp", "(", "self", ",", "timestep", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        Walk back to construct the full hypothesis.\n        \"\"\"", "\n", "hyp", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prevKs", "[", ":", "timestep", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "nextYs", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "attn", ".", "append", "(", "self", ".", "attn", "[", "j", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prevKs", "[", "j", "]", "[", "k", "]", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.GNMTGlobalScorer.__init__": [[143, 146], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha", ",", "beta", ")", ":", "\n", "        ", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.GNMTGlobalScorer.score": [[147, 154], ["torch.min().log().sum", "torch.min().log", "len", "torch.min", "cov.clone().fill_", "cov.clone"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.log"], ["", "def", "score", "(", "self", ",", "beam", ",", "logprobs", ")", ":", "\n", "        ", "\"Additional term add to log probability\"", "\n", "cov", "=", "beam", ".", "globalState", "[", "\"coverage\"", "]", "\n", "pen", "=", "self", ".", "beta", "*", "torch", ".", "min", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "log", "(", ")", ".", "sum", "(", "1", ")", "\n", "l_term", "=", "(", "(", "(", "5", "+", "len", "(", "beam", ".", "nextYs", ")", ")", "**", "self", ".", "alpha", ")", "/", "\n", "(", "(", "5", "+", "1", ")", "**", "self", ".", "alpha", ")", ")", "\n", "return", "(", "logprobs", "/", "l_term", ")", "+", "pen", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Beam.GNMTGlobalScorer.updateGlobalState": [[155, 162], ["len", "beam.globalState[].index_select().add", "beam.globalState[].index_select"], "methods", ["None"], ["", "def", "updateGlobalState", "(", "self", ",", "beam", ")", ":", "\n", "        ", "\"Keeps the coverage vector as sum of attens\"", "\n", "if", "len", "(", "beam", ".", "prevKs", ")", "==", "1", ":", "\n", "            ", "beam", ".", "globalState", "[", "\"coverage\"", "]", "=", "beam", ".", "attn", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "beam", ".", "globalState", "[", "\"coverage\"", "]", "=", "beam", ".", "globalState", "[", "\"coverage\"", "]", ".", "index_select", "(", "0", ",", "beam", ".", "prevKs", "[", "-", "1", "]", ")", ".", "add", "(", "beam", ".", "attn", "[", "-", "1", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_layout_encoder": [[59, 61], ["table.Models.RNNEncoder"], "function", ["None"], ["\n", "\n", "", "def", "make_cond_decoder", "(", "opt", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_q_co_attention": [[63, 67], ["table.Models.QCoAttention"], "function", ["None"], ["return", "CondDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "dec_layers", ",", "input_size", ",", "opt", ".", "rnn_size", ",", "opt", ".", "global_attention", ",", "opt", ".", "attn_hidden", ",", "opt", ".", "dropout", ",", "opt", ".", "lock_dropout", ",", "opt", ".", "weight_dropout", ")", "\n", "\n", "\n", "", "def", "make_co_attention", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "co_attention", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_lay_co_attention": [[69, 73], ["table.Models.LayCoAttention"], "function", ["None"], ["", "return", "None", "\n", "\n", "\n", "", "def", "make_base_model", "(", "model_opt", ",", "fields", ",", "checkpoint", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_decoder": [[75, 92], ["torch.Sequential", "table.Models.SeqDecoderParentFeedInput", "table.Models.SeqDecoder", "torch.Dropout", "torch.Linear", "torch.LogSoftmax", "len"], "function", ["None"], ["\n", "\n", "# embedding", "\n", "w_embeddings", "=", "make_word_embeddings", "(", "model_opt", ",", "fields", "[", "\"src\"", "]", ".", "vocab", ",", "fields", ")", "\n", "\n", "if", "model_opt", ".", "ent_vec_size", ">", "0", ":", "\n", "        ", "ent_embedding", "=", "make_embeddings", "(", "\n", "fields", "[", "\"ent\"", "]", ".", "vocab", ",", "model_opt", ".", "ent_vec_size", ")", "\n", "", "else", ":", "\n", "        ", "ent_embedding", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.count_token_prune_accuracy": [[72, 86], ["scores.gt().long", "target.long.long", "torch.ByteTensor().cuda().unsqueeze().expand_as", "torch.ByteTensor().cuda().unsqueeze().expand_as", "scores.gt().long.eq().masked_fill_().prod", "pred.eq().masked_select.numel", "torch.ByteTensor().cuda().unsqueeze().expand_as.ne", "scores.gt().long.eq().masked_select", "mask.ne.sum", "scores.gt", "torch.ByteTensor().cuda().unsqueeze", "torch.ByteTensor().cuda().unsqueeze", "scores.gt().long.eq().masked_fill_", "scores.gt().long.eq", "torch.ByteTensor().cuda", "torch.ByteTensor().cuda", "scores.gt().long.eq", "torch.ByteTensor", "torch.ByteTensor"], "function", ["None"], ["for", "metric_name", "in", "metric_name_list", ":", "\n", "        ", "m_list", ".", "append", "(", "r_dict", "[", "metric_name", "]", "[", "0", "]", ")", "\n", "", "agg", "=", "torch", ".", "stack", "(", "m_list", ",", "0", ")", ".", "prod", "(", "0", ",", "keepdim", "=", "False", ")", "\n", "return", "(", "agg", ".", "sum", "(", ")", ",", "agg", ".", "numel", "(", ")", ")", "\n", "\n", "\n", "", "class", "Trainer", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "model", ",", "train_iter", ",", "valid_iter", ",", "\n", "train_loss", ",", "valid_loss", ",", "optim", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer._debug_batch_content": [[96, 105], ["ts_batch.size", "ts_batch.size", "range", "range", "print", "tk_list.append"], "function", ["None"], ["self", ".", "optim", "=", "optim", "\n", "\n", "# Set model in training mode.", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "criterion", ")", ":", "\n", "# 1. F-prop.", "\n", "        ", "q", ",", "q_len", "=", "batch", ".", "src", "\n", "tbl", ",", "tbl_len", "=", "batch", ".", "tbl", "\n", "cond_op", ",", "cond_op_len", "=", "batch", ".", "cond_op", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.topk": [[40, 42], ["scores.topk", "scores.dim"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.topk"], ["", "def", "add_pad", "(", "b_list", ",", "pad_index", ",", "return_tensor", "=", "True", ")", ":", "\n", "    ", "max_len", "=", "max", "(", "(", "len", "(", "b", ")", "for", "b", "in", "b_list", ")", ")", "\n", "r_list", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder.__init__": [[94, 117], ["torch.Module.__init__", "Models._build_rnn", "table.modules.GlobalAttention", "table.modules.LockedDropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models._build_rnn"], ["if", "self", ".", "merge_type", "==", "'mlp'", ":", "\n", "            ", "self", ".", "merge", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "self", ".", "hidden_size", ",", "self", ".", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ")", ":", "\n", "        ", "\"\"\"\n        Encode table headers.\n            :param tbl: header token list\n            :param tbl_len: length of token list (num_table_header, batch)\n            :param tbl_split: table header boundary list\n        \"\"\"", "\n", "tbl_context", "=", "encode_unsorted_batch", "(", "self", ".", "encoder", ",", "tbl", ",", "tbl_len", ")", "\n", "# --> (num_table_header, batch, hidden_size * num_directions)", "\n", "if", "self", ".", "split_type", "==", "'outcell'", ":", "\n", "            ", "batch_index", "=", "torch", ".", "LongTensor", "(", "range", "(", "tbl_split", ".", "data", ".", "size", "(", "1", ")", ")", ")", ".", "unsqueeze_", "(", "\n", "0", ")", ".", "cuda", "(", ")", ".", "expand_as", "(", "tbl_split", ".", "data", ")", "\n", "enc_split", "=", "tbl_context", "[", "tbl_split", ".", "data", ",", "batch_index", ",", ":", "]", "\n", "enc_left", ",", "enc_right", "=", "enc_split", "[", ":", "-", "1", "]", ",", "enc_split", "[", "1", ":", "]", "\n", "", "elif", "self", ".", "split_type", "==", "'incell'", ":", "\n", "            ", "batch_index", "=", "torch", ".", "LongTensor", "(", "range", "(", "tbl_split", ".", "data", ".", "size", "(", "1", ")", ")", ")", ".", "unsqueeze_", "(", "\n", "0", ")", ".", "cuda", "(", ")", ".", "expand", "(", "tbl_split", ".", "data", ".", "size", "(", "0", ")", "-", "1", ",", "tbl_split", ".", "data", ".", "size", "(", "1", ")", ")", "\n", "split_left", "=", "(", "tbl_split", ".", "data", "[", ":", "-", "1", "]", "+", "\n", "1", ")", ".", "clamp", "(", "0", ",", "tbl_context", ".", "size", "(", "0", ")", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder.forward": [[118, 163], ["isinstance", "Models.SeqDecoder._run_forward_pass", "state.update_state", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "Models.SeqDecoder.word_dropout", "table.modules.embed_regularize.embedded_dropout", "Models.SeqDecoder.embeddings"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoderParentFeedInput._run_forward_pass", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.RNNDecoderState.update_state", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.embed_regularize.embedded_dropout"], ["enc_left", "=", "tbl_context", "[", "split_left", ",", "batch_index", ",", ":", "]", "\n", "split_right", "=", "(", "tbl_split", ".", "data", "[", "1", ":", "]", "-", "\n", "1", ")", ".", "clamp", "(", "0", ",", "tbl_context", ".", "size", "(", "0", ")", "-", "1", ")", "\n", "enc_right", "=", "tbl_context", "[", "split_right", ",", "batch_index", ",", ":", "]", "\n", "\n", "", "if", "self", ".", "merge_type", "==", "'sub'", ":", "\n", "            ", "return", "(", "enc_right", "-", "enc_left", ")", "\n", "", "elif", "self", ".", "merge_type", "==", "'cat'", ":", "\n", "# take half vector for each direction", "\n", "            ", "half_hidden_size", "=", "self", ".", "hidden_size", "//", "2", "\n", "return", "torch", ".", "cat", "(", "[", "enc_right", "[", ":", ",", ":", ",", ":", "half_hidden_size", "]", ",", "enc_left", "[", ":", ",", ":", ",", "half_hidden_size", ":", "]", "]", ",", "2", ")", "\n", "", "elif", "self", ".", "merge_type", "==", "'mlp'", ":", "\n", "            ", "return", "self", ".", "merge", "(", "torch", ".", "cat", "(", "[", "enc_right", ",", "enc_left", "]", ",", "2", ")", ")", "\n", "\n", "\n", "", "", "", "class", "MatchScorer", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "input_size", ",", "score_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "MatchScorer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "score_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "input_size", ",", "score_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "score_size", ",", "1", ")", ")", "\n", "self", ".", "log_sm", "=", "nn", ".", "LogSoftmax", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "q_enc", ",", "tbl_enc", ",", "tbl_mask", ")", ":", "\n", "        ", "\"\"\"\n        Match and return table column score.\n            :param q_enc: question encoding vectors (batch, rnn_size)\n            :param tbl_enc: header encoding vectors (num_table_header, batch, rnn_size)\n            :param tbl_num: length of token list\n        \"\"\"", "\n", "q_enc_expand", "=", "q_enc", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "\n", "tbl_enc", ".", "size", "(", "0", ")", ",", "tbl_enc", ".", "size", "(", "1", ")", ",", "q_enc", ".", "size", "(", "1", ")", ")", "\n", "# (batch, num_table_header, input_size)", "\n", "feat", "=", "torch", ".", "cat", "(", "(", "q_enc_expand", ",", "tbl_enc", ")", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# (batch, num_table_header)", "\n", "score", "=", "self", ".", "score_layer", "(", "feat", ")", ".", "squeeze", "(", "2", ")", "\n", "# mask scores", "\n", "score_mask", "=", "score", ".", "masked_fill", "(", "tbl_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# normalize", "\n", "return", "self", ".", "log_sm", "(", "score_mask", ")", "\n", "\n", "\n", "", "", "class", "CondMatchScorer", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "sel_match", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder._fix_enc_hidden": [[164, 172], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["None"], ["        ", "super", "(", "CondMatchScorer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sel_match", "=", "sel_match", "\n", "\n", "", "def", "forward", "(", "self", ",", "cond_context_filter", ",", "tbl_enc", ",", "tbl_mask", ",", "emb_span_l", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder.init_decoder_state": [[173, 175], ["Models.RNNDecoderState", "tuple", "Models.SeqDecoder._fix_enc_hidden", "range", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder._fix_enc_hidden"], ["\n", "# -> (num_cond, batch, rnn_size)", "\n", "if", "emb_span_l", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder._run_forward_pass": [[176, 215], ["Models.SeqDecoder.rnn", "Models.SeqDecoder.attn", "Models.SeqDecoder.word_dropout", "rnn_output.transpose().contiguous", "context.transpose", "rnn_output.transpose"], "methods", ["None"], ["# -> (num_cond, batch, 2*rnn_size)", "\n", "            ", "cond_context_filter", "=", "torch", ".", "cat", "(", "\n", "(", "cond_context_filter", ",", "emb_span_l", ")", ",", "2", ")", "\n", "", "r_list", "=", "[", "]", "\n", "for", "cond_context_one", "in", "cond_context_filter", ":", "\n", "# -> (batch, num_table_header)", "\n", "            ", "r_list", ".", "append", "(", "self", ".", "sel_match", "(", "cond_context_one", ",", "tbl_enc", ",", "tbl_mask", ")", ")", "\n", "# (num_cond, batch, num_table_header)", "\n", "", "return", "torch", ".", "stack", "(", "r_list", ",", "0", ")", "\n", "\n", "\n", "", "", "class", "CondDecoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "input_size", ",", "hidden_size", ",", "attn_type", ",", "attn_hidden", ",", "dropout", ",", "lock_dropout", ",", "weight_dropout", ")", ":", "\n", "        ", "super", "(", "CondDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'rnn'", "\n", "self", ".", "bidirectional_encoder", "=", "bidirectional_encoder", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "if", "lock_dropout", ":", "\n", "            ", "self", ".", "word_dropout", "=", "table", ".", "modules", ".", "LockedDropout", "(", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Build the RNN.", "\n", "", "self", ".", "rnn", "=", "_build_rnn", "(", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", ",", "num_layers", ",", "dropout", ",", "weight_dropout", ")", "\n", "\n", "# Set up the standard attention.", "\n", "self", ".", "attn", "=", "table", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "True", ",", "attn_type", "=", "attn_type", ",", "attn_hidden", "=", "attn_hidden", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "emb", ",", "context", ",", "state", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.QCoAttention.forward": [[383, 403], ["Models.QCoAttention.attn.applyMaskBySeqBatch", "Models.QCoAttention.attn", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Models.QCoAttention.rnn", "Models.QCoAttention.linear_context", "q_all.transpose().contiguous", "Models.QCoAttention.transpose", "isinstance", "lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "q_all.transpose", "lengths.view().tolist.view().tolist.view"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMaskBySeqBatch"], ["\n", "outputs", "=", "unpack", "(", "outputs", ")", "[", "0", "]", "\n", "\n", "return", "hidden_t", ",", "outputs", "\n", "\n", "\n", "", "", "class", "ParserModel", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "q_encoder", ",", "tbl_encoder", ",", "co_attention", ",", "agg_classifier", ",", "sel_match", ",", "lay_classifier", ",", "cond_embedding", ",", "lay_encoder", ",", "cond_decoder", ",", "cond_col_match", ",", "cond_span_l_match", ",", "cond_span_r_match", ",", "model_opt", ",", "pad_word_index", ")", ":", "\n", "        ", "super", "(", "ParserModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "q_encoder", "=", "q_encoder", "\n", "self", ".", "tbl_encoder", "=", "tbl_encoder", "\n", "self", ".", "agg_classifier", "=", "agg_classifier", "\n", "self", ".", "sel_match", "=", "sel_match", "\n", "self", ".", "lay_classifier", "=", "lay_classifier", "\n", "self", ".", "cond_embedding", "=", "cond_embedding", "\n", "self", ".", "lay_encoder", "=", "lay_encoder", "\n", "self", ".", "cond_decoder", "=", "cond_decoder", "\n", "self", ".", "opt", "=", "model_opt", "\n", "self", ".", "span_merge", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "model_opt", ".", "rnn_size", ",", "model_opt", ".", "rnn_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.LayCoAttention.run_rnn_unsorted_batch": [[406, 420], ["table.Utils.sort_for_pack", "emb.index_select", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Models.LayCoAttention.rnn", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "tbl_context.index_select.index_select.index_select", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.sort_for_pack"], ["self", ".", "cond_span_r_match", "=", "cond_span_r_match", "\n", "self", ".", "pad_word_index", "=", "pad_word_index", "\n", "self", ".", "co_attention", "=", "co_attention", "\n", "\n", "", "def", "enc", "(", "self", ",", "q", ",", "q_len", ",", "ent", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ",", "tbl_mask", ")", ":", "\n", "        ", "q_enc", ",", "q_all", "=", "self", ".", "q_encoder", "(", "q", ",", "lengths", "=", "q_len", ",", "ent", "=", "ent", ")", "\n", "tbl_enc", "=", "self", ".", "tbl_encoder", "(", "tbl", ",", "tbl_len", ",", "tbl_split", ")", "\n", "if", "self", ".", "co_attention", "is", "not", "None", ":", "\n", "            ", "q_enc", ",", "q_all", "=", "self", ".", "co_attention", "(", "q_all", ",", "q_len", ",", "tbl_enc", ",", "tbl_mask", ")", "\n", "# (num_layers * num_directions, batch, hidden_size)", "\n", "", "q_ht", ",", "q_ct", "=", "q_enc", "\n", "batch_size", "=", "q_ht", ".", "size", "(", "1", ")", "\n", "q_ht", "=", "q_ht", "[", "-", "1", "]", "if", "not", "self", ".", "opt", ".", "brnn", "else", "q_ht", "[", "-", "2", ":", "]", ".", "transpose", "(", "\n", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.LayCoAttention.forward": [[421, 435], ["Models.LayCoAttention.attn.applyMaskBySeqBatch", "Models.LayCoAttention.attn", "Models.LayCoAttention.run_rnn_unsorted_batch", "Models.LayCoAttention.linear_context", "lay_all.transpose().contiguous", "Models.LayCoAttention.transpose", "lay_all.transpose"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMaskBySeqBatch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.LayCoAttention.run_rnn_unsorted_batch"], ["return", "q_enc", ",", "q_all", ",", "tbl_enc", ",", "q_ht", ",", "batch_size", "\n", "\n", "", "def", "select3", "(", "self", ",", "cond_context", ",", "start_index", ")", ":", "\n", "        ", "return", "cond_context", "[", "start_index", ":", "cond_context", ".", "size", "(", "\n", "0", ")", ":", "3", "]", "\n", "\n", "", "def", "forward", "(", "self", ",", "q", ",", "q_len", ",", "ent", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ",", "tbl_mask", ",", "cond_op", ",", "cond_op_len", ",", "cond_col", ",", "cond_span_l", ",", "cond_span_r", ",", "lay", ")", ":", "\n", "# encoding", "\n", "        ", "q_enc", ",", "q_all", ",", "tbl_enc", ",", "q_ht", ",", "batch_size", "=", "self", ".", "enc", "(", "\n", "q", ",", "q_len", ",", "ent", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ",", "tbl_mask", ")", "\n", "\n", "# (1) decoding", "\n", "agg_out", "=", "self", ".", "agg_classifier", "(", "q_ht", ")", "\n", "sel_out", "=", "self", ".", "sel_match", "(", "q_ht", ",", "tbl_enc", ",", "tbl_mask", ")", "\n", "lay_out", "=", "self", ".", "lay_classifier", "(", "q_ht", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CopyGenerator.__init__": [[365, 378], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "len", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["num_directions", ",", "num_layers", ",", "dropout", ",", "weight_dropout", ",", "bidirectional", ")", "\n", "self", ".", "attn", "=", "table", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "False", ",", "attn_type", "=", "attn_type", ",", "attn_hidden", "=", "attn_hidden", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "q_all", ",", "lengths", ",", "tbl_enc", ",", "tbl_mask", ")", ":", "\n", "        ", "self", ".", "attn", ".", "applyMask", "(", "tbl_mask", ".", "data", ".", "unsqueeze", "(", "0", ")", ")", "\n", "# attention", "\n", "emb", ",", "_", "=", "self", ".", "attn", "(", "\n", "q_all", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "# (output_len, batch, d)", "\n", "tbl_enc", ".", "transpose", "(", "0", ",", "1", ")", "# (contxt_len, batch, d)", "\n", ")", "\n", "\n", "# feed to rnn", "\n", "if", "not", "isinstance", "(", "lengths", ",", "list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.CopyGenerator.forward": [[379, 444], ["Models.CopyGenerator.size", "Models.CopyGenerator.size", "Models.CopyGenerator.view", "dec_rnn_output.view.view.view", "concat_c.view.view.view", "attn.view.view.view", "Models.CopyGenerator.size", "attn.view.view.size", "copy_to_ext.size", "table.Utils.aeq", "table.Utils.aeq", "Models.CopyGenerator.dropout", "Models.CopyGenerator.linear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "table.modules.cross_entropy_smooth.onehot().float", "torch.bmm().transpose().contiguous().view", "torch.bmm().transpose().contiguous().view", "torch.bmm().transpose().contiguous().view", "torch.bmm().transpose().contiguous().view", "torch.bmm().transpose().contiguous().view", "torch.bmm().transpose().contiguous().view", "torch.bmm().transpose().contiguous().view", "torch.bmm().transpose().contiguous().view", "torch.bmm().transpose().contiguous().view", "Models.CopyGenerator.forward.safe_log"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq"], ["            ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "", "packed_emb", "=", "pack", "(", "emb", ",", "lengths", ")", "\n", "\n", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "packed_emb", ",", "None", ")", "\n", "\n", "outputs", "=", "unpack", "(", "outputs", ")", "[", "0", "]", "\n", "\n", "return", "hidden_t", ",", "outputs", "\n", "\n", "\n", "", "", "class", "ParserModel", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "q_encoder", ",", "tbl_encoder", ",", "co_attention", ",", "agg_classifier", ",", "sel_match", ",", "lay_classifier", ",", "cond_embedding", ",", "lay_encoder", ",", "cond_decoder", ",", "cond_col_match", ",", "cond_span_l_match", ",", "cond_span_r_match", ",", "model_opt", ",", "pad_word_index", ")", ":", "\n", "        ", "super", "(", "ParserModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "q_encoder", "=", "q_encoder", "\n", "self", ".", "tbl_encoder", "=", "tbl_encoder", "\n", "self", ".", "agg_classifier", "=", "agg_classifier", "\n", "self", ".", "sel_match", "=", "sel_match", "\n", "self", ".", "lay_classifier", "=", "lay_classifier", "\n", "self", ".", "cond_embedding", "=", "cond_embedding", "\n", "self", ".", "lay_encoder", "=", "lay_encoder", "\n", "self", ".", "cond_decoder", "=", "cond_decoder", "\n", "self", ".", "opt", "=", "model_opt", "\n", "self", ".", "span_merge", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "model_opt", ".", "rnn_size", ",", "model_opt", ".", "rnn_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ")", "\n", "self", ".", "cond_col_match", "=", "cond_col_match", "\n", "self", ".", "cond_span_l_match", "=", "cond_span_l_match", "\n", "self", ".", "cond_span_r_match", "=", "cond_span_r_match", "\n", "self", ".", "pad_word_index", "=", "pad_word_index", "\n", "self", ".", "co_attention", "=", "co_attention", "\n", "\n", "", "def", "enc", "(", "self", ",", "q", ",", "q_len", ",", "ent", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ",", "tbl_mask", ")", ":", "\n", "        ", "q_enc", ",", "q_all", "=", "self", ".", "q_encoder", "(", "q", ",", "lengths", "=", "q_len", ",", "ent", "=", "ent", ")", "\n", "tbl_enc", "=", "self", ".", "tbl_encoder", "(", "tbl", ",", "tbl_len", ",", "tbl_split", ")", "\n", "if", "self", ".", "co_attention", "is", "not", "None", ":", "\n", "            ", "q_enc", ",", "q_all", "=", "self", ".", "co_attention", "(", "q_all", ",", "q_len", ",", "tbl_enc", ",", "tbl_mask", ")", "\n", "# (num_layers * num_directions, batch, hidden_size)", "\n", "", "q_ht", ",", "q_ct", "=", "q_enc", "\n", "batch_size", "=", "q_ht", ".", "size", "(", "1", ")", "\n", "q_ht", "=", "q_ht", "[", "-", "1", "]", "if", "not", "self", ".", "opt", ".", "brnn", "else", "q_ht", "[", "-", "2", ":", "]", ".", "transpose", "(", "\n", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "return", "q_enc", ",", "q_all", ",", "tbl_enc", ",", "q_ht", ",", "batch_size", "\n", "\n", "", "def", "select3", "(", "self", ",", "cond_context", ",", "start_index", ")", ":", "\n", "        ", "return", "cond_context", "[", "start_index", ":", "cond_context", ".", "size", "(", "\n", "0", ")", ":", "3", "]", "\n", "\n", "", "def", "forward", "(", "self", ",", "q", ",", "q_len", ",", "ent", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ",", "tbl_mask", ",", "cond_op", ",", "cond_op_len", ",", "cond_col", ",", "cond_span_l", ",", "cond_span_r", ",", "lay", ")", ":", "\n", "# encoding", "\n", "        ", "q_enc", ",", "q_all", ",", "tbl_enc", ",", "q_ht", ",", "batch_size", "=", "self", ".", "enc", "(", "\n", "q", ",", "q_len", ",", "ent", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ",", "tbl_mask", ")", "\n", "\n", "# (1) decoding", "\n", "agg_out", "=", "self", ".", "agg_classifier", "(", "q_ht", ")", "\n", "sel_out", "=", "self", ".", "sel_match", "(", "q_ht", ",", "tbl_enc", ",", "tbl_mask", ")", "\n", "lay_out", "=", "self", ".", "lay_classifier", "(", "q_ht", ")", "\n", "\n", "# (2) decoding", "\n", "# emb_op", "\n", "if", "self", ".", "opt", ".", "layout_encode", "==", "'rnn'", ":", "\n", "            ", "emb_op", "=", "encode_unsorted_batch", "(", "\n", "self", ".", "lay_encoder", ",", "cond_op", ",", "cond_op_len", ".", "clamp", "(", "min", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "emb_op", "=", "self", ".", "cond_embedding", "(", "cond_op", ")", "\n", "# emb_col", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.enc_to_ht": [[456, 462], ["q_ht[].transpose().contiguous().view().unsqueeze", "q_ht[].transpose().contiguous().view", "q_ht[].transpose().contiguous", "q_ht[].transpose"], "methods", ["None"], ["# cond decoder", "\n", "self", ".", "cond_decoder", ".", "attn", ".", "applyMaskBySeqBatch", "(", "q", ")", "\n", "q_state", "=", "self", ".", "cond_decoder", ".", "init_decoder_state", "(", "q_all", ",", "q_enc", ")", "\n", "cond_context", ",", "_", ",", "_", "=", "self", ".", "cond_decoder", "(", "emb", ",", "q_all", ",", "q_state", ")", "\n", "# cond col", "\n", "cond_context_0", "=", "self", ".", "select3", "(", "cond_context", ",", "0", ")", "\n", "cond_col_out", "=", "self", ".", "cond_col_match", "(", "cond_context_0", ",", "tbl_enc", ",", "tbl_mask", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.run_decoder": [[463, 486], ["q.size", "decoder.attn.applyMaskBySeqBatch", "decoder.init_decoder_state", "decoder", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.view", "torch.cat.view", "torch.cat.view", "classifier", "dec_out.view.view.view", "Models.ParserModel.enc_to_ht", "decoder.init_parent_all", "Models.ParserModel.enc_to_ht", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "parent_index.size", "parent_index.size", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMaskBySeqBatch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder.init_decoder_state", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.enc_to_ht", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoderParentFeedInput.init_parent_all", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.enc_to_ht"], ["# cond span", "\n", "q_mask", "=", "Variable", "(", "q", ".", "data", ".", "eq", "(", "self", ".", "pad_word_index", ")", ".", "transpose", "(", "\n", "0", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "cond_context_1", "=", "self", ".", "select3", "(", "cond_context", ",", "1", ")", "\n", "cond_span_l_out", "=", "self", ".", "cond_span_l_match", "(", "\n", "cond_context_1", ",", "q_all", ",", "q_mask", ")", "\n", "cond_span_r_out", "=", "self", ".", "cond_span_r_match", "(", "\n", "cond_context_1", ",", "q_all", ",", "q_mask", ",", "emb_span_l", ")", "\n", "\n", "return", "agg_out", ",", "sel_out", ",", "lay_out", ",", "cond_col_out", ",", "cond_span_l_out", ",", "cond_span_r_out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.ParserModel.run_copy_decoder": [[484, 493], ["q.size", "decoder.attn.applyMaskBySeqBatch", "decoder.init_decoder_state", "decoder", "classifier"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMaskBySeqBatch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder.init_decoder_state"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.run_lay_decoder": [[180, 216], ["q.size", "decoder.attn.applyMaskBySeqBatch", "decoder.init_decoder_state", "torch.LongTensor().fill_().cuda", "torch.LongTensor().fill_().cuda", "torch.LongTensor().fill_().cuda", "torch.LongTensor().fill_().cuda", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "Translator.Translator._init_parent_list", "Translator.v_eval", "decoder", "Translator.Translator.view", "classifier", "dec_out.data.view.data.view.data.view", "table.Utils.argmax", "table.Utils.argmax", "table.Utils.argmax", "table.Utils.argmax", "table.Utils.argmax", "Translator.cpu_vector", "dec_list.append", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "Translator.Translator._cat_parent_feed_input", "Translator.Translator._cat_parent_feed_output", "dec_out_part.masked_fill_", "Translator.Translator._update_parent_list", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "float", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMaskBySeqBatch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder.init_decoder_state", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._init_parent_list", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.v_eval", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.cpu_vector", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._cat_parent_feed_input", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._cat_parent_feed_output", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._update_parent_list"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.run_tgt_decoder": [[217, 262], ["q.size", "decoder.attn.applyMaskBySeqBatch", "decoder.init_decoder_state", "torch.LongTensor().fill_().cuda", "torch.LongTensor().fill_().cuda", "torch.LongTensor().fill_().cuda", "torch.LongTensor().fill_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "Translator.Translator._init_parent_list", "min", "lay_index_seq[].unsqueeze", "embeddings", "Translator.v_eval", "decoder", "Translator.Translator.view", "classifier", "dec_out.view.view.view", "table.Utils.argmax", "table.Utils.argmax", "table.Utils.argmax", "table.Utils.argmax", "table.Utils.argmax", "range", "table.Utils.argmax.masked_fill_", "table.Utils.argmax.masked_fill_", "table.Utils.argmax.masked_fill_", "table.Utils.argmax.masked_fill_", "table.Utils.argmax.masked_fill_", "Translator.cpu_vector", "dec_list.append", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "lay_index_seq.size", "Translator.v_eval", "tgt_mask_seq[].unsqueeze().unsqueeze().expand_as", "embeddings.mul", "lay_select.mul", "Translator.Translator._cat_parent_feed_input", "Translator.Translator._cat_parent_feed_output", "rig_mask.append", "torch.ByteTensor().unsqueeze_().cuda", "torch.ByteTensor().unsqueeze_().cuda", "torch.ByteTensor().unsqueeze_().cuda", "torch.ByteTensor().unsqueeze_().cuda", "Translator.Translator._update_parent_list", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "tgt_mask_seq[].unsqueeze().unsqueeze", "len", "torch.ByteTensor().unsqueeze_", "torch.ByteTensor().unsqueeze_", "torch.ByteTensor().unsqueeze_", "torch.ByteTensor().unsqueeze_", "range", "tgt_mask_seq[].unsqueeze", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMaskBySeqBatch", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoder.init_decoder_state", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._init_parent_list", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.v_eval", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.argmax", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.cpu_vector", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.v_eval", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._cat_parent_feed_input", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._cat_parent_feed_output", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._update_parent_list"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.recover_layout_token": [[26, 34], ["range", "r_list.append"], "function", ["None"], ["self", ".", "fields", "=", "table", ".", "IO", ".", "TableDataset", ".", "load_fields", "(", "checkpoint", "[", "'vocab'", "]", ")", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "model_opt", ".", "pre_word_vecs", "=", "opt", ".", "pre_word_vecs", "\n", "for", "arg", "in", "dummy_opt", ":", "\n", "            ", "if", "arg", "not", "in", "model_opt", ":", "\n", "                ", "model_opt", ".", "__dict__", "[", "arg", "]", "=", "dummy_opt", "[", "arg", "]", "\n", "\n", "", "", "self", ".", "model", "=", "table", ".", "ModelConstructor", ".", "make_base_model", "(", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.recover_target_token": [[49, 59], ["range", "min", "len", "len", "r_list.append", "r_list.append", "r_list.append"], "function", ["None"], ["sel_pred", "=", "cpu_vector", "(", "argmax", "(", "self", ".", "model", ".", "sel_match", "(", "\n", "q_ht", ",", "tbl_enc", ",", "tbl_mask", ")", ".", "data", ")", ")", "\n", "lay_pred", "=", "argmax", "(", "self", ".", "model", ".", "lay_classifier", "(", "q_ht", ")", ".", "data", ")", "\n", "# get layout op tokens", "\n", "op_batch_list", "=", "[", "]", "\n", "op_idx_batch_list", "=", "[", "]", "\n", "if", "self", ".", "opt", ".", "gold_layout", ":", "\n", "            ", "lay_pred", "=", "batch", ".", "lay", ".", "data", "\n", "cond_op", ",", "cond_op_len", "=", "batch", ".", "cond_op", "\n", "cond_op_len_list", "=", "cond_op_len", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "for", "i", ",", "len_it", "in", "enumerate", "(", "cond_op_len_list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.get_decode_batch_length": [[61, 75], ["range", "torch.LongTensor", "torch.LongTensor", "range", "len", "r_list.append", "r_list.append"], "function", ["None"], ["                    ", "op_idx_batch_list", ".", "append", "(", "[", "]", ")", "\n", "op_batch_list", ".", "append", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "                    ", "idx_list", "=", "cond_op", ".", "data", "[", "0", ":", "len_it", ",", "i", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "op_idx_batch_list", ".", "append", "(", "[", "int", "(", "self", ".", "fields", "[", "'cond_op'", "]", ".", "vocab", ".", "itos", "[", "it", "]", ")", "for", "it", "in", "idx_list", "]", ")", "\n", "op_batch_list", ".", "append", "(", "idx_list", ")", "\n", "", "", "", "else", ":", "\n", "            ", "lay_batch_list", "=", "lay_pred", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "for", "lay_it", "in", "lay_batch_list", ":", "\n", "                ", "tk_list", "=", "self", ".", "fields", "[", "'lay'", "]", ".", "vocab", ".", "itos", "[", "lay_it", "]", ".", "split", "(", "' '", ")", "\n", "if", "(", "len", "(", "tk_list", ")", "==", "0", ")", "or", "(", "tk_list", "[", "0", "]", "==", "''", ")", ":", "\n", "                    ", "op_idx_batch_list", ".", "append", "(", "[", "]", ")", "\n", "op_batch_list", ".", "append", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "                    ", "op_idx_batch_list", ".", "append", "(", "[", "int", "(", "op_str", ")", "for", "op_str", "in", "tk_list", "]", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.expand_layout_with_skip": [[78, 105], ["table.Utils.add_pad().float().t", "table.Utils.add_pad().t", "lay_skip_list.append", "tgt_mask_list.append", "lay_index_list.append", "table.IO.get_tgt_mask", "table.IO.get_tgt_mask", "table.IO.get_tgt_mask", "table.IO.get_tgt_mask", "table.IO.get_tgt_mask", "table.IO.get_lay_index", "table.IO.get_lay_index", "table.IO.get_lay_index", "table.IO.get_lay_index", "table.IO.get_lay_index", "table.Utils.add_pad().float", "table.Utils.add_pad", "tk_lay.startswith", "lay_skip.append", "len", "lay_skip.append", "int", "lay_skip.extend", "lay_skip.append", "table.Utils.add_pad", "range"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_tgt_mask", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_tgt_mask", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_tgt_mask", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_tgt_mask", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_tgt_mask", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_lay_index", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_lay_index", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_lay_index", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_lay_index", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_lay_index", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.add_pad", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.add_pad"], ["# -> (num_cond, batch)", "\n", "", "", "cond_op", "=", "v_eval", "(", "add_pad", "(", "\n", "op_batch_list", ",", "self", ".", "fields", "[", "'cond_op'", "]", ".", "vocab", ".", "stoi", "[", "table", ".", "IO", ".", "PAD_WORD", "]", ")", ".", "t", "(", ")", ")", "\n", "cond_op_len", "=", "torch", ".", "LongTensor", "(", "[", "len", "(", "it", ")", "for", "it", "in", "op_batch_list", "]", ")", "\n", "# emb_op -> (num_cond, batch, emb_size)", "\n", "", "if", "self", ".", "model", ".", "opt", ".", "layout_encode", "==", "'rnn'", ":", "\n", "            ", "emb_op", "=", "table", ".", "Models", ".", "encode_unsorted_batch", "(", "\n", "self", ".", "model", ".", "lay_encoder", ",", "cond_op", ",", "cond_op_len", ".", "clamp", "(", "min", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "emb_op", "=", "self", ".", "model", ".", "cond_embedding", "(", "cond_op", ")", "\n", "\n", "# (2) decoding", "\n", "", "self", ".", "model", ".", "cond_decoder", ".", "attn", ".", "applyMaskBySeqBatch", "(", "q", ")", "\n", "cond_state", "=", "self", ".", "model", ".", "cond_decoder", ".", "init_decoder_state", "(", "q_all", ",", "q_enc", ")", "\n", "cond_col_list", ",", "cond_span_l_list", ",", "cond_span_r_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "emb_op_t", "in", "emb_op", ":", "\n", "            ", "emb_op_t", "=", "emb_op_t", ".", "unsqueeze", "(", "0", ")", "\n", "cond_context", ",", "cond_state", ",", "_", "=", "self", ".", "model", ".", "cond_decoder", "(", "\n", "emb_op_t", ",", "q_all", ",", "cond_state", ")", "\n", "# cond col -> (1, batch)", "\n", "cond_col", "=", "argmax", "(", "self", ".", "model", ".", "cond_col_match", "(", "\n", "cond_context", ",", "tbl_enc", ",", "tbl_mask", ")", ".", "data", ")", "\n", "cond_col_list", ".", "append", "(", "cpu_vector", "(", "cond_col", ")", ")", "\n", "# emb_col", "\n", "batch_index", "=", "torch", ".", "LongTensor", "(", "range", "(", "batch_size", ")", ")", ".", "unsqueeze_", "(", "0", ")", ".", "cuda", "(", ")", ".", "expand", "(", "\n", "cond_col", ".", "size", "(", "0", ")", ",", "cond_col", ".", "size", "(", "1", ")", ")", "\n", "emb_col", "=", "tbl_enc", "[", "cond_col", ",", "batch_index", ",", ":", "]", "\n", "cond_context", ",", "cond_state", ",", "_", "=", "self", ".", "model", ".", "cond_decoder", "(", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Loss.LossCompute.__init__": [[18, 32], ["torch.Module.__init__", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.KLDivLoss", "torch.KLDivLoss", "table.modules.cross_entropy_smooth.CrossEntropyLossSmooth", "table.modules.cross_entropy_smooth.CrossEntropyLossSmooth", "torch.NLLLoss", "torch.NLLLoss"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["    ", "def", "__init__", "(", "self", ",", "agg_sample_rate", ",", "smooth_eps", "=", "0", ")", ":", "\n", "        ", "super", "(", "TableLossCompute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "{", "}", "\n", "nll", "=", "nn", ".", "NLLLoss", "(", "size_average", "=", "False", ",", "ignore_index", "=", "-", "1", ")", "\n", "if", "smooth_eps", ">", "0", ":", "\n", "            ", "for", "loss_name", "in", "(", "'sel'", ",", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ":", "\n", "                ", "self", ".", "criterion", "[", "loss_name", "]", "=", "nll", "\n", "", "for", "loss_name", "in", "(", "'agg'", ",", "'lay'", ")", ":", "\n", "                ", "self", ".", "criterion", "[", "loss_name", "]", "=", "CrossEntropyLossSmooth", "(", "\n", "size_average", "=", "False", ",", "ignore_index", "=", "-", "1", ",", "smooth_eps", "=", "smooth_eps", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "loss_name", "in", "(", "'agg'", ",", "'sel'", ",", "'lay'", ",", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ":", "\n", "                ", "self", ".", "criterion", "[", "loss_name", "]", "=", "nll", "\n", "", "", "self", ".", "agg_sample_rate", "=", "agg_sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Loss.LossCompute.compute_loss": [[33, 49], ["sum", "zip", "loss_list.append", "itertools.count", "loss_list.append"], "methods", ["None"], ["", "def", "compute_loss", "(", "self", ",", "pred", ",", "gold", ")", ":", "\n", "# sum up the loss functions", "\n", "        ", "loss_list", "=", "[", "]", "\n", "for", "loss_name", "in", "(", "'agg'", ",", "'sel'", ",", "'lay'", ")", ":", "\n", "            ", "loss", "=", "self", ".", "criterion", "[", "loss_name", "]", "(", "pred", "[", "loss_name", "]", ",", "gold", "[", "loss_name", "]", ")", "\n", "if", "(", "loss_name", "!=", "'agg'", ")", "or", "(", "rnd", ".", "random", "(", ")", "<", "self", ".", "agg_sample_rate", ")", ":", "\n", "                ", "loss_list", ".", "append", "(", "loss", ")", "\n", "", "", "for", "loss_name", "in", "(", "'cond_col'", ",", "'cond_span_l'", ",", "'cond_span_r'", ")", ":", "\n", "            ", "for", "p", ",", "g", "in", "zip", "(", "pred", "[", "loss_name", "]", ",", "gold", "[", "loss_name", "]", ")", ":", "\n", "                ", "loss", "=", "self", ".", "criterion", "[", "loss_name", "]", "(", "p", ",", "g", ")", "\n", "loss_list", ".", "append", "(", "loss", ")", "\n", "", "", "return", "sum", "(", "loss_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_parent_index": [[33, 46], ["enumerate", "r_list.append", "r_list.append", "tk.startswith", "stack.append", "stack.pop"], "function", ["None"], ["\n", "", "torchtext", ".", "vocab", ".", "Vocab", ".", "__getstate__", "=", "__getstate__", "\n", "torchtext", ".", "vocab", ".", "Vocab", ".", "__setstate__", "=", "__setstate__", "\n", "\n", "\n", "def", "merge_vocabs", "(", "vocabs", ",", "vocab_size", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_tgt_mask": [[48, 52], ["None"], "function", ["None"], ["\n", "merged", "=", "sum", "(", "[", "vocab", ".", "freqs", "for", "vocab", "in", "vocabs", "]", ",", "Counter", "(", ")", ")", "\n", "return", "torchtext", ".", "vocab", ".", "Vocab", "(", "merged", ",", "\n", "specials", "=", "list", "(", "special_token_list", ")", ",", "\n", "max_size", "=", "vocab_size", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_lay_index": [[54, 65], ["r_list.append", "r_list.append"], "function", ["None"], ["\n", "", "def", "join_dicts", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    args: dictionaries with disjoint keys\n    returns: a single dictionary that has the union of these keys\n    \"\"\"", "\n", "return", "dict", "(", "chain", "(", "*", "[", "d", ".", "items", "(", ")", "for", "d", "in", "args", "]", ")", ")", "\n", "\n", "\n", "", "class", "OrderedIterator", "(", "torchtext", ".", "data", ".", "Iterator", ")", ":", "\n", "    ", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.get_tgt_loss": [[67, 83], ["zip", "r_list.append", "r_list.append", "r_list.append", "r_list.append", "r_list.append"], "function", ["None"], ["self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "sort_key", ",", "self", ".", "batch_size_fn", ",", "\n", "random_shuffler", "=", "self", ".", "random_shuffler", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "batches", "=", "[", "]", "\n", "for", "b", "in", "torchtext", ".", "data", ".", "batch", "(", "self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "batch_size_fn", ")", ":", "\n", "                ", "self", ".", "batches", ".", "append", "(", "sorted", "(", "b", ",", "key", "=", "self", ".", "sort_key", ")", ")", "\n", "\n", "\n", "", "", "", "", "def", "read_anno_json", "(", "anno_path", ")", ":", "\n", "    ", "with", "codecs", ".", "open", "(", "anno_path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "        ", "js_list", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "corpus_file", "]", "\n", "for", "js", "in", "js_list", ":", "\n", "            ", "cond_list", "=", "list", "(", "enumerate", "(", "js", "[", "'query'", "]", "[", "'conds'", "]", ")", ")", "\n", "# sort by (op, orginal index)", "\n", "# cond_list.sort(key=lambda x: (x[1][1], x[0]))", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.filter_counter": [[93, 99], ["collections.Counter", "freqs.items"], "function", ["None"], ["def", "sort_key", "(", "ex", ")", ":", "\n", "        ", "\"Sort in reverse size order\"", "\n", "return", "-", "len", "(", "ex", ".", "src", ")", "\n", "\n", "", "def", "__init__", "(", "self", ",", "anno", ",", "fields", ",", "opt", ",", "filter_ex", ",", "**", "kwargs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO._preprocess_json": [[139, 146], ["tree.STree", "tree.STree.layout", "tree.STree.layout", "str().split", "len", "len", "list", "str().split", "zip", "str", "str().split", "str", "str"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.layout", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.layout"], ["opt", ",", "js_list", ",", "'cond_op'", ",", "filter_ex", ")", "\n", "cond_op_examples", "=", "self", ".", "_construct_examples", "(", "cond_op_data", ",", "'cond_op'", ")", "\n", "\n", "cond_col_data", "=", "list", "(", "\n", "self", ".", "_read_annotated_file", "(", "opt", ",", "js_list", ",", "'cond_col'", ",", "filter_ex", ")", ")", "\n", "cond_col_examples", "=", "self", ".", "_construct_examples", "(", "cond_col_data", ",", "'cond_col'", ")", "\n", "cond_col_loss_examples", "=", "self", ".", "_construct_examples", "(", "\n", "cond_col_data", ",", "'cond_col_loss'", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoderParentFeedInput.__init__": [[218, 228], ["Models.SeqDecoder.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["\n", "# Args Check", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoderParentFeedInput.init_parent_all": [[229, 232], ["None"], "methods", ["None"], ["assert", "isinstance", "(", "state", ",", "RNNDecoderState", ")", "\n", "# END Args Check", "\n", "\n", "# Run the forward pass of the RNN.", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoderParentFeedInput._run_forward_pass": [[233, 302], ["Models.SeqDecoderParentFeedInput.size", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "torch.LongTensor().unsqueeze_().cuda().expand", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.SeqDecoderParentFeedInput.word_dropout", "parent_index.size", "Models.SeqDecoderParentFeedInput.size", "emb[].unsqueeze", "parent_index[].unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.SeqDecoderParentFeedInput.rnn", "rnn_output_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.SeqDecoderParentFeedInput.attn", "attn_outputs_list.append", "attn_scores_list.append", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "Models.SeqDecoderParentFeedInput.size", "Models.SeqDecoderParentFeedInput.parent_feed_input_layer().view", "rnn_output_t.transpose().contiguous", "context.transpose", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "Models.SeqDecoderParentFeedInput.parent_feed_input_layer", "rnn_output_t.transpose", "Models.SeqDecoderParentFeedInput.view", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range"], "methods", ["None"], ["hidden", ",", "outputs", ",", "attns", "=", "self", ".", "_run_forward_pass", "(", "emb", ",", "context", ",", "state", ")", "\n", "\n", "# Update the state with the result.", "\n", "state", ".", "update_state", "(", "hidden", ")", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "for", "k", "in", "attns", ":", "\n", "            ", "attns", "[", "k", "]", "=", "torch", ".", "stack", "(", "attns", "[", "k", "]", ")", "\n", "\n", "", "return", "outputs", ",", "state", ",", "attns", "\n", "\n", "", "def", "_fix_enc_hidden", "(", "self", ",", "h", ")", ":", "\n", "        ", "\"\"\"\n        The encoder hidden is  (layers*directions) x batch x dim.\n        We need to convert it to layers x batch x (directions*dim).\n        \"\"\"", "\n", "if", "self", ".", "bidirectional_encoder", ":", "\n", "            ", "h", "=", "torch", ".", "cat", "(", "[", "h", "[", "0", ":", "h", ".", "size", "(", "0", ")", ":", "2", "]", ",", "h", "[", "1", ":", "h", ".", "size", "(", "0", ")", ":", "2", "]", "]", ",", "2", ")", "\n", "", "return", "h", "\n", "\n", "", "def", "init_decoder_state", "(", "self", ",", "context", ",", "enc_hidden", ")", ":", "\n", "        ", "return", "RNNDecoderState", "(", "context", ",", "self", ".", "hidden_size", ",", "tuple", "(", "[", "self", ".", "_fix_enc_hidden", "(", "enc_hidden", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "enc_hidden", ")", ")", "]", ")", ")", "\n", "\n", "", "def", "_run_forward_pass", "(", "self", ",", "emb", ",", "context", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for running the specific RNN forward pass.\n        Must be overriden by all subclasses.\n        Args:\n            input (LongTensor): a sequence of input tokens tensors\n                                of size (len x batch x nfeats).\n            context (FloatTensor): output(tensor sequence) from the encoder\n                        RNN of size (src_len x batch x hidden_size).\n            state (FloatTensor): hidden state from the encoder RNN for\n                                 initializing the decoder.\n        Returns:\n            hidden (Variable): final hidden state from the decoder.\n            outputs ([FloatTensor]): an array of output of every time\n                                     step from the decoder.\n            attns (dict of (str, [FloatTensor]): a dictionary of different\n                            type of attention Tensor array of every time\n                            step from the decoder.\n        \"\"\"", "\n", "\n", "# Initialize local and return variables.", "\n", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "\n", "if", "self", ".", "word_dropout", "is", "not", "None", ":", "\n", "            ", "emb", "=", "self", ".", "word_dropout", "(", "emb", ")", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", ")", "\n", "\n", "# Calculate the attention.", "\n", "attn_outputs", ",", "attn_scores", "=", "self", ".", "attn", "(", "\n", "rnn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "# (output_len, batch, d)", "\n", "context", ".", "transpose", "(", "0", ",", "1", ")", "# (contxt_len, batch, d)", "\n", ")", "\n", "attns", "[", "\"std\"", "]", "=", "attn_scores", "\n", "\n", "outputs", "=", "attn_outputs", "# (input_len, batch, d)", "\n", "\n", "# Return result.", "\n", "return", "hidden", ",", "outputs", ",", "attns", "\n", "\n", "\n", "", "", "class", "DecoderState", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._init_parent_list": [[133, 146], ["q_ht[].transpose().contiguous().view", "decoder.init_parent_all", "q_ht[].transpose().contiguous", "q_ht[].unsqueeze", "range", "q_ht.unsqueeze", "range", "q_ht[].transpose"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Models.SeqDecoderParentFeedInput.init_parent_all"], ["for", "i", "in", "range", "(", "len", "(", "op_batch_list", "[", "b", "]", ")", ")", ":", "\n", "                ", "col", "=", "cond_col_list", "[", "i", "]", "[", "b", "]", "\n", "op", "=", "op_idx_batch_list", "[", "b", "]", "[", "i", "]", "\n", "span_l", "=", "cond_span_l_list", "[", "i", "]", "[", "b", "]", "\n", "span_r", "=", "cond_span_r_list", "[", "i", "]", "[", "b", "]", "\n", "cond", ".", "append", "(", "(", "col", ",", "op", ",", "(", "span_l", ",", "span_r", ")", ")", ")", "\n", "", "r_list", ".", "append", "(", "ParseResult", "(", "idx", ",", "agg", ",", "sel", ",", "cond", ")", ")", "\n", "\n", "", "return", "r_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._cat_parent_feed_input": [[147, 151], ["Translator.v_eval", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_().cuda", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor().unsqueeze_", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.v_eval"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._cat_parent_feed_output": [[152, 158], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator._update_parent_list": [[159, 179], ["range", "tk.startswith", "len", "parent_list[].append", "parent_list[].append", "len", "parent_list[].pop"], "methods", ["None"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.mix_lay_and_tgt": [[36, 47], ["len", "len", "zip", "tgt_mix.append", "tgt_mix.append"], "function", ["None"], ["self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "", "def", "translate", "(", "self", ",", "batch", ")", ":", "\n", "        ", "q", ",", "q_len", "=", "batch", ".", "src", "\n", "tbl", ",", "tbl_len", "=", "batch", ".", "tbl", "\n", "ent", ",", "tbl_split", ",", "tbl_mask", "=", "batch", ".", "ent", ",", "batch", ".", "tbl_split", ",", "batch", ".", "tbl_mask", "\n", "\n", "# encoding", "\n", "q_enc", ",", "q_all", ",", "tbl_enc", ",", "q_ht", ",", "batch_size", "=", "self", ".", "model", ".", "enc", "(", "\n", "q", ",", "q_len", ",", "ent", ",", "tbl", ",", "tbl_len", ",", "tbl_split", ",", "tbl_mask", ")", "\n", "\n", "# (1) decoding", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.data_aug_by_permute_order": [[156, 169], ["tree.STree", "range", "set", "IO._preprocess_json", "str", "p_list.append", "r_list.append", "str", "tree.STree.permute", "p.split"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO._preprocess_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.permute"], ["span_l_loss_examples", "=", "self", ".", "_construct_examples", "(", "\n", "_map_to_sublist_index", "(", "span_data", ",", "0", ")", ",", "'cond_span_l_loss'", ")", "\n", "span_r_loss_examples", "=", "self", ".", "_construct_examples", "(", "\n", "_map_to_sublist_index", "(", "span_data", ",", "1", ")", ",", "'cond_span_r_loss'", ")", "\n", "\n", "# examples: one for each src line or (src, tgt) line pair.", "\n", "examples", "=", "[", "join_dicts", "(", "*", "it", ")", "for", "it", "in", "zip", "(", "src_examples", ",", "ent_examples", ",", "agg_examples", ",", "sel_examples", ",", "lay_examples", ",", "tbl_examples", ",", "tbl_split_examples", ",", "tbl_mask_examples", ",", "\n", "cond_op_examples", ",", "cond_col_examples", ",", "span_l_examples", ",", "span_r_examples", ",", "cond_col_loss_examples", ",", "span_l_loss_examples", ",", "span_r_loss_examples", ")", "]", "\n", "# the examples should not contain None", "\n", "len_before_filter", "=", "len", "(", "examples", ")", "\n", "examples", "=", "list", "(", "filter", "(", "lambda", "x", ":", "all", "(", "\n", "(", "v", "is", "not", "None", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", ")", ")", ",", "examples", ")", ")", "\n", "len_after_filter", "=", "len", "(", "examples", ")", "\n", "num_filter", "=", "len_before_filter", "-", "len_after_filter", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.__init__": [[46, 86], ["torch.Module.__init__", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ELU", "torch.ELU", "torch.ELU", "torch.ELU", "table.modules.UtilClass.BottleLinear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "table.modules.UtilClass.BottleLinear"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["self", ".", "dim", "=", "dim", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "self", ".", "attn_hidden", "=", "attn_hidden", "\n", "assert", "(", "self", ".", "attn_type", "in", "[", "\"dot\"", ",", "\"general\"", ",", "\"mlp\"", "]", ")", ",", "(", "\n", "\"Please select a valid attention type.\"", ")", "\n", "\n", "if", "attn_hidden", ">", "0", ":", "\n", "            ", "self", ".", "transform_in", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim", ",", "attn_hidden", ")", ",", "\n", "nn", ".", "ELU", "(", "0.1", ")", ")", "\n", "\n", "", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "            ", "d", "=", "attn_hidden", "if", "attn_hidden", ">", "0", "else", "dim", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "d", ",", "d", ",", "bias", "=", "False", ")", "\n", "# initialization", "\n", "# self.linear_in.weight.data.add_(torch.eye(d))", "\n", "", "elif", "self", ".", "attn_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "linear_context", "=", "BottleLinear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "BottleLinear", "(", "dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "# mlp wants it with bias", "\n", "", "out_bias", "=", "self", ".", "attn_type", "==", "\"mlp\"", "\n", "if", "is_transform_out", ":", "\n", "            ", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear_out", "=", "None", "\n", "\n", "", "self", ".", "sm", "=", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n", "", "def", "applyMask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", "=", "mask", "\n", "\n", "", "def", "applyMaskBySeqBatch", "(", "self", ",", "q", ")", ":", "\n", "        ", "self", ".", "applyMask", "(", "q", ".", "data", ".", "eq", "(", "table", ".", "IO", ".", "PAD", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "def", "score", "(", "self", ",", "h_t", ",", "h_s", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMask": [[87, 89], ["None"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMaskBySeqBatch": [[90, 92], ["GlobalAttention.GlobalAttention.applyMask", "q.data.eq().t().contiguous().unsqueeze", "q.data.eq().t().contiguous", "q.data.eq().t", "q.data.eq"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.applyMask"], ["\n", "# Check input sizes", "\n", "src_batch", ",", "src_len", ",", "src_dim", "=", "h_s", ".", "size", "(", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.score": [[93, 132], ["GlobalAttention.GlobalAttention.size", "GlobalAttention.GlobalAttention.size", "table.Utils.aeq", "GlobalAttention.GlobalAttention.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "GlobalAttention.GlobalAttention.linear_query", "wq.expand.expand.view", "wq.expand.expand.expand", "GlobalAttention.GlobalAttention.linear_context", "uh.expand.expand.view", "uh.expand.expand.expand", "GlobalAttention.GlobalAttention.tanh", "GlobalAttention.GlobalAttention.v().view", "GlobalAttention.GlobalAttention.transform_in", "GlobalAttention.GlobalAttention.transform_in", "GlobalAttention.GlobalAttention.linear_in", "GlobalAttention.GlobalAttention.view", "GlobalAttention.GlobalAttention.contiguous().view", "GlobalAttention.GlobalAttention.v", "GlobalAttention.GlobalAttention.contiguous", "GlobalAttention.GlobalAttention.view"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq"], ["tgt_batch", ",", "tgt_len", ",", "tgt_dim", "=", "h_t", ".", "size", "(", ")", "\n", "aeq", "(", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "src_dim", ",", "tgt_dim", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "src_dim", ")", "\n", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "if", "self", ".", "attn_hidden", ">", "0", ":", "\n", "                ", "h_t", "=", "self", ".", "transform_in", "(", "h_t", ")", "\n", "h_s", "=", "self", ".", "transform_in", "(", "h_s", ")", "\n", "", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "                ", "h_t", "=", "self", ".", "linear_in", "(", "h_t", ")", "\n", "", "h_s_", "=", "h_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# (batch, t_len, d) x (batch, d, s_len) --> (batch, t_len, s_len)", "\n", "return", "torch", ".", "bmm", "(", "h_t", ",", "h_s_", ")", "\n", "", "else", ":", "\n", "            ", "dim", "=", "self", ".", "dim", "\n", "wq", "=", "self", ".", "linear_query", "(", "h_t", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "wq", "=", "wq", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "1", ",", "dim", ")", "\n", "wq", "=", "wq", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "uh", "=", "self", ".", "linear_context", "(", "h_s", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "uh", "=", "uh", ".", "view", "(", "src_batch", ",", "1", ",", "src_len", ",", "dim", ")", "\n", "uh", "=", "uh", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "# (batch, t_len, s_len, d)", "\n", "wquh", "=", "self", ".", "tanh", "(", "wq", "+", "uh", ")", "\n", "\n", "return", "self", ".", "v", "(", "wquh", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "input", ",", "context", ")", ":", "\n", "        ", "\"\"\"\n        input (FloatTensor): batch x tgt_len x dim: decoder's rnn's output.\n        context (FloatTensor): batch x src_len x dim: src hidden states\n        \"\"\"", "\n", "\n", "# one step input", "\n", "if", "input", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "input", "=", "input", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.forward": [[133, 210], ["context.size", "input.unsqueeze.unsqueeze.size", "table.Utils.aeq", "GlobalAttention.GlobalAttention.score", "GlobalAttention.GlobalAttention.sm", "align_vectors.transpose().contiguous.transpose().contiguous.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input.unsqueeze.unsqueeze.dim", "input.unsqueeze.unsqueeze.unsqueeze", "GlobalAttention.GlobalAttention.mask.size", "table.Utils.aeq", "table.Utils.aeq", "GlobalAttention.GlobalAttention.mask.view", "GlobalAttention.GlobalAttention.data.masked_fill_", "GlobalAttention.GlobalAttention.view", "torch.threshold", "torch.threshold", "torch.threshold", "torch.threshold", "GlobalAttention.GlobalAttention.linear_out", "GlobalAttention.GlobalAttention.squeeze", "align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "GlobalAttention.GlobalAttention.size", "table.Utils.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "table.Utils.aeq", "table.Utils.aeq", "GlobalAttention.GlobalAttention.transpose().contiguous", "align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "GlobalAttention.GlobalAttention.size", "table.Utils.aeq", "table.Utils.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "table.Utils.aeq", "table.Utils.aeq", "table.Utils.aeq", "GlobalAttention.GlobalAttention.tanh", "float", "GlobalAttention.GlobalAttention.transpose", "align_vectors.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.GlobalAttention.GlobalAttention.score", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Utils.aeq"], ["            ", "one_step", "=", "False", "\n", "\n", "", "batch", ",", "sourceL", ",", "dim", "=", "context", ".", "size", "(", ")", "\n", "batch_", ",", "targetL", ",", "dim_", "=", "input", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "dim", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "beam_", ",", "batch_", ",", "sourceL_", "=", "self", ".", "mask", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", "*", "beam_", ")", "\n", "aeq", "(", "sourceL", ",", "sourceL_", ")", "\n", "\n", "# compute attention scores, as in Luong et al.", "\n", "", "align", "=", "self", ".", "score", "(", "input", ",", "context", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "mask_", "=", "self", ".", "mask", ".", "view", "(", "batch", ",", "1", ",", "sourceL", ")", "# make it broardcastable", "\n", "align", ".", "data", ".", "masked_fill_", "(", "mask_", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# Softmax to normalize attention weights", "\n", "", "align_vectors", "=", "self", ".", "sm", "(", "align", ".", "view", "(", "batch", "*", "targetL", ",", "sourceL", ")", ")", "\n", "align_vectors", "=", "align_vectors", ".", "view", "(", "batch", ",", "targetL", ",", "sourceL", ")", "\n", "\n", "# each context vector c_t is the weighted average", "\n", "# over all the source hidden states", "\n", "c", "=", "torch", ".", "bmm", "(", "align_vectors", ",", "context", ")", "\n", "\n", "# concatenate", "\n", "concat_c", "=", "torch", ".", "cat", "(", "[", "c", ",", "input", "]", ",", "2", ")", "\n", "if", "self", ".", "linear_out", "is", "None", ":", "\n", "            ", "attn_h", "=", "concat_c", "\n", "", "else", ":", "\n", "            ", "attn_h", "=", "self", ".", "linear_out", "(", "concat_c", ")", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "                ", "attn_h", "=", "self", ".", "tanh", "(", "attn_h", ")", "\n", "\n", "", "", "if", "one_step", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "squeeze", "(", "1", ")", "\n", "align_vectors", "=", "align_vectors", ".", "squeeze", "(", "1", ")", "\n", "\n", "# Check output sizes", "\n", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "# aeq(dim, dim_)", "\n", "batch_", ",", "sourceL_", "=", "align_vectors", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "sourceL", ",", "sourceL_", ")", "\n", "", "else", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "align_vectors", "=", "align_vectors", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Check output sizes", "\n", "targetL_", ",", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n", "aeq", "(", "targetL", ",", "targetL_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "# aeq(dim, dim_)", "\n", "targetL_", ",", "batch_", ",", "sourceL_", "=", "align_vectors", ".", "size", "(", ")", "\n", "aeq", "(", "targetL", ",", "targetL_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "sourceL", ",", "sourceL_", ")", "\n", "\n", "", "return", "attn_h", ",", "align_vectors", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightDrop.WeightDrop.__init__": [[7, 14], ["super().__init__", "WeightDrop.WeightDrop._setup"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightDrop.WeightDrop._setup"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "weights", ",", "dropout", "=", "0", ",", "variational", "=", "False", ")", ":", "\n", "        ", "super", "(", "WeightDrop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "variational", "=", "variational", "\n", "self", ".", "_setup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightDrop.WeightDrop.widget_demagnetizer_y2k_edition": [[15, 21], ["None"], "methods", ["None"], ["", "def", "widget_demagnetizer_y2k_edition", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# We need to replace flatten_parameters with a nothing function", "\n", "# It must be a function rather than a lambda as otherwise pickling explodes", "\n", "# We can't write boring code though, so ... WIDGET DEMAGNETIZER Y2K EDITION!", "\n", "# (\u256f\u00b0\u25a1\u00b0\uff09\u256f\ufe35 \u253b\u2501\u253b", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightDrop.WeightDrop._setup": [[22, 32], ["issubclass", "type", "getattr", "WeightDrop.WeightDrop.module.register_parameter", "torch.nn.Parameter"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "# Terrible temporary solution to an issue regarding compacting weights re: CUDNN RNN", "\n", "        ", "if", "issubclass", "(", "type", "(", "self", ".", "module", ")", ",", "torch", ".", "nn", ".", "RNNBase", ")", ":", "\n", "            ", "self", ".", "module", ".", "flatten_parameters", "=", "self", ".", "widget_demagnetizer_y2k_edition", "\n", "\n", "", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "print", "(", "'Applying weight drop of {} to {}'", ".", "format", "(", "self", ".", "dropout", ",", "name_w", ")", ")", "\n", "w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", ")", "\n", "del", "self", ".", "module", ".", "_parameters", "[", "name_w", "]", "\n", "self", ".", "module", ".", "register_parameter", "(", "name_w", "+", "'_raw'", ",", "Parameter", "(", "w", ".", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightDrop.WeightDrop._setweights": [[33, 48], ["getattr", "setattr", "torch.autograd.Variable", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.ones", "mask.cuda.cuda.cuda", "mask.cuda.cuda.expand_as", "getattr.size"], "methods", ["None"], ["", "", "def", "_setweights", "(", "self", ")", ":", "\n", "        ", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "raw_w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", "+", "'_raw'", ")", "\n", "w", "=", "None", "\n", "if", "self", ".", "variational", ":", "\n", "                ", "mask", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "ones", "(", "raw_w", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "if", "raw_w", ".", "is_cuda", ":", "\n", "                    ", "mask", "=", "mask", ".", "cuda", "(", ")", "\n", "", "mask", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "\n", "mask", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "True", ")", "\n", "w", "=", "mask", ".", "expand_as", "(", "raw_w", ")", "*", "raw_w", "\n", "", "else", ":", "\n", "                ", "w", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "\n", "raw_w", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "", "setattr", "(", "self", ".", "module", ",", "name_w", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightDrop.WeightDrop.forward": [[49, 52], ["WeightDrop.WeightDrop._setweights", "WeightDrop.WeightDrop.module.forward"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightDrop.WeightDrop._setweights", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.forward"], ["", "", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_setweights", "(", ")", "\n", "return", "self", ".", "module", ".", "forward", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.__init__": [[7, 14], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["    ", "def", "__init__", "(", "self", ",", "update_index", ",", "emb_update", ",", "emb_fixed", ")", ":", "\n", "        ", "super", "(", "PartUpdateEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "update_index", "=", "update_index", "\n", "self", ".", "emb_update", "=", "emb_update", "\n", "self", ".", "emb_fixed", "=", "emb_fixed", "\n", "self", ".", "should_update", "=", "True", "\n", "self", ".", "embedding_dim", "=", "emb_update", ".", "embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.set_update": [[15, 17], ["None"], "methods", ["None"], ["", "def", "set_update", "(", "self", ",", "should_update", ")", ":", "\n", "        ", "self", ".", "should_update", "=", "should_update", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.forward": [[18, 30], ["Embeddings.PartUpdateEmbedding.emb_update", "Embeddings.PartUpdateEmbedding.emb_fixed", "torch.autograd.Variable", "torch.autograd.Variable", "r_update.mul.mul.mul", "r_fixed.mul.mul.mul", "inp.dim", "inp.clamp", "inp.data.lt().float().unsqueeze().expand_as", "torch.autograd.Variable", "torch.autograd.Variable", "inp.data.lt().float().unsqueeze", "inp.data.lt().float", "inp.data.lt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "assert", "(", "inp", ".", "dim", "(", ")", "==", "2", ")", "\n", "r_update", "=", "self", ".", "emb_update", "(", "inp", ".", "clamp", "(", "0", ",", "self", ".", "update_index", "-", "1", ")", ")", "\n", "r_fixed", "=", "self", ".", "emb_fixed", "(", "inp", ")", "\n", "mask", "=", "Variable", "(", "inp", ".", "data", ".", "lt", "(", "self", ".", "update_index", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "\n", "2", ")", ".", "expand_as", "(", "r_update", ")", ",", "requires_grad", "=", "False", ")", "\n", "r_update", "=", "r_update", ".", "mul", "(", "mask", ")", "\n", "r_fixed", "=", "r_fixed", ".", "mul", "(", "1", "-", "mask", ")", "\n", "if", "self", ".", "should_update", ":", "\n", "            ", "return", "r_update", "+", "r_fixed", "\n", "", "else", ":", "\n", "            ", "return", "r_update", "+", "Variable", "(", "r_fixed", ".", "data", ",", "requires_grad", "=", "False", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.ContextGate.__init__": [[28, 37], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "ContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "input_size", "=", "embeddings_size", "+", "decoder_size", "+", "attention_size", "\n", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "source_proj", "=", "nn", ".", "Linear", "(", "attention_size", ",", "output_size", ")", "\n", "self", ".", "target_proj", "=", "nn", ".", "Linear", "(", "embeddings_size", "+", "decoder_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.ContextGate.forward": [[38, 45], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "Gate.ContextGate.sig", "Gate.ContextGate.source_proj", "Gate.ContextGate.target_proj", "Gate.ContextGate.gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "input_tensor", "=", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ",", "dim", "=", "1", ")", "\n", "z", "=", "self", ".", "sig", "(", "self", ".", "gate", "(", "input_tensor", ")", ")", "\n", "proj_source", "=", "self", ".", "source_proj", "(", "attn_state", ")", "\n", "proj_target", "=", "self", ".", "target_proj", "(", "\n", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "z", ",", "proj_source", ",", "proj_target", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.SourceContextGate.__init__": [[50, 56], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "SourceContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.SourceContextGate.forward": [[57, 61], ["Gate.SourceContextGate.context_gate", "Gate.SourceContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "\n", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "target", "+", "z", "*", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.TargetContextGate.__init__": [[66, 72], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "TargetContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.TargetContextGate.forward": [[73, 76], ["Gate.TargetContextGate.context_gate", "Gate.TargetContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "z", "*", "target", "+", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.BothContextGate.__init__": [[81, 87], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "BothContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.BothContextGate.forward": [[88, 91], ["Gate.BothContextGate.context_gate", "Gate.BothContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "(", "1.", "-", "z", ")", "*", "target", "+", "z", "*", "source", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Gate.ContextGateFactory": [[12, 23], ["None"], "function", ["None"], ["def", "ContextGateFactory", "(", "type", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Returns the correct ContextGate class\"\"\"", "\n", "\n", "gate_types", "=", "{", "'source'", ":", "SourceContextGate", ",", "\n", "'target'", ":", "TargetContextGate", ",", "\n", "'both'", ":", "BothContextGate", "}", "\n", "\n", "assert", "type", "in", "gate_types", ",", "\"Not valid ContextGate type: {0}\"", ".", "format", "(", "type", ")", "\n", "return", "gate_types", "[", "type", "]", "(", "embeddings_size", ",", "decoder_size", ",", "attention_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.StackedRNN.StackedLSTM.__init__": [[10, 19], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "StackedRNN.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.StackedRNN.StackedLSTM.forward": [[20, 35], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "StackedRNN.StackedLSTM.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "input", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "input", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "input", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.StackedRNN.StackedGRU.__init__": [[39, 48], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "StackedRNN.StackedGRU.layers.append", "torch.GRUCell", "torch.GRUCell"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "GRUCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.StackedRNN.StackedGRU.forward": [[49, 60], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "StackedRNN.StackedGRU.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "h_1", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", "=", "layer", "(", "input", ",", "hidden", "[", "0", "]", "[", "i", "]", ")", "\n", "input", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "return", "input", ",", "(", "h_1", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.LockedDropout.LockedDropout.__init__": [[7, 10], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout_rate", ")", ":", "\n", "        ", "super", "(", "LockedDropout", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.LockedDropout.LockedDropout.forward": [[11, 18], ["x.data.new().bernoulli_", "mask.expand_as.expand_as.expand_as", "torch.autograd.Variable", "torch.autograd.Variable", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", "or", "not", "self", ".", "dropout_rate", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "1", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "self", ".", "dropout_rate", ")", "\n", "mask", "=", "Variable", "(", "m", ",", "requires_grad", "=", "False", ")", "/", "(", "1", "-", "self", ".", "dropout_rate", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.cross_entropy_smooth.CrossEntropyLossSmooth.__init__": [[66, 72], ["torch.CrossEntropyLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["\n", "\n", "", "class", "CrossEntropyLossSmooth", "(", "nn", ".", "CrossEntropyLoss", ")", ":", "\n", "    ", "\"\"\"CrossEntropyLossSmooth - with ability to recieve distrbution as targets, and optional label smoothing\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "weight", "=", "None", ",", "size_average", "=", "True", ",", "ignore_index", "=", "-", "100", ",", "reduce", "=", "True", ",", "\n", "smooth_eps", "=", "None", ",", "smooth_dist", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.cross_entropy_smooth.CrossEntropyLossSmooth.forward": [[73, 76], ["cross_entropy_smooth.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.cross_entropy_smooth.cross_entropy"], ["        ", "super", "(", "CrossEntropyLossSmooth", ",", "self", ")", ".", "__init__", "(", "\n", "weight", ",", "size_average", "=", "size_average", ",", "ignore_index", "=", "ignore_index", ")", "\n", "self", ".", "smooth_eps", "=", "smooth_eps", "\n", "self", ".", "smooth_dist", "=", "smooth_dist", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.cross_entropy_smooth.onehot": [[6, 28], ["isinstance", "list", "indexes.new().byte().resize_().zero_", "torch.autograd.Variable.scatter_", "indexes.size", "indexes.unsqueeze", "torch.autograd.Variable.masked_fill_", "torch.autograd.Variable", "indexes.max", "indexes.new().byte().resize_", "indexes.eq().unsqueeze", "indexes.new().byte", "indexes.eq", "indexes.new"], "function", ["None"], ["\n", "def", "onehot", "(", "indexes", ",", "N", "=", "None", ",", "ignore_index", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a one-representation of indexes with N possible entries\n    if N is not specified, it will suit the maximum index appearing.\n    indexes is a long-tensor of indexes\n    ignore_index will be zero in onehot representation\n    \"\"\"", "\n", "return_variable", "=", "False", "\n", "if", "isinstance", "(", "indexes", ",", "Variable", ")", ":", "\n", "        ", "return_variable", "=", "True", "\n", "indexes", "=", "indexes", ".", "data", "\n", "", "if", "ignore_index", "is", "not", "None", ":", "\n", "        ", "mask_idx", "=", "indexes", ".", "eq", "(", "ignore_index", ")", "\n", "", "if", "N", "is", "None", ":", "\n", "        ", "N", "=", "indexes", ".", "max", "(", ")", "+", "1", "\n", "", "sz", "=", "list", "(", "indexes", ".", "size", "(", ")", ")", "\n", "output", "=", "indexes", ".", "new", "(", ")", ".", "byte", "(", ")", ".", "resize_", "(", "*", "sz", ",", "N", ")", ".", "zero_", "(", ")", "\n", "# ignore_index could be < 0", "\n", "output", ".", "scatter_", "(", "-", "1", ",", "indexes", ".", "clone", "(", ")", ".", "masked_fill_", "(", "mask_idx", ",", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "1", ")", "\n", "if", "ignore_index", "is", "not", "None", ":", "\n", "        ", "output", ".", "masked_fill_", "(", "mask_idx", ".", "unsqueeze", "(", "-", "1", ")", ",", "0", ")", "\n", "", "if", "return_variable", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.cross_entropy_smooth._is_long": [[29, 33], ["hasattr", "isinstance", "isinstance"], "function", ["None"], ["        ", "output", "=", "Variable", "(", "output", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "return", "output", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.cross_entropy_smooth.cross_entropy": [[35, 61], ["logits.size", "cross_entropy_smooth._is_long", "ce.sum.mean", "ce.sum.sum", "onehot().type_as", "torch.lerp", "torch.lerp", "torch.lerp", "torch.lerp.masked_fill_", "weight.unsqueeze", "torch.lerp.eq", "smooth_dist.unsqueeze", "target.eq.unsqueeze", "cross_entropy_smooth.onehot"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.cross_entropy_smooth._is_long", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.cross_entropy_smooth.onehot"], ["    ", "if", "hasattr", "(", "x", ",", "'data'", ")", ":", "\n", "        ", "x", "=", "x", ".", "data", "\n", "", "return", "isinstance", "(", "x", ",", "torch", ".", "LongTensor", ")", "or", "isinstance", "(", "x", ",", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "\n", "\n", "", "def", "cross_entropy", "(", "logits", ",", "target", ",", "weight", "=", "None", ",", "size_average", "=", "True", ",", "\n", "ignore_index", "=", "None", ",", "smooth_eps", "=", "None", ",", "smooth_dist", "=", "None", ")", ":", "\n", "    ", "\"\"\"cross entropy loss, with support for target distributions and label smoothing https://arxiv.org/abs/1512.00567\"\"\"", "\n", "if", "smooth_eps", "is", "not", "None", "and", "smooth_eps", ">", "0", ":", "\n", "        ", "num_classes", "=", "logits", ".", "size", "(", "-", "1", ")", "\n", "mask_idx", "=", "None", "\n", "if", "_is_long", "(", "target", ")", ":", "\n", "            ", "if", "ignore_index", "is", "not", "None", ":", "\n", "                ", "mask_idx", "=", "target", ".", "eq", "(", "ignore_index", ")", "\n", "", "target", "=", "onehot", "(", "target", ",", "num_classes", ",", "ignore_index", ")", ".", "type_as", "(", "logits", ")", "\n", "", "if", "smooth_dist", "is", "None", ":", "\n", "            ", "target", "=", "(", "1", "-", "smooth_eps", ")", "*", "target", "+", "smooth_eps", "/", "num_classes", "\n", "", "else", ":", "\n", "            ", "target", "=", "torch", ".", "lerp", "(", "\n", "target", ",", "smooth_dist", ".", "unsqueeze", "(", "0", ")", ",", "smooth_eps", ")", "\n", "", "if", "mask_idx", "is", "not", "None", ":", "\n", "            ", "target", ".", "masked_fill_", "(", "mask_idx", ".", "unsqueeze", "(", "1", ")", ",", "0", ")", "\n", "", "", "if", "weight", "is", "not", "None", ":", "\n", "        ", "target", "=", "target", "*", "weight", ".", "unsqueeze", "(", "0", ")", "\n", "", "ce", "=", "-", "(", "logits", "*", "target", ")", ".", "sum", "(", "1", ")", "\n", "if", "size_average", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormLinear.__init__": [[37, 54], ["torch.Linear.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "WeightNorm.WeightNormLinear.register_buffer", "WeightNorm.WeightNormLinear.register_buffer", "WeightNorm.WeightNormLinear.register_buffer", "WeightNorm.WeightNormLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "\n", "init_scale", "=", "1.", ",", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormLinear", ",", "self", ")", ".", "__init__", "(", "\n", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "\n", "'V_avg'", ",", "torch", ".", "zeros", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormLinear.reset_parameters": [[55, 57], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormLinear.forward": [[58, 92], ["WeightNorm.WeightNormLinear.V.data.copy_", "WeightNorm.WeightNormLinear.g.data.copy_", "WeightNorm.WeightNormLinear.b.data.copy_", "WeightNorm.WeightNormLinear.V_avg.copy_", "WeightNorm.WeightNormLinear.g_avg.copy_", "WeightNorm.WeightNormLinear.b_avg.copy_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "WeightNorm.get_vars_maybe_avg", "torch.linear", "torch.linear", "torch.linear", "WeightNorm.WeightNormLinear.V.data.norm().expand_as", "torch.linear", "torch.linear", "torch.linear", "x_init.mean().squeeze", "x_init.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view().expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "b.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "m_init.view().expand_as", "scalar.view().expand_as", "WeightNorm.WeightNormLinear.V.data.norm", "x_init.mean", "x_init.var", "scale_init.view", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "b.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "m_init.view", "scalar.view", "WeightNorm.WeightNormLinear.V.data.size"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_features * in_features", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "# norm is out_features * 1", "\n", "V_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "norm", "(", "2", ",", "1", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "# batch_size * out_features", "\n", "x_init", "=", "F", ".", "linear", "(", "x", ",", "Variable", "(", "V_norm", ")", ")", ".", "data", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "x_init", ".", "mean", "(", "0", ")", ".", "squeeze", "(", "\n", "0", ")", ",", "x_init", ".", "var", "(", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "x_init", "=", "scale_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "Variable", "(", "x_init", ")", "\n", "", "else", ":", "\n", "            ", "V", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "\n", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "# batch_size * out_features", "\n", "x", "=", "F", ".", "linear", "(", "x", ",", "V", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "V", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "scalar", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "*", "x", "+", "b", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConv2d.__init__": [[95, 113], ["torch.Conv2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "WeightNorm.WeightNormConv2d.register_buffer", "WeightNorm.WeightNormConv2d.register_buffer", "WeightNorm.WeightNormConv2d.register_buffer", "WeightNorm.WeightNormConv2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "WeightNorm.WeightNormConv2d.V.size"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConv2d", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "dilation", ",", "groups", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConv2d.reset_parameters": [[114, 116], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConv2d.forward": [[117, 163], ["WeightNorm.WeightNormConv2d.V.data.copy_", "x_init.transpose().contiguous().view", "WeightNorm.WeightNormConv2d.g.data.copy_", "WeightNorm.WeightNormConv2d.b.data.copy_", "scale_init.view", "m_init.view", "WeightNorm.WeightNormConv2d.V_avg.copy_", "WeightNorm.WeightNormConv2d.g_avg.copy_", "WeightNorm.WeightNormConv2d.b_avg.copy_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "WeightNorm.get_vars_maybe_avg", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.conv2d", "torch.conv2d", "torch.conv2d", "WeightNorm.WeightNormConv2d.V.data.view().norm().view().expand_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "x_init.transpose().contiguous().view.mean().squeeze", "x_init.transpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "V.view", "len", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x_init.transpose().contiguous", "m_init.view.expand_as", "torch.norm.size", "torch.norm.size", "torch.norm.size", "torch.norm.squeeze", "torch.norm.squeeze", "torch.norm.squeeze", "WeightNorm.WeightNormConv2d.V.data.view().norm().view", "x_init.transpose().contiguous().view.mean", "x_init.transpose().contiguous().view.var", "torch.norm.view", "torch.norm.view", "torch.norm.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.transpose", "len", "len", "WeightNorm.WeightNormConv2d.V.data.size", "WeightNorm.WeightNormConv2d.V.data.view().norm", "x_init.size", "x_init.size", "WeightNorm.WeightNormConv2d.V.data.view", "len", "len", "V.size"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_channels, in_channels // groups, * kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "V_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "self", ".", "out_channels", ",", "*", "(", "\n", "[", "1", "]", "*", "(", "len", "(", "self", ".", "kernel_size", ")", "+", "1", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv2d", "(", "x", ",", "Variable", "(", "V_norm", ")", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", ".", "data", "\n", "t_x_init", "=", "x_init", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "\n", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "Variable", "(", "x_init", ")", "\n", "", "else", ":", "\n", "            ", "V", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "\n", "scalar", "=", "torch", ".", "norm", "(", "V", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", "\n", "if", "len", "(", "scalar", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", "\n", "\n", "", "W", "=", "scalar", ".", "view", "(", "self", ".", "out_channels", ",", "*", "\n", "(", "[", "1", "]", "*", "(", "len", "(", "V", ".", "size", "(", ")", ")", "-", "1", ")", ")", ")", ".", "expand_as", "(", "V", ")", "*", "V", "\n", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "W", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConvTranspose2d.__init__": [[166, 186], ["torch.ConvTranspose2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "WeightNorm.WeightNormConvTranspose2d.register_buffer", "WeightNorm.WeightNormConvTranspose2d.register_buffer", "WeightNorm.WeightNormConvTranspose2d.register_buffer", "WeightNorm.WeightNormConvTranspose2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "WeightNorm.WeightNormConvTranspose2d.V.size"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "output_padding", "=", "0", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConvTranspose2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "output_padding", ",", "\n", "groups", ")", "\n", "# in_channels, out_channels, *kernel_size", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConvTranspose2d.reset_parameters": [[187, 189], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.WeightNormConvTranspose2d.forward": [[190, 238], ["WeightNorm.WeightNormConvTranspose2d.V.data.copy_", "x_init.tranpose().contiguous().view", "WeightNorm.WeightNormConvTranspose2d.g.data.copy_", "WeightNorm.WeightNormConvTranspose2d.b.data.copy_", "scale_init.view", "m_init.view", "WeightNorm.WeightNormConvTranspose2d.V_avg.copy_", "WeightNorm.WeightNormConvTranspose2d.g_avg.copy_", "WeightNorm.WeightNormConvTranspose2d.b_avg.copy_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "WeightNorm.get_vars_maybe_avg", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view().expand_as", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "x_init.tranpose().contiguous().view.mean().squeeze", "x_init.tranpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "scalar.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x_init.tranpose().contiguous", "m_init.view.expand_as", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view", "x_init.tranpose().contiguous().view.mean", "x_init.tranpose().contiguous().view.var", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "scalar.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.tranpose", "len", "len", "V.transpose().contiguous().view", "WeightNorm.WeightNormConvTranspose2d.V.data.size", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm", "x_init.size", "x_init.size", "len", "V.transpose().contiguous", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view", "len", "V.transpose", "V.size", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# in_channels, out_channels, *kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "V_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "len", "(", "self", ".", "kernel_size", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv_transpose2d", "(", "\n", "x", ",", "Variable", "(", "V_norm", ")", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "self", ".", "groups", ")", ".", "data", "\n", "# self.out_channels, 1", "\n", "t_x_init", "=", "x_init", ".", "tranpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "Variable", "(", "x_init", ")", "\n", "", "else", ":", "\n", "            ", "V", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "V", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "W", "=", "scalar", ".", "view", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "(", "len", "(", "V", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", ".", "expand_as", "(", "V", ")", "*", "V", "\n", "\n", "x", "=", "F", ".", "conv_transpose2d", "(", "x", ",", "W", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "\n", "self", ".", "groups", ")", "\n", "return", "x", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.get_var_maybe_avg": [[14, 25], ["getattr", "getattr", "torch.autograd.Variable"], "function", ["None"], ["def", "get_var_maybe_avg", "(", "namespace", ",", "var_name", ",", "training", ",", "polyak_decay", ")", ":", "\n", "# utility for retrieving polyak averaged params", "\n", "# Update average", "\n", "    ", "v", "=", "getattr", "(", "namespace", ",", "var_name", ")", "\n", "v_avg", "=", "getattr", "(", "namespace", ",", "var_name", "+", "'_avg'", ")", "\n", "v_avg", "-=", "(", "1", "-", "polyak_decay", ")", "*", "(", "v_avg", "-", "v", ".", "data", ")", "\n", "\n", "if", "training", ":", "\n", "        ", "return", "v", "\n", "", "else", ":", "\n", "        ", "return", "Variable", "(", "v_avg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.get_vars_maybe_avg": [[27, 34], ["vars.append", "WeightNorm.get_var_maybe_avg"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.WeightNorm.get_var_maybe_avg"], ["", "", "def", "get_vars_maybe_avg", "(", "namespace", ",", "var_names", ",", "training", ",", "polyak_decay", ")", ":", "\n", "# utility for retrieving polyak averaged params", "\n", "    ", "vars", "=", "[", "]", "\n", "for", "vn", "in", "var_names", ":", "\n", "        ", "vars", ".", "append", "(", "get_var_maybe_avg", "(", "\n", "namespace", ",", "vn", ",", "training", ",", "polyak_decay", ")", ")", "\n", "", "return", "vars", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Bottle.forward": [[6, 12], ["super().forward", "super().forward.contiguous().view", "len", "super().forward", "input.size", "input.view", "input.size", "super().forward.contiguous"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.forward", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.forward"], ["        ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "            ", "if", "len", "(", "input", ".", "size", "(", ")", ")", "<=", "2", ":", "\n", "                ", "return", "super", "(", "Bottle", ",", "self", ")", ".", "forward", "(", "input", ")", "\n", "", "size", "=", "input", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "out", "=", "super", "(", "Bottle", ",", "self", ")", ".", "forward", "(", "input", ".", "view", "(", "size", "[", "0", "]", "*", "size", "[", "1", "]", ",", "-", "1", ")", ")", "\n", "return", "out", ".", "contiguous", "(", ")", ".", "view", "(", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Bottle2.forward": [[15, 22], ["input.size", "super().forward", "super().forward.contiguous().view", "len", "super().forward", "input.view", "input.size", "super().forward.contiguous"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.forward", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.forward"], ["        ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "            ", "if", "len", "(", "input", ".", "size", "(", ")", ")", "<=", "3", ":", "\n", "                ", "return", "super", "(", "Bottle2", ",", "self", ")", ".", "forward", "(", "input", ")", "\n", "", "size", "=", "input", ".", "size", "(", ")", "\n", "out", "=", "super", "(", "Bottle2", ",", "self", ")", ".", "forward", "(", "input", ".", "view", "(", "size", "[", "0", "]", "*", "size", "[", "1", "]", ",", "\n", "size", "[", "2", "]", ",", "size", "[", "3", "]", ")", ")", "\n", "return", "out", ".", "contiguous", "(", ")", ".", "view", "(", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "size", "[", "2", "]", ",", "size", "[", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.LayerNorm.__init__": [[27, 33], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["def", "__init__", "(", "self", ",", "d_hid", ",", "eps", "=", "1e-3", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "d_hid", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "d_hid", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.LayerNorm.forward": [[34, 47], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.std", "torch.std", "torch.std", "torch.std", "z.size", "mu.unsqueeze.unsqueeze.dim", "mu.unsqueeze.unsqueeze.unsqueeze", "sigma.unsqueeze.unsqueeze.unsqueeze", "ln_out.mul", "UtilClass.LayerNorm.b_2.expand_as", "mu.unsqueeze.unsqueeze.expand_as", "sigma.unsqueeze.unsqueeze.expand_as", "UtilClass.LayerNorm.a_2.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ")", ":", "\n", "        ", "if", "z", ".", "size", "(", "1", ")", "==", "1", ":", "\n", "            ", "return", "z", "\n", "", "mu", "=", "torch", ".", "mean", "(", "z", ",", "dim", "=", "1", ")", "\n", "sigma", "=", "torch", ".", "std", "(", "z", ",", "dim", "=", "1", ")", "\n", "# HACK. PyTorch is changing behavior", "\n", "if", "mu", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "mu", "=", "mu", ".", "unsqueeze", "(", "1", ")", "\n", "sigma", "=", "sigma", ".", "unsqueeze", "(", "1", ")", "\n", "", "ln_out", "=", "(", "z", "-", "mu", ".", "expand_as", "(", "z", ")", ")", "/", "(", "sigma", ".", "expand_as", "(", "z", ")", "+", "self", ".", "eps", ")", "\n", "ln_out", "=", "ln_out", ".", "mul", "(", "self", ".", "a_2", ".", "expand_as", "(", "ln_out", ")", ")", "+", "self", ".", "b_2", ".", "expand_as", "(", "ln_out", ")", "\n", "return", "ln_out", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.__init__": [[72, 76], ["torch.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__"], ["def", "__init__", "(", "self", ",", "merge", "=", "None", ",", "*", "args", ")", ":", "\n", "        ", "assert", "merge", "in", "[", "None", ",", "'first'", ",", "'concat'", ",", "'sum'", ",", "'mlp'", "]", "\n", "self", ".", "merge", "=", "merge", "\n", "super", "(", "Elementwise", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.UtilClass.Elementwise.forward": [[77, 89], ["feat.squeeze", "len", "len", "f", "input.split", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "inputs", "=", "[", "feat", ".", "squeeze", "(", "2", ")", "for", "feat", "in", "input", ".", "split", "(", "1", ",", "dim", "=", "2", ")", "]", "\n", "assert", "len", "(", "self", ")", "==", "len", "(", "inputs", ")", "\n", "outputs", "=", "[", "f", "(", "x", ")", "for", "f", ",", "x", "in", "zip", "(", "self", ",", "inputs", ")", "]", "\n", "if", "self", ".", "merge", "==", "'first'", ":", "\n", "            ", "return", "outputs", "[", "0", "]", "\n", "", "elif", "self", ".", "merge", "==", "'concat'", "or", "self", ".", "merge", "==", "'mlp'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "2", ")", "\n", "", "elif", "self", ".", "merge", "==", "'sum'", ":", "\n", "            ", "return", "sum", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "return", "outputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.embed_regularize.embedded_dropout": [[6, 26], ["embed._backend.Embedding.apply", "torch.autograd.Variable", "embed.weight.data.new().resize_().bernoulli_().expand_as", "scale.expand_as", "embed.weight.data.new().resize_().bernoulli_", "embed.weight.data.new().resize_", "embed.weight.data.new", "embed.weight.size"], "function", ["None"], ["def", "embedded_dropout", "(", "embed", ",", "words", ",", "dropout", "=", "0.1", ",", "scale", "=", "None", ")", ":", "\n", "    ", "if", "dropout", ":", "\n", "        ", "mask", "=", "embed", ".", "weight", ".", "data", ".", "new", "(", ")", ".", "resize_", "(", "(", "embed", ".", "weight", ".", "size", "(", "0", ")", ",", "1", ")", ")", ".", "bernoulli_", "(", "\n", "1", "-", "dropout", ")", ".", "expand_as", "(", "embed", ".", "weight", ")", "/", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "mask", ")", "\n", "masked_embed_weight", "=", "mask", "*", "embed", ".", "weight", "\n", "", "else", ":", "\n", "        ", "masked_embed_weight", "=", "embed", ".", "weight", "\n", "", "if", "scale", ":", "\n", "        ", "masked_embed_weight", "=", "scale", ".", "expand_as", "(", "\n", "masked_embed_weight", ")", "*", "masked_embed_weight", "\n", "\n", "", "padding_idx", "=", "embed", ".", "padding_idx", "\n", "if", "padding_idx", "is", "None", ":", "\n", "        ", "padding_idx", "=", "-", "1", "\n", "", "X", "=", "embed", ".", "_backend", ".", "Embedding", ".", "apply", "(", "words", ",", "masked_embed_weight", ",", "\n", "padding_idx", ",", "embed", ".", "max_norm", ",", "embed", ".", "norm_type", ",", "\n", "embed", ".", "scale_grad_by_freq", ",", "embed", ".", "sparse", "\n", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.opts.model_opts": [[4, 78], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["\n", "# Model options", "\n", "# Embedding Options", "\n", "parser", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "\n", "help", "=", "'Word embedding for both.'", ")", "\n", "parser", ".", "add_argument", "(", "'-ent_vec_size'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'POS embedding size.'", ")", "\n", "\n", "# RNN Options", "\n", "parser", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'brnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "'Type of decoder layer to use.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "parser", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "parser", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "250", ",", "\n", "help", "=", "'Size of LSTM hidden states'", ")", "\n", "parser", ".", "add_argument", "(", "'-score_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Size of hidden layer in scorer'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", "]", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-brnn_merge'", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", "]", ",", "\n", "help", "=", "\"Merge action for the bidir hidden states\"", ")", "\n", "\n", "# Table encoding options", "\n", "parser", ".", "add_argument", "(", "'-split_type'", ",", "default", "=", "'incell'", ",", "\n", "choices", "=", "[", "'incell'", ",", "'outcell'", "]", ",", "\n", "help", "=", "\"whether encode column split token |\"", ")", "\n", "parser", ".", "add_argument", "(", "'-merge_type'", ",", "default", "=", "'cat'", ",", "\n", "choices", "=", "[", "'sub'", ",", "'cat'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"compute span vector for table column: mlp>cat>sub\"", ")", "\n", "\n", "# Decoder options", "\n", "parser", ".", "add_argument", "(", "'-layout_encode'", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'none'", ",", "'rnn'", "]", ",", "\n", "help", "=", "\"Layout encoding method.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-cond_op_vec_size'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "\n", "help", "=", "'Layout embedding size.'", ")", "\n", "\n", "# Attention options", "\n", "parser", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                        dotprot or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-attn_hidden'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "\"if attn_hidden > 0, then attention score = f(Ue) B f(Ud)\"", ")", "\n", "parser", ".", "add_argument", "(", "'-co_attention'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if attn_hidden > 0, then attention score = f(Ue) B f(Ud)\"", ")", "\n", "\n", "\n", "", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "# Dictionary Options", "\n", "    ", "parser", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "# Truncation options", "\n", "parser", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "parser", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.opts.preprocess_opts": [[80, 107], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["help", "=", "\"Truncate target sequence length.\"", ")", "\n", "\n", "# Data processing options", "\n", "parser", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "parser", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-span_exact_match'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Must have exact match for cond span in WHERE clause'", ")", "\n", "\n", "\n", "", "def", "train_opts", "(", "parser", ")", ":", "\n", "# Model loading/saving options", "\n", "    ", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "''", ",", "\n", "help", "=", "\"\"\"Path prefix to the \"train.pt\" and\n                        \"valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-save_dir'", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Model save dir\"", ")", "\n", "parser", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                        path to the pretrained model's state_dict.\"\"\"", ")", "\n", "# GPU", "\n", "parser", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "0", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Use CUDA on the listed devices.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "123", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                        reproducibility.\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.opts.train_opts": [[109, 187], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["parser", ".", "add_argument", "(", "'-start_epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'The epoch from which to start'", ")", "\n", "parser", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.08", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                        with support (-param_init, param_init).\n                        Use 0 to not use initialization\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-fix_word_vecs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-update_word_vecs_after'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'When fix_word_vecs=True, only update word vectors after update_word_vecs_after epochs.'", ")", "\n", "parser", ".", "add_argument", "(", "'-agg_sample_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'Randomly skip agg loss, because this loss term tends to be overfitting.'", ")", "\n", "\n", "# Optimization options", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "'Maximum batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "40", ",", "\n", "help", "=", "'Number of training epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'-optim'", ",", "default", "=", "'rmsprop'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "\n", "'adadelta'", ",", "'adam'", ",", "'rmsprop'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                        renormalize it to have the norm equal to\n                        max_grad_norm\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"Dropout rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-lock_dropout'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use the same dropout mask for RNNs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-weight_dropout'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\">0: Weight dropout probability; applied in LSTM stacks.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-smooth_eps'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Label smoothing\"", ")", "\n", "# learning rate", "\n", "parser", ".", "add_argument", "(", "'-learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.002", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.95", ",", "\n", "help", "=", "\"Optimization hyperparameter\"", ")", "\n", "parser", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.98", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by this much if (i) perplexity does not decrease on the validation set or (ii) epoch has gone past start_decay_at\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-start_decay_at'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"\"\"Start decaying every epoch after and including this epoch\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-start_checkpoint_at'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"\"\"Start checkpointing every epoch after and including this epoch\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "\n", "\n", "", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-model_path'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file'", ")", "\n", "parser", ".", "add_argument", "(", "'-data_path'", ",", "default", "=", "''", ",", "\n", "help", "=", "'Path to data'", ")", "\n", "parser", ".", "add_argument", "(", "'-split'", ",", "default", "=", "\"dev\"", ",", "\n", "help", "=", "\"Path to the evaluation annotated data\"", ")", "\n", "parser", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will be the decoded sequence\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "parser", ".", "add_argument", "(", "'-gold_layout'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Given the golden layout sequences for evaluation.\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.opts.translate_opts": [[189, 218], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.evaluate.main": [[23, 68], ["argparse.ArgumentParser", "opts.model_opts", "opts.train_opts", "table.IO.read_anno_json", "table.IO.read_anno_json", "glob.glob", "argparse.ArgumentParser.parse_known_args", "print", "print", "table.Translator", "table.Translator", "table.IO.TableDataset", "table.IO.TableDataset", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "r_list.sort", "zip", "print", "table.Translator.translate", "len", "len", "len", "len", "pred.eval", "sum", "print", "codecs.open", "f_out.write", "len", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.model_opts", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.train_opts", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.translate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ParseResult.ParseResult.eval"], ["\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'evaluate.py'", ")", "\n", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "opt", ".", "anno", "=", "os", ".", "path", ".", "join", "(", "\n", "opt", ".", "data_path", ",", "'annotated_ent/{}.jsonl'", ".", "format", "(", "opt", ".", "split", ")", ")", "\n", "opt", ".", "source_file", "=", "os", ".", "path", ".", "join", "(", "\n", "opt", ".", "data_path", ",", "'data/{}.jsonl'", ".", "format", "(", "opt", ".", "split", ")", ")", "\n", "opt", ".", "db_file", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "'data/{}.db'", ".", "format", "(", "opt", ".", "split", ")", ")", "\n", "opt", ".", "pre_word_vecs", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "'embedding'", ")", "\n", "\n", "\n", "def", "main", "(", ")", ":", "\n", "    ", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "opts", ".", "train_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "\n", "engine", "=", "DBEngine", "(", "opt", ".", "db_file", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "opt", ".", "source_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "        ", "sql_list", "=", "[", "json", ".", "loads", "(", "line", ")", "[", "'sql'", "]", "for", "line", "in", "corpus_file", "]", "\n", "\n", "", "js_list", "=", "table", ".", "IO", ".", "read_anno_json", "(", "opt", ".", "anno", ")", "\n", "\n", "prev_best", "=", "(", "None", ",", "None", ")", "\n", "for", "fn_model", "in", "glob", ".", "glob", "(", "opt", ".", "model_path", ")", ":", "\n", "        ", "print", "(", "fn_model", ")", "\n", "print", "(", "opt", ".", "anno", ")", "\n", "opt", ".", "model", "=", "fn_model", "\n", "\n", "translator", "=", "table", ".", "Translator", "(", "opt", ",", "dummy_opt", ".", "__dict__", ")", "\n", "data", "=", "table", ".", "IO", ".", "TableDataset", "(", "js_list", ",", "translator", ".", "fields", ",", "None", ",", "False", ")", "\n", "test_data", "=", "table", ".", "IO", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "device", "=", "opt", ".", "gpu", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "train", "=", "False", ",", "sort", "=", "True", ",", "sort_within_batch", "=", "False", ")", "\n", "\n", "# inference", "\n", "r_list", "=", "[", "]", "\n", "for", "batch", "in", "test_data", ":", "\n", "            ", "r_list", "+=", "translator", ".", "translate", "(", "batch", ")", "\n", "", "r_list", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "idx", ")", "\n", "assert", "len", "(", "r_list", ")", "==", "len", "(", "js_list", ")", ",", "'len(r_list) != len(js_list): {} != {}'", ".", "format", "(", "\n", "len", "(", "r_list", ")", ",", "len", "(", "js_list", ")", ")", "\n", "\n", "# evaluation", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.train.get_save_index": [[21, 29], ["path.Path().exists", "path.Path", "os.path.join"], "function", ["None"], ["def", "get_save_index", "(", "save_dir", ")", ":", "\n", "    ", "save_index", "=", "0", "\n", "while", "True", ":", "\n", "        ", "if", "Path", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'run.%d'", "%", "(", "save_index", ",", ")", ")", ")", ".", "exists", "(", ")", ":", "\n", "            ", "save_index", "+=", "1", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "save_index", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.train.report_func": [[63, 84], ["table.Statistics.output", "table.Statistics", "table.Statistics", "table.Statistics", "table.Statistics"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.output"], ["    ", "\"\"\"\n    This is the user-defined batch-level traing progress\n    report function.\n\n    Args:\n        epoch(int): current epoch count.\n        batch(int): current batch count.\n        num_batches(int): total number of batches.\n        start_time(float): last report time.\n        lr(float): current learning rate.\n        report_stats(Statistics): old Statistics instance.\n    Returns:\n        report_stats(Statistics): updated Statistics instance.\n    \"\"\"", "\n", "if", "batch", "%", "opt", ".", "report_every", "==", "-", "1", "%", "opt", ".", "report_every", ":", "\n", "        ", "report_stats", ".", "output", "(", "epoch", ",", "batch", "+", "1", ",", "num_batches", ",", "start_time", ")", "\n", "report_stats", "=", "table", ".", "Statistics", "(", "0", ",", "{", "}", ")", "\n", "\n", "", "return", "report_stats", "\n", "\n", "\n", "", "def", "train_model", "(", "model", ",", "train_data", ",", "valid_data", ",", "fields", ",", "optim", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.train.train_model": [[86, 125], ["table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Trainer", "table.Trainer", "table.Trainer", "table.Trainer", "range", "print", "table.Trainer.train", "print", "table.Trainer.validate", "print", "table.Trainer.epoch_step", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Trainer.drop_checkpoint", "model.q_encoder.embeddings.set_update", "model.q_encoder.embeddings.set_update", "trainer.train.accuracy", "trainer.validate.accuracy"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.train", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.validate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.epoch_step", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.drop_checkpoint", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.set_update", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.set_update", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy"], ["dataset", "=", "train_data", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "device", "=", "opt", ".", "gpuid", "[", "0", "]", ",", "repeat", "=", "False", ")", "\n", "valid_iter", "=", "table", ".", "IO", ".", "OrderedIterator", "(", "\n", "dataset", "=", "valid_data", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "device", "=", "opt", ".", "gpuid", "[", "0", "]", ",", "train", "=", "False", ",", "sort", "=", "True", ",", "sort_within_batch", "=", "False", ")", "\n", "\n", "train_loss", "=", "table", ".", "Loss", ".", "TableLossCompute", "(", "opt", ".", "agg_sample_rate", ",", "smooth_eps", "=", "model", ".", "opt", ".", "smooth_eps", ")", ".", "cuda", "(", ")", "\n", "valid_loss", "=", "table", ".", "Loss", ".", "TableLossCompute", "(", "opt", ".", "agg_sample_rate", ",", "smooth_eps", "=", "model", ".", "opt", ".", "smooth_eps", ")", ".", "cuda", "(", ")", "\n", "\n", "trainer", "=", "table", ".", "Trainer", "(", "model", ",", "train_iter", ",", "valid_iter", ",", "\n", "train_loss", ",", "valid_loss", ",", "optim", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "opt", ".", "start_epoch", ",", "opt", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "print", "(", "''", ")", "\n", "\n", "if", "opt", ".", "fix_word_vecs", ":", "\n", "            ", "if", "(", "epoch", ">=", "opt", ".", "update_word_vecs_after", ")", ":", "\n", "                ", "model", ".", "q_encoder", ".", "embeddings", ".", "set_update", "(", "True", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "q_encoder", ".", "embeddings", ".", "set_update", "(", "False", ")", "\n", "\n", "# 1. Train for one epoch on the training set.", "\n", "", "", "train_stats", "=", "trainer", ".", "train", "(", "epoch", ",", "report_func", ")", "\n", "print", "(", "'Train accuracy: %s'", "%", "train_stats", ".", "accuracy", "(", "True", ")", ")", "\n", "\n", "# 2. Validate on the validation set.", "\n", "valid_stats", "=", "trainer", ".", "validate", "(", ")", "\n", "print", "(", "'Validation accuracy: %s'", "%", "valid_stats", ".", "accuracy", "(", "True", ")", ")", "\n", "\n", "# 3. Log to remote server.", "\n", "# train_stats.log(\"train\", logger, optim.lr, epoch)", "\n", "# valid_stats.log(\"valid\", logger, optim.lr, epoch)", "\n", "\n", "# 4. Update the learning rate", "\n", "trainer", ".", "epoch_step", "(", "None", ",", "epoch", ")", "\n", "\n", "# 5. Drop a checkpoint if needed.", "\n", "if", "epoch", ">=", "opt", ".", "start_checkpoint_at", ":", "\n", "            ", "trainer", ".", "drop_checkpoint", "(", "opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", "\n", "\n", "\n", "", "", "", "def", "load_fields", "(", "train", ",", "valid", ",", "checkpoint", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.train.load_fields": [[127, 140], ["table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "dict", "torch.load", "torch.load", "print", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "os.path.join", "table.IO.TableDataset.load_fields.items"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields"], ["torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'vocab.pt'", ")", ")", ")", "\n", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "train", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "train", ".", "fields", "=", "fields", "\n", "valid", ".", "fields", "=", "fields", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading vocab from checkpoint at %s.'", "%", "opt", ".", "train_from", ")", "\n", "fields", "=", "table", ".", "IO", ".", "TableDataset", ".", "load_fields", "(", "checkpoint", "[", "'vocab'", "]", ")", "\n", "\n", "", "return", "fields", "\n", "\n", "\n", "", "def", "build_model", "(", "model_opt", ",", "fields", ",", "checkpoint", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.train.build_model": [[142, 149], ["print", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "print"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model"], ["model", "=", "table", ".", "ModelConstructor", ".", "make_base_model", "(", "\n", "model_opt", ",", "fields", ",", "checkpoint", ")", "\n", "print", "(", "model", ")", "\n", "\n", "return", "model", "\n", "\n", "\n", "", "def", "build_optim", "(", "model", ",", "checkpoint", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.train.build_optim": [[151, 169], ["table.Optim.set_parameters", "print", "table.Optim.optimizer.load_state_dict", "table.Optim", "table.Optim", "table.Optim", "table.Optim", "model.parameters", "checkpoint[].optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.set_parameters"], ["        ", "print", "(", "'Loading optimizer from checkpoint.'", ")", "\n", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "'optim'", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "", "else", ":", "\n", "# what members of opt does Optim need?", "\n", "        ", "optim", "=", "table", ".", "Optim", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "alpha", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", ",", "\n", "opt", "=", "opt", "\n", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "return", "optim", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.train.main": [[171, 202], ["print", "torch.load", "torch.load", "torch.load", "torch.load", "print", "print", "train.load_fields", "train.build_model", "train.build_optim", "train.train_model", "os.path.join", "os.path.join", "print", "torch.load", "torch.load", "len"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.build_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.build_optim", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.train_model"], ["    ", "print", "(", "\"Loading train and validate data from '%s'\"", "%", "opt", ".", "data", ")", "\n", "train", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'train.pt'", ")", ")", "\n", "valid", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'valid.pt'", ")", ")", "\n", "print", "(", "' * number of training sentences: %d'", "%", "len", "(", "train", ")", ")", "\n", "print", "(", "' * maximum batch size: %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "\n", "opt", ".", "train_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "# I don't like reassigning attributes of opt: it's not clear", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "", "fields", "=", "load_fields", "(", "train", ",", "valid", ",", "checkpoint", ")", "\n", "\n", "# Build model.", "\n", "model", "=", "build_model", "(", "model_opt", ",", "fields", ",", "checkpoint", ")", "\n", "\n", "# Build optimizer.", "\n", "optim", "=", "build_optim", "(", "model", ",", "checkpoint", ")", "\n", "\n", "# Do training.", "\n", "train_model", "(", "model", ",", "train", ",", "valid", ",", "fields", ",", "optim", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.preprocess.main": [[39, 79], ["table.IO.read_anno_json", "table.IO.read_anno_json", "print", "table.IO.TableDataset.get_fields", "table.IO.TableDataset.get_fields", "print", "table.IO.TableDataset", "table.IO.TableDataset", "path.Path().exists", "path.Path().exists", "print", "table.IO.TableDataset.build_vocab", "table.IO.TableDataset.build_vocab", "print", "torch.save", "torch.save", "path.Path().exists", "path.Path().exists", "print", "table.IO.TableDataset", "table.IO.TableDataset", "print", "table.IO.TableDataset", "table.IO.TableDataset", "table.IO.TableDataset.save_vocab", "table.IO.TableDataset.save_vocab", "open", "open", "torch.save", "torch.save", "path.Path", "path.Path", "os.path.join", "os.path.join", "path.Path", "open", "path.Path", "open", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.get_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.get_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.build_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.build_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab"], ["\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "set_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "\n", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "'Preparing training ...'", ")", "\n", "fields", "=", "table", ".", "IO", ".", "TableDataset", ".", "get_fields", "(", ")", "\n", "print", "(", "\"Building Training...\"", ")", "\n", "train", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "train_anno", ",", "fields", ",", "opt", ",", "True", ")", "\n", "\n", "print", "(", "\"Building Valid...\"", ")", "\n", "valid", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "valid_anno", ",", "fields", ",", "opt", ",", "True", ")", "\n", "\n", "print", "(", "\"Building Test...\"", ")", "\n", "test", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "test_anno", ",", "fields", ",", "opt", ",", "False", ")", "\n", "\n", "print", "(", "\"Building Vocab...\"", ")", "\n", "table", ".", "IO", ".", "TableDataset", ".", "build_vocab", "(", "train", ",", "valid", ",", "test", ",", "opt", ")", "\n", "\n", "print", "(", "\"Saving train/valid/fields\"", ")", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "torch", ".", "save", "(", "table", ".", "IO", ".", "TableDataset", ".", "save_vocab", "(", "fields", ")", ",", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'vocab.pt'", ")", ",", "'wb'", ")", ")", "\n", "train", ".", "fields", "=", "[", "]", "\n", "valid", ".", "fields", "=", "[", "]", "\n", "torch", ".", "save", "(", "train", ",", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'train.pt'", ")", ",", "'wb'", ")", ")", "\n", "torch", ".", "save", "(", "valid", ",", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'valid.pt'", ")", ",", "'wb'", ")", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.__init__": [[12, 25], ["isinstance", "tree.SCode.set_by_list", "isinstance", "tree.SCode.set_by_list", "isinstance", "tree.SCode.set_by_str"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.set_by_list", "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.set_by_list", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.set_by_str"], ["    ", "def", "__init__", "(", "self", ",", "init", ")", ":", "\n", "        ", "self", ".", "token_list", "=", "None", "\n", "self", ".", "type_list", "=", "None", "\n", "\n", "if", "init", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "init", ",", "list", ")", ":", "\n", "                ", "self", ".", "set_by_list", "(", "init", ",", "None", ")", "\n", "", "elif", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "                ", "self", ".", "set_by_list", "(", "init", "[", "0", "]", ",", "init", "[", "1", "]", ")", "\n", "", "elif", "isinstance", "(", "init", ",", "six", ".", "string_types", ")", ":", "\n", "                ", "self", ".", "set_by_str", "(", "init", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.set_by_str": [[26, 31], ["list", "tokenize.tokenize.tokenize", "io.BytesIO", "f.strip().encode", "f.strip"], "methods", ["None"], ["", "", "", "def", "set_by_str", "(", "self", ",", "f", ")", ":", "\n", "        ", "tk_list", "=", "list", "(", "\n", "tokenize", "(", "BytesIO", "(", "f", ".", "strip", "(", ")", ".", "encode", "(", "'utf-8'", ")", ")", ".", "readline", ")", ")", "[", "1", ":", "-", "1", "]", "\n", "self", ".", "token_list", "=", "[", "tk", ".", "string", "for", "tk", "in", "tk_list", "]", "\n", "self", ".", "type_list", "=", "[", "token", ".", "tok_name", "[", "tk", ".", "type", "]", "for", "tk", "in", "tk_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.set_by_list": [[33, 37], ["list", "list"], "methods", ["None"], ["", "def", "set_by_list", "(", "self", ",", "token_list", ",", "type_list", ")", ":", "\n", "        ", "self", ".", "token_list", "=", "list", "(", "token_list", ")", "\n", "if", "type_list", "is", "not", "None", ":", "\n", "            ", "self", ".", "type_list", "=", "list", "(", "type_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.to_list": [[38, 40], ["None"], "methods", ["None"], ["", "", "def", "to_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "token_list", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.__str__": [[41, 43], ["tree.SCode.to_list"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.to_list"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "self", ".", "to_list", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.layout": [[44, 65], ["zip", "len", "len", "r_list.append", "r_list.append", "tk.split", "r_list.extend", "r_list.append", "range", "len"], "methods", ["None"], ["", "def", "layout", "(", "self", ",", "add_skip", "=", "False", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "token_list", ")", "==", "len", "(", "self", ".", "type_list", ")", "\n", "r_list", "=", "[", "]", "\n", "for", "tk", ",", "tp", "in", "zip", "(", "self", ".", "token_list", ",", "self", ".", "type_list", ")", ":", "\n", "            ", "if", "tp", "in", "(", "'OP'", ",", "'KEYWORD'", ")", ":", "\n", "                ", "r_list", ".", "append", "(", "tk", ")", "\n", "", "elif", "tp", "in", "(", "'STRING'", ",", ")", ":", "\n", "                ", "if", "add_skip", ":", "\n", "                    ", "s_list", "=", "tk", ".", "split", "(", "' '", ")", "\n", "r_list", ".", "extend", "(", "\n", "[", "LFT_WORD", "]", "+", "[", "SKP_WORD", "for", "__", "in", "range", "(", "len", "(", "s_list", ")", "-", "2", ")", "]", "+", "[", "RIG_WORD", "]", ")", "\n", "", "else", ":", "\n", "                    ", "r_list", ".", "append", "(", "tp", ")", "\n", "# elif tp in ('NAME', 'NUMBER'):", "\n", "#     if add_skip:", "\n", "#         r_list.append(SKP_WORD)", "\n", "#     else:", "\n", "#         r_list.append(tp)", "\n", "", "", "else", ":", "\n", "                ", "r_list", ".", "append", "(", "tp", ")", "\n", "", "", "return", "r_list", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.target": [[66, 76], ["zip", "len", "len", "tk.split", "r_list.extend", "r_list.append"], "methods", ["None"], ["", "def", "target", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "token_list", ")", "==", "len", "(", "self", ".", "type_list", ")", "\n", "r_list", "=", "[", "]", "\n", "for", "tk", ",", "tp", "in", "zip", "(", "self", ".", "token_list", ",", "self", ".", "type_list", ")", ":", "\n", "            ", "if", "tp", "in", "(", "'STRING'", ",", ")", ":", "\n", "                ", "s_list", "=", "tk", ".", "split", "(", "' '", ")", "\n", "r_list", ".", "extend", "(", "[", "LFT_WORD", "]", "+", "s_list", "[", "1", ":", "-", "1", "]", "+", "[", "RIG_WORD", "]", ")", "\n", "", "else", ":", "\n", "                ", "r_list", ".", "append", "(", "tk", ")", "\n", "", "", "return", "r_list", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.SCode.norm": [[77, 79], ["None"], "methods", ["None"], ["", "def", "norm", "(", "self", ",", "not_layout", "=", "False", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.django.tree.is_code_eq": [[81, 101], ["isinstance", "isinstance", "str", "str", "len", "len", "zip", "str.split", "str.split"], "function", ["None"], ["", "", "def", "is_code_eq", "(", "t1", ",", "t2", ",", "not_layout", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "t1", ",", "SCode", ")", ":", "\n", "        ", "t1", "=", "str", "(", "t1", ")", "\n", "", "else", ":", "\n", "        ", "t1", "=", "' '", ".", "join", "(", "t1", ")", "\n", "", "if", "isinstance", "(", "t2", ",", "SCode", ")", ":", "\n", "        ", "t2", "=", "str", "(", "t2", ")", "\n", "", "else", ":", "\n", "        ", "t2", "=", "' '", ".", "join", "(", "t2", ")", "\n", "", "t1", "=", "[", "'\\\"'", "if", "it", "in", "(", "RIG_WORD", ",", "LFT_WORD", ")", "else", "it", "for", "it", "in", "t1", ".", "split", "(", "' '", ")", "]", "\n", "t2", "=", "[", "'\\\"'", "if", "it", "in", "(", "RIG_WORD", ",", "LFT_WORD", ")", "else", "it", "for", "it", "in", "t2", ".", "split", "(", "' '", ")", "]", "\n", "if", "len", "(", "t1", ")", "==", "len", "(", "t2", ")", ":", "\n", "        ", "for", "tk1", ",", "tk2", "in", "zip", "(", "t1", ",", "t2", ")", ":", "\n", "# if not (tk1 == tk2 or tk1 == '<unk>' or tk2 == '<unk>'):", "\n", "            ", "if", "tk1", "!=", "tk2", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "", "return", "t1", "==", "t2", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.model_opts": [[4, 77], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["\n", "# Model options", "\n", "# Embedding Options", "\n", "parser", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "\n", "help", "=", "'Word embedding for both.'", ")", "\n", "parser", ".", "add_argument", "(", "'-ent_vec_size'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'POS embedding size.'", ")", "\n", "\n", "# RNN Options", "\n", "parser", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'brnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "'Type of decoder layer to use.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "parser", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "parser", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "250", ",", "\n", "help", "=", "'Size of LSTM hidden states'", ")", "\n", "parser", ".", "add_argument", "(", "'-score_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Size of hidden layer in scorer'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", "]", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-brnn_merge'", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", "]", ",", "\n", "help", "=", "\"Merge action for the bidir hidden states\"", ")", "\n", "\n", "# Table encoding options", "\n", "parser", ".", "add_argument", "(", "'-split_type'", ",", "default", "=", "'incell'", ",", "\n", "choices", "=", "[", "'incell'", ",", "'outcell'", "]", ",", "\n", "help", "=", "\"whether encode column split token |\"", ")", "\n", "parser", ".", "add_argument", "(", "'-merge_type'", ",", "default", "=", "'cat'", ",", "\n", "choices", "=", "[", "'sub'", ",", "'cat'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"compute span vector for table column: mlp>cat>sub\"", ")", "\n", "\n", "# Decoder options", "\n", "parser", ".", "add_argument", "(", "'-layout_encode'", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'none'", ",", "'rnn'", "]", ",", "\n", "help", "=", "\"Layout encoding method.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-cond_op_vec_size'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "\n", "help", "=", "'Layout embedding size.'", ")", "\n", "\n", "# Attention options", "\n", "parser", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                        dotprot or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-attn_hidden'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "\"if attn_hidden > 0, then attention score = f(Ue) B f(Ud)\"", ")", "\n", "parser", ".", "add_argument", "(", "'-co_attention'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if attn_hidden > 0, then attention score = f(Ue) B f(Ud)\"", ")", "\n", "\n", "\n", "", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "# Dictionary Options", "\n", "    ", "parser", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "# Truncation options", "\n", "parser", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "parser", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.preprocess_opts": [[79, 109], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["parser", ".", "add_argument", "(", "'-tgt_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "\n", "# Data processing options", "\n", "parser", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "parser", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-span_exact_match'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Must have exact match for cond span in WHERE clause'", ")", "\n", "\n", "\n", "", "def", "train_opts", "(", "parser", ")", ":", "\n", "# Model loading/saving options", "\n", "    ", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "''", ",", "\n", "help", "=", "\"\"\"Path prefix to the \"train.pt\" and\n                        \"valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-save_dir'", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Model save dir\"", ")", "\n", "parser", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                        path to the pretrained model's state_dict.\"\"\"", ")", "\n", "# GPU", "\n", "parser", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "0", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Use CUDA on the listed devices.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "123", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                        reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "parser", ".", "add_argument", "(", "'-start_epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.train_opts": [[111, 189], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["parser", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.08", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                        with support (-param_init, param_init).\n                        Use 0 to not use initialization\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-fix_word_vecs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-update_word_vecs_after'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'When fix_word_vecs=True, only update word vectors after update_word_vecs_after epochs.'", ")", "\n", "parser", ".", "add_argument", "(", "'-agg_sample_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'Randomly skip agg loss, because this loss term tends to be overfitting.'", ")", "\n", "\n", "# Optimization options", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "'Maximum batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "40", ",", "\n", "help", "=", "'Number of training epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'-optim'", ",", "default", "=", "'rmsprop'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "\n", "'adadelta'", ",", "'adam'", ",", "'rmsprop'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                        renormalize it to have the norm equal to\n                        max_grad_norm\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"Dropout rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-lock_dropout'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use the same dropout mask for RNNs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-weight_dropout'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\">0: Weight dropout probability; applied in LSTM stacks.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-smooth_eps'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Label smoothing\"", ")", "\n", "# learning rate", "\n", "parser", ".", "add_argument", "(", "'-learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.002", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.95", ",", "\n", "help", "=", "\"Optimization hyperparameter\"", ")", "\n", "parser", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.98", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by this much if (i) perplexity does not decrease on the validation set or (ii) epoch has gone past start_decay_at\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-start_decay_at'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"\"\"Start decaying every epoch after and including this epoch\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-start_checkpoint_at'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"\"\"Start checkpointing every epoch after and including this epoch\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "parser", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "\n", "\n", "", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-model_path'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file'", ")", "\n", "parser", ".", "add_argument", "(", "'-data_path'", ",", "default", "=", "''", ",", "\n", "help", "=", "'Path to data'", ")", "\n", "parser", ".", "add_argument", "(", "'-split'", ",", "default", "=", "\"dev\"", ",", "\n", "help", "=", "\"Path to the evaluation annotated data\"", ")", "\n", "parser", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will be the decoded sequence\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "parser", ".", "add_argument", "(", "'-gold_layout'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Given the golden layout sequences for evaluation.\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.translate_opts": [[191, 220], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.evaluate.get_run_epoch_by_fn": [[24, 32], ["fn_model.split", "tk.startswith", "int", "int", "tk.startswith", "tk.split"], "function", ["None"], ["parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'evaluate.py'", ")", "\n", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "opt", ".", "anno", "=", "os", ".", "path", ".", "join", "(", "\n", "opt", ".", "data_path", ",", "'annotated_ent/{}.jsonl'", ".", "format", "(", "opt", ".", "split", ")", ")", "\n", "opt", ".", "source_file", "=", "os", ".", "path", ".", "join", "(", "\n", "opt", ".", "data_path", ",", "'data/{}.jsonl'", ".", "format", "(", "opt", ".", "split", ")", ")", "\n", "opt", ".", "db_file", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "'data/{}.db'", ".", "format", "(", "opt", ".", "split", ")", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.evaluate.main": [[34, 80], ["argparse.ArgumentParser", "opts.model_opts", "opts.train_opts", "table.IO.read_anno_json", "table.IO.read_anno_json", "torch.load", "glob.glob", "argparse.ArgumentParser.parse_known_args", "print", "print", "table.Translator", "table.Translator", "table.IO.TableDataset", "table.IO.TableDataset", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "r_list.sort", "zip", "print", "table.Translator.translate", "len", "len", "len", "len", "pred.eval", "sum", "print", "codecs.open", "f_out.write", "len", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.model_opts", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.opts.train_opts", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Translator.Translator.translate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ParseResult.ParseResult.eval"], ["\n", "\n", "def", "main", "(", ")", ":", "\n", "    ", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "opts", ".", "train_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "\n", "engine", "=", "DBEngine", "(", "opt", ".", "db_file", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "opt", ".", "source_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "        ", "sql_list", "=", "[", "json", ".", "loads", "(", "line", ")", "[", "'sql'", "]", "for", "line", "in", "corpus_file", "]", "\n", "\n", "", "js_list", "=", "table", ".", "IO", ".", "read_anno_json", "(", "opt", ".", "anno", ")", "\n", "\n", "prev_best", "=", "(", "None", ",", "None", ")", "\n", "for", "fn_model", "in", "glob", ".", "glob", "(", "opt", ".", "model_path", ")", ":", "\n", "        ", "print", "(", "fn_model", ")", "\n", "print", "(", "opt", ".", "anno", ")", "\n", "opt", ".", "model", "=", "fn_model", "\n", "\n", "translator", "=", "table", ".", "Translator", "(", "opt", ",", "dummy_opt", ".", "__dict__", ")", "\n", "data", "=", "table", ".", "IO", ".", "TableDataset", "(", "js_list", ",", "translator", ".", "fields", ",", "None", ",", "False", ")", "\n", "test_data", "=", "table", ".", "IO", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "device", "=", "opt", ".", "gpu", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "train", "=", "False", ",", "sort", "=", "True", ",", "sort_within_batch", "=", "False", ")", "\n", "\n", "# inference", "\n", "r_list", "=", "[", "]", "\n", "for", "batch", "in", "test_data", ":", "\n", "            ", "r_list", "+=", "translator", ".", "translate", "(", "batch", ")", "\n", "", "r_list", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "idx", ")", "\n", "assert", "len", "(", "r_list", ")", "==", "len", "(", "js_list", ")", ",", "'len(r_list) != len(js_list): {} != {}'", ".", "format", "(", "\n", "len", "(", "r_list", ")", ",", "len", "(", "js_list", ")", ")", "\n", "\n", "# evaluation", "\n", "for", "pred", ",", "gold", ",", "sql_gold", "in", "zip", "(", "r_list", ",", "js_list", ",", "sql_list", ")", ":", "\n", "            ", "pred", ".", "eval", "(", "gold", ",", "sql_gold", ",", "engine", ")", "\n", "", "print", "(", "'Results:'", ")", "\n", "for", "metric_name", "in", "(", "'all'", ",", "'exe'", ")", ":", "\n", "            ", "c_correct", "=", "sum", "(", "(", "x", ".", "correct", "[", "metric_name", "]", "for", "x", "in", "r_list", ")", ")", "\n", "print", "(", "'{}: {} / {} = {:.2%}'", ".", "format", "(", "metric_name", ",", "c_correct", ",", "\n", "len", "(", "r_list", ")", ",", "c_correct", "/", "len", "(", "r_list", ")", ")", ")", "\n", "if", "metric_name", "==", "'all'", "and", "(", "prev_best", "[", "0", "]", "is", "None", "or", "c_correct", ">", "prev_best", "[", "1", "]", ")", ":", "\n", "                ", "prev_best", "=", "(", "fn_model", ",", "c_correct", ")", "\n", "\n", "", "", "", "if", "(", "opt", ".", "split", "==", "'dev'", ")", "and", "(", "prev_best", "[", "0", "]", "is", "not", "None", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "'dev_best.txt'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f_out", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.get_save_index": [[21, 29], ["path.Path().exists", "path.Path", "os.path.join"], "function", ["None"], ["def", "get_save_index", "(", "save_dir", ")", ":", "\n", "    ", "save_index", "=", "0", "\n", "while", "True", ":", "\n", "        ", "if", "Path", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'run.%d'", "%", "(", "save_index", ",", ")", ")", ")", ".", "exists", "(", ")", ":", "\n", "            ", "save_index", "+=", "1", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "save_index", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.report_func": [[63, 84], ["table.Statistics.output", "table.Statistics", "table.Statistics", "table.Statistics", "table.Statistics"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.output"], ["    ", "\"\"\"\n    This is the user-defined batch-level traing progress\n    report function.\n\n    Args:\n        epoch(int): current epoch count.\n        batch(int): current batch count.\n        num_batches(int): total number of batches.\n        start_time(float): last report time.\n        lr(float): current learning rate.\n        report_stats(Statistics): old Statistics instance.\n    Returns:\n        report_stats(Statistics): updated Statistics instance.\n    \"\"\"", "\n", "if", "batch", "%", "opt", ".", "report_every", "==", "-", "1", "%", "opt", ".", "report_every", ":", "\n", "        ", "report_stats", ".", "output", "(", "epoch", ",", "batch", "+", "1", ",", "num_batches", ",", "start_time", ")", "\n", "report_stats", "=", "table", ".", "Statistics", "(", "0", ",", "{", "}", ")", "\n", "\n", "", "return", "report_stats", "\n", "\n", "\n", "", "def", "train_model", "(", "model", ",", "train_data", ",", "valid_data", ",", "fields", ",", "optim", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.train_model": [[86, 125], ["table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.IO.OrderedIterator", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Loss.LossCompute().cuda", "table.Trainer", "table.Trainer", "table.Trainer", "table.Trainer", "range", "print", "table.Trainer.train", "print", "table.Trainer.validate", "print", "table.Trainer.epoch_step", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Loss.LossCompute", "table.Trainer.drop_checkpoint", "model.q_encoder.embeddings.set_update", "model.q_encoder.embeddings.set_update", "trainer.train.accuracy", "trainer.validate.accuracy"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.train", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.validate", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.epoch_step", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Trainer.drop_checkpoint", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.set_update", "home.repos.pwc.inspect_result.donglixp_coarse2fine.modules.Embeddings.PartUpdateEmbedding.set_update", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Trainer.Statistics.accuracy"], ["dataset", "=", "train_data", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "device", "=", "opt", ".", "gpuid", "[", "0", "]", ",", "repeat", "=", "False", ")", "\n", "valid_iter", "=", "table", ".", "IO", ".", "OrderedIterator", "(", "\n", "dataset", "=", "valid_data", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "device", "=", "opt", ".", "gpuid", "[", "0", "]", ",", "train", "=", "False", ",", "sort", "=", "True", ",", "sort_within_batch", "=", "False", ")", "\n", "\n", "train_loss", "=", "table", ".", "Loss", ".", "TableLossCompute", "(", "opt", ".", "agg_sample_rate", ",", "smooth_eps", "=", "model", ".", "opt", ".", "smooth_eps", ")", ".", "cuda", "(", ")", "\n", "valid_loss", "=", "table", ".", "Loss", ".", "TableLossCompute", "(", "opt", ".", "agg_sample_rate", ",", "smooth_eps", "=", "model", ".", "opt", ".", "smooth_eps", ")", ".", "cuda", "(", ")", "\n", "\n", "trainer", "=", "table", ".", "Trainer", "(", "model", ",", "train_iter", ",", "valid_iter", ",", "\n", "train_loss", ",", "valid_loss", ",", "optim", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "opt", ".", "start_epoch", ",", "opt", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "print", "(", "''", ")", "\n", "\n", "if", "opt", ".", "fix_word_vecs", ":", "\n", "            ", "if", "(", "epoch", ">=", "opt", ".", "update_word_vecs_after", ")", ":", "\n", "                ", "model", ".", "q_encoder", ".", "embeddings", ".", "set_update", "(", "True", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "q_encoder", ".", "embeddings", ".", "set_update", "(", "False", ")", "\n", "\n", "# 1. Train for one epoch on the training set.", "\n", "", "", "train_stats", "=", "trainer", ".", "train", "(", "epoch", ",", "report_func", ")", "\n", "print", "(", "'Train accuracy: %s'", "%", "train_stats", ".", "accuracy", "(", "True", ")", ")", "\n", "\n", "# 2. Validate on the validation set.", "\n", "valid_stats", "=", "trainer", ".", "validate", "(", ")", "\n", "print", "(", "'Validation accuracy: %s'", "%", "valid_stats", ".", "accuracy", "(", "True", ")", ")", "\n", "\n", "# 3. Log to remote server.", "\n", "# train_stats.log(\"train\", logger, optim.lr, epoch)", "\n", "# valid_stats.log(\"valid\", logger, optim.lr, epoch)", "\n", "\n", "# 4. Update the learning rate", "\n", "trainer", ".", "epoch_step", "(", "None", ",", "epoch", ")", "\n", "\n", "# 5. Drop a checkpoint if needed.", "\n", "if", "epoch", ">=", "opt", ".", "start_checkpoint_at", ":", "\n", "            ", "trainer", ".", "drop_checkpoint", "(", "opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", "\n", "\n", "\n", "", "", "", "def", "load_fields", "(", "train", ",", "valid", ",", "checkpoint", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields": [[127, 140], ["table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "dict", "torch.load", "torch.load", "print", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "table.IO.TableDataset.load_fields", "os.path.join", "table.IO.TableDataset.load_fields.items"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields"], ["torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'vocab.pt'", ")", ")", ")", "\n", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "train", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "train", ".", "fields", "=", "fields", "\n", "valid", ".", "fields", "=", "fields", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading vocab from checkpoint at %s.'", "%", "opt", ".", "train_from", ")", "\n", "fields", "=", "table", ".", "IO", ".", "TableDataset", ".", "load_fields", "(", "checkpoint", "[", "'vocab'", "]", ")", "\n", "\n", "", "return", "fields", "\n", "\n", "\n", "", "def", "build_model", "(", "model_opt", ",", "fields", ",", "checkpoint", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.build_model": [[142, 149], ["print", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "table.ModelConstructor.make_base_model", "print"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.ModelConstructor.make_base_model"], ["model", "=", "table", ".", "ModelConstructor", ".", "make_base_model", "(", "\n", "model_opt", ",", "fields", ",", "checkpoint", ")", "\n", "print", "(", "model", ")", "\n", "\n", "return", "model", "\n", "\n", "\n", "", "def", "build_optim", "(", "model", ",", "checkpoint", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.build_optim": [[151, 169], ["table.Optim.set_parameters", "print", "table.Optim.optimizer.load_state_dict", "table.Optim", "table.Optim", "table.Optim", "table.Optim", "model.parameters", "checkpoint[].optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.Optim.Optim.set_parameters"], ["        ", "print", "(", "'Loading optimizer from checkpoint.'", ")", "\n", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "'optim'", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "", "else", ":", "\n", "# what members of opt does Optim need?", "\n", "        ", "optim", "=", "table", ".", "Optim", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "alpha", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", ",", "\n", "opt", "=", "opt", "\n", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "return", "optim", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.main": [[171, 205], ["print", "torch.load", "torch.load", "path.Path().exists", "print", "print", "train.load_fields", "train.build_model", "train.build_optim", "train.train_model", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "print", "torch.load", "torch.load", "path.Path", "os.path.join", "os.path.join", "len", "os.path.join"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.load_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.build_model", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.build_optim", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.train.train_model"], ["    ", "print", "(", "\"Loading train and validate data from '%s'\"", "%", "opt", ".", "data", ")", "\n", "train", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'train.pt'", ")", ")", "\n", "valid", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "data", ",", "'valid.pt'", ")", ")", "\n", "print", "(", "' * number of training sentences: %d'", "%", "len", "(", "train", ")", ")", "\n", "print", "(", "' * maximum batch size: %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "\n", "opt", ".", "train_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "# I don't like reassigning attributes of opt: it's not clear", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "", "fields", "=", "load_fields", "(", "train", ",", "valid", ",", "checkpoint", ")", "\n", "\n", "# Build model.", "\n", "model", "=", "build_model", "(", "model_opt", ",", "fields", ",", "checkpoint", ")", "\n", "\n", "# Build optimizer.", "\n", "optim", "=", "build_optim", "(", "model", ",", "checkpoint", ")", "\n", "\n", "# Do training.", "\n", "train_model", "(", "model", ",", "train", ",", "valid", ",", "fields", ",", "optim", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__init__": [[8, 13], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "_in", ")", ":", "\n", "        ", "if", "isinstance", "(", "_in", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "p0", ",", "self", ".", "p1", ",", "self", ".", "type_pair", "=", "_in", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.is_match": [[14, 21], ["None"], "methods", ["None"], ["", "", "def", "is_match", "(", "self", ",", "c0", ",", "c1", ")", ":", "\n", "        ", "if", "self", ".", "type_pair", "in", "(", "PAR_CHILD_PAIR", ",", "ORD_PAIR", ")", ":", "\n", "            ", "return", "(", "self", ".", "p0", ",", "self", ".", "p1", ")", "==", "(", "c0", ",", "c1", ")", "\n", "", "elif", "self", ".", "type_pair", "==", "UNORD_PAIR", ":", "\n", "            ", "return", "(", "self", ".", "p0", ",", "self", ".", "p1", ")", "==", "(", "c0", ",", "c1", ")", "or", "(", "self", ".", "p0", ",", "self", ".", "p1", ")", "==", "(", "c1", ",", "c0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__key": [[22, 24], ["None"], "methods", ["None"], ["", "", "def", "__key", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "p0", ",", "self", ".", "p1", ",", "self", ".", "type_pair", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__hash__": [[25, 27], ["hash", "bpe.BpePair.__key"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__key"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "self", ".", "__key", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__eq__": [[28, 30], ["bpe.BpePair.__key", "other.__key"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__key", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__key"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__key", "(", ")", "==", "other", ".", "__key", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.__str__": [[31, 38], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "type_pair", "==", "PAR_CHILD_PAIR", ":", "\n", "            ", "return", "'({}|{})'", ".", "format", "(", "self", ".", "p0", ",", "self", ".", "p1", ")", ".", "replace", "(", "'('", ",", "'{'", ")", ".", "replace", "(", "')'", ",", "'}'", ")", "\n", "", "elif", "self", ".", "type_pair", "in", "(", "ORD_PAIR", ",", "UNORD_PAIR", ")", ":", "\n", "            ", "return", "'{}|{}'", ".", "format", "(", "self", ".", "p0", ",", "self", ".", "p1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpeProcessor.__init__": [[72, 75], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "bpe_list", ",", "enable", ")", ":", "\n", "        ", "self", ".", "bpe_list", "=", "bpe_list", "\n", "self", ".", "enable", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpeProcessor.process": [[76, 81], ["t.apply_bpe"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.apply_bpe"], ["", "def", "process", "(", "self", ",", "t", ")", ":", "\n", "        ", "if", "not", "self", ".", "enable", ":", "\n", "            ", "return", "\n", "", "for", "p", ",", "f", "in", "self", ".", "bpe_list", ":", "\n", "            ", "t", ".", "apply_bpe", "(", "p", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.recover_bpe": [[40, 42], ["None"], "function", ["None"], ["", "", "", "def", "recover_bpe", "(", "lay", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "lay", ")", ".", "replace", "(", "'|'", ",", "' '", ")", ".", "replace", "(", "'{'", ",", "'('", ")", ".", "replace", "(", "'}'", ",", "' )'", ")", ".", "split", "(", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.count_pair": [[44, 50], ["t.all_bpe_pairs", "c_dict.get"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.all_bpe_pairs"], ["", "def", "count_pair", "(", "t_list", ")", ":", "\n", "    ", "c_dict", "=", "{", "}", "\n", "for", "t", "in", "t_list", ":", "\n", "        ", "for", "p", "in", "t", ".", "all_bpe_pairs", "(", ")", ":", "\n", "            ", "c_dict", "[", "p", "]", "=", "c_dict", ".", "get", "(", "p", ",", "0", ")", "+", "1", "\n", "", "", "return", "c_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.merge_bpe": [[52, 55], ["t.apply_bpe"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.apply_bpe"], ["", "def", "merge_bpe", "(", "pair_best", ",", "t_list", ")", ":", "\n", "    ", "for", "t", "in", "t_list", ":", "\n", "        ", "t", ".", "apply_bpe", "(", "pair_best", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.learn_bpe": [[57, 69], ["range", "bpe.count_pair", "max", "bpe_list.append", "bpe.merge_bpe", "count_pair.items"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.count_pair", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.merge_bpe"], ["", "", "def", "learn_bpe", "(", "t_list", ",", "num_merge", ",", "min_freq", ")", ":", "\n", "    ", "bpe_list", "=", "[", "]", "\n", "for", "__", "in", "range", "(", "num_merge", ")", ":", "\n", "# get frequent pair", "\n", "        ", "c_dict", "=", "count_pair", "(", "t_list", ")", "\n", "pair_best", "=", "max", "(", "c_dict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "if", "pair_best", "[", "1", "]", "<", "min_freq", ":", "\n", "            ", "break", "\n", "", "bpe_list", ".", "append", "(", "pair_best", ")", "\n", "# merge trees using the learned pair", "\n", "merge_bpe", "(", "pair_best", "[", "0", "]", ",", "t_list", ")", "\n", "", "return", "bpe_list", "\n", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.preprocess.main": [[41, 86], ["table.IO.read_anno_json", "table.IO.read_anno_json", "bpe.learn_bpe", "bpe.BpeProcessor", "print", "table.IO.TableDataset.get_fields", "table.IO.TableDataset.get_fields", "print", "table.IO.TableDataset", "table.IO.TableDataset", "path.Path().exists", "path.Path().exists", "print", "table.IO.TableDataset.build_vocab", "table.IO.TableDataset.build_vocab", "print", "torch.save", "torch.save", "torch.save", "path.Path().exists", "path.Path().exists", "print", "table.IO.TableDataset", "table.IO.TableDataset", "print", "table.IO.TableDataset", "table.IO.TableDataset", "table.IO.TableDataset.save_vocab", "table.IO.TableDataset.save_vocab", "open", "open", "open", "torch.save", "torch.save", "tree.STree", "path.Path", "path.Path", "os.path.join", "os.path.join", "os.path.join", "path.Path", "open", "path.Path", "open", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.read_anno_json", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.learn_bpe", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.get_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.get_fields", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.build_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.build_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab", "home.repos.pwc.inspect_result.donglixp_coarse2fine.table.IO.TableDataset.save_vocab"], ["set_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "\n", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "'Preparing training ...'", ")", "\n", "fields", "=", "table", ".", "IO", ".", "TableDataset", ".", "get_fields", "(", ")", "\n", "print", "(", "\"Building Training...\"", ")", "\n", "train", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "train_anno", ",", "fields", ",", "opt", ",", "True", ")", "\n", "\n", "print", "(", "\"Building Valid...\"", ")", "\n", "valid", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "valid_anno", ",", "fields", ",", "opt", ",", "True", ")", "\n", "\n", "print", "(", "\"Building Test...\"", ")", "\n", "test", "=", "table", ".", "IO", ".", "TableDataset", "(", "opt", ".", "test_anno", ",", "fields", ",", "opt", ",", "False", ")", "\n", "\n", "print", "(", "\"Building Vocab...\"", ")", "\n", "table", ".", "IO", ".", "TableDataset", ".", "build_vocab", "(", "train", ",", "valid", ",", "test", ",", "opt", ")", "\n", "\n", "print", "(", "\"Saving train/valid/fields\"", ")", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "torch", ".", "save", "(", "table", ".", "IO", ".", "TableDataset", ".", "save_vocab", "(", "fields", ")", ",", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'vocab.pt'", ")", ",", "'wb'", ")", ")", "\n", "train", ".", "fields", "=", "[", "]", "\n", "valid", ".", "fields", "=", "[", "]", "\n", "torch", ".", "save", "(", "train", ",", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'train.pt'", ")", ",", "'wb'", ")", ")", "\n", "torch", ".", "save", "(", "valid", ",", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "save_data", ",", "'valid.pt'", ")", ",", "'wb'", ")", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__init__": [[15, 27], ["isinstance", "tree.STree.set_by_token_list", "isinstance", "tree.STree.set_by_str"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.set_by_token_list", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.set_by_str"], ["\n", "if", "init", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "init", ",", "list", ")", ":", "\n", "                ", "self", ".", "set_by_list", "(", "init", ",", "None", ")", "\n", "", "elif", "isinstance", "(", "init", ",", "tuple", ")", ":", "\n", "                ", "self", ".", "set_by_list", "(", "init", "[", "0", "]", ",", "init", "[", "1", "]", ")", "\n", "", "elif", "isinstance", "(", "init", ",", "six", ".", "string_types", ")", ":", "\n", "                ", "self", ".", "set_by_str", "(", "init", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "", "def", "set_by_str", "(", "self", ",", "f", ")", ":", "\n", "        ", "tk_list", "=", "list", "(", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.add_child": [[28, 32], ["isinstance", "tree.STree.children.append", "type"], "methods", ["None"], ["tokenize", "(", "BytesIO", "(", "f", ".", "strip", "(", ")", ".", "encode", "(", "'utf-8'", ")", ")", ".", "readline", ")", ")", "[", "1", ":", "-", "1", "]", "\n", "self", ".", "token_list", "=", "[", "tk", ".", "string", "for", "tk", "in", "tk_list", "]", "\n", "self", ".", "type_list", "=", "[", "token", ".", "tok_name", "[", "tk", ".", "type", "]", "for", "tk", "in", "tk_list", "]", "\n", "\n", "# well-tokenized token list", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.set_by_str": [[33, 36], ["s.replace().replace().strip().split", "tree.STree._set_by_token_list", "s.replace().replace().strip", "s.replace().replace", "s.replace"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree._set_by_token_list"], ["", "def", "set_by_list", "(", "self", ",", "token_list", ",", "type_list", ")", ":", "\n", "        ", "self", ".", "token_list", "=", "list", "(", "token_list", ")", "\n", "if", "type_list", "is", "not", "None", ":", "\n", "            ", "self", ".", "type_list", "=", "list", "(", "type_list", ")", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.set_by_token_list": [[37, 39], ["tree.STree.set_by_str"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.set_by_str"], ["\n", "", "", "def", "to_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "token_list", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree._set_by_token_list": [[41, 75], ["_tk_list.count", "_tk_list.count", "len", "len", "len", "range", "tree.STree.add_child", "len", "type", "tree.STree.add_child", "tk_list[].startswith", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.add_child", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.add_child"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "self", ".", "to_list", "(", ")", ")", "\n", "\n", "", "def", "layout", "(", "self", ",", "add_skip", "=", "False", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "token_list", ")", "==", "len", "(", "self", ".", "type_list", ")", "\n", "r_list", "=", "[", "]", "\n", "for", "tk", ",", "tp", "in", "zip", "(", "self", ".", "token_list", ",", "self", ".", "type_list", ")", ":", "\n", "            ", "if", "tp", "in", "(", "'OP'", ",", "'KEYWORD'", ")", ":", "\n", "                ", "r_list", ".", "append", "(", "tk", ")", "\n", "", "elif", "tp", "in", "(", "'STRING'", ",", ")", ":", "\n", "                ", "if", "add_skip", ":", "\n", "                    ", "s_list", "=", "tk", ".", "split", "(", "' '", ")", "\n", "r_list", ".", "extend", "(", "\n", "[", "LFT_WORD", "]", "+", "[", "SKP_WORD", "for", "__", "in", "range", "(", "len", "(", "s_list", ")", "-", "2", ")", "]", "+", "[", "RIG_WORD", "]", ")", "\n", "", "else", ":", "\n", "                    ", "r_list", ".", "append", "(", "tp", ")", "\n", "# elif tp in ('NAME', 'NUMBER'):", "\n", "#     if add_skip:", "\n", "#         r_list.append(SKP_WORD)", "\n", "#     else:", "\n", "#         r_list.append(tp)", "\n", "", "", "else", ":", "\n", "                ", "r_list", ".", "append", "(", "tp", ")", "\n", "", "", "return", "r_list", "\n", "\n", "", "def", "target", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "token_list", ")", "==", "len", "(", "self", ".", "type_list", ")", "\n", "r_list", "=", "[", "]", "\n", "for", "tk", ",", "tp", "in", "zip", "(", "self", ".", "token_list", ",", "self", ".", "type_list", ")", ":", "\n", "            ", "if", "tp", "in", "(", "'STRING'", ",", ")", ":", "\n", "                ", "s_list", "=", "tk", ".", "split", "(", "' '", ")", "\n", "r_list", ".", "extend", "(", "[", "LFT_WORD", "]", "+", "s_list", "[", "1", ":", "-", "1", "]", "+", "[", "RIG_WORD", "]", ")", "\n", "", "else", ":", "\n", "                ", "r_list", ".", "append", "(", "tk", ")", "\n", "", "", "return", "r_list", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.to_list": [[76, 90], ["isinstance", "type", "s_list.extend", "s_list.append", "len", "c.to_list"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.to_list"], ["\n", "", "def", "norm", "(", "self", ",", "not_layout", "=", "False", ")", ":", "\n", "        ", "return", "self", "\n", "\n", "\n", "", "", "def", "is_code_eq", "(", "t1", ",", "t2", ",", "not_layout", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "t1", ",", "SCode", ")", ":", "\n", "        ", "t1", "=", "str", "(", "t1", ")", "\n", "", "else", ":", "\n", "        ", "t1", "=", "' '", ".", "join", "(", "t1", ")", "\n", "", "if", "isinstance", "(", "t2", ",", "SCode", ")", ":", "\n", "        ", "t2", "=", "str", "(", "t2", ")", "\n", "", "else", ":", "\n", "        ", "t2", "=", "' '", ".", "join", "(", "t2", ")", "\n", "", "t1", "=", "[", "'\\\"'", "if", "it", "in", "(", "RIG_WORD", ",", "LFT_WORD", ")", "else", "it", "for", "it", "in", "t1", ".", "split", "(", "' '", ")", "]", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.__str__": [[91, 93], ["tree.STree.to_list"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.to_list"], ["t2", "=", "[", "'\\\"'", "if", "it", "in", "(", "RIG_WORD", ",", "LFT_WORD", ")", "else", "it", "for", "it", "in", "t2", ".", "split", "(", "' '", ")", "]", "\n", "if", "len", "(", "t1", ")", "==", "len", "(", "t2", ")", ":", "\n", "        ", "for", "tk1", ",", "tk2", "in", "zip", "(", "t1", ",", "t2", ")", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.layout": [[94, 103], ["tree.STree.atis_layout", "tree.STree.atis_layout", "tree.STree.jobs_layout"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.atis_layout", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.atis_layout", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.jobs_layout"], ["# if not (tk1 == tk2 or tk1 == '<unk>' or tk2 == '<unk>'):", "\n", "            ", "if", "tk1", "!=", "tk2", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "", "return", "t1", "==", "t2", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.atis_layout": [[104, 142], ["any", "range", "range", "len", "isinstance", "isinstance", "len", "lay_list.append", "type", "lay_list.extend", "lay_list.append", "type", "len", "c.atis_layout", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.atis_layout"], ["    ", "for", "s", "in", "(", "\"if base64d [ : 1 ] == b' _STR:0_ ' :\"", ".", "split", "(", ")", ",", "\"if base64d [ : 1 ] == b' _STR:0_ ' :\"", ".", "split", "(", ")", ",", "\"compressed = zlib . compress ( data )\"", ".", "split", "(", ")", ",", "\"compressed = zlib.compress(data)\"", ".", "split", "(", ")", ",", ")", ":", "\n", "        ", "t", "=", "SCode", "(", "s", ")", "\n", "print", "(", "1", ",", "t", ")", "\n", "print", "(", "2", ",", "t", ".", "to_list", "(", ")", ")", "\n", "print", "(", "3", ",", "' '", ".", "join", "(", "t", ".", "layout", "(", "add_skip", "=", "False", ")", ")", ")", "\n", "print", "(", "'\\n'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.geo_layout": [[143, 145], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.jobs_layout": [[146, 148], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm": [[149, 180], ["len", "isinstance", "list", "type", "c.norm", "len", "sorted", "set", "str", "set.add", "deduplicate_list.append", "str"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.permute": [[181, 202], ["len", "isinstance", "list", "random.shuffle", "type", "c.permute", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.permute"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.is_ordered": [[203, 209], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.all_bpe_pairs": [[210, 237], ["len", "isinstance", "pair_list.append", "len", "bpe.BpePair", "len", "tree.STree.is_ordered", "isinstance", "range", "s_list.sort", "range", "type", "pair_list.extend", "range", "c.all_bpe_pairs", "len", "isinstance", "isinstance", "pair_list.append", "isinstance", "len", "len", "pair_list.append", "bpe.BpePair", "bpe.BpePair"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.is_ordered", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.all_bpe_pairs"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.apply_bpe": [[238, 295], ["tree.STree.is_ordered", "len", "isinstance", "type", "tree.STree.apply_bpe", "isinstance", "isinstance", "p.is_match", "isinstance", "isinstance", "p.is_match", "new_list.append", "new_list.append", "type", "len", "str", "type", "len", "str", "len", "len", "isinstance", "isinstance", "p.is_match", "new_list.append", "new_list.append", "len", "str", "len", "range", "new_list.append", "new_list.extend", "range", "str", "len", "len", "isinstance", "isinstance", "p.is_match", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.is_ordered", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.apply_bpe", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.is_match", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.is_match", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.is_match", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.bpe.BpePair.is_match"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.norm_tree_var": [[297, 309], ["t.to_list", "enumerate", "tree.STree", "tk.startswith", "v_list.append", "str", "v_dict.get"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.to_list"], []], "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.is_tree_eq": [[311, 324], ["isinstance", "isinstance", "tree.STree", "tree.STree", "tree.STree", "tree.STree", "str().lower", "str().lower", "str", "str", "str", "str", "tree.norm_tree_var", "tree.norm_tree_var", "tree.STree.norm", "tree.STree.norm"], "function", ["home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower", "home.repos.pwc.inspect_result.donglixp_coarse2fine.lib.query.Query.lower", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.norm_tree_var", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.norm_tree_var", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm", "home.repos.pwc.inspect_result.donglixp_coarse2fine.logical.tree.STree.norm"], []]}