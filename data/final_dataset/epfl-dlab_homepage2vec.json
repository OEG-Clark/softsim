{"home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.TextualExtractor.__init__": [[14, 35], ["sentence_transformers.SentenceTransformer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "if", "not", "TextualExtractor", ".", "xlmr", ":", "\n", "            ", "TextualExtractor", ".", "xlmr", "=", "SentenceTransformer", "(", "'paraphrase-xlm-r-multilingual-v1'", ",", "device", "=", "device", ")", "\n", "# self.xlmr = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1', device=device)", "\n", "\n", "# TLD used for one-hot encoding", "\n", "", "self", ".", "rep_tld", "=", "[", "'com'", ",", "'org'", ",", "'net'", ",", "'info'", ",", "'xyz'", ",", "'club'", ",", "'biz'", ",", "'top'", ",", "'edu'", ",", "'online'", ",", "\n", "'pro'", ",", "'site'", ",", "'vip'", ",", "'icu'", ",", "'buzz'", ",", "'app'", ",", "'asia'", ",", "'su'", ",", "'gov'", ",", "'space'", "]", "\n", "\n", "# Metatags used for one-hot encoding", "\n", "self", ".", "rep_metatags", "=", "[", "'viewport'", ",", "'description'", ",", "'generator'", ",", "'keywords'", ",", "'robots'", ",", "'twitter:card'", ",", "\n", "'msapplication-tileimage'", ",", "'google-site-verification'", ",", "'author'", ",", "'twitter:title'", ",", "\n", "'twitter:description'", ",", "'theme-color'", ",", "'twitter:image'", ",", "'twitter:site'", ",", "\n", "'format-detection'", ",", "'msapplication-tilecolor'", ",", "'copyright'", ",", "'twitter:data1'", ",", "\n", "'twitter:label1'", ",", "'revisit-after'", ",", "'apple-mobile-web-app-capable'", ",", "'handheldfriendly'", ",", "\n", "'language'", ",", "'msvalidate.01'", ",", "'twitter:url'", ",", "'title'", ",", "'mobileoptimized'", ",", "\n", "'twitter:creator'", ",", "'skype_toolbar'", ",", "'rating'", "]", "\n", "\n", "# number of sentences and links over which we compute the features", "\n", "self", ".", "k_sentences", "=", "100", "\n", "self", ".", "k_links", "=", "50", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.TextualExtractor.get_features": [[36, 76], ["textual_extractor.embed_url", "textual_extractor.embed_tld", "bs4.BeautifulSoup", "textual_extractor.embed_metatags", "textual_extractor.embed_title", "textual_extractor.embed_description", "textual_extractor.embed_keywords", "textual_extractor.embed_links", "textual_extractor.embed_text", "str", "str"], "methods", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_url", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_tld", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_metatags", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_title", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_description", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_keywords", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_links", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_text"], ["", "def", "get_features", "(", "self", ",", "url", ",", "html", ")", ":", "\n", "\n", "        ", "features", "=", "{", "}", "\n", "\n", "# url", "\n", "url_feature", "=", "embed_url", "(", "url", ",", "TextualExtractor", ".", "xlmr", ")", "\n", "features", "[", "'f_url'", "]", "=", "url_feature", "\n", "\n", "# tld ", "\n", "tld_feature", "=", "embed_tld", "(", "url", ",", "self", ".", "rep_tld", ")", "\n", "features", "[", "'f_tld'", "]", "=", "tld_feature", "\n", "\n", "# print(html)", "\n", "soup", "=", "BeautifulSoup", "(", "html", ",", "'lxml'", ")", "\n", "\n", "# metatags", "\n", "metatags_feature", "=", "embed_metatags", "(", "soup", ",", "self", ".", "rep_metatags", ")", "\n", "features", "[", "'f_metatags'", "]", "=", "metatags_feature", "\n", "\n", "# title", "\n", "title_feature", "=", "embed_title", "(", "soup", ",", "TextualExtractor", ".", "xlmr", ")", "\n", "features", "[", "'f_title'", "]", "=", "title_feature", "\n", "\n", "# description", "\n", "description_feature", "=", "embed_description", "(", "soup", ",", "TextualExtractor", ".", "xlmr", ")", "\n", "features", "[", "'f_description'", "]", "=", "description_feature", "\n", "\n", "# keywords", "\n", "keywords_feature", "=", "embed_keywords", "(", "soup", ",", "TextualExtractor", ".", "xlmr", ")", "\n", "features", "[", "'f_keywords'", "]", "=", "keywords_feature", "\n", "\n", "# links", "\n", "links_feature", "=", "embed_links", "(", "soup", ",", "TextualExtractor", ".", "xlmr", ",", "self", ".", "k_links", ")", "\n", "features", "[", "'f_links_'", "+", "str", "(", "self", ".", "k_links", ")", "]", "=", "links_feature", "\n", "\n", "# text", "\n", "text_feature", "=", "embed_text", "(", "soup", ",", "TextualExtractor", ".", "xlmr", ",", "self", ".", "k_sentences", ")", "\n", "features", "[", "'f_text_'", "+", "str", "(", "self", ".", "k_sentences", ")", "]", "=", "text_feature", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_text": [[79, 97], ["transformer.encode", "transformer.encode.mean().tolist", "textual_extractor.split_in_sentences", "len", "textual_extractor.trunc", "transformer.encode.mean"], "function", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.split_in_sentences", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.trunc"], ["", "", "def", "embed_text", "(", "soup", ",", "transformer", ",", "k_sentences", ")", ":", "\n", "\n", "    ", "sentences", "=", "split_in_sentences", "(", "soup", ")", "[", ":", "k_sentences", "]", "\n", "\n", "if", "len", "(", "sentences", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "# this is needed to avoid some warnings, truncate the sentences", "\n", "", "sentences_trunc", "=", "[", "trunc", "(", "s", ",", "transformer", ".", "tokenizer", ",", "transformer", ".", "max_seq_length", ")", "for", "s", "in", "sentences", "]", "\n", "\n", "sentences_emb", "=", "transformer", ".", "encode", "(", "sentences_trunc", ")", "\n", "\n", "if", "sentences_emb", ".", "size", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "text_emb", "=", "sentences_emb", ".", "mean", "(", "axis", "=", "0", ")", ".", "tolist", "(", ")", "# mean of the sentences ", "\n", "\n", "return", "text_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_description": [[99, 121], ["soup.find", "soup.find.get", "textual_extractor.clean_field", "textual_extractor.trunc", "transformer.encode", "transformer.encode.tolist", "len", "clean_field.strip"], "function", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.clean_field", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.trunc"], ["", "def", "embed_description", "(", "soup", ",", "transformer", ")", ":", "\n", "\n", "    ", "desc", "=", "soup", ".", "find", "(", "'meta'", ",", "attrs", "=", "{", "'name'", ":", "[", "'description'", ",", "'Description'", "]", "}", ")", "\n", "\n", "if", "not", "desc", ":", "\n", "        ", "return", "None", "\n", "\n", "", "content", "=", "desc", ".", "get", "(", "'content'", ",", "''", ")", "\n", "\n", "if", "len", "(", "content", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "content", "=", "clean_field", "(", "content", ")", "\n", "\n", "# this is needed to avoid some warnings", "\n", "desc_trunc", "=", "trunc", "(", "content", ",", "transformer", ".", "tokenizer", ",", "transformer", ".", "max_seq_length", ")", "\n", "desc_emb", "=", "transformer", ".", "encode", "(", "desc_trunc", ")", "\n", "\n", "if", "desc_emb", ".", "size", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "return", "desc_emb", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_keywords": [[123, 143], ["soup.find", "soup.find.get", "textual_extractor.trunc", "transformer.encode", "transformer.encode.tolist", "len", "kw.get.strip"], "function", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.trunc"], ["", "def", "embed_keywords", "(", "soup", ",", "transformer", ")", ":", "\n", "\n", "    ", "kw", "=", "soup", ".", "find", "(", "'meta'", ",", "attrs", "=", "{", "'name'", ":", "'keywords'", "}", ")", "\n", "\n", "if", "not", "kw", ":", "\n", "        ", "return", "None", "\n", "\n", "", "content", "=", "kw", ".", "get", "(", "'content'", ",", "''", ")", "\n", "\n", "if", "len", "(", "content", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "# this is needed to avoid some warnings", "\n", "", "kw_trunc", "=", "trunc", "(", "content", ",", "transformer", ".", "tokenizer", ",", "transformer", ".", "max_seq_length", ")", "\n", "kw_emb", "=", "transformer", ".", "encode", "(", "kw_trunc", ")", "\n", "\n", "if", "kw_emb", ".", "size", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "return", "kw_emb", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_title": [[145, 166], ["soup.find", "str", "textual_extractor.clean_field", "textual_extractor.trunc", "transformer.encode", "transformer.encode.tolist", "len"], "function", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.clean_field", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.trunc"], ["", "def", "embed_title", "(", "soup", ",", "transformer", ")", ":", "\n", "\n", "    ", "title", "=", "soup", ".", "find", "(", "'title'", ")", "\n", "\n", "if", "title", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "title", "=", "str", "(", "title", ".", "string", ")", "\n", "title", "=", "clean_field", "(", "title", ")", "\n", "\n", "if", "len", "(", "title", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "# this is needed to avoid some warnings", "\n", "", "title_trunc", "=", "trunc", "(", "title", ",", "transformer", ".", "tokenizer", ",", "transformer", ".", "max_seq_length", ")", "\n", "title_emb", "=", "transformer", ".", "encode", "(", "title_trunc", ")", "\n", "\n", "if", "title_emb", ".", "size", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "return", "title_emb", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_links": [[168, 195], ["soup.find_all", "transformer.encode", "transformer.encode.mean().tolist", "a.get", "textual_extractor.clean_link", "w.lower", "len", "textual_extractor.trunc", "collections.Counter().most_common", "transformer.encode.mean", "len", "len", "collections.Counter"], "function", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.clean_link", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.trunc"], ["", "def", "embed_links", "(", "soup", ",", "transformer", ",", "k_links", ")", ":", "\n", "\n", "    ", "a_tags", "=", "soup", ".", "find_all", "(", "'a'", ",", "href", "=", "True", ")", "\n", "\n", "links", "=", "[", "a", ".", "get", "(", "'href'", ",", "''", ")", "for", "a", "in", "a_tags", "]", "\n", "links", "=", "[", "clean_link", "(", "link", ")", "for", "link", "in", "links", "]", "\n", "links", "=", "[", "link", "for", "link", "in", "links", "if", "len", "(", "link", ")", "!=", "0", "]", "\n", "\n", "words", "=", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "' '", ".", "join", "(", "links", ")", ".", "split", "(", "' '", ")", "if", "len", "(", "w", ")", "!=", "0", "]", "\n", "\n", "if", "len", "(", "words", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "most_frequent_words", "=", "[", "w", "[", "0", "]", "for", "w", "in", "Counter", "(", "words", ")", ".", "most_common", "(", "k_links", ")", "]", "\n", "\n", "# most_frequent_words = pd.Series(words).value_counts()[:k_links].index.values", "\n", "\n", "# this is needed to avoid some warnings", "\n", "words_trunc", "=", "[", "trunc", "(", "w", ",", "transformer", ".", "tokenizer", ",", "transformer", ".", "max_seq_length", ")", "for", "w", "in", "most_frequent_words", "]", "\n", "words_emb", "=", "transformer", ".", "encode", "(", "words_trunc", ")", "\n", "\n", "if", "words_emb", ".", "size", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "links_emb", "=", "words_emb", ".", "mean", "(", "axis", "=", "0", ")", ".", "tolist", "(", ")", "\n", "\n", "return", "links_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_url": [[197, 209], ["textual_extractor.clean_url", "transformer.encode", "transformer.encode.mean().tolist", "textual_extractor.trunc", "transformer.encode.mean"], "function", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.clean_url", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.trunc"], ["", "def", "embed_url", "(", "url", ",", "transformer", ")", ":", "\n", "\n", "    ", "cleaned_url", "=", "clean_url", "(", "url", ")", "\n", "\n", "# this is needed to avoid some warnings", "\n", "url_trunc", "=", "[", "trunc", "(", "w", ",", "transformer", ".", "tokenizer", ",", "transformer", ".", "max_seq_length", ")", "for", "w", "in", "cleaned_url", "]", "\n", "url_emb", "=", "transformer", ".", "encode", "(", "cleaned_url", ")", "\n", "\n", "if", "url_emb", ".", "size", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "return", "url_emb", ".", "mean", "(", "axis", "=", "0", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_tld": [[212, 219], ["url.split", "int", "tld.startswith"], "function", ["None"], ["", "def", "embed_tld", "(", "url", ",", "rep_tld", ")", ":", "\n", "\n", "    ", "tld", "=", "url", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "\n", "rep_onehot", "=", "[", "int", "(", "tld", ".", "startswith", "(", "d", ")", ")", "for", "d", "in", "rep_tld", "]", "\n", "continent_onehot", "=", "7", "*", "[", "0", "]", "#TODO", "\n", "\n", "return", "rep_onehot", "+", "continent_onehot", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.embed_metatags": [[222, 231], ["soup.findAll", "m.get", "a.lower", "int"], "function", ["None"], ["", "def", "embed_metatags", "(", "soup", ",", "rep_metatags", ")", ":", "\n", "\n", "    ", "metatags", "=", "soup", ".", "findAll", "(", "'meta'", ")", "\n", "attr", "=", "[", "m", ".", "get", "(", "'name'", ",", "None", ")", "for", "m", "in", "metatags", "]", "\n", "attr", "=", "[", "a", ".", "lower", "(", ")", "for", "a", "in", "attr", "if", "a", "!=", "None", "]", "\n", "\n", "attr_emb", "=", "[", "int", "(", "a", "in", "attr", ")", "for", "a", "in", "rep_metatags", "]", "\n", "\n", "return", "attr_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.split_in_sentences": [[234, 242], ["soup.get_text().split", "s.strip", "soup.get_text", "len"], "function", ["None"], ["", "def", "split_in_sentences", "(", "soup", ")", ":", "\n", "    ", "\"\"\" From the raw html content of a website, extract the text visible to the user and splits it in sentences \"\"\"", "\n", "\n", "sep", "=", "soup", ".", "get_text", "(", "'[SEP]'", ")", ".", "split", "(", "'[SEP]'", ")", "# separate text elements with special separators [SEP]", "\n", "strip", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "sep", "if", "s", "!=", "'\\n'", "]", "\n", "clean", "=", "[", "s", "for", "s", "in", "strip", "if", "len", "(", "s", ")", "!=", "0", "]", "\n", "\n", "return", "clean", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.clean_url": [[244, 247], ["re.sub", "re.sub.split"], "function", ["None"], ["", "def", "clean_url", "(", "url", ")", ":", "\n", "    ", "url", "=", "re", ".", "sub", "(", "r\"www.|http://|https://|-|_\"", ",", "''", ",", "url", ")", "\n", "return", "url", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.clean_field": [[249, 252], ["re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "clean_field", "(", "field", ")", ":", "\n", "    ", "field", "=", "re", ".", "sub", "(", "r\"\\*|\\n|\\r|\\t|\\||:|-|\u2013\"", ",", "''", ",", "field", ")", "\n", "return", "field", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.clean_link": [[254, 259], ["re.sub", "re.sub", "re.sub.split"], "function", ["None"], ["", "def", "clean_link", "(", "link", ")", ":", "\n", "    ", "link", "=", "re", ".", "sub", "(", "r\"www.|http://|https://|[0-9]+\"", ",", "''", ",", "link", ")", "\n", "link", "=", "re", ".", "sub", "(", "r\"-|_|=|\\?|:\"", ",", "' '", ",", "link", ")", "\n", "link", "=", "link", ".", "split", "(", "'/'", ")", "[", "1", ":", "]", "\n", "return", "' '", ".", "join", "(", "link", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.textual_extractor.trunc": [[261, 266], ["tok.encode", "tok.decode"], "function", ["None"], ["", "def", "trunc", "(", "seq", ",", "tok", ",", "max_length", ")", ":", "\n", "    ", "\"\"\" Truncate the output of a tokenizer to a given length, doesn't affect the performances \"\"\"", "\n", "e", "=", "tok", ".", "encode", "(", "seq", ",", "truncation", "=", "True", ")", "\n", "d", "=", "tok", ".", "decode", "(", "e", "[", "1", ":", "-", "1", "]", "[", ":", "max_length", "-", "2", "]", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.__init__": [[26, 68], ["homepage2vec.model_loader.get_model_path", "os.makedirs", "glob.glob", "torch.load", "model.SimpleClassifier", "model.WebsiteClassifier.model.load_state_dict", "logging.debug", "tempfile.gettempdir", "os.remove", "torch.cuda.is_available", "open", "torch.set_num_threads", "torch.device", "int", "model.WebsiteClassifier.features_order.append", "f.split", "f.split"], "methods", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model_loader.get_model_path"], ["def", "__init__", "(", "self", ",", "visual", "=", "False", ",", "device", "=", "None", ",", "cpu_threads_count", "=", "1", ",", "dataloader_workers", "=", "1", ")", ":", "\n", "        ", "self", ".", "input_dim", "=", "5177", "if", "visual", "else", "4665", "\n", "self", ".", "output_dim", "=", "14", "\n", "self", ".", "classes", "=", "[", "'Arts'", ",", "'Business'", ",", "'Computers'", ",", "'Games'", ",", "'Health'", ",", "'Home'", ",", "'Kids_and_Teens'", ",", "\n", "'News'", ",", "'Recreation'", ",", "'Reference'", ",", "'Science'", ",", "'Shopping'", ",", "'Society'", ",", "'Sports'", "]", "\n", "\n", "self", ".", "with_visual", "=", "visual", "\n", "\n", "self", ".", "model_home_path", ",", "self", ".", "model_path", "=", "get_model_path", "(", "visual", ")", "\n", "\n", "self", ".", "temporary_dir", "=", "tempfile", ".", "gettempdir", "(", ")", "+", "\"/homepage2vec/\"", "\n", "os", ".", "makedirs", "(", "self", ".", "temporary_dir", "+", "\"/screenshots\"", ",", "exist_ok", "=", "True", ")", "\n", "# clean screen shorts", "\n", "files", "=", "glob", ".", "glob", "(", "self", ".", "temporary_dir", "+", "\"/screenshots/*\"", ")", "\n", "for", "f", "in", "files", ":", "\n", "            ", "os", ".", "remove", "(", "f", ")", "\n", "\n", "", "self", ".", "device", "=", "device", "\n", "self", ".", "dataloader_workers", "=", "dataloader_workers", "\n", "os", ".", "environ", "[", "\"TOKENIZERS_PARALLELISM\"", "]", "=", "\"false\"", "\n", "if", "not", "device", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "self", ".", "device", "=", "'cuda:0'", "\n", "", "else", ":", "\n", "                ", "self", ".", "device", "=", "'cpu'", "\n", "torch", ".", "set_num_threads", "(", "cpu_threads_count", ")", "\n", "\n", "# load pretrained model", "\n", "", "", "model_tensor", "=", "torch", ".", "load", "(", "self", ".", "model_path", "+", "\"/model.pt\"", ",", "map_location", "=", "torch", ".", "device", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "model", "=", "SimpleClassifier", "(", "self", ".", "input_dim", ",", "self", ".", "output_dim", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "model_tensor", ")", "\n", "\n", "# features used in training", "\n", "self", ".", "features_order", "=", "[", "]", "\n", "self", ".", "features_dim", "=", "{", "}", "\n", "logging", ".", "debug", "(", "\"Loading features from {}\"", ".", "format", "(", "self", ".", "model_path", "+", "'/features.txt'", ")", ")", "\n", "with", "open", "(", "self", ".", "model_path", "+", "'/features.txt'", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "f", "in", "file", ":", "\n", "                ", "name", "=", "f", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "dim", "=", "int", "(", "f", ".", "split", "(", "' '", ")", "[", "1", "]", "[", ":", "-", "1", "]", ")", "\n", "self", ".", "features_order", ".", "append", "(", "name", ")", "\n", "self", ".", "features_dim", "[", "name", "]", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.get_scores": [[69, 73], ["torch.no_grad", "model.WebsiteClassifier.model.eval", "model.WebsiteClassifier.model.forward"], "methods", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.ResNetPretrained.forward"], ["", "", "", "def", "get_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "return", "self", ".", "model", ".", "forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.fetch_website": [[74, 90], ["logging.debug", "homepage2vec.data_collection.access_website", "model.Webpage", "model.WebsiteClassifier.is_valid", "logging.debug", "homepage2vec.data_collection.take_screenshot", "logging.debug", "str"], "methods", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.data_collection.access_website", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.is_valid", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.data_collection.take_screenshot"], ["", "", "def", "fetch_website", "(", "self", ",", "url", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "\"Fetching website: {}\"", ".", "format", "(", "url", ")", ")", "\n", "response", "=", "access_website", "(", "url", ")", "\n", "w", "=", "Webpage", "(", "url", ")", "\n", "if", "response", "is", "not", "None", ":", "\n", "            ", "html", ",", "get_code", ",", "content_type", "=", "response", "\n", "w", ".", "http_code", "=", "get_code", "\n", "if", "self", ".", "is_valid", "(", "get_code", ",", "content_type", ")", ":", "\n", "                ", "w", ".", "is_valid", "=", "True", "\n", "w", ".", "html", "=", "html", "\n", "", "", "if", "self", ".", "with_visual", ":", "\n", "            ", "logging", ".", "debug", "(", "\"Generating screenshot: {}\"", ".", "format", "(", "url", ")", ")", "\n", "out_path", "=", "self", ".", "temporary_dir", "+", "\"/screenshots/\"", "+", "str", "(", "w", ".", "uid", ")", "\n", "w", ".", "screenshot_path", "=", "take_screenshot", "(", "w", ".", "url", ",", "out_path", ")", "\n", "logging", ".", "debug", "(", "\"Screenshot for {} ready in {}\"", ".", "format", "(", "url", ",", "w", ".", "screenshot_path", ")", ")", "\n", "", "return", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.get_features": [[91, 99], ["homepage2vec.textual_extractor.TextualExtractor", "homepage2vec.textual_extractor.TextualExtractor.get_features", "homepage2vec.visual_extractor.VisualExtractor", "homepage2vec.visual_extractor.VisualExtractor.get_features"], "methods", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.VisualExtractor.get_features", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.VisualExtractor.get_features"], ["", "def", "get_features", "(", "self", ",", "url", ",", "html", ",", "screenshot_path", ")", ":", "\n", "        ", "te", "=", "TextualExtractor", "(", "self", ".", "device", ")", "\n", "features", "=", "te", ".", "get_features", "(", "url", ",", "html", ")", "\n", "if", "self", ".", "with_visual", ":", "\n", "            ", "ve", "=", "VisualExtractor", "(", "self", ".", "device", ")", "\n", "visual_features", "=", "ve", ".", "get_features", "(", "screenshot_path", ")", "\n", "features", "[", "'f_visual'", "]", "=", "visual_features", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.predict": [[100, 106], ["model.WebsiteClassifier.get_features", "model.WebsiteClassifier.concatenate_features", "torch.FloatTensor", "model.WebsiteClassifier.get_scores", "dict", "embeddings.tolist", "zip", "torch.sigmoid().tolist", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.VisualExtractor.get_features", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.concatenate_features", "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.get_scores"], ["", "def", "predict", "(", "self", ",", "website", ")", ":", "\n", "        ", "website", ".", "features", "=", "self", ".", "get_features", "(", "website", ".", "url", ",", "website", ".", "html", ",", "website", ".", "screenshot_path", ")", "\n", "all_features", "=", "self", ".", "concatenate_features", "(", "website", ")", "\n", "input_features", "=", "torch", ".", "FloatTensor", "(", "all_features", ")", "\n", "scores", ",", "embeddings", "=", "self", ".", "get_scores", "(", "input_features", ")", "\n", "return", "dict", "(", "zip", "(", "self", ".", "classes", ",", "torch", ".", "sigmoid", "(", "scores", ")", ".", "tolist", "(", ")", ")", ")", ",", "embeddings", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.concatenate_features": [[108, 126], ["numpy.zeros"], "methods", ["None"], ["", "def", "concatenate_features", "(", "self", ",", "w", ")", ":", "\n", "        ", "\"\"\"\n        Concatenate the features attributes of webpage instance, with respect to the features order in h2v\n        \"\"\"", "\n", "\n", "v", "=", "np", ".", "zeros", "(", "self", ".", "input_dim", ")", "\n", "\n", "ix", "=", "0", "\n", "\n", "for", "f_name", "in", "self", ".", "features_order", ":", "\n", "            ", "f_dim", "=", "self", ".", "features_dim", "[", "f_name", "]", "\n", "f_value", "=", "w", ".", "features", "[", "f_name", "]", "\n", "if", "f_value", "is", "None", ":", "\n", "                ", "f_value", "=", "f_dim", "*", "[", "0", "]", "# if no feature, replace with zeros", "\n", "", "v", "[", "ix", ":", "ix", "+", "f_dim", "]", "=", "f_value", "\n", "ix", "+=", "f_dim", "\n", "\n", "", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.WebsiteClassifier.is_valid": [[127, 131], ["content_type.startswith"], "methods", ["None"], ["", "def", "is_valid", "(", "self", ",", "get_code", ",", "content_type", ")", ":", "\n", "        ", "valid_get_code", "=", "get_code", "==", "200", "\n", "valid_content_type", "=", "content_type", ".", "startswith", "(", "'text/html'", ")", "\n", "return", "valid_get_code", "and", "valid_content_type", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.SimpleClassifier.__init__": [[138, 146], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.VisualExtractor.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "SimpleClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "layer1", "=", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "1000", ")", "\n", "self", ".", "layer2", "=", "torch", ".", "nn", ".", "Linear", "(", "1000", ",", "100", ")", "\n", "self", ".", "fc", "=", "torch", ".", "nn", ".", "Linear", "(", "100", ",", "output_dim", ")", "\n", "\n", "self", ".", "drop", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "# dropout of 0.5 before each layer", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.SimpleClassifier.forward": [[147, 157], ["model.SimpleClassifier.layer1", "torch.nn.functional.relu", "model.SimpleClassifier.layer2", "torch.nn.functional.relu", "model.SimpleClassifier.fc", "model.SimpleClassifier.drop", "model.SimpleClassifier.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "drop", "(", "x", ")", ")", "\n", "\n", "emb", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "drop", "(", "emb", ")", ")", "\n", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", ",", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.Webpage.__init__": [[164, 174], ["uuid.uuid4"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "url", ")", ":", "\n", "        ", "self", ".", "url", "=", "url", "\n", "self", ".", "uid", "=", "uuid", ".", "uuid4", "(", ")", ".", "hex", "\n", "self", ".", "is_valid", "=", "False", "\n", "self", ".", "http_code", "=", "False", "\n", "self", ".", "html", "=", "None", "\n", "self", ".", "screenshot_path", "=", "None", "\n", "self", ".", "features", "=", "None", "\n", "self", ".", "embedding", "=", "None", "\n", "self", ".", "scores", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model.Webpage.__repr__": [[175, 177], ["json.dumps"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "json", ".", "dumps", "(", "self", ".", "__dict__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.ResNetPretrained.__init__": [[13, 20], ["torch.nn.Module.__init__", "torchvision.resnet18", "torch.nn.Sequential", "torch.nn.Linear", "list", "torchvision.resnet18.children"], "methods", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.VisualExtractor.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ResNetPretrained", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "resnet", "=", "models", ".", "resnet18", "(", "pretrained", "=", "True", ")", "\n", "\n", "self", ".", "features", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "list", "(", "resnet", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", "\n", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "features_dim", ",", "out_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.ResNetPretrained.forward": [[22, 27], ["visual_extractor.ResNetPretrained.features().reshape", "visual_extractor.ResNetPretrained.fc1", "visual_extractor.ResNetPretrained.features"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", ".", "reshape", "(", "-", "1", ",", "features_dim", ")", "\n", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.VisualExtractor.__init__": [[37, 41], ["ResNetPretrained().to", "visual_extractor.ResNetPretrained"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "model", "=", "ResNetPretrained", "(", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "batch_size", "=", "128", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.visual_extractor.VisualExtractor.get_features": [[43, 80], ["torchvision.transforms.FiveCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Lambda", "torchvision.transforms.Compose", "PIL.Image.open", "torchvision.transforms.Compose.", "visual_extractor.VisualExtractor.model.eval", "int", "int", "torch.no_grad", "transforms.Compose.to", "data_transforms.to.size", "visual_extractor.VisualExtractor.model.features", "outputs.view().mean.view().mean.view().mean", "outputs.view().mean.view().mean.detach", "torch.stack", "data_transforms.to.view", "outputs.view().mean.view().mean.view", "torchvision.transforms.Normalize.", "torchvision.transforms.ToTensor."], "methods", ["None"], ["", "def", "get_features", "(", "self", ",", "screenshot_path", ")", ":", "\n", "\n", "# dimension of the images", "\n", "        ", "valid_xdim", "=", "640", "\n", "valid_ydim", "=", "360", "\n", "\n", "# factor for 5-crop transform", "\n", "crop_factor", "=", "0.6", "\n", "\n", "crop_dim", "=", "[", "int", "(", "crop_factor", "*", "valid_ydim", ")", ",", "int", "(", "crop_factor", "*", "valid_xdim", ")", "]", "\n", "\n", "# 5-crop transform", "\n", "five_crop", "=", "transforms", ".", "FiveCrop", "(", "size", "=", "crop_dim", ")", "\n", "\n", "# image to tensor transform", "\n", "tensorize", "=", "transforms", ".", "ToTensor", "(", ")", "\n", "\n", "# normalization transform", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "\n", "# to apply to each crop", "\n", "stack_norm_tensorize", "=", "transforms", ".", "Lambda", "(", "\n", "lambda", "crops", ":", "torch", ".", "stack", "(", "[", "normalize", "(", "tensorize", "(", "crop", ")", ")", "for", "crop", "in", "crops", "]", ")", ")", "\n", "\n", "# final transform: crop > tensorize > normalize", "\n", "data_transforms", "=", "transforms", ".", "Compose", "(", "[", "five_crop", ",", "stack_norm_tensorize", "]", ")", "\n", "\n", "img", "=", "Image", ".", "open", "(", "screenshot_path", ")", "\n", "img_tensor", "=", "data_transforms", "(", "img", ")", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "img_tensor", ".", "to", "(", "self", ".", "device", ")", "\n", "ncrops", ",", "c", ",", "h", ",", "w", "=", "inputs", ".", "size", "(", ")", "\n", "outputs", "=", "self", ".", "model", ".", "features", "(", "inputs", ".", "view", "(", "-", "1", ",", "c", ",", "h", ",", "w", ")", ")", "# output for each crop", "\n", "outputs", "=", "outputs", ".", "view", "(", "1", ",", "ncrops", ",", "-", "1", ")", ".", "mean", "(", "1", ")", "# mean over the crops", "\n", "", "return", "outputs", ".", "detach", "(", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.model_loader.get_model_path": [[11, 30], ["os.path.join", "os.makedirs", "os.path.join", "os.path.expanduser", "os.path.exists", "logging.debug", "urllib.request.urlretrieve", "logging.debug", "logging.debug", "zipfile.ZipFile", "zip_ref.extractall"], "function", ["None"], ["def", "get_model_path", "(", "visual", "=", "False", ")", ":", "\n", "    ", "if", "visual", ":", "\n", "        ", "model_name", "=", "\"h2v_1000_100\"", "\n", "model_url", "=", "model_with_visual_url", "\n", "", "else", ":", "\n", "        ", "model_name", "=", "\"h2v_1000_100_text_only\"", "\n", "model_url", "=", "model_without_visual_url", "\n", "", "model_home", "=", "os", ".", "path", ".", "join", "(", "expanduser", "(", "\"~\"", ")", ",", "'.homepage2vec'", ")", "\n", "os", ".", "makedirs", "(", "model_home", ",", "exist_ok", "=", "True", ")", "\n", "model_folder", "=", "os", ".", "path", ".", "join", "(", "model_home", ",", "model_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_folder", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'Downloading model {} in {}'", ".", "format", "(", "model_name", ",", "model_folder", ")", ")", "\n", "filename", ",", "headers", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "model_url", ")", "\n", "with", "zipfile", ".", "ZipFile", "(", "filename", ",", "\"r\"", ")", "as", "zip_ref", ":", "\n", "            ", "zip_ref", ".", "extractall", "(", "model_home", ")", "\n", "", "logging", ".", "debug", "(", "'Downloading model - Done.'", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "debug", "(", "'Model {} available in {}'", ".", "format", "(", "model_name", ",", "model_folder", ")", ")", "\n", "", "return", "model_home", ",", "model_folder", "\n", "", ""]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.data_collection.time_limit": [[18, 31], ["signal.signal", "signal.alarm", "data_collection.TimeoutException", "signal.alarm"], "function", ["None"], ["@", "contextmanager", "\n", "def", "time_limit", "(", "seconds", ")", ":", "\n", "    ", "\"\"\" Set a time limit on the execution of a block\"\"\"", "\n", "\n", "def", "signal_handler", "(", "signum", ",", "frame", ")", ":", "\n", "        ", "raise", "TimeoutException", "(", "\"Timed out!\"", ")", "\n", "\n", "", "signal", ".", "signal", "(", "signal", ".", "SIGALRM", ",", "signal_handler", ")", "\n", "signal", ".", "alarm", "(", "seconds", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "signal", ".", "alarm", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.data_collection.access_website": [[33, 63], ["data_collection.time_limit", "requests.utils.default_headers", "requests.utils.default_headers.update", "requests.get", "requests.get.headers.get().strip", "requests.get.encoding.lower", "url.startswith", "url.startswith", "requests.get.headers.get"], "function", ["home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.data_collection.time_limit"], ["", "", "def", "access_website", "(", "url", ",", "timeout", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Return the response corresponding to a url, or None if there was a request error\n    \"\"\"", "\n", "\n", "try", ":", "\n", "# avoid the script to be blocked", "\n", "        ", "with", "time_limit", "(", "10", "*", "timeout", ")", ":", "\n", "\n", "# change user-agent so that we don't look like a bot", "\n", "            ", "headers", "=", "requests", ".", "utils", ".", "default_headers", "(", ")", "\n", "headers", ".", "update", "(", "{", "\n", "'User-Agent'", ":", "'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.16; rv:84.0) Gecko/20100101 Firefox/84.0'", ",", "\n", "}", ")", "\n", "\n", "# r_head = requests.head(\"http://\" + url, timeout=timeout, headers=headers)", "\n", "if", "not", "url", ".", "startswith", "(", "\"http://\"", ")", "and", "not", "url", ".", "startswith", "(", "\"https:\"", ")", ":", "\n", "                ", "url", "=", "\"http://\"", "+", "url", "\n", "", "r_get", "=", "requests", ".", "get", "(", "url", ",", "timeout", "=", "timeout", ",", "headers", "=", "headers", ")", "\n", "\n", "# head_code = r_head.status_code", "\n", "get_code", "=", "r_get", ".", "status_code", "\n", "if", "r_get", ".", "encoding", ".", "lower", "(", ")", "!=", "'utf-8'", ":", "\n", "                ", "r_get", ".", "encoding", "=", "r_get", ".", "apparent_encoding", "\n", "", "text", "=", "r_get", ".", "text", "\n", "content_type", "=", "r_get", ".", "headers", ".", "get", "(", "'content-type'", ",", "'?'", ")", ".", "strip", "(", ")", "\n", "return", "text", ",", "get_code", ",", "content_type", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.epfl-dlab_homepage2vec.homepage2vec.data_collection.take_screenshot": [[65, 126], ["int", "int", "selenium.webdriver.ChromeOptions", "selenium.webdriver.Chrome", "webdriver.Chrome.set_page_load_timeout", "webdriver.Chrome.set_window_size", "webdriver.Chrome.get", "time.sleep", "webdriver.Chrome.save_screenshot", "PIL.Image.open", "img.resize.convert", "img.resize.resize", "img.resize.save", "os.remove", "webdriver.Chrome.execute_script", "print", "locals", "webdriver.Chrome.quit", "url.startswith", "url.startswith"], "function", ["None"], ["", "", "def", "take_screenshot", "(", "url", ",", "out_path", ",", "in_width", "=", "1920", ",", "in_height", "=", "1080", ",", "down_factor", "=", "3", ",", "quality", "=", "85", ",", "timeout", "=", "30", ")", ":", "\n", "    ", "\"\"\"\n    Take a screenshot of a website and save it under the outpath\n    \"\"\"", "\n", "\n", "out_width", "=", "int", "(", "in_width", "/", "down_factor", ")", "\n", "out_height", "=", "int", "(", "in_height", "/", "down_factor", ")", "\n", "\n", "try", ":", "\n", "\n", "# driver", "\n", "        ", "options", "=", "webdriver", ".", "ChromeOptions", "(", ")", "\n", "options", ".", "headless", "=", "True", "\n", "\n", "driver", "=", "webdriver", ".", "Chrome", "(", "'chromedriver'", ",", "options", "=", "options", ")", "\n", "\n", "driver", ".", "set_page_load_timeout", "(", "timeout", ")", "\n", "driver", ".", "set_window_size", "(", "in_width", ",", "in_height", ")", "\n", "\n", "# access the url", "\n", "if", "not", "url", ".", "startswith", "(", "\"http://\"", ")", "and", "not", "url", ".", "startswith", "(", "\"https:\"", ")", ":", "\n", "            ", "url", "=", "\"http://\"", "+", "url", "\n", "", "driver", ".", "get", "(", "url", ")", "\n", "\n", "# set the opacity to 0 for elements that might be popup, etc...", "\n", "try", ":", "\n", "            ", "targets", "=", "[", "\"popup\"", ",", "\"modal\"", ",", "\"cookie\"", "]", "# the substrings in the div we want to hide", "\n", "target_types", "=", "[", "\"class\"", ",", "\"id\"", "]", "# where the substrings are", "\n", "js_script", "=", "\"\"", "\n", "for", "tar", "in", "targets", ":", "\n", "                ", "for", "ty", "in", "target_types", ":", "\n", "                    ", "js_script", "+=", "\"document.styleSheets[0].insertRule('div[\"", "+", "ty", "+", "\"*=\"", "+", "tar", "+", "\"] {opacity: 0 !important}', 0); \\n\"", "\n", "\n", "", "", "driver", ".", "execute_script", "(", "js_script", ")", "\n", "\n", "# if can't access the css sheet", "\n", "", "except", "WebDriverException", "as", "e", ":", "\n", "            ", "pass", "\n", "\n", "# so that the website's elements are loaded", "\n", "", "time", ".", "sleep", "(", "2", ")", "\n", "\n", "# takes a screenshot (only in png)", "\n", "driver", ".", "save_screenshot", "(", "out_path", "+", "'.png'", ")", "\n", "\n", "# convert the png into a jpeg of lesser dimensions and quality", "\n", "img", "=", "Image", ".", "open", "(", "out_path", "+", "'.png'", ")", "\n", "img", "=", "img", ".", "convert", "(", "'RGB'", ")", "\n", "img", "=", "img", ".", "resize", "(", "(", "out_width", ",", "out_height", ")", ",", "Image", ".", "ANTIALIAS", ")", "\n", "img", ".", "save", "(", "out_path", "+", "'.jpeg'", ",", "optimize", "=", "True", ",", "quality", "=", "quality", ")", "\n", "os", ".", "remove", "(", "out_path", "+", "'.png'", ")", "\n", "return", "out_path", "+", "'.jpeg'", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "e", ")", "\n", "return", "\n", "\n", "", "finally", ":", "\n", "        ", "if", "'driver'", "in", "locals", "(", ")", ":", "\n", "            ", "driver", ".", "quit", "(", ")", "\n", "", "", "", ""]]}