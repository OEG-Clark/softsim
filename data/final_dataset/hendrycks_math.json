{"home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._fix_fracs": [[1, 31], ["string.split", "len", "len", "len", "len"], "function", ["None"], ["def", "_fix_fracs", "(", "string", ")", ":", "\n", "    ", "substrs", "=", "string", ".", "split", "(", "\"\\\\frac\"", ")", "\n", "new_str", "=", "substrs", "[", "0", "]", "\n", "if", "len", "(", "substrs", ")", ">", "1", ":", "\n", "        ", "substrs", "=", "substrs", "[", "1", ":", "]", "\n", "for", "substr", "in", "substrs", ":", "\n", "            ", "new_str", "+=", "\"\\\\frac\"", "\n", "if", "substr", "[", "0", "]", "==", "\"{\"", ":", "\n", "                ", "new_str", "+=", "substr", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "assert", "len", "(", "substr", ")", ">=", "2", "\n", "", "except", ":", "\n", "                    ", "return", "string", "\n", "", "a", "=", "substr", "[", "0", "]", "\n", "b", "=", "substr", "[", "1", "]", "\n", "if", "b", "!=", "\"{\"", ":", "\n", "                    ", "if", "len", "(", "substr", ")", ">", "2", ":", "\n", "                        ", "post_substr", "=", "substr", "[", "2", ":", "]", "\n", "new_str", "+=", "\"{\"", "+", "a", "+", "\"}{\"", "+", "b", "+", "\"}\"", "+", "post_substr", "\n", "", "else", ":", "\n", "                        ", "new_str", "+=", "\"{\"", "+", "a", "+", "\"}{\"", "+", "b", "+", "\"}\"", "\n", "", "", "else", ":", "\n", "                    ", "if", "len", "(", "substr", ")", ">", "2", ":", "\n", "                        ", "post_substr", "=", "substr", "[", "2", ":", "]", "\n", "new_str", "+=", "\"{\"", "+", "a", "+", "\"}\"", "+", "b", "+", "post_substr", "\n", "", "else", ":", "\n", "                        ", "new_str", "+=", "\"{\"", "+", "a", "+", "\"}\"", "+", "b", "\n", "", "", "", "", "", "string", "=", "new_str", "\n", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._fix_a_slash_b": [[32, 45], ["len", "string.split", "string.split", "int", "int", "string.split", "str", "str"], "function", ["None"], ["", "def", "_fix_a_slash_b", "(", "string", ")", ":", "\n", "    ", "if", "len", "(", "string", ".", "split", "(", "\"/\"", ")", ")", "!=", "2", ":", "\n", "        ", "return", "string", "\n", "", "a", "=", "string", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "b", "=", "string", ".", "split", "(", "\"/\"", ")", "[", "1", "]", "\n", "try", ":", "\n", "        ", "a", "=", "int", "(", "a", ")", "\n", "b", "=", "int", "(", "b", ")", "\n", "assert", "string", "==", "\"{}/{}\"", ".", "format", "(", "a", ",", "b", ")", "\n", "new_string", "=", "\"\\\\frac{\"", "+", "str", "(", "a", ")", "+", "\"}{\"", "+", "str", "(", "b", ")", "+", "\"}\"", "\n", "return", "new_string", "\n", "", "except", ":", "\n", "        ", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._remove_right_units": [[46, 54], ["string.split", "len"], "function", ["None"], ["", "", "def", "_remove_right_units", "(", "string", ")", ":", "\n", "# \"\\\\text{ \" only ever occurs (at least in the val set) when describing units", "\n", "    ", "if", "\"\\\\text{ \"", "in", "string", ":", "\n", "        ", "splits", "=", "string", ".", "split", "(", "\"\\\\text{ \"", ")", "\n", "assert", "len", "(", "splits", ")", "==", "2", "\n", "return", "splits", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._fix_sqrt": [[55, 68], ["string.split"], "function", ["None"], ["", "", "def", "_fix_sqrt", "(", "string", ")", ":", "\n", "    ", "if", "\"\\\\sqrt\"", "not", "in", "string", ":", "\n", "        ", "return", "string", "\n", "", "splits", "=", "string", ".", "split", "(", "\"\\\\sqrt\"", ")", "\n", "new_string", "=", "splits", "[", "0", "]", "\n", "for", "split", "in", "splits", "[", "1", ":", "]", ":", "\n", "        ", "if", "split", "[", "0", "]", "!=", "\"{\"", ":", "\n", "            ", "a", "=", "split", "[", "0", "]", "\n", "new_substr", "=", "\"\\\\sqrt{\"", "+", "a", "+", "\"}\"", "+", "split", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "new_substr", "=", "\"\\\\sqrt\"", "+", "split", "\n", "", "new_string", "+=", "new_substr", "\n", "", "return", "new_string", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._strip_string": [[69, 137], ["_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "math_equivalence._remove_right_units", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "_fix_a_slash_b.replace", "math_equivalence._fix_sqrt", "_fix_a_slash_b.replace", "math_equivalence._fix_fracs", "math_equivalence._fix_a_slash_b", "len", "len", "_fix_a_slash_b.split", "len", "_fix_a_slash_b.split", "_fix_a_slash_b.split"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._remove_right_units", "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._fix_sqrt", "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._fix_fracs", "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._fix_a_slash_b"], ["", "def", "_strip_string", "(", "string", ")", ":", "\n", "# linebreaks  ", "\n", "    ", "string", "=", "string", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "#print(string)", "\n", "\n", "# remove inverse spaces", "\n", "string", "=", "string", ".", "replace", "(", "\"\\\\!\"", ",", "\"\"", ")", "\n", "#print(string)", "\n", "\n", "# replace \\\\ with \\", "\n", "string", "=", "string", ".", "replace", "(", "\"\\\\\\\\\"", ",", "\"\\\\\"", ")", "\n", "#print(string)", "\n", "\n", "# replace tfrac and dfrac with frac", "\n", "string", "=", "string", ".", "replace", "(", "\"tfrac\"", ",", "\"frac\"", ")", "\n", "string", "=", "string", ".", "replace", "(", "\"dfrac\"", ",", "\"frac\"", ")", "\n", "#print(string)", "\n", "\n", "# remove \\left and \\right", "\n", "string", "=", "string", ".", "replace", "(", "\"\\\\left\"", ",", "\"\"", ")", "\n", "string", "=", "string", ".", "replace", "(", "\"\\\\right\"", ",", "\"\"", ")", "\n", "#print(string)", "\n", "\n", "# Remove circ (degrees)", "\n", "string", "=", "string", ".", "replace", "(", "\"^{\\\\circ}\"", ",", "\"\"", ")", "\n", "string", "=", "string", ".", "replace", "(", "\"^\\\\circ\"", ",", "\"\"", ")", "\n", "\n", "# remove dollar signs", "\n", "string", "=", "string", ".", "replace", "(", "\"\\\\$\"", ",", "\"\"", ")", "\n", "\n", "# remove units (on the right)", "\n", "string", "=", "_remove_right_units", "(", "string", ")", "\n", "\n", "# remove percentage", "\n", "string", "=", "string", ".", "replace", "(", "\"\\\\%\"", ",", "\"\"", ")", "\n", "string", "=", "string", ".", "replace", "(", "\"\\%\"", ",", "\"\"", ")", "\n", "\n", "# \" 0.\" equivalent to \" .\" and \"{0.\" equivalent to \"{.\" Alternatively, add \"0\" if \".\" is the start of the string", "\n", "string", "=", "string", ".", "replace", "(", "\" .\"", ",", "\" 0.\"", ")", "\n", "string", "=", "string", ".", "replace", "(", "\"{.\"", ",", "\"{0.\"", ")", "\n", "# if empty, return empty string", "\n", "if", "len", "(", "string", ")", "==", "0", ":", "\n", "        ", "return", "string", "\n", "", "if", "string", "[", "0", "]", "==", "\".\"", ":", "\n", "        ", "string", "=", "\"0\"", "+", "string", "\n", "\n", "# to consider: get rid of e.g. \"k = \" or \"q = \" at beginning", "\n", "", "if", "len", "(", "string", ".", "split", "(", "\"=\"", ")", ")", "==", "2", ":", "\n", "        ", "if", "len", "(", "string", ".", "split", "(", "\"=\"", ")", "[", "0", "]", ")", "<=", "2", ":", "\n", "            ", "string", "=", "string", ".", "split", "(", "\"=\"", ")", "[", "1", "]", "\n", "\n", "# fix sqrt3 --> sqrt{3}", "\n", "", "", "string", "=", "_fix_sqrt", "(", "string", ")", "\n", "\n", "# remove spaces", "\n", "string", "=", "string", ".", "replace", "(", "\" \"", ",", "\"\"", ")", "\n", "\n", "# \\frac1b or \\frac12 --> \\frac{1}{b} and \\frac{1}{2}, etc. Even works with \\frac1{72} (but not \\frac{72}1). Also does a/b --> \\\\frac{a}{b}", "\n", "string", "=", "_fix_fracs", "(", "string", ")", "\n", "\n", "# manually change 0.5 --> \\frac{1}{2}", "\n", "if", "string", "==", "\"0.5\"", ":", "\n", "        ", "string", "=", "\"\\\\frac{1}{2}\"", "\n", "\n", "# NOTE: X/Y changed to \\frac{X}{Y} in dataset, but in simple cases fix in case the model output is X/Y", "\n", "", "string", "=", "_fix_a_slash_b", "(", "string", ")", "\n", "\n", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv": [[138, 153], ["print", "math_equivalence._strip_string", "math_equivalence._strip_string", "print"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._strip_string", "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence._strip_string"], ["", "def", "is_equiv", "(", "str1", ",", "str2", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "if", "str1", "is", "None", "and", "str2", "is", "None", ":", "\n", "        ", "print", "(", "\"WARNING: Both None\"", ")", "\n", "return", "True", "\n", "", "if", "str1", "is", "None", "or", "str2", "is", "None", ":", "\n", "        ", "return", "False", "\n", "\n", "", "try", ":", "\n", "        ", "ss1", "=", "_strip_string", "(", "str1", ")", "\n", "ss2", "=", "_strip_string", "(", "str2", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "ss1", ",", "ss2", ")", "\n", "", "return", "ss1", "==", "ss2", "\n", "", "except", ":", "\n", "        ", "return", "str1", "==", "str2", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.GPT2Trainer.create_optimizer_and_scheduler": [[117, 152], ["print", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "print", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "print", "tune_gpt.GPT2Trainer.get_linear_schedule_with_warmup", "tune_gpt.GPT2Trainer.model.named_parameters", "tune_gpt.GPT2Trainer.model.named_parameters", "any", "any"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.GPT2Trainer.get_linear_schedule_with_warmup"], ["    ", "def", "create_optimizer_and_scheduler", "(", "self", ",", "num_training_steps", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Setup the optimizer and the learning rate scheduler.\n        We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\n        Trainer's init through :obj:`optimizers`, or subclass and override this method in a subclass.\n        \"\"\"", "\n", "if", "self", ".", "optimizer", "is", "None", ":", "\n", "            ", "print", "(", "\"Making AdamW Optimizer\"", ")", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "betas", "=", "(", "self", ".", "args", ".", "adam_beta1", ",", "self", ".", "args", ".", "adam_beta2", ")", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", "is", "None", ":", "\n", "\n", "            ", "if", "self", ".", "args", ".", "warmup_steps", "==", "-", "1", ":", "\n", "                ", "print", "(", "\"Using constant LR\"", ")", "\n", "self", ".", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "self", ".", "optimizer", ",", "lambda", "steps", ":", "1.0", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Using Linear warmup LR\"", ")", "\n", "self", ".", "lr_scheduler", "=", "self", ".", "get_linear_schedule_with_warmup", "(", "\n", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "num_training_steps", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.GPT2Trainer.get_linear_schedule_with_warmup": [[154, 170], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "max", "float", "float", "max", "float", "float", "max"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", ",", "num_training_steps", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"\n        Linear warmup from 0 to max lr, then linear decay from max_lr to 0.1*max_lr\n        As done in https://arxiv.org/pdf/2010.14701.pdf\n        \"\"\"", "\n", "def", "lr_lambda", "(", "current_step", ":", "int", ")", ":", "\n", "            ", "if", "current_step", "<", "num_warmup_steps", ":", "\n", "                ", "return", "float", "(", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "num_warmup_steps", ")", ")", "\n", "", "min_lr_multiplier", "=", "0.1", "\n", "return", "max", "(", "\n", "min_lr_multiplier", ",", "\n", "(", "(", "1", "-", "min_lr_multiplier", ")", "*", "float", "(", "num_training_steps", "-", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "num_training_steps", "-", "num_warmup_steps", ")", ")", ")", "+", "min_lr_multiplier", "\n", ")", "\n", "\n", "", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.run_training": [[32, 114], ["print", "print", "transformers.TrainingArguments", "tune_gpt.GPT2Trainer", "GPT2Trainer.remove_callback", "GPT2Trainer.add_callback", "print", "GPT2Trainer.train", "GPT2Trainer.save_model", "print", "transformers.GPT2LMHeadModel.from_pretrained", "print", "transformers.GPT2LMHeadModel.from_pretrained", "CustomTensorBoardCallback", "os.path.join", "len", "int", "int", "int", "len", "int", "int", "int", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["None"], ["def", "run_training", "(", "args", ",", "train_data", ")", ":", "\n", "\n", "    ", "if", "not", "args", ".", "save_steps", ":", "\n", "# Save every epoch", "\n", "        ", "if", "not", "args", ".", "tpu_num_cores", ":", "\n", "            ", "save_steps", "=", "len", "(", "train_data", ")", "\n", "save_steps", "=", "int", "(", "save_steps", "/", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", "\n", "save_steps", "=", "int", "(", "save_steps", "/", "args", ".", "grad_acc_steps", ")", "\n", "save_steps", "=", "int", "(", "save_steps", "/", "args", ".", "batch_size_per_replica", ")", "\n", "", "else", ":", "\n", "            ", "save_steps", "=", "len", "(", "train_data", ")", "\n", "save_steps", "=", "int", "(", "save_steps", "/", "8", ")", "# 8 TPU cores is constant for now.", "\n", "save_steps", "=", "int", "(", "save_steps", "/", "args", ".", "grad_acc_steps", ")", "\n", "save_steps", "=", "int", "(", "save_steps", "/", "args", ".", "batch_size_per_replica", ")", "\n", "", "", "else", ":", "\n", "        ", "save_steps", "=", "args", ".", "save_steps", "\n", "\n", "\n", "\n", "", "print", "(", "\"Save Steps = \"", ",", "save_steps", ")", "\n", "\n", "## Checkpoint Loading ######################################################## ", "\n", "if", "args", ".", "load", ":", "\n", "        ", "model", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "args", ".", "load", ")", "\n", "print", "(", "f\"Loaded model from {args.load}\"", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "args", ".", "arch", ")", "\n", "\n", "", "start_epoch", "=", "0", "\n", "start_iteration", "=", "0", "\n", "\n", "## Dataloading ######################################################## ", "\n", "train_data", ".", "start_iteration", "=", "start_iteration", "\n", "\n", "## Start Loop ########################################################", "\n", "print", "(", "f\"Setting up Trainer\"", ")", "\n", "\n", "training_args", "=", "transformers", ".", "TrainingArguments", "(", "\n", "output_dir", "=", "args", ".", "save_dir", ",", "\n", "overwrite_output_dir", "=", "False", ",", "\n", "\n", "do_train", "=", "True", ",", "\n", "do_eval", "=", "False", ",", "\n", "do_predict", "=", "True", ",", "\n", "evaluation_strategy", "=", "'no'", ",", "\n", "eval_steps", "=", "0", ",", "\n", "\n", "num_train_epochs", "=", "args", ".", "epochs", ",", "\n", "per_device_train_batch_size", "=", "args", ".", "batch_size_per_replica", ",", "\n", "gradient_accumulation_steps", "=", "args", ".", "grad_acc_steps", ",", "\n", "\n", "learning_rate", "=", "args", ".", "lr", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ",", "\n", "warmup_steps", "=", "args", ".", "lr_warmup_steps", ",", "\n", "max_grad_norm", "=", "100000.0", ",", "# Essentially disable gradient clipping", "\n", "\n", "logging_dir", "=", "args", ".", "save_dir", ",", "\n", "logging_first_step", "=", "True", ",", "\n", "logging_steps", "=", "args", ".", "log_freq", ",", "\n", "save_steps", "=", "save_steps", ",", "\n", "save_total_limit", "=", "10", ",", "# Only save the last epoch", "\n", "\n", "dataloader_drop_last", "=", "True", ",", "\n", "dataloader_num_workers", "=", "args", ".", "dataloader_num_workers", ",", "\n", "\n", "local_rank", "=", "args", ".", "local_rank", ",", "\n", "tpu_num_cores", "=", "args", ".", "tpu_num_cores", ",", "\n", ")", "\n", "\n", "trainer", "=", "GPT2Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_data", ",", "\n", ")", "\n", "trainer", ".", "remove_callback", "(", "transformers", ".", "integrations", ".", "TensorBoardCallback", ")", "\n", "trainer", ".", "add_callback", "(", "CustomTensorBoardCallback", "(", ")", ")", "\n", "\n", "print", "(", "f\"STARTING TRAINING. save_steps={save_steps}\"", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "\n", "trainer", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "\"final_checkpoint\"", ")", ")", "\n", "print", "(", "\"Finished\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.get_tokenizer_gpt": [[171, 198], ["transformers.GPT2Tokenizer.from_pretrained", "transformers.GPT2Tokenizer.from_pretrained"], "function", ["None"], ["", "", "def", "get_tokenizer_gpt", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    If args.tokenizer_merges_file is given, return a tokenizer that uses that merges_file.\n    In the paper, we use this to restrict models to ingest and outuput digits. For example:\n    \n    >>> tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"gpt2\", merges_file=\"merges_gpt2_single_digit_numbers.txt\")\n    >>> tokenizer_old = transformers.GPT2Tokenizer.from_pretrained(\"gpt2\")\n    >>> tokenizer.encode(\"1\")\n    [16]\n    >>> tokenizer_old.encode(\"1\")\n    [16]\n    >>> tokenizer.encode(\"2\")\n    [17] \n    >>> tokenizer_old.encode(\"12\")\n    [1065]\n    >>> tokenizer.encode(\"12\")\n    [16, 17]\n    >>> tokenizer.encode(\"HEllo world!\")\n    [13909, 18798, 995, 0]\n    >>> tokenizer_old.encode(\"HEllo world!\")\n    [13909, 18798, 995, 0]\n    \"\"\"", "\n", "if", "args", ".", "tokenizer_merges_file", "is", "not", "None", ":", "\n", "        ", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "args", ".", "arch", ",", "merges_file", "=", "args", ".", "tokenizer_merges_file", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "args", ".", "arch", ")", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.get_dataset": [[199, 270], ["tune_gpt.get_tokenizer_gpt", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "args.khan_dataroot.split", "float", "train_data.append", "train_data.append", "print", "mathematica_dr.split", "float", "os.path.join", "os.path.join", "dataset.khan_academy.KhanAcademyMathDataset", "dataset.MATH.MATHDataset", "open", "len", "open", "len", "train_data.append", "train_data.append", "f.readlines", "f.readlines", "dataset.mathematica.MathematicaMathDataset", "dataset.mathematica_with_steps.MathematicaWithStepsMathDataset", "len"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.get_tokenizer_gpt"], ["", "def", "get_dataset", "(", "args", ")", ":", "\n", "\n", "    ", "tokenizer", "=", "get_tokenizer_gpt", "(", "args", ")", "\n", "# print(tokenizer.tokenize(\"1231231234441234 blah dklkjl12490!!@ 2*x + y^k + f(x)\"))  # sanity check", "\n", "\n", "train_data", "=", "[", "]", "\n", "\n", "if", "args", ".", "mathematica_dataroot", ":", "\n", "        ", "for", "mathematica_dr", "in", "args", ".", "mathematica_dataroot", ":", "\n", "            ", "len_multiplier", ",", "dirname", "=", "mathematica_dr", ".", "split", "(", "\"@\"", ")", "\n", "len_multiplier", "=", "float", "(", "len_multiplier", ")", "\n", "\n", "no_steps_flist_fname", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"no_steps_flist_relative.txt\"", ")", "\n", "with_steps_flist_fname", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"with_steps_flist_relative.txt\"", ")", "\n", "\n", "with", "open", "(", "no_steps_flist_fname", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "no_steps_num_files", "=", "len", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "with_steps_flist_fname", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "with_steps_num_files", "=", "len", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n", "", "if", "no_steps_num_files", ":", "\n", "                ", "train_data", ".", "append", "(", "MathematicaMathDataset", "(", "\n", "dataroot", "=", "no_steps_flist_fname", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_tokens", "=", "384", "if", "args", ".", "arch", "==", "'gpt2-xl'", "else", "1024", ",", "\n", "mode", "=", "'gpt2'", ",", "\n", "len_multiplier", "=", "len_multiplier", "\n", ")", ")", "\n", "\n", "", "if", "with_steps_num_files", ":", "\n", "                ", "train_data", ".", "append", "(", "MathematicaWithStepsMathDataset", "(", "\n", "dataroot", "=", "with_steps_flist_fname", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_tokens", "=", "384", "if", "args", ".", "arch", "==", "'gpt2-xl'", "else", "1024", ",", "\n", "mode", "=", "'gpt2'", ",", "\n", "len_multiplier", "=", "len_multiplier", "\n", ")", ")", "\n", "\n", "", "", "", "if", "args", ".", "khan_dataroot", ":", "\n", "        ", "len_multiplier", ",", "dirname", "=", "args", ".", "khan_dataroot", ".", "split", "(", "\"@\"", ")", "\n", "len_multiplier", "=", "float", "(", "len_multiplier", ")", "\n", "train_data", ".", "append", "(", "KhanAcademyMathDataset", "(", "\n", "dataroot", "=", "dirname", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_tokens", "=", "384", "if", "args", ".", "arch", "==", "'gpt2-xl'", "else", "1024", ",", "\n", "mode", "=", "'gpt2'", ",", "\n", "mode_answer", "=", "args", ".", "khan_mode", ",", "\n", "len_multiplier", "=", "len_multiplier", ",", "\n", "latex_mask", "=", "args", ".", "khan_latex_mask", "\n", ")", ")", "\n", "\n", "", "if", "args", ".", "MATH_dataroot", ":", "\n", "        ", "train_data", ".", "append", "(", "MATHDataset", "(", "\n", "dataroot", "=", "args", ".", "MATH_dataroot", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_tokens", "=", "384", "if", "args", ".", "arch", "==", "'gpt2-xl'", "else", "1024", ",", "\n", "mode", "=", "'gpt2'", ",", "\n", "mode_answer", "=", "args", ".", "MATH_mode", ",", "\n", "len_multiplier", "=", "1.0", ",", "\n", "peek_fraction", "=", "(", "args", ".", "MATH_peek_min", ",", "args", ".", "MATH_peek_max", ")", ",", "\n", "packing", "=", "True", ",", "# Special for fine-tuning", "\n", "randomize", "=", "True", "# Special for fine-tuning", "\n", ")", ")", "\n", "\n", "\n", "# Print the sizes of each dataset, useful for weighting", "\n", "", "for", "dset", "in", "train_data", ":", "\n", "        ", "print", "(", "f\"{dset.__class__.__name__}: __len__ = {len(dset)}\"", ")", "\n", "\n", "", "return", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "train_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.main": [[272, 325], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "vars", "print", "tune_gpt.get_dataset", "os.makedirs", "tune_gpt.run_training", "datetime.datetime.now().strftime", "pprint.pformat", "open", "f.write", "os.path.join", "pprint.pformat", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.get_dataset", "home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.run_training"], ["", "def", "main", "(", ")", ":", "\n", "\n", "######### Arg parsing ###############################################################", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Language Modelling on Code\"", ")", "\n", "parser", ".", "add_argument", "(", "'--arch'", ",", "default", "=", "'gpt2'", ",", "choices", "=", "transformers", ".", "GPT2_PRETRAINED_MODEL_ARCHIVE_LIST", ")", "\n", "parser", ".", "add_argument", "(", "'--tokenizer-merges-file'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--load'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "\n", "# Dataloading", "\n", "parser", ".", "add_argument", "(", "'--khan-mode'", ",", "default", "=", "'mixed_hints'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--khan-dataroot'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--khan-latex-mask'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--deepmind-dataroot'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "action", "=", "'append'", ")", "\n", "parser", ".", "add_argument", "(", "'--mathematica-dataroot'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "action", "=", "'append'", ")", "\n", "parser", ".", "add_argument", "(", "'--mathematica-with-steps-dataroot'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "action", "=", "'append'", ")", "\n", "parser", ".", "add_argument", "(", "'--MATH-mode'", ",", "default", "=", "'mixed_final_boxed_and_full'", ",", "type", "=", "str", ",", "choices", "=", "[", "'mixed_final_boxed_and_full'", ",", "'final_boxed'", ",", "'peeking'", ",", "'nopack_padding'", ",", "'mixed_full_and_peeking'", ",", "'mixed_full_and_nopack_padding'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--MATH-peek-min'", ",", "default", "=", "0.1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--MATH-peek-max'", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--MATH-dataroot'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--stackexchange-dataroot'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--dataloader-num-workers'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "\n", "# Training", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "5e-5", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "default", "=", "0.05", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-warmup-steps'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size-per-replica'", ",", "default", "=", "8", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--grad-acc-steps'", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--tpu_num_cores'", ",", "default", "=", "None", ",", "type", "=", "int", ")", "\n", "\n", "# Logging and stuff", "\n", "parser", ".", "add_argument", "(", "'--save-dir'", ",", "default", "=", "\"checkpoints/TEMP\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--save-steps'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--log-freq'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%m-%d-%Y__%H:%M:%S\"", ")", ")", "\n", "\n", "######### Start training ###############################################################", "\n", "\n", "argsdict", "=", "vars", "(", "args", ")", "\n", "print", "(", "pprint", ".", "pformat", "(", "argsdict", ")", ")", "\n", "\n", "train_data", "=", "get_dataset", "(", "args", ")", "\n", "\n", "os", ".", "makedirs", "(", "args", ".", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "\"command.txt\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "pprint", ".", "pformat", "(", "argsdict", ")", ")", "\n", "\n", "", "run_training", "(", "args", ",", "train_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt._mp_fn": [[327, 330], ["tune_gpt.main"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.tune_gpt.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.clean_merges.hasNumbers": [[11, 13], ["any", "char.isdigit"], "function", ["None"], ["def", "hasNumbers", "(", "inputString", ")", ":", "\n", "    ", "return", "any", "(", "char", ".", "isdigit", "(", ")", "for", "char", "in", "inputString", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.get_level_type": [[40, 56], ["open", "int", "json.load", "print", "int.split"], "function", ["None"], ["def", "get_level_type", "(", "fname", ")", ":", "\n", "    ", "\"\"\"\n    Somewhat inefficient, but much easier than changing dataloader and probably fine for evaluation\n    \"\"\"", "\n", "with", "open", "(", "fname", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "try", ":", "\n", "            ", "problem_data", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "f\"Error loading JSON from {fname}\"", ",", "e", ")", "\n", "raise", "e", "\n", "", "", "level", ",", "prob_type", "=", "problem_data", "[", "'level'", "]", ",", "problem_data", "[", "'type'", "]", "\n", "try", ":", "\n", "        ", "level", "=", "int", "(", "level", ".", "split", "(", "\"Level \"", ")", "[", "1", "]", ")", "\n", "", "except", ":", "\n", "        ", "level", "=", "None", "\n", "", "return", "level", ",", "prob_type", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.remove_boxed": [[57, 65], ["len", "len"], "function", ["None"], ["", "def", "remove_boxed", "(", "s", ")", ":", "\n", "    ", "left", "=", "\"\\\\boxed{\"", "\n", "try", ":", "\n", "        ", "assert", "s", "[", ":", "len", "(", "left", ")", "]", "==", "left", "\n", "assert", "s", "[", "-", "1", "]", "==", "\"}\"", "\n", "return", "s", "[", "len", "(", "left", ")", ":", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.dict_to_gpu": [[67, 76], ["dict", "d.items", "dir", "value.cuda"], "function", ["None"], ["", "", "def", "dict_to_gpu", "(", "d", ",", "device_id", "=", "None", ")", ":", "\n", "    ", "new_dict", "=", "dict", "(", ")", "\n", "for", "key", ",", "value", "in", "d", ".", "items", "(", ")", ":", "\n", "# Only move to GPU is cuda() is a function", "\n", "        ", "if", "'cuda'", "in", "dir", "(", "value", ")", ":", "\n", "            ", "new_dict", "[", "key", "]", "=", "value", ".", "cuda", "(", "device_id", ")", "\n", "", "else", ":", "\n", "            ", "new_dict", "[", "key", "]", "=", "value", "\n", "", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.get_real_sol_idxs": [[78, 98], ["range", "tokens_sol[].item", "tokens_sol[].item", "tokens_sol[].item", "tokens_sol[].item"], "function", ["None"], ["", "def", "get_real_sol_idxs", "(", "tokens_sol", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"\n    Return the start and stop indexes (inclusive) for everything inside \\\\boxed{...}\n    \"\"\"", "\n", "left_idx", ",", "right_idx", "=", "None", ",", "None", "\n", "for", "i", "in", "range", "(", "tokens_sol", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "if", "i", "<", "3", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "tokens_sol", "[", "0", ",", "i", "]", ".", "item", "(", ")", "and", "tokens_sol", "[", "0", ",", "i", "-", "1", "]", ".", "item", "(", ")", "==", "276", "and", "tokens_sol", "[", "0", ",", "i", "-", "2", "]", ".", "item", "(", ")", "==", "3524", ":", "\n", "# at index i, we have the { of \\\\boxed{ ", "\n", "            ", "left_idx", "=", "i", "+", "1", "# Don't include the {", "\n", "\n", "", "if", "tokens_sol", "[", "0", ",", "i", "]", ".", "item", "(", ")", "==", "50256", ":", "\n", "            ", "right_idx", "=", "i", "-", "2", "# don't include the one token before the current one as well (usually the } from \\boxed{})", "\n", "\n", "# Will error if either is not found, which we dont expect", "\n", "", "", "return", "left_idx", ",", "right_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.run_eval": [[100, 312], ["vars", "print", "eval_math_gpt.get_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "transformers.GPT2LMHeadModel.from_pretrained.eval", "transformers.GPT2LMHeadModel.from_pretrained.cuda", "print", "print", "print", "pprint.pformat", "transformers.GPT2Tokenizer.from_pretrained", "transformers.GPT2Tokenizer.from_pretrained", "transformers.GPT2LMHeadModel.from_pretrained", "print", "transformers.GPT2LMHeadModel.from_pretrained", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "open", "enumerate", "print", "f.write", "sorted", "print", "f.write", "print", "f.write", "print", "print", "f.write", "f.write", "tqdm.tqdm", "fnames_list.append", "eval_math_gpt.get_level_type", "eval_math_gpt.dict_to_gpu", "transformers.GPT2LMHeadModel.from_pretrained.generate", "eval_math_gpt.get_model_output", "transformers.GPT2Tokenizer.from_pretrained.decode", "dataset.util.last_boxed_only_string", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "outputs.append", "answers.append", "types.append", "levels.append", "math_equivalence.is_equiv", "sum", "len", "sum", "len", "zip", "f.write", "print", "f.write", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "len", "dataset.util.last_boxed_only_string", "transformers.GPT2Tokenizer.from_pretrained.decode", "eval_math_gpt.remove_boxed", "eval_math_gpt.remove_boxed", "cors[].append", "level_cors[].append", "subject_cors[].append", "mean_max_probs_correct.append", "mean_max_probs_wrong.append", "sum", "len", "sum", "len", "print", "f.write", "transformers.GPT2Tokenizer.from_pretrained.decode", "transformers.GPT2Tokenizer.from_pretrained.decode", "print", "f.write", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.get_dataset", "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.get_level_type", "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.dict_to_gpu", "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.get_model_output", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.modeling.evaluate_gpt3.remove_boxed", "home.repos.pwc.inspect_result.hendrycks_math.modeling.evaluate_gpt3.remove_boxed"], ["", "def", "run_eval", "(", "args", ")", ":", "\n", "\n", "    ", "argsdict", "=", "vars", "(", "args", ")", "\n", "print", "(", "pprint", ".", "pformat", "(", "argsdict", ")", ")", "\n", "\n", "if", "args", ".", "tokenizer_merges_file", "is", "not", "None", ":", "\n", "        ", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "args", ".", "arch", ",", "merges_file", "=", "args", ".", "tokenizer_merges_file", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "args", ".", "arch", ")", "\n", "\n", "", "eval_data", "=", "get_dataset", "(", "args", ")", "\n", "for", "inner_dset", "in", "eval_data", ".", "datasets", ":", "\n", "        ", "inner_dset", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "eval_data", ",", "\n", "batch_size", "=", "1", ",", "\n", "num_workers", "=", "0", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "\n", "\"\"\"\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for i, batch in enumerate(tqdm(dataloader)):\n            batch = dict_to_gpu(batch, device_id=0)\n            print(batch['fnames'])\n            print(batch['input_ids'])\n            quit()\n    \"\"\"", "\n", "\n", "# Set up model", "\n", "if", "args", ".", "load", "is", "None", ":", "\n", "        ", "model", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "args", ".", "arch", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "f\"Loading model from {args.load}\"", ")", "\n", "model", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "args", ".", "load", ")", "\n", "print", "(", "f\"Successfully loaded model from {args.load}\"", ")", "\n", "\n", "", "model", "=", "model", ".", "eval", "(", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "loss_moving_average", "=", "0", "\n", "\n", "outputs", "=", "[", "]", "\n", "answers", "=", "[", "]", "\n", "types", "=", "[", "]", "\n", "levels", "=", "[", "]", "\n", "fnames_list", "=", "[", "]", "\n", "\n", "cors", "=", "{", "}", "\n", "subject_cors", "=", "{", "}", "\n", "level_cors", "=", "{", "}", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "correct", "=", "0", "\n", "total", "=", "0", "\n", "skipped", "=", "0", "\n", "mean_max_probs_correct", "=", "[", "]", "\n", "mean_max_probs_wrong", "=", "[", "]", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "dataloader", ")", ")", ":", "\n", "\n", "            ", "if", "torch", ".", "sum", "(", "batch", "[", "'input_ids'", "]", ")", "==", "0", ":", "\n", "                ", "skipped", "+=", "1", "\n", "print", "(", "\"SKIPPING\"", ",", "batch", "[", "'fnames'", "]", "[", "0", "]", ")", "\n", "continue", "\n", "\n", "", "fnames", "=", "batch", "[", "'fnames'", "]", "[", "0", "]", "\n", "assert", "len", "(", "fnames", ")", "==", "1", "\n", "fnames_list", ".", "append", "(", "fnames", "[", "0", "]", ")", "\n", "prob_level", ",", "prob_type", "=", "get_level_type", "(", "fnames", "[", "0", "]", ")", "\n", "batch", "=", "dict_to_gpu", "(", "batch", ",", "device_id", "=", "0", ")", "\n", "\n", "output_ids", "=", "model", ".", "generate", "(", "\n", "batch", "[", "'input_ids'", "]", ",", "\n", "num_beams", "=", "args", ".", "num_beams", ",", "\n", "early_stopping", "=", "True", ",", "\n", "temperature", "=", "1.0", ",", "\n", "max_length", "=", "384", "if", "args", ".", "arch", "==", "'gpt2-xl'", "else", "1024", "\n", ")", "\n", "\n", "# logits = model(output_ids).logits", "\n", "# probs = F.softmax(logits, dim=2) # torch.Size([1, L, 50257])", "\n", "# max_probs, max_tokens = probs.max(2) # torch.Size([1, L]), torch.Size([1, L])", "\n", "\n", "# num_tokens_for_question = batch['input_ids'].shape[1]", "\n", "# probs_sol = max_probs[:, num_tokens_for_question-1:]", "\n", "# tokens_sol = max_tokens[:, num_tokens_for_question-1:]", "\n", "\n", "# real_sol_start_idx, real_sol_stop_idx = get_real_sol_idxs(tokens_sol, tokenizer)", "\n", "# if real_sol_start_idx is None or real_sol_stop_idx is None:", "\n", "#     skipped += 1", "\n", "#     print(\"BAD ANSWER, SKIPPING\", batch['fnames'][0])", "\n", "#     continue", "\n", "# probs_sol = probs_sol[:, real_sol_start_idx:real_sol_stop_idx + 1]", "\n", "# mean_probs_sol = torch.mean(probs_sol).item()", "\n", "mean_probs_sol", "=", "0", "\n", "\n", "output_tokens", "=", "get_model_output", "(", "batch", "[", "'input_ids'", "]", "[", "0", "]", ",", "output_ids", "[", "0", "]", ",", "tokenizer", ")", "\n", "\n", "# Print this iteration", "\n", "output_str", "=", "tokenizer", ".", "decode", "(", "output_tokens", ")", "\n", "output_full", "=", "output_str", "\n", "output_str", "=", "last_boxed_only_string", "(", "output_str", ")", "\n", "\n", "if", "args", ".", "math_mode", "==", "\"eval_peeking\"", ":", "\n", "                ", "answer_str", "=", "last_boxed_only_string", "(", "tokenizer", ".", "decode", "(", "batch", "[", "'labels'", "]", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "answer_str", "=", "tokenizer", ".", "decode", "(", "batch", "[", "'labels'", "]", "[", "0", "]", ")", "\n", "\n", "", "output", ",", "answer", "=", "remove_boxed", "(", "output_str", ")", ",", "remove_boxed", "(", "answer_str", ")", "\n", "\n", "print", "(", "\"Problem String:\"", ")", "\n", "print", "(", "tokenizer", ".", "decode", "(", "batch", "[", "'input_ids'", "]", "[", "0", "]", ")", "+", "\"\\n\"", ")", "\n", "print", "(", "\"Model output:\"", ")", "\n", "print", "(", "output_full", ")", "\n", "print", "(", "output", ")", "\n", "print", "(", "\"Correct answer:\"", ")", "\n", "print", "(", "answer", ")", "\n", "print", "(", "\"fname\"", ")", "\n", "print", "(", "fnames", ")", "\n", "print", "(", "\"--------------------------------------------\"", ")", "\n", "\n", "# scratchwork_fname = \"___\".join(fnames[0].split(\"/\")[-2:])", "\n", "# with open(f\"scratchwork_Temp2e-1_{args.arch}/{scratchwork_fname}.txt\", 'w') as f:", "\n", "#     f.write(\"Problem String:\" + \"\\n\")", "\n", "#     f.write(tokenizer.decode(batch['input_ids'][0]) + \"\\n\")", "\n", "#     f.write(\"Model output:\" + \"\\n\")", "\n", "#     f.write(output_full + \"\\n\")", "\n", "#     f.write(str(output) + \"\\n\")", "\n", "#     f.write(\"Correct answer:\" + \"\\n\")", "\n", "#     f.write(answer + \"\\n\")", "\n", "#     f.write(\"--------------------------------------------\" + \"\\n\")", "\n", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "answers", ".", "append", "(", "answer", ")", "\n", "types", ".", "append", "(", "prob_type", ")", "\n", "levels", ".", "append", "(", "prob_level", ")", "\n", "\n", "equiv", "=", "is_equiv", "(", "output", ",", "answer", ")", "\n", "if", "(", "prob_level", ",", "prob_type", ")", "in", "cors", ":", "\n", "                ", "cors", "[", "(", "prob_level", ",", "prob_type", ")", "]", ".", "append", "(", "equiv", ")", "\n", "", "else", ":", "\n", "                ", "cors", "[", "(", "prob_level", ",", "prob_type", ")", "]", "=", "[", "equiv", "]", "\n", "\n", "", "if", "prob_level", "in", "level_cors", ":", "\n", "                ", "level_cors", "[", "prob_level", "]", ".", "append", "(", "equiv", ")", "\n", "", "else", ":", "\n", "                ", "if", "prob_level", "is", "not", "None", ":", "\n", "                    ", "level_cors", "[", "prob_level", "]", "=", "[", "equiv", "]", "\n", "\n", "", "", "if", "prob_type", "in", "subject_cors", ":", "\n", "                ", "subject_cors", "[", "prob_type", "]", ".", "append", "(", "equiv", ")", "\n", "", "else", ":", "\n", "                ", "if", "prob_type", "is", "not", "None", ":", "\n", "                    ", "subject_cors", "[", "prob_type", "]", "=", "[", "equiv", "]", "\n", "\n", "", "", "if", "equiv", ":", "\n", "                ", "correct", "+=", "1", "\n", "mean_max_probs_correct", ".", "append", "(", "mean_probs_sol", ")", "\n", "", "else", ":", "\n", "                ", "mean_max_probs_wrong", ".", "append", "(", "mean_probs_sol", ")", "\n", "\n", "# print(\"CORRECT\", mean_max_probs_correct)", "\n", "# print(\"WRONG\", mean_max_probs_wrong)", "\n", "\n", "", "total", "+=", "1", "\n", "\n", "", "", "subjects", "=", "[", "'Prealgebra'", ",", "'Algebra'", ",", "'Number Theory'", ",", "'Counting & Probability'", ",", "'Geometry'", ",", "'Intermediate Algebra'", ",", "'Precalculus'", "]", "\n", "\n", "print", "(", "f\"Average of mean_max_probs_correct = {sum(mean_max_probs_correct)}/{len(mean_max_probs_correct)} = \"", ",", "sum", "(", "mean_max_probs_correct", ")", "/", "len", "(", "mean_max_probs_correct", ")", ")", "\n", "print", "(", "f\"Average of mean_max_probs_wrong   = {sum(mean_max_probs_wrong)}/{len(mean_max_probs_wrong)} = \"", ",", "sum", "(", "mean_max_probs_wrong", ")", "/", "len", "(", "mean_max_probs_wrong", ")", ")", "\n", "\n", "# now save outputs and answers", "\n", "with", "open", "(", "f\"outputs_answers_Temp2e-1_{args.arch}.txt\"", ",", "\"w+\"", ")", "as", "f", ":", "\n", "        ", "for", "k", ",", "(", "output", ",", "answer", ",", "prob_type", ",", "prob_level", ",", "fname", ")", "in", "enumerate", "(", "zip", "(", "outputs", ",", "answers", ",", "types", ",", "levels", ",", "fnames_list", ")", ")", ":", "\n", "            ", "f", ".", "write", "(", "\"{} TYPE: {} | LEVEL: {} | OUTPUT: {} | ANSWER: {} | FNAME: {}\\n\"", ".", "format", "(", "k", ",", "prob_type", ",", "prob_level", ",", "output", ",", "answer", ",", "fname", ")", ")", "\n", "\n", "# print(cors)", "\n", "", "for", "prob_type", "in", "subjects", ":", "\n", "            ", "for", "prob_level", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ":", "\n", "                ", "if", "(", "prob_level", ",", "prob_type", ")", "in", "cors", ":", "\n", "                    ", "cors_list", "=", "cors", "[", "(", "prob_level", ",", "prob_type", ")", "]", "\n", "print", "(", "\"{} Level {} Accuracy = {}/{} = {:.3f}\"", ".", "format", "(", "prob_type", ",", "prob_level", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "f", ".", "write", "(", "\"{} Level {} Accuracy = {}/{} = {:.3f}\\n\"", ".", "format", "(", "prob_type", ",", "prob_level", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"#####################\"", ")", "\n", "f", ".", "write", "(", "\"#####################\\n\"", ")", "\n", "# also get accuracies for each ", "\n", "for", "level", "in", "sorted", "(", "level_cors", ")", ":", "\n", "            ", "cors_list", "=", "level_cors", "[", "level", "]", "\n", "print", "(", "\"Level {} Accuracy = {}/{} = {:.3f}\"", ".", "format", "(", "level", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "f", ".", "write", "(", "\"Level {} Accuracy = {}/{} = {:.3f}\\n\"", ".", "format", "(", "level", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "", "print", "(", "\"#####################\"", ")", "\n", "f", ".", "write", "(", "\"#####################\\n\"", ")", "\n", "\n", "for", "subject", "in", "subjects", ":", "\n", "# for subject in sorted(subject_cors):", "\n", "            ", "if", "subject", "in", "subject_cors", ":", "\n", "                ", "cors_list", "=", "subject_cors", "[", "subject", "]", "\n", "print", "(", "\"{} Accuracy = {}/{} = {:.3f}\"", ".", "format", "(", "subject", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "f", ".", "write", "(", "\"{} Accuracy = {}/{} = {:.3f}\\n\"", ".", "format", "(", "subject", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "", "", "print", "(", "\"#####################\"", ")", "\n", "f", ".", "write", "(", "\"#####################\\n\"", ")", "\n", "\n", "print", "(", "\"Overall Accuracy = {}/{} = {:.3f}\"", ".", "format", "(", "correct", ",", "total", ",", "correct", "/", "total", ")", ")", "\n", "print", "(", "\"Skipped = {}\"", ".", "format", "(", "skipped", ")", ")", "\n", "f", ".", "write", "(", "\"Overall Accuracy = {}/{} = {:.3f}\\n\"", ".", "format", "(", "correct", ",", "total", ",", "correct", "/", "total", ")", ")", "\n", "f", ".", "write", "(", "\"Skipped = {}\"", ".", "format", "(", "skipped", ")", ")", "\n", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.get_model_output": [[313, 323], ["len"], "function", ["None"], ["", "def", "get_model_output", "(", "context", ",", "full_output", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"\n    Given the context and the full model output (context + generated),\n    extract just the generated tokens.\n    Remove the last token if it is <|endoftext|>\n    \"\"\"", "\n", "ret", "=", "full_output", "[", "len", "(", "context", ")", ":", "]", "\n", "if", "ret", "[", "-", "1", "]", "==", "tokenizer", ".", "eos_token_id", ":", "\n", "        ", "ret", "=", "ret", "[", ":", "-", "1", "]", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.eval_math_gpt.get_dataset": [[324, 352], ["torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "all_datasets.append", "all_datasets.append", "dataset.MATH.MATHDataset", "dataset.MATH.MATHDataset"], "function", ["None"], ["", "def", "get_dataset", "(", "args", ")", ":", "\n", "    ", "all_datasets", "=", "[", "]", "\n", "\n", "if", "args", ".", "math_dataroot", "is", "not", "None", ":", "\n", "        ", "if", "args", ".", "math_mode", "==", "'gpt2-eval'", ":", "\n", "            ", "all_datasets", ".", "append", "(", "\n", "MATHDataset", "(", "\n", "dataroot", "=", "args", ".", "math_dataroot", ",", "\n", "tokenizer", "=", "None", ",", "# Set in run_training(), not in dataset creation ", "\n", "max_tokens", "=", "384", "if", "args", ".", "arch", "==", "'gpt2-xl'", "else", "1024", ",", "\n", "mode", "=", "'gpt2-eval'", ",", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "all_datasets", ".", "append", "(", "\n", "MATHDataset", "(", "\n", "dataroot", "=", "args", ".", "math_dataroot", ",", "\n", "tokenizer", "=", "None", ",", "# Set in run_training(), not in dataset creation ", "\n", "max_tokens", "=", "384", "if", "args", ".", "arch", "==", "'gpt2-xl'", "else", "1024", ",", "\n", "mode", "=", "'gpt2-eval'", ",", "\n", "mode_answer", "=", "args", ".", "math_mode", ",", "\n", "peek_fraction", "=", "args", ".", "peek_fraction", "\n", ")", "\n", ")", "\n", "\n", "\n", "", "", "train_data", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "all_datasets", ")", "\n", "return", "train_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.evaluate_gpt3.call_engine": [[11, 41], ["openai.Completion.create", "range", "max", "all_answers.items", "operator.itemgetter"], "function", ["None"], ["def", "call_engine", "(", "train_prompt", ",", "problem", ",", "engine", "=", "\"davinci\"", ")", ":", "\n", "    ", "'''\n    Given a problem, returns the most likely answer determined by the GPT engine \n    '''", "\n", "test_question", "=", "\"\\n\"", "+", "problem", "+", "\"\\n\"", "+", "\"Answer: $\"", "\n", "prompt", "=", "train_prompt", "+", "test_question", "\n", "# print(len(prompt))", "\n", "num_tokens", "=", "20", "\n", "c", "=", "openai", ".", "Completion", ".", "create", "(", "\n", "engine", "=", "engine", ",", "\n", "prompt", "=", "prompt", ",", "\n", "max_tokens", "=", "num_tokens", ",", "\n", "logprobs", "=", "100", ",", "\n", "temperature", "=", "0", ",", "\n", "echo", "=", "True", "\n", ")", "\n", "tokens", "=", "c", "[", "\"choices\"", "]", "[", "0", "]", "[", "\"logprobs\"", "]", "[", "\"tokens\"", "]", "\n", "startindex", "=", "-", "1", "*", "num_tokens", "\n", "endindex", "=", "-", "1", "*", "num_tokens", "+", "1", "\n", "for", "token", "in", "tokens", "[", "startindex", "+", "1", ":", "]", ":", "\n", "        ", "if", "token", "==", "\"$\"", "or", "token", "==", "\"###\"", "or", "token", "==", "\"\\n\"", ":", "\n", "            ", "break", "\n", "", "else", ":", "\n", "            ", "endindex", "+=", "1", "\n", "", "", "final_answer", "=", "\"\"", "\n", "for", "i", "in", "range", "(", "startindex", ",", "endindex", ")", ":", "\n", "        ", "all_answers", "=", "c", "[", "\"choices\"", "]", "[", "0", "]", "[", "\"logprobs\"", "]", "[", "\"top_logprobs\"", "]", "[", "i", "]", "\n", "best_answer", "=", "max", "(", "all_answers", ".", "items", "(", ")", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ")", "[", "0", "]", "\n", "final_answer", "+=", "best_answer", "\n", "", "return", "final_answer", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.evaluate_gpt3.remove_boxed": [[42, 50], ["len", "len"], "function", ["None"], ["", "def", "remove_boxed", "(", "s", ")", ":", "\n", "    ", "left", "=", "\"\\\\boxed{\"", "\n", "try", ":", "\n", "        ", "assert", "s", "[", ":", "len", "(", "left", ")", "]", "==", "left", "\n", "assert", "s", "[", "-", "1", "]", "==", "\"}\"", "\n", "return", "s", "[", "len", "(", "left", ")", ":", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.evaluate_gpt3.run": [[63, 171], ["os.walk", "open", "enumerate", "f.write", "print", "f.write", "sorted", "print", "f.write", "print", "f.write", "print", "f.write", "fnames_list.append", "zip", "f.write", "range", "print", "f.write", "print", "f.write", "os.path.join", "open", "evaluate_gpt3.call_engine", "evaluate_gpt3.remove_boxed", "levels.append", "types.append", "outputs.append", "answers.append", "print", "print", "print", "print", "print", "print", "print", "f.write", "level_cors.keys", "print", "subject_cors.keys", "print", "os.path.join", "json.load", "int", "dataset.util.last_boxed_only_string", "math_equivalence.is_equiv", "cors[].append", "level_cors[].append", "subject_cors[].append", "cors.keys", "print", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean", "print", "str", "numpy.sum", "len", "numpy.mean", "numpy.sum", "len", "numpy.mean", "int.split", "str"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.evaluate_gpt3.call_engine", "home.repos.pwc.inspect_result.hendrycks_math.modeling.evaluate_gpt3.remove_boxed", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["def", "run", "(", "engine", "=", "\"davinci\"", ",", "max", "=", "-", "1", ")", ":", "\n", "    ", "outputs", "=", "[", "]", "\n", "answers", "=", "[", "]", "\n", "types", "=", "[", "]", "\n", "levels", "=", "[", "]", "\n", "\n", "fnames_list", "=", "[", "]", "\n", "\n", "cors", "=", "{", "}", "\n", "subject_cors", "=", "{", "}", "\n", "level_cors", "=", "{", "}", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "for", "subdir", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "rootdir", ")", ":", "\n", "        ", "for", "file", "in", "files", ":", "\n", "            ", "fnames_list", ".", "append", "(", "os", ".", "path", ".", "join", "(", "subdir", ",", "file", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "subdir", ",", "file", ")", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "try", ":", "\n", "                    ", "problem_data", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "f\"Error loading JSON from {file}\"", ",", "e", ")", "\n", "raise", "e", "\n", "", "prob_level", "=", "problem_data", "[", "\"level\"", "]", "\n", "prob_type", "=", "problem_data", "[", "\"type\"", "]", "\n", "try", ":", "\n", "                    ", "prob_level", "=", "int", "(", "prob_level", ".", "split", "(", "\"Level \"", ")", "[", "1", "]", ")", "\n", "", "except", ":", "\n", "                    ", "prob_level", "=", "None", "\n", "", "model_output", "=", "call_engine", "(", "train_prompt", ",", "problem_data", "[", "\"problem\"", "]", ",", "engine", "=", "engine", ")", "\n", "answer", "=", "remove_boxed", "(", "last_boxed_only_string", "(", "problem_data", "[", "\"solution\"", "]", ")", ")", "\n", "\n", "levels", ".", "append", "(", "prob_level", ")", "\n", "types", ".", "append", "(", "prob_type", ")", "\n", "outputs", ".", "append", "(", "model_output", ")", "\n", "answers", ".", "append", "(", "answer", ")", "\n", "\n", "print", "(", "\"Model output:\"", ")", "\n", "print", "(", "model_output", ")", "\n", "print", "(", "\"Correct answer:\"", ")", "\n", "print", "(", "answer", ")", "\n", "print", "(", "\"--------------------------------------------\"", ")", "\n", "\n", "try", ":", "\n", "                    ", "equiv", "=", "is_equiv", "(", "model_output", ",", "answer", ")", "\n", "", "except", ":", "\n", "                    ", "equiv", "=", "False", "\n", "", "if", "(", "prob_level", ",", "prob_type", ")", "in", "cors", ":", "\n", "                    ", "cors", "[", "(", "prob_level", ",", "prob_type", ")", "]", ".", "append", "(", "equiv", ")", "\n", "", "else", ":", "\n", "                    ", "cors", "[", "(", "prob_level", ",", "prob_type", ")", "]", "=", "[", "equiv", "]", "\n", "", "if", "prob_level", "in", "level_cors", ":", "\n", "                    ", "level_cors", "[", "prob_level", "]", ".", "append", "(", "equiv", ")", "\n", "", "else", ":", "\n", "                    ", "if", "prob_level", "is", "not", "None", ":", "\n", "                        ", "level_cors", "[", "prob_level", "]", "=", "[", "equiv", "]", "\n", "", "", "if", "prob_type", "in", "subject_cors", ":", "\n", "                    ", "subject_cors", "[", "prob_type", "]", ".", "append", "(", "equiv", ")", "\n", "", "else", ":", "\n", "                    ", "if", "prob_type", "is", "not", "None", ":", "\n", "                        ", "subject_cors", "[", "prob_type", "]", "=", "[", "equiv", "]", "\n", "", "", "if", "equiv", ":", "\n", "                    ", "correct", "+=", "1", "\n", "", "total", "+=", "1", "\n", "\n", "print", "(", "str", "(", "correct", ")", "+", "\"/\"", "+", "str", "(", "total", ")", ")", "\n", "\n", "", "if", "max", ">", "0", "and", "total", ">", "max", ":", "\n", "                ", "break", "\n", "", "", "if", "max", ">", "0", "and", "total", ">", "max", ":", "\n", "            ", "break", "\n", "\n", "", "", "with", "open", "(", "\"outputs_answers_gpt3_{}.txt\"", ".", "format", "(", "engine", ")", ",", "\"w+\"", ")", "as", "f", ":", "\n", "        ", "for", "k", ",", "(", "output", ",", "answer", ",", "prob_type", ",", "prob_level", ",", "fname", ")", "in", "enumerate", "(", "zip", "(", "outputs", ",", "answers", ",", "types", ",", "levels", ",", "fnames_list", ")", ")", ":", "\n", "            ", "f", ".", "write", "(", "\"{} TYPE: {} | LEVEL: {} | OUTPUT: {} | ANSWER: {} | FNAME: {}\\n\"", ".", "format", "(", "k", ",", "prob_type", ",", "prob_level", ",", "output", ",", "answer", ",", "fname", ")", ")", "\n", "\n", "", "f", ".", "write", "(", "\"#####################\\n\"", ")", "\n", "# also get accuracies for each", "\n", "for", "subject", "in", "[", "'Prealgebra'", ",", "'Algebra'", ",", "'Number Theory'", ",", "'Counting & Probability'", ",", "'Geometry'", ",", "'Intermediate Algebra'", ",", "'Precalculus'", "]", ":", "\n", "            ", "for", "level", "in", "range", "(", "1", ",", "6", ")", ":", "\n", "                ", "key", "=", "(", "level", ",", "subject", ")", "\n", "if", "key", "not", "in", "cors", ".", "keys", "(", ")", ":", "\n", "                    ", "print", "(", "\"Skipping\"", ",", "key", ")", "\n", "continue", "\n", "", "cors_list", "=", "cors", "[", "key", "]", "\n", "print", "(", "\"{} Level {} Accuracy = {}/{} = {:.3f}\"", ".", "format", "(", "subject", ",", "level", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "f", ".", "write", "(", "\"{} Level {} Accuracy = {}/{} = {:.3f}\\n\"", ".", "format", "(", "subject", ",", "level", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "", "", "print", "(", "\"#####################\"", ")", "\n", "f", ".", "write", "(", "\"#####################\\n\"", ")", "\n", "for", "level", "in", "sorted", "(", "level_cors", ")", ":", "\n", "            ", "if", "level", "not", "in", "level_cors", ".", "keys", "(", ")", ":", "\n", "                ", "print", "(", "\"Skipping\"", ",", "level", ")", "\n", "continue", "\n", "", "cors_list", "=", "level_cors", "[", "level", "]", "\n", "print", "(", "\"Level {} Accuracy = {}/{} = {:.3f}\"", ".", "format", "(", "level", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "f", ".", "write", "(", "\"Level {} Accuracy = {}/{} = {:.3f}\\n\"", ".", "format", "(", "level", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "", "print", "(", "\"#####################\"", ")", "\n", "f", ".", "write", "(", "\"#####################\\n\"", ")", "\n", "for", "subject", "in", "[", "'Prealgebra'", ",", "'Algebra'", ",", "'Number Theory'", ",", "'Counting & Probability'", ",", "'Geometry'", ",", "'Intermediate Algebra'", ",", "'Precalculus'", "]", ":", "\n", "            ", "if", "subject", "not", "in", "subject_cors", ".", "keys", "(", ")", ":", "\n", "                ", "print", "(", "\"Skipping\"", ",", "subject", ")", "\n", "continue", "\n", "", "cors_list", "=", "subject_cors", "[", "subject", "]", "\n", "print", "(", "\"{} Accuracy = {}/{} = {:.3f}\"", ".", "format", "(", "subject", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "f", ".", "write", "(", "\"{} Accuracy = {}/{} = {:.3f}\\n\"", ".", "format", "(", "subject", ",", "np", ".", "sum", "(", "cors_list", ")", ",", "len", "(", "cors_list", ")", ",", "np", ".", "mean", "(", "cors_list", ")", ")", ")", "\n", "", "print", "(", "\"#####################\"", ")", "\n", "f", ".", "write", "(", "\"#####################\\n\"", ")", "\n", "print", "(", "\"Overall Accuracy = {}/{} = {:.3f}\"", ".", "format", "(", "correct", ",", "total", ",", "correct", "/", "total", ")", ")", "\n", "f", ".", "write", "(", "\"Overall Accuracy = {}/{} = {:.3f}\\n\"", ".", "format", "(", "correct", ",", "total", ",", "correct", "/", "total", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_fractions": [[7, 11], ["math_equivalence_test.TestIsEquiv.assertFalse", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["\t", "def", "test_fractions", "(", "self", ")", ":", "\n", "\t    ", "test_in", "=", "\"\\\\tfrac{1}{2} + \\\\frac1{72}\"", "\n", "test_out", "=", "\"\\\\\\\\frac{1}{2} + 2/3\"", "\n", "self", ".", "assertFalse", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_order": [[12, 16], ["math_equivalence_test.TestIsEquiv.assertFalse", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_order", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"10, 4, -2\"", "\n", "test_out", "=", "\"4, 10, -2\"", "\n", "self", ".", "assertFalse", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_order2": [[17, 21], ["math_equivalence_test.TestIsEquiv.assertFalse", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_order2", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"10, 4, 2\"", "\n", "test_out", "=", "\"4, 12, 2\"", "\n", "self", ".", "assertFalse", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_dfrac": [[22, 26], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_dfrac", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"\\\\tfrac{1}{2} +\\\\! \\\\frac1{72}\"", "\n", "test_out", "=", "\"\\\\\\\\dfrac{1}{2} +\\\\frac{1}{72}\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_units": [[27, 31], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_units", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"10\\\\text{ units}\"", "\n", "test_out", "=", "\"10 \"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_units2": [[32, 36], ["math_equivalence_test.TestIsEquiv.assertFalse", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_units2", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"10\\\\text{ units}\"", "\n", "test_out", "=", "\"100 \"", "\n", "self", ".", "assertFalse", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_dollars": [[37, 41], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_dollars", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"10\"", "\n", "test_out", "=", "\"\\\\$10\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_parentheses": [[42, 46], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_parentheses", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"\\\\left(x-2\\\\right)\\\\left(x+2\\\\right)\"", "\n", "test_out", "=", "\"(x-2)(x+2)\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_decimals": [[47, 51], ["math_equivalence_test.TestIsEquiv.assertFalse", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_decimals", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"0.1, 4, 2\"", "\n", "test_out", "=", "\"4, .1, 2\"", "\n", "self", ".", "assertFalse", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_decimals2": [[52, 56], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_decimals2", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"0.1\"", "\n", "test_out", "=", "\".1\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_percentage": [[57, 61], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_percentage", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"10\\\\%\"", "\n", "test_out", "=", "\"10\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_sqrt": [[62, 66], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_sqrt", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"10\\\\sqrt{3} + \\\\sqrt4\"", "\n", "test_out", "=", "\"10\\\\sqrt3 + \\\\sqrt{4}\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_frac": [[67, 71], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_frac", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"\\\\frac34i\"", "\n", "test_out", "=", "\"\\\\frac{3}{4}i\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_tfrac": [[72, 76], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_tfrac", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"\\\\tfrac83\"", "\n", "test_out", "=", "\"\\\\frac{8}{3}\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_expression": [[77, 81], ["math_equivalence_test.TestIsEquiv.assertFalse", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_expression", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"5x - 7y + 11z + 4 = 0\"", "\n", "test_out", "=", "\"x + y - z + 2 = 0\"", "\n", "self", ".", "assertFalse", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence_test.TestIsEquiv.test_half": [[82, 86], ["math_equivalence_test.TestIsEquiv.assertTrue", "math_equivalence.is_equiv"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.modeling.math_equivalence.is_equiv"], ["", "def", "test_half", "(", "self", ")", ":", "\n", "\t\t", "test_in", "=", "\"1/2\"", "\n", "test_out", "=", "\"\\\\frac{1}{2}\"", "\n", "self", ".", "assertTrue", "(", "is_equiv", "(", "test_in", ",", "test_out", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.mathematica_with_steps.MathematicaWithStepsMathDataset.__len__": [[27, 29], ["int", "len"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "len", "(", "self", ".", "samples", ")", "*", "self", ".", "len_multiplier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.mathematica_with_steps.MathematicaWithStepsMathDataset.initialize": [[30, 75], ["print", "tqdm.tqdm.tqdm", "print", "open", "fp.readlines", "os.path.join.rstrip", "os.path.join", "os.path.dirname", "open", "answers.append", "samples_raw.append", "len", "os.path.dirname", "len", "answers.append"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Set up self.samples by loading from the dataroot\n        \"\"\"", "\n", "\n", "with", "open", "(", "self", ".", "dataroot", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "all_filenames", "=", "fp", ".", "readlines", "(", ")", "\n", "\n", "", "print", "(", "f\"{self.__class__.__name__}: Loading samples from {len(all_filenames)} files.\"", ")", "\n", "samples_raw", "=", "[", "]", "\n", "for", "fname", "in", "tqdm", "(", "all_filenames", ")", ":", "\n", "            ", "fname", "=", "fname", ".", "rstrip", "(", ")", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "self", ".", "dataroot", ")", ")", ",", "fname", "[", "2", ":", "]", ")", "\n", "with", "open", "(", "fname", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "question", "=", "\"\"", "\n", "answers", "=", "[", "]", "\n", "reading_question", "=", "True", "\n", "curr_section", "=", "\"\"", "\n", "for", "line", "in", "fp", ":", "\n", "                    ", "if", "line", "==", "\"Problem:\\n\"", ":", "\n", "                        ", "reading_question", "=", "True", "\n", "", "elif", "line", "==", "\"Answer:\\n\"", ":", "\n", "                        ", "if", "reading_question", ":", "\n", "# curr_section contains Q", "\n", "                            ", "question", "=", "curr_section", "\n", "", "else", ":", "\n", "# curr_section contains an A", "\n", "                            ", "answers", ".", "append", "(", "curr_section", ")", "\n", "", "curr_section", "=", "\"\"", "\n", "reading_question", "=", "False", "\n", "", "else", ":", "\n", "                        ", "curr_section", "+=", "line", "\n", "\n", "# The last answer needs to be recorded.", "\n", "", "", "answers", ".", "append", "(", "curr_section", ")", "\n", "\n", "", "for", "a", "in", "answers", ":", "\n", "                ", "samples_raw", ".", "append", "(", "(", "question", ",", "a", ",", "fname", ")", ")", "\n", "\n", "# manager = Manager()", "\n", "# samples_raw = manager.list(samples_raw)", "\n", "", "", "self", ".", "samples", "=", "samples_raw", "\n", "del", "samples_raw", "\n", "\n", "print", "(", "f\"{self.__class__.__name__}: Loaded {len(self.samples)} samples.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.mathematica_with_steps.MathematicaWithStepsMathDataset.clean_filter_sample_gpt": [[76, 127], ["torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "mathematica_with_steps.MathematicaWithStepsMathDataset.tokenizer.encode", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "mathematica_with_steps.MathematicaWithStepsMathDataset.tokenizer.encode", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "NotImplementedError", "mathematica_with_steps.MathematicaWithStepsMathDataset.tokenizer.encode", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_gpt", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "if", "self", ".", "mode_answer", "==", "'default'", ":", "\n", "            ", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "sep_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFULL SOLUTION:\\n\"", ",", "verbose", "=", "False", ")", "\n", "sep_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "sep_ids", "=", "torch", ".", "LongTensor", "(", "sep_ids", ")", "\n", "\n", "answer_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer", ",", "verbose", "=", "False", ")", "\n", "answer_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "answer_ids", "=", "torch", ".", "LongTensor", "(", "answer_ids", ")", "\n", "\n", "# Use full solution", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "sep_ids", ",", "\n", "answer_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "question_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "sep_ids", ")", "*", "-", "100", ",", "\n", "answer_ids", ".", "clone", "(", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "", "if", "question_ids", ".", "shape", "[", "0", "]", "+", "sep_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"{self.__class__.__name__} Skipping due to input_ids being too big. question_ids.shape[0] + sep_ids.shape[0] = {question_ids.shape[0] + sep_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.mathematica_with_steps.MathematicaWithStepsMathDataset.clean_filter_sample_t5": [[129, 168], ["torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "NotImplementedError", "mathematica_with_steps.MathematicaWithStepsMathDataset.tokenizer.encode", "mathematica_with_steps.MathematicaWithStepsMathDataset.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_t5", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "if", "self", ".", "mode_answer", "==", "'default'", ":", "\n", "            ", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", "+", "\"\\nFULL SOLUTION:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "answer_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "", "if", "input_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"{self.__class__.__name__} Skipping due to input_ids being too big. input_ids.shape[0] = {input_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.khan_academy.KhanAcademyMathDataset.__len__": [[26, 28], ["int", "len"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "len", "(", "self", ".", "samples", ")", "*", "self", ".", "len_multiplier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.khan_academy.KhanAcademyMathDataset.initialize": [[29, 73], ["glob.glob", "print", "tqdm.tqdm.tqdm", "multiprocessing.Manager", "multiprocessing.Manager.list", "print", "multiprocessing.Manager.list.append", "open", "json.load", "json.load.get", "len", "print", "print", "print", "print", "len"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Set up self.samples by loading from the dataroot\n        \"\"\"", "\n", "\n", "all_filenames", "=", "glob", ".", "glob", "(", "self", ".", "dataroot", ")", "\n", "print", "(", "f\"{self.__class__.__name__}: Loading samples from {len(all_filenames)} files.\"", ")", "\n", "samples_raw", "=", "[", "]", "\n", "for", "fname", "in", "tqdm", "(", "all_filenames", ")", ":", "\n", "# Each fname is a json file with the following structure:", "\n", "# {", "\n", "#     \"problem\": \"How many positive three-digit ...?\",", "\n", "#     \"level\": \"Level 24\",", "\n", "#     \"type\": \"Counting & Probability\",", "\n", "#     \"solution\": \"<Blah>\",", "\n", "#     \"discuss\": \"\"", "\n", "# }", "\n", "            ", "with", "open", "(", "fname", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "problem_data", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "q", "=", "problem_data", ".", "get", "(", "'question'", ",", "None", ")", "or", "problem_data", "[", "'problem'", "]", "\n", "\n", "if", "'hints'", "in", "problem_data", ":", "\n", "                ", "a", "=", "problem_data", "[", "'hints'", "]", "\n", "", "elif", "'solution'", "in", "problem_data", ":", "\n", "                ", "print", "(", "f\"Falling back to 'solution': {fname}\"", ")", "\n", "a", "=", "problem_data", "[", "'solution'", "]", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Malformed file\"", ")", "\n", "print", "(", "fname", ")", "\n", "print", "(", "problem_data", ")", "\n", "\n", "\n", "", "assert", "q", "is", "not", "None", "and", "a", "is", "not", "None", "\n", "\n", "curr_sample_raw", "=", "(", "q", ",", "a", ",", "fname", ")", "\n", "samples_raw", ".", "append", "(", "curr_sample_raw", ")", "\n", "\n", "", "manager", "=", "Manager", "(", ")", "\n", "samples_raw", "=", "manager", ".", "list", "(", "samples_raw", ")", "\n", "self", ".", "samples", "=", "samples_raw", "\n", "del", "samples_raw", "\n", "\n", "print", "(", "f\"{self.__class__.__name__}: Loaded {len(self.samples)} samples.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.khan_academy.KhanAcademyMathDataset.tokenize_latex_mask_full_answer": [[75, 105], ["khan_academy.KhanAcademyMathDataset.tokenizer.encode", "khan_academy.KhanAcademyMathDataset.tokenizer.tokenize", "enumerate", "range", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "len", "len", "int"], "methods", ["None"], ["", "def", "tokenize_latex_mask_full_answer", "(", "self", ",", "answer_full", ")", ":", "\n", "        ", "\"\"\"\n        Tokenize the full answer string.\n        If needed, mask the tokenized version to only include latex tokens.\n        \"\"\"", "\n", "\n", "answer_full_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer_full", ",", "verbose", "=", "False", ")", "\n", "\n", "tokenized", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "answer_full", ")", "\n", "mask", "=", "[", "None", "for", "_", "in", "tokenized", "]", "\n", "\n", "prev_char", "=", "None", "\n", "in_latex", "=", "False", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokenized", ")", ":", "\n", "            ", "for", "char", "in", "token", ":", "\n", "                ", "if", "char", "==", "'$'", "and", "prev_char", "!=", "'\\\\'", ":", "\n", "# Found a dollar sign that represents latex start/end.", "\n", "                    ", "mask", "[", "i", "]", "=", "1", "\n", "in_latex", "=", "not", "in_latex", "\n", "", "else", ":", "\n", "                    ", "mask", "[", "i", "]", "=", "int", "(", "in_latex", ")", "\n", "\n", "", "", "", "assert", "len", "(", "mask", ")", "==", "len", "(", "answer_full_ids", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "answer_full_ids", ")", ")", ":", "\n", "            ", "if", "mask", "[", "i", "]", "==", "0", ":", "\n", "                ", "answer_full_ids", "[", "i", "]", "=", "-", "100", "\n", "\n", "", "", "answer_full_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "answer_full_ids", "=", "torch", ".", "LongTensor", "(", "answer_full_ids", ")", "\n", "return", "answer_full_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.khan_academy.KhanAcademyMathDataset.clean_filter_sample_gpt": [[107, 181], ["torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "dataset.util._clean_numbers", "list", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "NotImplementedError", "map", "khan_academy.KhanAcademyMathDataset.tokenizer.encode", "random.random", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "khan_academy.KhanAcademyMathDataset.tokenizer.encode", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "khan_academy.KhanAcademyMathDataset.tokenizer.encode", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "khan_academy.KhanAcademyMathDataset.tokenizer.encode", "khan_academy.KhanAcademyMathDataset.tokenize_latex_mask_full_answer", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone", "khan_academy.KhanAcademyMathDataset.tokenizer.encode", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.khan_academy.KhanAcademyMathDataset.tokenize_latex_mask_full_answer"], ["", "def", "clean_filter_sample_gpt", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "list", "(", "map", "(", "_clean_numbers", ",", "answer", ")", ")", "\n", "\n", "", "if", "self", ".", "mode_answer", "==", "'mixed_hints'", ":", "\n", "            ", "answer_full", "=", "\"\"", ".", "join", "(", "answer", ")", "\n", "answer_final", "=", "answer", "[", "-", "1", "]", "\n", "\n", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "# Use full solution", "\n", "                ", "sep_ids_2", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFULL SOLUTION:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_full_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer_full", ",", "verbose", "=", "False", ")", "\n", "answer_full_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "answer_full_ids", "=", "torch", ".", "LongTensor", "(", "answer_full_ids", ")", "\n", "if", "self", ".", "latex_mask", ":", "\n", "                    ", "answer_full_ids_label", "=", "self", ".", "tokenize_latex_mask_full_answer", "(", "answer_full", ")", "\n", "", "else", ":", "\n", "                    ", "answer_full_ids_label", "=", "answer_full_ids", ".", "clone", "(", ")", "\n", "\n", "", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "sep_ids_2", ",", "\n", "answer_full_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "question_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "sep_ids_2", ")", "*", "-", "100", ",", "\n", "answer_full_ids_label", "\n", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "# Use only final answer", "\n", "                ", "sep_ids_1", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFINAL ANSWER:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_final_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer_final", ",", "verbose", "=", "False", ")", "\n", "answer_final_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "answer_final_ids", "=", "torch", ".", "LongTensor", "(", "answer_final_ids", ")", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "sep_ids_1", ",", "\n", "answer_final_ids", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "question_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "sep_ids_1", ")", "*", "-", "100", ",", "\n", "answer_final_ids", ".", "clone", "(", ")", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "", "if", "question_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"{self.__class__.__name__} Skipping due to input_ids being too big. question_ids.shape[0] = {question_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.khan_academy.KhanAcademyMathDataset.clean_filter_sample_t5": [[183, 231], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.tolist.tolist.tolist", "label_ids.tolist.tolist.tolist", "dataset.util._clean_numbers", "list", "NotImplementedError", "map", "random.random", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "khan_academy.KhanAcademyMathDataset.tokenizer.encode", "khan_academy.KhanAcademyMathDataset.tokenizer.encode", "khan_academy.KhanAcademyMathDataset.tokenizer.encode", "khan_academy.KhanAcademyMathDataset.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_t5", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "list", "(", "map", "(", "_clean_numbers", ",", "answer", ")", ")", "\n", "\n", "", "if", "self", ".", "mode_answer", "==", "'mixed_hints'", ":", "\n", "            ", "answer_full", "=", "\"\"", ".", "join", "(", "answer", ")", "\n", "answer_final", "=", "answer", "[", "-", "1", "]", "\n", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "# Use full solution", "\n", "                ", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", "+", "\"\\nFULL SOLUTION:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer_full", ",", "verbose", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "# Use only final answer", "\n", "                ", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", "+", "\"\\nFINAL ANSWER:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer_final", ",", "verbose", "=", "False", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "answer_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "if", "question_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"{self.__class__.__name__} Skipping due to input_ids being too big. question_ids.shape[0] = {question_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.__init__": [[25, 65], ["base_math_dataset.BaseMathDataset.initialize", "set", "print", "print", "print", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.initialize"], ["def", "__init__", "(", "self", ",", "dataroot", ",", "tokenizer", ",", "max_tokens", ",", "mode", ",", "mode_answer", "=", "'default'", ",", "len_multiplier", "=", "1.0", ",", "packing", "=", "None", ",", "randomize", "=", "None", ",", "pack_end", "=", "None", ",", "clean_numbers", "=", "False", ",", "latex_mask", "=", "False", ",", "peek_fraction", "=", "(", "0.1", ",", "1.0", ")", ")", ":", "\n", "        ", "self", ".", "dataroot", "=", "dataroot", "\n", "self", ".", "tokenizer", "=", "tokenizer", "# Set in run_training(), not in dataset creation", "\n", "self", ".", "max_tokens", "=", "max_tokens", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "mode_answer", "=", "mode_answer", "# Used in subclass", "\n", "self", ".", "len_multiplier", "=", "len_multiplier", "\n", "self", ".", "clean_numbers", "=", "clean_numbers", "\n", "self", ".", "latex_mask", "=", "latex_mask", "\n", "self", ".", "peek_fraction", "=", "peek_fraction", "\n", "\n", "if", "self", ".", "mode", "in", "{", "'gpt2'", "}", ":", "\n", "            ", "self", ".", "clean_sample", "=", "self", ".", "clean_filter_sample_gpt", "\n", "self", ".", "packing", "=", "True", "\n", "self", ".", "randomize", "=", "True", "\n", "self", ".", "include_fnames", "=", "False", "\n", "self", ".", "pack_end", "=", "True", "\n", "", "elif", "self", ".", "mode", "in", "{", "'gpt2-eval'", "}", ":", "\n", "            ", "self", ".", "clean_sample", "=", "self", ".", "clean_filter_sample_gpt_eval", "\n", "self", ".", "packing", "=", "False", "\n", "self", ".", "randomize", "=", "False", "\n", "self", ".", "include_fnames", "=", "True", "\n", "self", ".", "pack_end", "=", "True", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "if", "packing", "!=", "None", ":", "\n", "            ", "print", "(", "\"Overriding packing to be\"", ",", "packing", ")", "\n", "self", ".", "packing", "=", "packing", "\n", "", "if", "randomize", "!=", "None", ":", "\n", "            ", "print", "(", "\"Overriding randomize to be\"", ",", "randomize", ")", "\n", "self", ".", "randomize", "=", "randomize", "\n", "", "if", "pack_end", "!=", "None", ":", "\n", "            ", "print", "(", "\"Overriding pack_end to be\"", ",", "pack_end", ")", "\n", "self", ".", "pack_end", "=", "pack_end", "\n", "\n", "", "self", ".", "initialize", "(", ")", "\n", "\n", "self", ".", "bad_fnames", "=", "set", "(", ")", "\n", "self", ".", "i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.initialize": [[67, 69], ["NotImplementedError"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.__len__": [[70, 72], ["NotImplementedError"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.__getitem__": [[73, 146], ["random.seed", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "base_math_dataset.BaseMathDataset.get_random_sample", "curr_input_ids.extend", "curr_label_ids.extend", "curr_fnames.append", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "random.random", "len", "len", "len", "len", "len", "len", "os.getpid", "time.time", "len", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.get_random_sample"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "# Each worker needs a different seed....", "\n", "        ", "random", ".", "seed", "(", "os", ".", "getpid", "(", ")", "+", "time", ".", "time", "(", ")", "+", "random", ".", "random", "(", ")", ")", "\n", "\n", "# Sampling with replacement.", "\n", "# We need to pack random elements to get close to self.max_tokens", "\n", "curr_input_ids", "=", "[", "]", "\n", "curr_label_ids", "=", "[", "]", "\n", "curr_fnames", "=", "[", "]", "\n", "num_samples", "=", "0", "\n", "while", "len", "(", "curr_input_ids", ")", "+", "1", "<=", "self", ".", "max_tokens", "and", "len", "(", "curr_label_ids", ")", "+", "1", "<=", "self", ".", "max_tokens", ":", "\n", "            ", "curr_sample", ",", "fname", "=", "self", ".", "get_random_sample", "(", ")", "\n", "if", "curr_sample", "is", "None", ":", "\n", "# This only happens in eval modes", "\n", "                ", "return", "{", "\n", "\"input_ids\"", ":", "torch", ".", "zeros", "(", "[", "self", ".", "max_tokens", "]", ")", ",", "\n", "\"labels\"", ":", "torch", ".", "zeros", "(", "[", "self", ".", "max_tokens", "]", ")", ",", "\n", "\"fnames\"", ":", "[", "fname", "]", "\n", "}", "\n", "\n", "", "if", "not", "self", ".", "pack_end", "and", "(", "\n", "(", "len", "(", "curr_input_ids", ")", "+", "1", "+", "len", "(", "curr_sample", "[", "'input_ids_list'", "]", ")", ">", "self", ".", "max_tokens", ")", "or", "\n", "(", "len", "(", "curr_label_ids", ")", "+", "1", "+", "len", "(", "curr_sample", "[", "'label_ids_list'", "]", ")", ">", "self", ".", "max_tokens", ")", "\n", ")", ":", "\n", "# Do not include curr_sample if either the input_ids or the label_ids will run off the end.", "\n", "                ", "break", "\n", "\n", "# Add curr_sample to the current inputs and labels", "\n", "", "curr_input_ids", ".", "extend", "(", "curr_sample", "[", "'input_ids_list'", "]", ")", "\n", "curr_label_ids", ".", "extend", "(", "curr_sample", "[", "'label_ids_list'", "]", ")", "\n", "curr_fnames", ".", "append", "(", "fname", ")", "\n", "\n", "num_samples", "+=", "1", "\n", "\n", "# Break on the first iteration if we don't want to do packing.", "\n", "if", "not", "self", ".", "packing", ":", "\n", "                ", "break", "\n", "\n", "", "", "input_ids", "=", "torch", ".", "LongTensor", "(", "curr_input_ids", ")", "\n", "label_ids", "=", "torch", ".", "LongTensor", "(", "curr_label_ids", ")", "\n", "\n", "# Sanity check", "\n", "if", "'eval'", "not", "in", "self", ".", "mode", ":", "\n", "            ", "assert", "len", "(", "curr_input_ids", ")", "==", "len", "(", "curr_label_ids", ")", "\n", "\n", "", "input_ids", "=", "input_ids", "[", ":", "self", ".", "max_tokens", "]", "\n", "label_ids", "=", "label_ids", "[", ":", "self", ".", "max_tokens", "]", "\n", "\n", "if", "len", "(", "curr_input_ids", ")", "<", "self", ".", "max_tokens", "and", "'eval'", "not", "in", "self", ".", "mode", ":", "\n", "# Pad", "\n", "            ", "num_to_pad", "=", "self", ".", "max_tokens", "-", "len", "(", "curr_input_ids", ")", "\n", "input_ids", "=", "F", ".", "pad", "(", "input_ids", ",", "[", "0", ",", "num_to_pad", "]", ",", "mode", "=", "'constant'", ",", "value", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "if", "len", "(", "curr_label_ids", ")", "<", "self", ".", "max_tokens", "and", "'eval'", "not", "in", "self", ".", "mode", ":", "\n", "            ", "num_to_pad", "=", "self", ".", "max_tokens", "-", "len", "(", "curr_label_ids", ")", "\n", "label_ids", "=", "F", ".", "pad", "(", "label_ids", ",", "[", "0", ",", "num_to_pad", "]", ",", "mode", "=", "'constant'", ",", "value", "=", "-", "100", ")", "\n", "\n", "# Sanity check", "\n", "", "if", "'eval'", "not", "in", "self", ".", "mode", ":", "\n", "            ", "assert", "input_ids", ".", "shape", "[", "0", "]", "==", "label_ids", ".", "shape", "[", "0", "]", "==", "self", ".", "max_tokens", ",", "f\"{input_ids.shape[0]}, {label_ids.shape[0]}, {self.max_tokens}\"", "\n", "\n", "", "if", "self", ".", "include_fnames", ":", "\n", "            ", "return", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"labels\"", ":", "label_ids", ",", "\n", "\"fnames\"", ":", "curr_fnames", "\n", "}", "\n", "", "else", ":", "\n", "# This is the format required by our GPT2Trainer class", "\n", "            ", "return", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"labels\"", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.get_random_sample": [[148, 166], ["base_math_dataset.BaseMathDataset.clean_sample", "random.choice", "len"], "methods", ["None"], ["", "", "def", "get_random_sample", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get a full on random sample (used for training)\n        \"\"\"", "\n", "random_sample", "=", "None", "\n", "while", "random_sample", "is", "None", ":", "\n", "            ", "if", "self", ".", "randomize", ":", "\n", "                ", "q", ",", "a", ",", "fname", "=", "random", ".", "choice", "(", "self", ".", "samples", ")", "\n", "", "else", ":", "\n", "                ", "q", ",", "a", ",", "fname", "=", "self", ".", "samples", "[", "self", ".", "i", "]", "\n", "self", ".", "i", "=", "(", "self", ".", "i", "+", "1", ")", "%", "len", "(", "self", ".", "samples", ")", "\n", "\n", "", "random_sample", "=", "self", ".", "clean_sample", "(", "(", "q", ",", "a", ")", ")", "\n", "\n", "if", "not", "self", ".", "randomize", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "random_sample", ",", "fname", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.clean_filter_sample_gpt": [[167, 169], ["NotImplementedError"], "methods", ["None"], ["", "def", "clean_filter_sample_gpt", "(", "self", ",", "sample", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.clean_filter_sample_gpt_eval": [[170, 172], ["NotImplementedError"], "methods", ["None"], ["", "def", "clean_filter_sample_gpt_eval", "(", "self", ",", "sample", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.clean_filter_sample_t5": [[173, 175], ["NotImplementedError"], "methods", ["None"], ["", "def", "clean_filter_sample_t5", "(", "self", ",", "sample", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.base_math_dataset.BaseMathDataset.clean_filter_sample_t5_eval": [[176, 178], ["NotImplementedError"], "methods", ["None"], ["", "def", "clean_filter_sample_t5_eval", "(", "self", ",", "sample", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.mathematica.MathematicaMathDataset.__len__": [[27, 29], ["int", "len"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "len", "(", "self", ".", "samples", ")", "*", "self", ".", "len_multiplier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.mathematica.MathematicaMathDataset.initialize": [[30, 78], ["print", "tqdm.tqdm.tqdm", "print", "open", "fp.readlines", "os.path.join.rstrip", "os.path.join", "os.path.dirname", "os.path.isfile", "print", "open", "answers.append", "samples_raw.append", "len", "os.path.dirname", "len", "answers.append"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Set up self.samples by loading from the dataroot\n        \"\"\"", "\n", "\n", "with", "open", "(", "self", ".", "dataroot", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "all_filenames", "=", "fp", ".", "readlines", "(", ")", "\n", "\n", "", "print", "(", "f\"{self.__class__.__name__}: Loading samples from {len(all_filenames)} files.\"", ")", "\n", "samples_raw", "=", "[", "]", "\n", "for", "fname", "in", "tqdm", "(", "all_filenames", ")", ":", "\n", "            ", "fname", "=", "fname", ".", "rstrip", "(", ")", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "self", ".", "dataroot", ")", ")", ",", "fname", "[", "2", ":", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "fname", ")", ":", "\n", "                ", "print", "(", "f\"SKIPPING {fname}\"", ")", "\n", "continue", "\n", "", "with", "open", "(", "fname", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "question", "=", "\"\"", "\n", "answers", "=", "[", "]", "\n", "reading_question", "=", "True", "\n", "curr_section", "=", "\"\"", "\n", "for", "line", "in", "fp", ":", "\n", "                    ", "if", "line", "==", "\"Problem:\\n\"", ":", "\n", "                        ", "reading_question", "=", "True", "\n", "", "elif", "line", "==", "\"Answer:\\n\"", ":", "\n", "                        ", "if", "reading_question", ":", "\n", "# curr_section contains Q", "\n", "                            ", "question", "=", "curr_section", "\n", "", "else", ":", "\n", "# curr_section contains an A", "\n", "                            ", "answers", ".", "append", "(", "curr_section", ")", "\n", "", "curr_section", "=", "\"\"", "\n", "reading_question", "=", "False", "\n", "", "else", ":", "\n", "                        ", "curr_section", "+=", "line", "\n", "\n", "# The last answer needs to be recorded.", "\n", "", "", "answers", ".", "append", "(", "curr_section", ")", "\n", "\n", "", "for", "a", "in", "answers", ":", "\n", "                ", "samples_raw", ".", "append", "(", "(", "question", ",", "a", ",", "fname", ")", ")", "\n", "\n", "# manager = Manager()", "\n", "# samples_raw = manager.list(samples_raw)", "\n", "", "", "self", ".", "samples", "=", "samples_raw", "\n", "del", "samples_raw", "\n", "\n", "print", "(", "f\"{self.__class__.__name__}: Loaded {len(self.samples)} samples.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.mathematica.MathematicaMathDataset.clean_filter_sample_gpt": [[79, 127], ["torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "mathematica.MathematicaMathDataset.tokenizer.encode", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "NotImplementedError", "mathematica.MathematicaMathDataset.tokenizer.encode", "mathematica.MathematicaMathDataset.tokenizer.encode", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_gpt", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "if", "self", ".", "mode_answer", "==", "'default'", ":", "\n", "            ", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "sep_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFINAL ANSWER:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer", ",", "verbose", "=", "False", ")", "\n", "answer_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "answer_ids", "=", "torch", ".", "LongTensor", "(", "answer_ids", ")", "\n", "\n", "# Use full solution", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "sep_ids", ",", "\n", "answer_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "question_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "sep_ids", ")", "*", "-", "100", ",", "\n", "answer_ids", ".", "clone", "(", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "", "if", "input_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"{self.__class__.__name__} Skipping due to input_ids being too big. input_ids.shape[0] = {input_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.mathematica.MathematicaMathDataset.clean_filter_sample_t5": [[129, 168], ["torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "NotImplementedError", "mathematica.MathematicaMathDataset.tokenizer.encode", "mathematica.MathematicaMathDataset.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_t5", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "if", "self", ".", "mode_answer", "==", "'default'", ":", "\n", "            ", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", "+", "\"\\nFINAL ANSWER:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "answer_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "", "if", "input_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"{self.__class__.__name__} Skipping due to input_ids being too big. input_ids.shape[0] = {input_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only": [[5, 15], ["util.last_boxed_only_string"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string"], ["def", "last_boxed_only", "(", "sample", ")", ":", "\n", "    ", "\"\"\"\n    Given a (q,a) sample, filter the answers so that they only contain \n    the last \\boxed{...} or \\fbox{...} element\n    \"\"\"", "\n", "q", ",", "a", "=", "sample", "\n", "a", "=", "last_boxed_only_string", "(", "a", ")", "\n", "if", "a", "==", "None", ":", "\n", "        ", "return", "None", "\n", "", "return", "(", "q", ",", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string": [[16, 42], ["string.rfind", "string.rfind", "len"], "function", ["None"], ["", "def", "last_boxed_only_string", "(", "string", ")", ":", "\n", "    ", "idx", "=", "string", ".", "rfind", "(", "\"\\\\boxed\"", ")", "\n", "if", "idx", "<", "0", ":", "\n", "        ", "idx", "=", "string", ".", "rfind", "(", "\"\\\\fbox\"", ")", "\n", "if", "idx", "<", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "", "i", "=", "idx", "\n", "right_brace_idx", "=", "None", "\n", "num_left_braces_open", "=", "0", "\n", "while", "i", "<", "len", "(", "string", ")", ":", "\n", "        ", "if", "string", "[", "i", "]", "==", "\"{\"", ":", "\n", "            ", "num_left_braces_open", "+=", "1", "\n", "", "if", "string", "[", "i", "]", "==", "\"}\"", ":", "\n", "            ", "num_left_braces_open", "-=", "1", "\n", "if", "num_left_braces_open", "==", "0", ":", "\n", "                ", "right_brace_idx", "=", "i", "\n", "break", "\n", "", "", "i", "+=", "1", "\n", "\n", "", "if", "right_brace_idx", "==", "None", ":", "\n", "        ", "retval", "=", "None", "\n", "", "else", ":", "\n", "        ", "retval", "=", "string", "[", "idx", ":", "right_brace_idx", "+", "1", "]", "\n", "\n", "", "return", "retval", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.only_until_first_boxed_from_tokens": [[43, 57], ["string.find", "enumerate", "string.find", "len"], "function", ["None"], ["", "def", "only_until_first_boxed_from_tokens", "(", "string", ",", "tokens", ")", ":", "\n", "    ", "idx", "=", "string", ".", "find", "(", "\"\\\\boxed\"", ")", "\n", "if", "idx", "<", "0", ":", "\n", "        ", "idx", "=", "string", ".", "find", "(", "\"\\\\fbox\"", ")", "\n", "if", "idx", "<", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "", "cum_length", "=", "0", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "cum_length", "+=", "len", "(", "t", ")", "\n", "if", "cum_length", ">=", "idx", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "tokens", "[", ":", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.clean_numbers": [[60, 68], ["list", "tuple", "list.append", "util._clean_numbers"], "function", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_numbers", "(", "sample", ")", ":", "\n", "    ", "if", "not", "sample", ":", "\n", "        ", "return", "None", "\n", "", "new_sample", "=", "list", "(", ")", "\n", "for", "s", "in", "sample", ":", "\n", "        ", "new_sample", ".", "append", "(", "_clean_numbers", "(", "s", ")", ")", "\n", "\n", "", "return", "tuple", "(", "new_sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers": [[69, 100], ["enumerate", "int", "int"], "function", ["None"], ["", "def", "_clean_numbers", "(", "string", ")", ":", "\n", "    ", "\"\"\"\n    Clean Numbers in the given string\n\n    >>> _clean_numbers(None, \"Hello 123\")\n    'Hello 123'\n    >>> _clean_numbers(None, \"Hello 1234\")\n    'Hello 1,234'\n    >>> _clean_numbers(None, \"Hello 1234324asdasd\")\n    'Hello 1,234,324asdasd'\n    \"\"\"", "\n", "num_prev_digits", "=", "0", "\n", "new_string", "=", "\"\"", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "string", ")", ":", "\n", "# isdigit() doesnt work here because of weird unicode chars.", "\n", "        ", "if", "c", "in", "{", "'1'", ",", "'2'", ",", "'3'", ",", "'4'", ",", "'5'", ",", "'6'", ",", "'7'", ",", "'8'", ",", "'9'", ",", "'0'", "}", ":", "\n", "            ", "num_prev_digits", "+=", "1", "\n", "", "else", ":", "\n", "            ", "if", "num_prev_digits", ">", "3", ":", "\n", "# Some fixing", "\n", "                ", "string_number", "=", "new_string", "[", "-", "num_prev_digits", ":", "]", "\n", "new_string", "=", "new_string", "[", ":", "-", "num_prev_digits", "]", "+", "\"{0:,}\"", ".", "format", "(", "int", "(", "string_number", ")", ")", "\n", "", "num_prev_digits", "=", "0", "\n", "", "new_string", "+=", "c", "\n", "\n", "", "if", "num_prev_digits", ">", "3", ":", "\n", "# Some fixing", "\n", "        ", "string_number", "=", "new_string", "[", "-", "num_prev_digits", ":", "]", "\n", "new_string", "=", "new_string", "[", ":", "-", "num_prev_digits", "]", "+", "\"{0:,}\"", ".", "format", "(", "int", "(", "string_number", ")", ")", "\n", "\n", "", "return", "new_string", "", "", ""]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.__len__": [[26, 28], ["int", "len"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "len", "(", "self", ".", "samples", ")", "*", "self", ".", "len_multiplier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.initialize": [[29, 54], ["glob.glob", "multiprocessing.Manager", "multiprocessing.Manager.list", "print", "multiprocessing.Manager.list.append", "open", "json.load", "len", "print"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Set up self.samples by loading from the dataroot\n        \"\"\"", "\n", "\n", "all_filenames", "=", "glob", ".", "glob", "(", "self", ".", "dataroot", ")", "\n", "samples_raw", "=", "[", "]", "\n", "for", "fname", "in", "all_filenames", ":", "\n", "            ", "with", "open", "(", "fname", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "try", ":", "\n", "                    ", "problem_data", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "f\"Error loading JSON from {fname}\"", ",", "e", ")", "\n", "raise", "e", "\n", "", "", "curr_sample_raw", "=", "(", "problem_data", "[", "'problem'", "]", ",", "problem_data", "[", "'solution'", "]", ",", "fname", ")", "\n", "for", "e", "in", "curr_sample_raw", ":", "\n", "                ", "assert", "e", "\n", "", "samples_raw", ".", "append", "(", "curr_sample_raw", ")", "\n", "\n", "", "manager", "=", "Manager", "(", ")", "\n", "samples_raw", "=", "manager", ".", "list", "(", "samples_raw", ")", "\n", "self", ".", "samples", "=", "samples_raw", "\n", "del", "samples_raw", "\n", "\n", "print", "(", "f\"{self.__class__.__name__}: Loaded {len(self.samples)} samples.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_gpt": [[55, 163], ["torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "MATH.MATHDataset.clean_filter_sample_peeking_gpt", "dataset.util.last_boxed_only_string", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "MATH.MATHDataset.tokenizer.encode", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "random.random", "MATH.MATHDataset.clean_filter_sample_peeking_gpt", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "dataset.util.last_boxed_only_string", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "MATH.MATHDataset.tokenizer.encode", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "NotImplementedError", "random.random", "MATH.MATHDataset.clean_filter_sample_nopackpadding_gpt", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "print", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "random.random", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone", "NotImplementedError", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_peeking_gpt", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_peeking_gpt", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_nopackpadding_gpt", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_gpt", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "mode_answer", "==", "'peeking_only'", ":", "\n", "            ", "return", "self", ".", "clean_filter_sample_peeking_gpt", "(", "sample", ")", "\n", "", "if", "self", ".", "mode_answer", "==", "'mixed_full_and_peeking'", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                ", "return", "self", ".", "clean_filter_sample_peeking_gpt", "(", "sample", ")", "\n", "", "else", ":", "\n", "                ", "_mode_answer", "=", "'full'", "\n", "", "", "elif", "self", ".", "mode_answer", "==", "'mixed_full_and_nopack_padding'", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                ", "return", "self", ".", "clean_filter_sample_nopackpadding_gpt", "(", "sample", ")", "\n", "", "else", ":", "\n", "                ", "_mode_answer", "=", "'full'", "\n", "", "", "elif", "self", ".", "mode_answer", "==", "'mixed_final_boxed_and_full'", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                ", "_mode_answer", "=", "'full'", "\n", "", "else", ":", "\n", "                ", "_mode_answer", "=", "'final_boxed'", "\n", "", "", "elif", "self", ".", "mode_answer", "==", "'full'", ":", "\n", "            ", "_mode_answer", "=", "'full'", "\n", "", "elif", "self", ".", "mode_answer", "==", "'final_boxed'", ":", "\n", "            ", "_mode_answer", "=", "'final_boxed'", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"self.mode_answer = {self.mode_answer} not recognized.\"", ")", "\n", "\n", "\n", "", "if", "_mode_answer", "==", "'full'", ":", "\n", "            ", "question", ",", "answer", "=", "sample", "\n", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "                ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "answer_final", "=", "last_boxed_only_string", "(", "answer", ")", "\n", "\n", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "sep_ids_2", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFULL SOLUTION:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer", ",", "verbose", "=", "False", ")", "\n", "answer_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "answer_ids", "=", "torch", ".", "LongTensor", "(", "answer_ids", ")", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "sep_ids_2", ",", "\n", "answer_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Only answer_ids contribute to the loss", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "question_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "sep_ids_2", ")", "*", "-", "100", ",", "\n", "answer_ids", ".", "clone", "(", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "elif", "_mode_answer", "==", "'final_boxed'", ":", "\n", "            ", "question", ",", "answer", "=", "sample", "\n", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "                ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "", "answer_final", "=", "last_boxed_only_string", "(", "answer", ")", "\n", "if", "not", "answer_final", ":", "\n", "                ", "print", "(", "\"ERROR FROM\"", ",", "question", ",", "answer", ")", "\n", "return", "None", "\n", "\n", "", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "sep_ids_1", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFINAL ANSWER:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_final_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "answer_final", ",", "verbose", "=", "False", ")", "\n", "answer_final_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "answer_final_ids", "=", "torch", ".", "LongTensor", "(", "answer_final_ids", ")", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "sep_ids_1", ",", "\n", "answer_final_ids", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Only answer_ids contribute to the loss", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "question_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "sep_ids_1", ")", "*", "-", "100", ",", "\n", "answer_final_ids", ".", "clone", "(", ")", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "", "if", "input_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"Skipping due to input_ids being too big. input_ids.shape[0] = {input_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_nopackpadding_gpt": [[165, 207], ["dataset.util.last_boxed_only_string", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.tolist.tolist.tolist", "label_ids.tolist.tolist.tolist", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_nopackpadding_gpt", "(", "self", ",", "sample", ")", ":", "\n", "\n", "        ", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "answer_final", "=", "last_boxed_only_string", "(", "answer", ")", "\n", "\n", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", ",", "verbose", "=", "False", ")", ")", "\n", "sep_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFINAL ANSWER:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "final_answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer_final", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "num_to_pad", "=", "32", "\n", "padding_tensor", "=", "torch", ".", "ones", "(", "(", "num_to_pad", ")", ")", "*", "220", "# 220 is the token for space in the case of GPT2 models", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "padding_tensor", ",", "\n", "sep_ids", ",", "\n", "final_answer_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Only answer_ids contribute to the loss", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "question_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "padding_tensor", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "sep_ids", ")", "*", "-", "100", ",", "\n", "final_answer_ids", ".", "clone", "(", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_nopackpadding_gpt_eval": [[209, 252], ["dataset.util.last_boxed_only_string", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.tolist.tolist.tolist", "label_ids.tolist.tolist.tolist", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_nopackpadding_gpt_eval", "(", "self", ",", "sample", ")", ":", "\n", "\n", "        ", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "answer_final", "=", "last_boxed_only_string", "(", "answer", ")", "\n", "\n", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", ",", "verbose", "=", "False", ")", ")", "\n", "sep_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFINAL ANSWER:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "final_answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer_final", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "num_to_pad", "=", "32", "\n", "padding_tensor", "=", "torch", ".", "ones", "(", "(", "num_to_pad", ")", ")", "*", "220", "# 220 is the token for space in the case of GPT2 models", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "padding_tensor", ",", "\n", "sep_ids", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Only answer_ids contribute to the loss", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "final_answer_ids", ".", "clone", "(", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "if", "input_ids", ".", "shape", "[", "0", "]", "+", "label_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"Skipping due to input_ids being too big. input_ids.shape[0] = {input_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_peeking_gpt": [[254, 316], ["dataset.util.last_boxed_only_string", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "MATH.MATHDataset.tokenizer.tokenize", "dataset.util.only_until_first_boxed_from_tokens", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "isinstance", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.tolist.tolist.tolist", "label_ids.tolist.tolist.tolist", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "int", "int", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone", "len", "random.uniform", "len", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.only_until_first_boxed_from_tokens", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_peeking_gpt", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "answer_final", "=", "last_boxed_only_string", "(", "answer", ")", "\n", "\n", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", "+", "\"\\nFULL SOLUTION:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_ids", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "answer", ")", "\n", "answer_ids", "=", "only_until_first_boxed_from_tokens", "(", "answer", ",", "answer_ids", ")", "\n", "answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer_ids", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "# Take a fraction", "\n", "if", "isinstance", "(", "self", ".", "peek_fraction", ",", "tuple", ")", ":", "\n", "            ", "final_idx", "=", "int", "(", "len", "(", "answer_ids", ")", "*", "random", ".", "uniform", "(", "*", "self", ".", "peek_fraction", ")", ")", "\n", "", "else", ":", "\n", "            ", "final_idx", "=", "int", "(", "len", "(", "answer_ids", ")", "*", "self", ".", "peek_fraction", ")", "\n", "\n", "# # Override peeking fraction", "\n", "# final_idx = int(len(answer_ids) * np.random.choice([0.25, 0.5, 0.75, 1.0], p=[1/6, 1/6, 1/3, 1/3]))", "\n", "\n", "", "answer_ids", "=", "answer_ids", "[", ":", "final_idx", "]", "\n", "\n", "sep_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nFINAL ANSWER:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "final_answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer_ids", "[", "final_idx", ":", "]", ")", ")", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "answer_ids", ",", "\n", "sep_ids", ",", "\n", "final_answer_ids", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Only answer_ids contribute to the loss", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "ones_like", "(", "question_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "answer_ids", ")", "*", "-", "100", ",", "\n", "torch", ".", "ones_like", "(", "sep_ids", ")", "*", "-", "100", ",", "\n", "final_answer_ids", ".", "clone", "(", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "if", "input_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"Skipping due to input_ids being too big. input_ids.shape[0] = {input_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_peeking_gpt_eval": [[318, 377], ["dataset.util.last_boxed_only_string", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "MATH.MATHDataset.tokenizer.tokenize", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "dataset.util.only_until_first_boxed_from_tokens", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "isinstance", "print", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.tolist.tolist.tolist", "label_ids.tolist.tolist.tolist", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "len", "MATH.MATHDataset.tokenizer.encode", "int", "int", "final_answer_ids.clone", "len", "random.uniform", "len"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util.only_until_first_boxed_from_tokens", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers"], ["", "def", "clean_filter_sample_peeking_gpt_eval", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does the actual tokenization. Should be parallelized because it can be a bit slow.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "\n", "", "answer_final", "=", "last_boxed_only_string", "(", "answer", ")", "\n", "\n", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", "+", "\"\\nFULL SOLUTION:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_ids", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "answer", ")", "\n", "answer_ids_full", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer", ")", ")", "\n", "answer_ids", "=", "only_until_first_boxed_from_tokens", "(", "answer", ",", "answer_ids", ")", "\n", "if", "len", "(", "answer_ids", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "answer_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer_ids", ",", "verbose", "=", "False", ")", ")", "\n", "\n", "# Take a fraction", "\n", "if", "isinstance", "(", "self", ".", "peek_fraction", ",", "tuple", ")", ":", "\n", "            ", "final_idx", "=", "int", "(", "len", "(", "answer_ids", ")", "*", "random", ".", "uniform", "(", "*", "self", ".", "peek_fraction", ")", ")", "\n", "", "else", ":", "\n", "            ", "final_idx", "=", "int", "(", "len", "(", "answer_ids", ")", "*", "self", ".", "peek_fraction", ")", "\n", "\n", "", "answer_ids", "=", "answer_ids", "[", ":", "final_idx", "]", "\n", "\n", "# sep_ids          = torch.LongTensor(self.tokenizer.encode(\"\\nFINAL ANSWER\\n\", verbose=False))", "\n", "final_answer_ids", "=", "answer_ids_full", "[", "final_idx", ":", "]", "\n", "print", "(", "final_answer_ids", ")", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "answer_ids", ",", "\n", "# sep_ids,", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Only answer_ids contribute to the loss", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "final_answer_ids", ".", "clone", "(", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "if", "input_ids", ".", "shape", "[", "0", "]", "+", "label_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"Skipping due to input_ids being too big. input_ids.shape[0] = {input_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "input_ids", "=", "input_ids", ".", "tolist", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "tolist", "(", ")", "\n", "\n", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ",", "\n", "'label_ids_list'", ":", "label_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_gpt_eval": [[379, 424], ["dataset.util.last_boxed_only_string", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "MATH.MATHDataset.clean_filter_sample_peeking_gpt_eval", "dataset.util._clean_numbers", "dataset.util._clean_numbers", "dataset.util._clean_numbers.isspace", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "MATH.MATHDataset.tokenizer.encode", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "MATH.MATHDataset.clean_filter_sample_nopackpadding_gpt_eval", "torch.LongTensor.clone", "torch.LongTensor.clone", "torch.LongTensor.clone"], "methods", ["home.repos.pwc.inspect_result.hendrycks_math.dataset.util.last_boxed_only_string", "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_peeking_gpt_eval", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.util._clean_numbers", "home.repos.pwc.inspect_result.hendrycks_math.dataset.MATH.MATHDataset.clean_filter_sample_nopackpadding_gpt_eval"], ["", "def", "clean_filter_sample_gpt_eval", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\"\n        Does tokenization for final model evaluation. This should return\n        input_ids as the context and labels as the true answer.\n        \"\"\"", "\n", "\n", "if", "sample", "==", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "mode_answer", "==", "'eval_peeking'", ":", "\n", "            ", "return", "self", ".", "clean_filter_sample_peeking_gpt_eval", "(", "sample", ")", "\n", "", "elif", "self", ".", "mode_answer", "==", "'eval_nopack_padding'", ":", "\n", "            ", "return", "self", ".", "clean_filter_sample_nopackpadding_gpt_eval", "(", "sample", ")", "\n", "\n", "", "question", ",", "answer", "=", "sample", "\n", "\n", "if", "self", ".", "clean_numbers", ":", "\n", "            ", "question", "=", "_clean_numbers", "(", "question", ")", "\n", "answer", "=", "_clean_numbers", "(", "answer", ")", "\n", "", "answer_final", "=", "last_boxed_only_string", "(", "answer", ")", "\n", "\n", "assert", "not", "answer", ".", "isspace", "(", ")", "\n", "\n", "question_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\nQUESTION:\\n\"", "+", "question", ",", "verbose", "=", "False", ")", ")", "\n", "sep_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "\"\\FULL SOLUTION:\\n\"", ",", "verbose", "=", "False", ")", ")", "\n", "answer_final_ids", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "encode", "(", "answer_final", ",", "verbose", "=", "False", ")", ")", "# Loss only counted on these tokens.", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "\n", "question_ids", ",", "\n", "sep_ids", ",", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "label_ids", "=", "torch", ".", "cat", "(", "[", "\n", "answer_final_ids", ".", "clone", "(", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Stop early if this Q,A pair is too long", "\n", "if", "input_ids", ".", "shape", "[", "0", "]", "+", "label_ids", ".", "shape", "[", "0", "]", ">", "self", ".", "max_tokens", ":", "\n", "# Print reason for skipping", "\n", "# print(f\"Skipping due to input_ids being too big. input_ids.shape[0] = {input_ids.shape[0]}.\")", "\n", "            ", "return", "None", "\n", "\n", "", "return", "{", "\n", "'input_ids_list'", ":", "input_ids", ".", "tolist", "(", ")", ",", "\n", "'label_ids_list'", ":", "label_ids", ".", "tolist", "(", ")", "\n", "}", "\n"]]}