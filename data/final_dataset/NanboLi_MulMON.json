{"home.repos.pwc.inspect_result.NanboLi_MulMON.None.demo.running_cfg": [[24, 124], ["os.path.join", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "len", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.join", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir"], ["def", "running_cfg", "(", "cfg", ")", ":", "\n", "###########################################", "\n", "# Config i/o path", "\n", "###########################################", "\n", "    ", "if", "cfg", ".", "DATA_TYPE", "==", "'gqn_jaco'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'jaco'", ",", "'generic'", "]", "\n", "cfg", ".", "v_in_dim", "=", "7", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'gqn_jaco'", ",", "'gqn_jaco_train.h5'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'gqn_jaco'", ",", "'gqn_jaco_test.h5'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'clevr_mv'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'cube'", ",", "'sphere'", ",", "'cylinder'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_mv'", ",", "'clevr_mv_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_mv'", ",", "'clevr_mv_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'clevr_aug'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'diamond'", ",", "'duck'", ",", "'mug'", ",", "'horse'", ",", "'dolphin'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_aug'", ",", "'clevr_aug_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_aug'", ",", "'clevr_aug_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "# ------------------- For your customised CLEVR -----------------------", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'your-clevr'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'xxx'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'your-clevr'", ",", "'your-clevr_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'your-clevr'", ",", "'your-clevr_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "# ------------------- For your customised CLEVR -----------------------", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "cfg", ".", "view_dim", "=", "cfg", ".", "v_in_dim", "\n", "\n", "# log directory", "\n", "ckpt_base", "=", "cfg", ".", "ckpt_base", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "ckpt_base", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "ckpt_base", ")", "\n", "\n", "# model savedir", "\n", "", "check_dir", "=", "os", ".", "path", ".", "join", "(", "ckpt_base", ",", "'{}_log/'", ".", "format", "(", "cfg", ".", "arch", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "check_dir", ")", "\n", "# os.mkdir(check_dir)", "\n", "\n", "# output prediction dir", "\n", "out_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "cfg", ".", "output_dir_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "\n", "# saved model dir", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'saved_models/'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "\n", "# generated sample dir  (for testing generation)", "\n", "", "generated_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'generated_{:02d}/'", ".", "format", "(", "cfg", ".", "num_vq_show", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "generated_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "generated_dir", ")", "\n", "\n", "", "if", "cfg", ".", "resume_path", "is", "not", "None", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "cfg", ".", "resume_path", ")", "\n", "", "elif", "cfg", ".", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "resume_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\n", "'checkpoint-epoch{}.pth'", ".", "format", "(", "cfg", ".", "resume_epoch", ")", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "resume_path", ")", "\n", "cfg", ".", "resume_path", "=", "resume_path", "\n", "\n", "", "cfg", ".", "DATA_DIR", "=", "data_dir", "\n", "cfg", ".", "test_data_filename", "=", "test_data_filename", "\n", "cfg", ".", "check_dir", "=", "check_dir", "\n", "cfg", ".", "save_dir", "=", "save_dir", "\n", "cfg", ".", "generated_dir", "=", "generated_dir", "\n", "cfg", ".", "output_dir", "=", "out_dir", "\n", "\n", "cfg", ".", "image_size", "=", "image_size", "\n", "cfg", ".", "CLASSES", "=", "CLASSES", "\n", "cfg", ".", "num_classes", "=", "len", "(", "CLASSES", ")", "\n", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.demo.run_demo": [[127, 221], ["ScnModel", "torch.cuda.set_device", "utils.set_random_seed", "ScnModel.cuda", "ScnModel.eval", "DataLoader", "min", "enumerate", "print", "random.randint", "utils.load_trained_mp", "ScnModel.load_state_dict", "os.path.exists", "os.mkdir", "len", "list", "print", "ScnModel.predict", "len", "len", "print", "torch.from_numpy().cuda", "torch.stack().cuda.expand().float", "ScnModel.v_travel", "torch.stack().type", "torch.stack().cuda", "ScnModel.z_travel", "print", "image.cuda().detach", "v.cuda().detach", "torch.arange", "torch.from_numpy().cuda", "t.items", "torch.from_numpy", "torch.stack().cuda.expand", "torch.stack", "torch.stack", "image.cuda", "v.cuda", "numpy.load", "torch.from_numpy", "os.path.join", "torch.stack().cuda.size"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.set_random_seed", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.load_trained_mp", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.predict", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.v_travel", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.z_travel"], ["", "def", "run_demo", "(", "CFG", ")", ":", "\n", "    ", "if", "'GQN'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "baseline_gqn", "import", "GQN", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: GQN ---\"", ")", "\n", "", "elif", "'IODINE'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "baseline_iodine", "import", "IODINE", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: IODINE ---\"", ")", "\n", "", "elif", "'MulMON'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "mulmon", "import", "MulMON", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: MulMON ---\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "# --- model to be evaluated ---", "\n", "", "scn_model", "=", "ScnModel", "(", "CFG", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "CFG", ".", "gpu", ")", "\n", "\n", "if", "CFG", ".", "seed", "is", "None", ":", "\n", "        ", "CFG", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "1000000", ")", "\n", "", "utils", ".", "set_random_seed", "(", "CFG", ".", "seed", ")", "\n", "\n", "if", "CFG", ".", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "state_dict", "=", "utils", ".", "load_trained_mp", "(", "CFG", ".", "resume_path", ")", "\n", "scn_model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "", "scn_model", ".", "cuda", "(", "CFG", ".", "gpu", ")", "\n", "scn_model", ".", "eval", "(", ")", "\n", "\n", "if", "'gqn'", "in", "CFG", ".", "DATA_TYPE", ":", "\n", "# if 'h5' data is used (by default), otherwise, use json loader", "\n", "        ", "from", "data_loader", ".", "getGqnH5", "import", "DataLoader", "\n", "# from data_loader.getGqnData import DataLoader", "\n", "", "elif", "'clevr'", "in", "CFG", ".", "DATA_TYPE", ":", "\n", "        ", "from", "data_loader", ".", "getClevrMV", "import", "DataLoader", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "eval_dataloader", "=", "DataLoader", "(", "CFG", ".", "DATA_ROOT", ",", "\n", "CFG", ".", "test_data_filename", ",", "\n", "batch_size", "=", "CFG", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "use_bg", "=", "CFG", ".", "use_bg", ")", "\n", "\n", "vis_eval_dir", "=", "CFG", ".", "generated_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "vis_eval_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "vis_eval_dir", ")", "\n", "\n", "# --- running on ---", "\n", "", "count_total_samples", "=", "0", "\n", "num_batches", "=", "min", "(", "CFG", ".", "test_batch", ",", "len", "(", "eval_dataloader", ")", ")", "\n", "for", "batch_id", ",", "(", "images", ",", "targets", ")", "in", "enumerate", "(", "eval_dataloader", ")", ":", "\n", "        ", "if", "batch_id", ">=", "num_batches", ":", "\n", "            ", "break", "\n", "# images, targets = next(iter(eval_dataloader))", "\n", "", "images", "=", "list", "(", "image", ".", "cuda", "(", "CFG", ".", "gpu", ")", ".", "detach", "(", ")", "for", "image", "in", "images", ")", "\n", "targets", "=", "[", "{", "k", ":", "v", ".", "cuda", "(", "CFG", ".", "gpu", ")", ".", "detach", "(", ")", "for", "k", ",", "v", "in", "t", ".", "items", "(", ")", "}", "for", "t", "in", "targets", "]", "\n", "\n", "if", "batch_id", ">=", "CFG", ".", "vis_batch", ":", "\n", "            ", "vis_eval_dir", "=", "None", "\n", "", "print", "(", "\"  predicting on batch: {}/{}\"", ".", "format", "(", "batch_id", "+", "1", ",", "num_batches", ")", ")", "\n", "test_out", "=", "scn_model", ".", "predict", "(", "images", ",", "targets", ",", "\n", "save_sample_to", "=", "vis_eval_dir", ",", "\n", "save_start_id", "=", "count_total_samples", ",", "\n", "vis_train", "=", "False", ")", "\n", "\n", "B", "=", "len", "(", "images", ")", "\n", "V", "=", "targets", "[", "0", "]", "[", "'view_points'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "# ----- traverse viewpoints to see 3D -----", "\n", "if", "CFG", ".", "traverse_v", ":", "\n", "# <<<<<<<<<< Load your own viewpoint trajectories (here we show) >>>>>>>>>>", "\n", "            ", "v_pts", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "CFG", ".", "check_dir", ",", "'interp_views.npy'", ")", ")", ")", ".", "cuda", "(", "CFG", ".", "gpu", ")", "\n", "select_views", "=", "torch", ".", "arange", "(", "72", ")", "*", "5", "\n", "v_pts", "=", "v_pts", "[", "select_views", ",", ":", "]", "\n", "v_pts", "=", "v_pts", ".", "expand", "(", "(", "B", ",", ")", "+", "v_pts", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "\n", "scn_model", ".", "v_travel", "(", "test_out", "[", "'lmbda'", "]", ",", "\n", "v_pts", "=", "v_pts", ",", "\n", "save_sample_to", "=", "CFG", ".", "output_dir", ",", "\n", "save_start_id", "=", "batch_id", "*", "CFG", ".", "batch_size", ")", "\n", "\n", "# ----- traverse 3D latents -----", "\n", "", "if", "CFG", ".", "traverse_z", ":", "\n", "            ", "v_pts", "=", "torch", ".", "stack", "(", "[", "tar", "[", "'view_points'", "]", "for", "tar", "in", "targets", "]", ",", "dim", "=", "0", ")", ".", "type", "(", "images", "[", "0", "]", ".", "dtype", ")", "\n", "v_pts", "=", "torch", ".", "stack", "(", "[", "v_pts", "[", ":", ",", "vid", ",", ":", "]", "for", "vid", "in", "test_out", "[", "'query_views'", "]", "]", ",", "dim", "=", "1", ")", ".", "cuda", "(", "CFG", ".", "gpu", ")", "\n", "z_3d", "=", "torch", ".", "from_numpy", "(", "test_out", "[", "'3d_latents'", "]", ")", ".", "cuda", "(", "CFG", ".", "gpu", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "\n", "# z_3d = torch.from_numpy(test_out['3d_latents']).cuda(CFG.gpu)", "\n", "scn_model", ".", "z_travel", "(", "z_3d", ",", "\n", "v_pts", "=", "v_pts", ",", "\n", "limit", "=", "4.0", ",", "int_step_size", "=", "0.2", ",", "\n", "save_sample_to", "=", "CFG", ".", "output_dir", ",", "\n", "save_start_id", "=", "batch_id", "*", "CFG", ".", "batch_size", ")", "\n", "\n", "", "count_total_samples", "+=", "len", "(", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.demo.main": [[223, 323], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "demo.running_cfg", "demo.run_demo", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.running_cfg", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.demo.run_demo"], ["", "", "def", "main", "(", "cfg", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--arch'", ",", "type", "=", "str", ",", "default", "=", "'ScnModel'", ",", "\n", "help", "=", "\"architecture name or model nickname\"", ")", "\n", "parser", ".", "add_argument", "(", "'--datatype'", ",", "type", "=", "str", ",", "default", "=", "'clevr_mv'", ",", "\n", "help", "=", "\"one of [clevr_mv, clevr_aug, gqn-jaco]\"", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of data samples of a minibatch'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch'", ",", "default", "=", "10000", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'run model on only the first [N] batch of the data set'", ")", "\n", "parser", ".", "add_argument", "(", "'--vis_batch'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'visualise only the first [N] batch and save to the generated dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--analyse_batch'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'save and analyse only the first [N] batch latents and ig_estimation'", ")", "\n", "parser", ".", "add_argument", "(", "'--work_mode'", ",", "type", "=", "str", ",", "default", "=", "'testing'", ",", "help", "=", "\"model's working mode\"", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_epoch'", ",", "default", "=", "500", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'resume weights from [N]th epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_name'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'save the prediction output to the specified dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'specify id of gpu to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'random seed'", ")", "\n", "\n", "# Model spec", "\n", "parser", ".", "add_argument", "(", "'--num_slots'", ",", "default", "=", "7", ",", "type", "=", "int", ",", "help", "=", "'(maximum) number of component slots'", ")", "\n", "parser", ".", "add_argument", "(", "'--temperature'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'spatial scheduler increase rate, the hotter the faster coeff grows'", ")", "\n", "parser", ".", "add_argument", "(", "'--latent_dim'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "help", "=", "'size of the latent dimensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--view_dim'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'size of the viewpoint latent dimensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_sample_views'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'mininum allowed #views for scene learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_sample_views'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'maximum allowed #views for scene learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_vq_show'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'#views selected for visualisation'", ")", "\n", "parser", ".", "add_argument", "(", "'--pixel_sigma'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_mc_samples'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "'monte carlo samples for uncertainty estimation'", ")", "\n", "parser", ".", "add_argument", "(", "'--kl_latent'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--kl_spatial'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_attention'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--query_nll'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_nll'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_bg\"", ",", "default", "=", "False", ",", "help", "=", "\"treat background also an object\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--traverse_v\"", ",", "default", "=", "False", ",", "help", "=", "\"traverse latent dimensions to see v disentanglement\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--traverse_z\"", ",", "default", "=", "False", ",", "help", "=", "\"traverse latent dimensions to see z disentanglement\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-i\"", ",", "'--input_dir'", ",", "required", "=", "True", ",", "help", "=", "\"path to the input data for the model to read\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-o\"", ",", "'--output_dir'", ",", "required", "=", "True", ",", "help", "=", "\"destination dir for the model to write out results\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "###########################################", "\n", "# General reconfig", "\n", "###########################################", "\n", "cfg", ".", "gpu", "=", "args", ".", "gpu", "\n", "\n", "cfg", ".", "arch", "=", "args", ".", "arch", "\n", "cfg", ".", "DATA_TYPE", "=", "args", ".", "datatype", "\n", "cfg", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "cfg", ".", "test_batch", "=", "args", ".", "test_batch", "\n", "cfg", ".", "vis_batch", "=", "args", ".", "vis_batch", "\n", "cfg", ".", "analyse_batch", "=", "args", ".", "analyse_batch", "\n", "cfg", ".", "WORK_MODE", "=", "args", ".", "work_mode", "\n", "cfg", ".", "resume_epoch", "=", "args", ".", "resume_epoch", "\n", "cfg", ".", "output_dir_name", "=", "args", ".", "output_name", "\n", "cfg", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "# model specs", "\n", "cfg", ".", "num_slots", "=", "args", ".", "num_slots", "\n", "cfg", ".", "temperature", "=", "args", ".", "temperature", "\n", "cfg", ".", "latent_dim", "=", "args", ".", "latent_dim", "\n", "cfg", ".", "view_dim", "=", "args", ".", "view_dim", "\n", "cfg", ".", "min_sample_views", "=", "args", ".", "min_sample_views", "\n", "cfg", ".", "max_sample_views", "=", "args", ".", "max_sample_views", "\n", "cfg", ".", "num_vq_show", "=", "args", ".", "num_vq_show", "\n", "cfg", ".", "num_mc_samples", "=", "args", ".", "num_mc_samples", "\n", "cfg", ".", "pixel_sigma", "=", "args", ".", "pixel_sigma", "\n", "cfg", ".", "elbo_weights", "=", "{", "\n", "'kl_latent'", ":", "args", ".", "kl_latent", ",", "\n", "'kl_spatial'", ":", "args", ".", "kl_spatial", ",", "\n", "'exp_attention'", ":", "args", ".", "exp_attention", ",", "\n", "'exp_nll'", ":", "args", ".", "exp_nll", ",", "\n", "'query_nll'", ":", "args", ".", "query_nll", "\n", "}", "\n", "\n", "# I/O path configurations", "\n", "cfg", ".", "DATA_ROOT", "=", "args", ".", "input_dir", "\n", "cfg", ".", "ckpt_base", "=", "args", ".", "output_dir", "\n", "\n", "# demo specs", "\n", "cfg", ".", "use_bg", "=", "args", ".", "use_bg", "\n", "cfg", ".", "traverse_v", "=", "args", ".", "traverse_v", "\n", "cfg", ".", "traverse_z", "=", "args", ".", "traverse_z", "\n", "running_cfg", "(", "cfg", ")", "\n", "\n", "# ---------- generating demos ----------", "\n", "run_demo", "(", "cfg", ")", "\n", "\n", "print", "(", "\"\\n== Demos generated!\"", ")", "\n", "print", "(", "\"----------------------------------\"", ")", "\n", "print", "(", "\"== Check them in:  '{}' \\n\"", ".", "format", "(", "cfg", ".", "output_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.eval.running_cfg": [[19, 119], ["os.path.join", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "len", "cfg.DATA_TYPE.lower", "os.path.exists", "os.path.join", "os.path.isfile", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.isfile", "cfg.DATA_TYPE.lower", "os.path.exists", "os.path.join", "os.path.isfile", "os.path.join", "os.path.isfile", "cfg.DATA_TYPE.lower", "os.path.exists", "os.path.join", "os.path.isfile", "cfg.DATA_TYPE.lower", "os.path.exists", "os.path.join", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir"], ["def", "running_cfg", "(", "cfg", ")", ":", "\n", "###########################################", "\n", "# Config i/o path", "\n", "###########################################", "\n", "    ", "if", "cfg", ".", "DATA_TYPE", ".", "lower", "(", ")", "==", "'gqn_jaco'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'jaco'", ",", "'generic'", "]", "\n", "cfg", ".", "v_in_dim", "=", "7", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "# train_data_filename = os.path.join(data_dir, 'gqn_jaco', 'gqn_jaco_train.h5')", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'gqn_jaco'", ",", "'gqn_jaco_test.h5'", ")", "\n", "# assert os.path.isfile(train_data_filename)", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "", "elif", "cfg", ".", "DATA_TYPE", ".", "lower", "(", ")", "==", "'clevr_mv'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'cube'", ",", "'sphere'", ",", "'cylinder'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "# train_data_filename = os.path.join(data_dir, 'clevr_mv', 'clevr_mv_train.json')", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_mv'", ",", "'clevr_mv_test.json'", ")", "\n", "# assert os.path.isfile(train_data_filename)", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "", "elif", "cfg", ".", "DATA_TYPE", ".", "lower", "(", ")", "==", "'clevr_aug'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'diamond'", ",", "'duck'", ",", "'mug'", ",", "'horse'", ",", "'dolphin'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "# train_data_filename = os.path.join(data_dir, 'clevr_aug', 'clevr_aug_train.json')", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_aug'", ",", "'clevr_aug_test.json'", ")", "\n", "# assert os.path.isfile(train_data_filename)", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "# ------------------- For your customised CLEVR -----------------------", "\n", "", "elif", "cfg", ".", "DATA_TYPE", ".", "lower", "(", ")", "==", "'your-clevr'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'xxx'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "# train_data_filename = os.path.join(data_dir, 'your-clevr', 'your-clevr_train.json')", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'your-clevr'", ",", "'your-clevr_test.json'", ")", "\n", "# assert os.path.isfile(train_data_filename)", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "# ------------------- For your customised CLEVR -----------------------", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "cfg", ".", "view_dim", "=", "cfg", ".", "v_in_dim", "\n", "\n", "# log directory", "\n", "ckpt_base", "=", "cfg", ".", "ckpt_base", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "ckpt_base", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "ckpt_base", ")", "\n", "\n", "# model savedir", "\n", "", "check_dir", "=", "os", ".", "path", ".", "join", "(", "ckpt_base", ",", "'{}_log/'", ".", "format", "(", "cfg", ".", "arch", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "check_dir", ")", "\n", "# os.mkdir(check_dir)", "\n", "\n", "# output prediction dir", "\n", "out_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "cfg", ".", "output_dir_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "\n", "# saved model dir", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'saved_models/'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "\n", "# generated sample dir  (for testing generation)", "\n", "", "generated_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'generated'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "generated_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "generated_dir", ")", "\n", "\n", "", "if", "cfg", ".", "resume_path", "is", "not", "None", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "cfg", ".", "resume_path", ")", "\n", "", "elif", "cfg", ".", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "resume_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\n", "'checkpoint-epoch{}.pth'", ".", "format", "(", "cfg", ".", "resume_epoch", ")", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "resume_path", ")", "\n", "cfg", ".", "resume_path", "=", "resume_path", "\n", "\n", "", "cfg", ".", "DATA_DIR", "=", "data_dir", "\n", "cfg", ".", "test_data_filename", "=", "test_data_filename", "\n", "cfg", ".", "check_dir", "=", "check_dir", "\n", "cfg", ".", "save_dir", "=", "save_dir", "\n", "cfg", ".", "generated_dir", "=", "generated_dir", "\n", "cfg", ".", "output_dir", "=", "out_dir", "\n", "\n", "cfg", ".", "image_size", "=", "image_size", "\n", "cfg", ".", "CLASSES", "=", "CLASSES", "\n", "cfg", ".", "num_classes", "=", "len", "(", "CLASSES", ")", "\n", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.eval.run_evaluation": [[122, 295], ["ScnModel", "torch.cuda.set_device", "utils.set_random_seed", "ScnModel.cuda", "ScnModel.eval", "DataLoader", "attrdict.AttrDict", "min", "enumerate", "utils.write_json", "print", "random.randint", "utils.load_trained_mp", "ScnModel.load_state_dict", "CFG.DATA_TYPE.lower", "CFG.DATA_TYPE.lower", "os.path.exists", "os.mkdir", "len", "list", "print", "ScnModel.predict", "len", "len", "len", "numpy.concatenate().mean", "np.concatenate().mean.item", "numpy.concatenate().mean", "np.concatenate().mean.item", "numpy.stack().mean().item", "numpy.stack().mean().item", "len", "utils.write_json", "os.path.join", "print", "CFG.DATA_TYPE.lower", "utils.read_json", "len", "numpy.sqrt", "obs_rec_record.append", "numpy.sqrt", "np.concatenate().mean.append", "torch.stack().permute", "numpy.asarray", "utils.match_or_compute_segmentation_iou", "torch.stack().permute", "numpy.asarray", "utils.match_or_compute_segmentation_iou", "torch.stack().permute", "numpy.asarray", "utils.match_or_compute_segmentation_iou", "list", "list", "utils.save_latents_for_eval", "os.path.join", "print", "image.cuda().detach", "v.cuda().detach", "numpy.sum().reshape().mean", "numpy.sum().reshape().mean", "torch.from_numpy().to", "list", "utils.match_or_compute_segmentation_iou", "torch.from_numpy().to", "list", "utils.match_or_compute_segmentation_iou", "CFG.DATA_TYPE.lower", "torch.from_numpy().to", "list", "utils.read_json", "numpy.concatenate", "numpy.concatenate", "numpy.stack().mean", "numpy.stack().mean", "t.items", "torch.stack", "torch.stack", "torch.stack", "os.path.join", "image.cuda", "v.cuda", "numpy.sum().reshape", "numpy.sum().reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "range", "range", "numpy.stack", "numpy.stack", "tar[].squeeze", "tar[].squeeze", "tar[].squeeze", "numpy.sum", "numpy.sum", "tar[].item", "tar[].item", "tar[].item"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.set_random_seed", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.write_json", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.load_trained_mp", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.predict", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.write_json", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_json", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.match_or_compute_segmentation_iou", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.match_or_compute_segmentation_iou", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.match_or_compute_segmentation_iou", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.save_latents_for_eval", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.match_or_compute_segmentation_iou", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.match_or_compute_segmentation_iou", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_json"], ["", "def", "run_evaluation", "(", "CFG", ")", ":", "\n", "    ", "if", "'GQN'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "baseline_gqn", "import", "GQN", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: GQN ---\"", ")", "\n", "", "elif", "'IODINE'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "baseline_iodine", "import", "IODINE", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: IODINE ---\"", ")", "\n", "", "elif", "'MulMON'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "mulmon", "import", "MulMON", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: MulMON ---\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "# --- model to be evaluated ---", "\n", "", "scn_model", "=", "ScnModel", "(", "CFG", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "CFG", ".", "gpu", ")", "\n", "\n", "if", "CFG", ".", "seed", "is", "None", ":", "\n", "        ", "CFG", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "1000000", ")", "\n", "", "utils", ".", "set_random_seed", "(", "CFG", ".", "seed", ")", "\n", "\n", "if", "CFG", ".", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "state_dict", "=", "utils", ".", "load_trained_mp", "(", "CFG", ".", "resume_path", ")", "\n", "scn_model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "", "scn_model", ".", "cuda", "(", "CFG", ".", "gpu", ")", "\n", "scn_model", ".", "eval", "(", ")", "\n", "\n", "if", "'gqn'", "in", "CFG", ".", "DATA_TYPE", ".", "lower", "(", ")", ":", "\n", "        ", "from", "data_loader", ".", "getGqnH5", "import", "DataLoader", "\n", "", "elif", "'clevr'", "in", "CFG", ".", "DATA_TYPE", ".", "lower", "(", ")", ":", "\n", "        ", "from", "data_loader", ".", "getClevrMV", "import", "DataLoader", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "eval_dataloader", "=", "DataLoader", "(", "CFG", ".", "DATA_ROOT", ",", "\n", "CFG", ".", "test_data_filename", ",", "\n", "batch_size", "=", "CFG", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "use_bg", "=", "CFG", ".", "use_bg", ")", "\n", "\n", "if", "'gqn'", "not", "in", "CFG", ".", "DATA_TYPE", ".", "lower", "(", ")", ":", "\n", "        ", "scene_meta_info", "=", "utils", ".", "read_json", "(", "CFG", ".", "test_data_filename", ")", "[", "'scenes'", "]", "\n", "\n", "", "vis_eval_dir", "=", "CFG", ".", "generated_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "vis_eval_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "vis_eval_dir", ")", "\n", "\n", "# --- dict that stores all the evaluation results ---", "\n", "", "EVAL_RESULT", "=", "AttrDict", "(", ")", "\n", "obs_rec_record", "=", "[", "]", "\n", "qry_obs_record", "=", "[", "]", "\n", "obs_seg_miou", "=", "[", "]", "\n", "qry_seg_miou", "=", "[", "]", "\n", "GT_latents", "=", "[", "]", "\n", "\n", "# --- running on ---", "\n", "count_total_samples", "=", "0", "\n", "num_batches", "=", "min", "(", "CFG", ".", "test_batch", ",", "len", "(", "eval_dataloader", ")", ")", "\n", "for", "batch_id", ",", "(", "images", ",", "targets", ")", "in", "enumerate", "(", "eval_dataloader", ")", ":", "\n", "        ", "if", "batch_id", ">=", "num_batches", ":", "\n", "            ", "break", "\n", "# images, targets = next(iter(eval_dataloader))", "\n", "", "images", "=", "list", "(", "image", ".", "cuda", "(", "CFG", ".", "gpu", ")", ".", "detach", "(", ")", "for", "image", "in", "images", ")", "\n", "targets", "=", "[", "{", "k", ":", "v", ".", "cuda", "(", "CFG", ".", "gpu", ")", ".", "detach", "(", ")", "for", "k", ",", "v", "in", "t", ".", "items", "(", ")", "}", "for", "t", "in", "targets", "]", "\n", "\n", "if", "batch_id", ">=", "CFG", ".", "vis_batch", ":", "\n", "            ", "vis_eval_dir", "=", "None", "\n", "", "print", "(", "\"  predicting on batch: {}/{}\"", ".", "format", "(", "batch_id", "+", "1", ",", "num_batches", ")", ")", "\n", "\n", "test_out", "=", "scn_model", ".", "predict", "(", "images", ",", "targets", ",", "\n", "save_sample_to", "=", "vis_eval_dir", ",", "\n", "save_start_id", "=", "count_total_samples", ",", "\n", "vis_train", "=", "False", ",", "\n", "vis_uncertainty", "=", "False", ")", "\n", "\n", "B", "=", "len", "(", "images", ")", "\n", "V", "=", "targets", "[", "0", "]", "[", "'view_points'", "]", ".", "shape", "[", "0", "]", "\n", "num_obs", "=", "CFG", ".", "num_vq_show", "\n", "\n", "# ----- viewpoints (ids) to be evaluated at -----", "\n", "# use these lists on GT only, as the output variables are specified by these indices already", "\n", "obs_view_ids", ",", "qry_view_ids", "=", "test_out", "[", "'obs_views'", "]", ",", "test_out", "[", "'query_views'", "]", "\n", "num_qry", "=", "len", "(", "qry_view_ids", ")", "\n", "assert", "num_obs", "==", "len", "(", "obs_view_ids", ")", "\n", "\n", "# ----- Task performance -----", "\n", "if", "CFG", ".", "eval_recon", ":", "\n", "            ", "x_obs", ",", "x_rec", "=", "test_out", "[", "'x_images'", "]", "[", ":", ",", ":", "num_obs", "]", ",", "test_out", "[", "'x_recon'", "]", "[", ":", ",", ":", "num_obs", "]", "\n", "rmse_out", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "(", "x_obs", "-", "x_rec", ")", "**", "2", ",", "axis", "=", "-", "3", ")", ".", "reshape", "(", "[", "B", ",", "-", "1", "]", ")", ".", "mean", "(", "-", "1", ")", ")", "\n", "obs_rec_record", ".", "append", "(", "rmse_out", ")", "\n", "\n", "", "if", "CFG", ".", "eval_qry_obs", ":", "\n", "            ", "xq_gt", ",", "xq_pred", "=", "test_out", "[", "'x_images'", "]", "[", ":", ",", "num_obs", ":", "]", ",", "test_out", "[", "'x_recon'", "]", "[", ":", ",", "num_obs", ":", "]", "\n", "rmse_out", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "(", "xq_gt", "-", "xq_pred", ")", "**", "2", ",", "axis", "=", "-", "3", ")", ".", "reshape", "(", "[", "B", ",", "-", "1", "]", ")", ".", "mean", "(", "-", "1", ")", ")", "\n", "qry_obs_record", ".", "append", "(", "rmse_out", ")", "\n", "\n", "", "if", "CFG", ".", "eval_seg", ":", "\n", "            ", "masks_gt", "=", "torch", ".", "stack", "(", "[", "tar", "[", "'masks'", "]", ".", "squeeze", "(", "1", ")", "for", "tar", "in", "targets", "]", ",", "dim", "=", "0", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", "\n", "m_gt", ",", "m_pred", "=", "masks_gt", "[", ":", ",", "obs_view_ids", "]", ",", "torch", ".", "from_numpy", "(", "test_out", "[", "'hiers'", "]", "[", ":", ",", ":", "num_obs", "]", ")", ".", "to", "(", "masks_gt", ".", "device", ")", "\n", "num_comps", "=", "np", ".", "asarray", "(", "list", "(", "[", "tar", "[", "'num_comps'", "]", ".", "item", "(", ")", "]", "*", "num_obs", "for", "tar", "in", "targets", ")", ",", "dtype", "=", "'uint8'", ")", "\n", "\n", "# Matching: find the best pred-gt object pairs as we don't enforce any permutation in the predictions", "\n", "_", ",", "match_list", "=", "utils", ".", "match_or_compute_segmentation_iou", "(", "m_pred", ",", "m_gt", ",", "num_comps", ",", "\n", "threshold", "=", "1.0", ")", "\n", "# compute mIoU using the match we find", "\n", "obs_seg_miou", "+=", "utils", ".", "match_or_compute_segmentation_iou", "(", "m_pred", ",", "m_gt", ",", "num_comps", ",", "\n", "match_list", "=", "match_list", ",", "threshold", "=", "1.0", ")", "[", "0", "]", "\n", "\n", "", "if", "CFG", ".", "eval_qry_seg", ":", "\n", "            ", "masks_gt", "=", "torch", ".", "stack", "(", "[", "tar", "[", "'masks'", "]", ".", "squeeze", "(", "1", ")", "for", "tar", "in", "targets", "]", ",", "dim", "=", "0", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", "\n", "m_gt", ",", "m_pred", "=", "masks_gt", "[", ":", ",", "qry_view_ids", "]", ",", "torch", ".", "from_numpy", "(", "test_out", "[", "'hiers'", "]", "[", ":", ",", "num_obs", ":", "]", ")", ".", "to", "(", "masks_gt", ".", "device", ")", "\n", "num_comps", "=", "np", ".", "asarray", "(", "list", "(", "[", "tar", "[", "'num_comps'", "]", ".", "item", "(", ")", "]", "*", "num_qry", "for", "tar", "in", "targets", ")", ",", "dtype", "=", "'uint8'", ")", "\n", "\n", "# Matching: find the best pred-gt object pairs as we don't enforce any permutation in the predictions", "\n", "_", ",", "match_list", "=", "utils", ".", "match_or_compute_segmentation_iou", "(", "m_pred", ",", "m_gt", ",", "num_comps", ",", "\n", "threshold", "=", "1.0", ")", "\n", "# compute mIoU using the match we find", "\n", "qry_seg_miou", "+=", "utils", ".", "match_or_compute_segmentation_iou", "(", "m_pred", ",", "m_gt", ",", "num_comps", ",", "\n", "match_list", "=", "match_list", ",", "threshold", "=", "1.0", ")", "[", "0", "]", "\n", "\n", "# ----- Save latents for disentanglement analysis -----", "\n", "", "if", "batch_id", "<", "CFG", ".", "analyse_batch", "and", "CFG", ".", "eval_dist", ":", "\n", "# find matches", "\n", "            ", "assert", "num_obs", "==", "V", ",", "\"Use all available observations for disentanglement evaluation\"", "\n", "assert", "CFG", ".", "batch_size", "==", "1", ",", "\"Must set batch size to 1 for disentanglement evaluation\"", "\n", "assert", "\"clevr\"", "in", "CFG", ".", "DATA_TYPE", ".", "lower", "(", ")", "\n", "masks_gt", "=", "torch", ".", "stack", "(", "[", "tar", "[", "'masks'", "]", ".", "squeeze", "(", "1", ")", "for", "tar", "in", "targets", "]", ",", "dim", "=", "0", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", "\n", "m_gt", ",", "m_pred", "=", "masks_gt", "[", ":", ",", "obs_view_ids", "]", ",", "torch", ".", "from_numpy", "(", "test_out", "[", "'hiers'", "]", "[", ":", ",", ":", "num_obs", "]", ")", ".", "to", "(", "masks_gt", ".", "device", ")", "\n", "num_comps", "=", "np", ".", "asarray", "(", "list", "(", "[", "tar", "[", "'num_comps'", "]", ".", "item", "(", ")", "]", "*", "num_obs", "for", "tar", "in", "targets", ")", ",", "dtype", "=", "'uint8'", ")", "\n", "\n", "# Matching: find the best pred-gt object pairs as we don't enforce any permutation in the predictions", "\n", "_", ",", "match_list", "=", "utils", ".", "match_or_compute_segmentation_iou", "(", "m_pred", ",", "m_gt", ",", "num_comps", ",", "\n", "threshold", "=", "1.0", ")", "\n", "\n", "z_2d", "=", "test_out", "[", "'2d_latents'", "]", "\n", "z_3d", "=", "test_out", "[", "'3d_latents'", "]", "\n", "scene_meta_info", "=", "utils", ".", "read_json", "(", "CFG", ".", "test_data_filename", ")", "[", "'scenes'", "]", "\n", "# we need remove background reps as it is less important", "\n", "z_2d", "=", "list", "(", "z_2d", "[", "0", ",", "vid", ",", "match_list", "[", "vid", "]", "[", "1", ":", "]", "]", "for", "vid", "in", "range", "(", "V", ")", ")", "\n", "z_3d", "=", "list", "(", "z_3d", "[", "0", ",", "vid", ",", "match_list", "[", "vid", "]", "[", "1", ":", "]", "]", "for", "vid", "in", "range", "(", "V", ")", ")", "# delete background", "\n", "g_latent", "=", "utils", ".", "save_latents_for_eval", "(", "z_v_out", "=", "z_2d", ",", "\n", "z_out", "=", "z_3d", ",", "\n", "scn_indices", "=", "test_out", "[", "'scene_indices'", "]", ",", "\n", "qry_views", "=", "obs_view_ids", ",", "\n", "gt_scenes_meta", "=", "scene_meta_info", ",", "\n", "out_dir", "=", "os", ".", "path", ".", "join", "(", "CFG", ".", "output_dir", ",", "'latents'", ")", ",", "\n", "save_count", "=", "count_total_samples", ")", "\n", "GT_latents", "+=", "g_latent", "\n", "", "count_total_samples", "+=", "len", "(", "images", ")", "\n", "\n", "", "if", "CFG", ".", "eval_recon", ":", "\n", "        ", "rmse_record", "=", "np", ".", "concatenate", "(", "obs_rec_record", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", "\n", "EVAL_RESULT", "[", "'rmse_rec'", "]", "=", "rmse_record", ".", "item", "(", ")", "\n", "\n", "", "if", "CFG", ".", "eval_qry_obs", ":", "\n", "        ", "qry_obs_record", "=", "np", ".", "concatenate", "(", "qry_obs_record", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", "\n", "EVAL_RESULT", "[", "'rmse_qry'", "]", "=", "qry_obs_record", ".", "item", "(", ")", "\n", "\n", "", "if", "CFG", ".", "eval_seg", ":", "\n", "        ", "EVAL_RESULT", "[", "'miou_seg'", "]", "=", "np", ".", "stack", "(", "obs_seg_miou", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "if", "CFG", ".", "eval_qry_seg", ":", "\n", "        ", "EVAL_RESULT", "[", "'miou_qry'", "]", "=", "np", ".", "stack", "(", "qry_seg_miou", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "if", "len", "(", "GT_latents", ")", ">", "0", ":", "\n", "        ", "utils", ".", "write_json", "(", "{", "'scene_meta'", ":", "GT_latents", "}", ",", "os", ".", "path", ".", "join", "(", "CFG", ".", "output_dir", ",", "'gt_latent_meta.json'", ")", ")", "\n", "\n", "", "utils", ".", "write_json", "(", "EVAL_RESULT", ",", "os", ".", "path", ".", "join", "(", "CFG", ".", "check_dir", ",", "'eval_{}.json'", ".", "format", "(", "CFG", ".", "DATA_TYPE", ")", ")", ")", "\n", "\n", "return", "EVAL_RESULT", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.eval.main": [[297, 457], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "eval.running_cfg", "eval.run_evaluation", "print", "print", "print", "cfg.arch.lower", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "os.path.join"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.running_cfg", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.eval.run_evaluation"], ["", "def", "main", "(", "cfg", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--arch'", ",", "type", "=", "str", ",", "default", "=", "'ScnModel'", ",", "\n", "help", "=", "\"architecture name or model nickname\"", ")", "\n", "parser", ".", "add_argument", "(", "'--datatype'", ",", "type", "=", "str", ",", "default", "=", "'clevr_mv'", ",", "\n", "help", "=", "\"one of [clevr_mv, clevr_aug, gqn-jaco]\"", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of data samples of a minibatch'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch'", ",", "default", "=", "10000", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'run model on only the first [N] batch of the data set'", ")", "\n", "parser", ".", "add_argument", "(", "'--vis_batch'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'visualise only the first [N] batch and save to the generated dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--analyse_batch'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'save and analyse only the first [N] batch latent codes'", ")", "\n", "parser", ".", "add_argument", "(", "'--work_mode'", ",", "type", "=", "str", ",", "default", "=", "'testing'", ",", "help", "=", "\"model's working mode\"", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_epoch'", ",", "default", "=", "500", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'resume weights from [N]th epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_name'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'save the prediction output to the specified dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'specify id of gpu to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'random seed'", ")", "\n", "\n", "# Model spec", "\n", "parser", ".", "add_argument", "(", "'--num_slots'", ",", "default", "=", "7", ",", "type", "=", "int", ",", "help", "=", "'(maximum) number of component slots'", ")", "\n", "parser", ".", "add_argument", "(", "'--temperature'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'spatial scheduler increase rate, the hotter the faster coeff grows'", ")", "\n", "parser", ".", "add_argument", "(", "'--latent_dim'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "help", "=", "'size of the latent dimensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--view_dim'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'size of the viewpoint latent dimensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_sample_views'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'mininum allowed #views for scene learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_sample_views'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'maximum allowed #views for scene learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_vq_show'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'#views selected for visualisation'", ")", "\n", "parser", ".", "add_argument", "(", "'--pixel_sigma'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_mc_samples'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "'monte carlo samples for uncertainty estimation'", ")", "\n", "parser", ".", "add_argument", "(", "'--kl_latent'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--kl_spatial'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_attention'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--query_nll'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_nll'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_bg\"", ",", "default", "=", "False", ",", "help", "=", "\"treat background also an object\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all\"", ",", "default", "=", "False", ",", "help", "=", "\"evaluate model with all the metrics\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_recon\"", ",", "default", "=", "False", ",", "help", "=", "\"perform reconstruction evaluation\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_seg\"", ",", "default", "=", "False", ",", "help", "=", "\"perform segmentation evaluation\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_qry_obs\"", ",", "default", "=", "False", ",", "help", "=", "\"perform queried Obs.Pred. evaluation\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_qry_seg\"", ",", "default", "=", "False", ",", "help", "=", "\"perform queried Seg.Pred. evaluation\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_dist\"", ",", "default", "=", "False", ",", "help", "=", "\"perform disentanglement evaluation\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-i\"", ",", "'--input_dir'", ",", "required", "=", "True", ",", "help", "=", "\"path to the input data for the model to read\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-o\"", ",", "'--output_dir'", ",", "required", "=", "True", ",", "help", "=", "\"destination dir for the model to write out results\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "###########################################", "\n", "# General reconfig", "\n", "###########################################", "\n", "cfg", ".", "gpu", "=", "args", ".", "gpu", "\n", "\n", "cfg", ".", "arch", "=", "args", ".", "arch", "\n", "cfg", ".", "DATA_TYPE", "=", "args", ".", "datatype", "\n", "cfg", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "cfg", ".", "test_batch", "=", "args", ".", "test_batch", "\n", "cfg", ".", "vis_batch", "=", "args", ".", "vis_batch", "\n", "cfg", ".", "analyse_batch", "=", "args", ".", "analyse_batch", "\n", "cfg", ".", "WORK_MODE", "=", "args", ".", "work_mode", "\n", "cfg", ".", "resume_epoch", "=", "args", ".", "resume_epoch", "\n", "cfg", ".", "output_dir_name", "=", "args", ".", "output_name", "\n", "cfg", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "# model specs", "\n", "cfg", ".", "num_slots", "=", "args", ".", "num_slots", "\n", "cfg", ".", "temperature", "=", "args", ".", "temperature", "\n", "cfg", ".", "latent_dim", "=", "args", ".", "latent_dim", "\n", "cfg", ".", "view_dim", "=", "args", ".", "view_dim", "\n", "cfg", ".", "min_sample_views", "=", "args", ".", "min_sample_views", "\n", "cfg", ".", "max_sample_views", "=", "args", ".", "max_sample_views", "\n", "cfg", ".", "num_vq_show", "=", "args", ".", "num_vq_show", "\n", "cfg", ".", "num_mc_samples", "=", "args", ".", "num_mc_samples", "\n", "cfg", ".", "pixel_sigma", "=", "args", ".", "pixel_sigma", "\n", "cfg", ".", "elbo_weights", "=", "{", "\n", "'kl_latent'", ":", "args", ".", "kl_latent", ",", "\n", "'kl_spatial'", ":", "args", ".", "kl_spatial", ",", "\n", "'exp_attention'", ":", "args", ".", "exp_attention", ",", "\n", "'exp_nll'", ":", "args", ".", "exp_nll", ",", "\n", "'query_nll'", ":", "args", ".", "query_nll", "\n", "}", "\n", "\n", "# I/O path configurations", "\n", "cfg", ".", "DATA_ROOT", "=", "args", ".", "input_dir", "\n", "cfg", ".", "ckpt_base", "=", "args", ".", "output_dir", "\n", "\n", "# eval specs", "\n", "cfg", ".", "use_bg", "=", "args", ".", "use_bg", "\n", "\n", "if", "args", ".", "eval_all", ":", "\n", "        ", "cfg", ".", "eval_recon", "=", "True", "\n", "cfg", ".", "eval_seg", "=", "True", "\n", "cfg", ".", "eval_qry_obs", "=", "True", "\n", "cfg", ".", "eval_qry_seg", "=", "True", "\n", "", "else", ":", "\n", "        ", "cfg", ".", "eval_recon", "=", "args", ".", "eval_recon", "\n", "cfg", ".", "eval_seg", "=", "args", ".", "eval_seg", "\n", "cfg", ".", "eval_qry_obs", "=", "args", ".", "eval_qry_obs", "\n", "cfg", ".", "eval_qry_seg", "=", "args", ".", "eval_qry_seg", "\n", "\n", "", "if", "args", ".", "eval_dist", ":", "\n", "        ", "cfg", ".", "eval_dist", "=", "True", "\n", "\n", "", "if", "'gqn'", "in", "cfg", ".", "arch", ".", "lower", "(", ")", ":", "\n", "        ", "cfg", ".", "eval_seg", "=", "False", "\n", "\n", "", "running_cfg", "(", "cfg", ")", "\n", "\n", "# ---------- RUNNING EVALUATION ----------", "\n", "eval_scores", "=", "run_evaluation", "(", "cfg", ")", "\n", "\n", "print", "(", "\"\\n =========== Model '{}' Evaluated on '{}' dataset =========== \\n\"", ".", "format", "(", "cfg", ".", "arch", ",", "cfg", ".", "DATA_TYPE", ")", ")", "\n", "\n", "# print evaluation form", "\n", "if", "args", ".", "eval_all", ":", "\n", "# Recomposition", "\n", "        ", "print", "(", "'\\n  <Reconstruction>:'", ")", "\n", "print", "(", "'   -Rec_RMSE:    {}'", ".", "format", "(", "eval_scores", "[", "'rmse_rec'", "]", ")", ")", "\n", "\n", "# Observation querying", "\n", "print", "(", "'\\n  <Querying observation>:'", ")", "\n", "print", "(", "'   -Qry_RMSE:    {}'", ".", "format", "(", "eval_scores", "[", "'rmse_qry'", "]", ")", ")", "\n", "\n", "# Segmentation", "\n", "print", "(", "'\\n  <Segmentation>:'", ")", "\n", "print", "(", "'   -Seg_mIoU:     {}'", ".", "format", "(", "eval_scores", "[", "'miou_seg'", "]", ")", ")", "\n", "\n", "# Segmentation querying", "\n", "print", "(", "'\\n  <Querying segmentation>:'", ")", "\n", "print", "(", "'   -Query_mIoU:   {}'", ".", "format", "(", "eval_scores", "[", "'miou_qry'", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "cfg", ".", "eval_recon", ":", "\n", "            ", "print", "(", "'\\n  <Reconstruction>:'", ")", "\n", "print", "(", "'   -Rec_RMSE:    {}'", ".", "format", "(", "eval_scores", "[", "'rmse_rec'", "]", ")", ")", "\n", "", "if", "cfg", ".", "eval_qry_obs", ":", "\n", "            ", "print", "(", "'\\n  <Querying observation>:'", ")", "\n", "print", "(", "'   -Query_RMSE:    {}'", ".", "format", "(", "eval_scores", "[", "'rmse_qry'", "]", ")", ")", "\n", "", "if", "cfg", ".", "eval_seg", ":", "\n", "            ", "print", "(", "'\\n  <Segmentation>:'", ")", "\n", "print", "(", "'   -Seg_mIoU:     {}'", ".", "format", "(", "eval_scores", "[", "'miou_seg'", "]", ")", ")", "\n", "", "if", "cfg", ".", "eval_qry_seg", ":", "\n", "            ", "print", "(", "'\\n  <Querying segmentation>:'", ")", "\n", "print", "(", "'   -Query_mIoU:     {}'", ".", "format", "(", "eval_scores", "[", "'miou_qry'", "]", ")", ")", "\n", "\n", "", "", "if", "args", ".", "eval_dist", ":", "\n", "        ", "print", "(", "\"  check the saved latent codes here:\\n     {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "cfg", ".", "output_dir", ",", "'latents'", ")", ")", ")", "\n", "print", "(", "\"  configure https://github.com/cianeastwood/qedr.git for disentanglement quantification.\"", ")", "\n", "\n", "", "print", "(", "'\\n ==============================================='", ")", "\n", "print", "(", "'  EVALUATION FINISHED\\n\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train.running_cfg": [[23, 119], ["utils.ensure_dir", "os.path.join", "utils.ensure_dir", "os.path.join", "utils.ensure_dir", "os.path.join", "utils.ensure_dir", "os.path.join", "utils.ensure_dir", "len", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.join", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir"], ["def", "running_cfg", "(", "cfg", ")", ":", "\n", "###########################################", "\n", "# Config i/o path", "\n", "###########################################", "\n", "    ", "if", "cfg", ".", "DATA_TYPE", "==", "'gqn_jaco'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'jaco'", ",", "'generic'", "]", "\n", "cfg", ".", "v_in_dim", "=", "7", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'gqn_jaco'", ",", "'gqn_jaco_train.h5'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'gqn_jaco'", ",", "'gqn_jaco_test.h5'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'clevr_mv'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'cube'", ",", "'sphere'", ",", "'cylinder'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_mv'", ",", "'clevr_mv_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_mv'", ",", "'clevr_mv_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'clevr_aug'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'diamond'", ",", "'duck'", ",", "'mug'", ",", "'horse'", ",", "'dolphin'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_aug'", ",", "'clevr_aug_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_aug'", ",", "'clevr_aug_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "# ------------------- For your customised CLEVR -----------------------", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'your-clevr'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'xxx'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'your-clevr'", ",", "'your-clevr_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'your-clevr'", ",", "'your-clevr_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "# ------------------- For your customised CLEVR -----------------------", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "cfg", ".", "view_dim", "=", "cfg", ".", "v_in_dim", "\n", "\n", "# log directory", "\n", "ckpt_base", "=", "cfg", ".", "ckpt_base", "\n", "ensure_dir", "(", "ckpt_base", ")", "\n", "\n", "# model savedir", "\n", "check_dir", "=", "os", ".", "path", ".", "join", "(", "ckpt_base", ",", "'{}_log/'", ".", "format", "(", "cfg", ".", "arch", ")", ")", "\n", "ensure_dir", "(", "check_dir", ")", "\n", "\n", "# generated sample dir", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'saved_models/'", ")", "\n", "ensure_dir", "(", "save_dir", ")", "\n", "\n", "# visualise training epochs", "\n", "vis_train_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'vis_training/'", ")", "\n", "ensure_dir", "(", "vis_train_dir", ")", "\n", "\n", "# generated sample dir  (for testing generation)", "\n", "generated_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'generated/'", ")", "\n", "ensure_dir", "(", "generated_dir", ")", "\n", "\n", "if", "cfg", ".", "resume_path", "is", "not", "None", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "cfg", ".", "resume_path", ")", "\n", "", "elif", "cfg", ".", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "resume_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\n", "'checkpoint-epoch{}.pth'", ".", "format", "(", "cfg", ".", "resume_epoch", ")", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "resume_path", ")", "\n", "cfg", ".", "resume_path", "=", "resume_path", "\n", "\n", "", "cfg", ".", "DATA_DIR", "=", "data_dir", "\n", "cfg", ".", "train_data_filename", "=", "train_data_filename", "\n", "cfg", ".", "test_data_filename", "=", "test_data_filename", "\n", "cfg", ".", "check_dir", "=", "check_dir", "\n", "cfg", ".", "save_dir", "=", "save_dir", "\n", "cfg", ".", "vis_train_dir", "=", "vis_train_dir", "\n", "cfg", ".", "generated_dir", "=", "generated_dir", "\n", "\n", "cfg", ".", "image_size", "=", "image_size", "\n", "cfg", ".", "CLASSES", "=", "CLASSES", "\n", "cfg", ".", "num_classes", "=", "len", "(", "CLASSES", ")", "\n", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train.get_trainable_params": [[122, 130], ["print", "model.named_parameters", "print", "params_to_update.append"], "function", ["None"], ["", "def", "get_trainable_params", "(", "model", ")", ":", "\n", "    ", "params_to_update", "=", "[", "]", "\n", "print", "(", "'trainable parameters:'", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "requires_grad", ":", "\n", "            ", "print", "(", "\"\\t\"", ",", "name", ")", "\n", "params_to_update", ".", "append", "(", "param", ")", "\n", "", "", "return", "params_to_update", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train.train": [[132, 202], ["ScnModel", "train.get_trainable_params", "DataLoader", "DataLoader", "utils.set_random_seed", "trainer.model_trainer.ModelTrainer", "trainer.model_trainer.ModelTrainer.train", "print", "utils.load_trained_mp", "ScnModel.load_state_dict", "torch.optim.RMSprop", "torch.optim.Adam", "scheduler.AnnealingStepLR", "random.randint", "print", "print"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.get_trainable_params", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.set_random_seed", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.load_trained_mp"], ["", "def", "train", "(", "gpu_id", ",", "CFG", ")", ":", "\n", "    ", "if", "'GQN'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "baseline_gqn", "import", "GQN", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: GQN ---\"", ")", "\n", "", "elif", "'IODINE'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "baseline_iodine", "import", "IODINE", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: IODINE ---\"", ")", "\n", "", "elif", "'MulMON'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "mulmon", "import", "MulMON", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: MulMON ---\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "# Create the model", "\n", "", "scn_model", "=", "ScnModel", "(", "CFG", ")", "\n", "if", "CFG", ".", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "state_dict", "=", "load_trained_mp", "(", "CFG", ".", "resume_path", ")", "\n", "scn_model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "", "params_to_update", "=", "get_trainable_params", "(", "scn_model", ")", "\n", "\n", "if", "CFG", ".", "optimiser", "==", "'RMSprop'", ":", "\n", "        ", "optimiser", "=", "torch", ".", "optim", ".", "RMSprop", "(", "params_to_update", ",", "\n", "lr", "=", "CFG", ".", "lr_rate", ",", "\n", "weight_decay", "=", "CFG", ".", "weight_decay", ")", "\n", "lr_scheduler", "=", "None", "\n", "", "else", ":", "\n", "        ", "optimiser", "=", "torch", ".", "optim", ".", "Adam", "(", "params_to_update", ",", "\n", "lr", "=", "CFG", ".", "lr_rate", ",", "\n", "weight_decay", "=", "CFG", ".", "weight_decay", ")", "\n", "lr_scheduler", "=", "AnnealingStepLR", "(", "optimiser", ",", "mu_i", "=", "CFG", ".", "lr_rate", ",", "mu_f", "=", "0.1", "*", "CFG", ".", "lr_rate", ",", "n", "=", "1e6", ")", "\n", "\n", "", "if", "'gqn'", "in", "CFG", ".", "DATA_TYPE", ":", "\n", "        ", "from", "data_loader", ".", "getGqnH5", "import", "DataLoader", "\n", "", "elif", "'clevr'", "in", "CFG", ".", "DATA_TYPE", ":", "\n", "        ", "from", "data_loader", ".", "getClevrMV", "import", "DataLoader", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "# get data Loader", "\n", "", "train_dl", "=", "DataLoader", "(", "CFG", ".", "DATA_ROOT", ",", "\n", "CFG", ".", "train_data_filename", ",", "\n", "batch_size", "=", "CFG", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_slots", "=", "CFG", ".", "num_slots", ",", "\n", "use_bg", "=", "True", ")", "\n", "val_dl", "=", "DataLoader", "(", "CFG", ".", "DATA_ROOT", ",", "\n", "CFG", ".", "test_data_filename", ",", "\n", "batch_size", "=", "CFG", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_slots", "=", "CFG", ".", "num_slots", ",", "\n", "use_bg", "=", "True", ")", "\n", "\n", "if", "CFG", ".", "seed", "is", "None", ":", "\n", "        ", "CFG", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "1000000", ")", "\n", "", "set_random_seed", "(", "CFG", ".", "seed", ")", "\n", "\n", "trainer", "=", "ModelTrainer", "(", "\n", "model", "=", "scn_model", ",", "\n", "loss", "=", "None", ",", "\n", "metrics", "=", "None", ",", "\n", "optimizer", "=", "optimiser", ",", "\n", "step_per_epoch", "=", "CFG", ".", "step_per_epoch", ",", "\n", "config", "=", "CFG", ",", "\n", "train_data_loader", "=", "train_dl", ",", "\n", "valid_data_loader", "=", "val_dl", ",", "\n", "device", "=", "gpu_id", ",", "\n", "lr_scheduler", "=", "lr_scheduler", "\n", ")", "\n", "# Start training session", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train.main": [[204, 300], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "train.running_cfg", "train.train"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.running_cfg", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.train"], ["", "def", "main", "(", "cfg", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--arch'", ",", "type", "=", "str", ",", "default", "=", "'ScnModel'", ",", "\n", "help", "=", "\"model name\"", ")", "\n", "parser", ".", "add_argument", "(", "'--datatype'", ",", "type", "=", "str", ",", "default", "=", "'clevr'", ",", "\n", "help", "=", "\"one of [gqn_jaco, clevr_mv, clevr_aug]\"", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of total epochs to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--step_per_epoch'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of total epochs to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data samples of a minibatch'", ")", "\n", "parser", ".", "add_argument", "(", "'--work_mode'", ",", "type", "=", "str", ",", "default", "=", "'training'", ",", "help", "=", "\"model's working mode\"", ")", "\n", "parser", ".", "add_argument", "(", "'--optimiser'", ",", "type", "=", "str", ",", "default", "=", "'Adam'", ",", "help", "=", "\"help= one of [Adam, RMSprop]\"", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_epoch'", ",", "default", "=", "None", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'resume weights from [N]th epochs'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--nodes'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpus'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'number of gpus per node'", ")", "\n", "parser", ".", "add_argument", "(", "'--nrank'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'ranking within the nodes'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_start'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'first gpu indicator, default using 0 as the start'", ")", "\n", "parser", ".", "add_argument", "(", "'--master_port'", ",", "default", "=", "'8888'", ",", "type", "=", "str", ",", "help", "=", "'used for rank0 communication with others'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_rate'", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "help", "=", "'learning rate'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_slots'", ",", "default", "=", "7", ",", "type", "=", "int", ",", "help", "=", "'(maximum) number of component slots'", ")", "\n", "parser", ".", "add_argument", "(", "'--temperature'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'spatial scheduler increase rate, the hotter the faster coeff grows'", ")", "\n", "parser", ".", "add_argument", "(", "'--latent_dim'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "help", "=", "'size of the latent dimensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--view_dim'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'size of the viewpoint latent dimensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_sample_views'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'mininum allowed #views for scene learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_sample_views'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'maximum allowed #views for scene learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_vq_show'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'#views selected for visualisation'", ")", "\n", "parser", ".", "add_argument", "(", "'--pixel_sigma'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--kl_latent'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--kl_spatial'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_attention'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--query_nll'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_nll'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_mask\"", ",", "help", "=", "\"use gt mask to by pass the segmentation phase\"", ",", "\n", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_bg\"", ",", "help", "=", "\"treat background as an object\"", ",", "\n", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-i\"", ",", "'--input_dir'", ",", "required", "=", "True", ",", "help", "=", "\"path to the input data for the model to read\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-o\"", ",", "'--output_dir'", ",", "required", "=", "True", ",", "help", "=", "\"destination dir for the model to write out results\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "###########################################", "\n", "# General training reconfig", "\n", "###########################################", "\n", "cfg", ".", "arch", "=", "args", ".", "arch", "\n", "cfg", ".", "DATA_TYPE", "=", "args", ".", "datatype", "\n", "cfg", ".", "num_epochs", "=", "args", ".", "epochs", "\n", "cfg", ".", "step_per_epoch", "=", "args", ".", "step_per_epoch", "if", "args", ".", "step_per_epoch", ">", "0", "else", "None", "\n", "cfg", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "cfg", ".", "WORK_MODE", "=", "args", ".", "work_mode", "\n", "cfg", ".", "optimiser", "=", "args", ".", "optimiser", "\n", "cfg", ".", "resume_epoch", "=", "args", ".", "resume_epoch", "\n", "cfg", ".", "seed", "=", "args", ".", "seed", "\n", "cfg", ".", "lr_rate", "=", "args", ".", "lr_rate", "\n", "cfg", ".", "num_slots", "=", "args", ".", "num_slots", "\n", "cfg", ".", "temperature", "=", "args", ".", "temperature", "\n", "cfg", ".", "latent_dim", "=", "args", ".", "latent_dim", "\n", "cfg", ".", "view_dim", "=", "args", ".", "view_dim", "\n", "cfg", ".", "min_sample_views", "=", "args", ".", "min_sample_views", "\n", "cfg", ".", "max_sample_views", "=", "args", ".", "max_sample_views", "\n", "cfg", ".", "num_vq_show", "=", "args", ".", "num_vq_show", "\n", "cfg", ".", "pixel_sigma", "=", "args", ".", "pixel_sigma", "\n", "cfg", ".", "use_mask", "=", "args", ".", "use_mask", "\n", "cfg", ".", "use_bg", "=", "args", ".", "use_bg", "\n", "cfg", ".", "elbo_weights", "=", "{", "\n", "'kl_latent'", ":", "args", ".", "kl_latent", ",", "\n", "'kl_spatial'", ":", "args", ".", "kl_spatial", ",", "\n", "'exp_attention'", ":", "args", ".", "exp_attention", ",", "\n", "'exp_nll'", ":", "args", ".", "exp_nll", ",", "\n", "'query_nll'", ":", "args", ".", "query_nll", "\n", "}", "\n", "# I/O path configurations", "\n", "cfg", ".", "DATA_ROOT", "=", "args", ".", "input_dir", "\n", "cfg", ".", "ckpt_base", "=", "args", ".", "output_dir", "\n", "\n", "###########################################", "\n", "# Config gpu usage", "\n", "###########################################", "\n", "cfg", ".", "nodes", "=", "args", ".", "nodes", "\n", "cfg", ".", "gpus", "=", "args", ".", "gpus", "\n", "cfg", ".", "nrank", "=", "args", ".", "nrank", "\n", "cfg", ".", "gpu_start", "=", "args", ".", "gpu_start", "\n", "cfg", ".", "world_size", "=", "args", ".", "gpus", "*", "args", ".", "nodes", "#", "\n", "\n", "cfg", "=", "running_cfg", "(", "cfg", ")", "\n", "\n", "# # save current config for later evaluation", "\n", "# utils.write_pickle(cfg, os.path.join(cfg.check_dir, 'config.obj'))", "\n", "\n", "train", "(", "cfg", ".", "gpu_start", ",", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.scheduler.AnnealingStepLR.__init__": [[8, 13], ["torch.optim.lr_scheduler._LRScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "optimizer", ",", "mu_i", "=", "5e-4", ",", "mu_f", "=", "5e-5", ",", "n", "=", "1.6e6", ")", ":", "\n", "        ", "self", ".", "mu_i", "=", "mu_i", "\n", "self", ".", "mu_f", "=", "mu_f", "\n", "self", ".", "n", "=", "n", "\n", "super", "(", "AnnealingStepLR", ",", "self", ")", ".", "__init__", "(", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.scheduler.AnnealingStepLR.get_lr": [[14, 16], ["max"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "[", "max", "(", "self", ".", "mu_f", "+", "(", "self", ".", "mu_i", "-", "self", ".", "mu_f", ")", "*", "(", "1.0", "-", "self", ".", "last_epoch", "/", "self", ".", "n", ")", ",", "self", ".", "mu_f", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.enhance_save_single_image": [[19, 32], ["PIL.Image.fromarray", "enh[].enhance", "enh[].enhance", "enh[].enhance.save", "skimage.transform.resize", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Contrast"], "function", ["None"], ["def", "enhance_save_single_image", "(", "img", ",", "save_fname", ",", "out_size", "=", "None", ")", ":", "\n", "    ", "if", "out_size", ":", "\n", "        ", "img", "=", "resize", "(", "img", ",", "out_size", ",", "anti_aliasing", "=", "True", ")", "\n", "", "if", "img", ".", "dtype", "!=", "'uint8'", ":", "\n", "        ", "img", "=", "(", "img", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "pimg", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "enh", "=", "{", "\n", "'bright'", ":", "ImageEnhance", ".", "Brightness", "(", "pimg", ")", ",", "\n", "'contra'", ":", "ImageEnhance", ".", "Contrast", "(", "pimg", ")", ",", "\n", "}", "\n", "pimg", "=", "enh", "[", "'contra'", "]", ".", "enhance", "(", "1.25", ")", "\n", "pimg", "=", "enh", "[", "'bright'", "]", ".", "enhance", "(", "1.25", ")", "\n", "pimg", ".", "save", "(", "save_fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.torch_save_image_enhanced": [[34, 60], ["torchvision.utils.make_grid", "torchvision.utils.make_grid.mul_().add_().clamp_().permute().to().numpy", "PIL.Image.fromarray", "enh[].enhance.save", "enh[].enhance", "enh[].enhance", "torchvision.utils.make_grid.mul_().add_().clamp_().permute().to", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Contrast", "torchvision.utils.make_grid.mul_().add_().clamp_().permute", "torchvision.utils.make_grid.mul_().add_().clamp_", "torchvision.utils.make_grid.mul_().add_", "torchvision.utils.make_grid.mul_"], "function", ["None"], ["", "def", "torch_save_image_enhanced", "(", "tensor", ",", "filename", ",", "nrow", "=", "8", ",", "padding", "=", "2", ",", "\n", "normalize", "=", "False", ",", "\n", "range", "=", "None", ",", "\n", "scale_each", "=", "False", ",", "\n", "pad_value", "=", "0", ",", "\n", "enhance", "=", "False", ")", ":", "\n", "    ", "\"\"\"Save a given Tensor into an image file.\n\n    Args:\n        tensor (Tensor or list): Image to be saved. If given a mini-batch tensor,\n            saves the tensor as a grid of images by calling ``make_grid``.\n        **kwargs: Other arguments are documented in ``make_grid``.\n    \"\"\"", "\n", "grid", "=", "make_grid", "(", "tensor", ",", "nrow", "=", "nrow", ",", "padding", "=", "padding", ",", "pad_value", "=", "pad_value", ",", "\n", "normalize", "=", "normalize", ",", "range", "=", "range", ",", "scale_each", "=", "scale_each", ")", "\n", "# Add 0.5 after unnormalizing to [0, 255] to round to nearest integer", "\n", "ndarr", "=", "grid", ".", "mul_", "(", "255", ")", ".", "add_", "(", "0.5", ")", ".", "clamp_", "(", "0", ",", "255", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "to", "(", "'cpu'", ",", "torch", ".", "uint8", ")", ".", "numpy", "(", ")", "\n", "im", "=", "Image", ".", "fromarray", "(", "ndarr", ")", "\n", "if", "enhance", ":", "\n", "        ", "enh", "=", "{", "\n", "'bright'", ":", "ImageEnhance", ".", "Brightness", "(", "im", ")", ",", "\n", "'contra'", ":", "ImageEnhance", ".", "Contrast", "(", "im", ")", ",", "\n", "}", "\n", "im", "=", "enh", "[", "'contra'", "]", ".", "enhance", "(", "1.2", ")", "\n", "im", "=", "enh", "[", "'bright'", "]", ".", "enhance", "(", "1.2", ")", "\n", "", "im", ".", "save", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_single_image": [[62, 66], ["imageio.imwrite", "skimage.transform.resize"], "function", ["None"], ["", "def", "save_single_image", "(", "img", ",", "save_fname", ",", "out_size", "=", "None", ")", ":", "\n", "    ", "if", "out_size", ":", "\n", "        ", "img", "=", "resize", "(", "img", ",", "out_size", ",", "anti_aliasing", "=", "True", ")", "\n", "", "imageio", ".", "imwrite", "(", "save_fname", ",", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_uncertainty_plots": [[68, 76], ["matplotlib.imshow", "matplotlib.set_cmap", "matplotlib.tight_layout", "matplotlib.clim", "matplotlib.colorbar", "matplotlib.savefig", "matplotlib.close"], "function", ["None"], ["", "def", "save_uncertainty_plots", "(", "umap", ",", "save_to", ",", "cmap", "=", "'jet'", ")", ":", "\n", "    ", "plt", ".", "imshow", "(", "umap", ")", "\n", "plt", ".", "set_cmap", "(", "cmap", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "clim", "(", "0.", ",", "1.7", ")", "\n", "plt", ".", "colorbar", "(", ")", "\n", "plt", ".", "savefig", "(", "save_to", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_dorder_plots": [[78, 85], ["matplotlib.cm.hsv", "matplotlib.cm.Set1", "matplotlib.cm.Set2", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize"], "function", ["None"], ["", "def", "save_dorder_plots", "(", "img", ",", "K_comps", "=", "7", ",", "cmap", "=", "'hsv'", ")", ":", "\n", "    ", "fun", "=", "{", "\n", "'hsv'", ":", "lambda", "t", ":", "cm", ".", "hsv", "(", "colors", ".", "Normalize", "(", "vmin", "=", "0", ",", "vmax", "=", "K_comps", ")", "(", "t", ")", ",", "bytes", "=", "True", ")", ",", "\n", "'Set1'", ":", "lambda", "t", ":", "cm", ".", "Set1", "(", "colors", ".", "Normalize", "(", "vmin", "=", "0", ",", "vmax", "=", "K_comps", ")", "(", "t", ")", ",", "bytes", "=", "True", ")", ",", "\n", "'Set2'", ":", "lambda", "t", ":", "cm", ".", "Set2", "(", "colors", ".", "Normalize", "(", "vmin", "=", "0", ",", "vmax", "=", "K_comps", ")", "(", "t", ")", ",", "bytes", "=", "True", ")", "\n", "}", "\n", "return", "fun", "[", "cmap", "]", "(", "K_comps", "-", "img", ")", "\n", "# plt.imshow(fun(K_comps-img))", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.map_val_colors": [[91, 99], ["matplotlib.cm.afmhot", "matplotlib.cm.jet", "matplotlib.cm.Greys", "matplotlib.cm.Blues", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize"], "function", ["None"], ["", "def", "map_val_colors", "(", "img", ",", "v_min", "=", "0.0", ",", "v_max", "=", "1.0", ",", "cmap", "=", "'hot'", ")", ":", "\n", "    ", "fun", "=", "{", "\n", "'hot'", ":", "lambda", "t", ":", "cm", ".", "afmhot", "(", "colors", ".", "Normalize", "(", "vmin", "=", "v_min", ",", "vmax", "=", "v_max", ")", "(", "t", ")", ",", "bytes", "=", "True", ")", ",", "\n", "'jet'", ":", "lambda", "t", ":", "cm", ".", "jet", "(", "colors", ".", "Normalize", "(", "vmin", "=", "v_min", ",", "vmax", "=", "v_max", ")", "(", "t", ")", ",", "bytes", "=", "True", ")", ",", "\n", "'Greys'", ":", "lambda", "t", ":", "cm", ".", "Greys", "(", "colors", ".", "Normalize", "(", "vmin", "=", "v_min", ",", "vmax", "=", "v_max", ")", "(", "t", ")", ",", "bytes", "=", "True", ")", ",", "\n", "'Blues'", ":", "lambda", "t", ":", "cm", ".", "Blues", "(", "colors", ".", "Normalize", "(", "vmin", "=", "v_min", ",", "vmax", "=", "v_max", ")", "(", "t", ")", ",", "bytes", "=", "True", ")", ",", "\n", "}", "\n", "return", "fun", "[", "cmap", "]", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.test_vis": [[101, 117], ["os.path.join", "sorted", "numpy.random.choice", "numpy.load", "range", "multi_plots", "glob.glob", "str", "os.path.join", "unpacked.append", "unpacked.append", "numpy.int8", "len"], "function", ["None"], ["", "def", "test_vis", "(", "cfg", ")", ":", "\n", "    ", "DIR", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "vis_train_dir", ",", "'epoch_'", "+", "str", "(", "cfg", ".", "num_epochs", ")", ")", "\n", "npys", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "DIR", ",", "'*.npy'", ")", ")", ")", "\n", "\n", "npy", "=", "np", ".", "random", ".", "choice", "(", "npys", ")", "\n", "arr", "=", "np", ".", "load", "(", "npy", ")", "\n", "unpacked", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "arr", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "unpacked", ".", "append", "(", "arr", "[", "i", ",", "...", "]", ")", "\n", "", "else", ":", "\n", "            ", "unpacked", ".", "append", "(", "np", ".", "int8", "(", "arr", "[", "i", ",", "...", "]", "*", "255", ")", ")", "\n", "\n", "", "", "multi_plots", "(", "unpacked", ",", "1", ",", "arr", ".", "shape", "[", "0", "]", ",", "\n", "figsize", "=", "[", "2", "+", "len", "(", "unpacked", ")", "*", "4", ",", "4", "]", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_images_grid": [[119, 139], ["len", "matplotlib.subplots", "axes.flatten.flatten", "enumerate", "type", "type", "ax.axis", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "ax.imshow", "ax.set_xticks", "ax.set_yticks"], "function", ["None"], ["", "def", "save_images_grid", "(", "imgs_", ",", "nrows", ",", "ncols", ",", "fig_size", "=", "4", ",", "save_to", "=", "None", ")", ":", "\n", "    ", "assert", "type", "(", "nrows", ")", "==", "int", "\n", "assert", "type", "(", "nrows", ")", "==", "int", "\n", "num_images", "=", "len", "(", "imgs_", ")", "\n", "assert", "nrows", "*", "ncols", "==", "num_images", "\n", "_", ",", "axes", "=", "plt", ".", "subplots", "(", "ncols", ",", "nrows", ",", "figsize", "=", "(", "nrows", "*", "fig_size", ",", "ncols", "*", "fig_size", ")", ")", "\n", "axes", "=", "axes", ".", "flatten", "(", ")", "\n", "\n", "for", "ax_i", ",", "ax", "in", "enumerate", "(", "axes", ")", ":", "\n", "        ", "if", "ax_i", "<", "num_images", ":", "\n", "          ", "ax", ".", "imshow", "(", "imgs_", "[", "ax_i", "]", ",", "cmap", "=", "'Greys_r'", ",", "interpolation", "=", "'nearest'", ")", "\n", "ax", ".", "set_xticks", "(", "[", "]", ")", "\n", "ax", ".", "set_yticks", "(", "[", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "ax", ".", "axis", "(", "'off'", ")", "\n", "\n", "", "if", "save_to", ":", "\n", "        ", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "save_to", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.show_images_grid": [[141, 159], ["int", "int", "matplotlib.subplots", "axes.flatten.flatten", "enumerate", "numpy.ceil", "numpy.ceil", "ax.axis", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "ax.imshow", "ax.set_xticks", "ax.set_yticks"], "function", ["None"], ["", "", "def", "show_images_grid", "(", "imgs_", ",", "num_images", "=", "25", ",", "fig_size", "=", "4", ",", "save_to", "=", "None", ")", ":", "\n", "    ", "ncols", "=", "int", "(", "np", ".", "ceil", "(", "num_images", "**", "0.5", ")", ")", "\n", "nrows", "=", "int", "(", "np", ".", "ceil", "(", "num_images", "/", "ncols", ")", ")", "\n", "_", ",", "axes", "=", "plt", ".", "subplots", "(", "ncols", ",", "nrows", ",", "figsize", "=", "(", "nrows", "*", "fig_size", ",", "ncols", "*", "fig_size", ")", ")", "\n", "axes", "=", "axes", ".", "flatten", "(", ")", "\n", "\n", "for", "ax_i", ",", "ax", "in", "enumerate", "(", "axes", ")", ":", "\n", "        ", "if", "ax_i", "<", "num_images", ":", "\n", "          ", "ax", ".", "imshow", "(", "imgs_", "[", "ax_i", "]", ",", "cmap", "=", "'Greys_r'", ",", "interpolation", "=", "'nearest'", ")", "\n", "ax", ".", "set_xticks", "(", "[", "]", ")", "\n", "ax", ".", "set_yticks", "(", "[", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "ax", ".", "axis", "(", "'off'", ")", "\n", "\n", "", "if", "save_to", ":", "\n", "        ", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "save_to", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.grid2gif": [[161, 168], ["subprocess.call", "str"], "function", ["None"], ["", "", "def", "grid2gif", "(", "image_str", ",", "output_gif", ",", "delay", "=", "100", ")", ":", "\n", "    ", "\"\"\"Make GIF from images.\n    code from:\n        https://stackoverflow.com/questions/753190/programmatically-generate-video-or-animated-gif-in-python/34555939#34555939\n    \"\"\"", "\n", "str1", "=", "'convert -delay '", "+", "str", "(", "delay", ")", "+", "' -loop 0 '", "+", "image_str", "+", "' '", "+", "output_gif", "\n", "subprocess", ".", "call", "(", "str1", ",", "shell", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir": [[18, 21], ["os.path.isdir", "os.makedirs"], "function", ["None"], ["def", "ensure_dir", "(", "dirname", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "isdir", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_json": [[23, 26], ["open", "json.load"], "function", ["None"], ["", "", "def", "read_json", "(", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "\"r\"", ")", "as", "read_file", ":", "\n", "        ", "return", "json", ".", "load", "(", "read_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.write_json": [[28, 31], ["open", "json.dump"], "function", ["None"], ["", "", "def", "write_json", "(", "content", ",", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "\"w\"", ")", "as", "write_file", ":", "\n", "        ", "json", ".", "dump", "(", "content", ",", "write_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_h5py": [[33, 35], ["h5py.File"], "function", ["None"], ["", "", "def", "read_h5py", "(", "fname", ")", ":", "\n", "    ", "return", "h5py", ".", "File", "(", "fname", ",", "'r'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.write_pick": [[37, 41], ["open", "pickle.dump", "open.close"], "function", ["None"], ["", "def", "write_pick", "(", "content", ",", "fname", ")", ":", "\n", "    ", "pickle_out", "=", "open", "(", "fname", ",", "\"wb\"", ")", "\n", "pickle", ".", "dump", "(", "content", ",", "pickle_out", ")", "\n", "pickle_out", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.load_pickle": [[43, 46], ["open", "pickle.load"], "function", ["None"], ["", "def", "load_pickle", "(", "fname", ")", ":", "\n", "    ", "pickle_in", "=", "open", "(", "fname", ",", "\"rb\"", ")", "\n", "return", "pickle", ".", "load", "(", "pickle_in", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.inf_loop": [[49, 53], ["itertools.repeat"], "function", ["None"], ["", "def", "inf_loop", "(", "data_loader", ")", ":", "\n", "    ", "\"\"\"wrapper function for endless data loader\"\"\"", "\n", "for", "loader", "in", "repeat", "(", "data_loader", ")", ":", "\n", "        ", "yield", "from", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.set_random_seed": [[55, 62], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "", "def", "set_random_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"set random seed\"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.load_trained_mp": [[64, 74], ["collections.OrderedDict", "state_dict.items", "torch.load"], "function", ["None"], ["", "def", "load_trained_mp", "(", "ckpt_path", ")", ":", "\n", "    ", "state_dict", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "'cpu'", ")", "[", "'model'", "]", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "[", ":", "7", "]", "==", "'module.'", ":", "\n", "            ", "name", "=", "k", "[", "7", ":", "]", "# remove `module.`", "\n", "", "else", ":", "\n", "            ", "name", "=", "k", "\n", "", "new_state_dict", "[", "name", "]", "=", "v", "\n", "", "return", "new_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify": [[77, 79], ["tensor.detach().cpu().numpy", "tensor.detach().cpu", "tensor.detach"], "function", ["None"], ["", "def", "numpify", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.iou_pair": [[81, 94], ["outputs.dim", "outputs.size", "outputs.dim", "labels.size", "intersection.float().sum", "union.float().sum", "intersection.float", "union.float"], "function", ["None"], ["", "def", "iou_pair", "(", "outputs", ":", "torch", ".", "Tensor", ",", "labels", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "assert", "outputs", ".", "dim", "(", ")", "==", "2", ",", "'expected [H, W], got {}'", ".", "format", "(", "outputs", ".", "size", "(", ")", ")", "\n", "assert", "outputs", ".", "dim", "(", ")", "==", "2", ",", "'expected [H, W], got {}'", ".", "format", "(", "labels", ".", "size", "(", ")", ")", "\n", "assert", "outputs", ".", "dtype", "==", "torch", ".", "float32", "\n", "assert", "labels", ".", "dtype", "==", "torch", ".", "float32", "\n", "\n", "intersection", "=", "(", "outputs", ">", "0.9", ")", "&", "(", "labels", ">", "0.9", ")", "\n", "union", "=", "(", "outputs", ">", "0.9", ")", "|", "(", "labels", ">", "0.9", ")", "\n", "\n", "# union = (outputs + labels > 0.8).float().sum(())  # Will be zzero if both are 0", "\n", "iou", "=", "(", "intersection", ".", "float", "(", ")", ".", "sum", "(", ")", "+", "1e-6", ")", "/", "(", "union", ".", "float", "(", ")", ".", "sum", "(", ")", "+", "1e-6", ")", "\n", "iou", "=", "iou", "if", "iou", ">", "0.05", "else", "iou", "*", "0.0", "\n", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.iou_scn": [[96, 118], ["x.size", "gt.size", "range", "torch.stack", "x.dim", "gt.dim", "M.append", "torch.stack.mean", "utils.iou_pair"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.iou_pair"], ["", "def", "iou_scn", "(", "x", ",", "gt", ",", "threshold", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"\n    outputs: [K, H, W]\n    labels:  [K, H, W]\n    \"\"\"", "\n", "assert", "x", ".", "dim", "(", ")", "==", "3", "\n", "assert", "gt", ".", "dim", "(", ")", "==", "3", "\n", "\n", "len_x", "=", "x", ".", "size", "(", "0", ")", "\n", "len_gt", "=", "gt", ".", "size", "(", "0", ")", "\n", "assert", "len_x", "==", "len_gt", "\n", "\n", "M", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len_x", ")", ":", "\n", "        ", "M", ".", "append", "(", "iou_pair", "(", "x", "[", "k", "]", ",", "gt", "[", "k", "]", ")", ")", "\n", "", "iou_scores", "=", "torch", ".", "stack", "(", "M", ",", "dim", "=", "0", ")", "\n", "\n", "# iou_scores = torch.stack(M, dim=0)", "\n", "if", "threshold", "<", "1.0", ":", "\n", "        ", "return", "(", "iou_scores", ">=", "threshold", ")", ".", "type", "(", "x", ".", "dtype", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "iou_scores", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.iou_scn_unmatch": [[120, 145], ["x.size", "gt.size", "range", "torch.stack", "torch.max", "x.dim", "gt.dim", "range", "torch.stack.append", "assign.append", "torch.tensor", "m_indices.tolist", "iou_assign.mean", "m_indices.tolist", "utils.iou_pair"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.iou_pair"], ["", "", "def", "iou_scn_unmatch", "(", "x", ",", "gt", ",", "threshold", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"\n    outputs: [K, H, W]\n    labels:  [K, H, W]\n    \"\"\"", "\n", "assert", "x", ".", "dim", "(", ")", "==", "3", "\n", "assert", "gt", ".", "dim", "(", ")", "==", "3", "\n", "\n", "len_x", "=", "x", ".", "size", "(", "0", ")", "\n", "len_gt", "=", "gt", ".", "size", "(", "0", ")", "\n", "\n", "M", "=", "[", "]", "\n", "for", "g", "in", "range", "(", "len_gt", ")", ":", "\n", "        ", "assign", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len_x", ")", ":", "\n", "# USE ONE OF THE METRIC AS OBJECTIVE TO MATCH pred & gt", "\n", "            ", "assign", ".", "append", "(", "iou_pair", "(", "x", "[", "k", "]", ",", "gt", "[", "g", "]", ")", ")", "\n", "", "M", ".", "append", "(", "torch", ".", "tensor", "(", "assign", ")", ")", "\n", "", "M", "=", "torch", ".", "stack", "(", "M", ",", "dim", "=", "0", ")", "\n", "# pdb.set_trace()", "\n", "iou_assign", ",", "m_indices", "=", "torch", ".", "max", "(", "M", ",", "dim", "=", "1", ")", "\n", "if", "threshold", "<", "1.0", ":", "\n", "        ", "return", "(", "iou_assign", ">=", "threshold", ")", ".", "type", "(", "x", ".", "dtype", ")", ".", "mean", "(", ")", ",", "m_indices", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "iou_assign", ".", "mean", "(", ")", ",", "m_indices", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.match_or_compute_segmentation_iou": [[147, 181], ["m_preds.reshape.size", "m_gts.reshape().type.size", "num_comps.reshape().tolist.reshape().tolist", "torch.zeros_like().scatter", "m_preds.reshape.reshape", "m_gts.reshape().type.reshape().type", "m_preds.reshape.size", "m_preds.reshape.dim", "m_gts.reshape().type.dim", "m_gts.reshape().type.size", "range", "range", "num_comps.reshape().tolist.reshape", "torch.zeros_like", "torch.max", "m_gts.reshape().type.reshape", "utils.iou_scn_unmatch", "iou_list.append", "match_list.append", "utils.iou_scn", "iou_list.append", "utils.numpify", "utils.numpify"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.iou_scn_unmatch", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.iou_scn", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify"], ["", "", "def", "match_or_compute_segmentation_iou", "(", "m_preds", ",", "m_gts", ",", "num_comps", ",", "match_list", "=", "None", ",", "threshold", "=", "1.0", ")", ":", "\n", "    ", "\"\"\" If the 'match_list' is provided, then we return the mIoU scores. Otherwise, this function does Hungarian-style\n    matching and then return a match list.\n    :param m_preds: [B, V, K, H, W] tensor\n    :param m_gts: [B, V, K1, H, W] tensor\n    :param num_comps: [B, V] the number of objects in the scene (given as GT)\n    \"\"\"", "\n", "assert", "m_preds", ".", "dim", "(", ")", "==", "m_gts", ".", "dim", "(", ")", "\n", "K", "=", "m_preds", ".", "size", "(", "2", ")", "\n", "B", ",", "V", ",", "K1", ",", "H", ",", "W", "=", "m_gts", ".", "size", "(", ")", "\n", "assert", "K", ">=", "K1", ",", "'K is smaller than the number of objects, segmentation evaluations should be disabled'", "\n", "\n", "assert", "num_comps", ".", "shape", "[", "0", "]", "==", "B", "\n", "num_comps", "=", "num_comps", ".", "reshape", "(", "(", "B", "*", "V", ",", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "m_preds", "=", "torch", ".", "zeros_like", "(", "m_preds", ")", ".", "scatter", "(", "2", ",", "torch", ".", "max", "(", "m_preds", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "[", "1", "]", ",", "1", ")", "\n", "m_preds", "=", "m_preds", ".", "reshape", "(", "B", "*", "V", ",", "K", ",", "H", ",", "W", ")", "\n", "m_gts", "=", "m_gts", ".", "reshape", "(", "B", "*", "V", ",", "K1", ",", "H", ",", "W", ")", ".", "type", "(", "m_preds", ".", "dtype", ")", "\n", "N", "=", "m_preds", ".", "size", "(", "0", ")", "\n", "assert", "m_gts", ".", "size", "(", "0", ")", "==", "N", "\n", "\n", "iou_list", "=", "[", "]", "\n", "if", "match_list", "is", "None", ":", "\n", "        ", "match_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "miou_scn_val", ",", "gt_to_out", "=", "iou_scn_unmatch", "(", "m_preds", "[", "i", "]", ",", "m_gts", "[", "i", ",", ":", "num_comps", "[", "i", "]", "]", ",", "threshold", "=", "threshold", ")", "\n", "iou_list", ".", "append", "(", "numpify", "(", "miou_scn_val", ")", ")", "\n", "match_list", ".", "append", "(", "gt_to_out", ")", "\n", "", "return", "iou_list", ",", "match_list", "\n", "", "else", ":", "\n", "        ", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "miou_scn_val", "=", "iou_scn", "(", "m_preds", "[", "i", ",", "match_list", "[", "i", "]", "]", ",", "m_gts", "[", "i", ",", ":", "num_comps", "[", "i", "]", "]", ",", "threshold", "=", "threshold", ")", "\n", "iou_list", ".", "append", "(", "numpify", "(", "miou_scn_val", ")", ")", "\n", "", "return", "iou_list", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.save_latents_for_eval": [[212, 244], ["len", "enumerate", "numpy.stack", "os.path.basename", "GTs.append", "obj_to_gt_idx.append", "utils.ensure_dir", "os.path.join", "numpy.savez", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir"], ["def", "save_latents_for_eval", "(", "z_v_out", ",", "z_out", ",", "scn_indices", ",", "qry_views", ",", "gt_scenes_meta", ",", "\n", "out_dir", "=", "None", ",", "\n", "save_count", "=", "0", ")", ":", "\n", "    ", "B", "=", "len", "(", "scn_indices", ")", "\n", "GTs", "=", "[", "]", "\n", "for", "s_count", ",", "sid", "in", "enumerate", "(", "scn_indices", ")", ":", "\n", "# correct objects' permuations", "\n", "        ", "obj_to_gt_idx", "=", "[", "]", "\n", "# for v in range(len(z_v_out)):", "\n", "#     obj_to_gt_idx.append(gt_scenes_meta[sid]['depth_orders'][v])", "\n", "for", "v", "in", "qry_views", ":", "\n", "            ", "obj_to_gt_idx", ".", "append", "(", "gt_scenes_meta", "[", "sid", "]", "[", "'depth_orders'", "]", "[", "v", "]", ")", "\n", "", "z_v_out", "=", "np", ".", "stack", "(", "z_v_out", ",", "axis", "=", "0", ")", "\n", "\n", "actual_idx", "=", "save_count", "+", "s_count", "\n", "base_dir_name", "=", "os", ".", "path", ".", "basename", "(", "out_dir", ")", "\n", "save_to", "=", "None", "\n", "if", "out_dir", ":", "\n", "            ", "ensure_dir", "(", "out_dir", ")", "\n", "save_to", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'zout_{:06d}'", ".", "format", "(", "actual_idx", ")", ")", "\n", "np", ".", "savez", "(", "save_to", ",", "\n", "out_z_v", "=", "z_v_out", ",", "\n", "out_z", "=", "z_out", "[", "s_count", "]", ")", "\n", "\n", "", "s", "=", "{", "\n", "'z_path'", ":", "'{}/{}'", ".", "format", "(", "base_dir_name", ",", "os", ".", "path", ".", "basename", "(", "save_to", ")", ")", ",", "\n", "'obj_to_gt_map'", ":", "obj_to_gt_idx", ",", "\n", "'objects'", ":", "gt_scenes_meta", "[", "sid", "]", "[", "'objects'", "]", ",", "\n", "'query_views'", ":", "qry_views", "\n", "}", "\n", "GTs", ".", "append", "(", "s", ")", "\n", "", "return", "GTs", "", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.running_cfg": [[26, 122], ["utils.ensure_dir", "os.path.join", "utils.ensure_dir", "os.path.join", "utils.ensure_dir", "os.path.join", "utils.ensure_dir", "os.path.join", "utils.ensure_dir", "len", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.join", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.exists", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir"], ["def", "running_cfg", "(", "cfg", ")", ":", "\n", "###########################################", "\n", "# Config i/o path", "\n", "###########################################", "\n", "    ", "if", "cfg", ".", "DATA_TYPE", "==", "'gqn_jaco'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'jaco'", ",", "'generic'", "]", "\n", "cfg", ".", "v_in_dim", "=", "7", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'gqn_jaco'", ",", "'gqn_jaco_train.h5'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'gqn_jaco'", ",", "'gqn_jaco_test.h5'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'clevr_mv'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'cube'", ",", "'sphere'", ",", "'cylinder'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_mv'", ",", "'clevr_mv_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_mv'", ",", "'clevr_mv_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'clevr_aug'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'diamond'", ",", "'duck'", ",", "'mug'", ",", "'horse'", ",", "'dolphin'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_aug'", ",", "'clevr_aug_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'clevr_aug'", ",", "'clevr_aug_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "# ------------------- For your customised CLEVR -----------------------", "\n", "", "elif", "cfg", ".", "DATA_TYPE", "==", "'your-clevr'", ":", "\n", "        ", "image_size", "=", "[", "64", ",", "64", "]", "\n", "CLASSES", "=", "[", "'_background_'", ",", "'xxx'", "]", "\n", "cfg", ".", "v_in_dim", "=", "3", "\n", "cfg", ".", "max_sample_views", "=", "6", "\n", "data_dir", "=", "cfg", ".", "DATA_ROOT", "\n", "assert", "os", ".", "path", ".", "exists", "(", "data_dir", ")", "\n", "train_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'your-clevr'", ",", "'your-clevr_train.json'", ")", "\n", "test_data_filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'your-clevr'", ",", "'your-clevr_test.json'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "train_data_filename", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "test_data_filename", ")", "\n", "# ------------------- For your customised CLEVR -----------------------", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "cfg", ".", "view_dim", "=", "cfg", ".", "v_in_dim", "\n", "\n", "# log directory", "\n", "ckpt_base", "=", "cfg", ".", "ckpt_base", "\n", "ensure_dir", "(", "ckpt_base", ")", "\n", "\n", "# model savedir", "\n", "check_dir", "=", "os", ".", "path", ".", "join", "(", "ckpt_base", ",", "'{}_log/'", ".", "format", "(", "cfg", ".", "arch", ")", ")", "\n", "ensure_dir", "(", "check_dir", ")", "\n", "\n", "# generated sample dir", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'saved_models/'", ")", "\n", "ensure_dir", "(", "save_dir", ")", "\n", "\n", "# visualise training epochs", "\n", "vis_train_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'vis_training/'", ")", "\n", "ensure_dir", "(", "vis_train_dir", ")", "\n", "\n", "# generated sample dir  (for testing generation)", "\n", "generated_dir", "=", "os", ".", "path", ".", "join", "(", "check_dir", ",", "'generated/'", ")", "\n", "ensure_dir", "(", "generated_dir", ")", "\n", "\n", "if", "cfg", ".", "resume_path", "is", "not", "None", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "cfg", ".", "resume_path", ")", "\n", "", "elif", "cfg", ".", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "resume_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\n", "'checkpoint-epoch{}.pth'", ".", "format", "(", "cfg", ".", "resume_epoch", ")", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "resume_path", ")", "\n", "cfg", ".", "resume_path", "=", "resume_path", "\n", "\n", "", "cfg", ".", "DATA_DIR", "=", "data_dir", "\n", "cfg", ".", "train_data_filename", "=", "train_data_filename", "\n", "cfg", ".", "test_data_filename", "=", "test_data_filename", "\n", "cfg", ".", "check_dir", "=", "check_dir", "\n", "cfg", ".", "save_dir", "=", "save_dir", "\n", "cfg", ".", "vis_train_dir", "=", "vis_train_dir", "\n", "cfg", ".", "generated_dir", "=", "generated_dir", "\n", "\n", "cfg", ".", "image_size", "=", "image_size", "\n", "cfg", ".", "CLASSES", "=", "CLASSES", "\n", "cfg", ".", "num_classes", "=", "len", "(", "CLASSES", ")", "\n", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.get_trainable_params": [[125, 133], ["print", "model.named_parameters", "print", "params_to_update.append"], "function", ["None"], ["", "def", "get_trainable_params", "(", "model", ")", ":", "\n", "    ", "params_to_update", "=", "[", "]", "\n", "print", "(", "'trainable parameters:'", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "requires_grad", ":", "\n", "            ", "print", "(", "\"\\t\"", ",", "name", ")", "\n", "params_to_update", ".", "append", "(", "param", ")", "\n", "", "", "return", "params_to_update", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.train": [[135, 243], ["torch.init_process_group", "utils.set_random_seed", "ScnModel", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "nn.parallel.DistributedDataParallel.cuda", "train_parallel.get_trainable_params", "torch.parallel.DistributedDataParallel", "distributed_loader", "distributed_loader", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "trainer.model_trainer_parallel.ModelTrainer", "trainer.model_trainer_parallel.ModelTrainer.train", "print", "random.randint", "utils.load_trained_mp", "nn.parallel.DistributedDataParallel.load_state_dict", "torch.optim.RMSprop", "torch.optim.RMSprop", "torch.optim.RMSprop", "torch.optim.RMSprop", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "scheduler.AnnealingStepLR", "print", "print", "tuple", "tuple", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.set_random_seed", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.get_trainable_params", "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.distributed_loader", "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.distributed_loader", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.load_trained_mp"], ["", "def", "train", "(", "process_id", ",", "CFG", ")", ":", "\n", "    ", "if", "'GQN'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "baseline_gqn", "import", "GQN", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: GQN ---\"", ")", "\n", "", "elif", "'IODINE'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "baseline_iodine", "import", "IODINE", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: IODINE ---\"", ")", "\n", "", "elif", "'MulMON'", "in", "CFG", ".", "arch", ":", "\n", "        ", "from", "models", ".", "mulmon", "import", "MulMON", "as", "ScnModel", "\n", "print", "(", "\" --- Arch: MulMON ---\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "rank", "=", "CFG", ".", "nrank", "*", "CFG", ".", "gpus", "+", "process_id", "\n", "gpu", "=", "process_id", "+", "CFG", ".", "gpu_start", "# e.g. gpus=2, gpu_start=1 means using gpu [0+1, 1+1] = [1, 2].", "\n", "\n", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "'nccl'", ",", "\n", "init_method", "=", "'env://'", ",", "\n", "world_size", "=", "CFG", ".", "world_size", ",", "\n", "rank", "=", "rank", "\n", ")", "\n", "\n", "if", "CFG", ".", "seed", "is", "None", ":", "\n", "        ", "CFG", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "1000000", ")", "\n", "", "set_random_seed", "(", "CFG", ".", "seed", ")", "\n", "\n", "# Create the model", "\n", "scn_model", "=", "ScnModel", "(", "CFG", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "gpu", ")", "\n", "\n", "if", "CFG", ".", "resume_epoch", "is", "not", "None", ":", "\n", "        ", "state_dict", "=", "load_trained_mp", "(", "CFG", ".", "resume_path", ")", "\n", "scn_model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "\n", "", "scn_model", ".", "cuda", "(", "gpu", ")", "\n", "params_to_update", "=", "get_trainable_params", "(", "scn_model", ")", "\n", "\n", "if", "CFG", ".", "optimiser", "==", "'RMSprop'", ":", "\n", "        ", "optimiser", "=", "torch", ".", "optim", ".", "RMSprop", "(", "params_to_update", ",", "\n", "lr", "=", "CFG", ".", "lr_rate", ",", "\n", "weight_decay", "=", "CFG", ".", "weight_decay", ")", "\n", "lr_scheduler", "=", "None", "\n", "", "else", ":", "\n", "        ", "optimiser", "=", "torch", ".", "optim", ".", "Adam", "(", "params_to_update", ",", "\n", "lr", "=", "CFG", ".", "lr_rate", ",", "\n", "weight_decay", "=", "CFG", ".", "weight_decay", ")", "\n", "lr_scheduler", "=", "AnnealingStepLR", "(", "optimiser", ",", "mu_i", "=", "CFG", ".", "lr_rate", ",", "mu_f", "=", "0.1", "*", "CFG", ".", "lr_rate", ",", "n", "=", "1.0e6", ")", "\n", "\n", "", "scn_model", "=", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "scn_model", ",", "\n", "device_ids", "=", "[", "gpu", "]", ")", "\n", "\n", "if", "'gqn'", "in", "CFG", ".", "DATA_TYPE", ":", "\n", "        ", "from", "data_loader", ".", "getGqnH5", "import", "distributed_loader", "\n", "", "elif", "'clevr'", "in", "CFG", ".", "DATA_TYPE", ":", "\n", "        ", "from", "data_loader", ".", "getClevrMV", "import", "distributed_loader", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "train_dataset", "=", "distributed_loader", "(", "CFG", ".", "DATA_ROOT", ",", "\n", "CFG", ".", "train_data_filename", ",", "\n", "num_slots", "=", "CFG", ".", "num_slots", ",", "\n", "use_bg", "=", "CFG", ".", "use_bg", ")", "\n", "val_dataset", "=", "distributed_loader", "(", "CFG", ".", "DATA_ROOT", ",", "\n", "CFG", ".", "test_data_filename", ",", "\n", "num_slots", "=", "CFG", ".", "num_slots", ",", "\n", "use_bg", "=", "CFG", ".", "use_bg", ")", "\n", "\n", "train_sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "train_dataset", ",", "\n", "num_replicas", "=", "CFG", ".", "world_size", ",", "\n", "rank", "=", "rank", "\n", ")", "\n", "val_sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "val_dataset", ",", "\n", "num_replicas", "=", "CFG", ".", "world_size", ",", "\n", "rank", "=", "rank", "\n", ")", "\n", "\n", "# get data Loader", "\n", "train_dl", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "train_dataset", ",", "\n", "batch_size", "=", "CFG", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "lambda", "x", ":", "tuple", "(", "zip", "(", "*", "x", ")", ")", ",", "\n", "sampler", "=", "train_sampler", ")", "\n", "val_dl", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "train_dataset", ",", "\n", "batch_size", "=", "CFG", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "lambda", "x", ":", "tuple", "(", "zip", "(", "*", "x", ")", ")", ",", "\n", "sampler", "=", "val_sampler", ")", "\n", "trainer", "=", "ModelTrainer", "(", "\n", "model", "=", "scn_model", ",", "\n", "loss", "=", "None", ",", "\n", "metrics", "=", "None", ",", "\n", "optimizer", "=", "optimiser", ",", "\n", "step_per_epoch", "=", "CFG", ".", "step_per_epoch", ",", "\n", "config", "=", "CFG", ",", "\n", "train_data_loader", "=", "train_dl", ",", "\n", "valid_data_loader", "=", "val_dl", ",", "\n", "device", "=", "gpu", ",", "\n", "lr_scheduler", "=", "lr_scheduler", "\n", ")", "\n", "# Start training session", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.main": [[245, 343], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "train_parallel.running_cfg", "torch.spawn"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.train_parallel.running_cfg"], ["", "def", "main", "(", "cfg", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--arch'", ",", "type", "=", "str", ",", "default", "=", "'ScnModel'", ",", "\n", "help", "=", "\"model name\"", ")", "\n", "parser", ".", "add_argument", "(", "'--datatype'", ",", "type", "=", "str", ",", "default", "=", "'clevr'", ",", "\n", "help", "=", "\"one of [gqn_jaco, clevr_mv, clevr_aug]\"", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of total epochs to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--step_per_epoch'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of total epochs to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "help", "=", "'number of data samples of a minibatch'", ")", "\n", "parser", ".", "add_argument", "(", "'--work_mode'", ",", "type", "=", "str", ",", "default", "=", "'training'", ",", "help", "=", "\"model's working mode\"", ")", "\n", "parser", ".", "add_argument", "(", "'--optimiser'", ",", "type", "=", "str", ",", "default", "=", "'Adam'", ",", "help", "=", "\"help= one of [Adam, RMSprop]\"", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_epoch'", ",", "default", "=", "None", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'resume weights from [N]th epochs'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--nodes'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpus'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'number of gpus per node'", ")", "\n", "parser", ".", "add_argument", "(", "'--nrank'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'ranking within the nodes'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_start'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'first gpu indicator, default using 0 as the start'", ")", "\n", "parser", ".", "add_argument", "(", "'--master_port'", ",", "default", "=", "'8888'", ",", "type", "=", "str", ",", "help", "=", "'used for rank0 communication with others'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_rate'", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "help", "=", "'learning rate'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_slots'", ",", "default", "=", "7", ",", "type", "=", "int", ",", "help", "=", "'(maximum) number of component slots'", ")", "\n", "parser", ".", "add_argument", "(", "'--temperature'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'spatial scheduler increase rate, the hotter the faster coeff grows'", ")", "\n", "parser", ".", "add_argument", "(", "'--latent_dim'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "help", "=", "'size of the latent dimensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--view_dim'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'size of the viewpoint latent dimensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_sample_views'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'mininum allowed #views for scene learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_sample_views'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'maximum allowed #views for scene learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_vq_show'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'#views selected for visualisation'", ")", "\n", "parser", ".", "add_argument", "(", "'--pixel_sigma'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--kl_latent'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--kl_spatial'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_attention'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--query_nll'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_nll'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "'loss strength item'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_mask\"", ",", "help", "=", "\"use gt mask to by pass the segmentation phase\"", ",", "\n", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_bg\"", ",", "help", "=", "\"treat background as an object\"", ",", "\n", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-i\"", ",", "'--input_dir'", ",", "required", "=", "True", ",", "help", "=", "\"path to the input data for the model to read\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-o\"", ",", "'--output_dir'", ",", "required", "=", "True", ",", "help", "=", "\"destination dir for the model to write out results\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "###########################################", "\n", "# General training reconfig", "\n", "###########################################", "\n", "cfg", ".", "arch", "=", "args", ".", "arch", "\n", "cfg", ".", "DATA_TYPE", "=", "args", ".", "datatype", "\n", "cfg", ".", "num_epochs", "=", "args", ".", "epochs", "\n", "cfg", ".", "step_per_epoch", "=", "args", ".", "step_per_epoch", "if", "args", ".", "step_per_epoch", ">", "0", "else", "None", "\n", "cfg", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "cfg", ".", "WORK_MODE", "=", "args", ".", "work_mode", "\n", "cfg", ".", "optimiser", "=", "args", ".", "optimiser", "\n", "cfg", ".", "resume_epoch", "=", "args", ".", "resume_epoch", "\n", "cfg", ".", "seed", "=", "args", ".", "seed", "\n", "cfg", ".", "lr_rate", "=", "args", ".", "lr_rate", "\n", "cfg", ".", "num_slots", "=", "args", ".", "num_slots", "\n", "cfg", ".", "temperature", "=", "args", ".", "temperature", "\n", "cfg", ".", "latent_dim", "=", "args", ".", "latent_dim", "\n", "cfg", ".", "view_dim", "=", "args", ".", "view_dim", "\n", "cfg", ".", "min_sample_views", "=", "args", ".", "min_sample_views", "\n", "cfg", ".", "max_sample_views", "=", "args", ".", "max_sample_views", "\n", "cfg", ".", "num_vq_show", "=", "args", ".", "num_vq_show", "\n", "cfg", ".", "pixel_sigma", "=", "args", ".", "pixel_sigma", "\n", "cfg", ".", "use_mask", "=", "args", ".", "use_mask", "\n", "cfg", ".", "use_bg", "=", "args", ".", "use_bg", "\n", "cfg", ".", "elbo_weights", "=", "{", "\n", "'kl_latent'", ":", "args", ".", "kl_latent", ",", "\n", "'kl_spatial'", ":", "args", ".", "kl_spatial", ",", "\n", "'exp_attention'", ":", "args", ".", "exp_attention", ",", "\n", "'exp_nll'", ":", "args", ".", "exp_nll", ",", "\n", "'query_nll'", ":", "args", ".", "query_nll", "\n", "}", "\n", "# I/O path configurations", "\n", "cfg", ".", "DATA_ROOT", "=", "args", ".", "input_dir", "\n", "cfg", ".", "ckpt_base", "=", "args", ".", "output_dir", "\n", "\n", "###########################################", "\n", "# Config gpu usage", "\n", "###########################################", "\n", "cfg", ".", "nodes", "=", "args", ".", "nodes", "\n", "cfg", ".", "gpus", "=", "args", ".", "gpus", "\n", "cfg", ".", "nrank", "=", "args", ".", "nrank", "\n", "cfg", ".", "gpu_start", "=", "args", ".", "gpu_start", "\n", "cfg", ".", "world_size", "=", "args", ".", "gpus", "*", "args", ".", "nodes", "#", "\n", "\n", "running_cfg", "(", "cfg", ")", "\n", "\n", "# # save current config for later evaluation", "\n", "# utils.write_pickle(cfg, os.path.join(cfg.check_dir, 'config.obj'))", "\n", "\n", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "=", "'localhost'", "#", "\n", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "=", "args", ".", "master_port", "#", "\n", "mp", ".", "spawn", "(", "train", ",", "nprocs", "=", "cfg", ".", "gpus", ",", "args", "=", "(", "cfg", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.Encoder.__init__": [[64, 87], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "image_size", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "height", "=", "image_size", "[", "0", "]", "\n", "width", "=", "image_size", "[", "1", "]", "\n", "self", ".", "convs", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "input_dim", ",", "32", ",", "3", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "3", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "3", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "width", "=", "(", "width", "-", "1", ")", "//", "2", "\n", "height", "=", "(", "height", "-", "1", ")", "//", "2", "\n", "\n", "", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "64", "*", "width", "*", "height", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "output_dim", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.Encoder.forward": [[89, 93], ["modules.Encoder.convs", "x.view.view.view", "modules.Encoder.mlp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "convs", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "return", "self", ".", "mlp", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.SpatialBroadcastDec.__init__": [[97, 117], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "modules.SpatialBroadcastDec.register_buffer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "image_size", ",", "decoder", "=", "'sbd'", ")", ":", "\n", "        ", "super", "(", "SpatialBroadcastDec", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "height", "=", "image_size", "[", "0", "]", "\n", "self", ".", "width", "=", "image_size", "[", "1", "]", "\n", "self", ".", "convs", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "input_dim", "+", "2", ",", "32", ",", "3", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "3", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "3", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "3", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "output_dim", ",", "1", ")", ",", "\n", ")", "\n", "ys", "=", "torch", ".", "linspace", "(", "-", "1", ",", "1", ",", "self", ".", "height", "+", "8", ")", "\n", "xs", "=", "torch", ".", "linspace", "(", "-", "1", ",", "1", ",", "self", ".", "width", "+", "8", ")", "\n", "ys", ",", "xs", "=", "torch", ".", "meshgrid", "(", "ys", ",", "xs", ")", "\n", "coord_map", "=", "torch", ".", "stack", "(", "(", "ys", ",", "xs", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "register_buffer", "(", "'coord_map_const'", ",", "coord_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.SpatialBroadcastDec.forward": [[118, 124], ["z.unsqueeze().unsqueeze().repeat", "modules.SpatialBroadcastDec.coord_map_const.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modules.SpatialBroadcastDec.convs", "z.unsqueeze().unsqueeze", "z.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ")", ":", "\n", "        ", "z_tiled", "=", "z", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "height", "+", "8", ",", "self", ".", "width", "+", "8", ")", "\n", "coord_map", "=", "self", ".", "coord_map_const", ".", "repeat", "(", "z", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", ")", "\n", "inp", "=", "torch", ".", "cat", "(", "(", "z_tiled", ",", "coord_map", ")", ",", "1", ")", "\n", "result", "=", "self", ".", "convs", "(", "inp", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.RefineNetLSTM.__init__": [[131, 136], ["torch.Module.__init__", "modules.Encoder", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["def", "__init__", "(", "self", ",", "z_dim", ",", "channels_in", ",", "image_size", ")", ":", "\n", "        ", "super", "(", "RefineNetLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convnet", "=", "Encoder", "(", "channels_in", ",", "128", ",", "image_size", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTMCell", "(", "128", "+", "4", "*", "z_dim", ",", "128", ",", "bias", "=", "True", ")", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "128", ",", "2", "*", "z_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.RefineNetLSTM.forward": [[137, 143], ["modules.RefineNetLSTM.convnet", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modules.RefineNetLSTM.lstm", "modules.RefineNetLSTM.fc_out"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "h", ",", "c", ")", ":", "\n", "        ", "x_img", ",", "lmbda_moment", "=", "x", "[", "'img'", "]", ",", "x", "[", "'state'", "]", "\n", "conv_codes", "=", "self", ".", "convnet", "(", "x_img", ")", "\n", "lstm_input", "=", "torch", ".", "cat", "(", "(", "lmbda_moment", ",", "conv_codes", ")", ",", "dim", "=", "1", ")", "\n", "h", ",", "c", "=", "self", ".", "lstm", "(", "lstm_input", ",", "(", "h", ",", "c", ")", ")", "\n", "return", "self", ".", "fc_out", "(", "h", ")", ",", "h", ",", "c", "", "", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.to_sigma": [[9, 12], ["torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["def", "to_sigma", "(", "logvar", ")", ":", "\n", "    ", "\"\"\" Compute std \"\"\"", "\n", "return", "torch", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.layernorm": [[14, 33], ["len", "x.mean", "x.std", "x.size", "len", "mean", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "x.size", "x.mean().mean().mean", "mean", "x.mean().mean", "x.mean"], "function", ["None"], ["", "def", "layernorm", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    :param x: (B, K, L) or (B, K, C, H, W)\n    (function adapted from: https://github.com/MichaelKevinKelly/IODINE)\n    \"\"\"", "\n", "if", "len", "(", "x", ".", "size", "(", ")", ")", "==", "3", ":", "\n", "        ", "layer_mean", "=", "x", ".", "mean", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "layer_std", "=", "x", ".", "std", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "", "elif", "len", "(", "x", ".", "size", "(", ")", ")", "==", "5", ":", "\n", "        ", "mean", "=", "lambda", "x", ":", "x", ".", "mean", "(", "2", ",", "keepdim", "=", "True", ")", ".", "mean", "(", "3", ",", "keepdim", "=", "True", ")", ".", "mean", "(", "4", ",", "keepdim", "=", "True", ")", "\n", "layer_mean", "=", "mean", "(", "x", ")", "\n", "# this is not implemented in some version of torch", "\n", "layer_std", "=", "torch", ".", "pow", "(", "x", "-", "layer_mean", ",", "2", ")", "\n", "layer_std", "=", "torch", ".", "sqrt", "(", "mean", "(", "layer_std", ")", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "'invalid size for layernorm'", "\n", "\n", "", "x", "=", "(", "x", "-", "layer_mean", ")", "/", "(", "layer_std", "+", "1e-5", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.kl_exponential": [[35, 46], ["torch.Normal", "torch.Normal", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "dist.Normal.rsample", "dist.Normal.log_prob", "dist.Normal.log_prob"], "function", ["None"], ["", "def", "kl_exponential", "(", "post_mu", ",", "post_sigma", ",", "z_samples", "=", "None", ",", "pri_mu", "=", "None", ",", "pri_sigma", "=", "None", ")", ":", "\n", "    ", "\"\"\"Support Gaussian only now\"\"\"", "\n", "if", "pri_mu", "is", "None", ":", "\n", "        ", "pri_mu", "=", "torch", ".", "zeros_like", "(", "post_mu", ",", "device", "=", "post_mu", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "", "if", "pri_sigma", "is", "None", ":", "\n", "        ", "pri_sigma", "=", "torch", ".", "ones_like", "(", "post_sigma", ",", "device", "=", "post_sigma", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "", "p_post", "=", "dist", ".", "Normal", "(", "post_mu", ",", "post_sigma", ")", "\n", "if", "z_samples", "is", "None", ":", "\n", "        ", "z_samples", "=", "p_post", ".", "rsample", "(", ")", "\n", "", "p_pri", "=", "dist", ".", "Normal", "(", "pri_mu", ",", "pri_sigma", ")", "\n", "return", "p_post", ".", "log_prob", "(", "z_samples", ")", "-", "p_pri", ".", "log_prob", "(", "z_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.Gaussian_ll": [[48, 61], ["x_col.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "std_t.expand().unsqueeze().unsqueeze().unsqueeze.expand().unsqueeze().unsqueeze().unsqueeze", "torch.Normal().log_prob", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp.min().item", "std_t.expand().unsqueeze().unsqueeze().unsqueeze.expand().unsqueeze().unsqueeze", "torch.Normal", "torch.logsumexp.min", "std_t.expand().unsqueeze().unsqueeze().unsqueeze.expand().unsqueeze", "std_t.expand().unsqueeze().unsqueeze().unsqueeze.expand"], "function", ["None"], ["", "def", "Gaussian_ll", "(", "x_col", ",", "_x", ",", "masks", ",", "std", ")", ":", "\n", "    ", "\"\"\"\n    x_col: [B,K,C,H,W]\n    _x:    [B,K,3,H,W]\n    masks:   [B,K,1,H,W]\n    \"\"\"", "\n", "B", ",", "K", ",", "_", ",", "_", ",", "_", "=", "x_col", ".", "size", "(", ")", "\n", "std_t", "=", "torch", ".", "tensor", "(", "[", "std", "]", "*", "K", ",", "device", "=", "x_col", ".", "device", ",", "dtype", "=", "x_col", ".", "dtype", ",", "requires_grad", "=", "False", ")", "\n", "std_t", "=", "std_t", ".", "expand", "(", "1", ",", "K", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "log_pxz", "=", "dist", ".", "Normal", "(", "x_col", ",", "std_t", ")", ".", "log_prob", "(", "_x", ")", "\n", "ll_pix", "=", "torch", ".", "logsumexp", "(", "(", "masks", "+", "1e-6", ")", ".", "log", "(", ")", "+", "log_pxz", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# [B,K,3,H,W]", "\n", "assert", "ll_pix", ".", "min", "(", ")", ".", "item", "(", ")", ">", "-", "math", ".", "inf", "\n", "return", "ll_pix", ",", "log_pxz", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.__init__": [[19, 50], ["torch.Module.__init__", "SpatialBroadcastDec", "RefineNetLSTM", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "name", "=", "'MulMON'", ")", ":", "\n", "        ", "super", "(", "MulMON", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "training", "=", "True", "if", "self", ".", "config", ".", "WORK_MODE", "==", "'training'", "else", "False", "\n", "self", ".", "nit_innerloop", "=", "5", "# num_iterations of the inner loop", "\n", "self", ".", "K", "=", "self", ".", "config", ".", "num_slots", "\n", "self", ".", "v_in_dim", "=", "self", ".", "config", ".", "v_in_dim", "\n", "self", ".", "z_dim", "=", "self", ".", "config", ".", "latent_dim", "\n", "self", ".", "v_dim", "=", "self", ".", "config", ".", "view_dim", "\n", "# self.v_dim = self.z_dim", "\n", "self", ".", "std", "=", "self", ".", "config", ".", "pixel_sigma", "\n", "self", ".", "min_num_views", "=", "self", ".", "config", ".", "min_sample_views", "\n", "self", ".", "max_num_views", "=", "self", ".", "config", ".", "max_sample_views", "\n", "self", ".", "num_vq_show", "=", "self", ".", "config", ".", "num_vq_show", "\n", "self", ".", "decoder", "=", "SpatialBroadcastDec", "(", "self", ".", "z_dim", ",", "4", ",", "self", ".", "config", ".", "image_size", ")", "\n", "# One could use v^t as an input to the refinement function too (s.t. comply with the math presented on the paper).", "\n", "self", ".", "refine_net", "=", "RefineNetLSTM", "(", "self", ".", "z_dim", ",", "channels_in", "=", "17", ",", "image_size", "=", "self", ".", "config", ".", "image_size", ")", "\n", "self", ".", "view_encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "v_in_dim", ",", "128", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "self", ".", "v_dim", ",", "bias", "=", "True", ")", "\n", ")", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "z_dim", "+", "self", ".", "v_dim", ",", "512", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "self", ".", "z_dim", ",", "bias", "=", "True", ")", "\n", ")", "\n", "self", ".", "lmbda0", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "2", "*", "self", ".", "z_dim", ")", "-", "0.5", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.save_visuals": [[51, 86], ["range", "range", "visualisation.save_images_grid", "print", "vis_images[].transpose", "ST.append", "vis_recons[].transpose", "ST.append", "range", "numpy.argmax", "d_order.astype.astype.astype", "ST.append", "vis_comps[].transpose", "ST.append", "visualisation.save_dorder_plots", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_images_grid", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_dorder_plots"], ["", "@", "staticmethod", "\n", "def", "save_visuals", "(", "vis_images", ",", "vis_recons", ",", "vis_comps", ",", "vis_hiers", ",", "save_dir", ",", "start_id", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Used for visualising training procedure as well as the prediction of new input\n        :param vis_images: (a list of [B, V, 3, H, W] tensors) the given scene images for learning.\n        :param vis_recons: (a tensor [B, V, 3, H, W]) the reconstructed scene images.\n        :param vis_comps: (a tensor [B, V, K, 3, H, W]) the generated scene-component appearances.\n        :param vis_hiers: (a tensor [B, V, K, 1, H, W]) the occlusion hierarchy (visibility), i.e. mixing coefficients.\n        :param save_dir: (optional) if specified, then the generate sample images will be saved in the very dir.\n        :param start_id: (optional) global indicator of filenames, useful to save multiple batches.\n        \"\"\"", "\n", "B", ",", "V", ",", "K", ",", "_", ",", "H", ",", "W", "=", "vis_comps", ".", "shape", "\n", "for", "count", "in", "range", "(", "B", ")", ":", "\n", "            ", "ST", "=", "[", "]", "\n", "for", "v", "in", "range", "(", "V", ")", ":", "\n", "# save the queried target images", "\n", "                ", "img", "=", "vis_images", "[", "count", ",", "v", ",", "...", "]", ".", "transpose", "(", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "ST", ".", "append", "(", "img", ")", "\n", "\n", "# save the reconstructed image", "\n", "rec", "=", "vis_recons", "[", "count", ",", "v", ",", "...", "]", ".", "transpose", "(", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "ST", ".", "append", "(", "rec", ")", "\n", "\n", "# save and check components", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "                    ", "c_app", "=", "vis_comps", "[", "count", ",", "v", ",", "k", ",", "...", "]", ".", "transpose", "(", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "ST", ".", "append", "(", "c_app", ")", "\n", "\n", "# save the hierarchy as depth-order maps", "\n", "", "d_order", "=", "np", ".", "argmax", "(", "vis_hiers", "[", "count", ",", "v", ",", "...", "]", ",", "axis", "=", "0", ")", "\n", "d_order", "=", "d_order", ".", "astype", "(", "'uint8'", ")", "\n", "ST", ".", "append", "(", "vis", ".", "save_dorder_plots", "(", "d_order", ",", "K_comps", "=", "K", ")", ")", "\n", "", "vis", ".", "save_images_grid", "(", "ST", ",", "nrows", "=", "3", "+", "K", ",", "ncols", "=", "V", ",", "fig_size", "=", "8", ",", "\n", "save_to", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'{:06d}.png'", ".", "format", "(", "count", "+", "start_id", ")", ")", ")", "\n", "print", "(", "\" -- {} generated scene samples have been saved\"", ".", "format", "(", "count", "+", "start_id", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.save_visuals_eval": [[87, 114], ["range", "range", "print", "visualisation.save_single_image", "visualisation.save_single_image", "range", "numpy.argmax().astype", "visualisation.save_dorder_plots", "visualisation.save_single_image", "vis_images[].transpose", "os.path.join", "vis_recons[].transpose", "os.path.join", "visualisation.save_single_image", "os.path.join", "vis_comps[].transpose", "os.path.join", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_single_image", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_single_image", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_dorder_plots", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_single_image", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_single_image"], ["", "", "@", "staticmethod", "\n", "def", "save_visuals_eval", "(", "num_obs_views", ",", "vis_images", ",", "vis_recons", ",", "vis_comps", ",", "vis_hiers", ",", "save_dir", ",", "start_id", "=", "0", ")", ":", "\n", "        ", "B", ",", "V", ",", "K", ",", "_", ",", "H", ",", "W", "=", "vis_comps", ".", "shape", "\n", "for", "b", "in", "range", "(", "B", ")", ":", "\n", "            ", "prefix", "=", "'obs'", "\n", "for", "v", "in", "range", "(", "V", ")", ":", "\n", "                ", "if", "v", ">=", "num_obs_views", ":", "\n", "                    ", "prefix", "=", "'qry'", "\n", "\n", "# --- save the observed --- #", "\n", "", "vis", ".", "save_single_image", "(", "vis_images", "[", "b", ",", "v", ",", "...", "]", ".", "transpose", "(", "[", "1", ",", "2", ",", "0", "]", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'{}_{}{}_alpha.png'", ".", "format", "(", "start_id", "+", "b", ",", "prefix", ",", "v", ")", ")", ")", "\n", "\n", "# --- save the generated ---#", "\n", "vis", ".", "save_single_image", "(", "vis_recons", "[", "b", ",", "v", ",", "...", "]", ".", "transpose", "(", "[", "1", ",", "2", ",", "0", "]", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'{}_{}{}_beta.png'", ".", "format", "(", "start_id", "+", "b", ",", "prefix", ",", "v", ")", ")", ")", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "                    ", "vis", ".", "save_single_image", "(", "vis_comps", "[", "b", ",", "v", ",", "k", ",", "...", "]", ".", "transpose", "(", "[", "1", ",", "2", ",", "0", "]", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'{}_{}{}_c{}.png'", ".", "format", "(", "start_id", "+", "b", ",", "prefix", ",", "v", ",", "k", ")", ")", ")", "\n", "\n", "# --- save the spatial reasoning --- #", "\n", "# hiers: [B, V, K, H, W]", "\n", "", "seg", "=", "np", ".", "argmax", "(", "vis_hiers", "[", "b", ",", "v", ",", "...", "]", ",", "axis", "=", "0", ")", ".", "astype", "(", "'uint8'", ")", "\n", "vis_seg", "=", "vis", ".", "save_dorder_plots", "(", "seg", ",", "K_comps", "=", "K", ")", "\n", "vis", ".", "save_single_image", "(", "vis_seg", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'{}_{}{}_seg.png'", ".", "format", "(", "start_id", "+", "b", ",", "prefix", ",", "v", ")", ")", ")", "\n", "", "print", "(", "\" -- {} generated scene samples have been saved\"", ".", "format", "(", "b", "+", "start_id", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.sample_view_config": [[115, 143], ["random.shuffle", "random.randint", "random.sample", "range"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "sample_view_config", "(", "num_views", ",", "min_limit", "=", "5", ",", "max_limit", "=", "7", ",", "allow_repeat", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Select the views the scenes are observed from, also generate viewpoints for the querying\n        :param num_views: (default depends on the data, e.g. 10) how many viewpoints are available, or reachable for the\n                            agents\n        :param min_limit: minimum number of observations one agent needs\n        :param max_limit: maximum number of observations the agent are provided\n        :param allow_repeat: allow repeated viewpoints to be sampled\n        :return: observation_view_id_list, querying_view_id_list\n        \"\"\"", "\n", "assert", "max_limit", "<=", "num_views", "\n", "FULL_HOUSE", "=", "[", "*", "range", "(", "num_views", ")", "]", "\n", "# randomise the order of views", "\n", "random", ".", "shuffle", "(", "FULL_HOUSE", ")", "\n", "# randomise the number of the given observations", "\n", "L", "=", "random", ".", "randint", "(", "min_limit", ",", "max_limit", ")", "\n", "\n", "if", "L", "==", "num_views", ":", "\n", "            ", "return", "FULL_HOUSE", ",", "FULL_HOUSE", "\n", "\n", "# random partition of the observation views and query views", "\n", "", "observation_view_id_list", "=", "FULL_HOUSE", "[", ":", "L", "]", "\n", "if", "allow_repeat", ":", "\n", "            ", "querying_view_id_list", "=", "random", ".", "sample", "(", "FULL_HOUSE", ",", "num_views", "-", "L", ")", "\n", "", "else", ":", "\n", "            ", "querying_view_id_list", "=", "FULL_HOUSE", "[", "L", ":", "]", "\n", "", "return", "observation_view_id_list", ",", "querying_view_id_list", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.get_refine_inputs": [[144, 198], ["ll_pxl.sum().exp().repeat", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "ll_col.sum().exp", "layernorm().detach", "layernorm().detach", "layernorm().detach", "layernorm().detach", "layernorm().detach", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "coords[].repeat().detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "img_inp.view.view.view", "ll_col.sum", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "ll_pxl.sum().exp", "ll_col.sum", "layernorm", "layernorm", "layernorm", "layernorm", "layernorm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "coords[].repeat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat().squeeze.split", "torch.cat().squeeze.split", "torch.cat().squeeze.split", "ll_pxl.sum", "dlmbda.chunk"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.layernorm", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.layernorm", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.layernorm", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.layernorm", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.layernorm"], ["", "def", "get_refine_inputs", "(", "self", ",", "_x", ",", "mu_x", ",", "masks", ",", "mask_logits", ",", "ll_pxl", ",", "lmbda", ",", "loss", ",", "ll_col", ")", ":", "\n", "        ", "\"\"\"\n        Generate inputs to refinement network\n        (adapted from: https://github.com/MichaelKevinKelly/IODINE)\n        \"\"\"", "\n", "N", ",", "K", ",", "C", ",", "H", ",", "W", "=", "mu_x", ".", "shape", "\n", "\n", "# Calculate additional non-gradient inputs", "\n", "# ll_pxl is the mixture log-likelihood [N, 1, 3, H, W]", "\n", "# ll_col is the color gaussian ll, not account for masks [N, K, 3, H, W]", "\n", "x_lik", "=", "ll_pxl", ".", "sum", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", ".", "exp", "(", ")", ".", "repeat", "(", "1", ",", "K", ",", "1", ",", "1", ",", "1", ")", "# [N, K, 1, H, W]", "\n", "col_lik", "=", "torch", ".", "softmax", "(", "ll_col", ".", "sum", "(", "2", ",", "keepdim", "=", "True", ")", ",", "dim", "=", "1", ")", "# (N,K,1,H,W)", "\n", "\n", "# This computation is a little weird. Basically we do not count one of the slot.", "\n", "K_likelihood", "=", "ll_col", ".", "sum", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", ".", "exp", "(", ")", "# (B, K, 1, H, W)", "\n", "# likelihood = (B, 1, 1, H, W), self.mask (B, K, 1, H, W)", "\n", "likelihood", "=", "(", "masks", "*", "K_likelihood", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# (B, 1, 1, H, W)", "\n", "# leave_one_out (B, K, 1, H, W)", "\n", "leave_one_out", "=", "likelihood", "-", "masks", "*", "K_likelihood", "\n", "# normalize", "\n", "leave_one_out", "=", "leave_one_out", "/", "(", "1", "-", "masks", "+", "1e-5", ")", "\n", "\n", "# Calculate gradient inputs", "\n", "dmu_x", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "mu_x", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "## (N,K,C,H,W)", "\n", "dmasks", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "masks", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "## (N,K,1,H,W)", "\n", "dlmbda", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "lmbda", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "## (N*K,2*z_dim)", "\n", "\n", "# Layer norm -- stablises trainings", "\n", "x_lik_stable", "=", "layernorm", "(", "x_lik", ")", ".", "detach", "(", ")", "\n", "leave_one_out_stable", "=", "layernorm", "(", "leave_one_out", ")", ".", "detach", "(", ")", "\n", "dmu_x_stable", "=", "layernorm", "(", "dmu_x", ")", ".", "detach", "(", ")", "\n", "dmasks_stable", "=", "layernorm", "(", "dmasks", ")", ".", "detach", "(", ")", "\n", "dlmbda_stable", "=", "layernorm", "(", "torch", ".", "stack", "(", "dlmbda", ".", "chunk", "(", "N", ",", "0", ")", ",", "0", ")", ")", ".", "detach", "(", ")", "\n", "dlmbda_stable", "=", "torch", ".", "cat", "(", "dlmbda_stable", ".", "split", "(", "1", ",", "dim", "=", "0", ")", ",", "dim", "=", "1", ")", ".", "squeeze", "(", "0", ")", "\n", "\n", "# Generate coordinate channels", "\n", "xx", "=", "torch", ".", "linspace", "(", "-", "1", ",", "1", ",", "W", ",", "device", "=", "_x", ".", "device", ")", "\n", "yy", "=", "torch", ".", "linspace", "(", "-", "1", ",", "1", ",", "H", ",", "device", "=", "_x", ".", "device", ")", "\n", "yy", ",", "xx", "=", "torch", ".", "meshgrid", "(", "(", "yy", ",", "xx", ")", ")", "\n", "# (2, H, W)", "\n", "coords", "=", "torch", ".", "stack", "(", "(", "xx", ",", "yy", ")", ",", "dim", "=", "0", ")", "\n", "coords", "=", "coords", "[", "None", ",", "None", "]", ".", "repeat", "(", "N", ",", "self", ".", "K", ",", "1", ",", "1", ",", "1", ")", ".", "detach", "(", ")", "\n", "\n", "# Concatenate into vec and mat inputs", "\n", "img_args", "=", "(", "_x", ",", "mu_x", ",", "masks", ",", "mask_logits", ",", "dmu_x_stable", ",", "dmasks_stable", ",", "\n", "col_lik", ",", "x_lik_stable", ",", "leave_one_out_stable", ",", "coords", ")", "\n", "state_args", "=", "(", "lmbda", ",", "dlmbda_stable", ")", "\n", "img_inp", "=", "torch", ".", "cat", "(", "img_args", ",", "dim", "=", "2", ")", "\n", "state_inp", "=", "torch", ".", "cat", "(", "state_args", ",", "dim", "=", "1", ")", "\n", "\n", "# Reshape", "\n", "img_inp", "=", "img_inp", ".", "view", "(", "(", "N", "*", "K", ",", ")", "+", "img_inp", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n", "return", "{", "'img'", ":", "img_inp", ",", "'state'", ":", "state_inp", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.decode": [[199, 208], ["mulmon.MulMON.decoder", "mask_logits.reshape.reshape.reshape", "mu_x.reshape.reshape.reshape", "z.size"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "z", ")", ":", "\n", "        ", "K", "=", "self", ".", "K", "\n", "B", "=", "z", ".", "size", "(", "0", ")", "//", "K", "\n", "# Get means and masks", "\n", "dec_out", "=", "self", ".", "decoder", "(", "z", ")", "# (B*K,4,H,W) where 4= 3(RGB) + 1(alpha)", "\n", "mu_x", ",", "mask_logits", "=", "dec_out", "[", ":", ",", ":", "3", ",", ":", ",", ":", "]", ",", "dec_out", "[", ":", ",", "3", ":", ",", ":", ",", ":", "]", "\n", "mask_logits", "=", "mask_logits", ".", "reshape", "(", "(", "B", ",", "K", ",", ")", "+", "mask_logits", ".", "shape", "[", "1", ":", "]", ")", "\n", "mu_x", "=", "mu_x", ".", "reshape", "(", "(", "B", ",", "K", ",", ")", "+", "mu_x", ".", "shape", "[", "1", ":", "]", ")", "\n", "return", "mask_logits", ",", "mu_x", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON._iterative_inference": [[209, 268], ["x.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "lmbda.chunk", "range", "lmbda.chunk", "torch.Normal().rsample", "torch.Normal().rsample", "torch.Normal().rsample", "kl_exponential", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "mulmon.MulMON.projector", "mulmon.MulMON.decode", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "x.unsqueeze().repeat", "Gaussian_ll", "mulmon.MulMON.get_refine_inputs", "mulmon.MulMON.refine_net", "torch.zeros.max().item", "torch.zeros.max().item", "torch.zeros.max().item", "torch.zeros.min().item", "torch.zeros.min().item", "torch.zeros.min().item", "to_sigma", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.Normal", "torch.Normal", "torch.Normal", "to_sigma", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.unsqueeze", "ll_pxl.flatten().sum().mean", "torch.stack().sum.mean", "torch.stack().sum.mean", "torch.stack().sum.mean", "torch.zeros.max", "torch.zeros.max", "torch.zeros.max", "torch.zeros.min", "torch.zeros.min", "torch.zeros.min", "to_sigma", "torch.stack().sum.chunk", "torch.stack().sum.chunk", "torch.stack().sum.chunk", "y.reshape", "float", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "ll_pxl.flatten().sum", "float", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "ll_pxl.flatten"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.kl_exponential", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.decode", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.Gaussian_ll", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.get_refine_inputs", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.to_sigma", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.to_sigma", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.to_sigma"], ["", "def", "_iterative_inference", "(", "self", ",", "x", ",", "y", ",", "lmbda", ",", "niter", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        :param x: [B, 3, H, W]\n        :param lmbda:  [B*K, 2*D]\n        \"\"\"", "\n", "B", ",", "C", ",", "_", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "K", "=", "self", ".", "K", "\n", "total_loss", "=", "0.", "\n", "\n", "# Initialize LSTMCell hidden states", "\n", "h", "=", "torch", ".", "zeros", "(", "B", "*", "K", ",", "128", ",", "device", "=", "x", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "c", "=", "torch", ".", "zeros_like", "(", "h", ",", "device", "=", "x", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "assert", "h", ".", "max", "(", ")", ".", "item", "(", ")", "==", "0.", "and", "h", ".", "min", "(", ")", ".", "item", "(", ")", "==", "0.", "\n", "mu_pri", ",", "logvar_pri", "=", "lmbda", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "\n", "balancing_discount", "=", "1.0", "/", "(", "0.5", "*", "(", "niter", "+", "1.0", ")", ")", "\n", "for", "it", "in", "range", "(", "niter", ")", ":", "\n", "# Sample latent code", "\n", "            ", "mu_z", ",", "logvar_z", "=", "lmbda", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "z", "=", "dist", ".", "Normal", "(", "mu_z", ",", "to_sigma", "(", "logvar_z", ")", ")", ".", "rsample", "(", ")", "# (N*K,z_dim)", "\n", "\n", "# Computes the IG term here. Note that we found taking out the viewpoint condition from the IG term that is presented on ", "\n", "# the paper and leave out v^t in inference gives better (?) results. In that case, the IG term here wouldn't be conditioning", "\n", "# on v^t anymore---IG(z^t, x^t; z^(t-1)) ~= DKL[ q_(z^t| x^t, z^(t-1)) || q_(z^(t-1)| x^(t-1), z^(t-2)) ].", "\n", "kl_qz", "=", "kl_exponential", "(", "mu_z", ",", "to_sigma", "(", "logvar_z", ")", ",", "\n", "pri_mu", "=", "mu_pri", ",", "pri_sigma", "=", "to_sigma", "(", "logvar_pri", ")", ",", "z_samples", "=", "z", ")", "\n", "kl_qz", "=", "torch", ".", "stack", "(", "kl_qz", ".", "chunk", "(", "B", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", ".", "sum", "(", "dim", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "# Obtain view-conditioned scene representations", "\n", "z_y", "=", "self", ".", "projector", "(", "torch", ".", "cat", "(", "(", "z", ",", "y", ".", "reshape", "(", "B", "*", "K", ",", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "# Generate independent components (object 2d geometries + RGB values)", "\n", "mask_logits", ",", "mu_x", "=", "self", ".", "decode", "(", "z_y", ")", "\n", "\n", "# get the mixing coefficients (Categorical parameters)", "\n", "masks", "=", "torch", ".", "softmax", "(", "mask_logits", ",", "dim", "=", "1", ")", "# (N,K,1,H,W)", "\n", "\n", "# Compute the loss (neg ELBO): reconstruction (nll) & KL divergence", "\n", "_x", "=", "x", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "repeat", "(", "1", ",", "K", ",", "1", ",", "1", ",", "1", ")", "\n", "ll_pxl", ",", "ll_col", "=", "Gaussian_ll", "(", "mu_x", ",", "_x", ",", "masks", ",", "self", ".", "std", ")", "# (N,1,3,H,W)", "\n", "nll", "=", "-", "1.", "*", "(", "ll_pxl", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", ")", "*", "self", ".", "config", ".", "elbo_weights", "[", "'exp_nll'", "]", "\n", "loss", "=", "nll", "+", "kl_qz", ".", "mean", "(", ")", "*", "self", ".", "config", ".", "elbo_weights", "[", "'kl_latent'", "]", "\n", "\n", "# Accumulate loss", "\n", "total_loss", "=", "total_loss", "+", "loss", "*", "(", "(", "float", "(", "it", ")", "+", "1", ")", "/", "float", "(", "niter", ")", ")", "\n", "\n", "assert", "not", "torch", ".", "isnan", "(", "loss", ")", ".", "any", "(", ")", ".", "item", "(", ")", ",", "'Loss at t={} is nan. (nll,div): ({},{})'", ".", "format", "(", "nll", ",", "kl_qz", ")", "\n", "if", "it", "==", "niter", "-", "1", ":", "\n", "                ", "continue", "\n", "\n", "# Refine lambda", "\n", "", "refine_inp", "=", "self", ".", "get_refine_inputs", "(", "_x", ",", "mu_x", ",", "masks", ",", "mask_logits", ",", "ll_pxl", ",", "lmbda", ",", "loss", ",", "ll_col", ")", "\n", "delta", ",", "h", ",", "c", "=", "self", ".", "refine_net", "(", "refine_inp", ",", "h", ",", "c", ")", "\n", "assert", "not", "torch", ".", "isnan", "(", "lmbda", ")", ".", "any", "(", ")", ".", "item", "(", ")", ",", "'Lmbda at t={} has nan: {}'", ".", "format", "(", "it", ",", "lmbda", ")", "\n", "assert", "not", "torch", ".", "isnan", "(", "delta", ")", ".", "any", "(", ")", ".", "item", "(", ")", ",", "'Delta at t={} has nan: {}'", ".", "format", "(", "it", ",", "delta", ")", "\n", "lmbda", "=", "lmbda", "+", "delta", "\n", "assert", "not", "torch", ".", "isnan", "(", "lmbda", ")", ".", "any", "(", ")", ".", "item", "(", ")", ",", "'Lmbda at t={} has nan: {}'", ".", "format", "(", "it", ",", "lmbda", ")", "\n", "\n", "", "return", "balancing_discount", "*", "total_loss", ",", "lmbda", ",", "mask_logits", ",", "mu_x", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.sample_qz_uncertainty": [[269, 284], ["yq.size", "lmbda.chunk", "torch.Normal().rsample", "torch.Normal().rsample", "torch.Normal().rsample", "range", "numpy.stack().var().sum", "mulmon.MulMON.projector", "mulmon.MulMON.decode", "numpy.stack().var().sum.append", "torch.Normal", "torch.Normal", "torch.Normal", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "utils.numpify", "numpy.stack().var", "to_sigma", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "yq.reshape", "numpy.stack", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.decode", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.to_sigma"], ["", "def", "sample_qz_uncertainty", "(", "self", ",", "lmbda", ",", "yq", ")", ":", "\n", "        ", "\"\"\"image-space pixel-wise uncertainty estimation via MC sampling\"\"\"", "\n", "B", ",", "K", ",", "_", "=", "yq", ".", "size", "(", ")", "\n", "mu_z", ",", "logvar_z", "=", "lmbda", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "z", "=", "dist", ".", "Normal", "(", "mu_z", ",", "to_sigma", "(", "logvar_z", ")", ")", ".", "rsample", "(", "[", "self", ".", "config", ".", "num_mc_samples", "]", ")", "\n", "var_x", "=", "[", "]", "\n", "# var_obj = []", "\n", "for", "s", "in", "range", "(", "self", ".", "config", ".", "num_mc_samples", ")", ":", "\n", "            ", "z_yq", "=", "self", ".", "projector", "(", "torch", ".", "cat", "(", "(", "z", "[", "s", "]", ",", "yq", ".", "reshape", "(", "B", "*", "K", ",", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "mask_logits", ",", "mu_x", "=", "self", ".", "decode", "(", "z_yq", ")", "\n", "var_x", ".", "append", "(", "utils", ".", "numpify", "(", "torch", ".", "sum", "(", "torch", ".", "softmax", "(", "mask_logits", ",", "dim", "=", "1", ")", "*", "mu_x", ",", "dim", "=", "1", ")", ")", ")", "# [B, 3, H, w]", "\n", "# var_obj.append(utils.numpify(torch.sigmoid(mask_logits) * mu_x))  # [B, K, 3, H, w]", "\n", "", "var_x", "=", "np", ".", "stack", "(", "var_x", ",", "axis", "=", "0", ")", ".", "var", "(", "axis", "=", "0", ",", "ddof", "=", "1", ")", ".", "sum", "(", "1", ")", "\n", "# var_obj = np.stack(var_obj, axis=0).var(axis=0, ddof=1).sum(2)", "\n", "return", "var_x", ",", "None", "# var_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.forward": [[285, 347], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack.size", "torch.stack.size", "torch.stack.size", "mulmon.MulMON.sample_view_config", "mulmon.MulMON.lmbda0.expand", "mulmon.MulMON.view_encoder", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat", "enumerate", "enumerate", "attrdict.AttrDict", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.stack().type.reshape", "torch.stack().type.reshape", "torch.stack().type.reshape", "mulmon.MulMON._iterative_inference", "mulmon.MulMON.chunk", "torch.Normal().rsample", "torch.Normal().rsample", "torch.Normal().rsample", "mulmon.MulMON.projector", "mulmon.MulMON.decode", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "Gaussian_ll", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.unsqueeze().expand", "ll_pxl.flatten().sum().mean", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "len", "nelbo_v.mean", "torch.Normal", "torch.Normal", "torch.Normal", "nll.mean", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape", "float", "to_sigma", "yq.reshape", "x.unsqueeze", "ll_pxl.flatten().sum", "float", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "float", "len", "len", "ll_pxl.flatten"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.sample_view_config", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON._iterative_inference", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.decode", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.Gaussian_ll", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.to_sigma"], ["", "def", "forward", "(", "self", ",", "images", ",", "targets", ",", "std", "=", "None", ")", ":", "\n", "        ", "xmul", "=", "torch", ".", "stack", "(", "images", ",", "dim", "=", "0", ")", "# [B, V, C, H, W]", "\n", "v_pts", "=", "torch", ".", "stack", "(", "[", "tar", "[", "'view_points'", "]", "for", "tar", "in", "targets", "]", ",", "dim", "=", "0", ")", ".", "type", "(", "xmul", ".", "dtype", ")", "# [B, V, 3]", "\n", "# adding noise to viewpoint vectors helps to robustify the model:", "\n", "v_pts", "+=", "0.015", "*", "torch", ".", "randn_like", "(", "v_pts", ",", "dtype", "=", "xmul", ".", "dtype", ",", "device", "=", "xmul", ".", "device", ",", "requires_grad", "=", "False", ")", "\n", "\n", "B", ",", "V", ",", "_", ",", "_", ",", "_", "=", "xmul", ".", "size", "(", ")", "\n", "K", ",", "nit_inner_loop", ",", "z_dim", "=", "self", ".", "K", ",", "self", ".", "nit_innerloop", ",", "self", ".", "z_dim", "\n", "\n", "if", "std", ":", "\n", "            ", "self", ".", "std", "=", "std", "\n", "\n", "# Random partition of observation viewpoints and query viewpoints", "\n", "", "obs_view_idx", ",", "qry_view_idx", "=", "self", ".", "sample_view_config", "(", "V", ",", "self", ".", "min_num_views", ",", "self", ".", "max_num_views", ",", "\n", "allow_repeat", "=", "'gqn'", "in", "self", ".", "config", ".", "DATA_TYPE", ")", "\n", "\n", "# Initialize parameters for the latents' distribution", "\n", "assert", "not", "torch", ".", "isnan", "(", "self", ".", "lmbda0", ")", ".", "any", "(", ")", ".", "item", "(", ")", ",", "'lmbda0 has nan'", "\n", "lmbda", "=", "self", ".", "lmbda0", ".", "expand", "(", "(", "B", "*", "K", ",", ")", "+", "self", ".", "lmbda0", ".", "shape", "[", "1", ":", "]", ")", "\n", "neg_elbo", "=", "0.", "# torch.tensor(B, 1, device=xmul.device, requires_grad=True)", "\n", "xq_nll", "=", "0.", "# torch.zeros(B, 1, device=xmul.device, requires_grad=True)", "\n", "\n", "# --- get view codes ---", "\n", "v_feat", "=", "self", ".", "view_encoder", "(", "v_pts", ".", "reshape", "(", "B", "*", "V", ",", "-", "1", ")", ")", "# output [B*V, 8]", "\n", "v_feat", "=", "v_feat", ".", "reshape", "(", "B", ",", "V", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "K", ",", "1", ",", "1", ")", "\n", "\n", "# --- scene learning phase --- #", "\n", "discount_obs", "=", "1.0", "/", "(", "0.5", "*", "(", "len", "(", "obs_view_idx", ")", "+", "1.0", ")", ")", "\n", "# Outer loop: learning scenes from multiple views", "\n", "for", "venum", ",", "v", "in", "enumerate", "(", "obs_view_idx", ")", ":", "\n", "            ", "x", "=", "xmul", "[", ":", ",", "v", ",", "...", "]", "\n", "y", "=", "v_feat", "[", ":", ",", ":", ",", "v", ",", ":", "]", "\n", "\n", "# Inner loop: single-view scene learning in an iterative fashion", "\n", "nelbo_v", ",", "lmbda", ",", "_", ",", "_", "=", "self", ".", "_iterative_inference", "(", "x", ",", "y", ",", "lmbda", ",", "nit_inner_loop", ")", "\n", "neg_elbo", "=", "neg_elbo", "+", "nelbo_v", ".", "mean", "(", ")", "*", "(", "(", "float", "(", "venum", ")", "+", "1", ")", "/", "float", "(", "len", "(", "obs_view_idx", ")", ")", ")", "\n", "\n", "# --- scene querying phase --- #", "\n", "", "for", "vqnum", ",", "vq", "in", "enumerate", "(", "qry_view_idx", ")", ":", "\n", "            ", "x", "=", "xmul", "[", ":", ",", "vq", ",", "...", "]", "\n", "yq", "=", "v_feat", "[", ":", ",", ":", ",", "vq", ",", ":", "]", "\n", "\n", "# Sample 3D-informative object latents", "\n", "mu_z", ",", "logvar_z", "=", "lmbda", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "z", "=", "dist", ".", "Normal", "(", "mu_z", ",", "to_sigma", "(", "logvar_z", ")", ")", ".", "rsample", "(", ")", "\n", "\n", "# Project the 3D latents to 2D w.r.t", "\n", "z_yq", "=", "self", ".", "projector", "(", "torch", ".", "cat", "(", "(", "z", ",", "yq", ".", "reshape", "(", "B", "*", "K", ",", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "mask_logits", ",", "mu_x", "=", "self", ".", "decode", "(", "z_yq", ")", "\n", "# get masks", "\n", "masks", "=", "torch", ".", "softmax", "(", "mask_logits", ",", "dim", "=", "1", ")", "\n", "ll_pxl", ",", "_", "=", "Gaussian_ll", "(", "mu_x", ",", "x", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "expand", "(", "(", "B", ",", "K", ",", ")", "+", "x", ".", "shape", "[", "1", ":", "]", ")", ",", "\n", "masks", ",", "self", ".", "std", ")", "# (N,1,3,H,W)", "\n", "nll", "=", "-", "1.", "*", "(", "ll_pxl", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", ")", "\n", "\n", "xq_nll", "=", "xq_nll", "+", "nll", ".", "mean", "(", ")", "*", "(", "1.0", "/", "float", "(", "len", "(", "qry_view_idx", ")", ")", ")", "\n", "\n", "", "loss_dict", "=", "AttrDict", "(", ")", "\n", "loss_dict", "[", "'neg_elbo'", "]", "=", "neg_elbo", "*", "discount_obs", "\n", "loss_dict", "[", "'query_nll'", "]", "=", "xq_nll", "*", "self", ".", "config", ".", "elbo_weights", "[", "'query_nll'", "]", "\n", "return", "loss_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.predict": [[348, 461], ["torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack.size", "torch.stack.size", "torch.stack.size", "mulmon.MulMON.sample_view_config", "mulmon.MulMON.lmbda0.expand", "mulmon.MulMON.view_encoder", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat", "enumerate", "enumerate", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.squeeze", "numpy.stack", "numpy.stack", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.isnan().any().item", "torch.stack().type.reshape", "torch.stack().type.reshape", "torch.stack().type.reshape", "mulmon.MulMON._iterative_inference", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "numpy.stack.append", "numpy.stack.append", "numpy.stack.append", "numpy.squeeze.append", "len", "mulmon.MulMON.chunk", "torch.Normal().rsample", "torch.Normal().rsample", "torch.Normal().rsample", "mulmon.MulMON.projector", "mulmon.MulMON.decode", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "numpy.stack.append", "numpy.stack.append", "numpy.stack.append", "numpy.squeeze.append", "numpy.stack.append", "numpy.stack.append", "numpy.stack", "list", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape().unsqueeze", "utils.numpify", "utils.numpify", "utils.numpify", "utils.numpify", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "utils.numpify", "utils.numpify", "utils.numpify", "utils.numpify", "utils.numpify", "utils.numpify", "mulmon.MulMON.save_visuals", "mulmon.MulMON.save_visuals_eval", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Normal", "torch.Normal", "torch.Normal", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mulmon.MulMON.reshape", "mu_z.reshape", "len", "[].item", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape", "to_sigma", "yq.reshape", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.sample_view_config", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON._iterative_inference", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.decode", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.save_visuals", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.save_visuals_eval", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.to_sigma"], ["", "@", "torch", ".", "enable_grad", "(", ")", "\n", "def", "predict", "(", "self", ",", "images", ",", "targets", ",", "\n", "save_sample_to", "=", "None", ",", "\n", "save_start_id", "=", "0", ",", "\n", "vis_train", "=", "True", ",", "\n", "vis_uncertainty", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        We show uncertainty\n        \"\"\"", "\n", "xmul", "=", "torch", ".", "stack", "(", "images", ",", "dim", "=", "0", ")", "# [B, V, C, H, W]", "\n", "v_pts", "=", "torch", ".", "stack", "(", "[", "tar", "[", "'view_points'", "]", "for", "tar", "in", "targets", "]", ",", "dim", "=", "0", ")", ".", "type", "(", "xmul", ".", "dtype", ")", "# [B, V, 3]", "\n", "\n", "B", ",", "V", ",", "_", ",", "_", ",", "_", "=", "xmul", ".", "size", "(", ")", "\n", "K", ",", "nit_inner_loop", ",", "z_dim", "=", "self", ".", "K", ",", "self", ".", "nit_innerloop", ",", "self", ".", "z_dim", "\n", "\n", "# sample the number of observations and which observations", "\n", "obs_view_idx", ",", "qry_view_idx", "=", "self", ".", "sample_view_config", "(", "V", ",", "self", ".", "num_vq_show", ",", "self", ".", "num_vq_show", ",", "\n", "allow_repeat", "=", "False", ")", "\n", "\n", "# Initialize parameters for latents' distribution", "\n", "assert", "not", "torch", ".", "isnan", "(", "self", ".", "lmbda0", ")", ".", "any", "(", ")", ".", "item", "(", ")", ",", "'lmbda0 has nan'", "\n", "lmbda", "=", "self", ".", "lmbda0", ".", "expand", "(", "(", "B", "*", "K", ",", ")", "+", "self", ".", "lmbda0", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "# --- get view codes ---", "\n", "v_feat", "=", "self", ".", "view_encoder", "(", "v_pts", ".", "reshape", "(", "B", "*", "V", ",", "-", "1", ")", ")", "# output [B*V, 8]", "\n", "v_feat", "=", "v_feat", ".", "reshape", "(", "B", ",", "V", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "K", ",", "1", ",", "1", ")", "\n", "\n", "# --- record for visualisation --- #", "\n", "vis_images", "=", "[", "]", "\n", "vis_recons", "=", "[", "]", "\n", "vis_comps", "=", "[", "]", "\n", "vis_hiers", "=", "[", "]", "\n", "vis_2d_latents", "=", "[", "]", "\n", "vis_3d_latents", "=", "[", "]", "\n", "\n", "# --- scene learning phase --- #", "\n", "for", "venum", ",", "v", "in", "enumerate", "(", "obs_view_idx", ")", ":", "\n", "            ", "x", "=", "xmul", "[", ":", ",", "v", ",", "...", "]", "\n", "y", "=", "v_feat", "[", ":", ",", ":", ",", "v", ",", ":", "]", "\n", "\n", "# Knowledge summarize in an iterative fashion (does not have to be though: set T=1)", "\n", "nelbo_v", ",", "lmbda", ",", "m_logits", ",", "mu_x", "=", "self", ".", "_iterative_inference", "(", "x", ",", "y", ",", "lmbda", ",", "nit_inner_loop", ")", "\n", "masks", "=", "torch", ".", "softmax", "(", "m_logits", ",", "dim", "=", "1", ")", "\n", "\n", "# get independent object silhouette", "\n", "indi_masks", "=", "torch", ".", "sigmoid", "(", "m_logits", ")", "\n", "\n", "vis_images", ".", "append", "(", "utils", ".", "numpify", "(", "x", ")", ")", "\n", "vis_recons", ".", "append", "(", "utils", ".", "numpify", "(", "torch", ".", "sum", "(", "masks", "*", "mu_x", ",", "dim", "=", "1", ")", ")", ")", "\n", "vis_comps", ".", "append", "(", "utils", ".", "numpify", "(", "indi_masks", "*", "mu_x", ")", ")", "\n", "vis_hiers", ".", "append", "(", "utils", ".", "numpify", "(", "masks", ")", ")", "\n", "\n", "del", "mu_x", ",", "m_logits", ",", "masks", "\n", "\n", "# --- scene querying phase --- #", "\n", "", "assert", "len", "(", "qry_view_idx", ")", ">", "0", "\n", "for", "vqnum", ",", "vq", "in", "enumerate", "(", "qry_view_idx", ")", ":", "\n", "            ", "x", "=", "xmul", "[", ":", ",", "vq", ",", "...", "]", "\n", "yq", "=", "v_feat", "[", ":", ",", ":", ",", "vq", ",", ":", "]", "\n", "\n", "# making view-dependent generation", "\n", "mu_z", ",", "logvar_z", "=", "lmbda", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "z", "=", "dist", ".", "Normal", "(", "mu_z", ",", "to_sigma", "(", "logvar_z", ")", ")", ".", "rsample", "(", ")", "\n", "\n", "z_yq", "=", "self", ".", "projector", "(", "torch", ".", "cat", "(", "(", "z", ",", "yq", ".", "reshape", "(", "B", "*", "K", ",", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "mask_logits", ",", "mu_x", "=", "self", ".", "decode", "(", "z_yq", ")", "\n", "# get masks", "\n", "masks", "=", "torch", ".", "softmax", "(", "mask_logits", ",", "dim", "=", "1", ")", "\n", "\n", "# get independent object silhouette", "\n", "indi_masks", "=", "torch", ".", "sigmoid", "(", "mask_logits", ")", "\n", "# uncomment the below to binarize the silhouette with a tunable threshold (default: 0.5).", "\n", "# indi_masks = (indi_masks > 0.5).type(mu_x.dtype)", "\n", "\n", "vis_images", ".", "append", "(", "utils", ".", "numpify", "(", "x", ")", ")", "\n", "vis_recons", ".", "append", "(", "utils", ".", "numpify", "(", "torch", ".", "sum", "(", "masks", "*", "mu_x", ",", "dim", "=", "1", ")", ")", ")", "\n", "vis_comps", ".", "append", "(", "utils", ".", "numpify", "(", "indi_masks", "*", "mu_x", ")", ")", "\n", "vis_hiers", ".", "append", "(", "utils", ".", "numpify", "(", "masks", ")", ")", "\n", "vis_2d_latents", ".", "append", "(", "utils", ".", "numpify", "(", "z_yq", ".", "reshape", "(", "B", ",", "K", ",", "-", "1", ")", ")", ")", "\n", "vis_3d_latents", ".", "append", "(", "utils", ".", "numpify", "(", "mu_z", ".", "reshape", "(", "B", ",", "K", ",", "-", "1", ")", ")", ")", "\n", "\n", "del", "mu_x", ",", "mask_logits", ",", "masks", "\n", "\n", "", "vis_images", "=", "np", ".", "stack", "(", "vis_images", ",", "axis", "=", "1", ")", "# [B, V, 3, H, W]", "\n", "vis_recons", "=", "np", ".", "stack", "(", "vis_recons", ",", "axis", "=", "1", ")", "# [B, V, 3, H, W]", "\n", "vis_comps", "=", "np", ".", "stack", "(", "vis_comps", ",", "axis", "=", "1", ")", "# [B, V, K, 3, H, W]", "\n", "vis_hiers", "=", "np", ".", "squeeze", "(", "np", ".", "stack", "(", "vis_hiers", ",", "axis", "=", "1", ")", ",", "axis", "=", "3", ")", "# [B, V, K, H, W]", "\n", "vis_2d_latents", "=", "np", ".", "stack", "(", "vis_2d_latents", ",", "axis", "=", "1", ")", "# [B, qV, K, D]", "\n", "vis_3d_latents", "=", "np", ".", "stack", "(", "vis_3d_latents", ",", "axis", "=", "1", ")", "# [B, qV, K, D]", "\n", "\n", "if", "save_sample_to", "is", "not", "None", ":", "\n", "            ", "if", "vis_train", ":", "\n", "                ", "self", ".", "save_visuals", "(", "vis_images", ",", "vis_recons", ",", "vis_comps", ",", "vis_hiers", ",", "\n", "save_dir", "=", "save_sample_to", ",", "\n", "start_id", "=", "save_start_id", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "save_visuals_eval", "(", "len", "(", "obs_view_idx", ")", ",", "vis_images", ",", "vis_recons", ",", "vis_comps", ",", "vis_hiers", ",", "\n", "save_dir", "=", "save_sample_to", ",", "\n", "start_id", "=", "save_start_id", ")", "\n", "", "", "preds", "=", "{", "\n", "'x_images'", ":", "vis_images", ",", "\n", "'x_recon'", ":", "vis_recons", ",", "\n", "'x_comps'", ":", "vis_comps", ",", "\n", "'hiers'", ":", "vis_hiers", ",", "\n", "'lmbda'", ":", "lmbda", ",", "\n", "'2d_latents'", ":", "vis_2d_latents", ",", "\n", "'3d_latents'", ":", "vis_3d_latents", ",", "\n", "'scene_indices'", ":", "list", "(", "tar", "[", "'scn_id'", "]", "[", "0", "]", ".", "item", "(", ")", "for", "tar", "in", "targets", ")", ",", "\n", "'obs_views'", ":", "obs_view_idx", ",", "\n", "'query_views'", ":", "qry_view_idx", "\n", "}", "\n", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.v_travel": [[462, 527], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "os.path.join", "utils.ensure_dir", "v_pts.size", "lmbda.chunk", "torch.Normal().rsample", "torch.Normal().rsample", "torch.Normal().rsample", "mulmon.MulMON.view_encoder", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat", "range", "GIFs.keys", "range", "lmbda.size", "v_pts.reshape", "mulmon.MulMON.projector", "mulmon.MulMON.decode", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mulmon.MulMON.sample_qz_uncertainty", "GIFs[].append", "GIFs[].append", "GIFs[].append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "os.path.join", "utils.ensure_dir", "GIFs.keys", "torch.Normal", "torch.Normal", "torch.Normal", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax.squeeze", "torch.softmax.squeeze", "torch.softmax.squeeze", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "str", "range", "visualisation.grid2gif", "to_sigma", "str", "str", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape", "yq.reshape", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "visualisation.enhance_save_single_image", "os.path.join", "os.path.join", "utils.numpify", "os.path.join", "numpy.argmax().astype", "visualisation.save_dorder_plots", "visualisation.save_single_image", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "[].cpu().permute", "os.path.join", "numpy.log10", "visualisation.map_val_colors", "visualisation.save_single_image", "numpy.argmax", "os.path.join", "[].cpu", "utils.numpify", "utils.numpify", "[].cpu", "[].cpu"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.decode", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.sample_qz_uncertainty", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.grid2gif", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.modules.to_sigma", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.enhance_save_single_image", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_dorder_plots", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_single_image", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.map_val_colors", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.save_single_image", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.numpify"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "v_travel", "(", "self", ",", "lmbda", ",", "v_pts", ",", "save_sample_to", "=", "None", ",", "save_start_id", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Viewpoint queired predictions along a viewpoint trajectory.\n\n        :param z: [B*K, D]\n        :param v_pts: [B, L, dview]   (a viewpoint trajectory)\n        \"\"\"", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_sample_to", ",", "'v_track'", ")", "\n", "utils", ".", "ensure_dir", "(", "save_dir", ")", "\n", "B", ",", "L", ",", "_", "=", "v_pts", ".", "size", "(", ")", "\n", "K", "=", "lmbda", ".", "size", "(", "0", ")", "//", "B", "\n", "\n", "mu_z", ",", "logvar_z", "=", "lmbda", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "z", "=", "dist", ".", "Normal", "(", "mu_z", ",", "to_sigma", "(", "logvar_z", ")", ")", ".", "rsample", "(", ")", "\n", "\n", "v_feat", "=", "self", ".", "view_encoder", "(", "v_pts", ".", "reshape", "(", "B", "*", "L", ",", "-", "1", ")", ")", "# output [B*V, 8]", "\n", "v_feat", "=", "v_feat", ".", "reshape", "(", "B", ",", "L", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "K", ",", "1", ",", "1", ")", "\n", "\n", "GIFs", "=", "{", "\n", "'alpha'", ":", "[", "]", ",", "# RGB images", "\n", "'seg'", ":", "[", "]", ",", "# Segmentation", "\n", "'uncer'", ":", "[", "]", "# Unvertainty (pixel-wise space)", "\n", "}", "\n", "for", "l", "in", "range", "(", "L", ")", ":", "\n", "            ", "yq", "=", "v_feat", "[", ":", ",", ":", ",", "l", ",", ":", "]", "\n", "z_yq", "=", "self", ".", "projector", "(", "torch", ".", "cat", "(", "(", "z", ",", "yq", ".", "reshape", "(", "B", "*", "K", ",", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "mask_logits", ",", "mu_x", "=", "self", ".", "decode", "(", "z_yq", ")", "\n", "masks", "=", "torch", ".", "softmax", "(", "mask_logits", ",", "dim", "=", "1", ")", "\n", "x_hat", "=", "torch", ".", "sum", "(", "masks", "*", "mu_x", ",", "dim", "=", "1", ")", "\n", "uncer", ",", "_", "=", "self", ".", "sample_qz_uncertainty", "(", "lmbda", ",", "yq", ")", "\n", "GIFs", "[", "'alpha'", "]", ".", "append", "(", "x_hat", ")", "\n", "GIFs", "[", "'seg'", "]", ".", "append", "(", "masks", ".", "squeeze", "(", "2", ")", ")", "\n", "GIFs", "[", "'uncer'", "]", ".", "append", "(", "torch", ".", "from_numpy", "(", "uncer", ")", ".", "to", "(", "masks", ")", ".", "float", "(", ")", ")", "\n", "\n", "", "for", "key", "in", "GIFs", ".", "keys", "(", ")", ":", "\n", "            ", "GIFs", "[", "key", "]", "=", "torch", ".", "stack", "(", "GIFs", "[", "key", "]", ",", "dim", "=", "0", ")", "# [steps, B, #, C, H, W]", "\n", "\n", "", "for", "b", "in", "range", "(", "B", ")", ":", "\n", "            ", "save_batch_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "str", "(", "b", "+", "save_start_id", ")", ")", "\n", "utils", ".", "ensure_dir", "(", "save_batch_dir", ")", "\n", "for", "key", "in", "GIFs", ".", "keys", "(", ")", ":", "\n", "                ", "prefix", "=", "'{}{}'", ".", "format", "(", "b", "+", "save_start_id", ",", "key", ")", "\n", "for", "iid", "in", "range", "(", "L", ")", ":", "\n", "                    ", "if", "key", "==", "'alpha'", ":", "\n", "                        ", "vis", ".", "enhance_save_single_image", "(", "utils", ".", "numpify", "(", "GIFs", "[", "key", "]", "[", "iid", ",", "b", ",", "...", "]", ".", "cpu", "(", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "save_batch_dir", ",", "'{}_{:02d}.png'", ".", "format", "(", "prefix", ",", "iid", ")", ")", ")", "\n", "# save_image(tensor=GIFs[key][iid, b, ...].cpu(),", "\n", "#            filename=os.path.join(save_batch_dir, '{}_{:02d}.jpg'.format(prefix, iid)))", "\n", "", "elif", "key", "==", "'seg'", ":", "\n", "                        ", "seg", "=", "np", ".", "argmax", "(", "utils", ".", "numpify", "(", "GIFs", "[", "key", "]", "[", "iid", ",", "b", ",", "...", "]", ".", "cpu", "(", ")", ")", ",", "\n", "axis", "=", "0", ")", ".", "astype", "(", "'uint8'", ")", "\n", "seg", "=", "vis", ".", "save_dorder_plots", "(", "seg", ",", "K_comps", "=", "K", ",", "cmap", "=", "'hsv'", ")", "\n", "vis", ".", "save_single_image", "(", "seg", ",", "\n", "os", ".", "path", ".", "join", "(", "save_batch_dir", ",", "'{}_{:02d}.png'", ".", "format", "(", "prefix", ",", "iid", ")", ")", ")", "\n", "", "elif", "key", "==", "'uncer'", ":", "\n", "                        ", "vis_var", "=", "np", ".", "log10", "(", "utils", ".", "numpify", "(", "GIFs", "[", "key", "]", "[", "iid", ",", "b", ",", "...", "]", ".", "cpu", "(", ")", ")", "+", "1e-6", ")", "\n", "vis_var", "=", "vis", ".", "map_val_colors", "(", "vis_var", ",", "\n", "v_min", "=", "-", "6.", ",", "v_max", "=", "-", "2.", ",", "cmap", "=", "'hot'", ")", "\n", "vis", ".", "save_single_image", "(", "vis_var", ",", "\n", "os", ".", "path", ".", "join", "(", "save_batch_dir", ",", "'{}_{:02d}.png'", ".", "format", "(", "prefix", ",", "iid", ")", ")", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "", "", "vis", ".", "grid2gif", "(", "str", "(", "os", ".", "path", ".", "join", "(", "save_batch_dir", ",", "prefix", "+", "'*.png'", ")", ")", ",", "\n", "str", "(", "os", ".", "path", ".", "join", "(", "save_batch_dir", ",", "'{}.gif'", ".", "format", "(", "prefix", ")", ")", ")", ",", "delay", "=", "20", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.z_travel": [[528, 586], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "os.path.join", "utils.ensure_dir", "z3d.size", "v_pts.size", "mulmon.MulMON.view_encoder", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat", "tuple", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gifs.reshape().permute.reshape().permute.reshape().permute", "range", "v_pts.reshape", "os.path.join", "utils.ensure_dir", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "range", "visualisation.grid2gif", "print", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape().unsqueeze", "z3d.clone", "range", "gifs.reshape().permute.reshape().permute.reshape", "str", "len", "visualisation.torch_save_image_enhanced", "str", "str", "mulmon.MulMON.projector", "mulmon.MulMON.decode", "gifs.reshape().permute.reshape().permute.append", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "os.path.join", "os.path.join", "v_feat.reshape().unsqueeze().repeat.reshape().unsqueeze().repeat.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().squeeze.chunk", "torch.cat().squeeze.chunk", "torch.cat().squeeze.chunk", "b_gifs[].cpu", "os.path.join", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "z3d.clone.reshape", "yq.reshape", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.ensure_dir", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.grid2gif", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.visualisation.torch_save_image_enhanced", "home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.decode"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "z_travel", "(", "self", ",", "z3d", ",", "v_pts", ",", "limit", "=", "3.0", ",", "int_step_size", "=", "0.66", ",", "save_sample_to", "=", "None", ",", "save_start_id", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Traverse latent space to visualise the learnt reps.\n\n        :param z3d:  [B, K, D]\n        :param v_pts:  [B, L, dView]\n        :param limit:  numerical bounds for traverse\n        :param int_step_size:  traverse step size (interpolation gap between traverse points)\n        :param save_dir:  save the output to this dir\n        :param start_id:  save the output as file\n        \"\"\"", "\n", "from", "torchvision", ".", "utils", "import", "save_image", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_sample_to", ",", "'disen_3d'", ")", "\n", "utils", ".", "ensure_dir", "(", "save_dir", ")", "\n", "B", ",", "K", ",", "D", "=", "z3d", ".", "size", "(", ")", "\n", "V", "=", "v_pts", ".", "size", "(", "1", ")", "\n", "\n", "v_feat", "=", "self", ".", "view_encoder", "(", "v_pts", ".", "reshape", "(", "B", "*", "V", ",", "-", "1", ")", ")", "# output [B*V, 8]", "\n", "v_feat", "=", "v_feat", ".", "reshape", "(", "B", ",", "V", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "K", ",", "1", ",", "1", ")", "\n", "\n", "H", ",", "W", "=", "tuple", "(", "self", ".", "config", ".", "image_size", ")", "\n", "interpolation", "=", "torch", ".", "arange", "(", "-", "limit", ",", "limit", "+", "0.1", ",", "int_step_size", ")", "\n", "\n", "gifs", "=", "[", "]", "\n", "# ------------ Select intereted object and informtive latent dimensions here ------------", "\n", "k", "=", "2", "# we select only one object out of K for analysis", "\n", "# SPECIFY_DIMENSIONS=[9, 31]", "\n", "# D = len(SPECIFY_DIMENSIONS)", "\n", "# ---------------------------------------------------------------------------------------", "\n", "for", "d", "in", "range", "(", "D", ")", ":", "\n", "            ", "for", "int_val", "in", "interpolation", ":", "\n", "                ", "z", "=", "z3d", ".", "clone", "(", ")", "# [B, K, D]", "\n", "z", "[", ":", ",", "k", ",", "d", "]", "+=", "int_val", "\n", "\n", "for", "vq", "in", "range", "(", "V", ")", ":", "\n", "                    ", "yq", "=", "v_feat", "[", ":", ",", ":", ",", "vq", ",", ":", "]", "\n", "z_yq", "=", "self", ".", "projector", "(", "torch", ".", "cat", "(", "(", "z", ".", "reshape", "(", "B", "*", "K", ",", "-", "1", ")", ",", "yq", ".", "reshape", "(", "B", "*", "K", ",", "-", "1", ")", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "mask_logits", ",", "mu_x", "=", "self", ".", "decode", "(", "z_yq", ")", "\n", "gifs", ".", "append", "(", "torch", ".", "sum", "(", "torch", ".", "softmax", "(", "mask_logits", ",", "dim", "=", "1", ")", "*", "mu_x", ",", "dim", "=", "1", ")", ".", "data", ")", "\n", "", "", "", "gifs", "=", "torch", ".", "cat", "(", "gifs", ",", "dim", "=", "0", ")", "\n", "gifs", "=", "gifs", ".", "reshape", "(", "D", ",", "len", "(", "interpolation", ")", ",", "V", ",", "B", ",", "3", ",", "H", ",", "W", ")", ".", "permute", "(", "[", "3", ",", "0", ",", "1", ",", "2", ",", "4", ",", "5", ",", "6", "]", ")", "\n", "\n", "for", "b", "in", "range", "(", "B", ")", ":", "\n", "            ", "save_batch_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "str", "(", "save_start_id", "+", "b", ")", ")", "\n", "utils", ".", "ensure_dir", "(", "save_batch_dir", ")", "\n", "b_gifs", "=", "gifs", "[", "b", ",", "...", "]", "\n", "b_gifs", "=", "torch", ".", "cat", "(", "b_gifs", ".", "chunk", "(", "V", ",", "dim", "=", "2", ")", ",", "dim", "=", "0", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "for", "iid", "in", "range", "(", "len", "(", "interpolation", ")", ")", ":", "\n", "                ", "key", "=", "'frame'", "\n", "vis", ".", "torch_save_image_enhanced", "(", "tensor", "=", "b_gifs", "[", ":", ",", "iid", ",", "...", "]", ".", "cpu", "(", ")", ",", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "save_batch_dir", ",", "'{}_{:02d}.jpg'", ".", "format", "(", "key", ",", "iid", ")", ")", ",", "\n", "nrow", "=", "D", ",", "pad_value", "=", "1", ",", "enhance", "=", "True", ")", "\n", "", "vis", ".", "grid2gif", "(", "str", "(", "os", ".", "path", ".", "join", "(", "save_batch_dir", ",", "key", "+", "'*.jpg'", ")", ")", ",", "\n", "str", "(", "os", ".", "path", ".", "join", "(", "save_batch_dir", ",", "'disten3d.gif'", ")", ")", ",", "delay", "=", "20", ")", "\n", "\n", "print", "(", "\" -- traversed latent space for {} scene samples\"", ".", "format", "(", "b", "+", "1", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnData.GqnDataset.__init__": [[15, 28], ["utils.read_json"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_json"], ["def", "__init__", "(", "self", ",", "addr_root", ",", "data_file", ",", "num_slots", "=", "7", ",", "transform", "=", "None", ",", "background", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param data_file: (abs_path) the root dir pf the dataset\n        :param transform: (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"", "\n", "self", ".", "addr_root", "=", "addr_root", "\n", "J", "=", "read_json", "(", "data_file", ")", "\n", "self", ".", "name", "=", "J", "[", "'info'", "]", "\n", "self", ".", "data_base", "=", "J", "[", "'scenes'", "]", "\n", "self", ".", "num_views", "=", "J", "[", "'num_views'", "]", "\n", "self", ".", "K_slots", "=", "num_slots", "\n", "self", ".", "background", "=", "background", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnData.GqnDataset.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_base", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnData.GqnDataset.__getitem__": [[32, 52], ["numpy.load", "mydata[].astype", "mydata[].astype", "os.path.join", "isinstance", "torch.tensor", "tfm"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "mydata", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "addr_root", ",", "self", ".", "data_base", "[", "idx", "]", ")", ")", "\n", "image", "=", "mydata", "[", "'images'", "]", ".", "astype", "(", "'float32'", ")", "\n", "if", "mydata", "[", "'images'", "]", ".", "dtype", "==", "'uint8'", ":", "\n", "            ", "image", "/=", "255.0", "\n", "", "view_pts", "=", "mydata", "[", "'camera'", "]", ".", "astype", "(", "'float32'", ")", "\n", "assert", "view_pts", ".", "ndim", "==", "2", ",", "'viewpoint data dimension bug, should be 2, but got {}'", ".", "format", "(", "view_pts", ".", "ndim", ")", "\n", "\n", "pre_sample", "=", "{", "'image'", ":", "image", ",", "\n", "'view_points'", ":", "view_pts", "}", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "transform", ",", "list", ")", "\n", "for", "tfm", "in", "self", ".", "transform", ":", "\n", "                ", "pre_sample", "=", "tfm", "(", "pre_sample", ")", "\n", "", "", "gt", "=", "{", "\n", "'scn_id'", ":", "torch", ".", "tensor", "(", "[", "idx", "]", ",", "requires_grad", "=", "False", ")", ",", "\n", "'view_points'", ":", "pre_sample", "[", "'view_points'", "]", ",", "\n", "}", "\n", "return", "pre_sample", "[", "'image'", "]", ",", "gt", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnData.GqnDataset.extract_masks": [[53, 55], ["None"], "methods", ["None"], ["", "def", "extract_masks", "(", "self", ",", "scn_pack", ",", "masks", ",", "use_bg", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnData.GqnDataset.normalise_viewpoints": [[56, 58], ["None"], "methods", ["None"], ["", "def", "normalise_viewpoints", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnData.ToTensor.__call__": [[62, 74], ["image.transpose.transpose.transpose", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "image", "=", "sample", "[", "'image'", "]", "# [V, H, W, C]", "\n", "view_pts", "=", "sample", "[", "'view_points'", "]", "# [V, D]", "\n", "\n", "# swap color axis because", "\n", "# numpy image: H x W x C", "\n", "# torch image: C X H X W", "\n", "image", "=", "image", ".", "transpose", "(", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "\n", "sample", "[", "'image'", "]", "=", "torch", ".", "from_numpy", "(", "image", ")", "\n", "sample", "[", "'view_points'", "]", "=", "torch", ".", "from_numpy", "(", "view_pts", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnData.DataLoader.__init__": [[77, 89], ["getGqnData.GqnDataset", "data_loader.base_data_loader.BaseDataLoader.__init__", "getGqnData.ToTensor", "tuple", "zip"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "datafile_path", ",", "batch_size", ",", "shuffle", "=", "True", ",", "validation_split", "=", "0.0", ",", "num_workers", "=", "8", ",", "\n", "num_slots", "=", "7", ",", "use_bg", "=", "True", ")", ":", "\n", "        ", "trsfm", "=", "[", "\n", "ToTensor", "(", ")", ",", "\n", "]", "\n", "self", ".", "dataset", "=", "GqnDataset", "(", "addr_root", "=", "data_root", ",", "\n", "data_file", "=", "datafile_path", ",", "\n", "num_slots", "=", "num_slots", ",", "\n", "transform", "=", "trsfm", ",", "\n", "background", "=", "use_bg", ")", "\n", "collate_fn", "=", "lambda", "x", ":", "tuple", "(", "zip", "(", "*", "x", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "dataset", ",", "batch_size", ",", "shuffle", ",", "validation_split", ",", "num_workers", ",", "collate_fn", "=", "collate_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnData.distributed_loader": [[91, 100], ["getGqnData.GqnDataset", "getGqnData.ToTensor"], "function", ["None"], ["", "", "def", "distributed_loader", "(", "data_root", ",", "datafile_path", ",", "num_slots", "=", "7", ",", "use_bg", "=", "True", ")", ":", "\n", "    ", "trsfm", "=", "[", "\n", "ToTensor", "(", ")", ",", "\n", "]", "\n", "return", "GqnDataset", "(", "addr_root", "=", "data_root", ",", "\n", "data_file", "=", "datafile_path", ",", "\n", "num_slots", "=", "num_slots", ",", "\n", "transform", "=", "trsfm", ",", "\n", "background", "=", "use_bg", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getClevrMV.ClevrMVDataset.__init__": [[15, 28], ["utils.read_json", "utils.read_json", "utils.read_json", "utils.read_json"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_json", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_json", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_json", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_json"], ["def", "__init__", "(", "self", ",", "addr_root", ",", "data_file", ",", "num_slots", "=", "7", ",", "transform", "=", "None", ",", "background", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param data_file: (abs_path) the root dir pf the dataset\n        :param transform: (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"", "\n", "self", ".", "addr_root", "=", "addr_root", "\n", "self", ".", "name", "=", "read_json", "(", "data_file", ")", "[", "'info'", "]", "\n", "self", ".", "data_base", "=", "read_json", "(", "data_file", ")", "[", "'scenes'", "]", "\n", "self", ".", "categories", "=", "read_json", "(", "data_file", ")", "[", "'shape_gallery'", "]", "\n", "self", ".", "num_views", "=", "read_json", "(", "data_file", ")", "[", "'num_views'", "]", "\n", "self", ".", "K_slots", "=", "num_slots", "\n", "self", ".", "background", "=", "background", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getClevrMV.ClevrMVDataset.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_base", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getClevrMV.ClevrMVDataset.__getitem__": [[32, 65], ["numpy.load", "getClevrMV.ClevrMVDataset.extract_masks", "getClevrMV.ClevrMVDataset.normalise_viewpoints", "os.path.join", "[].astype", "numpy.expand_dims", "numpy.expand_dims", "isinstance", "torch.tensor", "tfm"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.GqnDataset.extract_masks", "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.GqnDataset.normalise_viewpoints"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "item", "=", "self", ".", "data_base", "[", "idx", "]", "\n", "mydata", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "addr_root", ",", "item", "[", "'data_path'", "]", ")", ")", "\n", "image", "=", "mydata", "[", "'images'", "]", "[", "...", ",", ":", "3", "]", ".", "astype", "(", "'float32'", ")", "/", "255", "\n", "mask_pack_raw", "=", "mydata", "[", "'masks'", "]", "\n", "masks_obs", ",", "masks_clr", ",", "num_comps", "=", "self", ".", "extract_masks", "(", "item", ",", "mask_pack_raw", ",", "self", ".", "background", ")", "# [V, H, W, K]", "\n", "view_pts", "=", "self", ".", "normalise_viewpoints", "(", "item", ")", "\n", "\n", "if", "masks_obs", ".", "ndim", "==", "3", ":", "\n", "            ", "masks_obs", "=", "np", ".", "expand_dims", "(", "masks_obs", ",", "axis", "=", "-", "1", ")", "\n", "", "if", "masks_clr", ".", "ndim", "==", "3", ":", "\n", "            ", "masks_clr", "=", "np", ".", "expand_dims", "(", "masks_clr", ",", "axis", "=", "-", "1", ")", "\n", "", "assert", "view_pts", ".", "ndim", "==", "2", ",", "'viewpoint data dimension bug, should be 2, but got {}'", ".", "format", "(", "view_pts", ".", "ndim", ")", "\n", "\n", "pre_sample", "=", "{", "'image'", ":", "image", ",", "\n", "'masks'", ":", "masks_obs", ",", "\n", "'masks_clr'", ":", "masks_clr", ",", "\n", "'num_comps'", ":", "num_comps", ",", "\n", "'view_points'", ":", "view_pts", "}", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "transform", ",", "list", ")", "\n", "for", "tfm", "in", "self", ".", "transform", ":", "\n", "                ", "pre_sample", "=", "tfm", "(", "pre_sample", ")", "\n", "\n", "", "", "gt", "=", "{", "\n", "'scn_id'", ":", "torch", ".", "tensor", "(", "[", "idx", "]", ",", "requires_grad", "=", "False", ")", ",", "# access by gt['scn_id'].item()", "\n", "'num_comps'", ":", "pre_sample", "[", "'num_comps'", "]", ",", "\n", "'masks'", ":", "pre_sample", "[", "'masks'", "]", ",", "\n", "'masks_clr'", ":", "pre_sample", "[", "'masks_clr'", "]", ",", "\n", "'view_points'", ":", "pre_sample", "[", "'view_points'", "]", ",", "\n", "}", "\n", "return", "pre_sample", "[", "'image'", "]", ",", "gt", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getClevrMV.ClevrMVDataset.extract_masks": [[66, 110], ["range", "numpy.stack().astype", "range", "numpy.stack().astype", "numpy.zeros", "numpy.zeros", "mv_masks.append", "mv_mclrs.append", "numpy.stack", "numpy.stack", "numpy.concatenate", "numpy.stack().astype.append", "list", "len", "numpy.stack", "int", "numpy.float32", "numpy.stack", "numpy.ones_like", "m_occ_raw.max"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max"], ["", "def", "extract_masks", "(", "self", ",", "scn_pack", ",", "masks", ",", "use_bg", ")", ":", "\n", "        ", "\"\"\" Separating the raw mask data into two groups (masks w/o occlusions)\n        :param scn_pack:  scn dict that contains information about the scene\n        :param masks:  [V, H, W, N], where N <= K\n        :param use_bg:  include background as object or not.\n        \"\"\"", "\n", "V", ",", "H", ",", "W", ",", "_", "=", "masks", ".", "shape", "\n", "\n", "mv_masks", "=", "[", "]", "\n", "mv_mclrs", "=", "[", "]", "\n", "for", "v", "in", "range", "(", "self", ".", "num_views", ")", ":", "\n", "            ", "m_occ_raw", "=", "masks", "[", "v", ",", "...", ",", "0", "]", "\n", "m_clr", "=", "masks", "[", "v", ",", "...", ",", "1", ":", "]", "\n", "\n", "if", "use_bg", ":", "\n", "                ", "depth_order", "=", "[", "0", "]", "+", "list", "(", "i", "+", "1", "for", "i", "in", "scn_pack", "[", "'depth_orders'", "]", "[", "v", "]", ")", "\n", "m_clr", "=", "np", ".", "concatenate", "(", "(", "np", ".", "ones_like", "(", "m_clr", "[", "...", ",", ":", "1", "]", ")", ",", "m_clr", ")", ",", "axis", "=", "-", "1", ")", "\n", "assert", "len", "(", "depth_order", ")", "==", "m_clr", ".", "shape", "[", "-", "1", "]", ",", "'depth order and m_clr size do not match'", "\n", "skip_bg", "=", "0", "\n", "", "else", ":", "\n", "                ", "depth_order", "=", "scn_pack", "[", "'depth_orders'", "]", "[", "v", "]", "\n", "skip_bg", "=", "1", "\n", "", "m_clr", "=", "np", ".", "stack", "(", "[", "m_clr", "[", "...", ",", "i", "]", "for", "i", "in", "depth_order", "]", ",", "axis", "=", "-", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "\n", "m_occ", "=", "[", "]", "\n", "for", "vi", "in", "range", "(", "skip_bg", ",", "int", "(", "m_occ_raw", ".", "max", "(", ")", ")", "+", "1", ")", ":", "\n", "                ", "m_occ", ".", "append", "(", "np", ".", "float32", "(", "m_occ_raw", "==", "vi", ")", ")", "\n", "", "m_occ", "=", "np", ".", "stack", "(", "m_occ", ",", "axis", "=", "-", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "assert", "m_occ", ".", "shape", "[", "-", "1", "]", "==", "m_clr", ".", "shape", "[", "-", "1", "]", ",", "'depth order wrong {} '", ".", "format", "(", "scn_pack", "[", "'mask_path'", "]", ")", "\n", "\n", "# fill in slots with empty masks (nothing)", "\n", "N", "=", "m_occ", ".", "shape", "[", "-", "1", "]", "\n", "mask_occ_slots", "=", "np", ".", "zeros", "(", "[", "H", ",", "W", ",", "self", ".", "K_slots", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "mask_clr_slots", "=", "np", ".", "zeros", "(", "[", "H", ",", "W", ",", "self", ".", "K_slots", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "\n", "mask_occ_slots", "[", "...", ",", ":", "N", "]", "=", "m_occ", "\n", "mask_clr_slots", "[", "...", ",", ":", "N", "]", "=", "m_clr", "\n", "\n", "# record every single observations", "\n", "mv_masks", ".", "append", "(", "mask_occ_slots", ")", "\n", "mv_mclrs", ".", "append", "(", "mask_clr_slots", ")", "\n", "\n", "", "return", "np", ".", "stack", "(", "mv_masks", ",", "axis", "=", "0", ")", ",", "np", ".", "stack", "(", "mv_mclrs", ",", "axis", "=", "0", ")", ",", "N", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getClevrMV.ClevrMVDataset.normalise_viewpoints": [[111, 118], ["numpy.asarray", "numpy.linalg.norm", "numpy.asarray"], "methods", ["None"], ["", "def", "normalise_viewpoints", "(", "self", ",", "item", ")", ":", "\n", "        ", "\"\"\" view_pts standardization (not really necessary though) \"\"\"", "\n", "cams", "=", "np", ".", "asarray", "(", "item", "[", "'camera'", "]", "[", "'location'", "]", ")", "\n", "assert", "cams", ".", "shape", "[", "0", "]", "==", "self", ".", "num_views", ",", "'non-valid data: {}'", ".", "format", "(", "item", "[", "'image_filename'", "]", ")", "\n", "cams", "[", ":", ",", "2", "]", "=", "0.", "\n", "cams", "/=", "(", "np", ".", "linalg", ".", "norm", "(", "cams", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "+", "1e-5", ")", "\n", "return", "(", "cams", "-", "np", ".", "asarray", "(", "[", "[", "1.", ",", "0.", ",", "0.", "]", "]", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getClevrMV.ToTensor.__call__": [[122, 149], ["image.transpose.transpose.transpose", "numpy.int16().reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.expand_dims", "numpy.expand_dims", "numpy.int16"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "image", "=", "sample", "[", "'image'", "]", "# [V, H, W, C]", "\n", "masks", "=", "sample", "[", "'masks'", "]", "# [V, H, W, K]", "\n", "masks_clr", "=", "sample", "[", "'masks_clr'", "]", "# [V, H, W, K]", "\n", "num_objects", "=", "sample", "[", "'num_comps'", "]", "\n", "view_pts", "=", "sample", "[", "'view_points'", "]", "\n", "\n", "# swap color axis because", "\n", "# numpy image: H x W x C", "\n", "# torch image: C X H X W", "\n", "image", "=", "image", ".", "transpose", "(", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "\n", "# for masks:", "\n", "# numpy masks: V, H, W, K", "\n", "# torch masks: V, 1, H, W, K", "\n", "if", "masks", ".", "ndim", "==", "4", ":", "\n", "            ", "masks", "=", "np", ".", "expand_dims", "(", "masks", ",", "axis", "=", "1", ")", "# [V, 1, H, W, K]", "\n", "", "if", "masks_clr", ".", "ndim", "==", "4", ":", "\n", "            ", "masks_clr", "=", "np", ".", "expand_dims", "(", "masks_clr", ",", "axis", "=", "1", ")", "# [V, 1, H, W, K]", "\n", "", "n_comps_npy", "=", "np", ".", "int16", "(", "num_objects", ")", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "\n", "sample", "[", "'num_comps'", "]", "=", "torch", ".", "from_numpy", "(", "n_comps_npy", ")", "\n", "sample", "[", "'image'", "]", "=", "torch", ".", "from_numpy", "(", "image", ")", "\n", "sample", "[", "'masks'", "]", "=", "torch", ".", "from_numpy", "(", "masks", ")", "\n", "sample", "[", "'masks_clr'", "]", "=", "torch", ".", "from_numpy", "(", "masks_clr", ")", "\n", "sample", "[", "'view_points'", "]", "=", "torch", ".", "from_numpy", "(", "view_pts", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getClevrMV.DataLoader.__init__": [[152, 164], ["getClevrMV.ClevrMVDataset", "data_loader.base_data_loader.BaseDataLoader.__init__", "getClevrMV.ToTensor", "tuple", "zip"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "datafile_path", ",", "batch_size", ",", "shuffle", "=", "True", ",", "validation_split", "=", "0.0", ",", "num_workers", "=", "4", ",", "\n", "num_slots", "=", "7", ",", "use_bg", "=", "True", ")", ":", "\n", "        ", "trsfm", "=", "[", "\n", "ToTensor", "(", ")", ",", "\n", "]", "\n", "self", ".", "dataset", "=", "ClevrMVDataset", "(", "addr_root", "=", "data_root", ",", "\n", "data_file", "=", "datafile_path", ",", "\n", "num_slots", "=", "num_slots", ",", "\n", "transform", "=", "trsfm", ",", "\n", "background", "=", "use_bg", ")", "\n", "collate_fn", "=", "lambda", "x", ":", "tuple", "(", "zip", "(", "*", "x", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "dataset", ",", "batch_size", ",", "shuffle", ",", "validation_split", ",", "num_workers", ",", "collate_fn", "=", "collate_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getClevrMV.distributed_loader": [[166, 175], ["getClevrMV.ClevrMVDataset", "getClevrMV.ToTensor"], "function", ["None"], ["", "", "def", "distributed_loader", "(", "data_root", ",", "datafile_path", ",", "num_slots", "=", "7", ",", "use_bg", "=", "True", ")", ":", "\n", "    ", "trsfm", "=", "[", "\n", "ToTensor", "(", ")", ",", "\n", "]", "\n", "return", "ClevrMVDataset", "(", "addr_root", "=", "data_root", ",", "\n", "data_file", "=", "datafile_path", ",", "\n", "num_slots", "=", "num_slots", ",", "\n", "transform", "=", "trsfm", ",", "\n", "background", "=", "use_bg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.GqnDataset.__init__": [[13, 26], ["utils.read_h5py"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.read_h5py"], ["def", "__init__", "(", "self", ",", "addr_root", ",", "data_file", ",", "num_slots", "=", "7", ",", "transform", "=", "None", ",", "background", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param data_file: (abs_path) the root dir pf the dataset\n        :param transform: (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"", "\n", "self", ".", "addr_root", "=", "addr_root", "\n", "F", "=", "read_h5py", "(", "data_file", ")", "\n", "self", ".", "images", "=", "F", "[", "'images'", "]", "\n", "self", ".", "viewpoints", "=", "F", "[", "'viewpoints'", "]", "\n", "self", ".", "num_views", "=", "self", ".", "viewpoints", ".", "shape", "[", "1", "]", "\n", "self", ".", "K_slots", "=", "num_slots", "\n", "self", ".", "background", "=", "background", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.GqnDataset.__len__": [[27, 29], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "viewpoints", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.GqnDataset.__getitem__": [[30, 49], ["getGqnH5.GqnDataset.images[].astype", "getGqnH5.GqnDataset.viewpoints[].astype", "isinstance", "torch.tensor", "tfm"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "image", "=", "self", ".", "images", "[", "idx", "]", ".", "astype", "(", "'float32'", ")", "\n", "if", "self", ".", "images", "[", "idx", "]", ".", "dtype", "==", "'uint8'", ":", "\n", "            ", "image", "/=", "255.0", "\n", "", "view_pts", "=", "self", ".", "viewpoints", "[", "idx", "]", ".", "astype", "(", "'float32'", ")", "\n", "assert", "view_pts", ".", "ndim", "==", "2", ",", "'viewpoint data dimension bug, should be 2, but got {}'", ".", "format", "(", "view_pts", ".", "ndim", ")", "\n", "\n", "pre_sample", "=", "{", "'image'", ":", "image", ",", "\n", "'view_points'", ":", "view_pts", "}", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "transform", ",", "list", ")", "\n", "for", "tfm", "in", "self", ".", "transform", ":", "\n", "                ", "pre_sample", "=", "tfm", "(", "pre_sample", ")", "\n", "", "", "gt", "=", "{", "\n", "'scn_id'", ":", "torch", ".", "tensor", "(", "[", "idx", "]", ",", "requires_grad", "=", "False", ")", ",", "\n", "'view_points'", ":", "pre_sample", "[", "'view_points'", "]", ",", "\n", "}", "\n", "return", "pre_sample", "[", "'image'", "]", ",", "gt", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.GqnDataset.extract_masks": [[50, 52], ["None"], "methods", ["None"], ["", "def", "extract_masks", "(", "self", ",", "scn_pack", ",", "masks", ",", "use_bg", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.GqnDataset.normalise_viewpoints": [[53, 55], ["None"], "methods", ["None"], ["", "def", "normalise_viewpoints", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.ToTensor.__call__": [[59, 71], ["image.transpose.transpose.transpose", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "image", "=", "sample", "[", "'image'", "]", "# [V, H, W, C]", "\n", "view_pts", "=", "sample", "[", "'view_points'", "]", "# [V, D]", "\n", "\n", "# swap color axis because", "\n", "# numpy image: H x W x C", "\n", "# torch image: C X H X W", "\n", "image", "=", "image", ".", "transpose", "(", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "\n", "sample", "[", "'image'", "]", "=", "torch", ".", "from_numpy", "(", "image", ")", "\n", "sample", "[", "'view_points'", "]", "=", "torch", ".", "from_numpy", "(", "view_pts", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.DataLoader.__init__": [[74, 86], ["getGqnH5.GqnDataset", "data_loader.base_data_loader.BaseDataLoader.__init__", "getGqnH5.ToTensor", "tuple", "zip"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "datafile_path", ",", "batch_size", ",", "shuffle", "=", "True", ",", "validation_split", "=", "0.0", ",", "num_workers", "=", "8", ",", "\n", "num_slots", "=", "7", ",", "use_bg", "=", "True", ")", ":", "\n", "        ", "trsfm", "=", "[", "\n", "ToTensor", "(", ")", ",", "\n", "]", "\n", "self", ".", "dataset", "=", "GqnDataset", "(", "addr_root", "=", "data_root", ",", "\n", "data_file", "=", "datafile_path", ",", "\n", "num_slots", "=", "num_slots", ",", "\n", "transform", "=", "trsfm", ",", "\n", "background", "=", "use_bg", ")", "\n", "collate_fn", "=", "lambda", "x", ":", "tuple", "(", "zip", "(", "*", "x", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "dataset", ",", "batch_size", ",", "shuffle", ",", "validation_split", ",", "num_workers", ",", "collate_fn", "=", "collate_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.getGqnH5.distributed_loader": [[88, 97], ["getGqnH5.GqnDataset", "getGqnH5.ToTensor"], "function", ["None"], ["", "", "def", "distributed_loader", "(", "data_root", ",", "datafile_path", ",", "num_slots", "=", "7", ",", "use_bg", "=", "True", ")", ":", "\n", "    ", "trsfm", "=", "[", "\n", "ToTensor", "(", ")", ",", "\n", "]", "\n", "return", "GqnDataset", "(", "addr_root", "=", "data_root", ",", "\n", "data_file", "=", "datafile_path", ",", "\n", "num_slots", "=", "num_slots", ",", "\n", "transform", "=", "trsfm", ",", "\n", "background", "=", "use_bg", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.base_data_loader.BaseDataLoader.__init__": [[11, 28], ["len", "base_data_loader.BaseDataLoader._split_sampler", "torch.utils.data.DataLoader.__init__"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.base_data_loader.BaseDataLoader._split_sampler", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ",", "shuffle", ",", "validation_split", ",", "num_workers", ",", "collate_fn", "=", "default_collate", ")", ":", "\n", "        ", "self", ".", "validation_split", "=", "validation_split", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "self", ".", "batch_idx", "=", "0", "\n", "self", ".", "n_samples", "=", "len", "(", "dataset", ")", "\n", "\n", "self", ".", "sampler", ",", "self", ".", "valid_sampler", "=", "self", ".", "_split_sampler", "(", "self", ".", "validation_split", ")", "\n", "\n", "self", ".", "init_kwargs", "=", "{", "\n", "'dataset'", ":", "dataset", ",", "\n", "'batch_size'", ":", "batch_size", ",", "\n", "'shuffle'", ":", "self", ".", "shuffle", ",", "\n", "'collate_fn'", ":", "collate_fn", ",", "\n", "'num_workers'", ":", "num_workers", "\n", "}", "\n", "super", "(", ")", ".", "__init__", "(", "sampler", "=", "self", ".", "sampler", ",", "**", "self", ".", "init_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.base_data_loader.BaseDataLoader._split_sampler": [[29, 56], ["numpy.arange", "numpy.random.seed", "numpy.random.shuffle", "isinstance", "numpy.delete", "torch.utils.data.sampler.SubsetRandomSampler", "torch.utils.data.sampler.SubsetRandomSampler", "len", "int", "numpy.arange"], "methods", ["None"], ["", "def", "_split_sampler", "(", "self", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "0.0", ":", "\n", "            ", "return", "None", ",", "None", "\n", "\n", "", "idx_full", "=", "np", ".", "arange", "(", "self", ".", "n_samples", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx_full", ")", "\n", "\n", "if", "isinstance", "(", "split", ",", "int", ")", ":", "\n", "            ", "assert", "split", ">", "0", "\n", "assert", "split", "<", "self", ".", "n_samples", ",", "\"validation set size is configured to be larger than entire dataset.\"", "\n", "len_valid", "=", "split", "\n", "", "else", ":", "\n", "            ", "len_valid", "=", "int", "(", "self", ".", "n_samples", "*", "split", ")", "\n", "\n", "", "valid_idx", "=", "idx_full", "[", "0", ":", "len_valid", "]", "\n", "train_idx", "=", "np", ".", "delete", "(", "idx_full", ",", "np", ".", "arange", "(", "0", ",", "len_valid", ")", ")", "\n", "\n", "train_sampler", "=", "SubsetRandomSampler", "(", "train_idx", ")", "\n", "valid_sampler", "=", "SubsetRandomSampler", "(", "valid_idx", ")", "\n", "\n", "# turn off shuffle option which is mutually exclusive with sampler", "\n", "self", ".", "shuffle", "=", "False", "\n", "self", ".", "n_samples", "=", "len", "(", "train_idx", ")", "\n", "\n", "return", "train_sampler", ",", "valid_sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.data_loader.base_data_loader.BaseDataLoader.split_validation": [[57, 62], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "split_validation", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "valid_sampler", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "DataLoader", "(", "sampler", "=", "self", ".", "valid_sampler", ",", "**", "self", ".", "init_kwargs", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.__init__": [[20, 27], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "window_size", "=", "20", ",", "fmt", "=", "None", ")", ":", "\n", "        ", "if", "fmt", "is", "None", ":", "\n", "            ", "fmt", "=", "\"{median:.4f} ({global_avg:.4f})\"", "\n", "", "self", ".", "deque", "=", "deque", "(", "maxlen", "=", "window_size", ")", "\n", "self", ".", "total", "=", "0.0", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "fmt", "=", "fmt", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.update": [[28, 32], ["_utils.SmoothedValue.deque.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "deque", ".", "append", "(", "value", ")", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "total", "+=", "value", "*", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.synchronize_between_processes": [[33, 45], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.barrier", "torch.barrier", "torch.all_reduce", "torch.all_reduce", "t.tolist.tolist.tolist", "int", "_utils.is_dist_avail_and_initialized"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.is_dist_avail_and_initialized"], ["", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Warning: does not synchronize the deque!\n        \"\"\"", "\n", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "            ", "return", "\n", "", "t", "=", "torch", ".", "tensor", "(", "[", "self", ".", "count", ",", "self", ".", "total", "]", ",", "dtype", "=", "torch", ".", "float64", ",", "device", "=", "'cuda'", ")", "\n", "dist", ".", "barrier", "(", ")", "\n", "dist", ".", "all_reduce", "(", "t", ")", "\n", "t", "=", "t", ".", "tolist", "(", ")", "\n", "self", ".", "count", "=", "int", "(", "t", "[", "0", "]", ")", "\n", "self", ".", "total", "=", "t", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.median": [[46, 50], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.median().item", "torch.tensor.median().item", "list", "torch.tensor.median", "torch.tensor.median"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.median", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.median"], ["", "@", "property", "\n", "def", "median", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ")", "\n", "return", "d", ".", "median", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.avg": [[51, 55], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.mean().item", "torch.tensor.mean().item", "list", "torch.tensor.mean", "torch.tensor.mean"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "return", "d", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.global_avg": [[56, 59], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max": [[60, 63], ["_utils.SmoothedValue.max"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max"], ["", "@", "property", "\n", "def", "max", "(", "self", ")", ":", "\n", "        ", "return", "max", "(", "self", ".", "deque", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.value": [[64, 67], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "deque", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.__str__": [[68, 75], ["_utils.SmoothedValue.fmt.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fmt", ".", "format", "(", "\n", "median", "=", "self", ".", "median", ",", "\n", "avg", "=", "self", ".", "avg", ",", "\n", "global_avg", "=", "self", ".", "global_avg", ",", "\n", "max", "=", "self", ".", "max", ",", "\n", "value", "=", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.__init__": [[148, 151], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "delimiter", "=", "\"\\t\"", ")", ":", "\n", "        ", "self", ".", "meters", "=", "defaultdict", "(", "SmoothedValue", ")", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.update": [[152, 158], ["kwargs.items", "isinstance", "isinstance", "_utils.MetricLogger.meters[].update", "v.item.item.item"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.update"], ["", "def", "update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "item", "(", ")", "\n", "", "assert", "isinstance", "(", "v", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "meters", "[", "k", "]", ".", "update", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.__getattr__": [[159, 166], ["AttributeError", "type"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "        ", "if", "attr", "in", "self", ".", "meters", ":", "\n", "            ", "return", "self", ".", "meters", "[", "attr", "]", "\n", "", "if", "attr", "in", "self", ".", "__dict__", ":", "\n", "            ", "return", "self", ".", "__dict__", "[", "attr", "]", "\n", "", "raise", "AttributeError", "(", "\"'{}' object has no attribute '{}'\"", ".", "format", "(", "\n", "type", "(", "self", ")", ".", "__name__", ",", "attr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.__str__": [[167, 174], ["_utils.MetricLogger.meters.items", "_utils.MetricLogger.delimiter.join", "loss_str.append", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "loss_str", "=", "[", "]", "\n", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "loss_str", ".", "append", "(", "\n", "\"{}: {}\"", ".", "format", "(", "name", ",", "str", "(", "meter", ")", ")", "\n", ")", "\n", "", "return", "self", ".", "delimiter", ".", "join", "(", "loss_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.synchronize_between_processes": [[175, 178], ["_utils.MetricLogger.meters.values", "meter.synchronize_between_processes"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.synchronize_between_processes"], ["", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "for", "meter", "in", "self", ".", "meters", ".", "values", "(", ")", ":", "\n", "            ", "meter", ".", "synchronize_between_processes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.add_meter": [[179, 181], ["None"], "methods", ["None"], ["", "", "def", "add_meter", "(", "self", ",", "name", ",", "meter", ")", ":", "\n", "        ", "self", ".", "meters", "[", "name", "]", "=", "meter", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.log_every": [[182, 237], ["time.time", "time.time", "_utils.SmoothedValue", "_utils.SmoothedValue", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "str", "print", "len", "_utils.MetricLogger.delimiter.join", "_utils.MetricLogger.delimiter.join", "_utils.SmoothedValue.update", "_utils.SmoothedValue.update", "time.time", "time.time", "datetime.timedelta", "str", "str", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "len", "time.time", "time.time", "datetime.timedelta", "print", "print", "int", "str", "_utils.MetricLogger.format", "_utils.MetricLogger.format", "int", "str", "str", "str", "str", "str", "str", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.update", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.update"], ["", "def", "log_every", "(", "self", ",", "iterable", ",", "print_freq", ",", "len_iter", "=", "None", ",", "header", "=", "None", ")", ":", "\n", "        ", "i", "=", "0", "\n", "if", "not", "header", ":", "\n", "            ", "header", "=", "''", "\n", "", "if", "not", "len_iter", ":", "\n", "            ", "len_iter", "=", "len", "(", "iterable", ")", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "iter_time", "=", "SmoothedValue", "(", "fmt", "=", "'{avg:.4f}'", ")", "\n", "data_time", "=", "SmoothedValue", "(", "fmt", "=", "'{avg:.4f}'", ")", "\n", "space_fmt", "=", "':'", "+", "str", "(", "len", "(", "str", "(", "len_iter", ")", ")", ")", "+", "'d'", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "log_msg", "=", "self", ".", "delimiter", ".", "join", "(", "[", "\n", "header", ",", "\n", "'[{0'", "+", "space_fmt", "+", "'}/{1}]'", ",", "\n", "'eta: {eta}'", ",", "\n", "'{meters}'", ",", "\n", "'time: {time}'", ",", "\n", "'data: {data}'", ",", "\n", "'max mem: {memory:.0f}'", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "log_msg", "=", "self", ".", "delimiter", ".", "join", "(", "[", "\n", "header", ",", "\n", "'[{0'", "+", "space_fmt", "+", "'}/{1}]'", ",", "\n", "'eta: {eta}'", ",", "\n", "'{meters}'", ",", "\n", "'time: {time}'", ",", "\n", "'data: {data}'", "\n", "]", ")", "\n", "", "MB", "=", "1024.0", "*", "1024.0", "\n", "for", "obj", "in", "iterable", ":", "\n", "            ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "yield", "obj", "\n", "iter_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "if", "i", "%", "print_freq", "==", "0", "or", "i", "==", "len_iter", "-", "1", ":", "\n", "                ", "eta_seconds", "=", "iter_time", ".", "global_avg", "*", "(", "len_iter", "-", "i", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "print", "(", "log_msg", ".", "format", "(", "\n", "i", ",", "len_iter", ",", "eta", "=", "eta_string", ",", "\n", "meters", "=", "str", "(", "self", ")", ",", "\n", "time", "=", "str", "(", "iter_time", ")", ",", "data", "=", "str", "(", "data_time", ")", ",", "\n", "memory", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "MB", ")", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "log_msg", ".", "format", "(", "\n", "i", ",", "len_iter", ",", "eta", "=", "eta_string", ",", "\n", "meters", "=", "str", "(", "self", ")", ",", "\n", "time", "=", "str", "(", "iter_time", ")", ",", "data", "=", "str", "(", "data_time", ")", ")", ")", "\n", "", "", "i", "+=", "1", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", "\n", "print", "(", "'{} Total time: {} ({:.4f} s / it)'", ".", "format", "(", "\n", "header", ",", "total_time_str", ",", "total_time", "/", "len_iter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.all_gather": [[77, 118], ["_utils.get_world_size", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.tensor", "torch.tensor", "torch.all_gather", "max", "torch.all_gather", "zip", "torch.tensor", "torch.tensor", "int", "tensor_list.append", "torch.empty", "torch.empty", "torch.cat", "torch.cat", "data_list.append", "torch.ByteTensor", "torch.ByteTensor", "torch.cat.numel", "range", "size.item", "torch.empty", "torch.empty", "torch.cat.cpu().numpy().tobytes", "pickle.loads", "torch.cat.cpu().numpy", "torch.cat.cpu"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.get_world_size", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.all_gather", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.all_gather"], ["", "", "def", "all_gather", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors)\n    Args:\n        data: any picklable object\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "# serialized to a Tensor", "\n", "", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "# obtain Tensor size of each rank", "\n", "local_size", "=", "torch", ".", "tensor", "(", "[", "tensor", ".", "numel", "(", ")", "]", ",", "device", "=", "\"cuda\"", ")", "\n", "size_list", "=", "[", "torch", ".", "tensor", "(", "[", "0", "]", ",", "device", "=", "\"cuda\"", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "dist", ".", "all_gather", "(", "size_list", ",", "local_size", ")", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "tensor_list", "=", "[", "]", "\n", "for", "_", "in", "size_list", ":", "\n", "        ", "tensor_list", ".", "append", "(", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", ")", "\n", "", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "empty", "(", "size", "=", "(", "max_size", "-", "local_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.reduce_dict": [[120, 145], ["_utils.get_world_size", "torch.no_grad", "torch.no_grad", "sorted", "torch.stack", "torch.stack", "torch.all_reduce", "input_dict.keys", "names.append", "torch.stack.append", "zip"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.get_world_size"], ["", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input_dict (dict): all the values will be reduced\n        average (bool): whether to do average or sum\n    Reduce the values in the dictionary from all processes so that all processes\n    have the averaged results. Returns a dict with the same fields as\n    input_dict, after reduction.\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "# sort the keys so that they are consistent across processes", "\n", "for", "k", "in", "sorted", "(", "input_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "input_dict", "[", "k", "]", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "dist", ".", "all_reduce", "(", "values", ")", "\n", "if", "average", ":", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.collate_fn": [[239, 241], ["tuple", "zip"], "function", ["None"], ["", "", "def", "collate_fn", "(", "batch", ")", ":", "\n", "    ", "return", "tuple", "(", "zip", "(", "*", "batch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.warmup_lr_scheduler": [[243, 252], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "float"], "function", ["None"], ["", "def", "warmup_lr_scheduler", "(", "optimizer", ",", "warmup_iters", ",", "warmup_factor", ")", ":", "\n", "\n", "    ", "def", "f", "(", "x", ")", ":", "\n", "        ", "if", "x", ">=", "warmup_iters", ":", "\n", "            ", "return", "1", "\n", "", "alpha", "=", "float", "(", "x", ")", "/", "warmup_iters", "\n", "return", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "\n", "", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir": [[254, 260], ["os.makedirs"], "function", ["None"], ["", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "        ", "if", "e", ".", "errno", "!=", "errno", ".", "EEXIST", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.setup_for_distributed": [[262, 275], ["kwargs.pop", "builtin_print"], "function", ["None"], ["", "", "", "def", "setup_for_distributed", "(", "is_master", ")", ":", "\n", "    ", "\"\"\"\n    This function disables printing when not in master process\n    \"\"\"", "\n", "import", "builtins", "as", "__builtin__", "\n", "builtin_print", "=", "__builtin__", ".", "print", "\n", "\n", "def", "print", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "force", "=", "kwargs", ".", "pop", "(", "'force'", ",", "False", ")", "\n", "if", "is_master", "or", "force", ":", "\n", "            ", "builtin_print", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "__builtin__", ".", "print", "=", "print", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.is_dist_avail_and_initialized": [[277, 283], ["torch.is_available", "torch.is_initialized"], "function", ["None"], ["", "def", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.get_world_size": [[285, 289], ["torch.get_world_size", "_utils.is_dist_avail_and_initialized"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.get_world_size", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.is_dist_avail_and_initialized"], ["", "def", "get_world_size", "(", ")", ":", "\n", "    ", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.get_rank": [[291, 295], ["torch.get_rank", "_utils.is_dist_avail_and_initialized"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.get_rank", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.is_dist_avail_and_initialized"], ["", "def", "get_rank", "(", ")", ":", "\n", "    ", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.is_main_process": [[297, 299], ["_utils.get_rank"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.get_rank"], ["", "def", "is_main_process", "(", ")", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.save_on_master": [[301, 304], ["_utils.is_main_process", "torch.save", "torch.save"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.is_main_process"], ["", "def", "save_on_master", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "is_main_process", "(", ")", ":", "\n", "        ", "torch", ".", "save", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.init_distributed_mode": [[306, 329], ["torch.cuda.set_device", "torch.cuda.set_device", "_utils.setup_for_distributed.print", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.barrier", "torch.distributed.barrier", "_utils.setup_for_distributed", "int", "int", "int", "int", "_utils.setup_for_distributed.print", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.setup_for_distributed"], ["", "", "def", "init_distributed_mode", "(", "args", ")", ":", "\n", "    ", "if", "'RANK'", "in", "os", ".", "environ", "and", "'WORLD_SIZE'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", "\n", "args", ".", "gpu", "=", "int", "(", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", ")", "\n", "", "elif", "'SLURM_PROCID'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_PROCID'", "]", ")", "\n", "args", ".", "gpu", "=", "args", ".", "rank", "%", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Not using distributed mode'", ")", "\n", "args", ".", "distributed", "=", "False", "\n", "return", "\n", "\n", "", "args", ".", "distributed", "=", "True", "\n", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "args", ".", "dist_backend", "=", "'nccl'", "\n", "print", "(", "'| distributed init (rank {}): {}'", ".", "format", "(", "\n", "args", ".", "rank", ",", "args", ".", "dist_url", ")", ",", "flush", "=", "True", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "args", ".", "dist_backend", ",", "init_method", "=", "args", ".", "dist_url", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "rank", "=", "args", ".", "rank", ")", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "setup_for_distributed", "(", "args", ".", "rank", "==", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer.ModelTrainer.__init__": [[14, 45], ["trainer.base_trainer.BaseTrainer.__init__", "len", "trainer.inf_loop", "model_trainer.ModelTrainer.lr_scheduler.get_lr"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.inf_loop", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.scheduler.AnnealingStepLR.get_lr"], ["def", "__init__", "(", "self", ",", "model", ",", "loss", ",", "metrics", ",", "optimizer", ",", "config", ",", "train_data_loader", ",", "\n", "valid_data_loader", "=", "None", ",", "lr_scheduler", "=", "None", ",", "step_per_epoch", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "loss", ",", "metrics", ",", "optimizer", ",", "config", ",", "device", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "train_loader", "=", "train_data_loader", "\n", "if", "step_per_epoch", "is", "None", ":", "\n", "# epoch-based training", "\n", "            ", "self", ".", "step_per_epoch", "=", "len", "(", "self", ".", "train_loader", ")", "\n", "", "elif", "step_per_epoch", ":", "\n", "# iteration-based training", "\n", "            ", "self", ".", "train_loader", "=", "inf_loop", "(", "self", ".", "train_loader", ")", "# Reusable iterator", "\n", "self", ".", "step_per_epoch", "=", "step_per_epoch", "\n", "\n", "", "self", ".", "do_validation", "=", "valid_data_loader", "is", "not", "None", "\n", "if", "self", ".", "do_validation", ":", "\n", "            ", "self", ".", "valid_loader", "=", "valid_data_loader", "\n", "\n", "", "self", ".", "save_period", "=", "config", ".", "save_period", "\n", "self", ".", "lr_scheduler", "=", "lr_scheduler", "\n", "\n", "if", "self", ".", "config", ".", "resume_epoch", "is", "not", "None", ":", "\n", "            ", "self", ".", "start_epoch", "=", "self", ".", "config", ".", "resume_epoch", "+", "1", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "last_epoch", "=", "self", ".", "config", ".", "resume_epoch", "*", "self", ".", "step_per_epoch", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "\n", "# self.save_dir has been declared in parenthese", "\n", "", "", "assert", "config", ".", "vis_train_dir", "is", "not", "None", "\n", "self", ".", "vis_train_dir", "=", "config", ".", "vis_train_dir", "\n", "assert", "config", ".", "generated_dir", "is", "not", "None", "\n", "self", ".", "generated_dir", "=", "config", ".", "generated_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer.ModelTrainer.train": [[46, 62], ["print", "range", "print", "print", "print", "model_trainer.ModelTrainer._train_epoch", "model_trainer.ModelTrainer._validate_epoch", "model_trainer.ModelTrainer._save_checkpoint"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer._train_epoch", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer_parallel.ModelTrainer._validate_epoch", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer._save_checkpoint"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "print", "(", "'\\n================== Start training ==================='", ")", "\n", "# self.start_time = time.time()", "\n", "assert", "(", "self", ".", "epochs", "+", "1", ")", ">", "self", ".", "start_epoch", "\n", "for", "epoch", "in", "range", "(", "self", ".", "start_epoch", ",", "self", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "print", "(", "\"Epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "_train_epoch", "(", "epoch", ")", "\n", "\n", "if", "epoch", "%", "self", ".", "config", ".", "val_period", "==", "0", ":", "\n", "                ", "valid_outs", "=", "self", ".", "_validate_epoch", "(", "epoch", ")", "\n", "\n", "", "if", "epoch", "%", "self", ".", "save_period", "==", "0", ":", "\n", "                ", "self", ".", "_save_checkpoint", "(", "epoch", ")", "\n", "\n", "", "", "print", "(", "'models have been saved to {}'", ".", "format", "(", "self", ".", "save_dir", ")", ")", "\n", "print", "(", "'================= Training finished =================\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer.ModelTrainer._train_epoch": [[63, 123], ["model_trainer.ModelTrainer.model.train", "trainer.MetricLogger", "trainer.MetricLogger.add_meter", "enumerate", "trainer.SmoothedValue", "trainer.MetricLogger.log_every", "list", "model_trainer.ModelTrainer.optimizer.zero_grad", "model_trainer.ModelTrainer.model", "sum", "sum.backward", "torch.nn.utils.clip_grad_norm_", "model_trainer.ModelTrainer.optimizer.step", "trainer.reduce_dict", "sum", "sum.item", "trainer.MetricLogger.update", "trainer.MetricLogger.update", "max", "model_trainer.ModelTrainer.model.parameters", "trainer.reduce_dict.keys", "model_trainer.ModelTrainer.writer.add_scalar", "math.isfinite", "print", "print", "sys.exit", "model_trainer.ModelTrainer.lr_scheduler.step", "image.to().detach", "v.to().detach", "model_trainer.ModelTrainer.writer.add_scalar", "model_trainer.ModelTrainer.writer.add_scalar", "t.items", "model_trainer.ModelTrainer.values", "trainer.reduce_dict.values", "image.to", "v.to", "model_trainer.ModelTrainer.lr_scheduler.get_lr", "float"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.add_meter", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.log_every", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.reduce_dict", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.update", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.update", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.scheduler.AnnealingStepLR.get_lr"], ["", "def", "_train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Training logic for an epoch\n        :param epoch: Current training epoch.\n        :return: A log that contains all information you want to save.\n        \"\"\"", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "metric_logger", "=", "utils", ".", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "metric_logger", ".", "add_meter", "(", "'lr'", ",", "utils", ".", "SmoothedValue", "(", "window_size", "=", "1", ",", "fmt", "=", "'{value:.6f}'", ")", ")", "\n", "header", "=", "'Epoch: [{}]'", ".", "format", "(", "epoch", ")", "\n", "iter_count", "=", "(", "epoch", "-", "1", ")", "*", "self", ".", "step_per_epoch", "\n", "\n", "for", "bid", ",", "(", "images", ",", "targets", ")", "in", "enumerate", "(", "\n", "metric_logger", ".", "log_every", "(", "self", ".", "train_loader", ",", "self", ".", "config", ".", "log_period", ",", "len_iter", "=", "self", ".", "step_per_epoch", ",", "\n", "header", "=", "header", ")", ")", ":", "\n", "            ", "images", "=", "list", "(", "image", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "for", "image", "in", "images", ")", "\n", "targets", "=", "[", "{", "k", ":", "v", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "for", "k", ",", "v", "in", "t", ".", "items", "(", ")", "}", "for", "t", "in", "targets", "]", "\n", "\n", "if", "self", ".", "config", ".", "temperature", "!=", "0.0", ":", "\n", "                ", "std_global", "=", "max", "(", "self", ".", "config", ".", "temperature", "*", "(", "1.0", "-", "float", "(", "iter_count", "+", "bid", ")", "/", "20000.0", ")", ",", "\n", "self", ".", "config", ".", "pixel_sigma", ")", "\n", "", "else", ":", "\n", "                ", "std_global", "=", "self", ".", "config", ".", "pixel_sigma", "\n", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss_dict", "=", "self", ".", "model", "(", "images", ",", "targets", ",", "std", "=", "std_global", ")", "\n", "losses", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "# --- back prop gradients ---", "\n", "losses", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "5.0", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# reduce losses over all GPUs for logging purposes", "\n", "loss_dict_reduced", "=", "utils", ".", "reduce_dict", "(", "loss_dict", ")", "\n", "\n", "# logging ins", "\n", "if", "self", ".", "writer", "is", "not", "None", ":", "\n", "                ", "for", "kwd", "in", "loss_dict_reduced", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "'train/{}'", ".", "format", "(", "kwd", ")", ",", "loss_dict_reduced", "[", "kwd", "]", ",", "iter_count", "+", "bid", ")", "\n", "", "self", ".", "writer", ".", "add_scalar", "(", "'std_annealing'", ",", "std_global", ",", "iter_count", "+", "bid", ")", "\n", "\n", "", "losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict_reduced", ".", "values", "(", ")", ")", "\n", "loss_value", "=", "losses_reduced", ".", "item", "(", ")", "\n", "\n", "if", "not", "math", ".", "isfinite", "(", "loss_value", ")", ":", "\n", "                ", "print", "(", "\"Loss is {}, stopping training\"", ".", "format", "(", "loss_value", ")", ")", "\n", "print", "(", "loss_dict_reduced", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "if", "self", ".", "writer", "is", "not", "None", ":", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "'lr/optimizer'", ",", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "iter_count", "+", "bid", ")", "\n", "\n", "", "", "metric_logger", ".", "update", "(", "loss", "=", "losses_reduced", ",", "**", "loss_dict_reduced", ")", "\n", "metric_logger", ".", "update", "(", "lr", "=", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ")", "\n", "\n", "if", "bid", "==", "self", ".", "step_per_epoch", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer.ModelTrainer._validate_epoch": [[124, 142], ["model_trainer.ModelTrainer.model.eval", "os.path.join", "torch.no_grad", "next", "list", "model_trainer.ModelTrainer.model.predict", "os.path.exists", "os.mkdir", "iter", "image.to", "v.to", "t.items"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.predict", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir"], ["", "", "", "def", "_validate_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Validate model on validation data and save visual results for checking\n        :return: a dict of model's output\n        \"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "epoch", "%", "self", ".", "config", ".", "show_period", "==", "0", ":", "\n", "            ", "vis_epo_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "vis_train_dir", ",", "'epoch_{}'", ".", "format", "(", "epoch", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "vis_epo_dir", ")", ":", "\n", "                ", "os", ".", "mkdir", "(", "vis_epo_dir", ")", "\n", "", "", "else", ":", "\n", "            ", "vis_epo_dir", "=", "None", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "images", ",", "targets", "=", "next", "(", "iter", "(", "self", ".", "valid_loader", ")", ")", "\n", "images", "=", "list", "(", "image", ".", "to", "(", "self", ".", "device", ")", "for", "image", "in", "images", ")", "\n", "targets", "=", "[", "{", "k", ":", "v", ".", "to", "(", "self", ".", "device", ")", "for", "k", ",", "v", "in", "t", ".", "items", "(", ")", "}", "for", "t", "in", "targets", "]", "\n", "val_outs", "=", "self", ".", "model", ".", "predict", "(", "images", ",", "targets", ",", "save_sample_to", "=", "vis_epo_dir", ")", "\n", "", "return", "val_outs", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer.ModelTrainer._save_checkpoint": [[143, 157], ["os.path.abspath", "torch.save", "model_trainer.ModelTrainer.model.state_dict", "model_trainer.ModelTrainer.optimizer.state_dict", "os.path.join"], "methods", ["None"], ["", "def", "_save_checkpoint", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Saving checkpoints\n\n        :param epoch: current epoch number\n        \"\"\"", "\n", "d", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'model'", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "filename", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "\n", "'checkpoint-epoch{}.pth'", ".", "format", "(", "epoch", ")", ")", ")", "\n", "torch", ".", "save", "(", "d", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer.ModelTrainer._resume_checkpoint": [[158, 170], ["torch.load", "model_trainer.ModelTrainer.model.load_state_dict", "optimizer.load_state_dict"], "methods", ["None"], ["", "def", "_resume_checkpoint", "(", "self", ",", "resume_path", ",", "optimizer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Resume from saved checkpoints\n\n        :param resume_path: Checkpoint path to be resumed\n        :param optimizer: Specify whether using a new optimizer if provided or stick with the previous\n        \"\"\"", "\n", "ckpt", "=", "torch", ".", "load", "(", "resume_path", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "ckpt", "[", "'model'", "]", ",", "strict", "=", "True", ")", "\n", "self", ".", "start_epoch", "=", "ckpt", "[", "'epoch'", "]", "\n", "if", "optimizer", "is", "not", "None", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer'", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer_parallel.ModelTrainer.__init__": [[14, 45], ["trainer.base_trainer.BaseTrainer.__init__", "len", "trainer.inf_loop", "model_trainer_parallel.ModelTrainer.lr_scheduler.get_lr"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.utils.inf_loop", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.scheduler.AnnealingStepLR.get_lr"], ["def", "__init__", "(", "self", ",", "model", ",", "loss", ",", "metrics", ",", "optimizer", ",", "config", ",", "train_data_loader", ",", "\n", "valid_data_loader", "=", "None", ",", "lr_scheduler", "=", "None", ",", "step_per_epoch", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "loss", ",", "metrics", ",", "optimizer", ",", "config", ",", "device", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "train_loader", "=", "train_data_loader", "\n", "if", "step_per_epoch", "is", "None", ":", "\n", "# epoch-based training", "\n", "            ", "self", ".", "step_per_epoch", "=", "len", "(", "self", ".", "train_loader", ")", "\n", "", "elif", "step_per_epoch", ":", "\n", "# iteration-based training", "\n", "            ", "self", ".", "train_loader", "=", "inf_loop", "(", "self", ".", "train_loader", ")", "# Reusable iterator", "\n", "self", ".", "step_per_epoch", "=", "step_per_epoch", "\n", "\n", "", "self", ".", "do_validation", "=", "valid_data_loader", "is", "not", "None", "\n", "if", "self", ".", "do_validation", ":", "\n", "            ", "self", ".", "valid_loader", "=", "valid_data_loader", "\n", "\n", "", "self", ".", "save_period", "=", "config", ".", "save_period", "\n", "self", ".", "lr_scheduler", "=", "lr_scheduler", "\n", "\n", "if", "self", ".", "config", ".", "resume_epoch", "is", "not", "None", ":", "\n", "            ", "self", ".", "start_epoch", "=", "self", ".", "config", ".", "resume_epoch", "+", "1", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "last_epoch", "=", "self", ".", "config", ".", "resume_epoch", "*", "self", ".", "step_per_epoch", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "\n", "# self.save_dir has been declared in parenthese", "\n", "", "", "assert", "config", ".", "vis_train_dir", "is", "not", "None", "\n", "self", ".", "vis_train_dir", "=", "config", ".", "vis_train_dir", "\n", "assert", "config", ".", "generated_dir", "is", "not", "None", "\n", "self", ".", "generated_dir", "=", "config", ".", "generated_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer_parallel.ModelTrainer.train": [[46, 62], ["print", "range", "print", "print", "print", "model_trainer_parallel.ModelTrainer._train_epoch", "model_trainer_parallel.ModelTrainer._validate_epoch", "model_trainer_parallel.ModelTrainer._save_checkpoint"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer._train_epoch", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer_parallel.ModelTrainer._validate_epoch", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer._save_checkpoint"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "print", "(", "'\\n================== Start training ==================='", ")", "\n", "# self.start_time = time.time()", "\n", "assert", "(", "self", ".", "epochs", "+", "1", ")", ">", "self", ".", "start_epoch", "\n", "for", "epoch", "in", "range", "(", "self", ".", "start_epoch", ",", "self", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "print", "(", "\"Epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "_train_epoch", "(", "epoch", ")", "\n", "\n", "if", "epoch", "%", "self", ".", "config", ".", "val_period", "==", "0", ":", "\n", "                ", "valid_outs", "=", "self", ".", "_validate_epoch", "(", "epoch", ")", "\n", "\n", "", "if", "epoch", "%", "self", ".", "save_period", "==", "0", ":", "\n", "                ", "self", ".", "_save_checkpoint", "(", "epoch", ")", "\n", "\n", "", "", "print", "(", "'models have been saved to {}'", ".", "format", "(", "self", ".", "save_dir", ")", ")", "\n", "print", "(", "'================= Training finished =================\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer_parallel.ModelTrainer._train_epoch": [[63, 121], ["model_trainer_parallel.ModelTrainer.model.train", "trainer.MetricLogger", "trainer.MetricLogger.add_meter", "enumerate", "trainer.SmoothedValue", "trainer.MetricLogger.log_every", "list", "model_trainer_parallel.ModelTrainer.optimizer.zero_grad", "model_trainer_parallel.ModelTrainer.model", "sum", "sum.backward", "torch.nn.utils.clip_grad_norm_", "model_trainer_parallel.ModelTrainer.optimizer.step", "trainer.reduce_dict", "sum", "sum.item", "trainer.MetricLogger.update", "trainer.MetricLogger.update", "max", "model_trainer_parallel.ModelTrainer.model.parameters", "trainer.reduce_dict.keys", "model_trainer_parallel.ModelTrainer.writer.add_scalar", "math.isfinite", "print", "print", "sys.exit", "model_trainer_parallel.ModelTrainer.lr_scheduler.step", "image.to().detach", "v.to().detach", "model_trainer_parallel.ModelTrainer.writer.add_scalar", "model_trainer_parallel.ModelTrainer.writer.add_scalar", "t.items", "model_trainer_parallel.ModelTrainer.values", "trainer.reduce_dict.values", "image.to", "v.to", "model_trainer_parallel.ModelTrainer.lr_scheduler.get_lr", "float"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.add_meter", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.log_every", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.reduce_dict", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.update", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.MetricLogger.update", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.SmoothedValue.max", "home.repos.pwc.inspect_result.NanboLi_MulMON.None.scheduler.AnnealingStepLR.get_lr"], ["", "def", "_train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Training logic for an epoch\n        :param epoch: Current training epoch.\n        :return: A log that contains all information you want to save.\n        \"\"\"", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "metric_logger", "=", "utils", ".", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "metric_logger", ".", "add_meter", "(", "'lr'", ",", "utils", ".", "SmoothedValue", "(", "window_size", "=", "1", ",", "fmt", "=", "'{value:.6f}'", ")", ")", "\n", "header", "=", "'Epoch: [{}]'", ".", "format", "(", "epoch", ")", "\n", "iter_count", "=", "(", "epoch", "-", "1", ")", "*", "self", ".", "step_per_epoch", "\n", "\n", "for", "bid", ",", "(", "images", ",", "targets", ")", "in", "enumerate", "(", "metric_logger", ".", "log_every", "(", "self", ".", "train_loader", ",", "self", ".", "config", ".", "log_period", ",", "len_iter", "=", "self", ".", "step_per_epoch", ",", "header", "=", "header", ")", ")", ":", "\n", "            ", "images", "=", "list", "(", "image", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "for", "image", "in", "images", ")", "\n", "targets", "=", "[", "{", "k", ":", "v", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "for", "k", ",", "v", "in", "t", ".", "items", "(", ")", "}", "for", "t", "in", "targets", "]", "\n", "\n", "if", "self", ".", "config", ".", "temperature", "!=", "0.0", ":", "\n", "                ", "std_global", "=", "max", "(", "self", ".", "config", ".", "temperature", "*", "(", "1.0", "-", "float", "(", "iter_count", "+", "bid", ")", "/", "20000.0", ")", ",", "\n", "self", ".", "config", ".", "pixel_sigma", ")", "\n", "", "else", ":", "\n", "                ", "std_global", "=", "self", ".", "config", ".", "pixel_sigma", "\n", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss_dict", "=", "self", ".", "model", "(", "images", ",", "targets", ",", "std", "=", "std_global", ")", "\n", "losses", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "# --- back prop gradients ---", "\n", "losses", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "5.0", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# reduce losses over all GPUs for logging purposes", "\n", "loss_dict_reduced", "=", "utils", ".", "reduce_dict", "(", "loss_dict", ")", "\n", "\n", "# logging ins", "\n", "if", "self", ".", "writer", "is", "not", "None", ":", "\n", "                ", "for", "kwd", "in", "loss_dict_reduced", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "'train/{}'", ".", "format", "(", "kwd", ")", ",", "loss_dict_reduced", "[", "kwd", "]", ",", "iter_count", "+", "bid", ")", "\n", "", "self", ".", "writer", ".", "add_scalar", "(", "'std_annealing'", ",", "std_global", ",", "iter_count", "+", "bid", ")", "\n", "\n", "", "losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict_reduced", ".", "values", "(", ")", ")", "\n", "loss_value", "=", "losses_reduced", ".", "item", "(", ")", "\n", "\n", "if", "not", "math", ".", "isfinite", "(", "loss_value", ")", ":", "\n", "                ", "print", "(", "\"Loss is {}, stopping training\"", ".", "format", "(", "loss_value", ")", ")", "\n", "print", "(", "loss_dict_reduced", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "if", "self", ".", "writer", "is", "not", "None", ":", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "'lr/optimizer'", ",", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "iter_count", "+", "bid", ")", "\n", "\n", "", "", "metric_logger", ".", "update", "(", "loss", "=", "losses_reduced", ",", "**", "loss_dict_reduced", ")", "\n", "metric_logger", ".", "update", "(", "lr", "=", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ")", "\n", "\n", "if", "bid", "==", "self", ".", "step_per_epoch", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer_parallel.ModelTrainer._validate_epoch": [[122, 140], ["model_trainer_parallel.ModelTrainer.model.eval", "os.path.join", "torch.no_grad", "next", "list", "model_trainer_parallel.ModelTrainer.model.module.predict", "os.path.exists", "os.mkdir", "iter", "image.to", "v.to", "t.items"], "methods", ["home.repos.pwc.inspect_result.NanboLi_MulMON.models.mulmon.MulMON.predict", "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer._utils.mkdir"], ["", "", "", "def", "_validate_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Validate model on validation data and save visual results for checking\n        :return: a dict of model's output\n        \"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "epoch", "%", "self", ".", "config", ".", "show_period", "==", "0", "and", "self", ".", "device_id", "==", "self", ".", "config", ".", "gpu_start", ":", "\n", "            ", "vis_epo_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "vis_train_dir", ",", "'epoch_{}_gpu{}'", ".", "format", "(", "epoch", ",", "self", ".", "device_id", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "vis_epo_dir", ")", ":", "\n", "                ", "os", ".", "mkdir", "(", "vis_epo_dir", ")", "\n", "", "", "else", ":", "\n", "            ", "vis_epo_dir", "=", "None", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "images", ",", "targets", "=", "next", "(", "iter", "(", "self", ".", "valid_loader", ")", ")", "\n", "images", "=", "list", "(", "image", ".", "to", "(", "self", ".", "device", ")", "for", "image", "in", "images", ")", "\n", "targets", "=", "[", "{", "k", ":", "v", ".", "to", "(", "self", ".", "device", ")", "for", "k", ",", "v", "in", "t", ".", "items", "(", ")", "}", "for", "t", "in", "targets", "]", "\n", "val_outs", "=", "self", ".", "model", ".", "module", ".", "predict", "(", "images", ",", "targets", ",", "save_sample_to", "=", "vis_epo_dir", ")", "\n", "", "return", "val_outs", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer_parallel.ModelTrainer._save_checkpoint": [[141, 155], ["os.path.abspath", "torch.save", "model_trainer_parallel.ModelTrainer.model.module.state_dict", "model_trainer_parallel.ModelTrainer.optimizer.state_dict", "os.path.join"], "methods", ["None"], ["", "def", "_save_checkpoint", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Saving checkpoints\n\n        :param epoch: current epoch number\n        \"\"\"", "\n", "d", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'model'", ":", "self", ".", "model", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n", "filename", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "\n", "'checkpoint-epoch{}.pth'", ".", "format", "(", "epoch", ")", ")", ")", "\n", "torch", ".", "save", "(", "d", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.model_trainer_parallel.ModelTrainer._resume_checkpoint": [[156, 168], ["torch.load", "model_trainer_parallel.ModelTrainer.model.load_state_dict", "optimizer.load_state_dict"], "methods", ["None"], ["", "def", "_resume_checkpoint", "(", "self", ",", "resume_path", ",", "optimizer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Resume from saved checkpoints\n\n        :param resume_path: Checkpoint path to be resumed\n        :param optimizer: Specify whether using a new optimizer if provided or stick with the previous\n        \"\"\"", "\n", "ckpt", "=", "torch", ".", "load", "(", "resume_path", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "ckpt", "[", "'model'", "]", ",", "strict", "=", "True", ")", "\n", "self", ".", "start_epoch", "=", "ckpt", "[", "'epoch'", "]", "\n", "if", "optimizer", "is", "not", "None", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer'", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.__init__": [[17, 43], ["model.to", "torch.utils.tensorboard.writer.SummaryWriter", "type", "torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "loss", ",", "metrics", ",", "optimizer", ",", "config", ",", "device", "=", "None", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "if", "type", "(", "device", ")", "==", "int", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:{}\"", ".", "format", "(", "device", ")", ")", "\n", "self", ".", "device_id", "=", "device", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "device", "\n", "", "self", ".", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "loss", "=", "loss", "\n", "if", "metrics", ":", "\n", "            ", "self", ".", "metrics", "=", "metrics", "\n", "self", ".", "has_metric", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "has_metric", "=", "False", "\n", "", "self", ".", "optimizer", "=", "optimizer", "\n", "\n", "self", ".", "start_epoch", "=", "1", "\n", "self", ".", "epochs", "=", "config", ".", "num_epochs", "\n", "assert", "config", ".", "save_dir", "is", "not", "None", "\n", "self", ".", "save_dir", "=", "config", ".", "save_dir", "\n", "self", ".", "vis_train_dir", "=", "config", ".", "vis_train_dir", "\n", "self", ".", "generated_dir", "=", "config", ".", "generated_dir", "\n", "\n", "# setup visualization writer instance", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "self", ".", "save_dir", ",", "max_queue", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer._train_epoch": [[44, 56], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Training logic for an epoch\n\n        example return:\n            result = {\n                      'loss':  0.0,\n                      'metric': 1.0,\n                      }\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer.train": [[57, 69], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\" Main training loop contained\n        E.g.\n        for epoch in range(self.start_epoch, self.epochs + 1):\n            result = self._train_epoch(epoch)\n            printing ...(result)\n\n            if epoch % self.save_period == 0:\n                    self._save_checkpoint(epoch)\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer._prepare_device": [[70, 72], ["None"], "methods", ["None"], ["", "def", "_prepare_device", "(", "self", ",", "use_gpu", "=", "[", "]", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer._save_checkpoint": [[73, 82], ["None"], "methods", ["None"], ["", "def", "_save_checkpoint", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Saving checkpoints\n\n        :param epoch: current epoch number\n        :param log: logging information of the epoch\n        :param save_best: if True, rename the saved checkpoint to 'model_best.pth'\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.BaseTrainer._resume_checkpoint": [[83, 90], ["None"], "methods", ["None"], ["", "def", "_resume_checkpoint", "(", "self", ",", "resume_path", ")", ":", "\n", "        ", "\"\"\"\n        Resume from saved checkpoints\n\n        :param resume_path: Checkpoint path to be resumed\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NanboLi_MulMON.trainer.base_trainer.func": [[8, 11], ["torch.nn.DataParallel"], "function", ["None"], ["def", "func", "(", "m", ")", ":", "\n", "    ", "m", "=", "torch", ".", "nn", ".", "DataParallel", "(", "m", ",", "device_ids", "=", "[", "0", ",", "1", "]", ")", "\n", "return", "m", "\n", "\n"]]}