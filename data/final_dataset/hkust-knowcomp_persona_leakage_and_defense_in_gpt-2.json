{"home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.PersonaDataset.__init__": [[45, 49], ["tokenizer.encode"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "turn_ending", "=", "tokenizer", ".", "encode", "(", "'<|endoftext|>'", ")", "# dialogpt pretrain approach", "\n", "#self.turn_ending = [628, 198] #628:\\n\\n 198:\\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.PersonaDataset.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.PersonaDataset.__getitem__": [[53, 64], ["len", "len", "tokenizer.encode", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "conv", "=", "self", ".", "data", "[", "index", "]", "[", "'conv'", "]", "\n", "dial_tokens", "=", "[", "tokenizer", ".", "encode", "(", "item", ")", "+", "self", ".", "turn_ending", "for", "item", "in", "conv", "]", "\n", "role_ids", "=", "[", "0", ",", "1", "]", "*", "(", "len", "(", "conv", ")", "//", "2", ")", "\n", "\n", "#for labels", "\n", "labels", "=", "self", ".", "data", "[", "index", "]", "[", "'labels'", "]", "\n", "\n", "assert", "len", "(", "role_ids", ")", "==", "len", "(", "dial_tokens", ")", "\n", "return", "role_ids", ",", "dial_tokens", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.PersonaDataset.collate": [[65, 67], ["None"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "unpacked_data", ")", ":", "\n", "        ", "return", "unpacked_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.SequenceCrossEntropyLoss.__init__": [[70, 72], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.SequenceCrossEntropyLoss.forward": [[73, 78], ["training_dialogpt_defense.sequence_cross_entropy_with_logits"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.sequence_cross_entropy_with_logits"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", "=", "-", "1", ",", "reduce", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        reduce: None, \"batch\", \"sentence\"\n        \"\"\"", "\n", "return", "sequence_cross_entropy_with_logits", "(", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", ",", "reduce", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.persona_predict_model.__init__": [[80, 83], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_num", "=", "1024", ",", "out_num", "=", "8", ")", ":", "\n", "        ", "super", "(", "persona_predict_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_num", ",", "out_num", ")", "\n", "#self.act = F.softmax()", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.persona_predict_model.forward": [[85, 100], ["training_dialogpt_defense.persona_predict_model.fc1", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.size", "torch.mean.size", "torch.mean.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "out_shape", "=", "x", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "if", "(", "use_final_hidden_only", ")", ":", "\n", "# avg the info ", "\n", "            ", "x", "=", "torch", ".", "unsqueeze", "(", "x", "[", "-", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "", "assert", "(", "x", ".", "size", "(", ")", "[", "1", "]", "==", "out_shape", ")", "\n", "out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "#out = F.softmax(self.fc1(x),dim=1)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.persona_predict_model_2layer.__init__": [[102, 108], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_num", ",", "in_num", "=", "1024", ")", ":", "\n", "        ", "super", "(", "persona_predict_model_2layer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "hidden", "=", "512", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_num", ",", "hidden", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden", ",", "out_num", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "#self.act = F.softmax()", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.persona_predict_model_2layer.forward": [[110, 127], ["training_dialogpt_defense.persona_predict_model_2layer.fc1", "training_dialogpt_defense.persona_predict_model_2layer.relu", "training_dialogpt_defense.persona_predict_model_2layer.fc2", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.size", "torch.mean.size", "torch.mean.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "out_shape", "=", "x", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "if", "(", "use_final_hidden_only", ")", ":", "\n", "# avg the info ", "\n", "            ", "x", "=", "torch", ".", "unsqueeze", "(", "x", "[", "-", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "", "assert", "(", "x", ".", "size", "(", ")", "[", "1", "]", "==", "out_shape", ")", "\n", "out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "fc2", "(", "out", ")", "\n", "#out = F.softmax(self.fc1(x),dim=1)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.persona_predict_model_transformer.__init__": [[129, 133], ["torch.Module.__init__", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_num", ",", "in_num", "=", "1024", ")", ":", "\n", "        ", "super", "(", "persona_predict_model_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder_layer", "=", "nn", ".", "TransformerEncoderLayer", "(", "d_model", "=", "1024", ",", "nhead", "=", "8", ")", "#1024 as output", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "1024", ",", "out_num", ")", "\n", "#self.fc1 = nn.Linear(in_num, out_num)", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.persona_predict_model_transformer.forward": [[136, 154], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "training_dialogpt_defense.persona_predict_model_transformer.encoder_layer", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "training_dialogpt_defense.persona_predict_model_transformer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "x_resize", "=", "torch", ".", "unsqueeze", "(", "x", ",", "0", ")", "\n", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "#assert(x.size()[1] == out_shape)", "\n", "out", "=", "self", ".", "encoder_layer", "(", "x_resize", ")", "\n", "out_squeeze", "=", "torch", ".", "squeeze", "(", "out", ",", "0", ")", "\n", "# use avg hidden", "\n", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "final_out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "#print(f'before encoder: {x_resize.size()}')", "\n", "#print(f'after encoder: {out.shape}')", "\n", "#print(f'after squeeze: {out_squeeze.shape}')", "\n", "#print(f'after fc1: {x.shape}')", "\n", "#print(f'final out: {final_out.shape}')", "\n", "return", "final_out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.get_processed_persona": [[34, 43], ["open", "json.load"], "function", ["None"], ["def", "get_processed_persona", "(", "kind", ",", "require_label", "=", "True", ")", ":", "\n", "#processed_persona_path = config.processed_persona", "\n", "    ", "if", "(", "require_label", ")", ":", "\n", "        ", "path", "=", "processed_persona_path", "+", "'/%s_merged_shuffle.txt'", "%", "kind", "\n", "", "else", ":", "\n", "        ", "path", "=", "processed_persona_path", "+", "'/%s.txt'", "%", "kind", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.sequence_cross_entropy_with_logits": [[156, 196], ["logits.view", "torch.log_softmax", "targets.view().long", "negative_log_likelihood_flat.sum.view", "logits.size", "logits.size", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "negative_log_likelihood_flat.sum.sum", "targets.view", "float", "torch.gather", "torch.gather", "torch.gather", "loss.mean.sum", "loss.mean.mean", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "mask.sum"], "function", ["None"], ["", "", "def", "sequence_cross_entropy_with_logits", "(", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", ",", "reduce", ")", ":", "\n", "# type: (Tensor, Tensor, Tensor, float, bool)-> Tensor", "\n", "    ", "\"\"\"\n    label_smoothing : ``float``, optional (default = 0.0)\n        It should be smaller than 1.\n    \"\"\"", "\n", "# shape : (batch * sequence_length, num_classes)", "\n", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "\n", "# shape : (batch * sequence_length, num_classes)", "\n", "log_probs_flat", "=", "F", ".", "log_softmax", "(", "logits_flat", ",", "dim", "=", "-", "1", ")", "\n", "# shape : (batch * max_len, 1)", "\n", "targets_flat", "=", "targets", ".", "view", "(", "-", "1", ",", "1", ")", ".", "long", "(", ")", "\n", "\n", "if", "label_smoothing", ">", "0.0", ":", "\n", "        ", "num_classes", "=", "logits", ".", "size", "(", "-", "1", ")", "\n", "smoothing_value", "=", "label_smoothing", "/", "float", "(", "num_classes", ")", "\n", "# Fill all the correct indices with 1 - smoothing value.", "\n", "one_hot_targets", "=", "torch", ".", "zeros_like", "(", "log_probs_flat", ")", ".", "scatter_", "(", "-", "1", ",", "targets_flat", ",", "1.0", "-", "label_smoothing", ")", "\n", "smoothed_targets", "=", "one_hot_targets", "+", "smoothing_value", "\n", "negative_log_likelihood_flat", "=", "-", "log_probs_flat", "*", "smoothed_targets", "\n", "negative_log_likelihood_flat", "=", "negative_log_likelihood_flat", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "# shape : (batch * sequence_length, 1)", "\n", "        ", "negative_log_likelihood_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "targets_flat", ")", "\n", "\n", "# shape : (batch, sequence_length)", "\n", "", "negative_log_likelihood", "=", "negative_log_likelihood_flat", ".", "view", "(", "-", "1", ",", "logits", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# shape : (batch, sequence_length)", "\n", "loss", "=", "negative_log_likelihood", "*", "mask", "\n", "\n", "if", "reduce", ":", "\n", "# shape : (batch,)", "\n", "        ", "loss", "=", "loss", ".", "sum", "(", "1", ")", "/", "(", "mask", ".", "sum", "(", "1", ")", "+", "1e-13", ")", "\n", "\n", "if", "reduce", "is", "\"batch\"", ":", "\n", "# shape : scalar", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.train_one_iter": [[198, 292], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "all_logits[].contiguous", "[].contiguous", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "criterion", "numpy.exp", "print", "criterion.backward", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "criterion.item", "max", "print", "print", "model_A", "all_logits[].contiguous.append", "model_A", "all_logits[].contiguous.append", "torch.squeeze", "torch.squeeze", "torch.squeeze", "external_model", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.CrossEntropyLoss", "nn.CrossEntropyLoss.", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "external_model.size", "torch.softmax", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.log", "torch.log", "torch.log", "torch.mean", "torch.mean", "torch.mean", "opt_attacker.zero_grad", "attacker_loss.backward", "opt_attacker.step", "scheduler_attacker.step", "opt_attacker.zero_grad", "optimizer.zero_grad", "torch.cat", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "function", ["None"], ["", "def", "train_one_iter", "(", "external_model", ",", "batch", ",", "update_count", ",", "fp16", "=", "False", ",", "require_KL_loss", "=", "False", ",", "KL_ratio", "=", "KL_ratio", ",", "ga_ratio", "=", "GA_ratio", ",", "require_GA", "=", "require_GA", ",", "require_GA_loss", "=", "require_GA_loss", ")", ":", "\n", "    ", "role_ids", ",", "dialog_tokens", ",", "labels", "=", "batch", "\n", "dial_inputs", "=", "[", "torch", ".", "LongTensor", "(", "item", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "for", "item", "in", "dialog_tokens", "]", "\n", "\n", "past", "=", "None", "\n", "all_logits", "=", "[", "]", "\n", "\n", "temp_sum", "=", "0", "\n", "\n", "running_loss", "=", "0.0", "\n", "for", "turn_num", ",", "dial_turn_inputs", "in", "enumerate", "(", "dial_inputs", ")", ":", "\n", "        ", "temp_sum", "+=", "1", "\n", "if", "role_ids", "[", "turn_num", "]", "==", "0", ":", "\n", "\n", "#logits, past = model_A(dial_turn_inputs, past=past)", "\n", "            ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "# hidden:torch.Size([1, 6, 1024])", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "#now let's move to external module", "\n", "", "if", "(", "labels", "[", "turn_num", "]", ">=", "0", ")", ":", "\n", "            ", "hidden_out", "=", "torch", ".", "squeeze", "(", "hidden", "[", "-", "1", "]", ",", "0", ")", "\n", "external_out", "=", "external_model", "(", "hidden_out", ")", "\n", "assert", "external_out", ".", "ndim", "==", "2", "\n", "num_labels", "=", "external_out", ".", "size", "(", ")", "[", "1", "]", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "labels", "[", "turn_num", "]", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "#print('label: ',label)", "\n", "#print('external_out: ',external_out.size())", "\n", "external_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "external_loss", "=", "external_criterion", "(", "external_out", ",", "label", ")", "\n", "# gradient ascending use '-'", "\n", "if", "(", "require_GA_loss", ")", ":", "\n", "                ", "running_loss", "-=", "external_loss", "\n", "", "if", "(", "require_KL_loss", ")", ":", "\n", "                ", "KL_loss", "=", "F", ".", "softmax", "(", "external_out", ",", "dim", "=", "1", ")", "\n", "KL_loss", "=", "torch", ".", "squeeze", "(", "KL_loss", ",", "0", ")", "\n", "KL_loss", "=", "torch", ".", "log", "(", "KL_loss", ")", "\n", "KL_loss", "=", "torch", ".", "mean", "(", "KL_loss", ")", "\n", "# KL divergence with uniform distribution", "\n", "# running_loss -= KL_ratio * KL_loss", "\n", "# No Gradient Ascending", "\n", "if", "(", "require_GA", ")", ":", "\n", "                    ", "running_loss", "-=", "KL_ratio", "*", "KL_loss", "\n", "", "else", ":", "\n", "                    ", "running_loss", "=", "KL_ratio", "*", "KL_loss", "\n", "\n", "\n", "# optmizing attacker part", "\n", "", "", "if", "(", "use_attacker_GD", ")", ":", "\n", "                ", "attacker_loss", "=", "ga_ratio", "*", "attacker_ratio", "*", "external_loss", "\n", "opt_attacker", ".", "zero_grad", "(", ")", "\n", "attacker_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "opt_attacker", ".", "step", "(", ")", "\n", "scheduler_attacker", ".", "step", "(", ")", "\n", "# make sure no grad for GPT optimizer", "\n", "opt_attacker", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "\n", "", "", "", "all_logits", "=", "torch", ".", "cat", "(", "all_logits", ",", "dim", "=", "1", ")", "#torch.Size([1, 611, 50257])", "\n", "#print(all_logits.size())", "\n", "# sys.exit(0)", "\n", "\n", "\n", "\n", "# target", "\n", "all_logits", "=", "all_logits", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "torch", ".", "cat", "(", "dial_inputs", ",", "dim", "=", "1", ")", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "target_mask", "=", "torch", ".", "ones_like", "(", "target", ")", ".", "float", "(", ")", "\n", "\n", "\n", "loss", "=", "criterion", "(", "all_logits", ",", "target", ",", "target_mask", ",", "label_smoothing", "=", "0.02", ",", "reduce", "=", "\"batch\"", ")", "\n", "loss", "/=", "num_gradients_accumulation", "\n", "record_loss", "=", "loss", ".", "item", "(", ")", "*", "num_gradients_accumulation", "\n", "perplexity", "=", "np", ".", "exp", "(", "record_loss", ")", "\n", "print", "(", "'training loss: '", ",", "loss", ",", "'PPL'", ",", "perplexity", ")", "\n", "#print('training loss: ', loss)", "\n", "#add external", "\n", "if", "(", "max", "(", "labels", ")", ">=", "0", ")", ":", "\n", "#lm_loss += loss", "\n", "\n", "        ", "loss", "+=", "ga_ratio", "*", "running_loss", "\n", "print", "(", "'---label training with loss: '", ",", "loss", ")", "\n", "print", "(", "'---attacker loss: '", ",", "attacker_loss", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "\n", "return", "record_loss", ",", "perplexity", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_dialogpt_defense.validate": [[294, 377], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "progress_bar", "print", "numpy.mean", "enumerate", "torch.cat", "torch.cat", "torch.cat", "all_logits[].contiguous", "[].contiguous", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "criterion", "torch.exp", "torch.exp", "torch.exp", "total_ppl.extend", "max", "print", "sum", "enumerate", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.exp.tolist", "model_A", "all_logits[].contiguous.append", "model_A", "all_logits[].contiguous.append", "torch.squeeze", "torch.squeeze", "torch.squeeze", "external_model", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.ones_like", "torch.ones_like", "torch.ones_like", "numpy.mean", "numpy.var", "len", "len", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "function", ["None"], ["", "def", "validate", "(", "dataloader", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "pbar", "=", "progress_bar", "(", "dataloader", ")", "\n", "\n", "total_ppl", "=", "[", "]", "\n", "#total_ppl_recommender = []", "\n", "predict_num", "=", "0", "\n", "correct_num", "=", "0", "\n", "\n", "for", "batch", "in", "pbar", ":", "\n", "            ", "if", "sum", "(", "[", "len", "(", "item", ")", "for", "item", "in", "batch", "[", "0", "]", "[", "1", "]", "]", ")", ">", "1024", ":", "\n", "                ", "total_length", "=", "0", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "batch", "[", "0", "]", "[", "1", "]", ")", ":", "\n", "                    ", "total_length", "=", "total_length", "+", "len", "(", "item", ")", "\n", "if", "total_length", ">=", "1024", ":", "\n", "                        ", "batch", "=", "[", "(", "batch", "[", "0", "]", "[", "0", "]", "[", "0", ":", "index", "-", "1", "]", ",", "batch", "[", "0", "]", "[", "1", "]", "[", "0", ":", "index", "-", "1", "]", ")", "]", "\n", "break", "\n", "\n", "", "", "", "role_ids", ",", "dialog_tokens", ",", "labels", "=", "batch", "[", "0", "]", "\n", "dial_inputs", "=", "[", "torch", ".", "LongTensor", "(", "item", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "for", "item", "in", "dialog_tokens", "]", "\n", "#dial_inputs_rec = [torch.LongTensor(item).unsqueeze(0).to(device) for item in dialog_tokens if item[0] == 32]", "\n", "past", "=", "None", "\n", "all_logits", "=", "[", "]", "\n", "#all_logits_rec = []", "\n", "running_loss", "=", "0.0", "\n", "for", "turn_num", ",", "dial_turn_inputs", "in", "enumerate", "(", "dial_inputs", ")", ":", "\n", "                ", "if", "role_ids", "[", "turn_num", "]", "==", "0", ":", "\n", "#logits, past = model_A(dial_turn_inputs, past=past)", "\n", "                    ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "#all_logits_rec.append(logits)", "\n", "", "else", ":", "\n", "\n", "                    ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "#now let's move to external module", "\n", "", "if", "(", "labels", "[", "turn_num", "]", ">=", "0", ")", ":", "\n", "#make prediction here", "\n", "                    ", "predict_num", "+=", "1", "\n", "hidden_out", "=", "torch", ".", "squeeze", "(", "hidden", "[", "-", "1", "]", ",", "0", ")", "\n", "external_out", "=", "external_model", "(", "hidden_out", ")", "\n", "assert", "external_out", ".", "ndim", "==", "2", "\n", "predict_label", "=", "torch", ".", "argmax", "(", "external_out", ")", "\n", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "labels", "[", "turn_num", "]", "]", ")", ".", "to", "(", "device", ")", "\n", "#print('label: ',label)", "\n", "#print('external_out: ',external_out.size())", "\n", "#external_criterion = nn.CrossEntropyLoss()", "\n", "#external_loss = external_criterion(external_out,label)", "\n", "#running_loss += external_loss", "\n", "#print('external_loss passed with loss:',external_loss)", "\n", "if", "(", "predict_label", "==", "label", ")", ":", "\n", "                        ", "correct_num", "+=", "1", "\n", "\n", "", "", "", "all_logits", "=", "torch", ".", "cat", "(", "all_logits", ",", "dim", "=", "1", ")", "\n", "#all_logits_rec = torch.cat(all_logits_rec, dim=1)", "\n", "\n", "\n", "\n", "\n", "# target", "\n", "all_logits", "=", "all_logits", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "torch", ".", "cat", "(", "dial_inputs", ",", "dim", "=", "1", ")", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "target_mask", "=", "torch", ".", "ones_like", "(", "target", ")", ".", "float", "(", ")", "\n", "\n", "\n", "loss", "=", "criterion", "(", "all_logits", ",", "target", ",", "target_mask", ",", "label_smoothing", "=", "-", "1", ",", "reduce", "=", "\"sentence\"", ")", "\n", "\n", "\n", "ppl", "=", "torch", ".", "exp", "(", "loss", ")", "\n", "total_ppl", ".", "extend", "(", "ppl", ".", "tolist", "(", ")", ")", "\n", "\n", "#ppl_recommender = torch.exp(loss_recommender)", "\n", "#total_ppl_recommender.extend(ppl_recommender.tolist())", "\n", "\n", "", "print", "(", "f\"Epcoh {ep} Validation Perplexity: {np.mean(total_ppl)} Variance: {np.var(total_ppl)}\"", ")", "\n", "if", "(", "max", "(", "labels", ")", ">=", "0", ")", ":", "\n", "            ", "acc", "=", "correct_num", "/", "predict_num", "\n", "print", "(", "f\"Epcoh {ep} Validation prediction loss: {acc}\"", ")", "\n", "#print(f\"Epcoh {ep} Validation Perplexity on recommender (A): {np.mean(total_ppl_recommender)} Variance: {np.var(total_ppl_recommender)}\")", "\n", "\n", "", "return", "np", ".", "mean", "(", "total_ppl", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.persona_predict_model.__init__": [[33, 36], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_num", "=", "1024", ",", "out_num", "=", "8", ")", ":", "\n", "        ", "super", "(", "persona_predict_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_num", ",", "out_num", ")", "\n", "#self.act = F.softmax()", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.persona_predict_model.forward": [[38, 53], ["generate.persona_predict_model.fc1", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.size", "torch.mean.size", "torch.mean.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "out_shape", "=", "x", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "if", "(", "use_final_hidden_only", ")", ":", "\n", "# avg the info ", "\n", "            ", "x", "=", "torch", ".", "unsqueeze", "(", "x", "[", "-", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "", "assert", "(", "x", ".", "size", "(", ")", "[", "1", "]", "==", "out_shape", ")", "\n", "out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "#out = F.softmax(self.fc1(x),dim=1)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.PersonaDataset.__init__": [[66, 70], ["tokenizer.encode"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "turn_ending", "=", "tokenizer", ".", "encode", "(", "'<|endoftext|>'", ")", "# dialogpt pretrain approach", "\n", "#self.turn_ending = [628, 198] #628:\\n\\n 198:\\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.PersonaDataset.__len__": [[71, 73], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.PersonaDataset.__getitem__": [[74, 85], ["len", "len", "tokenizer.encode", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "conv", "=", "self", ".", "data", "[", "index", "]", "[", "'conv'", "]", "\n", "dial_tokens", "=", "[", "tokenizer", ".", "encode", "(", "item", ")", "+", "self", ".", "turn_ending", "for", "item", "in", "conv", "]", "\n", "role_ids", "=", "[", "0", ",", "1", "]", "*", "(", "len", "(", "conv", ")", "//", "2", ")", "\n", "\n", "#for labels", "\n", "labels", "=", "self", ".", "data", "[", "index", "]", "[", "'labels'", "]", "\n", "\n", "assert", "len", "(", "role_ids", ")", "==", "len", "(", "dial_tokens", ")", "\n", "return", "role_ids", ",", "dial_tokens", ",", "labels", ",", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.PersonaDataset.collate": [[86, 88], ["None"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "unpacked_data", ")", ":", "\n", "        ", "return", "unpacked_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.get_processed_persona": [[55, 64], ["open", "json.load"], "function", ["None"], ["", "", "def", "get_processed_persona", "(", "kind", ",", "require_label", "=", "True", ")", ":", "\n", "#processed_persona_path = config.processed_persona", "\n", "    ", "if", "(", "require_label", ")", ":", "\n", "        ", "path", "=", "processed_persona_path", "+", "'/%s_merged_shuffle.txt'", "%", "kind", "\n", "", "else", ":", "\n", "        ", "path", "=", "processed_persona_path", "+", "'/%s.txt'", "%", "kind", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.top_filtering": [[91, 123], ["float", "torch.topk", "torch.topk", "torch.topk", "values[].unsqueeze().repeat", "torch.where", "torch.where", "torch.where", "torch.sort", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_logits.masked_fill_.masked_fill_", "torch.zeros_like().scatter", "torch.zeros_like().scatter", "torch.zeros_like().scatter", "torch.softmax", "values[].unsqueeze", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "float"], "function", ["None"], ["", "", "def", "top_filtering", "(", "logits", ",", "top_k", "=", "0", ",", "top_p", "=", "0.0", ",", "filter_value", "=", "-", "float", "(", "'Inf'", ")", ")", ":", "\n", "    ", "\"\"\" Filter a distribution of logits using top-k, top-p (nucleus) and/or threshold filtering\n        Args:\n            logits: logits distribution shape (vocabulary size)\n            top_k: <=0: no filtering, >0: keep only top k tokens with highest probability.\n            top_p: <=0.0: no filtering, >0.0: keep only a subset S of candidates, where S is the smallest subset\n                whose total probability mass is greater than or equal to the threshold top_p.\n                In practice, we select the highest probability tokens whose cumulative probability mass exceeds\n                the threshold top_p.\n    \"\"\"", "\n", "# batch support!", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "values", ",", "_", "=", "torch", ".", "topk", "(", "logits", ",", "top_k", ")", "\n", "min_values", "=", "values", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "logits", ".", "shape", "[", "-", "1", "]", ")", "\n", "logits", "=", "torch", ".", "where", "(", "logits", "<", "min_values", ",", "\n", "torch", ".", "ones_like", "(", "logits", ",", "dtype", "=", "logits", ".", "dtype", ")", "*", "-", "float", "(", "'Inf'", ")", ",", "\n", "logits", ")", "\n", "", "if", "top_p", ">", "0.0", ":", "\n", "# Compute cumulative probabilities of sorted tokens", "\n", "        ", "sorted_logits", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "cumulative_probabilities", "=", "torch", ".", "cumsum", "(", "F", ".", "softmax", "(", "sorted_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Remove tokens with cumulative probability above the threshold", "\n", "sorted_indices_to_remove", "=", "cumulative_probabilities", ">", "top_p", "\n", "# Shift the indices to the right to keep also the first token above the threshold", "\n", "sorted_indices_to_remove", "[", "...", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", "...", ",", "0", "]", "=", "0", "\n", "\n", "sorted_logits", "=", "sorted_logits", ".", "masked_fill_", "(", "sorted_indices_to_remove", ",", "filter_value", ")", "\n", "logits", "=", "torch", ".", "zeros_like", "(", "logits", ")", ".", "scatter", "(", "1", ",", "sorted_indices", ",", "sorted_logits", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.generate_sentence": [[124, 155], ["generate.top_filtering", "torch.softmax", "torch.softmax", "torch.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial.item", "sent.append", "range", "tokenizer.decode", "model_B", "generate.top_filtering", "torch.softmax", "torch.softmax", "torch.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial.item", "sent.append"], "function", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.top_filtering", "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.top_filtering"], ["", "def", "generate_sentence", "(", "logits", ",", "past", ")", ":", "\n", "    ", "sent", "=", "[", "]", "\n", "prev_input", "=", "None", "\n", "logits", "=", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", "\n", "logits", "=", "top_filtering", "(", "logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "\n", "probs", "=", "torch", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "prev_input", "=", "torch", ".", "multinomial", "(", "probs", ",", "num_samples", "=", "1", ")", "\n", "prev_word", "=", "prev_input", ".", "item", "(", ")", "\n", "#if prev_word == eos[0]:", "\n", "#    break", "\n", "sent", ".", "append", "(", "prev_word", ")", "\n", "\n", "for", "i", "in", "range", "(", "500", ")", ":", "\n", "        ", "logits", ",", "past", "=", "model_B", "(", "prev_input", ",", "past", "=", "past", ")", "\n", "logits", "=", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", "\n", "logits", "=", "top_filtering", "(", "logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "\n", "probs", "=", "torch", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "prev_input", "=", "torch", ".", "multinomial", "(", "probs", ",", "num_samples", "=", "1", ")", "\n", "prev_word", "=", "prev_input", ".", "item", "(", ")", "\n", "\n", "if", "prev_word", "==", "eos", "[", "0", "]", ":", "\n", "            ", "break", "\n", "", "sent", ".", "append", "(", "prev_word", ")", "\n", "\n", "", "output", "=", "tokenizer", ".", "decode", "(", "sent", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.generate_response": [[157, 205], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "progress_bar", "enumerate", "json_list.append", "open", "json.dump", "sum", "enumerate", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "model_A", "all_logits.append", "generate.generate_sentence", "ref_output.append", "model_B", "all_logits.append", "ref_gt.append", "len", "len", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.generate.generate_sentence"], ["", "def", "generate_response", "(", "dataloader", ",", "all_pred", "=", "False", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "json_list", "=", "[", "]", "\n", "\n", "pbar", "=", "progress_bar", "(", "dataloader", ")", "\n", "\n", "total_ppl", "=", "[", "]", "\n", "predict_num", "=", "0", "\n", "correct_num", "=", "0", "\n", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "for", "batch", "in", "pbar", ":", "\n", "            ", "ref_dict", "=", "{", "}", "\n", "ref_gt", "=", "[", "]", "\n", "ref_output", "=", "[", "]", "\n", "if", "sum", "(", "[", "len", "(", "item", ")", "for", "item", "in", "batch", "[", "0", "]", "[", "1", "]", "]", ")", ">", "1024", ":", "\n", "                ", "total_length", "=", "0", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "batch", "[", "0", "]", "[", "1", "]", ")", ":", "\n", "                    ", "total_length", "=", "total_length", "+", "len", "(", "item", ")", "\n", "if", "total_length", ">=", "1024", ":", "\n", "                        ", "batch", "=", "[", "(", "batch", "[", "0", "]", "[", "0", "]", "[", "0", ":", "index", "-", "1", "]", ",", "batch", "[", "0", "]", "[", "1", "]", "[", "0", ":", "index", "-", "1", "]", ")", "]", "\n", "break", "\n", "\n", "", "", "", "role_ids", ",", "dialog_tokens", ",", "labels", ",", "conv", "=", "batch", "[", "0", "]", "\n", "dial_inputs", "=", "[", "torch", ".", "LongTensor", "(", "item", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "for", "item", "in", "dialog_tokens", "]", "\n", "\n", "past", "=", "None", "\n", "all_logits", "=", "[", "]", "\n", "running_loss", "=", "0.0", "\n", "for", "turn_num", ",", "dial_turn_inputs", "in", "enumerate", "(", "dial_inputs", ")", ":", "\n", "                ", "if", "role_ids", "[", "turn_num", "]", "==", "0", ":", "\n", "\n", "                    ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "generated_output", "=", "generate_sentence", "(", "logits", ",", "past", ")", "\n", "ref_output", ".", "append", "(", "generated_output", ")", "\n", "", "else", ":", "\n", "                    ", "logits", ",", "past", ",", "hidden", "=", "model_B", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "ref_gt", ".", "append", "(", "conv", "[", "turn_num", "]", ")", "\n", "\n", "", "", "ref_dict", "[", "'conv'", "]", "=", "conv", "\n", "ref_dict", "[", "'output'", "]", "=", "ref_output", "\n", "ref_dict", "[", "'ref'", "]", "=", "ref_gt", "\n", "json_list", ".", "append", "(", "ref_dict", ")", "\n", "", "with", "open", "(", "save_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "json_list", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.metrics.load_data": [[33, 43], ["enumerate", "open", "json.load"], "function", ["None"], ["def", "load_data", "(", "data_dir", ")", ":", "\n", "    ", "with", "open", "(", "data_dir", ",", "'r'", ")", "as", "f", ":", "\n", "#list of dicts", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "cands_list", "=", "[", "]", "\n", "refs_list", "=", "[", "]", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "cands_list", "+=", "d", "[", "'output'", "]", "\n", "refs_list", "+=", "d", "[", "'ref'", "]", "\n", "", "return", "data", ",", "cands_list", ",", "refs_list", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.metrics.pad_sequence": [[47, 77], ["iter", "itertools.chain", "itertools.chain"], "function", ["None"], ["", "def", "pad_sequence", "(", "sequence", ",", "n", ",", "pad_left", "=", "False", ",", "pad_right", "=", "False", ",", "\n", "left_pad_symbol", "=", "None", ",", "right_pad_symbol", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Returns a padded sequence of items before ngram extraction.\n        >>> list(pad_sequence([1,2,3,4,5], 2, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n        ['<s>', 1, 2, 3, 4, 5, '</s>']\n        >>> list(pad_sequence([1,2,3,4,5], 2, pad_left=True, left_pad_symbol='<s>'))\n        ['<s>', 1, 2, 3, 4, 5]\n        >>> list(pad_sequence([1,2,3,4,5], 2, pad_right=True, right_pad_symbol='</s>'))\n        [1, 2, 3, 4, 5, '</s>']\n    :param sequence: the source data to be padded\n    :type sequence: sequence or iter\n    :param n: the degree of the ngrams\n    :type n: int\n    :param pad_left: whether the ngrams should be left-padded\n    :type pad_left: bool\n    :param pad_right: whether the ngrams should be right-padded\n    :type pad_right: bool\n    :param left_pad_symbol: the symbol to use for left padding (default is None)\n    :type left_pad_symbol: any\n    :param right_pad_symbol: the symbol to use for right padding (default is None)\n    :type right_pad_symbol: any\n    :rtype: sequence or iter\n    \"\"\"", "\n", "sequence", "=", "iter", "(", "sequence", ")", "\n", "if", "pad_left", ":", "\n", "        ", "sequence", "=", "chain", "(", "(", "left_pad_symbol", ",", ")", "*", "(", "n", "-", "1", ")", ",", "sequence", ")", "\n", "", "if", "pad_right", ":", "\n", "        ", "sequence", "=", "chain", "(", "sequence", ",", "(", "right_pad_symbol", ",", ")", "*", "(", "n", "-", "1", ")", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.metrics.ngrams": [[79, 123], ["metrics.pad_sequence", "history.append", "history.append", "next", "tuple"], "function", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.metrics.pad_sequence"], ["", "def", "ngrams", "(", "sequence", ",", "n", ",", "pad_left", "=", "False", ",", "pad_right", "=", "False", ",", "\n", "left_pad_symbol", "=", "None", ",", "right_pad_symbol", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the ngrams generated from a sequence of items, as an iterator.\n    For example:\n        >>> from nltk.util import ngrams\n        >>> list(ngrams([1,2,3,4,5], 3))\n        [(1, 2, 3), (2, 3, 4), (3, 4, 5)]\n    Wrap with list for a list version of this function.  Set pad_left\n    or pad_right to true in order to get additional ngrams:\n        >>> list(ngrams([1,2,3,4,5], 2, pad_right=True))\n        [(1, 2), (2, 3), (3, 4), (4, 5), (5, None)]\n        >>> list(ngrams([1,2,3,4,5], 2, pad_right=True, right_pad_symbol='</s>'))\n        [(1, 2), (2, 3), (3, 4), (4, 5), (5, '</s>')]\n        >>> list(ngrams([1,2,3,4,5], 2, pad_left=True, left_pad_symbol='<s>'))\n        [('<s>', 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n        >>> list(ngrams([1,2,3,4,5], 2, pad_left=True, pad_right=True, left_pad_symbol='<s>', right_pad_symbol='</s>'))\n        [('<s>', 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, '</s>')]\n    :param sequence: the source data to be converted into ngrams\n    :type sequence: sequence or iter\n    :param n: the degree of the ngrams\n    :type n: int\n    :param pad_left: whether the ngrams should be left-padded\n    :type pad_left: bool\n    :param pad_right: whether the ngrams should be right-padded\n    :type pad_right: bool\n    :param left_pad_symbol: the symbol to use for left padding (default is None)\n    :type left_pad_symbol: any\n    :param right_pad_symbol: the symbol to use for right padding (default is None)\n    :type right_pad_symbol: any\n    :rtype: sequence or iter\n    \"\"\"", "\n", "sequence", "=", "pad_sequence", "(", "sequence", ",", "n", ",", "pad_left", ",", "pad_right", ",", "\n", "left_pad_symbol", ",", "right_pad_symbol", ")", "\n", "\n", "history", "=", "[", "]", "\n", "while", "n", ">", "1", ":", "\n", "        ", "history", ".", "append", "(", "next", "(", "sequence", ")", ")", "\n", "n", "-=", "1", "\n", "", "for", "item", "in", "sequence", ":", "\n", "        ", "history", ".", "append", "(", "item", ")", "\n", "#print('his: ',history)", "\n", "yield", "tuple", "(", "history", ")", "\n", "del", "history", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.metrics.distinct_n_sentence_level": [[124, 136], ["set", "len", "metrics.ngrams", "len", "len"], "function", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.metrics.ngrams"], ["", "", "def", "distinct_n_sentence_level", "(", "sentence", ",", "n", ")", ":", "\n", "    ", "\"\"\"\n    Compute distinct-N for a single sentence.\n    :param sentence: a list of words.\n    :param n: int, ngram.\n    :return: float, the metric value.\n    \"\"\"", "\n", "if", "len", "(", "sentence", ")", "==", "0", ":", "\n", "        ", "return", "0.0", "# Prevent a zero division", "\n", "", "distinct_ngrams", "=", "set", "(", "ngrams", "(", "sentence", ",", "n", ")", ")", "\n", "#print(distinct_ngrams)", "\n", "return", "len", "(", "distinct_ngrams", ")", "/", "len", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.PersonaDataset.__init__": [[62, 66], ["tokenizer.encode"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "turn_ending", "=", "tokenizer", ".", "encode", "(", "'<|endoftext|>'", ")", "# dialogpt pretrain approach", "\n", "#self.turn_ending = [628, 198] #628:\\n\\n 198:\\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.PersonaDataset.__len__": [[67, 69], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.PersonaDataset.__getitem__": [[70, 81], ["len", "len", "tokenizer.encode", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "conv", "=", "self", ".", "data", "[", "index", "]", "[", "'conv'", "]", "\n", "dial_tokens", "=", "[", "tokenizer", ".", "encode", "(", "item", ")", "+", "self", ".", "turn_ending", "for", "item", "in", "conv", "]", "\n", "role_ids", "=", "[", "0", ",", "1", "]", "*", "(", "len", "(", "conv", ")", "//", "2", ")", "\n", "\n", "#for labels", "\n", "labels", "=", "self", ".", "data", "[", "index", "]", "[", "'labels'", "]", "\n", "\n", "assert", "len", "(", "role_ids", ")", "==", "len", "(", "dial_tokens", ")", "\n", "return", "role_ids", ",", "dial_tokens", ",", "labels", ",", "conv", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.PersonaDataset.collate": [[82, 84], ["None"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "unpacked_data", ")", ":", "\n", "        ", "return", "unpacked_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.SequenceCrossEntropyLoss.__init__": [[87, 89], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.SequenceCrossEntropyLoss.forward": [[90, 95], ["eval_privacy.sequence_cross_entropy_with_logits"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.sequence_cross_entropy_with_logits"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", "=", "-", "1", ",", "reduce", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        reduce: None, \"batch\", \"sentence\"\n        \"\"\"", "\n", "return", "sequence_cross_entropy_with_logits", "(", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", ",", "reduce", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.persona_predict_model.__init__": [[97, 100], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_num", "=", "1024", ",", "out_num", "=", "8", ")", ":", "\n", "        ", "super", "(", "persona_predict_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_num", ",", "out_num", ")", "\n", "#self.act = F.softmax()", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.persona_predict_model.forward": [[102, 117], ["eval_privacy.persona_predict_model.fc1", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.size", "torch.mean.size", "torch.mean.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "out_shape", "=", "x", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "if", "(", "use_final_hidden_only", ")", ":", "\n", "# avg the info ", "\n", "            ", "x", "=", "torch", ".", "unsqueeze", "(", "x", "[", "-", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "", "assert", "(", "x", ".", "size", "(", ")", "[", "1", "]", "==", "out_shape", ")", "\n", "out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "#out = F.softmax(self.fc1(x),dim=1)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.persona_predict_model_2layer.__init__": [[119, 125], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_num", ",", "in_num", "=", "1024", ")", ":", "\n", "        ", "super", "(", "persona_predict_model_2layer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "hidden", "=", "512", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_num", ",", "hidden", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden", ",", "out_num", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "#self.act = F.softmax()", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.persona_predict_model_2layer.forward": [[127, 144], ["eval_privacy.persona_predict_model_2layer.fc1", "eval_privacy.persona_predict_model_2layer.relu", "eval_privacy.persona_predict_model_2layer.fc2", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.size", "torch.mean.size", "torch.mean.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "out_shape", "=", "x", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "if", "(", "use_final_hidden_only", ")", ":", "\n", "# avg the info ", "\n", "            ", "x", "=", "torch", ".", "unsqueeze", "(", "x", "[", "-", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "", "assert", "(", "x", ".", "size", "(", ")", "[", "1", "]", "==", "out_shape", ")", "\n", "out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "fc2", "(", "out", ")", "\n", "#out = F.softmax(self.fc1(x),dim=1)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.persona_predict_model_transformer.__init__": [[146, 150], ["torch.Module.__init__", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_num", ",", "in_num", "=", "1024", ")", ":", "\n", "        ", "super", "(", "persona_predict_model_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder_layer", "=", "nn", ".", "TransformerEncoderLayer", "(", "d_model", "=", "1024", ",", "nhead", "=", "8", ")", "#1024 as output", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "1024", ",", "out_num", ")", "\n", "#self.fc1 = nn.Linear(in_num, out_num)", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.persona_predict_model_transformer.forward": [[153, 166], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "eval_privacy.persona_predict_model_transformer.encoder_layer", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "eval_privacy.persona_predict_model_transformer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "x_resize", "=", "torch", ".", "unsqueeze", "(", "x", ",", "0", ")", "\n", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "#assert(x.size()[1] == out_shape)", "\n", "out", "=", "self", ".", "encoder_layer", "(", "x_resize", ")", "\n", "out_squeeze", "=", "torch", ".", "squeeze", "(", "out", ",", "0", ")", "\n", "# use avg hidden", "\n", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "final_out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "return", "final_out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.get_processed_persona": [[51, 60], ["open", "json.load"], "function", ["None"], ["def", "get_processed_persona", "(", "kind", ",", "require_label", "=", "True", ")", ":", "\n", "#processed_persona_path = config.processed_persona", "\n", "    ", "if", "(", "require_label", ")", ":", "\n", "        ", "path", "=", "processed_persona_path", "+", "'/case_study.txt'", "\n", "", "else", ":", "\n", "        ", "path", "=", "processed_persona_path", "+", "'/%s.txt'", "%", "kind", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.sequence_cross_entropy_with_logits": [[167, 207], ["logits.view", "torch.log_softmax", "targets.view().long", "negative_log_likelihood_flat.sum.view", "logits.size", "logits.size", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "negative_log_likelihood_flat.sum.sum", "targets.view", "float", "torch.gather", "torch.gather", "torch.gather", "loss.mean.sum", "loss.mean.mean", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "mask.sum"], "function", ["None"], ["", "", "def", "sequence_cross_entropy_with_logits", "(", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", ",", "reduce", ")", ":", "\n", "# type: (Tensor, Tensor, Tensor, float, bool)-> Tensor", "\n", "    ", "\"\"\"\n    label_smoothing : ``float``, optional (default = 0.0)\n        It should be smaller than 1.\n    \"\"\"", "\n", "# shape : (batch * sequence_length, num_classes)", "\n", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "\n", "# shape : (batch * sequence_length, num_classes)", "\n", "log_probs_flat", "=", "F", ".", "log_softmax", "(", "logits_flat", ",", "dim", "=", "-", "1", ")", "\n", "# shape : (batch * max_len, 1)", "\n", "targets_flat", "=", "targets", ".", "view", "(", "-", "1", ",", "1", ")", ".", "long", "(", ")", "\n", "\n", "if", "label_smoothing", ">", "0.0", ":", "\n", "        ", "num_classes", "=", "logits", ".", "size", "(", "-", "1", ")", "\n", "smoothing_value", "=", "label_smoothing", "/", "float", "(", "num_classes", ")", "\n", "# Fill all the correct indices with 1 - smoothing value.", "\n", "one_hot_targets", "=", "torch", ".", "zeros_like", "(", "log_probs_flat", ")", ".", "scatter_", "(", "-", "1", ",", "targets_flat", ",", "1.0", "-", "label_smoothing", ")", "\n", "smoothed_targets", "=", "one_hot_targets", "+", "smoothing_value", "\n", "negative_log_likelihood_flat", "=", "-", "log_probs_flat", "*", "smoothed_targets", "\n", "negative_log_likelihood_flat", "=", "negative_log_likelihood_flat", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "# shape : (batch * sequence_length, 1)", "\n", "        ", "negative_log_likelihood_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "targets_flat", ")", "\n", "\n", "# shape : (batch, sequence_length)", "\n", "", "negative_log_likelihood", "=", "negative_log_likelihood_flat", ".", "view", "(", "-", "1", ",", "logits", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# shape : (batch, sequence_length)", "\n", "loss", "=", "negative_log_likelihood", "*", "mask", "\n", "\n", "if", "reduce", ":", "\n", "# shape : (batch,)", "\n", "        ", "loss", "=", "loss", ".", "sum", "(", "1", ")", "/", "(", "mask", ".", "sum", "(", "1", ")", "+", "1e-13", ")", "\n", "\n", "if", "reduce", "is", "\"batch\"", ":", "\n", "# shape : scalar", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.train_one_iter": [[209, 276], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "all_logits[].contiguous", "[].contiguous", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "criterion", "criterion.backward", "numpy.exp", "print", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "max", "print", "lm_loss.item", "model_A", "all_logits[].contiguous.append", "model_B", "all_logits[].contiguous.append", "torch.squeeze", "torch.squeeze", "torch.squeeze", "external_model", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "external_criterion", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "external_model.size", "torch.softmax", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.log", "torch.log", "torch.log", "torch.mean", "torch.mean", "torch.mean", "torch.cat", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "function", ["None"], ["", "def", "train_one_iter", "(", "external_model", ",", "batch", ",", "update_count", ",", "fp16", "=", "False", ",", "require_KL_loss", "=", "False", ",", "KL_ratio", "=", "0.5", ",", "ga_ratio", "=", "0.1", ")", ":", "\n", "    ", "role_ids", ",", "dialog_tokens", ",", "labels", "=", "batch", "\n", "dial_inputs", "=", "[", "torch", ".", "LongTensor", "(", "item", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "for", "item", "in", "dialog_tokens", "]", "\n", "\n", "past", "=", "None", "\n", "all_logits", "=", "[", "]", "\n", "\n", "temp_sum", "=", "0", "\n", "\n", "running_loss", "=", "0.0", "\n", "for", "turn_num", ",", "dial_turn_inputs", "in", "enumerate", "(", "dial_inputs", ")", ":", "\n", "        ", "temp_sum", "+=", "1", "\n", "if", "role_ids", "[", "turn_num", "]", "==", "0", ":", "\n", "\n", "#logits, past = model_A(dial_turn_inputs, past=past)", "\n", "            ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "# hidden:torch.Size([1, 6, 1024])", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "", "else", ":", "\n", "#logits, past = model_B(dial_turn_inputs, past=past)", "\n", "            ", "logits", ",", "past", ",", "hidden", "=", "model_B", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "#now let's move to external module", "\n", "", "if", "(", "labels", "[", "turn_num", "]", ">=", "0", ")", ":", "\n", "            ", "hidden_out", "=", "torch", ".", "squeeze", "(", "hidden", "[", "-", "1", "]", ",", "0", ")", "\n", "external_out", "=", "external_model", "(", "hidden_out", ")", "\n", "assert", "external_out", ".", "ndim", "==", "2", "\n", "num_labels", "=", "external_out", ".", "size", "(", ")", "[", "1", "]", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "labels", "[", "turn_num", "]", "]", ")", ".", "to", "(", "device", ")", "\n", "external_loss", "=", "external_criterion", "(", "external_out", ",", "label", ")", "\n", "# gradient ascending use '-'", "\n", "running_loss", "+=", "external_loss", "\n", "if", "(", "require_KL_loss", ")", ":", "\n", "                ", "KL_loss", "=", "F", ".", "softmax", "(", "external_out", ",", "dim", "=", "1", ")", "\n", "KL_loss", "=", "torch", ".", "squeeze", "(", "KL_loss", ",", "0", ")", "\n", "KL_loss", "=", "torch", ".", "log", "(", "KL_loss", ")", "\n", "KL_loss", "=", "torch", ".", "mean", "(", "KL_loss", ")", "\n", "# KL divergence with uniform distribution", "\n", "running_loss", "-=", "KL_ratio", "*", "KL_loss", "\n", "#print('external_loss passed with loss:',external_loss)", "\n", "\n", "", "", "", "all_logits", "=", "torch", ".", "cat", "(", "all_logits", ",", "dim", "=", "1", ")", "#torch.Size([1, 611, 50257])", "\n", "\n", "# target", "\n", "all_logits", "=", "all_logits", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "torch", ".", "cat", "(", "dial_inputs", ",", "dim", "=", "1", ")", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "target_mask", "=", "torch", ".", "ones_like", "(", "target", ")", ".", "float", "(", ")", "\n", "\n", "loss", "=", "criterion", "(", "all_logits", ",", "target", ",", "target_mask", ",", "label_smoothing", "=", "0.02", ",", "reduce", "=", "\"batch\"", ")", "\n", "loss", "/=", "num_gradients_accumulation", "\n", "\n", "lm_loss", "=", "loss", "\n", "if", "(", "max", "(", "labels", ")", ">=", "0", ")", ":", "\n", "#lm_loss += loss", "\n", "        ", "loss", "+=", "ga_ratio", "*", "running_loss", "\n", "print", "(", "'---label training with loss: '", ",", "running_loss", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "record_loss", "=", "lm_loss", ".", "item", "(", ")", "*", "num_gradients_accumulation", "\n", "perplexity", "=", "np", ".", "exp", "(", "record_loss", ")", "\n", "#print(perplexity)", "\n", "#sys.exit(0)", "\n", "print", "(", "'training loss: '", ",", "loss", ",", "'PPL'", ",", "perplexity", ")", "\n", "#if(perplexity == 1):", "\n", "#    print('***Sentence: ',dial_inputs)", "\n", "return", "record_loss", ",", "perplexity", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.validate": [[278, 435], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "progress_bar", "eval_privacy.get_data_dist", "logger.info", "len", "numpy.random.randint", "sklearn.metrics.accuracy_score", "logger.info", "sklearn.metrics.accuracy_score", "logger.info", "sklearn.metrics.f1_score", "logger.info", "sklearn.metrics.f1_score", "logger.info", "numpy.histogram", "numpy.arange", "numpy.argmax", "logger.info", "numpy.histogram", "numpy.arange", "numpy.argmax", "logger.info", "logger.info", "logger.info", "logger.info", "numpy.array", "numpy.array", "numpy.array", "numpy.mean", "enumerate", "torch.cat", "torch.cat", "torch.cat", "all_logits[].contiguous", "[].contiguous", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "criterion", "torch.exp", "torch.exp", "torch.exp", "total_ppl.extend", "open", "json.dump", "sklearn.metrics.top_k_accuracy_score", "logger.info", "sum", "enumerate", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.exp.tolist", "numpy.arange", "zip", "numpy.arange", "zip", "range", "model_A", "all_logits[].contiguous.append", "model_B", "all_logits[].contiguous.append", "torch.squeeze", "torch.squeeze", "torch.squeeze", "external_model", "torch.softmax", "torch.squeeze", "torch.squeeze", "torch.squeeze", "np.array.append", "logits_list.append", "torch.kl_div().cpu", "torch.kl_div().cpu", "data_kl_list.append", "uni_kl_list.append", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.CrossEntropyLoss", "nn.CrossEntropyLoss.", "loss_list.append", "int", "int", "np.array.append", "y_pred.append", "conv_list.append", "torch.ones_like", "torch.ones_like", "torch.ones_like", "numpy.mean", "numpy.var", "numpy.mean", "numpy.mean", "numpy.mean", "len", "len", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.squeeze.cpu().detach().numpy", "external_criterion.cpu", "int.cpu", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.kl_div", "torch.kl_div", "torch.tensor", "torch.tensor", "torch.tensor", "int.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.squeeze.cpu().detach", "data_dist.log", "uni_dist.log", "torch.squeeze.cpu"], "function", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.get_data_dist"], ["", "def", "validate", "(", "dataloader", ",", "dataset", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "pbar", "=", "progress_bar", "(", "dataloader", ")", "\n", "data_count", ",", "data_dist", ",", "uni_dist", "=", "get_data_dist", "(", "dataset", ",", "num_labels", ")", "\n", "\n", "total_ppl", "=", "[", "]", "\n", "predict_num", "=", "0", "\n", "correct_num", "=", "0", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "conv_list", "=", "[", "]", "\n", "logits_list", "=", "[", "]", "\n", "y_scores", "=", "[", "]", "\n", "for", "batch", "in", "pbar", ":", "\n", "\n", "            ", "if", "sum", "(", "[", "len", "(", "item", ")", "for", "item", "in", "batch", "[", "0", "]", "[", "1", "]", "]", ")", ">", "1024", ":", "\n", "                ", "total_length", "=", "0", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "batch", "[", "0", "]", "[", "1", "]", ")", ":", "\n", "                    ", "total_length", "=", "total_length", "+", "len", "(", "item", ")", "\n", "if", "total_length", ">=", "1024", ":", "\n", "                        ", "batch", "=", "[", "(", "batch", "[", "0", "]", "[", "0", "]", "[", "0", ":", "index", "-", "1", "]", ",", "batch", "[", "0", "]", "[", "1", "]", "[", "0", ":", "index", "-", "1", "]", ")", "]", "\n", "break", "\n", "\n", "", "", "", "role_ids", ",", "dialog_tokens", ",", "labels", ",", "conv", "=", "batch", "[", "0", "]", "\n", "dial_inputs", "=", "[", "torch", ".", "LongTensor", "(", "item", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "for", "item", "in", "dialog_tokens", "]", "\n", "past", "=", "None", "\n", "\n", "\n", "all_logits", "=", "[", "]", "\n", "data_kl_list", "=", "[", "]", "\n", "uni_kl_list", "=", "[", "]", "\n", "loss_list", "=", "[", "]", "\n", "running_loss", "=", "0.0", "\n", "for", "turn_num", ",", "dial_turn_inputs", "in", "enumerate", "(", "dial_inputs", ")", ":", "\n", "                ", "conv_dict", "=", "{", "}", "\n", "if", "role_ids", "[", "turn_num", "]", "==", "0", ":", "\n", "                    ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "logits", ",", "past", ",", "hidden", "=", "model_B", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "#now let's move to external module", "\n", "", "if", "(", "labels", "[", "turn_num", "]", "<", "0", ")", ":", "\n", "                    ", "labels", "[", "turn_num", "]", "=", "0", "\n", "", "if", "(", "labels", "[", "turn_num", "]", ">=", "0", ")", ":", "\n", "#make prediction here", "\n", "                    ", "predict_num", "+=", "1", "\n", "hidden_out", "=", "torch", ".", "squeeze", "(", "hidden", "[", "-", "1", "]", ",", "0", ")", "\n", "external_out", "=", "external_model", "(", "hidden_out", ")", "\n", "est_dist", "=", "F", ".", "softmax", "(", "external_out", ")", "\n", "est_squeeze", "=", "torch", ".", "squeeze", "(", "est_dist", ")", "\n", "y_scores", ".", "append", "(", "est_squeeze", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "#y_scores.append()", "\n", "#logit_cpu = external_out.cpu()", "\n", "assert", "torch", ".", "sum", "(", "est_dist", ")", "-", "1", "<=", "1e-5", "\n", "assert", "external_out", ".", "ndim", "==", "2", "\n", "logits_list", ".", "append", "(", "est_dist", ")", "\n", "#data_kl = entropy(data_dist, logit_cpu)", "\n", "#uni_kl = entropy(uni_dist, logit_cpu)", "\n", "data_kl", "=", "F", ".", "kl_div", "(", "data_dist", ".", "log", "(", ")", ",", "est_dist", ")", ".", "cpu", "(", ")", "\n", "uni_kl", "=", "F", ".", "kl_div", "(", "uni_dist", ".", "log", "(", ")", ",", "est_dist", ")", ".", "cpu", "(", ")", "\n", "data_kl_list", ".", "append", "(", "data_kl", ")", "\n", "uni_kl_list", ".", "append", "(", "uni_kl", ")", "\n", "\n", "predict_label", "=", "torch", ".", "argmax", "(", "external_out", ")", "\n", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "labels", "[", "turn_num", "]", "]", ")", ".", "to", "(", "device", ")", "\n", "#print('label: ',label)", "\n", "#print('external_out: ',external_out.size())", "\n", "external_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "external_loss", "=", "external_criterion", "(", "external_out", ",", "label", ")", "\n", "loss_list", ".", "append", "(", "external_loss", ".", "cpu", "(", ")", ")", "\n", "#running_loss += external_loss", "\n", "#print('external_loss passed with loss:',external_loss)", "\n", "conv_dict", "[", "'context'", "]", "=", "conv", "[", "0", ":", "turn_num", "+", "1", "]", "\n", "conv_dict", "[", "'predict'", "]", "=", "id2persona", "[", "predict_label", ".", "item", "(", ")", "]", "\n", "conv_dict", "[", "'ground_truth'", "]", "=", "id2persona", "[", "labels", "[", "turn_num", "]", "]", "\n", "conv_dict", "[", "'correct_pred'", "]", "=", "'False'", "\n", "predict_label", "=", "int", "(", "predict_label", ".", "cpu", "(", ")", ")", "\n", "label", "=", "int", "(", "labels", "[", "turn_num", "]", ")", "\n", "y_true", ".", "append", "(", "label", ")", "\n", "y_pred", ".", "append", "(", "predict_label", ")", "\n", "if", "(", "predict_label", "==", "label", ")", ":", "\n", "                        ", "conv_dict", "[", "'correct_pred'", "]", "=", "'True'", "\n", "correct_num", "+=", "1", "\n", "", "conv_list", ".", "append", "(", "conv_dict", ")", "\n", "\n", "", "", "all_logits", "=", "torch", ".", "cat", "(", "all_logits", ",", "dim", "=", "1", ")", "\n", "\n", "# target", "\n", "all_logits", "=", "all_logits", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "torch", ".", "cat", "(", "dial_inputs", ",", "dim", "=", "1", ")", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "target_mask", "=", "torch", ".", "ones_like", "(", "target", ")", ".", "float", "(", ")", "\n", "\n", "\n", "\n", "\n", "loss", "=", "criterion", "(", "all_logits", ",", "target", ",", "target_mask", ",", "label_smoothing", "=", "-", "1", ",", "reduce", "=", "\"sentence\"", ")", "\n", "\n", "\n", "ppl", "=", "torch", ".", "exp", "(", "loss", ")", "\n", "total_ppl", ".", "extend", "(", "ppl", ".", "tolist", "(", ")", ")", "\n", "\n", "\n", "", "logger", ".", "info", "(", "f\"Epoch {ep} Validation Perplexity: {np.mean(total_ppl)} Variance: {np.var(total_ppl)}\"", ")", "\n", "with", "open", "(", "save_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "conv_list", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "predict_num", "=", "len", "(", "y_pred", ")", "\n", "random_prediction", "=", "np", ".", "random", ".", "randint", "(", "4332", ",", "size", "=", "predict_num", ")", "\n", "acc", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "logger", ".", "info", "(", "f\"Epoch {ep} Validation prediction acc: {acc} over {predict_num} instances\"", ")", "\n", "\n", "\n", "random_acc", "=", "accuracy_score", "(", "y_true", ",", "random_prediction", ")", "\n", "logger", ".", "info", "(", "f\"Epoch {ep} random prediction acc: {random_acc} over {predict_num} instances\"", ")", "\n", "\n", "f1", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'weighted'", ")", "\n", "logger", ".", "info", "(", "f\"Epoch {ep} weighted f1 score: {f1}\"", ")", "\n", "\n", "random_f1", "=", "f1_score", "(", "y_true", ",", "random_prediction", ",", "average", "=", "'weighted'", ")", "\n", "logger", ".", "info", "(", "f\"Epoch {ep} weighted random_f1 score: {random_f1}\"", ")", "\n", "\n", "hist_bins", "=", "np", ".", "histogram", "(", "y_true", ",", "bins", "=", "np", ".", "arange", "(", "4332", ")", ")", "\n", "bins", "=", "hist_bins", "[", "0", "]", "\n", "bins_key", "=", "np", ".", "arange", "(", "4332", ")", "\n", "bins_ratio", "=", "bins", "/", "predict_num", "\n", "bins_dict", "=", "{", "i", ":", "[", "j", ",", "k", "]", "for", "i", ",", "j", ",", "k", "in", "zip", "(", "bins_key", ",", "bins", ",", "bins_ratio", ")", "}", "\n", "index", "=", "np", ".", "argmax", "(", "bins_ratio", ")", "\n", "logger", ".", "info", "(", "f'max labels has id: {index} and ratio: {bins_dict[index]}'", ")", "\n", "\n", "hist_bins", "=", "np", ".", "histogram", "(", "y_pred", ",", "bins", "=", "np", ".", "arange", "(", "4332", ")", ")", "\n", "bins", "=", "hist_bins", "[", "0", "]", "\n", "bins_key", "=", "np", ".", "arange", "(", "4332", ")", "\n", "bins_ratio", "=", "bins", "/", "predict_num", "\n", "bins_dict", "=", "{", "i", ":", "[", "j", ",", "k", "]", "for", "i", ",", "j", ",", "k", "in", "zip", "(", "bins_key", ",", "bins", ",", "bins_ratio", ")", "}", "\n", "index", "=", "np", ".", "argmax", "(", "bins_ratio", ")", "\n", "logger", ".", "info", "(", "f'max predict labels has id: {index} and ratio: {bins_dict[index]}'", ")", "\n", "\n", "logger", ".", "info", "(", "f'data_kl_list: {np.mean(data_kl_list)}'", ")", "\n", "logger", ".", "info", "(", "f'uni_kl_list: {np.mean(uni_kl_list)}'", ")", "\n", "logger", ".", "info", "(", "f'loss_list: {np.mean(loss_list)}'", ")", "\n", "\n", "y_true", "=", "np", ".", "array", "(", "y_true", ")", "\n", "y_scores", "=", "np", ".", "array", "(", "y_scores", ")", "\n", "label_space", "=", "[", "i", "for", "i", "in", "range", "(", "num_labels", ")", "]", "\n", "label_space", "=", "np", ".", "array", "(", "label_space", ")", "\n", "\n", "k_list", "=", "[", "2", ",", "3", ",", "4", ",", "5", ",", "10", ",", "50", ",", "100", ",", "500", ",", "1000", ",", "2000", "]", "\n", "for", "k", "in", "k_list", ":", "\n", "            ", "top_k", "=", "top_k_accuracy_score", "(", "y_true", ",", "y_scores", ",", "k", "=", "k", ",", "labels", "=", "label_space", ")", "\n", "logger", ".", "info", "(", "f'top {k} acc score: {top_k}'", ")", "\n", "\n", "\n", "\n", "", "return", "np", ".", "mean", "(", "total_ppl", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.eval_privacy.get_data_dist": [[436, 447], ["torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones"], "function", ["None"], ["", "", "def", "get_data_dist", "(", "dataset", ",", "num_labels", ")", ":", "\n", "    ", "distribution", "=", "torch", ".", "zeros", "(", "num_labels", ")", ".", "cuda", "(", ")", "\n", "uni_dist", "=", "torch", ".", "ones", "(", "num_labels", ")", ".", "cuda", "(", ")", "\n", "uni_dist", "=", "uni_dist", "/", "num_labels", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "dataset", ")", ":", "\n", "        ", "labels", "=", "data", "[", "'labels'", "]", "\n", "for", "label", "in", "labels", ":", "\n", "            ", "if", "(", "label", ">=", "0", ")", ":", "\n", "                ", "distribution", "[", "label", "]", "+=", "1", "\n", "", "", "", "distribution_ratio", "=", "distribution", "/", "torch", ".", "sum", "(", "distribution", ")", "\n", "return", "distribution", ",", "distribution_ratio", ",", "uni_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.PersonaDataset.__init__": [[35, 39], ["tokenizer.encode"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "turn_ending", "=", "tokenizer", ".", "encode", "(", "'<|endoftext|>'", ")", "# dialogpt pretrain approach", "\n", "#self.turn_ending = [628, 198] #628:\\n\\n 198:\\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.PersonaDataset.__len__": [[40, 42], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.PersonaDataset.__getitem__": [[43, 54], ["len", "len", "tokenizer.encode", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "conv", "=", "self", ".", "data", "[", "index", "]", "[", "'conv'", "]", "\n", "dial_tokens", "=", "[", "tokenizer", ".", "encode", "(", "item", ")", "+", "self", ".", "turn_ending", "for", "item", "in", "conv", "]", "\n", "role_ids", "=", "[", "0", ",", "1", "]", "*", "(", "len", "(", "conv", ")", "//", "2", ")", "\n", "\n", "#for labels", "\n", "labels", "=", "self", ".", "data", "[", "index", "]", "[", "'labels'", "]", "\n", "\n", "assert", "len", "(", "role_ids", ")", "==", "len", "(", "dial_tokens", ")", "\n", "return", "role_ids", ",", "dial_tokens", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.PersonaDataset.collate": [[55, 57], ["None"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "unpacked_data", ")", ":", "\n", "        ", "return", "unpacked_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.SequenceCrossEntropyLoss.__init__": [[60, 62], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.SequenceCrossEntropyLoss.forward": [[63, 68], ["training_attacker.sequence_cross_entropy_with_logits"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.sequence_cross_entropy_with_logits"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", "=", "-", "1", ",", "reduce", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        reduce: None, \"batch\", \"sentence\"\n        \"\"\"", "\n", "return", "sequence_cross_entropy_with_logits", "(", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", ",", "reduce", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model.__init__": [[70, 73], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_num", ",", "in_num", "=", "1024", ")", ":", "\n", "        ", "super", "(", "persona_predict_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_num", ",", "out_num", ")", "\n", "#self.act = F.softmax()", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model.forward": [[75, 90], ["training_attacker.persona_predict_model.fc1", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.size", "torch.mean.size", "torch.mean.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "out_shape", "=", "x", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "if", "(", "use_final_hidden_only", ")", ":", "\n", "# avg the info ", "\n", "            ", "x", "=", "torch", ".", "unsqueeze", "(", "x", "[", "-", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "", "assert", "(", "x", ".", "size", "(", ")", "[", "1", "]", "==", "out_shape", ")", "\n", "out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "#out = F.softmax(self.fc1(x),dim=1)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_2layer.__init__": [[92, 98], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_num", ",", "in_num", "=", "1024", ")", ":", "\n", "        ", "super", "(", "persona_predict_model_2layer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "hidden", "=", "512", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_num", ",", "hidden", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden", ",", "out_num", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "#self.act = F.softmax()", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_2layer.forward": [[100, 117], ["training_attacker.persona_predict_model_2layer.fc1", "training_attacker.persona_predict_model_2layer.relu", "training_attacker.persona_predict_model_2layer.fc2", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.size", "torch.mean.size", "torch.mean.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "out_shape", "=", "x", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "if", "(", "use_final_hidden_only", ")", ":", "\n", "# avg the info ", "\n", "            ", "x", "=", "torch", ".", "unsqueeze", "(", "x", "[", "-", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "", "assert", "(", "x", ".", "size", "(", ")", "[", "1", "]", "==", "out_shape", ")", "\n", "out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "fc2", "(", "out", ")", "\n", "#out = F.softmax(self.fc1(x),dim=1)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__": [[119, 123], ["torch.Module.__init__", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.TransformerEncoderLayer", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_num", ",", "in_num", "=", "1024", ")", ":", "\n", "        ", "super", "(", "persona_predict_model_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder_layer", "=", "nn", ".", "TransformerEncoderLayer", "(", "d_model", "=", "1024", ",", "nhead", "=", "8", ")", "#1024 as output", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "1024", ",", "out_num", ")", "\n", "#self.fc1 = nn.Linear(in_num, out_num)", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.persona_predict_model_transformer.forward": [[126, 144], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "training_attacker.persona_predict_model_transformer.encoder_layer", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "training_attacker.persona_predict_model_transformer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_final_hidden_only", "=", "True", ")", ":", "\n", "# x should be of shape (?,1024) according to gpt2 output", "\n", "        ", "x_resize", "=", "torch", ".", "unsqueeze", "(", "x", ",", "0", ")", "\n", "\n", "# cut first dimension, now should of shape(1024) only", "\n", "# x = torch.squeeze(x, 0)", "\n", "#assert(x.size()[1] == out_shape)", "\n", "out", "=", "self", ".", "encoder_layer", "(", "x_resize", ")", "\n", "out_squeeze", "=", "torch", ".", "squeeze", "(", "out", ",", "0", ")", "\n", "# use avg hidden", "\n", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "final_out", "=", "self", ".", "fc1", "(", "x", ")", "\n", "#print(f'before encoder: {x_resize.size()}')", "\n", "#print(f'after encoder: {out.shape}')", "\n", "#print(f'after squeeze: {out_squeeze.shape}')", "\n", "#print(f'after fc1: {x.shape}')", "\n", "#print(f'final out: {final_out.shape}')", "\n", "return", "final_out", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.get_processed_persona": [[24, 33], ["open", "json.load"], "function", ["None"], ["def", "get_processed_persona", "(", "kind", ",", "require_label", "=", "True", ")", ":", "\n", "#processed_persona_path = config.processed_persona", "\n", "    ", "if", "(", "require_label", ")", ":", "\n", "        ", "path", "=", "processed_persona_path", "+", "'/%s_merged_shuffle.txt'", "%", "kind", "\n", "", "else", ":", "\n", "        ", "path", "=", "processed_persona_path", "+", "'/%s.txt'", "%", "kind", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.sequence_cross_entropy_with_logits": [[146, 186], ["logits.view", "torch.log_softmax", "targets.view().long", "negative_log_likelihood_flat.sum.view", "logits.size", "logits.size", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "negative_log_likelihood_flat.sum.sum", "targets.view", "float", "torch.gather", "torch.gather", "torch.gather", "loss.mean.sum", "loss.mean.mean", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "mask.sum"], "function", ["None"], ["", "", "def", "sequence_cross_entropy_with_logits", "(", "logits", ",", "targets", ",", "mask", ",", "label_smoothing", ",", "reduce", ")", ":", "\n", "# type: (Tensor, Tensor, Tensor, float, bool)-> Tensor", "\n", "    ", "\"\"\"\n    label_smoothing : ``float``, optional (default = 0.0)\n        It should be smaller than 1.\n    \"\"\"", "\n", "# shape : (batch * sequence_length, num_classes)", "\n", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "\n", "# shape : (batch * sequence_length, num_classes)", "\n", "log_probs_flat", "=", "F", ".", "log_softmax", "(", "logits_flat", ",", "dim", "=", "-", "1", ")", "\n", "# shape : (batch * max_len, 1)", "\n", "targets_flat", "=", "targets", ".", "view", "(", "-", "1", ",", "1", ")", ".", "long", "(", ")", "\n", "\n", "if", "label_smoothing", ">", "0.0", ":", "\n", "        ", "num_classes", "=", "logits", ".", "size", "(", "-", "1", ")", "\n", "smoothing_value", "=", "label_smoothing", "/", "float", "(", "num_classes", ")", "\n", "# Fill all the correct indices with 1 - smoothing value.", "\n", "one_hot_targets", "=", "torch", ".", "zeros_like", "(", "log_probs_flat", ")", ".", "scatter_", "(", "-", "1", ",", "targets_flat", ",", "1.0", "-", "label_smoothing", ")", "\n", "smoothed_targets", "=", "one_hot_targets", "+", "smoothing_value", "\n", "negative_log_likelihood_flat", "=", "-", "log_probs_flat", "*", "smoothed_targets", "\n", "negative_log_likelihood_flat", "=", "negative_log_likelihood_flat", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "# shape : (batch * sequence_length, 1)", "\n", "        ", "negative_log_likelihood_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "targets_flat", ")", "\n", "\n", "# shape : (batch, sequence_length)", "\n", "", "negative_log_likelihood", "=", "negative_log_likelihood_flat", ".", "view", "(", "-", "1", ",", "logits", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# shape : (batch, sequence_length)", "\n", "loss", "=", "negative_log_likelihood", "*", "mask", "\n", "\n", "if", "reduce", ":", "\n", "# shape : (batch,)", "\n", "        ", "loss", "=", "loss", ".", "sum", "(", "1", ")", "/", "(", "mask", ".", "sum", "(", "1", ")", "+", "1e-13", ")", "\n", "\n", "if", "reduce", "is", "\"batch\"", ":", "\n", "# shape : scalar", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.train_one_iter": [[188, 274], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "all_logits[].contiguous", "[].contiguous", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "criterion", "numpy.exp", "print", "criterion.backward", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "criterion.item", "max", "print", "model_A", "all_logits[].contiguous.append", "model_B", "all_logits[].contiguous.append", "torch.squeeze", "torch.squeeze", "torch.squeeze", "external_model", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.CrossEntropyLoss", "nn.CrossEntropyLoss.", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "external_model.size", "torch.softmax", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.log", "torch.log", "torch.log", "torch.mean", "torch.mean", "torch.mean", "torch.cat", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "function", ["None"], ["", "def", "train_one_iter", "(", "external_model", ",", "batch", ",", "update_count", ",", "fp16", "=", "False", ",", "require_KL_loss", "=", "False", ",", "KL_ratio", "=", "0.5", ",", "ga_ratio", "=", "0.1", ")", ":", "\n", "    ", "role_ids", ",", "dialog_tokens", ",", "labels", "=", "batch", "\n", "dial_inputs", "=", "[", "torch", ".", "LongTensor", "(", "item", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "for", "item", "in", "dialog_tokens", "]", "\n", "\n", "past", "=", "None", "\n", "all_logits", "=", "[", "]", "\n", "\n", "temp_sum", "=", "0", "\n", "\n", "running_loss", "=", "0.0", "\n", "for", "turn_num", ",", "dial_turn_inputs", "in", "enumerate", "(", "dial_inputs", ")", ":", "\n", "        ", "temp_sum", "+=", "1", "\n", "if", "role_ids", "[", "turn_num", "]", "==", "0", ":", "\n", "\n", "#logits, past = model_A(dial_turn_inputs, past=past)", "\n", "            ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "# hidden:torch.Size([1, 6, 1024])", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "", "else", ":", "\n", "#logits, past = model_B(dial_turn_inputs, past=past)", "\n", "            ", "logits", ",", "past", ",", "hidden", "=", "model_B", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "#now let's move to external module", "\n", "", "if", "(", "labels", "[", "turn_num", "]", ">=", "0", ")", ":", "\n", "            ", "hidden_out", "=", "torch", ".", "squeeze", "(", "hidden", "[", "-", "1", "]", ",", "0", ")", "\n", "external_out", "=", "external_model", "(", "hidden_out", ")", "\n", "assert", "external_out", ".", "ndim", "==", "2", "\n", "num_labels", "=", "external_out", ".", "size", "(", ")", "[", "1", "]", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "labels", "[", "turn_num", "]", "]", ")", ".", "to", "(", "device", ")", "\n", "#assign random label", "\n", "#label = np.random.randint(low=0,high=4332)", "\n", "#label = torch.tensor([label]).to(device)", "\n", "#print('label: ',label)", "\n", "#print('external_out: ',external_out.size())", "\n", "external_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "external_loss", "=", "external_criterion", "(", "external_out", ",", "label", ")", "\n", "# gradient ascending use '-'", "\n", "running_loss", "+=", "external_loss", "\n", "if", "(", "require_KL_loss", ")", ":", "\n", "                ", "KL_loss", "=", "F", ".", "softmax", "(", "external_out", ",", "dim", "=", "1", ")", "\n", "KL_loss", "=", "torch", ".", "squeeze", "(", "KL_loss", ",", "0", ")", "\n", "KL_loss", "=", "torch", ".", "log", "(", "KL_loss", ")", "\n", "KL_loss", "=", "torch", ".", "mean", "(", "KL_loss", ")", "\n", "# KL divergence with uniform distribution", "\n", "running_loss", "-=", "KL_ratio", "*", "KL_loss", "\n", "#print('external_loss passed with loss:',external_loss)", "\n", "\n", "# print('--'*20)", "\n", "# print('hidden:',len(hidden))", "\n", "# for i,h in enumerate(hidden):", "\n", "#     print(i,'-th hidden:',h.size())", "\n", "# if(temp_sum >= 5):", "\n", "#     sys.exit(0)", "\n", "", "", "", "all_logits", "=", "torch", ".", "cat", "(", "all_logits", ",", "dim", "=", "1", ")", "#torch.Size([1, 611, 50257])", "\n", "#print(all_logits.size())", "\n", "# sys.exit(0)", "\n", "\n", "\n", "\n", "# target", "\n", "all_logits", "=", "all_logits", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "torch", ".", "cat", "(", "dial_inputs", ",", "dim", "=", "1", ")", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "target_mask", "=", "torch", ".", "ones_like", "(", "target", ")", ".", "float", "(", ")", "\n", "\n", "\n", "#print(all_logits.size())", "\n", "#print(target.size())", "\n", "\n", "loss", "=", "criterion", "(", "all_logits", ",", "target", ",", "target_mask", ",", "label_smoothing", "=", "0.02", ",", "reduce", "=", "\"batch\"", ")", "\n", "loss", "/=", "num_gradients_accumulation", "\n", "record_loss", "=", "loss", ".", "item", "(", ")", "*", "num_gradients_accumulation", "\n", "perplexity", "=", "np", ".", "exp", "(", "record_loss", ")", "\n", "print", "(", "'training loss: '", ",", "loss", ",", "'PPL'", ",", "perplexity", ")", "\n", "#print('training loss: ', loss)", "\n", "#add external", "\n", "if", "(", "max", "(", "labels", ")", ">=", "0", ")", ":", "\n", "#lm_loss += loss", "\n", "\n", "        ", "loss", "+=", "ga_ratio", "*", "running_loss", "\n", "print", "(", "'---label training with loss: '", ",", "loss", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "\n", "return", "record_loss", ",", "perplexity", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_persona_leakage_and_defense_in_gpt-2.None.training_attacker.validate": [[276, 359], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "progress_bar", "print", "numpy.mean", "enumerate", "torch.cat", "torch.cat", "torch.cat", "all_logits[].contiguous", "[].contiguous", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "criterion", "torch.exp", "torch.exp", "torch.exp", "total_ppl.extend", "max", "print", "sum", "enumerate", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.LongTensor().unsqueeze().to", "torch.exp.tolist", "model_A", "all_logits[].contiguous.append", "model_B", "all_logits[].contiguous.append", "torch.squeeze", "torch.squeeze", "torch.squeeze", "external_model", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.ones_like", "torch.ones_like", "torch.ones_like", "numpy.mean", "numpy.var", "len", "len", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "function", ["None"], ["", "def", "validate", "(", "dataloader", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "pbar", "=", "progress_bar", "(", "dataloader", ")", "\n", "\n", "total_ppl", "=", "[", "]", "\n", "#total_ppl_recommender = []", "\n", "predict_num", "=", "0", "\n", "correct_num", "=", "0", "\n", "\n", "for", "batch", "in", "pbar", ":", "\n", "            ", "if", "sum", "(", "[", "len", "(", "item", ")", "for", "item", "in", "batch", "[", "0", "]", "[", "1", "]", "]", ")", ">", "1024", ":", "\n", "                ", "total_length", "=", "0", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "batch", "[", "0", "]", "[", "1", "]", ")", ":", "\n", "                    ", "total_length", "=", "total_length", "+", "len", "(", "item", ")", "\n", "if", "total_length", ">=", "1024", ":", "\n", "                        ", "batch", "=", "[", "(", "batch", "[", "0", "]", "[", "0", "]", "[", "0", ":", "index", "-", "1", "]", ",", "batch", "[", "0", "]", "[", "1", "]", "[", "0", ":", "index", "-", "1", "]", ")", "]", "\n", "break", "\n", "\n", "", "", "", "role_ids", ",", "dialog_tokens", ",", "labels", "=", "batch", "[", "0", "]", "\n", "dial_inputs", "=", "[", "torch", ".", "LongTensor", "(", "item", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "for", "item", "in", "dialog_tokens", "]", "\n", "#dial_inputs_rec = [torch.LongTensor(item).unsqueeze(0).to(device) for item in dialog_tokens if item[0] == 32]", "\n", "past", "=", "None", "\n", "all_logits", "=", "[", "]", "\n", "#all_logits_rec = []", "\n", "running_loss", "=", "0.0", "\n", "for", "turn_num", ",", "dial_turn_inputs", "in", "enumerate", "(", "dial_inputs", ")", ":", "\n", "                ", "if", "role_ids", "[", "turn_num", "]", "==", "0", ":", "\n", "#logits, past = model_A(dial_turn_inputs, past=past)", "\n", "                    ", "logits", ",", "past", ",", "hidden", "=", "model_A", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "\n", "#all_logits_rec.append(logits)", "\n", "", "else", ":", "\n", "#logits, past = model_B(dial_turn_inputs, past=past)", "\n", "                    ", "logits", ",", "past", ",", "hidden", "=", "model_B", "(", "dial_turn_inputs", ",", "past", "=", "past", ",", "output_hidden_states", "=", "True", ")", "\n", "all_logits", ".", "append", "(", "logits", ")", "\n", "#now let's move to external module", "\n", "", "if", "(", "labels", "[", "turn_num", "]", ">=", "0", ")", ":", "\n", "#make prediction here", "\n", "                    ", "predict_num", "+=", "1", "\n", "hidden_out", "=", "torch", ".", "squeeze", "(", "hidden", "[", "-", "1", "]", ",", "0", ")", "\n", "external_out", "=", "external_model", "(", "hidden_out", ")", "\n", "assert", "external_out", ".", "ndim", "==", "2", "\n", "predict_label", "=", "torch", ".", "argmax", "(", "external_out", ")", "\n", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "labels", "[", "turn_num", "]", "]", ")", ".", "to", "(", "device", ")", "\n", "#print('label: ',label)", "\n", "#print('external_out: ',external_out.size())", "\n", "#external_criterion = nn.CrossEntropyLoss()", "\n", "#external_loss = external_criterion(external_out,label)", "\n", "#running_loss += external_loss", "\n", "#print('external_loss passed with loss:',external_loss)", "\n", "if", "(", "predict_label", "==", "label", ")", ":", "\n", "                        ", "correct_num", "+=", "1", "\n", "\n", "", "", "", "all_logits", "=", "torch", ".", "cat", "(", "all_logits", ",", "dim", "=", "1", ")", "\n", "#all_logits_rec = torch.cat(all_logits_rec, dim=1)", "\n", "\n", "\n", "\n", "\n", "# target", "\n", "all_logits", "=", "all_logits", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "torch", ".", "cat", "(", "dial_inputs", ",", "dim", "=", "1", ")", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "target_mask", "=", "torch", ".", "ones_like", "(", "target", ")", ".", "float", "(", ")", "\n", "\n", "\n", "loss", "=", "criterion", "(", "all_logits", ",", "target", ",", "target_mask", ",", "label_smoothing", "=", "-", "1", ",", "reduce", "=", "\"sentence\"", ")", "\n", "\n", "\n", "ppl", "=", "torch", ".", "exp", "(", "loss", ")", "\n", "total_ppl", ".", "extend", "(", "ppl", ".", "tolist", "(", ")", ")", "\n", "\n", "#ppl_recommender = torch.exp(loss_recommender)", "\n", "#total_ppl_recommender.extend(ppl_recommender.tolist())", "\n", "\n", "", "print", "(", "f\"Epcoh {ep} Validation Perplexity: {np.mean(total_ppl)} Variance: {np.var(total_ppl)}\"", ")", "\n", "if", "(", "max", "(", "labels", ")", ">=", "0", ")", ":", "\n", "            ", "acc", "=", "correct_num", "/", "predict_num", "\n", "print", "(", "f\"Epcoh {ep} Validation prediction loss: {acc}\"", ")", "\n", "#print(f\"Epcoh {ep} Validation Perplexity on recommender (A): {np.mean(total_ppl_recommender)} Variance: {np.var(total_ppl_recommender)}\")", "\n", "\n", "", "return", "np", ".", "mean", "(", "total_ppl", ")", "\n", "\n"]]}